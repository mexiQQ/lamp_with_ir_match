


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 1 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 48.97it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9992715259422633
highest_index [0]
highest [0.9992715259422633]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.0055351257324219 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9447663426399231 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9361805319786072 for ['[CLS] ronnie huff [SEP]']
[Init] best rec loss: 0.9271856546401978 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9249287247657776 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8513282537460327 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.590 (perp=11.621, rec=0.255, cos=0.011), tot_loss_proj:2.656 [t=0.17s]
prediction: ['[CLS] severe disappointed [SEP]']
[ 100/2000] tot_loss=2.228 (perp=10.251, rec=0.174, cos=0.004), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.152 (perp=10.251, rec=0.101, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.136 (perp=10.251, rec=0.085, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.117 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.109 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.115 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.122 (perp=10.251, rec=0.070, cos=0.001), tot_loss_proj:2.117 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.103 (perp=10.251, rec=0.051, cos=0.001), tot_loss_proj:2.121 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.107 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.111 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.118 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.111 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.124 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.102 (perp=10.251, rec=0.051, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.105 (perp=10.251, rec=0.054, cos=0.001), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.120 (perp=10.251, rec=0.069, cos=0.001), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.117 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.115 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.109 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.122 (perp=10.251, rec=0.070, cos=0.001), tot_loss_proj:2.130 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.120 (perp=10.251, rec=0.068, cos=0.001), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.109 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.104 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.122 (perp=10.251, rec=0.070, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.124 (perp=10.251, rec=0.072, cos=0.001), tot_loss_proj:2.125 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.121 (perp=10.251, rec=0.069, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.115 (perp=10.251, rec=0.064, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.116 (perp=10.251, rec=0.065, cos=0.001), tot_loss_proj:2.107 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.119 (perp=10.251, rec=0.067, cos=0.001), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.110 (perp=10.251, rec=0.059, cos=0.001), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.104 (perp=10.251, rec=0.053, cos=0.001), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.095 (perp=10.251, rec=0.043, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.104 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.109 (perp=10.251, rec=0.057, cos=0.001), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.126 (perp=10.251, rec=0.075, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.106 (perp=10.251, rec=0.055, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.116 (perp=10.251, rec=0.065, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.114 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.099 (perp=10.251, rec=0.047, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.093 (perp=10.251, rec=0.041, cos=0.001), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:08:30 | total time: 0:08:30


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9993548278348494
highest_index [0]
highest [0.9993548278348494]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.0210397243499756 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9793888926506042 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8951830267906189 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.864271879196167 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8217445015907288 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8215807676315308 for ['[CLS] siam presidents [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.347 (perp=10.521, rec=0.240, cos=0.003), tot_loss_proj:2.661 [t=0.17s]
prediction: ['[CLS]tically successful [SEP]']
[ 100/2000] tot_loss=2.169 (perp=10.288, rec=0.110, cos=0.001), tot_loss_proj:2.351 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.148 (perp=10.288, rec=0.089, cos=0.001), tot_loss_proj:2.351 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.133 (perp=10.288, rec=0.074, cos=0.001), tot_loss_proj:2.343 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.909 (perp=9.171, rec=0.074, cos=0.001), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.904 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.886 (perp=9.171, rec=0.050, cos=0.001), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.908 (perp=9.171, rec=0.072, cos=0.001), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.903 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.894 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.901 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.902 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.896 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.882 (perp=9.171, rec=0.046, cos=0.001), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.904 (perp=9.171, rec=0.068, cos=0.001), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.885 (perp=9.171, rec=0.050, cos=0.001), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.896 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.888 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.905 (perp=9.171, rec=0.070, cos=0.001), tot_loss_proj:1.890 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.882 (perp=9.171, rec=0.047, cos=0.001), tot_loss_proj:1.889 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.888 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.891 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.895 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.881 (perp=9.171, rec=0.045, cos=0.001), tot_loss_proj:1.885 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.884 (perp=9.171, rec=0.048, cos=0.001), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.905 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.905 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.901 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.904 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.900 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.894 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.905 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.886 (perp=9.171, rec=0.051, cos=0.001), tot_loss_proj:1.897 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.888 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.902 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.878 (perp=9.171, rec=0.042, cos=0.001), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.890 (perp=9.171, rec=0.054, cos=0.001), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.884 (perp=9.171, rec=0.049, cos=0.001), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.902 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:08:10 | total time: 0:16:41


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9994340582458305
highest_index [0]
highest [0.9994340582458305]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8397367596626282 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.8254684805870056 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8126578330993652 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.805020809173584 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.7947117686271667 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7828556895256042 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 0.7795121073722839 for ['[CLS] would we working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.585 (perp=10.605, rec=0.443, cos=0.021), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] very momentum growth [SEP]']
[ 100/2000] tot_loss=2.425 (perp=10.888, rec=0.240, cos=0.007), tot_loss_proj:2.686 [t=0.17s]
prediction: ['[CLS] much momentum gaining [SEP]']
[ 150/2000] tot_loss=2.300 (perp=10.888, rec=0.121, cos=0.001), tot_loss_proj:2.701 [t=0.17s]
prediction: ['[CLS] much momentum gaining [SEP]']
[ 200/2000] tot_loss=2.266 (perp=10.888, rec=0.087, cos=0.001), tot_loss_proj:2.700 [t=0.17s]
prediction: ['[CLS] much momentum gaining [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.787 (perp=8.515, rec=0.083, cos=0.002), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.776 (perp=8.515, rec=0.072, cos=0.001), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.769 (perp=8.515, rec=0.065, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.774 (perp=8.515, rec=0.070, cos=0.001), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.788 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.771 (perp=8.515, rec=0.067, cos=0.001), tot_loss_proj:1.790 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.787 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.785 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.762 (perp=8.515, rec=0.058, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.753 (perp=8.515, rec=0.049, cos=0.001), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.786 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.786 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.785 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.756 (perp=8.515, rec=0.052, cos=0.001), tot_loss_proj:1.795 [t=0.20s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.786 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.788 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.754 (perp=8.515, rec=0.050, cos=0.001), tot_loss_proj:1.795 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.758 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.785 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.786 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.798 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.795 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.784 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.789 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.781 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.765 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.795 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.758 (perp=8.515, rec=0.054, cos=0.001), tot_loss_proj:1.786 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:07:39 | total time: 0:24:21


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9993001481006445
highest_index [0]
highest [0.9993001481006445]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.0116136074066162 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9035081267356873 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8794226050376892 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8757002949714661 for ['[CLS] role bart [SEP]']
[Init] best rec loss: 0.8483982086181641 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8467844724655151 for ['[CLS] canterbury havoc [SEP]']
[Init] best rec loss: 0.8355522155761719 for ['[CLS] anthony robin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.589 (perp=11.496, rec=0.285, cos=0.005), tot_loss_proj:2.765 [t=0.17s]
prediction: ['[CLS] smooth flawless [SEP]']
[ 100/2000] tot_loss=2.210 (perp=10.224, rec=0.163, cos=0.002), tot_loss_proj:2.377 [t=0.17s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.138 (perp=10.224, rec=0.091, cos=0.001), tot_loss_proj:2.370 [t=0.17s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.109 (perp=10.224, rec=0.063, cos=0.001), tot_loss_proj:2.371 [t=0.17s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.757 (perp=8.385, rec=0.079, cos=0.001), tot_loss_proj:1.771 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.753 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.730 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.760 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.754 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.731 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.746 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.752 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.728 (perp=8.385, rec=0.050, cos=0.001), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.742 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.758 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.745 (perp=8.385, rec=0.066, cos=0.001), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.726 (perp=8.385, rec=0.048, cos=0.001), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.750 (perp=8.385, rec=0.072, cos=0.001), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.746 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.746 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.740 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.731 (perp=8.385, rec=0.053, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.758 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.747 (perp=8.385, rec=0.069, cos=0.001), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.762 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.749 (perp=8.385, rec=0.070, cos=0.001), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.766 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.723 (perp=8.385, rec=0.045, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.757 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.744 (perp=8.385, rec=0.066, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.751 (perp=8.385, rec=0.073, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.741 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.733 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.731 (perp=8.385, rec=0.053, cos=0.001), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:08:09 | total time: 0:32:30


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.9992301171062454
highest_index [0]
highest [0.9992301171062454]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.0361230373382568 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9819928407669067 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.963243842124939 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9556242823600769 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 0.9394267797470093 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.9341257810592651 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.9212238788604736 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.9182291030883789 for ['[CLS] troupe stopped clayton [SEP]']
[Init] best rec loss: 0.8931007385253906 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.807 (perp=12.580, rec=0.283, cos=0.008), tot_loss_proj:3.146 [t=0.22s]
prediction: ['[CLS] tires uglyistle [SEP]']
[ 100/2000] tot_loss=1.622 (perp=7.516, rec=0.117, cos=0.002), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.590 (perp=7.516, rec=0.086, cos=0.002), tot_loss_proj:1.561 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.575 (perp=7.516, rec=0.070, cos=0.001), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.575 (perp=7.516, rec=0.070, cos=0.002), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.576 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.575 (perp=7.516, rec=0.070, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.574 (perp=7.516, rec=0.069, cos=0.001), tot_loss_proj:1.561 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.558 (perp=7.516, rec=0.054, cos=0.001), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.570 (perp=7.516, rec=0.065, cos=0.001), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.572 (perp=7.516, rec=0.067, cos=0.001), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.568 (perp=7.516, rec=0.064, cos=0.001), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.569 (perp=7.516, rec=0.064, cos=0.001), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.579 (perp=7.516, rec=0.074, cos=0.001), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.572 (perp=7.516, rec=0.067, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.570 (perp=7.516, rec=0.066, cos=0.001), tot_loss_proj:1.561 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.559 (perp=7.516, rec=0.055, cos=0.001), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.572 (perp=7.516, rec=0.068, cos=0.001), tot_loss_proj:1.560 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.567 (perp=7.516, rec=0.063, cos=0.001), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.568 (perp=7.516, rec=0.064, cos=0.001), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.578 (perp=7.516, rec=0.073, cos=0.001), tot_loss_proj:1.575 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.565 (perp=7.516, rec=0.061, cos=0.001), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.576 (perp=7.516, rec=0.072, cos=0.001), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.578 (perp=7.516, rec=0.073, cos=0.001), tot_loss_proj:1.582 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.553 (perp=7.516, rec=0.048, cos=0.001), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.563 (perp=7.516, rec=0.059, cos=0.001), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.559 (perp=7.516, rec=0.054, cos=0.001), tot_loss_proj:1.563 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.001), tot_loss_proj:1.556 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.001), tot_loss_proj:1.575 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.567 (perp=7.516, rec=0.063, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.568 (perp=7.516, rec=0.064, cos=0.001), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.557 (perp=7.516, rec=0.052, cos=0.001), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.560 (perp=7.516, rec=0.056, cos=0.001), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.001), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.563 (perp=7.516, rec=0.059, cos=0.001), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.548 (perp=7.516, rec=0.044, cos=0.001), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.001), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.554 (perp=7.516, rec=0.049, cos=0.001), tot_loss_proj:1.578 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.567 (perp=7.516, rec=0.063, cos=0.001), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.545 (perp=7.516, rec=0.040, cos=0.001), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:09:20 | total time: 0:41:51


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9993649146105028
highest_index [0]
highest [0.9993649146105028]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9572856426239014 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9517245292663574 for ['[CLS] stay orgasm [SEP]']
[Init] best rec loss: 0.9491873979568481 for ['[CLS] territorial half [SEP]']
[Init] best rec loss: 0.9308651685714722 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.927051305770874 for ['[CLS]iv fl [SEP]']
[Init] best rec loss: 0.9123218059539795 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8898680210113525 for ['[CLS] quiet. [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.640 (perp=12.316, rec=0.174, cos=0.004), tot_loss_proj:2.526 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 100/2000] tot_loss=2.564 (perp=12.316, rec=0.099, cos=0.002), tot_loss_proj:2.538 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 150/2000] tot_loss=2.535 (perp=12.316, rec=0.070, cos=0.001), tot_loss_proj:2.530 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 200/2000] tot_loss=2.542 (perp=12.316, rec=0.078, cos=0.001), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.452 (perp=11.854, rec=0.080, cos=0.001), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 300/2000] tot_loss=2.429 (perp=11.854, rec=0.057, cos=0.001), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.425 (perp=11.854, rec=0.052, cos=0.001), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.423 (perp=11.854, rec=0.051, cos=0.001), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.434 (perp=11.854, rec=0.062, cos=0.001), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.431 (perp=11.854, rec=0.059, cos=0.001), tot_loss_proj:2.580 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.429 (perp=11.854, rec=0.057, cos=0.001), tot_loss_proj:2.582 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.437 (perp=11.854, rec=0.065, cos=0.001), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.422 (perp=11.854, rec=0.050, cos=0.001), tot_loss_proj:2.579 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.439 (perp=11.854, rec=0.067, cos=0.001), tot_loss_proj:2.581 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.421 (perp=11.854, rec=0.049, cos=0.001), tot_loss_proj:2.588 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.440 (perp=11.854, rec=0.067, cos=0.001), tot_loss_proj:2.577 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.428 (perp=11.854, rec=0.056, cos=0.001), tot_loss_proj:2.585 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.440 (perp=11.854, rec=0.068, cos=0.001), tot_loss_proj:2.585 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.445 (perp=11.854, rec=0.073, cos=0.001), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.432 (perp=11.854, rec=0.060, cos=0.001), tot_loss_proj:2.586 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.592 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.429 (perp=11.854, rec=0.057, cos=0.001), tot_loss_proj:2.578 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.578 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.452 (perp=11.854, rec=0.080, cos=0.001), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.582 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.436 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.581 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.434 (perp=11.854, rec=0.062, cos=0.001), tot_loss_proj:2.577 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.438 (perp=11.854, rec=0.066, cos=0.001), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.581 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.442 (perp=11.854, rec=0.070, cos=0.001), tot_loss_proj:2.582 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.429 (perp=11.854, rec=0.056, cos=0.001), tot_loss_proj:2.587 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.440 (perp=11.854, rec=0.068, cos=0.001), tot_loss_proj:2.580 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.443 (perp=11.854, rec=0.071, cos=0.001), tot_loss_proj:2.588 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.432 (perp=11.854, rec=0.060, cos=0.001), tot_loss_proj:2.586 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.446 (perp=11.854, rec=0.074, cos=0.001), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.439 (perp=11.854, rec=0.067, cos=0.001), tot_loss_proj:2.579 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.437 (perp=11.854, rec=0.065, cos=0.001), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.438 (perp=11.854, rec=0.066, cos=0.001), tot_loss_proj:2.582 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.424 (perp=11.854, rec=0.052, cos=0.001), tot_loss_proj:2.572 [t=0.17s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:08:34 | total time: 0:50:26


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.999250469444722
highest_index [0]
highest [0.999250469444722]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9556694626808167 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9542555809020996 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9281026721000671 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.870527982711792 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8636731505393982 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8084701895713806 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7869214415550232 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7772212028503418 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.7523331046104431 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.7494601011276245 for ['[CLS] too u2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.093 (perp=8.874, rec=0.306, cos=0.012), tot_loss_proj:2.841 [t=0.18s]
prediction: ['[CLS] evil gray [SEP]']
[ 100/2000] tot_loss=1.578 (perp=6.813, rec=0.212, cos=0.004), tot_loss_proj:2.720 [t=0.17s]
prediction: ['[CLS] gray gray [SEP]']
[ 150/2000] tot_loss=1.557 (perp=6.813, rec=0.191, cos=0.003), tot_loss_proj:2.716 [t=0.18s]
prediction: ['[CLS] gray gray [SEP]']
[ 200/2000] tot_loss=2.218 (perp=10.460, rec=0.124, cos=0.002), tot_loss_proj:2.468 [t=0.20s]
prediction: ['[CLS]ish gray [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.708 (perp=8.089, rec=0.089, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.695 (perp=8.089, rec=0.075, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.680 (perp=8.089, rec=0.060, cos=0.002), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.687 (perp=8.089, rec=0.068, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.667 (perp=8.089, rec=0.047, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.671 (perp=8.089, rec=0.051, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.686 (perp=8.089, rec=0.067, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.674 (perp=8.089, rec=0.055, cos=0.001), tot_loss_proj:1.685 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.684 (perp=8.089, rec=0.065, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.687 (perp=8.089, rec=0.068, cos=0.001), tot_loss_proj:1.692 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.676 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.684 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.678 (perp=8.089, rec=0.059, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.677 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.681 (perp=8.089, rec=0.061, cos=0.001), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.698 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.678 (perp=8.089, rec=0.059, cos=0.001), tot_loss_proj:1.683 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=8.089, rec=0.055, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.674 (perp=8.089, rec=0.055, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.676 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.688 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.668 (perp=8.089, rec=0.049, cos=0.001), tot_loss_proj:1.690 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.684 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.001), tot_loss_proj:1.695 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.001), tot_loss_proj:1.697 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.686 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.679 (perp=8.089, rec=0.059, cos=0.001), tot_loss_proj:1.689 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.664 (perp=8.089, rec=0.045, cos=0.001), tot_loss_proj:1.698 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.001), tot_loss_proj:1.677 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.001), tot_loss_proj:1.676 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.678 (perp=8.089, rec=0.059, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:08:43 | total time: 0:59:09


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9991768686555793
highest_index [0]
highest [0.9991768686555793]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9112632274627686 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8373158574104309 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8293389678001404 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.7947319149971008 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.7944874167442322 for ['[CLS] manual main disease mukherjee pacific animal battalion classics careernies gold 17th none ranide on blow depending sony alec madagascar tourismzed moffat consisting life [SEP]']
[Init] best perm rec loss: 0.7915330529212952 for ['[CLS] blow animal disease manual consistingzedidenies battalion main pacific on career gold madagascar 17th mukherjee sony alec none depending classics ran life tourism moffat [SEP]']
[Init] best perm rec loss: 0.7903832793235779 for ['[CLS] ran tourism career 17th consisting battalionzed classics madagascar depending manual none gold blowide disease life mainnies animal alec pacific sony mukherjee moffat on [SEP]']
[Init] best perm rec loss: 0.790372371673584 for ['[CLS] none consistingnies depending tourism main moffat classics 17th animal blow alec battalion life ran manual on sony madagascar career goldzed diseaseide mukherjee pacific [SEP]']
[Init] best perm rec loss: 0.790019154548645 for ['[CLS] tourism aleczedidenies depending moffat blow 17th none ran pacific sony main gold madagascar mukherjee manual life classics consisting on disease battalion career animal [SEP]']
[Init] best perm rec loss: 0.7886852025985718 for ['[CLS] tourism disease mainide battalionnies 17th moffat on animal madagascar consistingzed life career sony ran pacific gold alec depending mukherjee manual blow none classics [SEP]']
[Init] best perm rec loss: 0.7882210612297058 for ['[CLS] gold 17th on classics sony blow career pacific battalionzed depending tourismnies ran mukherjee animal consisting diseaseide main madagascar life manual moffat alec none [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.816 (perp=11.896, rec=0.433, cos=0.004), tot_loss_proj:3.309 [t=0.17s]
prediction: ['[CLS] problem lackoid probably junk government exhaust just failure abandoned problem asbestosute - worst badly attempt bullshit rule allegedly. - discrimination - asshole blocked [SEP]']
[ 100/2000] tot_loss=2.601 (perp=11.245, rec=0.350, cos=0.002), tot_loss_proj:3.183 [t=0.17s]
prediction: ['[CLS] problem thingoid probably junk government ugly just late damn problem unidentified.pe archdiocese badly attempt issue systemus. instead discrimination - ugly blocked [SEP]']
[ 150/2000] tot_loss=2.286 (perp=9.995, rec=0.286, cos=0.001), tot_loss_proj:2.881 [t=0.20s]
prediction: ['[CLS] problem was? no ugly if ugly not late no offense unidentified.pe pmid badly were issuedeus. instead discrimination - ugly no [SEP]']
[ 200/2000] tot_loss=2.212 (perp=9.572, rec=0.293, cos=0.005), tot_loss_proj:2.773 [t=0.20s]
prediction: ['[CLS] problem was? is ugly if ugly not not no offense wrong.pepromising badly were issuedeus. he illusion - ugly no [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.244 (perp=9.559, rec=0.327, cos=0.005), tot_loss_proj:3.204 [t=0.18s]
prediction: ['[CLS] compliance is no want nothing tragedy example ; which relatives has uglyging problem was ) no excuses no ugly no not no invented ）. [SEP]']
[ 300/2000] tot_loss=2.111 (perp=9.311, rec=0.248, cos=0.001), tot_loss_proj:2.737 [t=0.18s]
prediction: ['[CLS]riety is no want he tonight or character appears satan has uglyging problem is ) is ugly no ugly no less / unless without. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.100 (perp=9.363, rec=0.226, cos=0.001), tot_loss_proj:2.771 [t=0.18s]
prediction: ['[CLS]pe is no fun hevilleable character which morals has uglyging problem is ) or only no ugly no less no myself or. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.011 (perp=9.060, rec=0.197, cos=0.002), tot_loss_proj:2.703 [t=0.24s]
prediction: ['[CLS] jamie is no pretty he hereable character which has otherwise uglyoid problem is ) or only hence ugly no less no myself without. [SEP]']
[ 450/2000] tot_loss=2.118 (perp=9.601, rec=0.196, cos=0.002), tot_loss_proj:2.748 [t=0.19s]
prediction: ['[CLS] jamie is no pretty he hereable character which has otherwise uglyoid problem is a or invisible mind ugly no mind no myself or. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.026 (perp=9.198, rec=0.184, cos=0.002), tot_loss_proj:2.646 [t=0.18s]
prediction: ['[CLS] jamie is no cute he hereable character which has otherwise uglyoid problem is invisible or a mind ugly no mind no myself without. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.939 (perp=8.832, rec=0.171, cos=0.001), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] jamie is no cute he hereable character which has otherwise uglyging problem is invisible or a ugly mind no mind no myself ;. [SEP]']
[ 600/2000] tot_loss=1.961 (perp=8.972, rec=0.165, cos=0.002), tot_loss_proj:2.612 [t=0.18s]
prediction: ['[CLS] jamie is no cute he hereable character which has otherwise uglyging problem is invisible or a ugly mind no mind no i ;. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.960 (perp=8.968, rec=0.165, cos=0.002), tot_loss_proj:3.573 [t=0.17s]
prediction: ['[CLS] jamie isville cute he noable character which has otherwise uglyging problem is invisible or the ugly mind no mind no i ;. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.854 (perp=8.429, rec=0.167, cos=0.001), tot_loss_proj:3.354 [t=0.18s]
prediction: ['[CLS] ے is here cute he noable character which has otherwise ugly i problem is invisible or the ugly mind no mind nooid ;. [SEP]']
[ 750/2000] tot_loss=1.846 (perp=8.433, rec=0.158, cos=0.002), tot_loss_proj:3.348 [t=0.18s]
prediction: ['[CLS] jamie is here cute he noable character which has otherwise ugly i problem is invisible or the ugly mind no mind nooid ;. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.808 (perp=8.216, rec=0.163, cos=0.002), tot_loss_proj:3.393 [t=0.18s]
prediction: ['[CLS] jamie is here cute he noable character which the otherwise ugly i problem is invisible or has ugly mind no mind nooid ;. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.842 (perp=8.403, rec=0.160, cos=0.001), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS] jamie is here cute he noable character which the otherwise ugly i problem is invisible or has ugly mind no mind notoid ;. [SEP]']
[ 900/2000] tot_loss=1.828 (perp=8.403, rec=0.146, cos=0.001), tot_loss_proj:3.412 [t=0.18s]
prediction: ['[CLS] jamie is here cute he noable character which the otherwise ugly i problem is invisible or has ugly mind no mind notoid ;. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.797 (perp=8.201, rec=0.155, cos=0.001), tot_loss_proj:2.416 [t=0.18s]
prediction: ['[CLS] jamie is here he no cuteable character again the otherwise ugly i problem is invisible or has ugly mind no mind notging ;. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.793 (perp=8.201, rec=0.151, cos=0.002), tot_loss_proj:2.420 [t=0.18s]
prediction: ['[CLS] jamie is here he no cuteable character again the otherwise ugly i problem is invisible or has ugly mind no mind notging ;. [SEP]']
[1050/2000] tot_loss=1.785 (perp=8.194, rec=0.145, cos=0.002), tot_loss_proj:2.388 [t=0.18s]
prediction: ['[CLS] jamie is here he no cuteable character again. otherwise ugly i problem is invisible or has ugly mind no mind notging ;. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.738 (perp=7.976, rec=0.141, cos=0.002), tot_loss_proj:2.360 [t=0.18s]
prediction: ['[CLS] jamie is here he no cuteable character again. otherwise invisible i problem is ugly or has ugly mind no mind notging ;. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.742 (perp=7.975, rec=0.145, cos=0.002), tot_loss_proj:2.473 [t=0.18s]
prediction: ['[CLS] jamie is here he no cuteable character again. otherwise i only problem is ugly or has ugly mind no mind notging ;. [SEP]']
[1200/2000] tot_loss=1.740 (perp=7.975, rec=0.144, cos=0.002), tot_loss_proj:2.475 [t=0.21s]
prediction: ['[CLS] jamie is here he no cuteable character again. otherwise i only problem is ugly or has ugly mind no mind notging ;. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.715 (perp=7.865, rec=0.141, cos=0.002), tot_loss_proj:2.404 [t=0.19s]
prediction: ['[CLS]ging is here he no cuteable character again. otherwise i only problem is ugly or has ugly mind no mind not jamie ;. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.687 (perp=7.719, rec=0.142, cos=0.001), tot_loss_proj:2.421 [t=0.22s]
prediction: ['[CLS]ging is here he no cuteable character again. otherwise i only problem is ugly or ugly has mind no mind not jamie ;. [SEP]']
[1350/2000] tot_loss=1.675 (perp=7.719, rec=0.130, cos=0.002), tot_loss_proj:2.418 [t=0.19s]
prediction: ['[CLS]ging is here he no cuteable character again. otherwise i only problem is ugly or ugly has mind no mind not jamie ;. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.710 (perp=7.862, rec=0.136, cos=0.002), tot_loss_proj:2.399 [t=0.19s]
prediction: ['[CLS]ging is here he no cuteable character again. otherwise i only problem here ugly or ugly has mind no mind not danny ;. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.585 (perp=7.234, rec=0.137, cos=0.002), tot_loss_proj:2.233 [t=0.19s]
prediction: ['[CLS]ging here he is no cuteable character again. otherwise i only problem here ugly or ugly has mind no mind not danny ;. [SEP]']
[1500/2000] tot_loss=1.741 (perp=8.028, rec=0.134, cos=0.002), tot_loss_proj:2.466 [t=0.19s]
prediction: ['[CLS]ging factor he is no cuteable character again. otherwise i only problem here ugly or ugly has mind no mind not danny ;. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.743 (perp=8.028, rec=0.136, cos=0.002), tot_loss_proj:2.472 [t=0.19s]
prediction: ['[CLS]ging factor he is no cuteable character again. otherwise i only problem here ugly or ugly has mind no mind not danny ;. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.663 (perp=7.593, rec=0.143, cos=0.002), tot_loss_proj:2.484 [t=0.18s]
prediction: ['[CLS] here factor he is no cuteable character again. otherwise i only problem little ugly or ugly has mind no mind not danny ;. [SEP]']
[1650/2000] tot_loss=1.750 (perp=8.059, rec=0.136, cos=0.002), tot_loss_proj:2.668 [t=0.18s]
prediction: ['[CLS] here factor he is no cuteable character again. otherwise i only problem little love or ugly has mind no mind not danny ;. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.631 (perp=7.456, rec=0.138, cos=0.002), tot_loss_proj:2.506 [t=0.18s]
prediction: ['[CLS] here factor he is no cuteable character again. otherwise i only love little problem or ugly has mind no mind not danny ;. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.617 (perp=7.392, rec=0.137, cos=0.001), tot_loss_proj:2.491 [t=0.18s]
prediction: ['[CLS] here factor he is no cuteable character again. otherwise i only love little problem or mind ugly has no mind not danny ;. [SEP]']
[1800/2000] tot_loss=1.643 (perp=7.500, rec=0.141, cos=0.002), tot_loss_proj:2.399 [t=0.18s]
prediction: ['[CLS] here factor he is no cuteable character again. otherwise i only love little problem or mind ugly has no mind no danny ;. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.539 (perp=7.036, rec=0.130, cos=0.002), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS] here factor he is no cuteable character again. otherwise i only love little problem or mind ugly ; no mind no danny has. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.525 (perp=6.974, rec=0.128, cos=0.002), tot_loss_proj:2.201 [t=0.17s]
prediction: ['[CLS] here little he is no cuteable character again. otherwise i only love factor problem or mind ugly ; no mind no danny has. [SEP]']
[1950/2000] tot_loss=1.528 (perp=6.974, rec=0.131, cos=0.002), tot_loss_proj:2.200 [t=0.17s]
prediction: ['[CLS] here little he is no cuteable character again. otherwise i only love factor problem or mind ugly ; no mind no danny has. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.537 (perp=6.974, rec=0.140, cos=0.002), tot_loss_proj:2.199 [t=0.17s]
prediction: ['[CLS] here little he is no cuteable character again. otherwise i only love factor problem or mind ugly ; no mind no danny has. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS]ging factor he is no cuteable character again. otherwise i only problem here ugly or ugly has mind no mind not danny ;. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.556 | p: 70.833 | r: 80.952
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 31.111 | p: 29.167 | r: 33.333
rougeLsum  | fm: 31.111 | p: 29.167 | r: 33.333
r1fm+r2fm = 75.556

[Aggregate metrics]:
rouge1     | fm: 96.944 | p: 96.354 | r: 97.619
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 88.264 | p: 88.021 | r: 88.542
rougeLsum  | fm: 88.264 | p: 88.021 | r: 88.542
r1fm+r2fm = 171.944

input #7 time: 0:08:57 | total time: 1:08:07


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9994032830483026
highest_index [0]
highest [0.9994032830483026]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.7545608878135681 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7099087834358215 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6953709125518799 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6868163347244263 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.6856463551521301 for ['[CLS] shouts guards germany space establishments sometimes flags dead rear protestant floyd breed article gut id occupational development institute loss joint hull meat mode required [SEP]']
[Init] best rec loss: 0.6826488375663757 for ['[CLS] normal bo set supreme something justified brahms mmmering age forward deafting wins backchen growth frozeere romney fighting crawl popularity copy [SEP]']
[Init] best rec loss: 0.6799412369728088 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.6793580651283264 for ['[CLS] sense bc dani actually ceased look thunder launch old doin translated ordainedrk case legal privately vatican pilot language sqldine turing midnight guard [SEP]']
[Init] best rec loss: 0.6682642102241516 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6651372313499451 for ['[CLS]dentey simei sweat franchise arkansas plaque facts canon february product res badminton screens adventuretta socially wanda prison eisenhower season tail dna [SEP]']
[Init] best perm rec loss: 0.6647960543632507 for ['[CLS] si socially tail dna wanda res arkansas february eisenhower screens sweat season franchiseey prison adventure product canonmeitta facts badminton plaquedent [SEP]']
[Init] best perm rec loss: 0.6633939146995544 for ['[CLS] dna sweat factsttadent sociallymei arkansas eisenhower si franchise canon adventure plaque season product tail res prison screens badminton wanda februaryey [SEP]']
[Init] best perm rec loss: 0.6628186106681824 for ['[CLS]mei si franchise wanda sweat product dna adventure eisenhowertta arkansas seasoney canon plaquedent tail february facts screens badminton res prison socially [SEP]']
[Init] best perm rec loss: 0.6616048216819763 for ['[CLS] res product socially badminton tail arkansas february facts sweat wandameident prison plaque eisenhower franchise adventure sitta dna seasoney screens canon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.024 (perp=12.983, rec=0.421, cos=0.007), tot_loss_proj:4.185 [t=0.19s]
prediction: ['[CLS] feeed prison remorse day felix puerto owed criminal partners crimes owed prison opera institute bargain bitch hearingsvita gift limousine strap kidnapping criminals [SEP]']
[ 100/2000] tot_loss=3.029 (perp=13.393, rec=0.347, cos=0.003), tot_loss_proj:4.182 [t=0.18s]
prediction: ['[CLS] feeed creation brute vanity paradox puerto vanity criminal colombia debt whatever prison gambling film perception drama vanity redding gift vanity strap mimic vanity [SEP]']
[ 150/2000] tot_loss=2.733 (perp=12.221, rec=0.288, cos=0.001), tot_loss_proj:4.037 [t=0.17s]
prediction: ['[CLS] beauxed film vanity vanity :mity vanity un colombia debt whatever prison gambling film vanity drama vanity redding must vanity pays vanity vanity [SEP]']
[ 200/2000] tot_loss=2.829 (perp=12.863, rec=0.256, cos=0.001), tot_loss_proj:4.060 [t=0.17s]
prediction: ['[CLS] beauxed film vanity vanity :endra vanity dread film debt what debt gambling film vanity natalie vanity cocaine horror vanity pays vanity vanity [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.594 (perp=11.804, rec=0.230, cos=0.003), tot_loss_proj:3.810 [t=0.17s]
prediction: ['[CLS] dollarsed film vanity vanity : vanity doubt dread film debt what debt gambling film vanity diversion vanity cocaine horror vanity pays vanity keeps [SEP]']
[ 300/2000] tot_loss=2.773 (perp=12.873, rec=0.195, cos=0.003), tot_loss_proj:4.202 [t=0.17s]
prediction: ['[CLS] percent doubt film vanity vanitytypic vanity doubt dread film debt what debt debt film vanity lisa vanity cocaine horror vanity pays vanitypoint [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.552 (perp=11.668, rec=0.204, cos=0.014), tot_loss_proj:3.888 [t=0.17s]
prediction: ['[CLS] percent doubt film vanity vanity : vanity doubt dread film debt what debt debt film vanity film vanity enforcement horror vanity pays vanity keeps [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.572 (perp=11.883, rec=0.192, cos=0.003), tot_loss_proj:3.943 [t=0.18s]
prediction: ['[CLS] percent doubt film vanity vanity greenish vanity doubt monitor film vanity what debt debt film vanity film vanity military horror vanity pays debt keeps [SEP]']
[ 450/2000] tot_loss=2.558 (perp=11.874, rec=0.176, cos=0.007), tot_loss_proj:3.711 [t=0.18s]
prediction: ["[CLS]'s film vanity vanity capcom vanity doubt monitor film vanity what debt debt film vanity film vanity cruiser horror vanity pays debt keeps [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.368 (perp=11.010, rec=0.166, cos=0.000), tot_loss_proj:3.627 [t=0.19s]
prediction: ["[CLS]'s tiberius vanity vanity capcom vanity doubt film that vanity what debt debt film vanity film felt cruiser horror vanity pays owed keeps [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.367 (perp=10.972, rec=0.162, cos=0.010), tot_loss_proj:3.435 [t=0.18s]
prediction: ["[CLS]'s desperately vanity film capcom vanity film doubt that vanity what debt debt film vanity film felt cruiser wonders vanity pays owed keeps [SEP]"]
[ 600/2000] tot_loss=2.353 (perp=10.999, rec=0.153, cos=0.001), tot_loss_proj:3.524 [t=0.18s]
prediction: ["[CLS]'s desperately vanity film capcom vanity film doubt that vanity what debt debt film vanity film felt dispose wonders vanity pays owed keeps [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.400 (perp=11.231, rec=0.152, cos=0.002), tot_loss_proj:3.742 [t=0.17s]
prediction: ["[CLS]'s desperately vanity film capcom vanity no doubt that fright what debt vanity film vanity europe felt enforcement horror vanity pays owed regarded [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.285 (perp=10.673, rec=0.149, cos=0.001), tot_loss_proj:3.570 [t=0.18s]
prediction: ["[CLS] that s desperately vanity film capcom vanity no doubt'fright what debt vanity film vanity europe felt upon horror vanity pays owed regarded [SEP]"]
[ 750/2000] tot_loss=2.264 (perp=10.573, rec=0.140, cos=0.010), tot_loss_proj:3.524 [t=0.17s]
prediction: ["[CLS] that s desperately vanity film capcom vanity no doubt'fright what debt vanity film vanity film felt upon horror vanity pays owed opinion [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.216 (perp=10.339, rec=0.144, cos=0.004), tot_loss_proj:3.303 [t=0.18s]
prediction: ["[CLS] that s desperately vanity film capcom vanity no doubt'positive what debt vanity film vanity film felt upon horror vanity pays owed fright [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.173 (perp=10.167, rec=0.139, cos=0.001), tot_loss_proj:3.355 [t=0.17s]
prediction: ["[CLS] that s desperately vanity film film vanity no doubt'lay what debt vanity film vanity capcom felt upon horror vanity pays owed fright [SEP]"]
[ 900/2000] tot_loss=2.106 (perp=9.829, rec=0.137, cos=0.003), tot_loss_proj:3.240 [t=0.18s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay what debt vanity film vanity capcom felt upon horror vanity pays owed fright [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.139 (perp=9.986, rec=0.141, cos=0.001), tot_loss_proj:3.000 [t=0.18s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay debt what vanity film vanity capcom felt upon wonders vanity pays owed fright [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=2.131 (perp=9.921, rec=0.145, cos=0.002), tot_loss_proj:3.218 [t=0.17s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay debt what film vanity capcom felt hats uponrri vanity pays owed fright [SEP]"]
[1050/2000] tot_loss=2.124 (perp=9.921, rec=0.136, cos=0.004), tot_loss_proj:3.219 [t=0.18s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay debt what film vanity capcom felt hats uponrri vanity pays owed fright [SEP]"]
Attempt swap
[1100/2000] tot_loss=2.124 (perp=9.921, rec=0.139, cos=0.001), tot_loss_proj:3.222 [t=0.18s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay debt what film vanity capcom felt hats uponrri vanity pays owed fright [SEP]"]
Attempt swap
[1150/2000] tot_loss=2.124 (perp=9.921, rec=0.138, cos=0.001), tot_loss_proj:3.214 [t=0.19s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay debt what film vanity capcom felt hats uponrri vanity pays owed fright [SEP]"]
[1200/2000] tot_loss=2.116 (perp=9.921, rec=0.128, cos=0.004), tot_loss_proj:3.215 [t=0.19s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay debt what film vanity capcom felt hats uponrri vanity pays owed fright [SEP]"]
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.986 (perp=9.216, rec=0.142, cos=0.001), tot_loss_proj:2.985 [t=0.21s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay debt what film vanity'felt owed hats upon again vanity pays fright [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=2.207 (perp=10.367, rec=0.132, cos=0.002), tot_loss_proj:3.428 [t=0.19s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay debt what film vanity capcom vanity felt owed hats benignrri pays fright [SEP]"]
[1350/2000] tot_loss=2.255 (perp=10.613, rec=0.131, cos=0.001), tot_loss_proj:3.519 [t=0.19s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'lay debt whatmax vanity'vanity felt owed hats benignrri pays fright [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.286 (perp=10.769, rec=0.131, cos=0.001), tot_loss_proj:3.745 [t=0.22s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'benign debt whatmax felt'vanity vanity owed hats benignrri pays fright [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=2.164 (perp=10.159, rec=0.131, cos=0.001), tot_loss_proj:3.482 [t=0.17s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'benign debt whatmax felt vanity vanity owed hats benignrri, pays fright [SEP]"]
[1500/2000] tot_loss=2.158 (perp=10.159, rec=0.125, cos=0.001), tot_loss_proj:3.475 [t=0.17s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'benign debt whatmax felt vanity vanity owed hats benignrri, pays fright [SEP]"]
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.060 (perp=9.639, rec=0.131, cos=0.001), tot_loss_proj:3.294 [t=0.17s]
prediction: ["[CLS] that s un vanity film film vanity no doubt'benign debt what benignrrimax felt vanity vanity owed hats, pays fright [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.028 (perp=9.435, rec=0.139, cos=0.001), tot_loss_proj:3.229 [t=0.17s]
prediction: ["[CLS] that s un vanity film film fright no doubt'benign debt what benignrrimax felt vanity vanity owed hats, pays vanity [SEP]"]
[1650/2000] tot_loss=2.136 (perp=9.997, rec=0.136, cos=0.001), tot_loss_proj:3.307 [t=0.17s]
prediction: ["[CLS] that s fright vanity film film fright no doubt'benign debt what benignrrimax felt vanity vanity owed hats, pays vanity [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.070 (perp=9.650, rec=0.139, cos=0.001), tot_loss_proj:3.313 [t=0.18s]
prediction: ["[CLS] that s benign vanity film film fright no doubt'un debt what benignrrimax felt vanity vanity owed hats, pays vanity [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.016 (perp=9.435, rec=0.128, cos=0.001), tot_loss_proj:3.232 [t=0.18s]
prediction: ["[CLS] that s un vanity film film fright no doubt'benign debt what benignrrimax felt vanity vanity owed hats, pays vanity [SEP]"]
[1800/2000] tot_loss=2.013 (perp=9.435, rec=0.125, cos=0.001), tot_loss_proj:3.229 [t=0.18s]
prediction: ["[CLS] that s un vanity film film fright no doubt'benign debt what benignrrimax felt vanity vanity owed hats, pays vanity [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=2.146 (perp=10.088, rec=0.127, cos=0.001), tot_loss_proj:3.485 [t=0.17s]
prediction: ["[CLS] that s fright vanity film film fright no doubt'benign debt what benignrrimax felt vanity owed hats'vanity pays vanity [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.064 (perp=9.642, rec=0.134, cos=0.002), tot_loss_proj:3.414 [t=0.18s]
prediction: ["[CLS] that s hats vanity film film fright no doubt'benign debt what benignrrimax felt vanity owed fright, vanity pays vanity [SEP]"]
[1950/2000] tot_loss=2.065 (perp=9.642, rec=0.135, cos=0.001), tot_loss_proj:3.415 [t=0.17s]
prediction: ["[CLS] that s hats vanity film film fright no doubt'benign debt what benignrrimax felt vanity owed fright, vanity pays vanity [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=2.027 (perp=9.460, rec=0.134, cos=0.001), tot_loss_proj:3.365 [t=0.17s]
prediction: ["[CLS] that s vanity film film fright no doubt'benign hats debt what benignrrimax felt vanity owed fright, vanity pays vanity [SEP]"]
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] that s un vanity film film vanity no doubt'benign debt whatmax felt vanity vanity owed hats benignrri, pays fright [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 54.545 | r: 60.000
rouge2     | fm: 10.000 | p: 9.524 | r: 10.526
rougeL     | fm: 47.619 | p: 45.455 | r: 50.000
rougeLsum  | fm: 47.619 | p: 45.455 | r: 50.000
r1fm+r2fm = 67.143

[Aggregate metrics]:
rouge1     | fm: 92.522 | p: 91.709 | r: 93.439
rouge2     | fm: 67.778 | p: 67.725 | r: 67.836
rougeL     | fm: 83.748 | p: 83.291 | r: 84.259
rougeLsum  | fm: 83.748 | p: 83.291 | r: 84.259
r1fm+r2fm = 160.300

input #8 time: 0:10:15 | total time: 1:18:22


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9993981275486599
highest_index [0]
highest [0.9993981275486599]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8187081217765808 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.7782889604568481 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7333240509033203 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7192718386650085 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6858556866645813 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6808661222457886 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6510923504829407 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6500662565231323 for ['[CLS] cody luck deaths outlaw decca arsenaldden edward [SEP]']
[Init] best perm rec loss: 0.6491195559501648 for ['[CLS]dden deaths arsenal luck decca outlaw cody edward [SEP]']
[Init] best perm rec loss: 0.648005485534668 for ['[CLS] outlaw deaths luckdden cody edward arsenal decca [SEP]']
[Init] best perm rec loss: 0.6462655663490295 for ['[CLS] decca cody luck edward deaths outlawdden arsenal [SEP]']
[Init] best perm rec loss: 0.6440391540527344 for ['[CLS] cody decca deaths arsenal luck edwarddden outlaw [SEP]']
[Init] best perm rec loss: 0.6436610221862793 for ['[CLS] cody decca outlaw luck arsenal edwarddden deaths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.977 (perp=13.047, rec=0.357, cos=0.011), tot_loss_proj:3.831 [t=0.19s]
prediction: ['[CLS] bubba double rope crazylogue pu keeper would [SEP]']
[ 100/2000] tot_loss=2.777 (perp=12.417, rec=0.291, cos=0.002), tot_loss_proj:4.270 [t=0.19s]
prediction: ['[CLS] her double turbo metaphysical clap extremely clap will [SEP]']
[ 150/2000] tot_loss=2.514 (perp=11.438, rec=0.224, cos=0.002), tot_loss_proj:3.590 [t=0.19s]
prediction: ['[CLS] oftra clap soft clap ethical claptra [SEP]']
[ 200/2000] tot_loss=2.838 (perp=13.236, rec=0.186, cos=0.005), tot_loss_proj:3.573 [t=0.17s]
prediction: ['[CLS] oftra clap softhead ethical claptra [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.073 (perp=9.496, rec=0.168, cos=0.005), tot_loss_proj:3.010 [t=0.17s]
prediction: ['[CLS] of clap claphead soft clap claptra [SEP]']
[ 300/2000] tot_loss=2.431 (perp=11.408, rec=0.148, cos=0.001), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] oftra claphead soft metaphysical claptra [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.303 (perp=10.757, rec=0.151, cos=0.001), tot_loss_proj:3.216 [t=0.17s]
prediction: ['[CLS]headtra clap of soft metaphysical claptra [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.177 (perp=10.167, rec=0.142, cos=0.002), tot_loss_proj:3.192 [t=0.17s]
prediction: ['[CLS]head of claptra soft metaphysical claptra [SEP]']
[ 450/2000] tot_loss=2.170 (perp=10.167, rec=0.136, cos=0.001), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS]head of claptra soft metaphysical claptra [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.945 (perp=8.976, rec=0.147, cos=0.003), tot_loss_proj:2.903 [t=0.17s]
prediction: ['[CLS]head of metaphysical claptra soft claptra [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.414 (perp=11.399, rec=0.133, cos=0.001), tot_loss_proj:3.478 [t=0.17s]
prediction: ['[CLS]head of metaphysical claptra soft metaphysicaltra [SEP]']
[ 600/2000] tot_loss=2.408 (perp=11.399, rec=0.127, cos=0.001), tot_loss_proj:3.482 [t=0.17s]
prediction: ['[CLS]head of metaphysical claptra soft metaphysicaltra [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.210 (perp=10.391, rec=0.131, cos=0.001), tot_loss_proj:2.855 [t=0.17s]
prediction: ['[CLS] metaphysical of metaphysical claptra softheadtra [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.176 (perp=10.251, rec=0.125, cos=0.001), tot_loss_proj:2.684 [t=0.17s]
prediction: ['[CLS] of metaphysical metaphysical claptra softheadtra [SEP]']
[ 750/2000] tot_loss=2.178 (perp=10.251, rec=0.127, cos=0.001), tot_loss_proj:2.679 [t=0.17s]
prediction: ['[CLS] of metaphysical metaphysical claptra softheadtra [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.079 (perp=9.772, rec=0.124, cos=0.001), tot_loss_proj:2.793 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.076 (perp=9.772, rec=0.121, cos=0.001), tot_loss_proj:2.793 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
[ 900/2000] tot_loss=2.068 (perp=9.772, rec=0.113, cos=0.001), tot_loss_proj:2.795 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.072 (perp=9.772, rec=0.116, cos=0.001), tot_loss_proj:2.796 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1000/2000] tot_loss=2.080 (perp=9.772, rec=0.125, cos=0.001), tot_loss_proj:2.800 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
[1050/2000] tot_loss=2.071 (perp=9.772, rec=0.115, cos=0.001), tot_loss_proj:2.803 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1100/2000] tot_loss=2.055 (perp=9.772, rec=0.100, cos=0.001), tot_loss_proj:2.799 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1150/2000] tot_loss=2.059 (perp=9.772, rec=0.104, cos=0.001), tot_loss_proj:2.800 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
[1200/2000] tot_loss=2.067 (perp=9.772, rec=0.112, cos=0.001), tot_loss_proj:2.801 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1250/2000] tot_loss=2.069 (perp=9.772, rec=0.114, cos=0.001), tot_loss_proj:2.802 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1300/2000] tot_loss=2.059 (perp=9.772, rec=0.104, cos=0.001), tot_loss_proj:2.795 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
[1350/2000] tot_loss=2.054 (perp=9.772, rec=0.098, cos=0.001), tot_loss_proj:2.797 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1400/2000] tot_loss=2.061 (perp=9.772, rec=0.106, cos=0.001), tot_loss_proj:2.797 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1450/2000] tot_loss=2.051 (perp=9.772, rec=0.095, cos=0.001), tot_loss_proj:2.795 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
[1500/2000] tot_loss=2.062 (perp=9.772, rec=0.106, cos=0.001), tot_loss_proj:2.793 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1550/2000] tot_loss=2.057 (perp=9.772, rec=0.102, cos=0.001), tot_loss_proj:2.802 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1600/2000] tot_loss=2.049 (perp=9.772, rec=0.094, cos=0.001), tot_loss_proj:2.798 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
[1650/2000] tot_loss=2.045 (perp=9.772, rec=0.090, cos=0.001), tot_loss_proj:2.794 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1700/2000] tot_loss=2.047 (perp=9.772, rec=0.092, cos=0.001), tot_loss_proj:2.800 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1750/2000] tot_loss=2.044 (perp=9.772, rec=0.088, cos=0.001), tot_loss_proj:2.797 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
[1800/2000] tot_loss=2.051 (perp=9.772, rec=0.095, cos=0.001), tot_loss_proj:2.801 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1850/2000] tot_loss=2.049 (perp=9.772, rec=0.094, cos=0.001), tot_loss_proj:2.803 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[1900/2000] tot_loss=2.048 (perp=9.772, rec=0.093, cos=0.001), tot_loss_proj:2.799 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
[1950/2000] tot_loss=2.047 (perp=9.772, rec=0.091, cos=0.001), tot_loss_proj:2.804 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Attempt swap
[2000/2000] tot_loss=2.043 (perp=9.772, rec=0.087, cos=0.001), tot_loss_proj:2.797 [t=0.17s]
prediction: ['[CLS] oftra metaphysical claptra softhead metaphysical [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] oftra metaphysical claptra softhead metaphysical [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 46.154 | p: 42.857 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 46.154 | p: 42.857 | r: 50.000
rougeLsum  | fm: 46.154 | p: 42.857 | r: 50.000
r1fm+r2fm = 46.154

[Aggregate metrics]:
rouge1     | fm: 87.885 | p: 86.824 | r: 89.286
rouge2     | fm: 61.000 | p: 60.952 | r: 61.053
rougeL     | fm: 80.135 | p: 79.508 | r: 80.833
rougeLsum  | fm: 79.988 | p: 79.248 | r: 80.833
r1fm+r2fm = 148.885

input #9 time: 0:08:25 | total time: 1:26:48


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9991472052153934
highest_index [0]
highest [0.9991472052153934]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8814778923988342 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8704736828804016 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8242684602737427 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8198046684265137 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8065224885940552 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8059665560722351 for ['[CLS] help reachercar hid championship immediately besideselin accompanied eva nervous pounded swing [SEP]']
[Init] best perm rec loss: 0.8049544095993042 for ['[CLS] help nervouscarelin besides reacher championship swing pounded hid immediately accompanied eva [SEP]']
[Init] best perm rec loss: 0.8048099279403687 for ['[CLS] hid helpcar pounded eva immediately besideselin swing reacher championship accompanied nervous [SEP]']
[Init] best perm rec loss: 0.8033286333084106 for ['[CLS] besides nervous immediately eva hid swing pounded reacherelincar accompanied help championship [SEP]']
[Init] best perm rec loss: 0.8032909035682678 for ['[CLS]car championship hid accompanied reacher swing evaelin immediately nervous help pounded besides [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.134 (perp=13.748, rec=0.378, cos=0.006), tot_loss_proj:3.737 [t=0.17s]
prediction: ['[CLS] ab enterprise sweet, pictorialion eva institution traditionally maddie dynamics henry pieces [SEP]']
[ 100/2000] tot_loss=2.559 (perp=11.358, rec=0.286, cos=0.002), tot_loss_proj:3.303 [t=0.17s]
prediction: ['[CLS] ab compositions often, based stress balance experimental independent jacket dynamics ; outward [SEP]']
[ 150/2000] tot_loss=2.746 (perp=12.531, rec=0.238, cos=0.002), tot_loss_proj:3.645 [t=0.17s]
prediction: ['[CLS] ab compositions often. baseding balance experimental independently maddie percussion ; spectators [SEP]']
[ 200/2000] tot_loss=2.157 (perp=9.598, rec=0.226, cos=0.012), tot_loss_proj:3.100 [t=0.17s]
prediction: ['[CLS] ablyulsive. balance balance balance experimentally prop rhythms. spectators [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.418 (perp=10.828, rec=0.248, cos=0.004), tot_loss_proj:2.847 [t=0.17s]
prediction: ['[CLS] ably rhythm. spatialing balance experimentally blade intelligent clarinet theatrical [SEP]']
[ 300/2000] tot_loss=2.356 (perp=10.804, rec=0.192, cos=0.004), tot_loss_proj:2.897 [t=0.17s]
prediction: ['[CLS] ably rhythm. symbolicing balance experimentally ridge intelligent clarinet when [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.114 (perp=9.710, rec=0.170, cos=0.002), tot_loss_proj:2.674 [t=0.19s]
prediction: ['[CLS] ably rhythms. ridgeing balance balancely symbolic intelligent clarinet. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.069 (perp=9.476, rec=0.169, cos=0.004), tot_loss_proj:2.881 [t=0.17s]
prediction: ['[CLS] ab clarinet rhythms with ridgeing balance balancely spatialulsively when [SEP]']
[ 450/2000] tot_loss=1.993 (perp=9.188, rec=0.154, cos=0.002), tot_loss_proj:2.825 [t=0.17s]
prediction: ['[CLS] ab clarinet rhythms with ridgeed balance balancely spatialulsively. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.881 (perp=8.694, rec=0.140, cos=0.002), tot_loss_proj:2.946 [t=0.18s]
prediction: ['[CLS] ab initiated rhythms with ridge incident balance balance spatiallyulsively. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.923 (perp=8.888, rec=0.144, cos=0.001), tot_loss_proj:2.658 [t=0.17s]
prediction: ['[CLS] ab prop times rhythms with incident balance realulsivelyulsively. [SEP]']
[ 600/2000] tot_loss=1.902 (perp=8.888, rec=0.122, cos=0.002), tot_loss_proj:2.659 [t=0.17s]
prediction: ['[CLS] ab prop times rhythms with incident balance realulsivelyulsively. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.737 (perp=8.041, rec=0.127, cos=0.002), tot_loss_proj:3.057 [t=0.18s]
prediction: ['[CLS] ab balance time rhythms with - balance propulsivelyulsively. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.979 (perp=8.808, rec=0.213, cos=0.005), tot_loss_proj:3.053 [t=0.17s]
prediction: ['[CLS] ab balance - rhythms. with balance ridge spatiallyulsively ; [SEP]']
[ 750/2000] tot_loss=2.038 (perp=9.330, rec=0.170, cos=0.002), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] ab balance - rhythms. with balance ridge timelyulsively ; [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.989 (perp=9.163, rec=0.155, cos=0.002), tot_loss_proj:3.205 [t=0.17s]
prediction: ['[CLS] ab balance times rhythms. with balance proply timeulsively ; [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.940 (perp=8.950, rec=0.148, cos=0.002), tot_loss_proj:2.756 [t=0.17s]
prediction: ['[CLS] ab real times rhythms ; with balance proply timeulsively. [SEP]']
[ 900/2000] tot_loss=2.138 (perp=9.938, rec=0.148, cos=0.002), tot_loss_proj:3.204 [t=0.17s]
prediction: ['[CLS] ab real times rhythms ; with balance proply timeulsiveulsive. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.834 (perp=8.516, rec=0.129, cos=0.002), tot_loss_proj:2.748 [t=0.17s]
prediction: ['[CLS] ab real time rhythms ; with balance timely propulsiveulsive. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.663 (perp=7.626, rec=0.136, cos=0.002), tot_loss_proj:2.768 [t=0.17s]
prediction: ['[CLS] ab real time rhythms ; with balance timeulsively propulsive. [SEP]']
[1050/2000] tot_loss=1.904 (perp=8.842, rec=0.134, cos=0.002), tot_loss_proj:2.846 [t=0.19s]
prediction: ['[CLS] ab real time rhythms. with balance timeulsively incidentulsive. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.784 (perp=8.277, rec=0.126, cos=0.002), tot_loss_proj:2.619 [t=0.17s]
prediction: ['[CLS] ab. real time rhythms with balance timeulsively incidentulsive. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.773 (perp=8.203, rec=0.131, cos=0.002), tot_loss_proj:2.661 [t=0.17s]
prediction: ['[CLS] ab. real time rhythms with time balanceulsively incidentulsive. [SEP]']
[1200/2000] tot_loss=1.779 (perp=8.203, rec=0.137, cos=0.002), tot_loss_proj:2.663 [t=0.17s]
prediction: ['[CLS] ab. real time rhythms with time balanceulsively incidentulsive. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.814 (perp=8.424, rec=0.128, cos=0.002), tot_loss_proj:2.566 [t=0.17s]
prediction: ['[CLS] ab. real time rhythms with time balanceulsively incident real. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.653 (perp=7.619, rec=0.127, cos=0.002), tot_loss_proj:2.418 [t=0.17s]
prediction: ['[CLS] ab. incident real time rhythms with time balanceulsively real. [SEP]']
[1350/2000] tot_loss=1.723 (perp=8.065, rec=0.108, cos=0.002), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] ab. incident real time rhythms with incident balanceulsively real. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.704 (perp=7.873, rec=0.128, cos=0.002), tot_loss_proj:2.602 [t=0.17s]
prediction: ['[CLS] time ab. incident real rhythms with incident balanceulsively real. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.697 (perp=7.873, rec=0.121, cos=0.002), tot_loss_proj:2.610 [t=0.19s]
prediction: ['[CLS] time ab. incident real rhythms with incident balanceulsively real. [SEP]']
[1500/2000] tot_loss=1.688 (perp=7.873, rec=0.112, cos=0.002), tot_loss_proj:2.607 [t=0.17s]
prediction: ['[CLS] time ab. incident real rhythms with incident balanceulsively real. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.701 (perp=7.873, rec=0.124, cos=0.002), tot_loss_proj:2.609 [t=0.17s]
prediction: ['[CLS] time ab. incident real rhythms with incident balanceulsively real. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.795 (perp=8.360, rec=0.122, cos=0.002), tot_loss_proj:2.473 [t=0.19s]
prediction: ['[CLS] time ab incident. real rhythms withulsive balanceulsively real. [SEP]']
[1650/2000] tot_loss=1.800 (perp=8.360, rec=0.126, cos=0.002), tot_loss_proj:2.476 [t=0.19s]
prediction: ['[CLS] time ab incident. real rhythms withulsive balanceulsively real. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.625 (perp=7.446, rec=0.134, cos=0.002), tot_loss_proj:2.596 [t=0.19s]
prediction: ['[CLS] time abulsive. real rhythms with incident balanceulsively real. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.593 (perp=7.328, rec=0.125, cos=0.002), tot_loss_proj:2.820 [t=0.17s]
prediction: ['[CLS] time abulsive. real rhythms incident with balanceulsively real. [SEP]']
[1800/2000] tot_loss=1.600 (perp=7.328, rec=0.133, cos=0.002), tot_loss_proj:2.821 [t=0.17s]
prediction: ['[CLS] time abulsive. real rhythms incident with balanceulsively real. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.582 (perp=7.328, rec=0.115, cos=0.002), tot_loss_proj:2.830 [t=0.18s]
prediction: ['[CLS] time abulsive. real rhythms incident with balanceulsively real. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.588 (perp=7.328, rec=0.121, cos=0.002), tot_loss_proj:2.826 [t=0.17s]
prediction: ['[CLS] time abulsive. real rhythms incident with balanceulsively real. [SEP]']
[1950/2000] tot_loss=1.601 (perp=7.328, rec=0.134, cos=0.002), tot_loss_proj:2.823 [t=0.18s]
prediction: ['[CLS] time abulsive. real rhythms incident with balanceulsively real. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.603 (perp=7.342, rec=0.133, cos=0.002), tot_loss_proj:2.733 [t=0.17s]
prediction: ['[CLS] time abulsive. real incident rhythms with balanceulsively real. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] time abulsive. real rhythms incident with balanceulsively real. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.000 | p: 70.000 | r: 70.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 70.000

[Aggregate metrics]:
rouge1     | fm: 86.205 | p: 85.218 | r: 87.359
rouge2     | fm: 55.455 | p: 55.411 | r: 55.502
rougeL     | fm: 77.262 | p: 76.825 | r: 78.030
rougeLsum  | fm: 77.395 | p: 76.825 | r: 78.030
r1fm+r2fm = 141.659

input #10 time: 0:10:28 | total time: 1:37:16


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9992849825911105
highest_index [0]
highest [0.9992849825911105]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.9119930863380432 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.9002856016159058 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8241632580757141 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.8143832683563232 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.8102236986160278 for ['[CLS]ture inlandvd tal me platform drawngu mile familiar [SEP]']
[Init] best perm rec loss: 0.8092162609100342 for ['[CLS] inlandture drawngu platform tal familiar mevd mile [SEP]']
[Init] best perm rec loss: 0.8080193400382996 for ['[CLS] inland mevdgu mile tal drawn familiarture platform [SEP]']
[Init] best perm rec loss: 0.8064080476760864 for ['[CLS] inland me milevd platformture familiar talgu drawn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.711 (perp=11.452, rec=0.417, cos=0.004), tot_loss_proj:3.649 [t=0.18s]
prediction: ['[CLS] missing earlier blockted pole not driven wards damage struggling [SEP]']
[ 100/2000] tot_loss=2.630 (perp=11.498, rec=0.329, cos=0.002), tot_loss_proj:4.151 [t=0.19s]
prediction: ['[CLS] not attempted gelted horse never refused gel opinion refused [SEP]']
[ 150/2000] tot_loss=2.421 (perp=10.723, rec=0.274, cos=0.002), tot_loss_proj:3.516 [t=0.17s]
prediction: ['[CLS] that attempted gel to gel refused refused gel stubborn refused [SEP]']
[ 200/2000] tot_loss=2.372 (perp=10.723, rec=0.226, cos=0.002), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] that attempted gel to gel refused refused gel stubborn refused [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.475 (perp=11.248, rec=0.222, cos=0.003), tot_loss_proj:3.419 [t=0.17s]
prediction: ['[CLS] that attempted gel to gelusly refused stubborn refused here [SEP]']
[ 300/2000] tot_loss=2.376 (perp=11.049, rec=0.165, cos=0.001), tot_loss_proj:3.283 [t=0.17s]
prediction: ['[CLS] that attempted gel to herely refused stubborn refused here [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.968 (perp=9.110, rec=0.144, cos=0.001), tot_loss_proj:2.774 [t=0.19s]
prediction: ['[CLS] that attempted gel to stubbornly refused here refused here [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.990 (perp=9.319, rec=0.125, cos=0.001), tot_loss_proj:2.763 [t=0.17s]
prediction: ['[CLS] that attempted gel was stubbornly stubborn refused here here [SEP]']
[ 450/2000] tot_loss=1.977 (perp=9.319, rec=0.112, cos=0.001), tot_loss_proj:2.761 [t=0.17s]
prediction: ['[CLS] that attempted gel was stubbornly stubborn refused here here [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.848 (perp=8.702, rec=0.107, cos=0.001), tot_loss_proj:2.637 [t=0.19s]
prediction: ['[CLS] that attempted gel was here stubbornly stubborn refused here [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.813 (perp=8.522, rec=0.108, cos=0.001), tot_loss_proj:2.664 [t=0.19s]
prediction: ['[CLS] that attempted here was gel stubbornly stubborn refused here [SEP]']
[ 600/2000] tot_loss=1.810 (perp=8.522, rec=0.104, cos=0.001), tot_loss_proj:2.671 [t=0.19s]
prediction: ['[CLS] that attempted here was gel stubbornly stubborn refused here [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.799 (perp=8.522, rec=0.094, cos=0.001), tot_loss_proj:2.664 [t=0.19s]
prediction: ['[CLS] that attempted here was gel stubbornly stubborn refused here [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.782 (perp=8.426, rec=0.096, cos=0.001), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused here [SEP]']
[ 750/2000] tot_loss=1.788 (perp=8.426, rec=0.102, cos=0.001), tot_loss_proj:2.483 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused here [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.784 (perp=8.426, rec=0.098, cos=0.001), tot_loss_proj:2.485 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused here [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.778 (perp=8.426, rec=0.091, cos=0.001), tot_loss_proj:2.476 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused here [SEP]']
[ 900/2000] tot_loss=1.715 (perp=8.075, rec=0.099, cos=0.001), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.709 (perp=8.075, rec=0.092, cos=0.001), tot_loss_proj:2.506 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
Attempt swap
[1000/2000] tot_loss=1.713 (perp=8.075, rec=0.097, cos=0.001), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
[1050/2000] tot_loss=1.704 (perp=8.075, rec=0.087, cos=0.001), tot_loss_proj:2.509 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.701 (perp=8.075, rec=0.084, cos=0.001), tot_loss_proj:2.518 [t=0.19s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.707 (perp=8.075, rec=0.090, cos=0.001), tot_loss_proj:2.510 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
[1200/2000] tot_loss=1.702 (perp=8.075, rec=0.086, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
Attempt swap
[1250/2000] tot_loss=1.705 (perp=8.075, rec=0.089, cos=0.001), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
Attempt swap
[1300/2000] tot_loss=1.711 (perp=8.075, rec=0.094, cos=0.001), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
[1350/2000] tot_loss=1.704 (perp=8.075, rec=0.087, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
Attempt swap
[1400/2000] tot_loss=1.706 (perp=8.075, rec=0.089, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.709 (perp=8.075, rec=0.093, cos=0.001), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
[1500/2000] tot_loss=1.692 (perp=8.075, rec=0.076, cos=0.001), tot_loss_proj:2.522 [t=0.17s]
prediction: ['[CLS] that attempted here was gel stubborn stubbornly refused to [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.590 (perp=7.521, rec=0.084, cos=0.001), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.586 (perp=7.521, rec=0.081, cos=0.001), tot_loss_proj:1.970 [t=0.19s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
[1650/2000] tot_loss=1.584 (perp=7.521, rec=0.079, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.583 (perp=7.521, rec=0.077, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.595 (perp=7.521, rec=0.090, cos=0.001), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
[1800/2000] tot_loss=1.589 (perp=7.521, rec=0.084, cos=0.001), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.585 (perp=7.521, rec=0.079, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.589 (perp=7.521, rec=0.083, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
[1950/2000] tot_loss=1.574 (perp=7.521, rec=0.069, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.587 (perp=7.521, rec=0.081, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] that attempted here was stubborn stubbornly refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 140.909

[Aggregate metrics]:
rouge1     | fm: 86.597 | p: 85.703 | r: 87.652
rouge2     | fm: 55.833 | p: 55.754 | r: 55.921
rougeL     | fm: 76.812 | p: 76.267 | r: 77.588
rougeLsum  | fm: 76.884 | p: 76.281 | r: 77.588
r1fm+r2fm = 142.430

input #11 time: 0:10:26 | total time: 1:47:43


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.99934391763152
highest_index [0]
highest [0.99934391763152]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.867132842540741 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.861339807510376 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.799628496170044 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7725229263305664 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7675877213478088 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.743887186050415 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7403388023376465 for ['[CLS] ha guess shades margin office series bethitasyn few victor laynction translate [SEP]']
[Init] best perm rec loss: 0.7387611269950867 for ['[CLS] guess beth ha few series shadesitas translate office marginnction layyn victor [SEP]']
[Init] best perm rec loss: 0.7375137805938721 for ['[CLS]nction translate few victor beth office margin series shades haitas guessyn lay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.853 (perp=12.210, rec=0.406, cos=0.005), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] handicapaur barelymarket ago lay on internet accused avoid television freak cable cable [SEP]']
[ 100/2000] tot_loss=2.290 (perp=10.055, rec=0.276, cos=0.002), tot_loss_proj:2.930 [t=0.20s]
prediction: ['[CLS] handicapphone barely better might lay on attack would better advantage threat advantage cable [SEP]']
[ 150/2000] tot_loss=2.394 (perp=10.873, rec=0.217, cos=0.002), tot_loss_proj:3.243 [t=0.19s]
prediction: ['[CLS] handicapphone barely better will record on attack would better better listed advantage cable [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.387, rec=0.184, cos=0.002), tot_loss_proj:3.033 [t=0.19s]
prediction: ['[CLS] handicapination barely better will seen on against considering better on listed advantage cable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.174 (perp=10.086, rec=0.155, cos=0.001), tot_loss_proj:2.927 [t=0.17s]
prediction: ['[CLS] handicapination barely better will seen to crow considering better on cable advantage because [SEP]']
[ 300/2000] tot_loss=2.114 (perp=9.877, rec=0.136, cos=0.002), tot_loss_proj:2.803 [t=0.17s]
prediction: ['[CLS] thoughination barely better will seen to crow considering better on cable advantage because [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.038 (perp=9.572, rec=0.122, cos=0.002), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] which nomination barely better will seen to crow considering on cable better advantage because [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.942 (perp=9.114, rec=0.119, cos=0.001), tot_loss_proj:2.685 [t=0.17s]
prediction: ['[CLS] its barely better will seen an to consider considering on cable better advantage because [SEP]']
[ 450/2000] tot_loss=1.882 (perp=8.850, rec=0.111, cos=0.001), tot_loss_proj:2.758 [t=0.17s]
prediction: ['[CLS] its barely better will seen its to consider considering on cable better advantage its [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.773 (perp=8.309, rec=0.110, cos=0.001), tot_loss_proj:2.544 [t=0.17s]
prediction: ['[CLS] its barely better will seen its to consider considering on its better advantage cable [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.794 (perp=8.328, rec=0.127, cos=0.002), tot_loss_proj:2.468 [t=0.17s]
prediction: ['[CLS] its barely seen will be its to why considering on its better advantage cable [SEP]']
[ 600/2000] tot_loss=1.773 (perp=8.328, rec=0.107, cos=0.001), tot_loss_proj:2.459 [t=0.17s]
prediction: ['[CLS] its barely seen will be its to why considering on its better advantage cable [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.742 (perp=8.192, rec=0.102, cos=0.001), tot_loss_proj:2.449 [t=0.17s]
prediction: ['[CLS] its barely seen will be to why considering its on its better advantage cable [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.687 (perp=7.893, rec=0.107, cos=0.002), tot_loss_proj:2.408 [t=0.17s]
prediction: ['[CLS] barely seen will be to why considering its on its better advantage its cable [SEP]']
[ 750/2000] tot_loss=1.639 (perp=7.717, rec=0.094, cos=0.001), tot_loss_proj:2.334 [t=0.17s]
prediction: ['[CLS] barely seen will be to why considering that on its better advantage its cable [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.594 (perp=7.516, rec=0.089, cos=0.001), tot_loss_proj:2.183 [t=0.17s]
prediction: ['[CLS] barely seen will be why considering that on to its better advantage its cable [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.569 (perp=7.392, rec=0.089, cos=0.001), tot_loss_proj:2.159 [t=0.17s]
prediction: ['[CLS] barely seen why considering that will be on to its better advantage its cable [SEP]']
[ 900/2000] tot_loss=1.559 (perp=7.392, rec=0.079, cos=0.001), tot_loss_proj:2.160 [t=0.17s]
prediction: ['[CLS] barely seen why considering that will be on to its better advantage its cable [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.523 (perp=7.188, rec=0.084, cos=0.001), tot_loss_proj:2.157 [t=0.17s]
prediction: ['[CLS] barely why considering that will be seen on to its better advantage its cable [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.460 (perp=6.877, rec=0.083, cos=0.001), tot_loss_proj:2.185 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on to its better advantage its cable [SEP]']
[1050/2000] tot_loss=1.458 (perp=6.877, rec=0.082, cos=0.001), tot_loss_proj:2.180 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on to its better advantage its cable [SEP]']
Attempt swap
[1100/2000] tot_loss=1.457 (perp=6.877, rec=0.081, cos=0.001), tot_loss_proj:2.181 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on to its better advantage its cable [SEP]']
Attempt swap
[1150/2000] tot_loss=1.448 (perp=6.877, rec=0.071, cos=0.001), tot_loss_proj:2.183 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on to its better advantage its cable [SEP]']
[1200/2000] tot_loss=1.452 (perp=6.877, rec=0.075, cos=0.001), tot_loss_proj:2.185 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on to its better advantage its cable [SEP]']
Attempt swap
[1250/2000] tot_loss=1.461 (perp=6.877, rec=0.084, cos=0.001), tot_loss_proj:2.181 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on to its better advantage its cable [SEP]']
Attempt swap
[1300/2000] tot_loss=1.577 (perp=7.470, rec=0.082, cos=0.001), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on to especially better advantage its cable [SEP]']
[1350/2000] tot_loss=1.576 (perp=7.470, rec=0.081, cos=0.001), tot_loss_proj:2.255 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on to especially better advantage its cable [SEP]']
Attempt swap
[1400/2000] tot_loss=1.579 (perp=7.470, rec=0.084, cos=0.001), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on to especially better advantage its cable [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.551 (perp=7.349, rec=0.080, cos=0.001), tot_loss_proj:2.251 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
[1500/2000] tot_loss=1.548 (perp=7.349, rec=0.077, cos=0.001), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
Attempt swap
[1550/2000] tot_loss=1.545 (perp=7.349, rec=0.074, cos=0.001), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
Attempt swap
[1600/2000] tot_loss=1.546 (perp=7.349, rec=0.075, cos=0.001), tot_loss_proj:2.255 [t=0.19s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
[1650/2000] tot_loss=1.557 (perp=7.349, rec=0.086, cos=0.001), tot_loss_proj:2.256 [t=0.19s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
Attempt swap
[1700/2000] tot_loss=1.552 (perp=7.349, rec=0.081, cos=0.001), tot_loss_proj:2.252 [t=0.19s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
Attempt swap
[1750/2000] tot_loss=1.548 (perp=7.349, rec=0.077, cos=0.001), tot_loss_proj:2.253 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
[1800/2000] tot_loss=1.561 (perp=7.349, rec=0.090, cos=0.001), tot_loss_proj:2.254 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
Attempt swap
[1850/2000] tot_loss=1.545 (perp=7.349, rec=0.074, cos=0.001), tot_loss_proj:2.252 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
Attempt swap
[1900/2000] tot_loss=1.550 (perp=7.349, rec=0.079, cos=0.001), tot_loss_proj:2.253 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
[1950/2000] tot_loss=1.555 (perp=7.349, rec=0.084, cos=0.001), tot_loss_proj:2.257 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.468 (perp=6.949, rec=0.077, cos=0.001), tot_loss_proj:2.181 [t=0.17s]
prediction: ['[CLS] barely considering why that will be seen on cable especially to better advantage its [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] barely considering why that will be seen on especially to better advantage its cable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.774 | p: 93.750 | r: 100.000
rouge2     | fm: 34.483 | p: 33.333 | r: 35.714
rougeL     | fm: 64.516 | p: 62.500 | r: 66.667
rougeLsum  | fm: 64.516 | p: 62.500 | r: 66.667
r1fm+r2fm = 131.257

[Aggregate metrics]:
rouge1     | fm: 87.588 | p: 86.531 | r: 88.605
rouge2     | fm: 53.422 | p: 53.297 | r: 53.557
rougeL     | fm: 76.037 | p: 75.366 | r: 76.923
rougeLsum  | fm: 75.504 | p: 74.846 | r: 76.399
r1fm+r2fm = 141.010

input #12 time: 0:09:24 | total time: 1:57:08


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9992538394516878
highest_index [0]
highest [0.9992538394516878]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8887738585472107 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8844950199127197 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.8545551896095276 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7818396091461182 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7813502550125122 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 0.7700784802436829 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7579190731048584 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7517123222351074 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best rec loss: 0.7473309636116028 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 0.7472784519195557 for ['[CLS] permanent defeat arm cardinal roweional precision [SEP]']
[Init] best perm rec loss: 0.7453463077545166 for ['[CLS] cardinal arm defeat rowe permanent precisionional [SEP]']
[Init] best perm rec loss: 0.7436425089836121 for ['[CLS]ional precision arm cardinal permanent rowe defeat [SEP]']
[Init] best perm rec loss: 0.7426804900169373 for ['[CLS] rowe cardinal defeat armional permanent precision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.489 (perp=10.746, rec=0.331, cos=0.009), tot_loss_proj:3.362 [t=0.17s]
prediction: ['[CLS] up losses ( off have flames hell [SEP]']
[ 100/2000] tot_loss=2.560 (perp=11.552, rec=0.247, cos=0.002), tot_loss_proj:3.416 [t=0.19s]
prediction: ['[CLS] point things ( more explode flame flame [SEP]']
[ 150/2000] tot_loss=2.504 (perp=11.547, rec=0.192, cos=0.003), tot_loss_proj:3.268 [t=0.19s]
prediction: ['[CLS] point things at more explode flame flame [SEP]']
[ 200/2000] tot_loss=2.477 (perp=11.547, rec=0.166, cos=0.001), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS] point things at more explode flame flame [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.227 (perp=10.433, rec=0.139, cos=0.002), tot_loss_proj:3.217 [t=0.17s]
prediction: ['[CLS] point things at flame explode more flame [SEP]']
[ 300/2000] tot_loss=2.206 (perp=10.433, rec=0.118, cos=0.001), tot_loss_proj:3.216 [t=0.17s]
prediction: ['[CLS] point things at flame explode more flame [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.923 (perp=9.064, rec=0.109, cos=0.001), tot_loss_proj:2.472 [t=0.17s]
prediction: ['[CLS] point at things into explode with flame [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.904 (perp=9.026, rec=0.097, cos=0.002), tot_loss_proj:2.740 [t=0.19s]
prediction: ['[CLS] point at things when explode into flame [SEP]']
[ 450/2000] tot_loss=1.749 (perp=8.254, rec=0.097, cos=0.001), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.735 (perp=8.254, rec=0.082, cos=0.001), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.739 (perp=8.254, rec=0.087, cos=0.001), tot_loss_proj:2.005 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 600/2000] tot_loss=1.737 (perp=8.254, rec=0.085, cos=0.001), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.745 (perp=8.254, rec=0.093, cos=0.001), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.735 (perp=8.254, rec=0.083, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 750/2000] tot_loss=1.729 (perp=8.254, rec=0.077, cos=0.001), tot_loss_proj:2.001 [t=0.19s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.727 (perp=8.254, rec=0.074, cos=0.001), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.740 (perp=8.254, rec=0.088, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[ 900/2000] tot_loss=1.737 (perp=8.254, rec=0.084, cos=0.002), tot_loss_proj:1.998 [t=0.18s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.734 (perp=8.254, rec=0.082, cos=0.001), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.733 (perp=8.254, rec=0.081, cos=0.001), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1050/2000] tot_loss=1.738 (perp=8.254, rec=0.086, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.736 (perp=8.254, rec=0.083, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.732 (perp=8.254, rec=0.080, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1200/2000] tot_loss=1.729 (perp=8.254, rec=0.077, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.733 (perp=8.254, rec=0.081, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.732 (perp=8.254, rec=0.080, cos=0.001), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1350/2000] tot_loss=1.730 (perp=8.254, rec=0.078, cos=0.001), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.729 (perp=8.254, rec=0.077, cos=0.001), tot_loss_proj:1.997 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.738 (perp=8.254, rec=0.086, cos=0.001), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1500/2000] tot_loss=1.726 (perp=8.254, rec=0.074, cos=0.001), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.741 (perp=8.254, rec=0.089, cos=0.001), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.721 (perp=8.254, rec=0.068, cos=0.001), tot_loss_proj:1.999 [t=0.19s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1650/2000] tot_loss=1.733 (perp=8.254, rec=0.080, cos=0.001), tot_loss_proj:1.995 [t=0.18s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.739 (perp=8.254, rec=0.087, cos=0.001), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.730 (perp=8.254, rec=0.078, cos=0.001), tot_loss_proj:1.999 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1800/2000] tot_loss=1.743 (perp=8.254, rec=0.091, cos=0.001), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.736 (perp=8.254, rec=0.083, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.728 (perp=8.254, rec=0.076, cos=0.001), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
[1950/2000] tot_loss=1.725 (perp=8.254, rec=0.073, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.736 (perp=8.254, rec=0.084, cos=0.001), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] point at things that explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point at things that explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.482 | p: 87.494 | r: 89.484
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 77.540 | p: 76.828 | r: 78.409
rougeLsum  | fm: 77.771 | p: 77.089 | r: 78.409
r1fm+r2fm = 145.625

input #13 time: 0:09:43 | total time: 2:06:51


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9993219682705545
highest_index [0]
highest [0.9993219682705545]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9556125998497009 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9368494749069214 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9233089089393616 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9153460264205933 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.9128281474113464 for ['[CLS] models cordytness gun [SEP]']
[Init] best rec loss: 0.8928517699241638 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8734212517738342 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720963597297668 for ['[CLS] myers sprayed harold [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720387816429138 for ['[CLS] [MASK] harold sprayed tom myers [SEP]']
[Init] best perm rec loss: 0.8698037266731262 for ['[CLS] tom [MASK] harold myers sprayed [SEP]']
[Init] best perm rec loss: 0.8688009977340698 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.190 (perp=9.643, rec=0.257, cos=0.004), tot_loss_proj:2.310 [t=0.18s]
prediction: ['[CLS] intriguing intriguing film deeply moving [SEP]']
[ 100/2000] tot_loss=2.396 (perp=11.102, rec=0.174, cos=0.002), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS] intriguing intriguing filmbly intriguing [SEP]']
[ 150/2000] tot_loss=2.304 (perp=10.861, rec=0.131, cos=0.002), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS]bly intriguing filmbly intriguing [SEP]']
[ 200/2000] tot_loss=2.578 (perp=12.243, rec=0.128, cos=0.001), tot_loss_proj:2.951 [t=0.17s]
prediction: ['[CLS]enia intriguing filmbly intriguing [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.981 (perp=9.271, rec=0.125, cos=0.001), tot_loss_proj:2.138 [t=0.17s]
prediction: ['[CLS] intriguing filmeniably intriguing [SEP]']
[ 300/2000] tot_loss=1.956 (perp=9.271, rec=0.100, cos=0.001), tot_loss_proj:2.140 [t=0.19s]
prediction: ['[CLS] intriguing filmeniably intriguing [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.692 (perp=7.971, rec=0.096, cos=0.001), tot_loss_proj:1.918 [t=0.19s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.688 (perp=7.971, rec=0.093, cos=0.001), tot_loss_proj:1.907 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.688 (perp=7.971, rec=0.092, cos=0.001), tot_loss_proj:1.911 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=7.971, rec=0.083, cos=0.001), tot_loss_proj:1.915 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.681 (perp=7.971, rec=0.086, cos=0.001), tot_loss_proj:1.918 [t=0.18s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.676 (perp=7.971, rec=0.080, cos=0.001), tot_loss_proj:1.910 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.673 (perp=7.971, rec=0.078, cos=0.001), tot_loss_proj:1.912 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.689 (perp=7.971, rec=0.094, cos=0.001), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.678 (perp=7.971, rec=0.083, cos=0.001), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.683 (perp=7.971, rec=0.088, cos=0.001), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.680 (perp=7.971, rec=0.084, cos=0.001), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.682 (perp=7.971, rec=0.086, cos=0.001), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.678 (perp=7.971, rec=0.083, cos=0.001), tot_loss_proj:1.902 [t=0.17s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.093 (perp=10.059, rec=0.079, cos=0.001), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] intriguingeniably und film [SEP]']
[1050/2000] tot_loss=2.094 (perp=10.059, rec=0.081, cos=0.001), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] intriguingeniably und film [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.417 (perp=6.728, rec=0.070, cos=0.001), tot_loss_proj:1.405 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.412 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.419 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.412 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.418 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.415 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.418 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.419 (perp=6.728, rec=0.072, cos=0.001), tot_loss_proj:1.415 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.414 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.409 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.404 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.404 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.412 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.416 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.407 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.416 (perp=6.728, rec=0.069, cos=0.001), tot_loss_proj:1.417 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.409 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.413 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.142 | p: 88.247 | r: 90.124
rouge2     | fm: 59.931 | p: 59.683 | r: 60.000
rougeL     | fm: 79.177 | p: 78.602 | r: 79.848
rougeLsum  | fm: 79.004 | p: 78.413 | r: 79.697
r1fm+r2fm = 149.073

input #14 time: 0:08:27 | total time: 2:15:19


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9992724874303516
highest_index [0]
highest [0.9992724874303516]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9709395170211792 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9276955127716064 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9179652333259583 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.9067785143852234 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9063056707382202 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8998844623565674 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8911759257316589 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8846814036369324 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8817172050476074 for ['[CLS] 0 humanities metaphor olivia easily fetch first sweden [SEP]']
[Init] best perm rec loss: 0.8800804018974304 for ['[CLS] easily first olivia metaphor fetch 0 humanities sweden [SEP]']
[Init] best perm rec loss: 0.879218578338623 for ['[CLS] easily sweden humanities first olivia 0 fetch metaphor [SEP]']
[Init] best perm rec loss: 0.879126250743866 for ['[CLS] easily sweden humanities 0 olivia first fetch metaphor [SEP]']
[Init] best perm rec loss: 0.8768956065177917 for ['[CLS] fetch humanities first 0 sweden olivia easily metaphor [SEP]']
[Init] best perm rec loss: 0.8764843344688416 for ['[CLS] 0 first humanities sweden olivia metaphor easily fetch [SEP]']
[Init] best perm rec loss: 0.8753165006637573 for ['[CLS] 0 sweden fetch metaphor humanities olivia first easily [SEP]']
[Init] best perm rec loss: 0.8751561641693115 for ['[CLS] metaphor 0 first humanities sweden olivia easily fetch [SEP]']
[Init] best perm rec loss: 0.8732092976570129 for ['[CLS] metaphor first sweden fetch 0 easily olivia humanities [SEP]']
[Init] best perm rec loss: 0.8722246885299683 for ['[CLS] first easily 0 sweden metaphor olivia humanities fetch [SEP]']
[Init] best perm rec loss: 0.8716493844985962 for ['[CLS] metaphor humanities first sweden olivia fetch easily 0 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.757 (perp=12.349, rec=0.284, cos=0.003), tot_loss_proj:3.614 [t=0.17s]
prediction: ['[CLS] efficient managedably hipably waitress so ∞ [SEP]']
[ 100/2000] tot_loss=2.860 (perp=13.261, rec=0.207, cos=0.002), tot_loss_proj:3.922 [t=0.17s]
prediction: ['[CLS] efficient managedably suit efficient chill so chill [SEP]']
[ 150/2000] tot_loss=2.488 (perp=11.569, rec=0.172, cos=0.002), tot_loss_proj:2.831 [t=0.17s]
prediction: ['[CLS] efficient namedably suitably chill ; suit [SEP]']
[ 200/2000] tot_loss=2.420 (perp=11.409, rec=0.136, cos=0.002), tot_loss_proj:2.904 [t=0.17s]
prediction: ['[CLS] efficient namedably suitably chill ;er [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.056 (perp=9.674, rec=0.120, cos=0.002), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] efficient anonymousably suitably chiller ; [SEP]']
[ 300/2000] tot_loss=1.927 (perp=9.083, rec=0.109, cos=0.001), tot_loss_proj:2.267 [t=0.17s]
prediction: ['[CLS] efficient anonymousably suitably chiller. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.718 (perp=8.082, rec=0.100, cos=0.001), tot_loss_proj:1.919 [t=0.17s]
prediction: ['[CLS] efficientably suitably anonymous chiller. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.583 (perp=7.428, rec=0.096, cos=0.002), tot_loss_proj:1.726 [t=0.17s]
prediction: ['[CLS]ably suitably efficient anonymous chiller. [SEP]']
[ 450/2000] tot_loss=1.572 (perp=7.428, rec=0.085, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS]ably suitably efficient anonymous chiller. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.578 (perp=7.428, rec=0.091, cos=0.001), tot_loss_proj:1.728 [t=0.17s]
prediction: ['[CLS]ably suitably efficient anonymous chiller. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.563 (perp=7.403, rec=0.081, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] suitably, efficient anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.563 (perp=7.403, rec=0.081, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] suitably, efficient anonymous chiller. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.421 (perp=6.697, rec=0.080, cos=0.001), tot_loss_proj:1.513 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.428 (perp=6.697, rec=0.087, cos=0.001), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.403 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.508 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.407 (perp=6.697, rec=0.067, cos=0.001), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.413 (perp=6.697, rec=0.072, cos=0.001), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.416 (perp=6.697, rec=0.075, cos=0.001), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.407 (perp=6.697, rec=0.066, cos=0.001), tot_loss_proj:1.504 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.396 (perp=6.697, rec=0.055, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.415 (perp=6.697, rec=0.074, cos=0.001), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.408 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.400 (perp=6.697, rec=0.059, cos=0.001), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.415 (perp=6.697, rec=0.074, cos=0.001), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.399 (perp=6.697, rec=0.058, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1350/2000] tot_loss=1.403 (perp=6.697, rec=0.062, cos=0.001), tot_loss_proj:1.504 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.398 (perp=6.697, rec=0.057, cos=0.001), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.405 (perp=6.697, rec=0.064, cos=0.001), tot_loss_proj:1.511 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.417 (perp=6.697, rec=0.076, cos=0.001), tot_loss_proj:1.513 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.399 (perp=6.697, rec=0.058, cos=0.001), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.406 (perp=6.697, rec=0.066, cos=0.001), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.397 (perp=6.697, rec=0.056, cos=0.001), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.395 (perp=6.697, rec=0.055, cos=0.001), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.405 (perp=6.697, rec=0.065, cos=0.001), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.403 (perp=6.697, rec=0.062, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.401 (perp=6.697, rec=0.060, cos=0.001), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.409 (perp=6.697, rec=0.068, cos=0.001), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.402 (perp=6.697, rec=0.061, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.404 (perp=6.697, rec=0.063, cos=0.001), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 90.134 | p: 89.215 | r: 91.250
rouge2     | fm: 58.405 | p: 58.318 | r: 58.515
rougeL     | fm: 79.746 | p: 79.075 | r: 80.445
rougeLsum  | fm: 79.553 | p: 78.957 | r: 80.208
r1fm+r2fm = 148.539

input #15 time: 0:09:11 | total time: 2:24:30


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9993411698074052
highest_index [0]
highest [0.9993411698074052]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.018147349357605 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.9020346403121948 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7366529107093811 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7362502217292786 for ['[CLS]athi alta lord film slowly various [SEP]']
[Init] best perm rec loss: 0.7362011075019836 for ['[CLS] lord slowly film variousathi alta [SEP]']
[Init] best perm rec loss: 0.7361390590667725 for ['[CLS] various slowly film lordathi alta [SEP]']
[Init] best perm rec loss: 0.7351789474487305 for ['[CLS]athi alta lord slowly various film [SEP]']
[Init] best perm rec loss: 0.7351776957511902 for ['[CLS] various film lord slowlyathi alta [SEP]']
[Init] best perm rec loss: 0.7336527705192566 for ['[CLS] various film lord slowly altaathi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.803 (perp=11.033, rec=0.587, cos=0.010), tot_loss_proj:4.031 [t=0.17s]
prediction: ['[CLS] some as sloane on therapy cotton [SEP]']
[ 100/2000] tot_loss=2.453 (perp=10.194, rec=0.410, cos=0.004), tot_loss_proj:3.576 [t=0.17s]
prediction: ['[CLS] that from gogh on already ship [SEP]']
[ 150/2000] tot_loss=1.823 (perp=7.387, rec=0.343, cos=0.002), tot_loss_proj:2.897 [t=0.17s]
prediction: ['[CLS] that from this that all and [SEP]']
[ 200/2000] tot_loss=2.080 (perp=8.488, rec=0.376, cos=0.007), tot_loss_proj:3.041 [t=0.17s]
prediction: ['[CLS] that up extra that all, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.639 (perp=6.525, rec=0.327, cos=0.008), tot_loss_proj:2.616 [t=0.19s]
prediction: ['[CLS] that up all that extra, [SEP]']
[ 300/2000] tot_loss=1.902 (perp=8.149, rec=0.270, cos=0.001), tot_loss_proj:2.993 [t=0.19s]
prediction: ['[CLS] that talk all that this and [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.612 (perp=6.793, rec=0.252, cos=0.001), tot_loss_proj:2.619 [t=0.17s]
prediction: ['[CLS] that more, all that this [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.580 (perp=6.283, rec=0.315, cos=0.009), tot_loss_proj:2.472 [t=0.17s]
prediction: ['[CLS] that more, and all this [SEP]']
[ 450/2000] tot_loss=1.500 (perp=6.283, rec=0.241, cos=0.002), tot_loss_proj:2.384 [t=0.17s]
prediction: ['[CLS] that more, and all this [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.278 (perp=5.339, rec=0.208, cos=0.002), tot_loss_proj:2.242 [t=0.17s]
prediction: ['[CLS] this, and all this more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.261 (perp=5.339, rec=0.192, cos=0.001), tot_loss_proj:2.232 [t=0.17s]
prediction: ['[CLS] this, and all this more [SEP]']
[ 600/2000] tot_loss=1.237 (perp=5.339, rec=0.168, cos=0.001), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS] this, and all this more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.210 (perp=5.339, rec=0.140, cos=0.001), tot_loss_proj:2.241 [t=0.17s]
prediction: ['[CLS] this, and all this more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.208 (perp=5.339, rec=0.139, cos=0.001), tot_loss_proj:2.240 [t=0.19s]
prediction: ['[CLS] this, and all this more [SEP]']
[ 750/2000] tot_loss=1.203 (perp=5.339, rec=0.134, cos=0.001), tot_loss_proj:2.229 [t=0.17s]
prediction: ['[CLS] this, and all this more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.196 (perp=5.339, rec=0.127, cos=0.001), tot_loss_proj:2.237 [t=0.18s]
prediction: ['[CLS] this, and all this more [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.069 (perp=4.697, rec=0.127, cos=0.003), tot_loss_proj:1.314 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.039 (perp=4.697, rec=0.099, cos=0.001), tot_loss_proj:1.294 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.035 (perp=4.697, rec=0.095, cos=0.001), tot_loss_proj:1.278 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.035 (perp=4.697, rec=0.094, cos=0.001), tot_loss_proj:1.280 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.026 (perp=4.697, rec=0.085, cos=0.001), tot_loss_proj:1.275 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.033 (perp=4.697, rec=0.092, cos=0.001), tot_loss_proj:1.266 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.023 (perp=4.697, rec=0.082, cos=0.001), tot_loss_proj:1.268 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.013 (perp=4.697, rec=0.072, cos=0.001), tot_loss_proj:1.270 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.025 (perp=4.697, rec=0.085, cos=0.001), tot_loss_proj:1.271 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.023 (perp=4.697, rec=0.082, cos=0.001), tot_loss_proj:1.270 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.016 (perp=4.697, rec=0.076, cos=0.001), tot_loss_proj:1.270 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.014 (perp=4.697, rec=0.073, cos=0.001), tot_loss_proj:1.267 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.010 (perp=4.697, rec=0.069, cos=0.001), tot_loss_proj:1.265 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=1.015 (perp=4.697, rec=0.074, cos=0.001), tot_loss_proj:1.271 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.012 (perp=4.697, rec=0.071, cos=0.001), tot_loss_proj:1.270 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.004 (perp=4.697, rec=0.064, cos=0.001), tot_loss_proj:1.268 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.018 (perp=4.697, rec=0.077, cos=0.001), tot_loss_proj:1.265 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.012 (perp=4.697, rec=0.071, cos=0.001), tot_loss_proj:1.263 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.012 (perp=4.697, rec=0.071, cos=0.001), tot_loss_proj:1.272 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=1.021 (perp=4.697, rec=0.081, cos=0.001), tot_loss_proj:1.262 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.013 (perp=4.697, rec=0.072, cos=0.001), tot_loss_proj:1.270 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.010 (perp=4.697, rec=0.070, cos=0.001), tot_loss_proj:1.264 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.017 (perp=4.697, rec=0.076, cos=0.001), tot_loss_proj:1.271 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.014 (perp=4.697, rec=0.073, cos=0.001), tot_loss_proj:1.261 [t=0.17s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.599 | p: 89.749 | r: 91.449
rouge2     | fm: 61.146 | p: 61.064 | r: 61.176
rougeL     | fm: 81.144 | p: 80.605 | r: 81.729
rougeLsum  | fm: 80.627 | p: 80.072 | r: 81.373
r1fm+r2fm = 151.745

input #16 time: 0:10:03 | total time: 2:34:34


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9992301552937229
highest_index [0]
highest [0.9992301552937229]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8486641645431519 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8205068111419678 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8189647197723389 for ['[CLS] santa bourneity church jacence move nativeburnub early [SEP]']
[Init] best rec loss: 0.8072818517684937 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7922393679618835 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.7693865895271301 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7615459561347961 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.7598406076431274 for ['[CLS] meeting marius miss pressure greyuin i magazine saved lieutenant honestly [SEP]']
[Init] best perm rec loss: 0.7584831714630127 for ['[CLS] marius missuin lieutenant grey magazine honestly i saved meeting pressure [SEP]']
[Init] best perm rec loss: 0.7562015652656555 for ['[CLS] pressure marius honestly magazine saved meeting grey lieutenant iuin miss [SEP]']
[Init] best perm rec loss: 0.7561701536178589 for ['[CLS] i pressure marius lieutenant magazine miss greyuin meeting saved honestly [SEP]']
[Init] best perm rec loss: 0.7556576132774353 for ['[CLS]uin lieutenant honestly i pressure marius miss meeting grey saved magazine [SEP]']
[Init] best perm rec loss: 0.7535409927368164 for ['[CLS] i meetinguin pressure honestly magazine grey lieutenant marius saved miss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.953 (perp=12.208, rec=0.507, cos=0.004), tot_loss_proj:3.981 [t=0.17s]
prediction: ['[CLS] the franticactic bullshit alleged dispersal feed area about tax mum [SEP]']
[ 100/2000] tot_loss=2.572 (perp=10.708, rec=0.427, cos=0.003), tot_loss_proj:3.455 [t=0.17s]
prediction: ['[CLS] too rushed bacterial study supposed who fed about about bound taboo [SEP]']
[ 150/2000] tot_loss=2.682 (perp=12.022, rec=0.274, cos=0.003), tot_loss_proj:3.610 [t=0.19s]
prediction: ['[CLS] too much bacterial suck want what what about about hospital asked [SEP]']
[ 200/2000] tot_loss=2.603 (perp=12.044, rec=0.193, cos=0.002), tot_loss_proj:3.503 [t=0.20s]
prediction: ['[CLS] too much bacterial aren want much much about about hospital want [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.217 (perp=10.273, rec=0.161, cos=0.002), tot_loss_proj:3.131 [t=0.17s]
prediction: ['[CLS] too much hospitalsett want much think about about symptoms think [SEP]']
[ 300/2000] tot_loss=2.195 (perp=10.273, rec=0.139, cos=0.001), tot_loss_proj:3.129 [t=0.17s]
prediction: ['[CLS] too much hospitalsett want much think about about symptoms think [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.091 (perp=9.830, rec=0.124, cos=0.001), tot_loss_proj:2.923 [t=0.17s]
prediction: ['[CLS] too much hospitalausen want much think about because thinkore [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.872 (perp=8.690, rec=0.132, cos=0.002), tot_loss_proj:2.706 [t=0.17s]
prediction: ['[CLS] too much hospital think want much think about because they s [SEP]']
[ 450/2000] tot_loss=1.568 (perp=7.300, rec=0.107, cos=0.002), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] too much hospital to want much think about because they s [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.716 (perp=8.123, rec=0.090, cos=0.001), tot_loss_proj:2.604 [t=0.17s]
prediction: ['[CLS] too much hospital much want to think about on they s [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.532 (perp=7.169, rec=0.096, cos=0.001), tot_loss_proj:2.404 [t=0.17s]
prediction: ['[CLS] too much hospital they much want to think about on s [SEP]']
[ 600/2000] tot_loss=1.523 (perp=7.169, rec=0.088, cos=0.002), tot_loss_proj:2.410 [t=0.17s]
prediction: ['[CLS] too much hospital they much want to think about on s [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.442 (perp=6.757, rec=0.089, cos=0.001), tot_loss_proj:2.237 [t=0.19s]
prediction: ['[CLS] too much hospital they want to think much about on s [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.434 (perp=6.757, rec=0.081, cos=0.002), tot_loss_proj:2.242 [t=0.19s]
prediction: ['[CLS] too much hospital they want to think much about on s [SEP]']
[ 750/2000] tot_loss=1.432 (perp=6.757, rec=0.079, cos=0.002), tot_loss_proj:2.228 [t=0.20s]
prediction: ['[CLS] too much hospital they want to think much about on s [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.437 (perp=6.757, rec=0.084, cos=0.002), tot_loss_proj:2.237 [t=0.19s]
prediction: ['[CLS] too much hospital they want to think much about on s [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.566 (perp=7.414, rec=0.082, cos=0.002), tot_loss_proj:2.658 [t=0.19s]
prediction: ['[CLS] too what hospital they want to think much about on s [SEP]']
[ 900/2000] tot_loss=1.568 (perp=7.414, rec=0.083, cos=0.002), tot_loss_proj:2.649 [t=0.19s]
prediction: ['[CLS] too what hospital they want to think much about on s [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.399 (perp=6.554, rec=0.086, cos=0.001), tot_loss_proj:2.260 [t=0.19s]
prediction: ['[CLS] what hospital they want to think too much about on s [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.194 (perp=5.544, rec=0.083, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
[1050/2000] tot_loss=1.187 (perp=5.544, rec=0.077, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1100/2000] tot_loss=1.192 (perp=5.544, rec=0.082, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1150/2000] tot_loss=1.200 (perp=5.544, rec=0.089, cos=0.002), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
[1200/2000] tot_loss=1.194 (perp=5.544, rec=0.084, cos=0.002), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1250/2000] tot_loss=1.200 (perp=5.544, rec=0.089, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1300/2000] tot_loss=1.188 (perp=5.544, rec=0.078, cos=0.002), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
[1350/2000] tot_loss=1.186 (perp=5.544, rec=0.076, cos=0.002), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1400/2000] tot_loss=1.187 (perp=5.544, rec=0.077, cos=0.002), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1450/2000] tot_loss=1.193 (perp=5.544, rec=0.082, cos=0.002), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
[1500/2000] tot_loss=1.184 (perp=5.544, rec=0.074, cos=0.002), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1550/2000] tot_loss=1.197 (perp=5.544, rec=0.086, cos=0.002), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1600/2000] tot_loss=1.190 (perp=5.544, rec=0.080, cos=0.002), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
[1650/2000] tot_loss=1.185 (perp=5.544, rec=0.074, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1700/2000] tot_loss=1.191 (perp=5.544, rec=0.081, cos=0.002), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1750/2000] tot_loss=1.191 (perp=5.544, rec=0.081, cos=0.002), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
[1800/2000] tot_loss=1.192 (perp=5.544, rec=0.082, cos=0.002), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1850/2000] tot_loss=1.184 (perp=5.544, rec=0.074, cos=0.002), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[1900/2000] tot_loss=1.188 (perp=5.544, rec=0.077, cos=0.002), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
[1950/2000] tot_loss=1.182 (perp=5.544, rec=0.071, cos=0.002), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Attempt swap
[2000/2000] tot_loss=1.184 (perp=5.544, rec=0.074, cos=0.002), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] on hospital they want to think too much about what s [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] on hospital they want to think too much about what s [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 60.870 | p: 58.333 | r: 63.636
rougeL     | fm: 80.000 | p: 76.923 | r: 83.333
rougeLsum  | fm: 80.000 | p: 76.923 | r: 83.333
r1fm+r2fm = 148.870

[Aggregate metrics]:
rouge1     | fm: 90.402 | p: 89.510 | r: 91.364
rouge2     | fm: 61.159 | p: 60.919 | r: 61.512
rougeL     | fm: 80.711 | p: 80.036 | r: 81.481
rougeLsum  | fm: 80.647 | p: 80.012 | r: 81.355
r1fm+r2fm = 151.562

input #17 time: 0:08:04 | total time: 2:42:38


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9993194147820215
highest_index [0]
highest [0.9993194147820215]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9796279072761536 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9423751831054688 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9344695806503296 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9258310198783875 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.8895648717880249 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.8812242150306702 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.869970977306366 for ['[CLS] oniest α department [SEP]']
[Init] best rec loss: 0.8667334318161011 for ['[CLS] middle away mc reserves [SEP]']
[Init] best rec loss: 0.8235080242156982 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8209102153778076 for ['[CLS]odle circle du dual [SEP]']
[Init] best perm rec loss: 0.8185354471206665 for ['[CLS] dual duodle circle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.746 (perp=11.985, rec=0.344, cos=0.005), tot_loss_proj:3.534 [t=0.17s]
prediction: ['[CLS] human special received horsemen [SEP]']
[ 100/2000] tot_loss=3.112 (perp=14.328, rec=0.245, cos=0.002), tot_loss_proj:4.348 [t=0.17s]
prediction: ['[CLS]vi welcomealgor [SEP]']
[ 150/2000] tot_loss=3.197 (perp=15.031, rec=0.189, cos=0.002), tot_loss_proj:4.550 [t=0.17s]
prediction: ['[CLS]vi extendingatinggor [SEP]']
[ 200/2000] tot_loss=2.594 (perp=12.222, rec=0.148, cos=0.002), tot_loss_proj:4.175 [t=0.17s]
prediction: ['[CLS]vi inatinggor [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.560 (perp=7.299, rec=0.099, cos=0.001), tot_loss_proj:1.834 [t=0.17s]
prediction: ['[CLS]vigorating in [SEP]']
[ 300/2000] tot_loss=1.534 (perp=7.299, rec=0.073, cos=0.001), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS]vigorating in [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.204 (perp=5.588, rec=0.085, cos=0.001), tot_loss_proj:1.191 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.184 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.189 (perp=5.588, rec=0.070, cos=0.001), tot_loss_proj:1.179 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.189 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.175 (perp=5.588, rec=0.056, cos=0.001), tot_loss_proj:1.193 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.170 (perp=5.588, rec=0.051, cos=0.001), tot_loss_proj:1.186 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.180 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.177 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.191 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.179 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.189 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.169 (perp=5.588, rec=0.050, cos=0.001), tot_loss_proj:1.176 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.177 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.187 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.189 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.187 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.188 (perp=5.588, rec=0.069, cos=0.001), tot_loss_proj:1.188 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.184 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.177 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.191 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.171 (perp=5.588, rec=0.052, cos=0.001), tot_loss_proj:1.185 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.190 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.191 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.183 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.180 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.180 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.191 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.170 (perp=5.588, rec=0.051, cos=0.001), tot_loss_proj:1.178 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.177 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.188 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.182 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.190 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.180 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.183 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.167 (perp=5.588, rec=0.048, cos=0.001), tot_loss_proj:1.177 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.861 | p: 90.016 | r: 91.821
rouge2     | fm: 62.959 | p: 62.769 | r: 63.274
rougeL     | fm: 81.910 | p: 81.206 | r: 82.536
rougeLsum  | fm: 81.668 | p: 80.974 | r: 82.396
r1fm+r2fm = 153.820

input #18 time: 0:07:37 | total time: 2:50:15


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9993635209107408
highest_index [0]
highest [0.9993635209107408]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7703872323036194 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7632964253425598 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7431591749191284 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7254143357276917 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7071809768676758 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.7017049789428711 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.688244640827179 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.680355966091156 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.6743445992469788 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6420117020606995 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6395600438117981 for ['[CLS] reaching pin orderyna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.879 (perp=12.214, rec=0.430, cos=0.006), tot_loss_proj:3.824 [t=0.19s]
prediction: ['[CLS] pope lanes violent came [SEP]']
[ 100/2000] tot_loss=2.831 (perp=12.392, rec=0.342, cos=0.010), tot_loss_proj:3.702 [t=0.18s]
prediction: ['[CLS] duringda violentfa [SEP]']
[ 150/2000] tot_loss=3.055 (perp=14.052, rec=0.242, cos=0.003), tot_loss_proj:4.233 [t=0.17s]
prediction: ['[CLS] tomyfafa [SEP]']
[ 200/2000] tot_loss=2.493 (perp=11.655, rec=0.160, cos=0.002), tot_loss_proj:3.694 [t=0.17s]
prediction: ['[CLS] tomymyfa [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.427 (perp=11.137, rec=0.193, cos=0.006), tot_loss_proj:3.783 [t=0.17s]
prediction: ['[CLS] tofa inmy [SEP]']
[ 300/2000] tot_loss=2.350 (perp=11.137, rec=0.121, cos=0.001), tot_loss_proj:3.860 [t=0.17s]
prediction: ['[CLS] tofa inmy [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.324 (perp=6.110, rec=0.101, cos=0.001), tot_loss_proj:1.317 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.302 (perp=6.110, rec=0.078, cos=0.001), tot_loss_proj:1.321 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.304 (perp=6.110, rec=0.081, cos=0.001), tot_loss_proj:1.312 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.302 (perp=6.110, rec=0.079, cos=0.001), tot_loss_proj:1.315 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.304 (perp=6.110, rec=0.081, cos=0.001), tot_loss_proj:1.311 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.292 (perp=6.110, rec=0.069, cos=0.001), tot_loss_proj:1.319 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.322 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.294 (perp=6.110, rec=0.071, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.281 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.307 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.303 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.286 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.287 (perp=6.110, rec=0.064, cos=0.001), tot_loss_proj:1.322 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.285 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.321 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.291 (perp=6.110, rec=0.068, cos=0.001), tot_loss_proj:1.322 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.286 (perp=6.110, rec=0.063, cos=0.001), tot_loss_proj:1.313 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.307 (perp=6.110, rec=0.084, cos=0.001), tot_loss_proj:1.314 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.287 (perp=6.110, rec=0.064, cos=0.001), tot_loss_proj:1.311 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.281 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.291 (perp=6.110, rec=0.068, cos=0.001), tot_loss_proj:1.315 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.279 (perp=6.110, rec=0.056, cos=0.001), tot_loss_proj:1.300 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.294 (perp=6.110, rec=0.071, cos=0.001), tot_loss_proj:1.312 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.290 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.316 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.272 (perp=6.110, rec=0.049, cos=0.001), tot_loss_proj:1.311 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.307 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.320 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.289 (perp=6.110, rec=0.066, cos=0.001), tot_loss_proj:1.317 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.294 (perp=6.110, rec=0.071, cos=0.001), tot_loss_proj:1.314 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.276 (perp=6.110, rec=0.052, cos=0.001), tot_loss_proj:1.304 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.290 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.294 (perp=6.110, rec=0.071, cos=0.001), tot_loss_proj:1.324 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.288 (perp=6.110, rec=0.065, cos=0.001), tot_loss_proj:1.311 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.514 | p: 90.688 | r: 92.368
rouge2     | fm: 64.948 | p: 64.613 | r: 65.062
rougeL     | fm: 82.852 | p: 82.220 | r: 83.636
rougeLsum  | fm: 82.680 | p: 82.038 | r: 83.333
r1fm+r2fm = 156.462

input #19 time: 0:07:29 | total time: 2:57:44


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9992466071766843
highest_index [0]
highest [0.9992466071766843]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.813522219657898 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8018914461135864 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7928059697151184 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7927916049957275 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.7916965484619141 for ['[CLS] glad home gentlemanboard [SEP]']
[Init] best rec loss: 0.765182614326477 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7627440690994263 for ['[CLS]pid poor forming african [SEP]']
[Init] best perm rec loss: 0.7611280083656311 for ['[CLS] african poor formingpid [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.945 (perp=12.525, rec=0.426, cos=0.014), tot_loss_proj:3.597 [t=0.18s]
prediction: ['[CLS]uation candi pleasure something [SEP]']
[ 100/2000] tot_loss=2.419 (perp=10.658, rec=0.282, cos=0.006), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS]verseverse pleasureverse [SEP]']
[ 150/2000] tot_loss=2.377 (perp=10.658, rec=0.241, cos=0.005), tot_loss_proj:3.438 [t=0.20s]
prediction: ['[CLS]verseverse pleasureverse [SEP]']
[ 200/2000] tot_loss=2.091 (perp=9.639, rec=0.160, cos=0.003), tot_loss_proj:2.844 [t=0.19s]
prediction: ['[CLS] theverse pleasureverse [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.058 (perp=9.639, rec=0.129, cos=0.002), tot_loss_proj:2.838 [t=0.19s]
prediction: ['[CLS] theverse pleasureverse [SEP]']
[ 300/2000] tot_loss=2.022 (perp=9.639, rec=0.093, cos=0.001), tot_loss_proj:2.838 [t=0.18s]
prediction: ['[CLS] theverse pleasureverse [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.644 (perp=7.784, rec=0.086, cos=0.001), tot_loss_proj:1.938 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.641 (perp=7.784, rec=0.083, cos=0.001), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 450/2000] tot_loss=1.636 (perp=7.784, rec=0.077, cos=0.001), tot_loss_proj:1.936 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.634 (perp=7.784, rec=0.076, cos=0.001), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.631 (perp=7.784, rec=0.072, cos=0.001), tot_loss_proj:1.932 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 600/2000] tot_loss=1.629 (perp=7.784, rec=0.070, cos=0.001), tot_loss_proj:1.930 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.623 (perp=7.784, rec=0.064, cos=0.001), tot_loss_proj:1.944 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.623 (perp=7.784, rec=0.064, cos=0.001), tot_loss_proj:1.930 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 750/2000] tot_loss=1.632 (perp=7.784, rec=0.074, cos=0.001), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.631 (perp=7.784, rec=0.073, cos=0.001), tot_loss_proj:1.945 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.626 (perp=7.784, rec=0.068, cos=0.001), tot_loss_proj:1.927 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 900/2000] tot_loss=1.631 (perp=7.784, rec=0.073, cos=0.001), tot_loss_proj:1.936 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.628 (perp=7.784, rec=0.069, cos=0.001), tot_loss_proj:1.924 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1000/2000] tot_loss=1.624 (perp=7.784, rec=0.065, cos=0.001), tot_loss_proj:1.938 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1050/2000] tot_loss=1.614 (perp=7.784, rec=0.056, cos=0.001), tot_loss_proj:1.926 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1100/2000] tot_loss=1.625 (perp=7.784, rec=0.067, cos=0.001), tot_loss_proj:1.934 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1150/2000] tot_loss=1.616 (perp=7.784, rec=0.058, cos=0.001), tot_loss_proj:1.941 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1200/2000] tot_loss=1.622 (perp=7.784, rec=0.064, cos=0.001), tot_loss_proj:1.944 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1250/2000] tot_loss=1.615 (perp=7.784, rec=0.056, cos=0.001), tot_loss_proj:1.928 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1300/2000] tot_loss=1.640 (perp=7.784, rec=0.081, cos=0.001), tot_loss_proj:1.934 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1350/2000] tot_loss=1.623 (perp=7.784, rec=0.064, cos=0.001), tot_loss_proj:1.930 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1400/2000] tot_loss=1.629 (perp=7.784, rec=0.071, cos=0.001), tot_loss_proj:1.943 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1450/2000] tot_loss=1.626 (perp=7.784, rec=0.067, cos=0.001), tot_loss_proj:1.931 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1500/2000] tot_loss=1.630 (perp=7.784, rec=0.071, cos=0.001), tot_loss_proj:1.937 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1550/2000] tot_loss=1.620 (perp=7.784, rec=0.062, cos=0.001), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1600/2000] tot_loss=1.629 (perp=7.784, rec=0.071, cos=0.001), tot_loss_proj:1.937 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1650/2000] tot_loss=1.618 (perp=7.784, rec=0.060, cos=0.001), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1700/2000] tot_loss=1.619 (perp=7.784, rec=0.061, cos=0.001), tot_loss_proj:1.939 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1750/2000] tot_loss=1.623 (perp=7.784, rec=0.065, cos=0.001), tot_loss_proj:1.927 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1800/2000] tot_loss=1.626 (perp=7.784, rec=0.068, cos=0.001), tot_loss_proj:1.934 [t=0.19s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1850/2000] tot_loss=1.612 (perp=7.784, rec=0.053, cos=0.001), tot_loss_proj:1.941 [t=0.19s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[1900/2000] tot_loss=1.628 (perp=7.784, rec=0.069, cos=0.001), tot_loss_proj:1.926 [t=0.23s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[1950/2000] tot_loss=1.630 (perp=7.784, rec=0.071, cos=0.001), tot_loss_proj:1.928 [t=0.19s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
[2000/2000] tot_loss=1.618 (perp=7.784, rec=0.060, cos=0.001), tot_loss_proj:1.941 [t=0.19s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the pleasure perverse [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.821 | p: 91.048 | r: 92.677
rouge2     | fm: 63.145 | p: 63.005 | r: 63.438
rougeL     | fm: 82.703 | p: 82.137 | r: 83.413
rougeLsum  | fm: 82.599 | p: 81.997 | r: 83.297
r1fm+r2fm = 154.966

input #20 time: 0:07:29 | total time: 3:05:14


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.999323347023505
highest_index [0]
highest [0.999323347023505]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9415550231933594 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.881145179271698 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8719595670700073 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8715744018554688 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.8490786552429199 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8239164352416992 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.820530891418457 for ['[CLS]westock displays lock [MASK] peg potatoes precious sarajevo tomorrow gingerhis offers extension recently part lake pena comedy punjabhraors hardware alabama chemical [SEP]']
[Init] best rec loss: 0.8185598850250244 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8150901794433594 for ['[CLS] jin [SEP] brows return clear firm ashland evidence villageoom daddy speed extra sq chamberfying above odd episode viva surgical commission right range waters [SEP]']
[Init] best perm rec loss: 0.8130291700363159 for ['[CLS] daddy odd range surgical firm chamber jinoom [SEP] above viva extra brows speed ashland clear episode evidence returnfying sq village waters right commission [SEP]']
[Init] best perm rec loss: 0.8112152814865112 for ['[CLS] extra brows odd speedoom commission daddy range clear surgical evidence firm episode [SEP] viva waters above returnfying village jin ashland right chamber sq [SEP]']
[Init] best perm rec loss: 0.8100186586380005 for ['[CLS] right evidence ashland extra range speed return odd surgical episodeoom commissionfying viva [SEP] daddy brows jin waters sq village above firm chamber clear [SEP]']
[Init] best perm rec loss: 0.8091968297958374 for ['[CLS] speed evidenceoom extra commission return ashland chamber firm daddy episodefying right jin brows [SEP] above village clear viva sq surgical odd range waters [SEP]']
[Init] best perm rec loss: 0.8089424967765808 for ['[CLS] surgical sq odd return vivafying browsoom village [SEP] jin chamber firm clear daddy range ashland waters extra above commission evidence speed right episode [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.989 (perp=12.692, rec=0.447, cos=0.004), tot_loss_proj:3.527 [t=0.17s]
prediction: ['[CLS] government instead might overturned bribes less undernsed worker % truck vietnamesees ` hash list accused evacuate doubt duct? guilt ole head flat [SEP]']
[ 100/2000] tot_loss=2.740 (perp=11.906, rec=0.355, cos=0.004), tot_loss_proj:3.382 [t=0.19s]
prediction: ['[CLS] policy despite likely ) procedure rates of bad worker % truck pitcherses ratio front. superintendent infantry want engineering robberyfying product a flat [SEP]']
[ 150/2000] tot_loss=2.747 (perp=12.198, rec=0.306, cos=0.002), tot_loss_proj:3.321 [t=0.19s]
prediction: ['[CLS] ruling made way compound methods athletes ofnsedtypical women that transmitter effect female on. exiting instead want therefore¦fying looking a machine [SEP]']
[ 200/2000] tot_loss=2.459 (perp=10.950, rec=0.266, cos=0.002), tot_loss_proj:3.193 [t=0.19s]
prediction: ['[CLS] way made way figure look athletes hisnsedtypical women of caretaker effect women on. putting instead due therefore¦fying looking a machine [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.443 (perp=11.039, rec=0.234, cos=0.001), tot_loss_proj:3.644 [t=0.19s]
prediction: ['[CLS] way makes way works look athletes theirnsedtypical women of caretaker effect women. on putting instead due therefore wordfying looking more system [SEP]']
[ 300/2000] tot_loss=2.293 (perp=10.425, rec=0.205, cos=0.003), tot_loss_proj:3.490 [t=0.18s]
prediction: ['[CLS] way makes all works look athletes the brokentypical women of caretaker out women. on putting instead due afford wordfying looking more camera [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.113 (perp=9.695, rec=0.172, cos=0.002), tot_loss_proj:3.408 [t=0.18s]
prediction: ['[CLS] way makes all works out athletes the caretakertypical women offying out women. on putting instead of combine word caretaker look more camera [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.260 (perp=10.471, rec=0.164, cos=0.001), tot_loss_proj:3.357 [t=0.19s]
prediction: ['[CLS] way makes all works out athletes the caretakertypical women offying out mistress.ened instead of enough position word caretaker look more camera [SEP]']
[ 450/2000] tot_loss=2.103 (perp=9.732, rec=0.154, cos=0.002), tot_loss_proj:3.265 [t=0.19s]
prediction: ['[CLS] way makes all works out athletes the caretakertypical women offying out moral.ened instead of enough position murphy caretaker look more like [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.021 (perp=9.368, rec=0.146, cos=0.002), tot_loss_proj:3.076 [t=0.19s]
prediction: ['[CLS] way makes all works out athletes the caretakertypical women allfying out moral caretaker.ened instead of enough - words look more like [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.927 (perp=8.893, rec=0.147, cos=0.001), tot_loss_proj:3.173 [t=0.19s]
prediction: ['[CLS] way makes all works out athletes the stereotypical women allfying out moral caretaker.ened instead of because enough - look more like [SEP]']
[ 600/2000] tot_loss=1.918 (perp=8.893, rec=0.138, cos=0.001), tot_loss_proj:3.172 [t=0.23s]
prediction: ['[CLS] way makes all works out athletes the stereotypical women allfying out moral caretaker.ened instead of because enough - look more like [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.881 (perp=8.717, rec=0.137, cos=0.001), tot_loss_proj:2.962 [t=0.18s]
prediction: ['[CLS] way makes all works out athletes the stereotypical women allfying out moral caretaker.ened instead of enough - because look more like [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.843 (perp=8.545, rec=0.133, cos=0.001), tot_loss_proj:3.204 [t=0.17s]
prediction: ['[CLS] way makes all works athletes out the stereotypical women allfying out moral caretaker.ted instead of enough - because look more like [SEP]']
[ 750/2000] tot_loss=1.952 (perp=9.149, rec=0.121, cos=0.001), tot_loss_proj:3.671 [t=0.17s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women allfying out moral caretaker.ted instead of ; health because look more like [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.953 (perp=9.138, rec=0.124, cos=0.001), tot_loss_proj:3.452 [t=0.17s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women allfying out moral caretaker. enough instead ofted health because look more like [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.917 (perp=8.952, rec=0.125, cos=0.001), tot_loss_proj:3.448 [t=0.17s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women allfying out moral caretaker because enough instead ofted health. look more like [SEP]']
[ 900/2000] tot_loss=1.914 (perp=8.952, rec=0.122, cos=0.001), tot_loss_proj:3.455 [t=0.17s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women allfying out moral caretaker because enough instead ofted health. look more like [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.854 (perp=8.647, rec=0.124, cos=0.001), tot_loss_proj:3.433 [t=0.17s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women all outfying moral caretaker words ; instead ofted moral. look more like [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.971 (perp=9.152, rec=0.138, cos=0.002), tot_loss_proj:3.585 [t=0.18s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women all words enough instead ofted outfying moral caretaker moral. look more like [SEP]']
[1050/2000] tot_loss=1.958 (perp=9.176, rec=0.121, cos=0.001), tot_loss_proj:3.635 [t=0.18s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women all words enough instead ofened outfying moral caretaker moral. look more like [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.932 (perp=9.041, rec=0.123, cos=0.001), tot_loss_proj:3.618 [t=0.18s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women all words enough instead ofened moral outfying moral caretaker. look more like [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.882 (perp=8.785, rec=0.124, cos=0.001), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women instead ofened moral out upside moral caretaker, all words because look more like [SEP]']
[1200/2000] tot_loss=1.887 (perp=8.837, rec=0.118, cos=0.001), tot_loss_proj:3.596 [t=0.18s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women instead ofened moral out upside moral caretaker, all because because look more like [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.829 (perp=8.535, rec=0.120, cos=0.001), tot_loss_proj:3.558 [t=0.17s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women instead ofened out upside moral moral caretaker, all because because look more like [SEP]']
Attempt swap
[1300/2000] tot_loss=1.826 (perp=8.535, rec=0.118, cos=0.001), tot_loss_proj:3.555 [t=0.18s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women instead ofened out upside moral moral caretaker, all because because look more like [SEP]']
[1350/2000] tot_loss=1.824 (perp=8.535, rec=0.116, cos=0.001), tot_loss_proj:3.556 [t=0.18s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women instead ofened out upside moral moral caretaker, all because because look more like [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.792 (perp=8.371, rec=0.117, cos=0.001), tot_loss_proj:3.500 [t=0.18s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women moral moral caretaker instead ofened out upside, all because because look more like [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.779 (perp=8.308, rec=0.116, cos=0.001), tot_loss_proj:3.460 [t=0.17s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women moral moral caretaker instead ofened out upside, all because ; look more like [SEP]']
[1500/2000] tot_loss=1.780 (perp=8.308, rec=0.117, cos=0.001), tot_loss_proj:3.455 [t=0.18s]
prediction: ['[CLS] way makes serious works athletes out the stereotypical women moral moral caretaker instead ofened out upside, all because ; look more like [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.754 (perp=8.180, rec=0.117, cos=0.001), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral moral caretaker instead ofened out upside, all because ; look more like [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.742 (perp=8.148, rec=0.111, cos=0.001), tot_loss_proj:3.464 [t=0.18s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral moral caretaker instead of out upsideened, all because ; look more like [SEP]']
[1650/2000] tot_loss=1.746 (perp=8.148, rec=0.115, cos=0.001), tot_loss_proj:3.463 [t=0.18s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral moral caretaker instead of out upsideened, all because ; look more like [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.744 (perp=8.128, rec=0.117, cos=0.001), tot_loss_proj:3.460 [t=0.17s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral moral caretaker instead of outened upside, all because ; look more like [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.723 (perp=8.044, rec=0.113, cos=0.001), tot_loss_proj:3.450 [t=0.20s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral caretaker instead of outened moral upside, all because because look more like [SEP]']
[1800/2000] tot_loss=1.724 (perp=8.044, rec=0.114, cos=0.001), tot_loss_proj:3.450 [t=0.18s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral caretaker instead of outened moral upside, all because because look more like [SEP]']
Attempt swap
[1850/2000] tot_loss=1.730 (perp=8.044, rec=0.120, cos=0.001), tot_loss_proj:3.452 [t=0.18s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral caretaker instead of outened moral upside, all because because look more like [SEP]']
Attempt swap
[1900/2000] tot_loss=1.726 (perp=8.044, rec=0.115, cos=0.001), tot_loss_proj:3.454 [t=0.17s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral caretaker instead of outened moral upside, all because because look more like [SEP]']
[1950/2000] tot_loss=1.722 (perp=8.044, rec=0.112, cos=0.001), tot_loss_proj:3.449 [t=0.18s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral caretaker instead of outened moral upside, all because because look more like [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.715 (perp=8.004, rec=0.112, cos=0.001), tot_loss_proj:3.473 [t=0.19s]
prediction: ['[CLS] makes way serious works athletes out the stereotypical women moral caretaker instead of outened moral upside, because because look more like all [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] makes way serious works athletes out the stereotypical women moral caretaker instead of outened moral upside, all because because look more like [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.596 | p: 75.000 | r: 78.261
rouge2     | fm: 13.333 | p: 13.043 | r: 13.636
rougeL     | fm: 42.553 | p: 41.667 | r: 43.478
rougeLsum  | fm: 42.553 | p: 41.667 | r: 43.478
r1fm+r2fm = 89.929

[Aggregate metrics]:
rouge1     | fm: 91.207 | p: 90.321 | r: 92.149
rouge2     | fm: 60.875 | p: 60.723 | r: 61.080
rougeL     | fm: 81.009 | p: 80.405 | r: 81.646
rougeLsum  | fm: 80.591 | p: 79.929 | r: 81.267
r1fm+r2fm = 152.083

input #21 time: 0:07:58 | total time: 3:13:12


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9993366894184397
highest_index [0]
highest [0.9993366894184397]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9641942381858826 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9582980871200562 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 0.9533578157424927 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9530670642852783 for ['[CLS] husband figures individual merge gdp planongriders beat your nur [SEP]']
[Init] best rec loss: 0.936561644077301 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9236189723014832 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.9202683568000793 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9199215769767761 for ['[CLS] poor resemblance wrote $ manufacture i vested another dir immunity access [SEP]']
[Init] best perm rec loss: 0.9190679788589478 for ['[CLS] $ wrote poor vested dir immunity resemblance manufacture i another access [SEP]']
[Init] best perm rec loss: 0.917163074016571 for ['[CLS] dir manufacture i $ another poor access immunity wrote vested resemblance [SEP]']
[Init] best perm rec loss: 0.9159475564956665 for ['[CLS] $ i another manufacture resemblance immunity vested access poor wrote dir [SEP]']
[Init] best perm rec loss: 0.9134272336959839 for ['[CLS] dir wrote i vested manufacture immunity access $ another poor resemblance [SEP]']
[Init] best perm rec loss: 0.9125464558601379 for ['[CLS] manufacture $ immunity vested resemblance wrote i dir another access poor [SEP]']
[Init] best perm rec loss: 0.9117497801780701 for ['[CLS] manufacture vested access immunity poor another resemblance i $ wrote dir [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.353 (perp=10.456, rec=0.259, cos=0.003), tot_loss_proj:2.507 [t=0.19s]
prediction: ['[CLS] adventure successful integral good design a wonderful successful adaptation produced successful [SEP]']
[ 100/2000] tot_loss=2.054 (perp=9.354, rec=0.182, cos=0.002), tot_loss_proj:2.302 [t=0.19s]
prediction: ['[CLS] successful successfuleller adaptation adaptation a successful enjoyable adaptation. successful [SEP]']
[ 150/2000] tot_loss=1.790 (perp=8.200, rec=0.149, cos=0.001), tot_loss_proj:2.034 [t=0.20s]
prediction: ['[CLS] a successful self adaptation adaptation a successful enjoyable adaptation. its [SEP]']
[ 200/2000] tot_loss=1.869 (perp=8.647, rec=0.138, cos=0.001), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] a successful self adaptation film a an enjoyable adaptation. its [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.583 (perp=7.308, rec=0.120, cos=0.001), tot_loss_proj:1.829 [t=0.17s]
prediction: ['[CLS] a successful film adaptation right and an enjoyable adaptation film its [SEP]']
[ 300/2000] tot_loss=1.672 (perp=7.874, rec=0.096, cos=0.001), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] a successful film film right and an enjoyable adaptation film its [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.703 (perp=8.095, rec=0.083, cos=0.001), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] a successful film film adaptation and an enjoyable right in own [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.375 (perp=6.503, rec=0.073, cos=0.001), tot_loss_proj:1.532 [t=0.17s]
prediction: ['[CLS] a successful film film adaptation and an enjoyable in own right [SEP]']
[ 450/2000] tot_loss=1.383 (perp=6.503, rec=0.081, cos=0.001), tot_loss_proj:1.524 [t=0.17s]
prediction: ['[CLS] a successful film film adaptation and an enjoyable in own right [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.184 (perp=5.548, rec=0.073, cos=0.001), tot_loss_proj:1.281 [t=0.17s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.185 (perp=5.548, rec=0.074, cos=0.001), tot_loss_proj:1.276 [t=0.17s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
[ 600/2000] tot_loss=1.190 (perp=5.548, rec=0.079, cos=0.001), tot_loss_proj:1.271 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.188 (perp=5.548, rec=0.077, cos=0.001), tot_loss_proj:1.291 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.176 (perp=5.548, rec=0.065, cos=0.001), tot_loss_proj:1.281 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
[ 750/2000] tot_loss=1.181 (perp=5.548, rec=0.070, cos=0.001), tot_loss_proj:1.280 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.187 (perp=5.548, rec=0.076, cos=0.001), tot_loss_proj:1.282 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.177 (perp=5.548, rec=0.067, cos=0.001), tot_loss_proj:1.282 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
[ 900/2000] tot_loss=1.176 (perp=5.548, rec=0.065, cos=0.001), tot_loss_proj:1.286 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.191 (perp=5.548, rec=0.080, cos=0.001), tot_loss_proj:1.285 [t=0.17s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
Attempt swap
[1000/2000] tot_loss=1.189 (perp=5.548, rec=0.078, cos=0.001), tot_loss_proj:1.281 [t=0.17s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
[1050/2000] tot_loss=1.182 (perp=5.548, rec=0.071, cos=0.001), tot_loss_proj:1.287 [t=0.17s]
prediction: ['[CLS] a successful film adaptation and an enjoyable film in own right [SEP]']
Attempt swap
[1100/2000] tot_loss=1.411 (perp=6.759, rec=0.058, cos=0.001), tot_loss_proj:1.577 [t=0.17s]
prediction: ['[CLS] a successful its adaptation and an enjoyable film in own right [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.330 (perp=6.234, rec=0.082, cos=0.001), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] a successful film in film adaptation and an enjoyable own right [SEP]']
[1200/2000] tot_loss=1.271 (perp=6.023, rec=0.065, cos=0.001), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] a successful film in its adaptation and an enjoyable own right [SEP]']
Attempt swap
[1250/2000] tot_loss=1.274 (perp=6.023, rec=0.068, cos=0.001), tot_loss_proj:1.512 [t=0.17s]
prediction: ['[CLS] a successful film in its adaptation and an enjoyable own right [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.056 (perp=4.881, rec=0.078, cos=0.001), tot_loss_proj:1.068 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[1350/2000] tot_loss=1.053 (perp=4.881, rec=0.075, cos=0.001), tot_loss_proj:1.080 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Attempt swap
[1400/2000] tot_loss=1.040 (perp=4.881, rec=0.063, cos=0.001), tot_loss_proj:1.069 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Attempt swap
[1450/2000] tot_loss=1.038 (perp=4.881, rec=0.060, cos=0.001), tot_loss_proj:1.072 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[1500/2000] tot_loss=1.045 (perp=4.881, rec=0.068, cos=0.001), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Attempt swap
[1550/2000] tot_loss=1.045 (perp=4.881, rec=0.067, cos=0.001), tot_loss_proj:1.077 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Attempt swap
[1600/2000] tot_loss=1.038 (perp=4.881, rec=0.060, cos=0.001), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[1650/2000] tot_loss=1.048 (perp=4.881, rec=0.070, cos=0.001), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Attempt swap
[1700/2000] tot_loss=1.052 (perp=4.881, rec=0.074, cos=0.001), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Attempt swap
[1750/2000] tot_loss=1.047 (perp=4.881, rec=0.070, cos=0.001), tot_loss_proj:1.078 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[1800/2000] tot_loss=1.036 (perp=4.881, rec=0.059, cos=0.001), tot_loss_proj:1.068 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Attempt swap
[1850/2000] tot_loss=1.037 (perp=4.881, rec=0.059, cos=0.001), tot_loss_proj:1.073 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Attempt swap
[1900/2000] tot_loss=1.037 (perp=4.881, rec=0.059, cos=0.001), tot_loss_proj:1.081 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[1950/2000] tot_loss=1.036 (perp=4.881, rec=0.059, cos=0.001), tot_loss_proj:1.069 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Attempt swap
[2000/2000] tot_loss=1.035 (perp=4.881, rec=0.058, cos=0.001), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.589 | p: 90.779 | r: 92.444
rouge2     | fm: 62.602 | p: 62.415 | r: 62.856
rougeL     | fm: 81.692 | p: 81.109 | r: 82.371
rougeLsum  | fm: 81.656 | p: 81.044 | r: 82.325
r1fm+r2fm = 154.190

input #22 time: 0:07:47 | total time: 3:20:59


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.999235259621351
highest_index [0]
highest [0.999235259621351]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8047433495521545 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7619422078132629 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7616995573043823 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7562028169631958 for ['[CLS] catching directita antibiotics portrait omeza billy together nile skirtly rovers \\ aw remarks [CLS] soothing nonprofit attitude maybetag amar article tattooll camp [SEP] iii toe been ouaine var outrina " wild addition barry faced travelled rocket leigh engine ribbon abbreviation orders [SEP]']
[Init] best rec loss: 0.7405182719230652 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.7381587028503418 for ['[CLS] compiling ears eponymous education carlo debutrk area guᵈ yeah spare span hugolene belowtile draft housing trade box grace these head engineback ter depend likelihood previous meantime steam imagery extra fond those reissued 2 form privatepromising roads schools search maximti gazeshold [SEP]']
[Init] best rec loss: 0.7374657392501831 for ['[CLS] florence heck vineyard breachpping spider hoptive mp ware property exploitation drew genre producer vic 5 alien straw becoming todder cut lackdity takgles queen warner una cloak orientation relations mouth copmed integer dd pearson jessie exterioristic abbreviated extra home round responded facts [SEP]']
[Init] best rec loss: 0.7275494337081909 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.7270619869232178 for ['[CLS] baseball remote finlandperation tracks. erica another air her created must total madame marijuana mayo steam quit test monroe clutch fine reaching sensation into writ colon asleeptat eve level office rocker x debuted competitionblood pepper bullshitcellular culture - critics countont host major novel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.826 (perp=11.814, rec=0.461, cos=0.003), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] has environmental education orion mission. composition soldier operate creative 2015 should vision aims pulse heritage heritage project globalgc wonderful explosion zero once history unique significance which the rescue curve function project international harder area britten reach be [SEP] needed mission crafts piazzaivar ; urban its [SEP]']
[ 100/2000] tot_loss=2.746 (perp=11.476, rec=0.378, cos=0.073), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] besides european education rangers program, composition soldier rather ze 1955 should total aims visionlan heritage artistic thermal the archie design madeline demand psychological its dominatedhang the rescue critics objective project graduates head as britten the, becoming needed historical crafts its major ; the its [SEP]']
[ 150/2000] tot_loss=2.663 (perp=11.923, rec=0.277, cos=0.002), tot_loss_proj:3.589 [t=0.17s]
prediction: ['[CLS] estonian european education rangers asset, state crisis rather ze camera should total aims latinlan history ministry thermal the archie design madeline beg built its dominated what the 、 critics objective projects infantry head issues britten the, better ) emotional cannot its major ; : its [SEP]']
[ 200/2000] tot_loss=2.636 (perp=11.943, rec=0.246, cos=0.001), tot_loss_proj:3.385 [t=0.18s]
prediction: ['[CLS] picture strategic education rangers portfolio,ity dramas ratherfi re patriotic its aims :lan history ministry energy and archie drama madeline ni environmental its ultimately its france strategic critics objective projects soldiers stage melissa vietnam the, becoming ) emotional alloys its main ; :... [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.407 (perp=10.983, rec=0.210, cos=0.001), tot_loss_proj:3.278 [t=0.17s]
prediction: ['[CLS] photographed strategic objective rangers portfolio,ity dramas ratherfi re patriotic its achieved : : generation ethics energy the archie picture madeline became otherwise its ultimately its the strategic critics objective projects soldiers mouth the melissa patriotic, becoming ) emotionalegorical its main ; : that [SEP]']
[ 300/2000] tot_loss=2.264 (perp=10.431, rec=0.176, cos=0.001), tot_loss_proj:3.105 [t=0.20s]
prediction: ['[CLS]zing strategic objective soldiers portfolio, military vietnam ratherfi which patriotic list ultimatelys ; generation ethics : the thanked picture madeline became ultimately its achieve its the strategic ultimately objective projects soldiersuch the melissa patriotic, subsequently ) emotionalegorical its main ; : that [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.055 (perp=9.385, rec=0.175, cos=0.003), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS]zing strategic value soldiers portfolio, military drama which patriotic list ultimately a is generation drama : the thanked picture madeline rathersh were ultimately its achieve : the strategic ultimately objective drama soldiers while the melissa patriotic, crisis ) emotional colonial its main ; : that [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.225 (perp=10.369, rec=0.151, cos=0.001), tot_loss_proj:3.155 [t=0.17s]
prediction: ['[CLS]zing strategic vietnam soldiers portfolio, military drama in patriotic list ultimately a picture, generation dramaci the jax chronic ratherh meditation ultimately its achieve : the strategic ultimately objective drama soldiers while the melissa patriotic, crisis or emotional colonial its main ; : that [SEP]']
[ 450/2000] tot_loss=2.045 (perp=9.503, rec=0.140, cos=0.005), tot_loss_proj:3.138 [t=0.17s]
prediction: ['[CLS]zing strategic vietnam vietnam portfolio, vietnam drama in patriotic list ultimately a picture, generation drama, the jax chronic ratherh meditation ultimately its achieves the strategic ultimately objective drama soldiers while them patriotic, crisis involving selena. its main ; : that [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.017 (perp=9.324, rec=0.146, cos=0.007), tot_loss_proj:2.781 [t=0.17s]
prediction: ['[CLS]zing strategic vietnam vietnam +, vietnam drama that patriotic list ultimately a picture, generation drama, the jax chronic ratherh drama ultimately its achieves the strategic ultimately objective were soldiers while them patriotic, crisis involving selena. its main ; : that [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.152 (perp=10.103, rec=0.129, cos=0.002), tot_loss_proj:3.014 [t=0.17s]
prediction: ['[CLS] strategic vietnam vietnam bazing, vietnam ra that patriotic list ultimately a picture, generation dramaci the jax chronic ratherh drama ultimately its achieves the strategic cost objectivenal soldiers while them patriotic, crisis involving selena. its main ; : that [SEP]']
[ 600/2000] tot_loss=2.112 (perp=9.922, rec=0.127, cos=0.001), tot_loss_proj:2.932 [t=0.17s]
prediction: ['[CLS] strategic vietnam vietnam bazing to vietnam ra that patriotic list ultimately a picture, generation dramati the iraqi chronic ratherh drama ultimately its achieves the strategic cost objectivenal soldiers while them conflict, crisis involving selena. its main ; : that [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.144 (perp=10.120, rec=0.119, cos=0.001), tot_loss_proj:3.035 [t=0.17s]
prediction: ['[CLS] strategic that vietnam bazing to vietnam ra vietnam patriotic list ultimately a picture, generation dramati the iraqi chronic ratherh drama ultimately its achievess strategic cost objectivenal soldiers while them conflict, crisis involving selena,s main ; : that [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.089 (perp=9.839, rec=0.120, cos=0.002), tot_loss_proj:2.977 [t=0.17s]
prediction: ['[CLS] strategic that vietnam pictureszing to vietnam drama ra vietnam patriotic list ultimately a picture, generationti the iraqi chronic ratherh drama ultimately its achievess strategic cost objectivenal soldiers while them conflict, crisis involving selena.s main ; : that [SEP]']
[ 750/2000] tot_loss=2.121 (perp=10.017, rec=0.116, cos=0.001), tot_loss_proj:3.078 [t=0.17s]
prediction: ['[CLS] strategic that vietnam cannotzing to vietnam drama ra vietnam patriotic list ultimately a picture, generationti the ra chronic musth drama ultimately its achievess strategic cost objectivenal soldiers while them conflict, crisis involving selena,s main ; : that [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.028 (perp=9.551, rec=0.117, cos=0.001), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] strategic that vietnam cannotzing to vietnam drama ra vietnam patriotic its ultimately a picture, generationti the ra chronic soh drama ultimatelys achieves its strategic cost objectivenal soldiers while the fei conflict, crisis involving selena,s main ; : that [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.002 (perp=9.432, rec=0.115, cos=0.001), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] strategic that vietnam cannotzing to vietnam drama ra vietnam patriotic such ultimately a picture, generationti the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the fei conflict, conflict involving selenanals main ; : that [SEP]']
[ 900/2000] tot_loss=1.961 (perp=9.232, rec=0.113, cos=0.001), tot_loss_proj:2.879 [t=0.17s]
prediction: ['[CLS] strategic that vietnam cannotzing to vietnam drama ra vietnam patriotic such ultimately a picture, generationti the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the such conflict, conflict involving selenanals main ; : that [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.889 (perp=8.899, rec=0.108, cos=0.001), tot_loss_proj:2.780 [t=0.20s]
prediction: ['[CLS] strategic that vietnam cannotzing to vietnam drama ra such patriotic vietnam ultimately a picture, generationti the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the such conflict, conflict involving selenanals main ; : that [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.875 (perp=8.854, rec=0.103, cos=0.001), tot_loss_proj:2.759 [t=0.17s]
prediction: ['[CLS] strategic that vietnam willzing to vietnam drama ra such patriotic vietnamti a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the such conflict, conflict hiv selenanals main ; : that [SEP]']
[1050/2000] tot_loss=1.852 (perp=8.737, rec=0.104, cos=0.001), tot_loss_proj:2.751 [t=0.17s]
prediction: ['[CLS] strategic that vietnam willzing to vietnam drama ra such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the such conflict, conflict involving dramanals main ; : that [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.833 (perp=8.638, rec=0.103, cos=0.002), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] such that vietnam willzing to vietnam drama ra such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the strategic conflict, conflict involving dramanals main ; : that [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.788 (perp=8.382, rec=0.111, cos=0.001), tot_loss_proj:2.649 [t=0.17s]
prediction: ['[CLS] such that vietnam will to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the strategic conflict, conflict involving dramanals main ; : that [SEP]']
[1200/2000] tot_loss=1.787 (perp=8.382, rec=0.109, cos=0.001), tot_loss_proj:2.652 [t=0.17s]
prediction: ['[CLS] such that vietnam will to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the strategic conflict, conflict involving dramanals main ; : that [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.773 (perp=8.357, rec=0.100, cos=0.001), tot_loss_proj:2.745 [t=0.20s]
prediction: ['[CLS] such that will vietnam to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the strategic conflict, conflict underworld dramanals main ; : that [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.733 (perp=8.157, rec=0.100, cos=0.001), tot_loss_proj:2.649 [t=0.19s]
prediction: ['[CLS] such that will vietnam to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the strategic conflict, main underworld dramanals conflict ; : that [SEP]']
[1350/2000] tot_loss=1.758 (perp=8.242, rec=0.108, cos=0.001), tot_loss_proj:2.705 [t=0.19s]
prediction: ['[CLS] such that will vietnam to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the strategic conflict, main pixel dramanals conflict ; : that [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.723 (perp=8.088, rec=0.105, cos=0.001), tot_loss_proj:2.662 [t=0.19s]
prediction: ['[CLS] such that will vietnam to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic cost objective, soldiers while the strategic conflict, main that pixel dramanals conflict ; : [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.696 (perp=7.970, rec=0.102, cos=0.001), tot_loss_proj:2.620 [t=0.19s]
prediction: ['[CLS] such that will cost to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic vietnam objective, soldiers while the strategic conflict, main that pixel dramanals conflict ; : [SEP]']
[1500/2000] tot_loss=1.703 (perp=7.970, rec=0.108, cos=0.001), tot_loss_proj:2.626 [t=0.19s]
prediction: ['[CLS] such that will cost to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic vietnam objective, soldiers while the strategic conflict, main that pixel dramanals conflict ; : [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.674 (perp=7.878, rec=0.097, cos=0.001), tot_loss_proj:2.581 [t=0.19s]
prediction: ['[CLS] such that will cost to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic objective, soldiers while the strategic conflict, main that vietnam pixel dramanals conflict ; : [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.660 (perp=7.815, rec=0.096, cos=0.001), tot_loss_proj:2.568 [t=0.19s]
prediction: ['[CLS] such that will cost to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic objective, soldiers while the strategic conflict, main that vietnam pixel dramanal conflicts ; : [SEP]']
[1650/2000] tot_loss=1.664 (perp=7.815, rec=0.100, cos=0.001), tot_loss_proj:2.570 [t=0.19s]
prediction: ['[CLS] such that will cost to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic objective, soldiers while the strategic conflict, main that vietnam pixel dramanal conflicts ; : [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.636 (perp=7.650, rec=0.105, cos=0.001), tot_loss_proj:2.612 [t=0.19s]
prediction: ['[CLS] such that will cost to vietnam drama razing such patriotic vietnam tone a picture, that ultimately the ra chronic soh drama ultimatelys achieves its strategic objective, soldiers while the strategic conflict, main generation vietnam pixel dramanal conflicts ; : [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.605 (perp=7.492, rec=0.106, cos=0.001), tot_loss_proj:2.510 [t=0.19s]
prediction: ['[CLS] such that will cost to vietnam drama razing such patriotic vietnamh a picture, that ultimately the ra chronic soh drama ultimately achieves its strategic objective, soldiers while the strategic conflicts, main generation vietnam pixel dramanal conflicts ; : [SEP]']
[1800/2000] tot_loss=1.602 (perp=7.492, rec=0.103, cos=0.001), tot_loss_proj:2.512 [t=0.19s]
prediction: ['[CLS] such that will cost to vietnam drama razing such patriotic vietnamh a picture, that ultimately the ra chronic soh drama ultimately achieves its strategic objective, soldiers while the strategic conflicts, main generation vietnam pixel dramanal conflicts ; : [SEP]']
Attempt swap
[1850/2000] tot_loss=1.603 (perp=7.492, rec=0.103, cos=0.001), tot_loss_proj:2.512 [t=0.19s]
prediction: ['[CLS] such that will cost to vietnam drama razing such patriotic vietnamh a picture, that ultimately the ra chronic soh drama ultimately achieves its strategic objective, soldiers while the strategic conflicts, main generation vietnam pixel dramanal conflicts ; : [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.565 (perp=7.298, rec=0.104, cos=0.001), tot_loss_proj:2.402 [t=0.19s]
prediction: ['[CLS] that will cost to vietnam drama razing such patriotic vietnamh such a picture, that ultimately the ra chronic soh drama ultimately achieves its strategic objective, soldiers while the strategic conflicts, main generation vietnam pixel dramanal conflicts ; : [SEP]']
[1950/2000] tot_loss=1.561 (perp=7.276, rec=0.104, cos=0.001), tot_loss_proj:2.407 [t=0.19s]
prediction: ['[CLS] that will cost to vietnam drama razing such patriotic vietnam tone of a picture, that ultimately the ra chronic soh drama ultimately achieves its strategic objective, soldiers while the strategic conflicts, main generation vietnam pixel dramanal conflicts ; : [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.604 (perp=7.507, rec=0.102, cos=0.001), tot_loss_proj:2.358 [t=0.20s]
prediction: ['[CLS] that will cost to vietnam drama razing such patriotic must vietnamh with a picture, that ultimately the ra chronich drama ultimately achieves its strategic objective, soldiers while the strategic conflicts, main generation vietnam pixel dramanal conflicts ; : [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] such that will cost to vietnam drama razing such patriotic vietnam tone a picture, generation ultimately the ra chronic soh drama ultimatelys achieves its strategic objective, soldiers while the strategic conflict, main that vietnam pixel dramanal conflicts ; : [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.759 | p: 61.538 | r: 60.000
rouge2     | fm: 5.195 | p: 5.263 | r: 5.128
rougeL     | fm: 40.506 | p: 41.026 | r: 40.000
rougeLsum  | fm: 40.506 | p: 41.026 | r: 40.000
r1fm+r2fm = 65.954

[Aggregate metrics]:
rouge1     | fm: 90.319 | p: 89.624 | r: 91.059
rouge2     | fm: 60.064 | p: 59.965 | r: 60.244
rougeL     | fm: 79.974 | p: 79.448 | r: 80.559
rougeLsum  | fm: 79.707 | p: 79.130 | r: 80.359
r1fm+r2fm = 150.383

input #23 time: 0:07:43 | total time: 3:28:43


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9993537840940762
highest_index [0]
highest [0.9993537840940762]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.894450843334198 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.867894172668457 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8559075593948364 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8252934217453003 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.822307825088501 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8148989677429199 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7632057666778564 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7629173994064331 for ['[CLS]aneous county port play em bond mid damned snow village bush ryuwyl suffer arms attack happy unless younger no [SEP]']
[Init] best perm rec loss: 0.7620291113853455 for ['[CLS] em village damned suffer snow county mid bush attackaneous happy port bond younger unless armswyl no play ryu [SEP]']
[Init] best perm rec loss: 0.7610010504722595 for ['[CLS] em snow no bond suffer villagewyl play bush unlessaneous ryu mid arms port attack damned happy county younger [SEP]']
[Init] best perm rec loss: 0.7564561367034912 for ['[CLS] portaneouswyl em arms attack damned play ryu happy younger bond mid suffer county unless no village bush snow [SEP]']
[Init] best perm rec loss: 0.7562641501426697 for ['[CLS] county damned play sufferaneouswyl younger unless snow no mid happy arms em ryu attack village bush port bond [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.853 (perp=11.968, rec=0.453, cos=0.006), tot_loss_proj:3.395 [t=0.17s]
prediction: ['[CLS] protest sect ac workers fringe - evil taken garbage interrupting drugrta organizations stupid?ched japanese chain terrorists terrorist [SEP]']
[ 100/2000] tot_loss=2.919 (perp=12.789, rec=0.360, cos=0.001), tot_loss_proj:3.583 [t=0.18s]
prediction: ['[CLS] police terrorist ac political fringe xml evilinatory accused terrorist drug an countries stupid!feit su chain terrorists defensive [SEP]']
[ 150/2000] tot_loss=2.419 (perp=10.477, rec=0.320, cos=0.004), tot_loss_proj:2.994 [t=0.18s]
prediction: ['[CLS] transport qaeda the political cause xml evil taken controversy terrorists drug an ( stupid! terrorists / ) terrorists outside [SEP]']
[ 200/2000] tot_loss=2.469 (perp=11.031, rec=0.262, cos=0.001), tot_loss_proj:3.166 [t=0.18s]
prediction: ['[CLS] siouxpartisan the political review taken evil context controversy terrorists drug an ( evil! terrorists / ) terrorists outside [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.172 (perp=9.778, rec=0.215, cos=0.001), tot_loss_proj:2.916 [t=0.18s]
prediction: ['[CLS] the context the political review taken evilathic controversy terrorists supply an ( evil! terrorist / ) terrorists outside [SEP]']
[ 300/2000] tot_loss=2.172 (perp=9.890, rec=0.193, cos=0.002), tot_loss_proj:2.844 [t=0.18s]
prediction: ['[CLS] see context the political review taken evil evil controversy terrorists supply related ( evil! terrorists / ) terrorists outside [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.997 (perp=9.075, rec=0.180, cos=0.002), tot_loss_proj:2.654 [t=0.18s]
prediction: ['[CLS] see context the context ) taken evil evil current / political related ( evil! terrorists terrorists are terrorists outside [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.973 (perp=8.936, rec=0.183, cos=0.002), tot_loss_proj:2.711 [t=0.17s]
prediction: ['[CLS] see context the context ) taken evil evil evil / climate related ( current! terrorists terrorists are! outside [SEP]']
[ 450/2000] tot_loss=1.926 (perp=8.837, rec=0.158, cos=0.001), tot_loss_proj:2.702 [t=0.17s]
prediction: ['[CLS] see context the context ) taken evil evil evil / climates ( current! terrorists terrorists are! outside [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.729 (perp=10.866, rec=0.503, cos=0.053), tot_loss_proj:3.016 [t=0.18s]
prediction: ['[CLS] see context the contextyd taken evil -c operation political foyer ; current! terrorists terrorists were thereafter outside [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.451 (perp=9.965, rec=0.433, cos=0.024), tot_loss_proj:2.826 [t=0.18s]
prediction: ['[CLS] see context the contextyd evil - environmental operation political foyer ; current! terrorists terrorists were thereafter taken outside [SEP]']
[ 600/2000] tot_loss=2.432 (perp=10.089, rec=0.398, cos=0.016), tot_loss_proj:2.854 [t=0.18s]
prediction: ['[CLS] see context the contextyd evil -nded operation political president ; current! terrorists terrorists were thereafter taken outside [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.370 (perp=9.895, rec=0.378, cos=0.013), tot_loss_proj:2.881 [t=0.18s]
prediction: ['[CLS] see context the contextyd evil suchnded operation! president. current political terrorists terrorists were thereafter taken outside [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.240 (perp=9.325, rec=0.364, cos=0.011), tot_loss_proj:2.920 [t=0.18s]
prediction: ['[CLS] see context the contextyd defending evil such operation! president. current political terrorists terrorists were thereafter taken outside [SEP]']
[ 750/2000] tot_loss=2.224 (perp=9.317, rec=0.351, cos=0.009), tot_loss_proj:2.871 [t=0.18s]
prediction: ['[CLS] see context the contextyd defending evil - operation! president ) current political terrorists terrorists were thereafter taken outside [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.125 (perp=8.871, rec=0.342, cos=0.008), tot_loss_proj:2.783 [t=0.18s]
prediction: ['[CLS] see context the contextyd defending evil - operation president! ) current political terrorists terrorists were thereafter taken outside [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.103 (perp=8.759, rec=0.344, cos=0.007), tot_loss_proj:2.685 [t=0.18s]
prediction: ['[CLS] see context the contextyd defending evil - operation president! ) current political terrorists were terrorists thereafter taken outside [SEP]']
[ 900/2000] tot_loss=2.153 (perp=9.047, rec=0.337, cos=0.006), tot_loss_proj:2.777 [t=0.18s]
prediction: ['[CLS] see context the contextyd defending evil - operation foyer! ) current political terrorists were terrorists thereafter taken outside [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.214 (perp=9.385, rec=0.331, cos=0.006), tot_loss_proj:2.895 [t=0.17s]
prediction: ['[CLS] see context the contextyd defending evil president operation -! ) current political terrorists were terrorists thereafter taken outside [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.144 (perp=9.058, rec=0.327, cos=0.006), tot_loss_proj:2.846 [t=0.17s]
prediction: ['[CLS] see context the contextyd defending evil president operation )! - current political terrorists were terrorists thereafter taken outside [SEP]']
[1050/2000] tot_loss=2.140 (perp=9.058, rec=0.324, cos=0.005), tot_loss_proj:2.849 [t=0.17s]
prediction: ['[CLS] see context the contextyd defending evil president operation )! - current political terrorists were terrorists thereafter taken outside [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.109 (perp=8.859, rec=0.332, cos=0.005), tot_loss_proj:2.743 [t=0.19s]
prediction: ['[CLS] see context the presidentyd defending evil context operation )! - current political terrorists were terrorists thereafter taken outside [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.054 (perp=8.605, rec=0.327, cos=0.006), tot_loss_proj:2.896 [t=0.17s]
prediction: ['[CLS] see context the presidentyd defending evil context operation! - current political terrorists were terrorists thereafter taken outside ) [SEP]']
[1200/2000] tot_loss=2.049 (perp=8.605, rec=0.323, cos=0.005), tot_loss_proj:2.894 [t=0.17s]
prediction: ['[CLS] see context the presidentyd defending evil context operation! - current political terrorists were terrorists thereafter taken outside ) [SEP]']
Attempt swap
[1250/2000] tot_loss=2.038 (perp=8.605, rec=0.312, cos=0.004), tot_loss_proj:2.904 [t=0.17s]
prediction: ['[CLS] see context the presidentyd defending evil context operation! - current political terrorists were terrorists thereafter taken outside ) [SEP]']
Attempt swap
[1300/2000] tot_loss=2.041 (perp=8.605, rec=0.316, cos=0.004), tot_loss_proj:2.902 [t=0.18s]
prediction: ['[CLS] see context the presidentyd defending evil context operation! - current political terrorists were terrorists thereafter taken outside ) [SEP]']
[1350/2000] tot_loss=2.033 (perp=8.605, rec=0.308, cos=0.004), tot_loss_proj:2.898 [t=0.18s]
prediction: ['[CLS] see context the presidentyd defending evil context operation! - current political terrorists were terrorists thereafter taken outside ) [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.017 (perp=8.531, rec=0.307, cos=0.004), tot_loss_proj:3.077 [t=0.17s]
prediction: ['[CLS] see context the presidentyd context defending evil operation! - current political terrorists were terrorists thereafter taken outside ) [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.019 (perp=8.541, rec=0.307, cos=0.004), tot_loss_proj:3.068 [t=0.17s]
prediction: ['[CLS] see context the presidentyd context defending operation evil! - current political terrorists were terrorists thereafter taken outside ) [SEP]']
[1500/2000] tot_loss=2.013 (perp=8.541, rec=0.301, cos=0.004), tot_loss_proj:3.067 [t=0.17s]
prediction: ['[CLS] see context the presidentyd context defending operation evil! - current political terrorists were terrorists thereafter taken outside ) [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.072 (perp=8.811, rec=0.306, cos=0.004), tot_loss_proj:2.718 [t=0.19s]
prediction: ['[CLS] see context the presidentyd context environmental evil! - current political operation terrorists were terrorists over taken outside ) [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.007 (perp=8.461, rec=0.310, cos=0.005), tot_loss_proj:2.787 [t=0.18s]
prediction: ['[CLS] see context the presidentyd context environmental evil! - current political operation terrorists over terrorists were taken outside ) [SEP]']
[1650/2000] tot_loss=2.001 (perp=8.461, rec=0.305, cos=0.004), tot_loss_proj:2.788 [t=0.17s]
prediction: ['[CLS] see context the presidentyd context environmental evil! - current political operation terrorists over terrorists were taken outside ) [SEP]']
Attempt swap
[1700/2000] tot_loss=1.997 (perp=8.461, rec=0.300, cos=0.004), tot_loss_proj:2.787 [t=0.17s]
prediction: ['[CLS] see context the presidentyd context environmental evil! - current political operation terrorists over terrorists were taken outside ) [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.957 (perp=8.241, rec=0.305, cos=0.004), tot_loss_proj:2.873 [t=0.17s]
prediction: ['[CLS] see context context presidentyd the environmental evil! - current political operation terrorists over terrorists were taken outside ) [SEP]']
[1800/2000] tot_loss=1.959 (perp=8.241, rec=0.307, cos=0.004), tot_loss_proj:2.869 [t=0.18s]
prediction: ['[CLS] see context context presidentyd the environmental evil! - current political operation terrorists over terrorists were taken outside ) [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.924 (perp=8.065, rec=0.307, cos=0.004), tot_loss_proj:2.764 [t=0.18s]
prediction: ['[CLS] see context operation presidentyd the environmental evil! - current political context terrorists over terrorists were taken outside ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.922 (perp=8.065, rec=0.306, cos=0.004), tot_loss_proj:2.764 [t=0.18s]
prediction: ['[CLS] see context operation presidentyd the environmental evil! - current political context terrorists over terrorists were taken outside ) [SEP]']
[1950/2000] tot_loss=1.916 (perp=8.065, rec=0.299, cos=0.004), tot_loss_proj:2.761 [t=0.17s]
prediction: ['[CLS] see context operation presidentyd the environmental evil! - current political context terrorists over terrorists were taken outside ) [SEP]']
Attempt swap
[2000/2000] tot_loss=1.913 (perp=8.065, rec=0.296, cos=0.004), tot_loss_proj:2.762 [t=0.17s]
prediction: ['[CLS] see context operation presidentyd the environmental evil! - current political context terrorists over terrorists were taken outside ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] see context the context ) taken evil / evil evil climates ( current! terrorists terrorists are! outside [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.706 | p: 68.750 | r: 61.111
rouge2     | fm: 12.500 | p: 13.333 | r: 11.765
rougeL     | fm: 41.176 | p: 43.750 | r: 38.889
rougeLsum  | fm: 41.176 | p: 43.750 | r: 38.889
r1fm+r2fm = 77.206

[Aggregate metrics]:
rouge1     | fm: 89.172 | p: 88.605 | r: 89.811
rouge2     | fm: 58.317 | p: 58.195 | r: 58.426
rougeL     | fm: 78.197 | p: 77.861 | r: 78.751
rougeLsum  | fm: 78.170 | p: 77.717 | r: 78.697
r1fm+r2fm = 147.489

input #24 time: 0:07:56 | total time: 3:36:40


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9993176191193096
highest_index [0]
highest [0.9993176191193096]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.002394437789917 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9406914114952087 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9302701950073242 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9185459613800049 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9134899973869324 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9054555296897888 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.876388669013977 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.875738263130188 for ['[CLS] cycle oblast jury mouth [SEP]']
[Init] best perm rec loss: 0.8756436705589294 for ['[CLS] oblast cycle jury mouth [SEP]']
[Init] best perm rec loss: 0.8743534088134766 for ['[CLS] oblast jury mouth cycle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.068 (perp=8.906, rec=0.281, cos=0.005), tot_loss_proj:2.273 [t=0.17s]
prediction: ['[CLS] beautiful film beautiful beautiful [SEP]']
[ 100/2000] tot_loss=2.276 (perp=10.589, rec=0.157, cos=0.002), tot_loss_proj:2.506 [t=0.17s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 150/2000] tot_loss=2.232 (perp=10.589, rec=0.113, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 200/2000] tot_loss=2.186 (perp=10.501, rec=0.084, cos=0.001), tot_loss_proj:2.504 [t=0.17s]
prediction: ['[CLS] beautiful film strange and [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.409 (perp=6.646, rec=0.078, cos=0.001), tot_loss_proj:1.437 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 300/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.432 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.380 (perp=6.646, rec=0.050, cos=0.001), tot_loss_proj:1.442 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.426 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.424 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.432 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.435 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.384 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.434 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.433 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.387 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.435 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.380 (perp=6.646, rec=0.049, cos=0.001), tot_loss_proj:1.420 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.422 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.432 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.427 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.422 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.390 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.442 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.431 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.396 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.438 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.440 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.386 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.417 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.387 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.436 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.386 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.440 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.398 (perp=6.646, rec=0.068, cos=0.001), tot_loss_proj:1.440 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.402 (perp=6.646, rec=0.071, cos=0.001), tot_loss_proj:1.429 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.385 (perp=6.646, rec=0.054, cos=0.001), tot_loss_proj:1.429 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.381 (perp=6.646, rec=0.051, cos=0.001), tot_loss_proj:1.426 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.437 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.435 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.433 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.429 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.387 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.437 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.383 (perp=6.646, rec=0.053, cos=0.001), tot_loss_proj:1.441 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.383 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.425 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.628 | p: 89.096 | r: 90.224
rouge2     | fm: 60.202 | p: 59.991 | r: 60.343
rougeL     | fm: 79.278 | p: 78.824 | r: 79.758
rougeLsum  | fm: 78.765 | p: 78.357 | r: 79.272
r1fm+r2fm = 149.829

input #25 time: 0:07:16 | total time: 3:43:56


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9992061826546763
highest_index [0]
highest [0.9992061826546763]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9740388989448547 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9654331803321838 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.959073543548584 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.9550803303718567 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9425822496414185 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.9396986365318298 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.9339746832847595 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain depending⁺ isolation [SEP]']
[Init] best rec loss: 0.8896158337593079 for ['[CLS] also space add ao intent bat intentם should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8848931789398193 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy familyם add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8846459984779358 for ['[CLS] boat huge supposed hair teaches ao rectangular deputy should bat family also addם whomness space timeline charity intent failed intent list [SEP]']
[Init] best perm rec loss: 0.8816198706626892 for ['[CLS] add also failed timeline whom list bat space hairness teaches ao familyם boat charity intent huge deputy intent supposed should rectangular [SEP]']
[Init] best perm rec loss: 0.8793452978134155 for ['[CLS] also family list supposed teaches ao bat hair space failed intentness whom huge intent add boat should rectangular deputy charityם timeline [SEP]']
[Init] best perm rec loss: 0.878869354724884 for ['[CLS] space hairם intent also timeline supposed boatness teaches should family huge whom ao list rectangular charity add failed intent bat deputy [SEP]']
[Init] best perm rec loss: 0.8787726163864136 for ['[CLS] bat rectangular intent should space timeline family alsoם failed teaches charity add boatness ao deputy supposed huge intent whom list hair [SEP]']
[Init] best perm rec loss: 0.8780877590179443 for ['[CLS] huge list add spaceם bat also family hair failed teaches boat should deputy intent supposed intent aoness charity whom timeline rectangular [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.913 (perp=13.011, rec=0.308, cos=0.003), tot_loss_proj:3.283 [t=0.19s]
prediction: ['[CLS] pointless pounds ¨bre insult wrong import june doubt fraudulent evil maybe fake flat court issued criminal wayed waste federal translit null [SEP]']
[ 100/2000] tot_loss=2.744 (perp=12.456, rec=0.249, cos=0.004), tot_loss_proj:3.147 [t=0.19s]
prediction: ['[CLS] pointless chemicals )bre messageste import ) questionable broken french dry fake of princess issued currency heading writer claim import - [SEP]']
[ 150/2000] tot_loss=2.317 (perp=10.539, rec=0.208, cos=0.002), tot_loss_proj:2.721 [t=0.19s]
prediction: ['[CLS] pointless french ) age messages of import ) poor broken french dry fake - princess issued currency undering writer french import - [SEP]']
[ 200/2000] tot_loss=2.363 (perp=10.963, rec=0.169, cos=0.001), tot_loss_proj:2.891 [t=0.19s]
prediction: ['[CLS] pointless french ) age message of import )en broken french dry bro - woman used currency height from writer writer coming - [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.319 (perp=10.798, rec=0.158, cos=0.001), tot_loss_proj:2.856 [t=0.19s]
prediction: ['[CLS] pointless french ) age bother of import )en - french dark bro age writer used agency height from writer anne coming - [SEP]']
[ 300/2000] tot_loss=2.171 (perp=10.164, rec=0.137, cos=0.001), tot_loss_proj:2.977 [t=0.19s]
prediction: ['[CLS] pointless this ) age mean of import )en - french mean age age writer used agency sophie from writer anne coming - [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.991 (perp=9.367, rec=0.116, cos=0.001), tot_loss_proj:3.216 [t=0.19s]
prediction: ['[CLS] pointless this ) age sophie of import )en - french mean age age sophie - ageder from writer anne coming - [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.984 (perp=9.409, rec=0.100, cos=0.002), tot_loss_proj:3.258 [t=0.19s]
prediction: ['[CLS] pointless this ) sophie and of import sophieing - french mean age age sophie - ageder from writer anne coming - [SEP]']
[ 450/2000] tot_loss=1.950 (perp=9.275, rec=0.093, cos=0.002), tot_loss_proj:3.092 [t=0.20s]
prediction: ['[CLS] pointless this ) sophie and of import sophieing - french mean ageder sophie - ageder from writer anne coming - [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.852 (perp=8.808, rec=0.089, cos=0.002), tot_loss_proj:2.910 [t=0.18s]
prediction: ['[CLS] pointless this )ing and of import sophie sophie - french mean ageder sophie - ageder from writer anne coming - [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.743 (perp=8.280, rec=0.085, cos=0.001), tot_loss_proj:2.791 [t=0.17s]
prediction: ['[CLS] pointless this )ing and of import sophie sophie - coming mean ageder sophie - ageder from writer anne french - [SEP]']
[ 600/2000] tot_loss=1.805 (perp=8.601, rec=0.083, cos=0.001), tot_loss_proj:2.777 [t=0.17s]
prediction: ['[CLS] pointless this )ing and of import sophie anne - coming mean ageder sophie - ageder from writer anne french - [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.743 (perp=8.299, rec=0.081, cos=0.002), tot_loss_proj:2.708 [t=0.18s]
prediction: ['[CLS] pointless this )ing and of import sophie anne mean coming - ageder sophie - ageder from writer anne french - [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.827 (perp=8.650, rec=0.096, cos=0.001), tot_loss_proj:2.904 [t=0.17s]
prediction: ['[CLS] pointless this ) and of importingrot anne mean coming - ageder sophie - ageder from writer anne french - [SEP]']
[ 750/2000] tot_loss=1.813 (perp=8.650, rec=0.082, cos=0.002), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] pointless this ) and of importingrot anne mean coming - ageder sophie - ageder from writer anne french - [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.828 (perp=8.726, rec=0.082, cos=0.001), tot_loss_proj:2.821 [t=0.17s]
prediction: ['[CLS] pointless this ) and of importing director anne mean coming - agederrot - ageder from writer - french - [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.760 (perp=8.370, rec=0.084, cos=0.002), tot_loss_proj:2.741 [t=0.18s]
prediction: ['[CLS] pointless this ) and of importing director anne mean coming - agederrot - ageder from french writer - - [SEP]']
[ 900/2000] tot_loss=1.756 (perp=8.370, rec=0.080, cos=0.002), tot_loss_proj:2.740 [t=0.19s]
prediction: ['[CLS] pointless this ) and of importing director anne mean coming - agederrot - ageder from french writer - - [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.721 (perp=8.157, rec=0.088, cos=0.002), tot_loss_proj:2.299 [t=0.20s]
prediction: ['[CLS] pointless ) and of this importing director anne mean coming - agederrot - ageder from french writer - - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.715 (perp=8.157, rec=0.082, cos=0.002), tot_loss_proj:2.298 [t=0.18s]
prediction: ['[CLS] pointless ) and of this importing director anne mean coming - agederrot - ageder from french writer - - [SEP]']
[1050/2000] tot_loss=1.712 (perp=8.157, rec=0.079, cos=0.002), tot_loss_proj:2.300 [t=0.18s]
prediction: ['[CLS] pointless ) and of this importing director anne mean coming - agederrot - ageder from french writer - - [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.664 (perp=7.943, rec=0.073, cos=0.001), tot_loss_proj:2.234 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director anne mean coming - agederrot - ageder from french - - writer [SEP]']
Attempt swap
[1150/2000] tot_loss=1.669 (perp=7.943, rec=0.079, cos=0.002), tot_loss_proj:2.230 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director anne mean coming - agederrot - ageder from french - - writer [SEP]']
[1200/2000] tot_loss=1.661 (perp=7.943, rec=0.071, cos=0.002), tot_loss_proj:2.235 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director anne mean coming - agederrot - ageder from french - - writer [SEP]']
Attempt swap
[1250/2000] tot_loss=1.661 (perp=7.943, rec=0.071, cos=0.002), tot_loss_proj:2.231 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director anne mean coming - agederrot - ageder from french - - writer [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.616 (perp=7.717, rec=0.071, cos=0.001), tot_loss_proj:2.094 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director - mean coming - agederrot - ageder from french - anne writer [SEP]']
[1350/2000] tot_loss=1.612 (perp=7.717, rec=0.067, cos=0.002), tot_loss_proj:2.089 [t=0.18s]
prediction: ['[CLS] pointless ) and of this importing director - mean coming - agederrot - ageder from french - anne writer [SEP]']
Attempt swap
[1400/2000] tot_loss=1.628 (perp=7.717, rec=0.083, cos=0.002), tot_loss_proj:2.097 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director - mean coming - agederrot - ageder from french - anne writer [SEP]']
Attempt swap
[1450/2000] tot_loss=1.618 (perp=7.717, rec=0.073, cos=0.002), tot_loss_proj:2.092 [t=0.18s]
prediction: ['[CLS] pointless ) and of this importing director - mean coming - agederrot - ageder from french - anne writer [SEP]']
[1500/2000] tot_loss=1.624 (perp=7.717, rec=0.079, cos=0.002), tot_loss_proj:2.090 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director - mean coming - agederrot - ageder from french - anne writer [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.594 (perp=7.564, rec=0.079, cos=0.001), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
Attempt swap
[1600/2000] tot_loss=1.586 (perp=7.564, rec=0.071, cos=0.002), tot_loss_proj:2.106 [t=0.18s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
[1650/2000] tot_loss=1.589 (perp=7.564, rec=0.074, cos=0.002), tot_loss_proj:2.109 [t=0.18s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
Attempt swap
[1700/2000] tot_loss=1.592 (perp=7.564, rec=0.077, cos=0.002), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
Attempt swap
[1750/2000] tot_loss=1.597 (perp=7.564, rec=0.082, cos=0.002), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
[1800/2000] tot_loss=1.589 (perp=7.564, rec=0.074, cos=0.002), tot_loss_proj:2.102 [t=0.18s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
Attempt swap
[1850/2000] tot_loss=1.586 (perp=7.564, rec=0.072, cos=0.002), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
Attempt swap
[1900/2000] tot_loss=1.591 (perp=7.564, rec=0.076, cos=0.002), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
[1950/2000] tot_loss=1.590 (perp=7.564, rec=0.076, cos=0.002), tot_loss_proj:2.106 [t=0.18s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
Attempt swap
[2000/2000] tot_loss=1.594 (perp=7.564, rec=0.080, cos=0.002), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] pointless ) and of this importing director - - mean coming agederrot - ageder from french - anne writer [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 75.000 | r: 70.588
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 36.364 | p: 37.500 | r: 35.294
rougeLsum  | fm: 36.364 | p: 37.500 | r: 35.294
r1fm+r2fm = 72.727

[Aggregate metrics]:
rouge1     | fm: 88.971 | p: 88.568 | r: 89.521
rouge2     | fm: 57.660 | p: 57.517 | r: 57.807
rougeL     | fm: 77.743 | p: 77.366 | r: 78.131
rougeLsum  | fm: 77.352 | p: 76.967 | r: 77.780
r1fm+r2fm = 146.631

input #26 time: 0:07:54 | total time: 3:51:50


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.999345236003067
highest_index [0]
highest [0.999345236003067]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9609618782997131 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9331122636795044 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9077965617179871 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.8589619994163513 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8030321598052979 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.8014320135116577 for ['[CLS] transit givenwine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.567 (perp=13.685, rec=0.812, cos=0.018), tot_loss_proj:4.559 [t=0.17s]
prediction: ['[CLS] katrina provided shakes [SEP]']
[ 100/2000] tot_loss=3.426 (perp=13.123, rec=0.761, cos=0.040), tot_loss_proj:4.510 [t=0.17s]
prediction: ['[CLS]cablerri lawn [SEP]']
[ 150/2000] tot_loss=2.739 (perp=10.328, rec=0.660, cos=0.014), tot_loss_proj:2.614 [t=0.17s]
prediction: ['[CLS] yer " generic [SEP]']
[ 200/2000] tot_loss=2.459 (perp=9.153, rec=0.620, cos=0.009), tot_loss_proj:2.337 [t=0.17s]
prediction: ['[CLS] generic " generic [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.748 (perp=10.501, rec=0.642, cos=0.005), tot_loss_proj:2.601 [t=0.17s]
prediction: ['[CLS] generic generic are [SEP]']
[ 300/2000] tot_loss=2.694 (perp=10.501, rec=0.591, cos=0.002), tot_loss_proj:2.604 [t=0.17s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.701 (perp=10.501, rec=0.579, cos=0.022), tot_loss_proj:2.603 [t=0.17s]
prediction: ['[CLS] generic generic are [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.837 (perp=11.001, rec=0.628, cos=0.009), tot_loss_proj:2.770 [t=0.17s]
prediction: ['[CLS] are generic kenton [SEP]']
[ 450/2000] tot_loss=2.507 (perp=9.509, rec=0.596, cos=0.009), tot_loss_proj:2.334 [t=0.19s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.479 (perp=9.509, rec=0.573, cos=0.004), tot_loss_proj:2.337 [t=0.17s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.459 (perp=9.509, rec=0.555, cos=0.002), tot_loss_proj:2.331 [t=0.17s]
prediction: ['[CLS] are generic generic [SEP]']
[ 600/2000] tot_loss=2.452 (perp=9.509, rec=0.544, cos=0.006), tot_loss_proj:2.326 [t=0.17s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.460 (perp=9.509, rec=0.552, cos=0.006), tot_loss_proj:2.328 [t=0.17s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.439 (perp=9.509, rec=0.534, cos=0.003), tot_loss_proj:2.331 [t=0.17s]
prediction: ['[CLS] are generic generic [SEP]']
[ 750/2000] tot_loss=2.470 (perp=9.509, rec=0.564, cos=0.004), tot_loss_proj:2.339 [t=0.17s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.435 (perp=9.509, rec=0.532, cos=0.001), tot_loss_proj:2.332 [t=0.17s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.426 (perp=9.509, rec=0.521, cos=0.004), tot_loss_proj:2.336 [t=0.17s]
prediction: ['[CLS] are generic generic [SEP]']
[ 900/2000] tot_loss=2.422 (perp=9.509, rec=0.518, cos=0.002), tot_loss_proj:2.335 [t=0.17s]
prediction: ['[CLS] are generic generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.550 (perp=10.088, rec=0.530, cos=0.003), tot_loss_proj:2.387 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1000/2000] tot_loss=2.540 (perp=10.088, rec=0.516, cos=0.007), tot_loss_proj:2.390 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
[1050/2000] tot_loss=2.530 (perp=10.088, rec=0.511, cos=0.002), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1100/2000] tot_loss=2.523 (perp=10.088, rec=0.504, cos=0.001), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1150/2000] tot_loss=2.545 (perp=10.088, rec=0.515, cos=0.013), tot_loss_proj:2.386 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
[1200/2000] tot_loss=2.527 (perp=10.088, rec=0.508, cos=0.002), tot_loss_proj:2.397 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1250/2000] tot_loss=2.524 (perp=10.088, rec=0.505, cos=0.001), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1300/2000] tot_loss=2.541 (perp=10.088, rec=0.503, cos=0.020), tot_loss_proj:2.396 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
[1350/2000] tot_loss=2.528 (perp=10.088, rec=0.509, cos=0.002), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1400/2000] tot_loss=2.525 (perp=10.088, rec=0.505, cos=0.002), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1450/2000] tot_loss=2.517 (perp=10.088, rec=0.498, cos=0.002), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
[1500/2000] tot_loss=2.514 (perp=10.088, rec=0.495, cos=0.001), tot_loss_proj:2.398 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1550/2000] tot_loss=2.518 (perp=10.088, rec=0.499, cos=0.002), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1600/2000] tot_loss=2.516 (perp=10.088, rec=0.497, cos=0.002), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
[1650/2000] tot_loss=2.511 (perp=10.088, rec=0.492, cos=0.002), tot_loss_proj:2.396 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1700/2000] tot_loss=2.516 (perp=10.088, rec=0.498, cos=0.001), tot_loss_proj:2.397 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1750/2000] tot_loss=2.525 (perp=10.088, rec=0.506, cos=0.001), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
[1800/2000] tot_loss=2.522 (perp=10.088, rec=0.503, cos=0.001), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1850/2000] tot_loss=2.517 (perp=10.088, rec=0.498, cos=0.001), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[1900/2000] tot_loss=2.518 (perp=10.088, rec=0.499, cos=0.001), tot_loss_proj:2.390 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
[1950/2000] tot_loss=2.519 (perp=10.088, rec=0.500, cos=0.001), tot_loss_proj:2.397 [t=0.17s]
prediction: ['[CLS] so generic generic [SEP]']
Attempt swap
[2000/2000] tot_loss=2.515 (perp=10.088, rec=0.496, cos=0.001), tot_loss_proj:2.393 [t=0.19s]
prediction: ['[CLS] so generic generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] so generic generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 88.727 | p: 88.352 | r: 89.169
rouge2     | fm: 56.912 | p: 56.814 | r: 57.112
rougeL     | fm: 77.705 | p: 77.426 | r: 78.103
rougeLsum  | fm: 77.483 | p: 77.137 | r: 77.880
r1fm+r2fm = 145.639

input #27 time: 0:07:57 | total time: 3:59:47


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9993345319062628
highest_index [0]
highest [0.9993345319062628]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8165134787559509 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7931988835334778 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7827070355415344 for ['[CLS] james facilitieslty ¨ [SEP]']
[Init] best rec loss: 0.7524273991584778 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best rec loss: 0.7502107620239258 for ['[CLS]vron sex guessed morgan [SEP]']
[Init] best perm rec loss: 0.7490264177322388 for ['[CLS] guessed morganvron sex [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.124 (perp=9.036, rec=0.308, cos=0.009), tot_loss_proj:2.997 [t=0.17s]
prediction: ['[CLS] s for minutes longest [SEP]']
[ 100/2000] tot_loss=1.812 (perp=8.319, rec=0.145, cos=0.003), tot_loss_proj:2.358 [t=0.17s]
prediction: ['[CLS] only for minutes 8 [SEP]']
[ 150/2000] tot_loss=1.901 (perp=9.045, rec=0.090, cos=0.002), tot_loss_proj:2.509 [t=0.17s]
prediction: ['[CLS] only for minutes 71 [SEP]']
[ 200/2000] tot_loss=1.898 (perp=9.045, rec=0.087, cos=0.001), tot_loss_proj:2.508 [t=0.17s]
prediction: ['[CLS] only for minutes 71 [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.656 (perp=7.912, rec=0.073, cos=0.001), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] only for 71 minutes [SEP]']
[ 300/2000] tot_loss=1.652 (perp=7.912, rec=0.068, cos=0.001), tot_loss_proj:1.950 [t=0.17s]
prediction: ['[CLS] only for 71 minutes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.615 (perp=7.699, rec=0.074, cos=0.001), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.604 (perp=7.699, rec=0.063, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.606 (perp=7.699, rec=0.066, cos=0.001), tot_loss_proj:1.630 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.607 (perp=7.699, rec=0.066, cos=0.001), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.603 (perp=7.699, rec=0.062, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.597 (perp=7.699, rec=0.057, cos=0.001), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.595 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.596 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.606 (perp=7.699, rec=0.065, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.595 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.603 (perp=7.699, rec=0.062, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.592 (perp=7.699, rec=0.051, cos=0.001), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.604 (perp=7.699, rec=0.063, cos=0.001), tot_loss_proj:1.625 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.621 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.598 (perp=7.699, rec=0.057, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.637 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.607 (perp=7.699, rec=0.066, cos=0.001), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.621 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.602 (perp=7.699, rec=0.061, cos=0.001), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.602 (perp=7.699, rec=0.061, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.602 (perp=7.699, rec=0.061, cos=0.001), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.606 (perp=7.699, rec=0.065, cos=0.001), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.699, rec=0.052, cos=0.001), tot_loss_proj:1.631 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.604 (perp=7.699, rec=0.063, cos=0.001), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.611 (perp=7.699, rec=0.070, cos=0.001), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.594 (perp=7.699, rec=0.053, cos=0.001), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.598 (perp=7.699, rec=0.057, cos=0.001), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.632 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.610 (perp=7.699, rec=0.069, cos=0.001), tot_loss_proj:1.628 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.603 (perp=7.699, rec=0.062, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.021 | p: 88.629 | r: 89.559
rouge2     | fm: 58.795 | p: 58.673 | r: 58.892
rougeL     | fm: 78.442 | p: 78.089 | r: 78.881
rougeLsum  | fm: 78.157 | p: 77.777 | r: 78.632
r1fm+r2fm = 147.815

input #28 time: 0:07:50 | total time: 4:07:38


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9992943703711437
highest_index [0]
highest [0.9992943703711437]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9436143040657043 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9236282706260681 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.9098904132843018 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8565943837165833 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8468968868255615 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8464521765708923 for ['[CLS] lordship buckingham rather postsbor we home wildlife valleygan [SEP]']
[Init] best rec loss: 0.844285249710083 for ['[CLS] downke his heir wantedø degree opposition march head [SEP]']
[Init] best rec loss: 0.8212891221046448 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.8188213109970093 for ['[CLS] type attack www estate ambulance + chelsealand out todd [SEP]']
[Init] best rec loss: 0.8150292038917542 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 0.8131462931632996 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 0.8110625147819519 for ['[CLS] tv oil envelope administration taste this engagementuted runs landed [SEP]']
[Init] best perm rec loss: 0.8109373450279236 for ['[CLS] runs administration tv oil this taste landed engagement envelopeuted [SEP]']
[Init] best perm rec loss: 0.8048712015151978 for ['[CLS] taste landed tv this engagementuted runs oil administration envelope [SEP]']
[Init] best perm rec loss: 0.8036940097808838 for ['[CLS] runs taste engagementuted envelope oil this tv landed administration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.542 (perp=10.682, rec=0.401, cos=0.004), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS] what. settlement scientology released facts indefinitely under caused limits [SEP]']
[ 100/2000] tot_loss=2.806 (perp=12.342, rec=0.334, cos=0.003), tot_loss_proj:3.624 [t=0.17s]
prediction: ['[CLS].... toni scientology poisoning dali for under settlement authorities [SEP]']
[ 150/2000] tot_loss=2.266 (perp=9.919, rec=0.279, cos=0.003), tot_loss_proj:3.010 [t=0.17s]
prediction: ['[CLS].... resign costume is believe it under generally not [SEP]']
[ 200/2000] tot_loss=2.203 (perp=9.909, rec=0.218, cos=0.003), tot_loss_proj:3.038 [t=0.17s]
prediction: ['[CLS]... also believe resident is evil it the owns not [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.623 (perp=7.185, rec=0.183, cos=0.003), tot_loss_proj:2.376 [t=0.17s]
prediction: ['[CLS] mono also believe resident evil is it that is not [SEP]']
[ 300/2000] tot_loss=1.584 (perp=7.185, rec=0.145, cos=0.002), tot_loss_proj:2.373 [t=0.17s]
prediction: ['[CLS] mono also believe resident evil is it that is not [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.463 (perp=6.638, rec=0.134, cos=0.001), tot_loss_proj:2.205 [t=0.17s]
prediction: ['[CLS] mono also believe resident evil is that it is not [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.147 (perp=5.127, rec=0.120, cos=0.001), tot_loss_proj:2.256 [t=0.17s]
prediction: ['[CLS] i also believe resident evil is that it is not [SEP]']
[ 450/2000] tot_loss=1.139 (perp=5.127, rec=0.112, cos=0.001), tot_loss_proj:2.260 [t=0.17s]
prediction: ['[CLS] i also believe resident evil is that it is not [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.334 (perp=6.102, rec=0.112, cos=0.002), tot_loss_proj:3.026 [t=0.17s]
prediction: ['[CLS] i also believe resident evil is that it if not [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.282 (perp=5.842, rec=0.112, cos=0.002), tot_loss_proj:1.931 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is it because not [SEP]']
[ 600/2000] tot_loss=1.267 (perp=5.842, rec=0.097, cos=0.001), tot_loss_proj:1.928 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is it because not [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.140 (perp=5.253, rec=0.088, cos=0.001), tot_loss_proj:1.381 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it because [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.141 (perp=5.253, rec=0.089, cos=0.001), tot_loss_proj:1.385 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it because [SEP]']
[ 750/2000] tot_loss=1.128 (perp=5.253, rec=0.076, cos=0.001), tot_loss_proj:1.377 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it because [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.129 (perp=5.253, rec=0.077, cos=0.001), tot_loss_proj:1.379 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil is not it because [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.996 (perp=4.570, rec=0.080, cos=0.001), tot_loss_proj:1.070 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[ 900/2000] tot_loss=0.997 (perp=4.570, rec=0.082, cos=0.001), tot_loss_proj:1.063 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.986 (perp=4.570, rec=0.070, cos=0.001), tot_loss_proj:1.066 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1000/2000] tot_loss=0.992 (perp=4.570, rec=0.077, cos=0.001), tot_loss_proj:1.060 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1050/2000] tot_loss=0.989 (perp=4.570, rec=0.073, cos=0.001), tot_loss_proj:1.062 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.984 (perp=4.570, rec=0.069, cos=0.001), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.990 (perp=4.570, rec=0.074, cos=0.001), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1200/2000] tot_loss=0.983 (perp=4.570, rec=0.067, cos=0.001), tot_loss_proj:1.066 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.983 (perp=4.570, rec=0.067, cos=0.001), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1300/2000] tot_loss=0.972 (perp=4.570, rec=0.057, cos=0.001), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1350/2000] tot_loss=0.981 (perp=4.570, rec=0.066, cos=0.001), tot_loss_proj:1.057 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.983 (perp=4.570, rec=0.067, cos=0.001), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.977 (perp=4.570, rec=0.062, cos=0.001), tot_loss_proj:1.066 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1500/2000] tot_loss=0.974 (perp=4.570, rec=0.059, cos=0.001), tot_loss_proj:1.061 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.985 (perp=4.570, rec=0.070, cos=0.001), tot_loss_proj:1.053 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1600/2000] tot_loss=0.992 (perp=4.570, rec=0.077, cos=0.001), tot_loss_proj:1.062 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1650/2000] tot_loss=0.985 (perp=4.570, rec=0.070, cos=0.001), tot_loss_proj:1.073 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.987 (perp=4.570, rec=0.072, cos=0.001), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.981 (perp=4.570, rec=0.066, cos=0.001), tot_loss_proj:1.061 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1800/2000] tot_loss=0.988 (perp=4.570, rec=0.072, cos=0.001), tot_loss_proj:1.070 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.993 (perp=4.570, rec=0.078, cos=0.001), tot_loss_proj:1.051 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[1900/2000] tot_loss=0.982 (perp=4.570, rec=0.066, cos=0.001), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
[1950/2000] tot_loss=0.985 (perp=4.570, rec=0.070, cos=0.001), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.981 (perp=4.570, rec=0.066, cos=0.001), tot_loss_proj:1.062 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil is not it. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.311 | p: 88.911 | r: 89.786
rouge2     | fm: 60.037 | p: 59.931 | r: 60.206
rougeL     | fm: 79.230 | p: 78.955 | r: 79.608
rougeLsum  | fm: 78.959 | p: 78.570 | r: 79.295
r1fm+r2fm = 149.348

input #29 time: 0:07:54 | total time: 4:15:32


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.999272099459075
highest_index [0]
highest [0.999272099459075]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.9139088988304138 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8701140880584717 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8681485652923584 for ['[CLS] superior vary lynne [SEP]']
[Init] best rec loss: 0.8041428923606873 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7869581580162048 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7338038682937622 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7189111113548279 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 0.7150062918663025 for ['[CLS] lizard acceleration council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.519 (perp=10.941, rec=0.325, cos=0.006), tot_loss_proj:3.975 [t=0.17s]
prediction: ['[CLS] estate chassis list [SEP]']
[ 100/2000] tot_loss=2.742 (perp=12.475, rec=0.241, cos=0.006), tot_loss_proj:3.546 [t=0.18s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 150/2000] tot_loss=2.659 (perp=12.475, rec=0.161, cos=0.003), tot_loss_proj:3.554 [t=0.17s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 200/2000] tot_loss=2.625 (perp=12.475, rec=0.128, cos=0.002), tot_loss_proj:3.578 [t=0.17s]
prediction: ['[CLS]zzabilitybility [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.026 (perp=9.540, rec=0.115, cos=0.002), tot_loss_proj:1.980 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.990 (perp=9.540, rec=0.081, cos=0.001), tot_loss_proj:1.971 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.973 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.981 (perp=9.540, rec=0.072, cos=0.001), tot_loss_proj:1.980 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.969 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.983 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.982 (perp=9.540, rec=0.073, cos=0.001), tot_loss_proj:1.991 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.964 (perp=9.540, rec=0.055, cos=0.001), tot_loss_proj:1.979 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.979 (perp=9.540, rec=0.070, cos=0.001), tot_loss_proj:1.981 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.980 (perp=9.540, rec=0.070, cos=0.001), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.957 (perp=9.540, rec=0.048, cos=0.001), tot_loss_proj:1.997 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.963 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.989 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.967 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.986 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.983 (perp=9.540, rec=0.074, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.988 (perp=9.540, rec=0.079, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.971 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.962 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.987 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.969 (perp=9.540, rec=0.060, cos=0.001), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.975 (perp=9.540, rec=0.066, cos=0.001), tot_loss_proj:1.967 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.960 (perp=9.540, rec=0.050, cos=0.001), tot_loss_proj:1.986 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.965 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.974 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.977 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.974 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.974 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.964 (perp=9.540, rec=0.055, cos=0.001), tot_loss_proj:1.984 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.974 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.962 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.969 (perp=9.540, rec=0.060, cos=0.001), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.974 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.981 (perp=9.540, rec=0.071, cos=0.001), tot_loss_proj:1.987 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.957 (perp=9.540, rec=0.048, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.963 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.979 (perp=9.540, rec=0.070, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.778 | p: 89.424 | r: 90.262
rouge2     | fm: 61.373 | p: 61.271 | r: 61.433
rougeL     | fm: 79.746 | p: 79.485 | r: 80.095
rougeLsum  | fm: 79.592 | p: 79.308 | r: 79.941
r1fm+r2fm = 151.150

input #30 time: 0:08:06 | total time: 4:23:38


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.999339325216174
highest_index [0]
highest [0.999339325216174]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9432398676872253 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.920174777507782 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8837398290634155 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.8651828765869141 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8041785955429077 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8038828372955322 for ['[CLS] robin running artwork [SEP]']
[Init] best perm rec loss: 0.8038730621337891 for ['[CLS] artwork running robin [SEP]']
[Init] best perm rec loss: 0.7982505559921265 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.423 (perp=10.371, rec=0.336, cos=0.012), tot_loss_proj:3.209 [t=0.17s]
prediction: ['[CLS] better creditneuve [SEP]']
[ 100/2000] tot_loss=2.132 (perp=9.658, rec=0.196, cos=0.005), tot_loss_proj:2.401 [t=0.17s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=1.854 (perp=8.742, rec=0.104, cos=0.002), tot_loss_proj:3.285 [t=0.17s]
prediction: ['[CLS] better a vehicle [SEP]']
[ 200/2000] tot_loss=1.824 (perp=8.742, rec=0.072, cos=0.003), tot_loss_proj:3.289 [t=0.17s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.591 (perp=7.603, rec=0.068, cos=0.002), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.596 (perp=7.603, rec=0.075, cos=0.001), tot_loss_proj:1.684 [t=0.20s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.587 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.670 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.591 (perp=7.603, rec=0.070, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.589 (perp=7.603, rec=0.068, cos=0.001), tot_loss_proj:1.687 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.574 (perp=7.603, rec=0.052, cos=0.001), tot_loss_proj:1.674 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.692 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.685 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.594 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.676 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.580 (perp=7.603, rec=0.058, cos=0.001), tot_loss_proj:1.670 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.579 (perp=7.603, rec=0.058, cos=0.001), tot_loss_proj:1.677 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.578 (perp=7.603, rec=0.056, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.578 (perp=7.603, rec=0.056, cos=0.001), tot_loss_proj:1.674 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.673 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.581 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.676 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.592 (perp=7.603, rec=0.070, cos=0.001), tot_loss_proj:1.676 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.579 (perp=7.603, rec=0.058, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.585 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.670 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.685 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.593 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.577 (perp=7.603, rec=0.056, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.592 (perp=7.603, rec=0.070, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.574 (perp=7.603, rec=0.052, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.677 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.194 | p: 89.839 | r: 90.609
rouge2     | fm: 62.677 | p: 62.576 | r: 62.814
rougeL     | fm: 80.579 | p: 80.277 | r: 80.876
rougeLsum  | fm: 80.402 | p: 80.101 | r: 80.706
r1fm+r2fm = 152.871

input #31 time: 0:07:26 | total time: 4:31:05


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9992521630934186
highest_index [0]
highest [0.9992521630934186]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0409706830978394 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9490888714790344 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8853940367698669 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8810258507728577 for ['[CLS]le force cheers discarded replicateباد clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.8623101115226746 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8531050086021423 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.8450931906700134 for ['[CLS] palaceshire athletic th funds lilith bio circlecting thomas cake natalie [SEP]']
[Init] best perm rec loss: 0.8438608646392822 for ['[CLS] athletic palace th thomasshire bio cake circle lilith fundscting natalie [SEP]']
[Init] best perm rec loss: 0.842842161655426 for ['[CLS] cake funds lilith athletic thshire biocting natalie palace circle thomas [SEP]']
[Init] best perm rec loss: 0.8413686156272888 for ['[CLS] th natalie circlecting thomas funds bio lilith palace cakeshire athletic [SEP]']
[Init] best perm rec loss: 0.8397578001022339 for ['[CLS]cting lilith thomas cake bio athleticshire natalie th circle palace funds [SEP]']
[Init] best perm rec loss: 0.8387935161590576 for ['[CLS] cakecting natalie bio lilith athletic th thomas circle palaceshire funds [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.843 (perp=12.790, rec=0.280, cos=0.004), tot_loss_proj:3.178 [t=0.17s]
prediction: ['[CLS] valuedvable story stories spirit ; diverse ellen create sunlight deeply funds [SEP]']
[ 100/2000] tot_loss=2.385 (perp=10.892, rec=0.204, cos=0.003), tot_loss_proj:2.995 [t=0.17s]
prediction: ['[CLS] easily accessible stories stories together ; easily frank pullonate easilyonate [SEP]']
[ 150/2000] tot_loss=2.366 (perp=10.952, rec=0.173, cos=0.002), tot_loss_proj:3.906 [t=0.17s]
prediction: ['[CLS] easily accessible stories stories together into easily potentially pullonateundity [SEP]']
[ 200/2000] tot_loss=2.191 (perp=10.287, rec=0.132, cos=0.002), tot_loss_proj:3.535 [t=0.17s]
prediction: ['[CLS] easily accessible stories stories together with accessible slightly pullonateundity [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.055 (perp=9.713, rec=0.111, cos=0.001), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] easily accessible stories stories together that slightly pull resonateundity [SEP]']
[ 300/2000] tot_loss=2.076 (perp=9.927, rec=0.089, cos=0.001), tot_loss_proj:2.588 [t=0.17s]
prediction: ['[CLS] easily accessible stories stories together that prof pull resonateundity [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.800 (perp=8.502, rec=0.098, cos=0.001), tot_loss_proj:2.025 [t=0.17s]
prediction: ['[CLS] easily accessible stories stories together that pull resonate profundity [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.525 (perp=7.163, rec=0.092, cos=0.001), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS] easily accessible stories stories that pull together resonate profundity [SEP]']
[ 450/2000] tot_loss=1.535 (perp=7.163, rec=0.099, cos=0.003), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS] easily accessible stories stories that pull together resonate profundity [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.455 (perp=6.812, rec=0.092, cos=0.001), tot_loss_proj:1.673 [t=0.29s]
prediction: ['[CLS] easily accessible stories that pull stories together resonate profundity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.445 (perp=6.812, rec=0.081, cos=0.001), tot_loss_proj:1.671 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull stories together resonate profundity [SEP]']
[ 600/2000] tot_loss=1.437 (perp=6.812, rec=0.073, cos=0.001), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull stories together resonate profundity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.533 (perp=7.286, rec=0.074, cos=0.001), tot_loss_proj:1.792 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull with together resonate profundity [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.307 (perp=6.185, rec=0.068, cos=0.001), tot_loss_proj:1.551 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
[ 750/2000] tot_loss=1.305 (perp=6.185, rec=0.066, cos=0.001), tot_loss_proj:1.552 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.305 (perp=6.185, rec=0.067, cos=0.001), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.309 (perp=6.185, rec=0.071, cos=0.001), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
[ 900/2000] tot_loss=1.297 (perp=6.185, rec=0.059, cos=0.001), tot_loss_proj:1.556 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.300 (perp=6.185, rec=0.061, cos=0.001), tot_loss_proj:1.555 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.305 (perp=6.185, rec=0.067, cos=0.001), tot_loss_proj:1.559 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
[1050/2000] tot_loss=1.306 (perp=6.185, rec=0.068, cos=0.001), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.302 (perp=6.185, rec=0.064, cos=0.001), tot_loss_proj:1.563 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.304 (perp=6.185, rec=0.065, cos=0.001), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
[1200/2000] tot_loss=1.303 (perp=6.185, rec=0.064, cos=0.001), tot_loss_proj:1.555 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.305 (perp=6.185, rec=0.066, cos=0.001), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.308 (perp=6.185, rec=0.070, cos=0.001), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
[1350/2000] tot_loss=1.304 (perp=6.185, rec=0.065, cos=0.001), tot_loss_proj:1.553 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.304 (perp=6.185, rec=0.066, cos=0.001), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.296 (perp=6.185, rec=0.058, cos=0.001), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
[1500/2000] tot_loss=1.311 (perp=6.185, rec=0.072, cos=0.001), tot_loss_proj:1.552 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.315 (perp=6.185, rec=0.077, cos=0.001), tot_loss_proj:1.549 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.302 (perp=6.185, rec=0.063, cos=0.001), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
[1650/2000] tot_loss=1.297 (perp=6.185, rec=0.058, cos=0.001), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.297 (perp=6.185, rec=0.058, cos=0.001), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.310 (perp=6.185, rec=0.071, cos=0.001), tot_loss_proj:1.546 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
[1800/2000] tot_loss=1.303 (perp=6.185, rec=0.064, cos=0.001), tot_loss_proj:1.560 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.304 (perp=6.185, rec=0.066, cos=0.001), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.304 (perp=6.185, rec=0.065, cos=0.001), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
[1950/2000] tot_loss=1.297 (perp=6.185, rec=0.059, cos=0.001), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.299 (perp=6.185, rec=0.060, cos=0.001), tot_loss_proj:1.555 [t=0.17s]
prediction: ['[CLS] easily accessible stories that pull together resonate with profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] easily accessible stories that pull together resonate with profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 81.818 | p: 81.818 | r: 81.818
rougeLsum  | fm: 81.818 | p: 81.818 | r: 81.818
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 90.280 | p: 89.957 | r: 90.723
rouge2     | fm: 62.769 | p: 62.661 | r: 62.879
rougeL     | fm: 80.529 | p: 80.262 | r: 80.926
rougeLsum  | fm: 80.476 | p: 80.195 | r: 80.809
r1fm+r2fm = 153.049

input #32 time: 0:07:18 | total time: 4:38:24


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9992763851579931
highest_index [0]
highest [0.9992763851579931]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9998520612716675 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9732957482337952 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.9511236548423767 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.9041293859481812 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8212264180183411 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7986159920692444 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.7904055118560791 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.543 (perp=11.231, rec=0.278, cos=0.019), tot_loss_proj:3.025 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.327 (perp=11.231, rec=0.079, cos=0.002), tot_loss_proj:2.449 [t=0.20s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.303 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.403 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.396 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.408 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.420 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.295 (perp=11.231, rec=0.048, cos=0.001), tot_loss_proj:2.408 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.299 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.406 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.299 (perp=11.231, rec=0.051, cos=0.001), tot_loss_proj:2.407 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.302 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.291 (perp=11.231, rec=0.043, cos=0.001), tot_loss_proj:2.405 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.311 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.400 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.314 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.403 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.295 (perp=11.231, rec=0.047, cos=0.001), tot_loss_proj:2.407 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.306 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.298 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.302 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.405 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.399 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.394 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.298 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.411 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.400 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.301 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.406 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.310 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.396 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.296 (perp=11.231, rec=0.048, cos=0.001), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.305 (perp=11.231, rec=0.058, cos=0.001), tot_loss_proj:2.398 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.314 (perp=11.231, rec=0.067, cos=0.001), tot_loss_proj:2.400 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.294 (perp=11.231, rec=0.046, cos=0.001), tot_loss_proj:2.404 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.303 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.402 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.302 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.414 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.295 (perp=11.231, rec=0.047, cos=0.001), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.322 (perp=11.231, rec=0.075, cos=0.001), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.670 | p: 90.347 | r: 91.019
rouge2     | fm: 64.029 | p: 63.941 | r: 64.139
rougeL     | fm: 81.202 | p: 80.908 | r: 81.530
rougeLsum  | fm: 80.946 | p: 80.656 | r: 81.378
r1fm+r2fm = 154.698

input #33 time: 0:07:28 | total time: 4:45:52


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9992091879502123
highest_index [0]
highest [0.9992091879502123]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8935192823410034 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8888072967529297 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8439813256263733 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8383127450942993 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.813098132610321 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.8127062320709229 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.8103282451629639 for ['[CLS] who slightask founderibe field lissa along ship drivers statue worth okay [SEP]']
[Init] best perm rec loss: 0.8098567128181458 for ['[CLS] field slight who statueibe founder lissa shipask drivers okay along worth [SEP]']
[Init] best perm rec loss: 0.808777928352356 for ['[CLS] okayibe statueask slight founder along drivers field worth ship who lissa [SEP]']
[Init] best perm rec loss: 0.8087007999420166 for ['[CLS] okay field ship slight alongask statue lissa founder worth driversibe who [SEP]']
[Init] best perm rec loss: 0.8083059787750244 for ['[CLS] who along lissa ship statue okay slight field driversibe worth founderask [SEP]']
[Init] best perm rec loss: 0.8071286082267761 for ['[CLS] worth founder drivers okay along ship lissa field whoask statueibe slight [SEP]']
[Init] best perm rec loss: 0.8067096471786499 for ['[CLS] founder worth okayaskibe lissa who statue along drivers ship slight field [SEP]']
[Init] best perm rec loss: 0.8060021996498108 for ['[CLS] slight founder fieldaskibe okay lissa ship statue who worth along drivers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.704 (perp=11.579, rec=0.378, cos=0.011), tot_loss_proj:3.802 [t=0.18s]
prediction: ['[CLS] volume libretto transform viewers wales itpot expand hazardous, awarded the locomotives [SEP]']
[ 100/2000] tot_loss=2.578 (perp=11.544, rec=0.266, cos=0.004), tot_loss_proj:3.940 [t=0.19s]
prediction: ['[CLS] urgency viewer transform viewer urgency of unlimited build hazardous urgencyu the urgency [SEP]']
[ 150/2000] tot_loss=2.316 (perp=10.542, rec=0.206, cos=0.002), tot_loss_proj:3.451 [t=0.19s]
prediction: ['[CLS] urgency viewer extreme viewer urgency ofpot build extreme urgency and and urgency [SEP]']
[ 200/2000] tot_loss=2.272 (perp=10.467, rec=0.177, cos=0.001), tot_loss_proj:3.645 [t=0.19s]
prediction: ['[CLS] urgency viewer extreme viewer urgency ofpot build extreme urgency of. extreme [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.106 (perp=9.757, rec=0.153, cos=0.002), tot_loss_proj:3.396 [t=0.17s]
prediction: ['[CLS] urgency viewer extreme viewer urgency inpot build extreme urgency in extreme. [SEP]']
[ 300/2000] tot_loss=2.157 (perp=10.075, rec=0.140, cos=0.002), tot_loss_proj:3.361 [t=0.17s]
prediction: ['[CLS] urgency viewer extreme viewer urgency insing build extreme urgency in extreme. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.774 (perp=8.159, rec=0.141, cos=0.002), tot_loss_proj:2.921 [t=0.17s]
prediction: ['[CLS] urgency by extreme viewer urgency of buildsing extreme urgency in extreme. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.787 (perp=8.197, rec=0.146, cos=0.002), tot_loss_proj:3.307 [t=0.17s]
prediction: ['[CLS] extreme urgency by viewer urgency the build whether extreme urgency and extreme. [SEP]']
[ 450/2000] tot_loss=1.743 (perp=8.077, rec=0.126, cos=0.002), tot_loss_proj:3.262 [t=0.17s]
prediction: ['[CLS] extreme urgency by viewer mind the build whether extreme urgency and extreme. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.625 (perp=7.491, rec=0.125, cos=0.002), tot_loss_proj:3.166 [t=0.17s]
prediction: ['[CLS] extreme urgency in the mind viewer build whether extreme urgency and extreme. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.732 (perp=7.923, rec=0.145, cos=0.003), tot_loss_proj:3.358 [t=0.17s]
prediction: ['[CLS] extreme urgency in of extreme viewer build whether extreme urgency and mind. [SEP]']
[ 600/2000] tot_loss=1.586 (perp=7.335, rec=0.118, cos=0.001), tot_loss_proj:2.724 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer build for take urgency and mind. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.524 (perp=6.996, rec=0.123, cos=0.002), tot_loss_proj:2.694 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take build for urgency and mind. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.523 (perp=6.996, rec=0.122, cos=0.002), tot_loss_proj:2.685 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take build for urgency and mind. [SEP]']
[ 750/2000] tot_loss=1.513 (perp=6.996, rec=0.113, cos=0.002), tot_loss_proj:2.688 [t=0.19s]
prediction: ['[CLS] extreme urgency in the extreme viewer take build for urgency and mind. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.457 (perp=6.763, rec=0.103, cos=0.001), tot_loss_proj:2.593 [t=0.19s]
prediction: ['[CLS] extreme urgency in the extreme viewer take build for mind and urgency. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.396 (perp=6.519, rec=0.091, cos=0.001), tot_loss_proj:2.363 [t=0.19s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
[ 900/2000] tot_loss=1.404 (perp=6.519, rec=0.099, cos=0.002), tot_loss_proj:2.364 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.391 (perp=6.519, rec=0.086, cos=0.002), tot_loss_proj:2.366 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.401 (perp=6.519, rec=0.096, cos=0.002), tot_loss_proj:2.361 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
[1050/2000] tot_loss=1.388 (perp=6.519, rec=0.083, cos=0.002), tot_loss_proj:2.363 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.392 (perp=6.519, rec=0.087, cos=0.002), tot_loss_proj:2.363 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.382 (perp=6.519, rec=0.076, cos=0.002), tot_loss_proj:2.368 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
[1200/2000] tot_loss=1.390 (perp=6.519, rec=0.085, cos=0.002), tot_loss_proj:2.363 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.386 (perp=6.519, rec=0.081, cos=0.002), tot_loss_proj:2.373 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.390 (perp=6.519, rec=0.084, cos=0.002), tot_loss_proj:2.365 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
[1350/2000] tot_loss=1.395 (perp=6.519, rec=0.090, cos=0.002), tot_loss_proj:2.361 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.390 (perp=6.519, rec=0.085, cos=0.002), tot_loss_proj:2.370 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.395 (perp=6.519, rec=0.090, cos=0.002), tot_loss_proj:2.361 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
[1500/2000] tot_loss=1.389 (perp=6.519, rec=0.084, cos=0.002), tot_loss_proj:2.372 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.386 (perp=6.519, rec=0.080, cos=0.002), tot_loss_proj:2.375 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.389 (perp=6.519, rec=0.083, cos=0.002), tot_loss_proj:2.368 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
[1650/2000] tot_loss=1.384 (perp=6.519, rec=0.078, cos=0.002), tot_loss_proj:2.372 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.398 (perp=6.519, rec=0.093, cos=0.002), tot_loss_proj:2.366 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.389 (perp=6.519, rec=0.083, cos=0.002), tot_loss_proj:2.367 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
[1800/2000] tot_loss=1.390 (perp=6.519, rec=0.084, cos=0.002), tot_loss_proj:2.370 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.394 (perp=6.519, rec=0.089, cos=0.002), tot_loss_proj:2.366 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.386 (perp=6.519, rec=0.081, cos=0.002), tot_loss_proj:2.365 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
[1950/2000] tot_loss=1.389 (perp=6.519, rec=0.084, cos=0.002), tot_loss_proj:2.369 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.385 (perp=6.519, rec=0.079, cos=0.002), tot_loss_proj:2.372 [t=0.17s]
prediction: ['[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] extreme urgency in the extreme viewer take for mind and build urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 78.571 | r: 78.571
rouge2     | fm: 23.077 | p: 23.077 | r: 23.077
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 101.648

[Aggregate metrics]:
rouge1     | fm: 90.301 | p: 90.004 | r: 90.679
rouge2     | fm: 62.734 | p: 62.648 | r: 62.847
rougeL     | fm: 80.338 | p: 80.038 | r: 80.662
rougeLsum  | fm: 80.117 | p: 79.879 | r: 80.512
r1fm+r2fm = 153.035

input #34 time: 0:07:23 | total time: 4:53:15


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9993278544896083
highest_index [0]
highest [0.9993278544896083]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9250960350036621 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.9220249056816101 for ['[CLS] nightstand locality shall shifted pdfish migrated reason features happy statisticsbant medium singled anti but least [SEP] contemptness second mia architecture nonsense departments order deserved ا guardian [MASK] hospitaluts itsried direction soc christmas merely sodiummeral score because [SEP]']
[Init] best rec loss: 0.9155790209770203 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9139524698257446 for ['[CLS] field thousand published nightmares alternative organized position primary energy one appointment act sole device flow,sardrive somehow lack intervals outside denied sleeper singerght beauty isabella signs fae part lynch zion pages provincevil ms folk fadedran deserve dynamic [SEP]']
[Init] best perm rec loss: 0.9106967449188232 for ['[CLS] province nightmares deserve energy act fae ms singer device field alternative folk denied signs flow thousand outsidedrive beauty intervals somehow published isabella part organized lack primaryght sleeper position lynch,dran solesar zion pages appointment dynamicvil one fade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.552 (perp=10.572, rec=0.434, cos=0.004), tot_loss_proj:2.980 [t=0.17s]
prediction: ['[CLS] unique personal ℝ throughout being and amazing kinetic heritage. new first performed kingdom the 2010. when historical the, unique medieval role wonderful young goodnch truly amazingrid, city the appreciation started musical stainless after received hindwings khan [SEP]']
[ 100/2000] tot_loss=2.473 (perp=10.610, rec=0.350, cos=0.001), tot_loss_proj:3.771 [t=0.17s]
prediction: ["[CLS] special living initially during we with overseas historical magic but different also performed palace critical 2010. after historical touch. significant city championship good more ( my'important watching, city cause currency started and gershwin after byuled khan [SEP]"]
[ 150/2000] tot_loss=2.363 (perp=10.215, rec=0.317, cos=0.003), tot_loss_proj:3.852 [t=0.17s]
prediction: ["[CLS] personal living initially we we after overseas wire magic but but also director source criticalca ( before historical resolution. about city performance good these ( to me about watching'city cause psychology started / kumar after by directorial force [SEP]"]
[ 200/2000] tot_loss=2.438 (perp=10.841, rec=0.269, cos=0.001), tot_loss_proj:3.569 [t=0.17s]
prediction: ["[CLS] personal teacher initially we we'overseas before prior but and : director service great which ( afterur among, becca seen performance great these ( to me seen have'city the care makes / kumar before by yang goal [SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.136 (perp=9.459, rec=0.243, cos=0.001), tot_loss_proj:3.655 [t=0.17s]
prediction: ["[CLS] personal teacher initially we we'it before before but and, director and death who reservoir among, becca ( after seen director great some care to me seen ve'of the care makes its kumar before bynation plan [SEP]"]
[ 300/2000] tot_loss=2.217 (perp=9.400, rec=0.332, cos=0.006), tot_loss_proj:3.273 [t=0.17s]
prediction: ["[CLS] this teacher'about we'net before before but well, director and the facts book and, magical'director seen director great of care of us seen ve'of the care makes its kumar before from southern need [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.055 (perp=9.109, rec=0.232, cos=0.001), tot_loss_proj:3.029 [t=0.17s]
prediction: ["[CLS] this outstanding'about we'it before before but of, director and the necessity dvd and. verity'director seen director kumar of care of us seen ve'infant the care makes the great pamphlet without southern help [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.964 (perp=8.740, rec=0.214, cos=0.001), tot_loss_proj:3.438 [t=0.17s]
prediction: ["[CLS] this teacher. about we'it before before but of, director and the necessity dvd of'lifestyle'director seen director kumar of care of us seen ve'latest the care makes the great before without southern help [SEP]"]
[ 450/2000] tot_loss=2.021 (perp=9.159, rec=0.188, cos=0.001), tot_loss_proj:3.255 [t=0.17s]
prediction: ["[CLS] this teacher. about we'it before before but of, director. bruce humiliation dvd and'lifestyle'director seen director kumar of care that us seen ve'latest the care makes its great seen withoutnation help [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.083 (perp=9.509, rec=0.180, cos=0.001), tot_loss_proj:3.689 [t=0.17s]
prediction: ["[CLS] this teacher. about we'it seen before but of, director on bruce humiliation dvd of'existent'director seen director centro with care to us before ve'latest the care makes its great ve withoutnation help [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.355 (perp=10.139, rec=0.324, cos=0.003), tot_loss_proj:3.401 [t=0.17s]
prediction: ["[CLS] this father, about we'it has before but human. director world growth ruth high and we even. allen seen director pastor with care bf us before ve'latest about care makes [CLS] great teaching venation help [SEP]"]
[ 600/2000] tot_loss=2.193 (perp=9.698, rec=0.252, cos=0.001), tot_loss_proj:3.433 [t=0.17s]
prediction: ["[CLS] this father, about we'it has before but human - director, profound mentor world and we even. director seen director hoffman with care bf us before ve'latest about care makes sit great teaching venation help [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.111 (perp=9.460, rec=0.218, cos=0.001), tot_loss_proj:3.671 [t=0.17s]
prediction: ["[CLS] this teacher, about we'it has before but in gen director, profound mentor world and we even. hoffman seen director hoffman with carebl us before ve'latest great care makes sit about teaching venation help [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.948 (perp=8.480, rec=0.250, cos=0.002), tot_loss_proj:3.425 [t=0.17s]
prediction: ["[CLS] this father, about we'it has before but in - director of identity mentor high and we even'hoffman seen director hoffman with care, us before ve'latest great care makes it about teaching venation help [SEP]"]
[ 750/2000] tot_loss=1.977 (perp=8.835, rec=0.208, cos=0.001), tot_loss_proj:3.419 [t=0.17s]
prediction: ["[CLS] this teacher, about we'it has before but in - directorbl identity personality great and we in'hoffman seen director hoffman with ', us before ve'latest great care makes it about teaching venation help [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.921 (perp=8.595, rec=0.201, cos=0.001), tot_loss_proj:3.273 [t=0.17s]
prediction: ["[CLS] this teacher, from we'it has before but in - director of identity mentor great and we in'hoffman seen director hoffman with'about us before ve'latest great care makes it about teaching venation help [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.958 (perp=8.708, rec=0.215, cos=0.001), tot_loss_proj:2.971 [t=0.19s]
prediction: ["[CLS] this teacher, in we'it has before but in previous directorbl technology mentor great and we in'hoffman seen director hoffman with'about us from ve'latest great care makes it about teaching venation help [SEP]"]
[ 900/2000] tot_loss=1.959 (perp=8.809, rec=0.196, cos=0.001), tot_loss_proj:3.105 [t=0.20s]
prediction: ["[CLS] this teacher, in we'it has before but in later directorll technology mentor great and we in'hoffman seen director hoffman with'about us from ve'latest great care makes it about meaning venation help [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.907 (perp=8.573, rec=0.191, cos=0.001), tot_loss_proj:2.993 [t=0.20s]
prediction: ["[CLS] this teacher, we in'it has before but in previous directorll technology mentor great and'in'hoffman seen director hoffman with'about us from ve'latest great care makes it about meaning venation help [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.915 (perp=8.642, rec=0.186, cos=0.001), tot_loss_proj:2.925 [t=0.18s]
prediction: ["[CLS] this teacher, we in'it'before but in previous directorll technology mentor great ve'even'hoffman seen director hoffman with'about us from ve'latest great care makes it about meaning andnation help [SEP]"]
[1050/2000] tot_loss=1.955 (perp=8.860, rec=0.181, cos=0.001), tot_loss_proj:2.931 [t=0.18s]
prediction: ["[CLS] this teacher, we in'it'before but in previous directorll usc mentor great ve'even'hoffman seen director hoffman with'about us from ve'latest great care makes it about meaning andnation help [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.947 (perp=8.813, rec=0.183, cos=0.001), tot_loss_proj:2.795 [t=0.18s]
prediction: ["[CLS]nation teacher, we in'it'before but in previous directorbl usc mentor great ve'even'hoffman seen director hoffman with, about us from ve'latest great care makes it about meaning and this help [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.940 (perp=8.815, rec=0.175, cos=0.001), tot_loss_proj:2.842 [t=0.17s]
prediction: ["[CLS]nation teacher, we in'it'before but in previous director uscll mentor great ve'in guantanamo hoffman seen director hoffman with, about us from ve'latest great care makes it about meaning and this help [SEP]"]
[1200/2000] tot_loss=1.980 (perp=9.016, rec=0.175, cos=0.001), tot_loss_proj:3.040 [t=0.18s]
prediction: ["[CLS]nation teacher, we in'it'before but in previous director uscll task great ve'in guantanamo hoffman seen director hoffman with, about us from ve'latest great care makes it about meaning and this help [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.967 (perp=8.985, rec=0.169, cos=0.001), tot_loss_proj:3.013 [t=0.18s]
prediction: ["[CLS]nation teacher, we in'we'before but in previous director uscll task greatest ve'even guantanamo hoffman seen director hoffman with care about us from ve'latest great, makes it about meaning and this help [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.087 (perp=8.961, rec=0.292, cos=0.003), tot_loss_proj:3.048 [t=0.17s]
prediction: ["[CLS]nation teacher. we in'we'before but in next directorⁿll'greatest ve'her guantanamo hoffman seen director hoffman with care about us from ve teacher latest great, makes it about meaning and this help [SEP]"]
[1350/2000] tot_loss=2.017 (perp=9.069, rec=0.201, cos=0.002), tot_loss_proj:3.028 [t=0.18s]
prediction: ["[CLS]nation teacher. we in'we'before but in next directorⁿll'great ve we the guantanamo hoffman seen director hoffman with care about us from ve teacher latest great here makes it about meaning and this help [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.904 (perp=8.554, rec=0.191, cos=0.001), tot_loss_proj:2.901 [t=0.18s]
prediction: ["[CLS]nation teacher. we in've'before but in next directorⁿll'great we we the guantanamo hoffman seen director hoffman with care about us from ve teacher latest great, makes it about meaning and this help [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.055 (perp=9.087, rec=0.233, cos=0.004), tot_loss_proj:2.894 [t=0.18s]
prediction: ["[CLS]nationnation. we in've'before but in the directorⁿll'great we we next overall hoffman seen director hoffman with care about us from ve teacher latest great we makes it about meaning and this help [SEP]"]
[1500/2000] tot_loss=2.079 (perp=9.478, rec=0.182, cos=0.001), tot_loss_proj:2.888 [t=0.18s]
prediction: ["[CLS]nationnation, we in've'before but in the director brucebl'greatest it we next overall hoffman seen director hoffman with care about us from ve teacher latest great we makes it about of and this help [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.056 (perp=9.395, rec=0.176, cos=0.001), tot_loss_proj:2.956 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the directorⁿbl'greatest it we ve overall hoffman seen director hoffman with care about us from ve teacher latest great we makes it about of and this help [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.926 (perp=8.712, rec=0.183, cos=0.001), tot_loss_proj:2.919 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the director ofbl'greatest it we ve. hoffman seen director hoffman with care about us from ve teacher latest great we makes it aboutⁿ and this help [SEP]"]
[1650/2000] tot_loss=1.905 (perp=8.712, rec=0.161, cos=0.001), tot_loss_proj:2.922 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the director ofbl'greatest it we ve. hoffman seen director hoffman with care about us from ve teacher latest great we makes it aboutⁿ and this help [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.948 (perp=8.934, rec=0.160, cos=0.001), tot_loss_proj:2.801 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the director ofbl'greatest overall we ve it hoffman seen director hoffman with care about us from ve teacher latest great we makes it aboutⁿ and this help [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.891 (perp=8.650, rec=0.160, cos=0.001), tot_loss_proj:2.782 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the director whenbl'it overall we ve great hoffman seen director hoffman with care about us from ve teacher latest great we makes it about bruce and this help [SEP]"]
[1800/2000] tot_loss=1.892 (perp=8.650, rec=0.160, cos=0.001), tot_loss_proj:2.777 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the director whenbl'it overall we ve great hoffman seen director hoffman with care about us from ve teacher latest great we makes it about bruce and this help [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.851 (perp=8.411, rec=0.167, cos=0.001), tot_loss_proj:2.660 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the director webl'it overall we ve great hoffman seen director hoffman with care about us from ve teacher latest great of makes it about bruce and this help [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.837 (perp=8.347, rec=0.166, cos=0.001), tot_loss_proj:2.622 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the director webl'it overall we ve great hoffman seen director hoffman with care about us from ve teacher of great latest makes it about bruce and this help [SEP]"]
[1950/2000] tot_loss=1.852 (perp=8.454, rec=0.160, cos=0.001), tot_loss_proj:2.699 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the director webl'it overall we ve greatest hoffman seen director hoffman with care about us from ve teacher of great latest makes it about bruce and this help [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.827 (perp=8.330, rec=0.160, cos=0.001), tot_loss_proj:2.700 [t=0.18s]
prediction: ["[CLS]nationnation. we in'next'before but in the director webl'it overall we ve greatest hoffman seen director hoffman with care about us this ve teacher of great latest makes it about bruce and from help [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS]nationnation. we in'next'before but in the director webl'it overall we ve great hoffman seen director hoffman with care about us from ve teacher of great latest makes it about bruce and this help [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.753 | p: 63.158 | r: 68.571
rouge2     | fm: 11.268 | p: 10.811 | r: 11.765
rougeL     | fm: 32.877 | p: 31.579 | r: 34.286
rougeLsum  | fm: 32.877 | p: 31.579 | r: 34.286
r1fm+r2fm = 77.021

[Aggregate metrics]:
rouge1     | fm: 89.575 | p: 89.231 | r: 90.006
rouge2     | fm: 60.950 | p: 60.845 | r: 61.092
rougeL     | fm: 78.867 | p: 78.543 | r: 79.273
rougeLsum  | fm: 78.772 | p: 78.525 | r: 79.135
r1fm+r2fm = 150.524

input #35 time: 0:07:32 | total time: 5:00:47


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.9992842743865827
highest_index [0]
highest [0.9992842743865827]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9986883401870728 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9958099126815796 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9545882940292358 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9252082705497742 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9223971962928772 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.9177457690238953 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8233659863471985 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8216447234153748 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 0.8213571906089783 for ['[CLS] bates harassment ramsey cornelius [SEP]']
[Init] best perm rec loss: 0.8175345659255981 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.568 (perp=11.389, rec=0.283, cos=0.007), tot_loss_proj:2.762 [t=0.17s]
prediction: ['[CLS] severely wrong horribly wrong [SEP]']
[ 100/2000] tot_loss=1.893 (perp=8.844, rec=0.123, cos=0.002), tot_loss_proj:2.233 [t=0.17s]
prediction: ['[CLS] horribly wrong horribly wrong [SEP]']
[ 150/2000] tot_loss=2.167 (perp=10.398, rec=0.086, cos=0.001), tot_loss_proj:2.673 [t=0.17s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
[ 200/2000] tot_loss=2.162 (perp=10.398, rec=0.081, cos=0.002), tot_loss_proj:2.663 [t=0.17s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.846 (perp=8.829, rec=0.079, cos=0.002), tot_loss_proj:2.100 [t=0.22s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 300/2000] tot_loss=1.843 (perp=8.829, rec=0.075, cos=0.001), tot_loss_proj:2.102 [t=0.21s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.837 (perp=8.829, rec=0.070, cos=0.001), tot_loss_proj:2.092 [t=0.17s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.832 (perp=8.829, rec=0.064, cos=0.001), tot_loss_proj:2.095 [t=0.20s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 450/2000] tot_loss=1.838 (perp=8.829, rec=0.071, cos=0.001), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.831 (perp=8.829, rec=0.063, cos=0.001), tot_loss_proj:2.093 [t=0.17s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.833 (perp=8.829, rec=0.066, cos=0.001), tot_loss_proj:2.094 [t=0.17s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 600/2000] tot_loss=1.832 (perp=8.829, rec=0.064, cos=0.001), tot_loss_proj:2.091 [t=0.17s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.841 (perp=8.829, rec=0.074, cos=0.001), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.834 (perp=8.829, rec=0.067, cos=0.001), tot_loss_proj:2.090 [t=0.17s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
[ 750/2000] tot_loss=1.823 (perp=8.829, rec=0.056, cos=0.001), tot_loss_proj:2.092 [t=0.17s]
prediction: ['[CLS] s wrong horribly wrong [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.692 (perp=8.105, rec=0.070, cos=0.001), tot_loss_proj:1.940 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.692 (perp=8.105, rec=0.070, cos=0.001), tot_loss_proj:1.945 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.683 (perp=8.105, rec=0.060, cos=0.001), tot_loss_proj:1.955 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.694 (perp=8.105, rec=0.072, cos=0.001), tot_loss_proj:1.940 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.687 (perp=8.105, rec=0.065, cos=0.001), tot_loss_proj:1.959 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1050/2000] tot_loss=1.681 (perp=8.105, rec=0.059, cos=0.001), tot_loss_proj:1.950 [t=0.20s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.686 (perp=8.105, rec=0.064, cos=0.001), tot_loss_proj:1.945 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.691 (perp=8.105, rec=0.069, cos=0.001), tot_loss_proj:1.947 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1200/2000] tot_loss=1.681 (perp=8.105, rec=0.059, cos=0.001), tot_loss_proj:1.949 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.678 (perp=8.105, rec=0.056, cos=0.001), tot_loss_proj:1.954 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.681 (perp=8.105, rec=0.059, cos=0.001), tot_loss_proj:1.956 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1350/2000] tot_loss=1.686 (perp=8.105, rec=0.064, cos=0.001), tot_loss_proj:1.950 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.687 (perp=8.105, rec=0.065, cos=0.001), tot_loss_proj:1.950 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.687 (perp=8.105, rec=0.064, cos=0.001), tot_loss_proj:1.959 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1500/2000] tot_loss=1.687 (perp=8.105, rec=0.064, cos=0.001), tot_loss_proj:1.945 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.681 (perp=8.105, rec=0.058, cos=0.001), tot_loss_proj:1.951 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.677 (perp=8.105, rec=0.054, cos=0.001), tot_loss_proj:1.958 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1650/2000] tot_loss=1.674 (perp=8.105, rec=0.051, cos=0.001), tot_loss_proj:1.946 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.685 (perp=8.105, rec=0.063, cos=0.001), tot_loss_proj:1.949 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.687 (perp=8.105, rec=0.064, cos=0.001), tot_loss_proj:1.941 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1800/2000] tot_loss=1.690 (perp=8.105, rec=0.068, cos=0.001), tot_loss_proj:1.945 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.685 (perp=8.105, rec=0.063, cos=0.001), tot_loss_proj:1.957 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.691 (perp=8.105, rec=0.069, cos=0.001), tot_loss_proj:1.950 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1950/2000] tot_loss=1.688 (perp=8.105, rec=0.066, cos=0.001), tot_loss_proj:1.949 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.692 (perp=8.105, rec=0.070, cos=0.001), tot_loss_proj:1.945 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s'horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.852 | p: 89.512 | r: 90.315
rouge2     | fm: 62.265 | p: 62.155 | r: 62.424
rougeL     | fm: 79.542 | p: 79.188 | r: 79.862
rougeLsum  | fm: 79.463 | p: 79.135 | r: 79.834
r1fm+r2fm = 152.117

input #36 time: 0:07:45 | total time: 5:08:33


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9993688501312639
highest_index [0]
highest [0.9993688501312639]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9638330340385437 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.9471154808998108 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.8868577480316162 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.809199333190918 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.8002374172210693 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7850696444511414 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.7521161437034607 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7474158406257629 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.7218530774116516 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.7020721435546875 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6827971339225769 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6734248399734497 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.6440885663032532 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6402079463005066 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.475 (perp=10.295, rec=0.388, cos=0.028), tot_loss_proj:3.105 [t=0.17s]
prediction: ['[CLS] eccentric again [SEP]']
[ 100/2000] tot_loss=2.118 (perp=9.583, rec=0.193, cos=0.008), tot_loss_proj:2.036 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 150/2000] tot_loss=2.051 (perp=9.583, rec=0.131, cos=0.004), tot_loss_proj:2.025 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=2.001 (perp=9.583, rec=0.083, cos=0.001), tot_loss_proj:2.012 [t=0.20s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:1.999 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.984 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.982 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.970 (perp=9.583, rec=0.052, cos=0.001), tot_loss_proj:2.017 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.987 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.992 (perp=9.583, rec=0.074, cos=0.001), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.009 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.964 (perp=9.583, rec=0.046, cos=0.001), tot_loss_proj:2.013 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.001 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.989 (perp=9.583, rec=0.071, cos=0.001), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.985 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:1.997 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.969 (perp=9.583, rec=0.051, cos=0.001), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.985 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.970 (perp=9.583, rec=0.052, cos=0.001), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:1.995 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.981 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.987 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.018 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.987 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.007 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:1.996 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.014 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.974 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.059 | p: 89.737 | r: 90.498
rouge2     | fm: 63.144 | p: 63.075 | r: 63.253
rougeL     | fm: 79.889 | p: 79.674 | r: 80.239
rougeLsum  | fm: 79.880 | p: 79.649 | r: 80.160
r1fm+r2fm = 153.203

input #37 time: 0:08:16 | total time: 5:16:49


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9992650714710192
highest_index [0]
highest [0.9992650714710192]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8147767186164856 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8102814555168152 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.8013331294059753 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.767846405506134 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7035160064697266 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6697532534599304 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6317602396011353 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.000 (perp=14.069, rec=0.176, cos=0.011), tot_loss_proj:3.017 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.903 (perp=14.069, rec=0.088, cos=0.001), tot_loss_proj:2.879 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.873 (perp=14.069, rec=0.057, cos=0.003), tot_loss_proj:2.880 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.884 (perp=14.069, rec=0.069, cos=0.001), tot_loss_proj:2.882 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.873 (perp=14.069, rec=0.058, cos=0.001), tot_loss_proj:2.875 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.879 (perp=14.069, rec=0.064, cos=0.001), tot_loss_proj:2.878 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.863 (perp=14.069, rec=0.048, cos=0.001), tot_loss_proj:2.871 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.882 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.873 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.874 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.878 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.872 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.866 (perp=14.069, rec=0.051, cos=0.001), tot_loss_proj:2.865 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.873 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.875 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.879 (perp=14.069, rec=0.064, cos=0.001), tot_loss_proj:2.876 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.870 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.877 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.875 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.878 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.882 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.863 (perp=14.069, rec=0.047, cos=0.001), tot_loss_proj:2.875 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.885 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.881 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.879 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.869 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.894 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.888 (perp=14.069, rec=0.072, cos=0.001), tot_loss_proj:2.884 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.878 (perp=14.069, rec=0.063, cos=0.001), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.887 (perp=14.069, rec=0.072, cos=0.001), tot_loss_proj:2.871 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.874 (perp=14.069, rec=0.059, cos=0.001), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.874 (perp=14.069, rec=0.058, cos=0.001), tot_loss_proj:2.872 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.889 (perp=14.069, rec=0.074, cos=0.001), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.872 (perp=14.069, rec=0.057, cos=0.001), tot_loss_proj:2.874 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.860 (perp=14.069, rec=0.044, cos=0.001), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.409 | p: 90.053 | r: 90.779
rouge2     | fm: 64.316 | p: 64.212 | r: 64.430
rougeL     | fm: 80.648 | p: 80.375 | r: 80.929
rougeLsum  | fm: 80.385 | p: 80.127 | r: 80.697
r1fm+r2fm = 154.725

input #38 time: 0:08:41 | total time: 5:25:31


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9992526747729698
highest_index [0]
highest [0.9992526747729698]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.0125712156295776 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0075626373291016 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9883815050125122 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9328680038452148 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9286262392997742 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9213950037956238 for ['[CLS] mutual peopleュ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9183960556983948 for ['[CLS] will press caseztty never crimson bohemia journal search band relations behind formula cells main commissioner quick palmer present bible backs duty sogh [SEP]']
[Init] best rec loss: 0.9107301235198975 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9091352820396423 for ['[CLS]pher happened sailowa jury cassidy gordon main etcwind thentivehy event south sometimes positionney lab be hurtpet wash town in [SEP]']
[Init] best perm rec loss: 0.9068863391876221 for ['[CLS]hy jurypet wash then townney sometimestive hurt eventpher position main happened etc south bewind gordon cassidy labowa sail in [SEP]']
[Init] best perm rec loss: 0.9056861400604248 for ['[CLS] cassidypher eventneypet southowa in gordonwind position sail town thentive wash sometimeshy etc be happened jury lab main hurt [SEP]']
[Init] best perm rec loss: 0.9048677086830139 for ['[CLS] happened event hurt lab be gordonwind in sometimeshy south wash thenney etc cassidy position sailpetpherowa main towntive jury [SEP]']
[Init] best perm rec loss: 0.9048073887825012 for ['[CLS]owa south sailpetneytive main hurt sometimes cassidy town in gordon etc happened be labhy then positionwind jury washpher event [SEP]']
[Init] best perm rec loss: 0.902324914932251 for ['[CLS] be jurypher etc wash position gordon cassidy happened southney sometimesowa in mainhytive lab then eventpet sailwind hurt town [SEP]']
[Init] best perm rec loss: 0.9018852710723877 for ['[CLS] position labney gordon happened mainpher wash thenowa south sail jury inpet cassidy etctive eventwind be hurt sometimes townhy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.876 (perp=12.399, rec=0.391, cos=0.005), tot_loss_proj:3.293 [t=0.18s]
prediction: ['[CLS] finding centennial william review dun institute online literary art ） dante design : energy madeline alonso stone under heritage [CLS] love touch film tradition then [SEP]']
[ 100/2000] tot_loss=2.398 (perp=10.398, rec=0.316, cos=0.003), tot_loss_proj:2.802 [t=0.18s]
prediction: ['[CLS] finding movie resulting truth gives deeply new artists family new new roots returns element, constructed stone new historical. new bathing movie treasure then [SEP]']
[ 150/2000] tot_loss=2.417 (perp=10.874, rec=0.239, cos=0.003), tot_loss_proj:3.029 [t=0.17s]
prediction: ['[CLS] of movie texture conservative wilton finds new luke austen most, anniversary conservative texture and gives wolf new historical. relevance finds movie tradition then [SEP]']
[ 200/2000] tot_loss=2.416 (perp=10.934, rec=0.225, cos=0.004), tot_loss_proj:3.308 [t=0.17s]
prediction: ['[CLS] his movie texture conservative conservative finds new luke traditions most - anniversary conservative texture and gives founder new texture, relevance finds movietypical then [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.328 (perp=10.755, rec=0.175, cos=0.001), tot_loss_proj:3.263 [t=0.17s]
prediction: ['[CLS] his movie texture hide conservative finds new hide tradition traditions most most conservative texture and givesield new texture, relevance finds moviebound then [SEP]']
[ 300/2000] tot_loss=2.106 (perp=9.718, rec=0.160, cos=0.003), tot_loss_proj:2.859 [t=0.17s]
prediction: ['[CLS] his movie texture hide conservative finds new hide tradition traditions most most conservative texture and gives them new texture, relevance finds moviebound " [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.971 (perp=8.905, rec=0.187, cos=0.003), tot_loss_proj:2.309 [t=0.17s]
prediction: ['[CLS] his movie texture hide texture finds new hide tradition traditions most most conservative conservative and gives it new texture, relevance our moviebound. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.964 (perp=9.124, rec=0.138, cos=0.001), tot_loss_proj:2.357 [t=0.17s]
prediction: ['[CLS] our movie texture hide texture finds new hide tradition traditions most most conservative conservative and gives it new texture,. and moviebound relevance [SEP]']
[ 450/2000] tot_loss=1.854 (perp=8.688, rec=0.115, cos=0.001), tot_loss_proj:2.476 [t=0.17s]
prediction: ['[CLS] our movie texture hide texture finds new hidebound traditions most most conservative conservative and gives it new texture,. and moviebound reality [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.812 (perp=8.477, rec=0.115, cos=0.001), tot_loss_proj:2.489 [t=0.17s]
prediction: ['[CLS] our movie texture hide new texture finds hidebound traditions most most conservative conservative and gives it new texture,. and moviebound reality [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.788 (perp=8.363, rec=0.114, cos=0.001), tot_loss_proj:2.443 [t=0.17s]
prediction: ['[CLS] our movie texture hide new texture finds hidebound traditions most conservative conservative - and gives it new texture,. and moviebound reality [SEP]']
[ 600/2000] tot_loss=1.772 (perp=8.363, rec=0.098, cos=0.001), tot_loss_proj:2.438 [t=0.19s]
prediction: ['[CLS] our movie texture hide new texture finds hidebound traditions most conservative conservative - and gives it new texture,. and moviebound reality [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.658 (perp=7.796, rec=0.098, cos=0.001), tot_loss_proj:2.273 [t=0.17s]
prediction: ['[CLS] our movie texture hide new texture finds hidebound traditions most conservative conservative - and gives it new texture, reality and moviebound. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.638 (perp=7.662, rec=0.105, cos=0.001), tot_loss_proj:2.215 [t=0.19s]
prediction: ['[CLS] our movie texture hide movie texture finds hidebound traditions most conservative conservative - and gives it new texture, reality and newbound. [SEP]']
[ 750/2000] tot_loss=1.629 (perp=7.662, rec=0.095, cos=0.001), tot_loss_proj:2.221 [t=0.19s]
prediction: ['[CLS] our movie texture hide movie texture finds hidebound traditions most conservative conservative - and gives it new texture, reality and newbound. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.626 (perp=7.662, rec=0.092, cos=0.001), tot_loss_proj:2.217 [t=0.17s]
prediction: ['[CLS] our movie texture hide movie texture finds hidebound traditions most conservative conservative - and gives it new texture, reality and newbound. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.623 (perp=7.662, rec=0.089, cos=0.001), tot_loss_proj:2.214 [t=0.17s]
prediction: ['[CLS] our movie texture hide movie texture finds hidebound traditions most conservative conservative - and gives it new texture, reality and newbound. [SEP]']
[ 900/2000] tot_loss=1.625 (perp=7.714, rec=0.081, cos=0.001), tot_loss_proj:2.185 [t=0.17s]
prediction: ['[CLS] our movie texture hide movie texture finds hidemaking traditions most conservative conservative - and gives it new texture, reality and newbound. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.638 (perp=7.738, rec=0.089, cos=0.001), tot_loss_proj:2.207 [t=0.18s]
prediction: ['[CLS] our movie texture hide movie texture finds hide making traditions most conservative conservative - and gives it new texture, new and realitybound. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.639 (perp=7.748, rec=0.088, cos=0.001), tot_loss_proj:2.327 [t=0.18s]
prediction: ['[CLS] our movie texture hide movie texture finds hide making traditions most conservative conservative - and gives it new texture, and new realitybound. [SEP]']
[1050/2000] tot_loss=1.638 (perp=7.748, rec=0.087, cos=0.001), tot_loss_proj:2.329 [t=0.17s]
prediction: ['[CLS] our movie texture hide movie texture finds hide making traditions most conservative conservative - and gives it new texture, and new realitybound. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.615 (perp=7.671, rec=0.079, cos=0.001), tot_loss_proj:3.063 [t=0.18s]
prediction: ['[CLS] our movie texture hide movie texture finds hide making traditions most conservative - and conservative gives it new texture, and new realitybound. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.573 (perp=7.438, rec=0.084, cos=0.001), tot_loss_proj:2.968 [t=0.17s]
prediction: ['[CLS] our movie texture hide finds movie texture hide making traditions most conservative - and conservative gives it new texture, and new realitybound. [SEP]']
[1200/2000] tot_loss=1.578 (perp=7.438, rec=0.089, cos=0.001), tot_loss_proj:2.971 [t=0.17s]
prediction: ['[CLS] our movie texture hide finds movie texture hide making traditions most conservative - and conservative gives it new texture, and new realitybound. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.545 (perp=7.294, rec=0.085, cos=0.001), tot_loss_proj:3.037 [t=0.17s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.554 (perp=7.294, rec=0.094, cos=0.001), tot_loss_proj:3.036 [t=0.18s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
[1350/2000] tot_loss=1.546 (perp=7.294, rec=0.086, cos=0.001), tot_loss_proj:3.036 [t=0.17s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.545 (perp=7.294, rec=0.084, cos=0.001), tot_loss_proj:3.034 [t=0.17s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.547 (perp=7.294, rec=0.087, cos=0.001), tot_loss_proj:3.032 [t=0.17s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
[1500/2000] tot_loss=1.546 (perp=7.294, rec=0.085, cos=0.001), tot_loss_proj:3.036 [t=0.17s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.549 (perp=7.294, rec=0.089, cos=0.001), tot_loss_proj:3.034 [t=0.18s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.534 (perp=7.294, rec=0.074, cos=0.001), tot_loss_proj:3.034 [t=0.17s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
[1650/2000] tot_loss=1.546 (perp=7.294, rec=0.086, cos=0.001), tot_loss_proj:3.033 [t=0.17s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.539 (perp=7.294, rec=0.079, cos=0.001), tot_loss_proj:3.034 [t=0.18s]
prediction: ['[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.496 (perp=7.026, rec=0.089, cos=0.001), tot_loss_proj:2.993 [t=0.18s]
prediction: ['[CLS] our movie texture hide - new movie texture hide making traditions most conservative and conservative gives it new texture, and finds realitybound. [SEP]']
[1800/2000] tot_loss=1.498 (perp=7.026, rec=0.091, cos=0.001), tot_loss_proj:3.000 [t=0.18s]
prediction: ['[CLS] our movie texture hide - new movie texture hide making traditions most conservative and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.501 (perp=7.026, rec=0.094, cos=0.001), tot_loss_proj:2.990 [t=0.17s]
prediction: ['[CLS] our movie texture hide - new movie texture hide making traditions most conservative and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.491 (perp=7.026, rec=0.084, cos=0.001), tot_loss_proj:2.996 [t=0.17s]
prediction: ['[CLS] our movie texture hide - new movie texture hide making traditions most conservative and conservative gives it new texture, and finds realitybound. [SEP]']
[1950/2000] tot_loss=1.491 (perp=7.026, rec=0.084, cos=0.001), tot_loss_proj:2.999 [t=0.17s]
prediction: ['[CLS] our movie texture hide - new movie texture hide making traditions most conservative and conservative gives it new texture, and finds realitybound. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.485 (perp=7.026, rec=0.078, cos=0.001), tot_loss_proj:2.995 [t=0.17s]
prediction: ['[CLS] our movie texture hide - new movie texture hide making traditions most conservative and conservative gives it new texture, and finds realitybound. [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] our movie texture hide new movie texture hide making traditions most conservative - and conservative gives it new texture, and finds realitybound. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.111 | p: 69.565 | r: 72.727
rouge2     | fm: 27.907 | p: 27.273 | r: 28.571
rougeL     | fm: 48.889 | p: 47.826 | r: 50.000
rougeLsum  | fm: 48.889 | p: 47.826 | r: 50.000
r1fm+r2fm = 99.018

[Aggregate metrics]:
rouge1     | fm: 89.856 | p: 89.496 | r: 90.318
rouge2     | fm: 63.389 | p: 63.289 | r: 63.580
rougeL     | fm: 79.742 | p: 79.424 | r: 80.056
rougeLsum  | fm: 79.414 | p: 79.097 | r: 79.728
r1fm+r2fm = 153.245

input #39 time: 0:09:08 | total time: 5:34:39


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9993178197074233
highest_index [0]
highest [0.9993178197074233]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9942196607589722 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9584137797355652 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9366960525512695 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.935725748538971 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 0.9297330379486084 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9249941110610962 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.9139153957366943 for ['[CLS] formula expression groundsoft written used ⇒ution murray [SEP]']
[Init] best rec loss: 0.9052402973175049 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.8458519577980042 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8345496654510498 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8326913118362427 for ['[CLS] but already lady° georgian kent deciding abd many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.729 (perp=11.858, rec=0.353, cos=0.004), tot_loss_proj:3.255 [t=0.17s]
prediction: ["[CLS] contact choke lack random bombardment leningrad video'stupid [SEP]"]
[ 100/2000] tot_loss=2.665 (perp=12.018, rec=0.259, cos=0.003), tot_loss_proj:3.511 [t=0.19s]
prediction: ['[CLS] photommelonyviewony us imagery or sick [SEP]']
[ 150/2000] tot_loss=2.277 (perp=10.554, rec=0.164, cos=0.002), tot_loss_proj:3.076 [t=0.18s]
prediction: ['[CLS] pummelony withony us imagery or confused [SEP]']
[ 200/2000] tot_loss=2.341 (perp=11.124, rec=0.115, cos=0.002), tot_loss_proj:3.520 [t=0.17s]
prediction: ['[CLS] pummelony withony us imagery or pu [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.125 (perp=10.135, rec=0.096, cos=0.002), tot_loss_proj:3.689 [t=0.17s]
prediction: ['[CLS] pummelony with ph imagery us imagery or [SEP]']
[ 300/2000] tot_loss=2.154 (perp=10.375, rec=0.077, cos=0.001), tot_loss_proj:3.934 [t=0.17s]
prediction: ['[CLS] pummelony with ph imagery us music or [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.029 (perp=9.700, rec=0.088, cos=0.001), tot_loss_proj:3.674 [t=0.21s]
prediction: ['[CLS] pummelony with ph us imagery music or [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.683 (perp=7.975, rec=0.087, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery music or [SEP]']
[ 450/2000] tot_loss=1.666 (perp=7.975, rec=0.069, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery music or [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.473 (perp=6.973, rec=0.077, cos=0.001), tot_loss_proj:1.492 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.463 (perp=6.973, rec=0.067, cos=0.001), tot_loss_proj:1.490 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 600/2000] tot_loss=1.467 (perp=6.973, rec=0.071, cos=0.001), tot_loss_proj:1.503 [t=0.20s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.465 (perp=6.973, rec=0.069, cos=0.001), tot_loss_proj:1.487 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.453 (perp=6.973, rec=0.057, cos=0.001), tot_loss_proj:1.504 [t=0.20s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 750/2000] tot_loss=1.451 (perp=6.973, rec=0.055, cos=0.001), tot_loss_proj:1.497 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.463 (perp=6.973, rec=0.067, cos=0.001), tot_loss_proj:1.496 [t=0.20s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.465 (perp=6.973, rec=0.069, cos=0.001), tot_loss_proj:1.500 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 900/2000] tot_loss=1.463 (perp=6.973, rec=0.067, cos=0.001), tot_loss_proj:1.492 [t=0.20s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.462 (perp=6.973, rec=0.066, cos=0.001), tot_loss_proj:1.492 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1050/2000] tot_loss=1.452 (perp=6.973, rec=0.056, cos=0.001), tot_loss_proj:1.506 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.466 (perp=6.973, rec=0.070, cos=0.001), tot_loss_proj:1.501 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.452 (perp=6.973, rec=0.056, cos=0.001), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1200/2000] tot_loss=1.455 (perp=6.973, rec=0.059, cos=0.001), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.468 (perp=6.973, rec=0.072, cos=0.001), tot_loss_proj:1.485 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.466 (perp=6.973, rec=0.070, cos=0.001), tot_loss_proj:1.492 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1350/2000] tot_loss=1.455 (perp=6.973, rec=0.059, cos=0.001), tot_loss_proj:1.488 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.451 (perp=6.973, rec=0.055, cos=0.001), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.458 (perp=6.973, rec=0.062, cos=0.001), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1500/2000] tot_loss=1.449 (perp=6.973, rec=0.053, cos=0.001), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.451 (perp=6.973, rec=0.056, cos=0.001), tot_loss_proj:1.493 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.454 (perp=6.973, rec=0.058, cos=0.001), tot_loss_proj:1.504 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1650/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.483 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.458 (perp=6.973, rec=0.062, cos=0.001), tot_loss_proj:1.492 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.462 (perp=6.973, rec=0.066, cos=0.001), tot_loss_proj:1.485 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1800/2000] tot_loss=1.461 (perp=6.973, rec=0.065, cos=0.001), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.503 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1950/2000] tot_loss=1.449 (perp=6.973, rec=0.053, cos=0.001), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.468 (perp=6.973, rec=0.072, cos=0.001), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony music or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 90.112 | p: 89.788 | r: 90.561
rouge2     | fm: 63.003 | p: 62.907 | r: 63.205
rougeL     | fm: 79.647 | p: 79.346 | r: 79.973
rougeLsum  | fm: 79.559 | p: 79.264 | r: 79.851
r1fm+r2fm = 153.116

input #40 time: 0:07:57 | total time: 5:42:36


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.999304507364323
highest_index [0]
highest [0.999304507364323]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9788511395454407 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9516528844833374 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9389455914497375 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.9341390132904053 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.928720235824585 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.924547553062439 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9216023683547974 for ['[CLS] style tomorrow [SEP]']
[Init] best rec loss: 0.9001919627189636 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8952876925468445 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.8542567491531372 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8272965550422668 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.8260568976402283 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.162 (perp=10.212, rec=0.117, cos=0.002), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.114 (perp=10.212, rec=0.070, cos=0.002), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.102 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.108 (perp=10.212, rec=0.065, cos=0.002), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.100 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.107 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.115 (perp=10.212, rec=0.071, cos=0.001), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.118 (perp=10.212, rec=0.075, cos=0.001), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.091 (perp=10.212, rec=0.047, cos=0.001), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.101 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.113 (perp=10.212, rec=0.069, cos=0.001), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.001), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.096 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.119 (perp=10.212, rec=0.075, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.093 (perp=10.212, rec=0.049, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.100 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.120 (perp=10.212, rec=0.076, cos=0.001), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.097 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.114 (perp=10.212, rec=0.071, cos=0.001), tot_loss_proj:2.108 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.378 | p: 90.033 | r: 90.839
rouge2     | fm: 63.701 | p: 63.578 | r: 63.798
rougeL     | fm: 80.202 | p: 79.903 | r: 80.552
rougeLsum  | fm: 80.082 | p: 79.866 | r: 80.322
r1fm+r2fm = 154.078

input #41 time: 0:07:42 | total time: 5:50:18


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9993257960966828
highest_index [0]
highest [0.9993257960966828]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9041017889976501 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8518991470336914 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8484532237052917 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8162120580673218 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.8055222630500793 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.8025503158569336 for ['[CLS] liftedures ever dare kitchenrs attracted scale enough ran cut mapletaking bandabe treatygible international wishpling superseded stages larger assignmentctric offended [SEP]']
[Init] best perm rec loss: 0.7999148368835449 for ['[CLS] wishtakingctric enoughurespling dare maple supersededbe stages ran offended larger treaty scale assignment bandagiblers international kitchen attracted lifted cut ever [SEP]']
[Init] best perm rec loss: 0.7986771464347839 for ['[CLS]be assignment lifted stages largerrs attracted maplepling enough banda offended daretaking treaty ever ran cutures international wish kitchen scalectric supersededgible [SEP]']
[Init] best perm rec loss: 0.7972655892372131 for ['[CLS] wish ran larger kitchen treaty assignmentpling maple offendedures attracted supersededctrictaking ever stages scale bandabe cut enough lifted darersgible international [SEP]']
[Init] best perm rec loss: 0.7947720885276794 for ['[CLS]ctric dare wish treaty stages superseded international scalebegible largerpling banda offendedures kitchen ever cut liftedtakingrs maple ran attracted enough assignment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.745 (perp=11.821, rec=0.378, cos=0.003), tot_loss_proj:3.264 [t=0.17s]
prediction: ["[CLS] gibbons expecting before failing for madeline assessment barbe mouth federal alleged toward poorly'office town phone drug drug episode rca internet fuck prostitution council [SEP]"]
[ 100/2000] tot_loss=2.749 (perp=12.234, rec=0.301, cos=0.001), tot_loss_proj:3.193 [t=0.19s]
prediction: ['[CLS] poorly procedure forgot billion for forgot meter bar insult mouth whose alleged poorly forgot against office town result drug drughouses harper presidential fuckential council [SEP]']
[ 150/2000] tot_loss=2.687 (perp=12.106, rec=0.264, cos=0.002), tot_loss_proj:3.253 [t=0.19s]
prediction: ['[CLS] poorly procedure forgot not election forgot survivor re school detector assessment alleged poorly forgot as they poorly result drug drughouses loyalist presidential fuckential department [SEP]']
[ 200/2000] tot_loss=2.725 (perp=12.529, rec=0.218, cos=0.001), tot_loss_proj:3.158 [t=0.19s]
prediction: ['[CLS] poorly project forgot jayne to forgotcreen anything school anything entry attributed poorly forgot as they poorly police drunk gang. loyalist presidential goatential project [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.583 (perp=11.952, rec=0.191, cos=0.001), tot_loss_proj:3.227 [t=0.19s]
prediction: ['[CLS]writing project forgot anything to forgotcreen jayne school anything whose ministerial poorly forgot as theygger police drunk gang. loyalist presidential debrisential project [SEP]']
[ 300/2000] tot_loss=2.529 (perp=11.780, rec=0.172, cos=0.001), tot_loss_proj:3.200 [t=0.19s]
prediction: ['[CLS] filmmakers project forgot anything to forgotcreen include school anything whose into poorly forgot as theygger police drunk gang. loyalist presidential goatential project [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.458 (perp=11.410, rec=0.175, cos=0.001), tot_loss_proj:3.197 [t=0.19s]
prediction: ['[CLS] filmmakers channel forgot anything to forgot attraction include school anything loyalist into poorly forgot as theygger police drunk programme. is presidential containsential project [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.396 (perp=11.195, rec=0.155, cos=0.002), tot_loss_proj:3.303 [t=0.19s]
prediction: ['[CLS] filmmakers channel forgot anything attraction forgot to include school anything loyalist into poorly forgot as theygger police drunk programme. is ebook containsitive project [SEP]']
[ 450/2000] tot_loss=2.379 (perp=11.168, rec=0.144, cos=0.001), tot_loss_proj:3.151 [t=0.19s]
prediction: ['[CLS] filmmakers channel forgot anything attraction forgot to include school anything loyalist into poorly forgot as theygger they drunk refer. is ebookateditive project [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.172 (perp=10.220, rec=0.126, cos=0.001), tot_loss_proj:2.994 [t=0.22s]
prediction: ["[CLS] filmmakers project the anything they forgot to include school anything loyalist into poorly forgot as theygger attraction drunk voter.'scary extremely threatening project [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.089 (perp=9.761, rec=0.135, cos=0.001), tot_loss_proj:2.802 [t=0.18s]
prediction: ["[CLS] filmmakers channel the anything they even to include school anythinghesive into poorly forgot as they threaten attraction drunk identification.'scary scarygger setting [SEP]"]
[ 600/2000] tot_loss=2.206 (perp=10.404, rec=0.124, cos=0.001), tot_loss_proj:3.156 [t=0.18s]
prediction: ['[CLS] filmmakers channel the anything they even to include school anythinghesive into poorly forgot as re threatening attraction drunk attractions. is scary scarygger setting [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.242 (perp=10.619, rec=0.117, cos=0.001), tot_loss_proj:3.308 [t=0.18s]
prediction: ['[CLS] filmmakers channel its anything they scary to include school anythinghesive into poorly forgot asji threatening attraction drunk attractions. is even scarygger setting [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.201 (perp=10.412, rec=0.118, cos=0.001), tot_loss_proj:3.319 [t=0.18s]
prediction: ['[CLS] filmmakers channel the anything they scary to include school anythingtative into poorly forgot as chevroletji attraction drunk attraction. is even scarygger setting [SEP]']
[ 750/2000] tot_loss=2.286 (perp=10.894, rec=0.106, cos=0.001), tot_loss_proj:3.885 [t=0.17s]
prediction: ['[CLS] filmmakers channel the scary they scary to include school anythingtative into poorly forgot as chevroletji attraction drunk attraction. is even scarygger setting [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.257 (perp=10.774, rec=0.101, cos=0.001), tot_loss_proj:3.941 [t=0.17s]
prediction: ['[CLS] filmmakers channel the scary they scary to include school intotative anything poorly forgot as chevroletji attraction death attraction. is even fatalgger setting [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.187 (perp=10.368, rec=0.112, cos=0.001), tot_loss_proj:3.796 [t=0.18s]
prediction: ["[CLS] filmmakers\\ the scary they scary to include school intotative anything poorly forgot as chevroletji attraction death attraction setting'even fatalgger. [SEP]"]
[ 900/2000] tot_loss=2.181 (perp=10.368, rec=0.106, cos=0.001), tot_loss_proj:3.792 [t=0.17s]
prediction: ["[CLS] filmmakers\\ the scary they scary to include school intotative anything poorly forgot as chevroletji attraction death attraction setting'even fatalgger. [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.114 (perp=10.061, rec=0.100, cos=0.001), tot_loss_proj:3.673 [t=0.17s]
prediction: ['[CLS] filmmakers\\ the scary they scary to include school intotative anything poorly forgot as chevroletji attraction deathgger setting is even fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.025 (perp=9.551, rec=0.113, cos=0.001), tot_loss_proj:3.610 [t=0.17s]
prediction: ['[CLS] filmmakers\\ the scary they scary to include school intotative anything poorly forgot as chevroletjigger death attraction setting is even fatal attraction. [SEP]']
[1050/2000] tot_loss=2.017 (perp=9.551, rec=0.105, cos=0.001), tot_loss_proj:3.615 [t=0.17s]
prediction: ['[CLS] filmmakers\\ the scary they scary to include school intotative anything poorly forgot as chevroletjigger death attraction setting is even fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.910 (perp=9.040, rec=0.101, cos=0.001), tot_loss_proj:2.538 [t=0.17s]
prediction: ['[CLS] filmmakers\\ the scary they forgot to include school intotative anything poorly scary as chevroletjigger death attraction setting is even fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.862 (perp=8.826, rec=0.095, cos=0.001), tot_loss_proj:2.802 [t=0.19s]
prediction: ['[CLS] filmmakers even the scary they forgot to include school intotative anything poorly scary as chevroletjigger death attraction setting isअ fatal attraction. [SEP]']
[1200/2000] tot_loss=1.866 (perp=8.826, rec=0.099, cos=0.001), tot_loss_proj:2.805 [t=0.19s]
prediction: ['[CLS] filmmakers even the scary they forgot to include school intotative anything poorly scary as chevroletjigger death attraction setting isअ fatal attraction. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.827 (perp=8.659, rec=0.094, cos=0.001), tot_loss_proj:2.882 [t=0.17s]
prediction: ['[CLS] filmmakers even the scary they forgot to include into schooltative anything poorly scary as chevroletjigger death attraction setting isअ fatal attraction. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.857 (perp=8.827, rec=0.090, cos=0.001), tot_loss_proj:3.016 [t=0.17s]
prediction: ['[CLS] filmmakers even the scary they forgot to include into schooltative anything poorly as vicious scaryjigger death attraction setting isअ fatal attraction. [SEP]']
[1350/2000] tot_loss=1.869 (perp=8.827, rec=0.102, cos=0.001), tot_loss_proj:3.017 [t=0.17s]
prediction: ['[CLS] filmmakers even the scary they forgot to include into schooltative anything poorly as vicious scaryjigger death attraction setting isअ fatal attraction. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.863 (perp=8.827, rec=0.096, cos=0.001), tot_loss_proj:3.011 [t=0.18s]
prediction: ['[CLS] filmmakers even the scary they forgot to include into schooltative anything poorly as vicious scaryjigger death attraction setting isअ fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.826 (perp=8.566, rec=0.111, cos=0.002), tot_loss_proj:2.651 [t=0.18s]
prediction: ['[CLS] filmmakers even vicious scary they forgot to include into schooltative anything poorly as the scaryjigger death attraction setting is 比 fatal attraction. [SEP]']
[1500/2000] tot_loss=1.819 (perp=8.566, rec=0.104, cos=0.001), tot_loss_proj:2.655 [t=0.17s]
prediction: ['[CLS] filmmakers even vicious scary they forgot to include into schooltative anything poorly as the scaryjigger death attraction setting is 比 fatal attraction. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.810 (perp=8.566, rec=0.095, cos=0.001), tot_loss_proj:2.652 [t=0.18s]
prediction: ['[CLS] filmmakers even vicious scary they forgot to include into schooltative anything poorly as the scaryjigger death attraction setting is 比 fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.806 (perp=8.515, rec=0.101, cos=0.001), tot_loss_proj:2.350 [t=0.17s]
prediction: ['[CLS] filmmakers poorly vicious scary they forgot to include into school gallagher anything even as the scaryjigger death attraction setting is 比 fatal attraction. [SEP]']
[1650/2000] tot_loss=1.932 (perp=9.173, rec=0.096, cos=0.001), tot_loss_proj:2.454 [t=0.18s]
prediction: ['[CLS] filmmakers poorly vicious scary they forgot to include into school gallagher anything even as the scaryjigger death attraction setting is 比 fatal re. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.797 (perp=8.488, rec=0.098, cos=0.001), tot_loss_proj:2.373 [t=0.18s]
prediction: ['[CLS] filmmakers poorly fatal scary they forgot to include into school re anything even as the scaryjigger death attraction setting is 比 fatal attraction. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.777 (perp=8.384, rec=0.099, cos=0.001), tot_loss_proj:2.293 [t=0.17s]
prediction: ['[CLS] filmmakers poorly scary scary they forgot to include into school re anything even as the fataljigger death attraction setting is 比 fatal attraction. [SEP]']
[1800/2000] tot_loss=1.777 (perp=8.384, rec=0.099, cos=0.001), tot_loss_proj:2.286 [t=0.17s]
prediction: ['[CLS] filmmakers poorly scary scary they forgot to include into school re anything even as the fataljigger death attraction setting is 比 fatal attraction. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.815 (perp=8.589, rec=0.096, cos=0.001), tot_loss_proj:2.298 [t=0.17s]
prediction: ['[CLS] filmmakers poorly attraction scary they forgot to include into school re anything even as the fataljigger death attraction setting is 比 fatal attraction. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.699 (perp=7.949, rec=0.108, cos=0.001), tot_loss_proj:2.201 [t=0.17s]
prediction: ['[CLS] filmmakers poorly scary they forgot to include into school re anything even as the fatal attractionjigger death attraction setting is 比 fatal attraction. [SEP]']
[1950/2000] tot_loss=1.694 (perp=7.949, rec=0.103, cos=0.001), tot_loss_proj:2.203 [t=0.17s]
prediction: ['[CLS] filmmakers poorly scary they forgot to include into school re anything even as the fatal attractionjigger death attraction setting is 比 fatal attraction. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.686 (perp=7.949, rec=0.095, cos=0.001), tot_loss_proj:2.203 [t=0.17s]
prediction: ['[CLS] filmmakers poorly scary they forgot to include into school re anything even as the fatal attractionjigger death attraction setting is 比 fatal attraction. [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] filmmakers even the scary they forgot to include into schooltative anything poorly as vicious scaryjigger death attraction setting isअ fatal attraction. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.340 | p: 73.913 | r: 70.833
rouge2     | fm: 13.333 | p: 13.636 | r: 13.043
rougeL     | fm: 42.553 | p: 43.478 | r: 41.667
rougeLsum  | fm: 42.553 | p: 43.478 | r: 41.667
r1fm+r2fm = 85.674

[Aggregate metrics]:
rouge1     | fm: 90.044 | p: 89.692 | r: 90.425
rouge2     | fm: 62.632 | p: 62.505 | r: 62.793
rougeL     | fm: 79.212 | p: 78.960 | r: 79.575
rougeLsum  | fm: 79.122 | p: 78.819 | r: 79.501
r1fm+r2fm = 152.675

input #42 time: 0:08:02 | total time: 5:58:21


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9992732655805339
highest_index [0]
highest [0.9992732655805339]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9607493281364441 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9227121472358704 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8925204873085022 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8689665198326111 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.8586649298667908 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.846950888633728 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.8364328742027283 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.7888320684432983 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7853228449821472 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 0.7806761264801025 for ['[CLS] deserved oxidation council enrollment [SEP]']
[Init] best perm rec loss: 0.7801570892333984 for ['[CLS] oxidation enrollment deserved council [SEP]']
[Init] best perm rec loss: 0.7796530723571777 for ['[CLS] oxidation council enrollment deserved [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.086 (perp=13.832, rec=0.316, cos=0.004), tot_loss_proj:3.616 [t=0.17s]
prediction: ['[CLS] emptyomagyistic [SEP]']
[ 100/2000] tot_loss=2.138 (perp=9.570, rec=0.222, cos=0.002), tot_loss_proj:2.691 [t=0.17s]
prediction: ['[CLS] emptyrcissistic [SEP]']
[ 150/2000] tot_loss=1.162 (perp=5.048, rec=0.150, cos=0.002), tot_loss_proj:1.106 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 200/2000] tot_loss=1.100 (perp=5.048, rec=0.089, cos=0.001), tot_loss_proj:1.111 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.086 (perp=5.048, rec=0.075, cos=0.001), tot_loss_proj:1.119 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.087 (perp=5.048, rec=0.076, cos=0.001), tot_loss_proj:1.123 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.082 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.106 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.087 (perp=5.048, rec=0.076, cos=0.002), tot_loss_proj:1.099 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.099 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.100 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.081 (perp=5.048, rec=0.070, cos=0.001), tot_loss_proj:1.107 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.104 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.105 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.103 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.105 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.075 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.093 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.001), tot_loss_proj:1.099 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.115 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.093 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.101 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.100 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.063 (perp=5.048, rec=0.052, cos=0.001), tot_loss_proj:1.107 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.102 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.103 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.109 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.100 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.094 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.093 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.108 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.095 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.095 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.101 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.090 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.098 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.085 (perp=5.048, rec=0.074, cos=0.001), tot_loss_proj:1.093 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.099 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.065 (perp=5.048, rec=0.054, cos=0.001), tot_loss_proj:1.094 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.098 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.100 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.088 (perp=5.048, rec=0.077, cos=0.001), tot_loss_proj:1.103 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.295 | p: 89.967 | r: 90.588
rouge2     | fm: 63.846 | p: 63.711 | r: 63.921
rougeL     | fm: 79.745 | p: 79.509 | r: 80.001
rougeLsum  | fm: 79.683 | p: 79.431 | r: 80.023
r1fm+r2fm = 154.140

input #43 time: 0:07:27 | total time: 6:05:48


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9992417534706349
highest_index [0]
highest [0.9992417534706349]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9856536388397217 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9538675546646118 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great ¡wark grand [SEP]']
[Init] best rec loss: 0.9338456988334656 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9291354417800903 for ['[CLS]hat since shotsisance morning her wound ji living appealing fifapis aus braun filmed james saved ian service person alias motion inclination age storage hyper heard wind any [SEP]']
[Init] best rec loss: 0.9056149125099182 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.904999852180481 for ['[CLS] fatty formerly haley ltd raceway nation brow harbor slavehair intent contact hello ; contains contestants heeosi data graphic capacity settled landon blue comedy rock s co illustrated [SEP]']
[Init] best perm rec loss: 0.9043598175048828 for ['[CLS] s comedyosi slave ltd co contestants contains hello graphic settled capacity hee intent ; contact formerly brow landon blue data illustrated rock nationhair harbor haley fatty raceway [SEP]']
[Init] best perm rec loss: 0.903514564037323 for ['[CLS] comedyhair settled intent contestants capacity contact contains hello rock data nation brow formerly ; hee co blueosi graphic fatty illustrated raceway ltd slave s landon haley harbor [SEP]']
[Init] best perm rec loss: 0.90308678150177 for ['[CLS] graphic contains comedy settled raceway ; intent hee hello slave contact fatty brow ltd s capacityosi formerly rock co data illustratedhair harbor contestants landon haley blue nation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.829 (perp=12.691, rec=0.289, cos=0.001), tot_loss_proj:3.321 [t=0.19s]
prediction: ["[CLS] mongolian fat wasted nadia lost nearly lost explanations lost cover hoffman abandoned segment sept'attempt devoid avoid absurd signing report |ted murder actually is lossulentization [SEP]"]
[ 100/2000] tot_loss=2.278 (perp=10.419, rec=0.192, cos=0.002), tot_loss_proj:2.753 [t=0.17s]
prediction: ['[CLS] slack was wasted translation lost nearly lost in lost translation translation routine segment due routine fright devoid the absurd execution routine ated damon actually was losesboat attack [SEP]']
[ 150/2000] tot_loss=2.166 (perp=10.120, rec=0.140, cos=0.002), tot_loss_proj:2.550 [t=0.17s]
prediction: ['[CLS] slack been hollywood translation translationhole lost in lost translation routine routinefest whose routine frightalic the slack execution routine the slack hollywood a.ity premise. [SEP]']
[ 200/2000] tot_loss=2.265 (perp=10.664, rec=0.131, cos=0.001), tot_loss_proj:2.680 [t=0.17s]
prediction: ['[CLS] slack been hollywood translation translationcut lost in lost translation routine routinefest whose routine frightalic the slack executionfest the slack hollywood which.ity premise. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.192 (perp=10.346, rec=0.122, cos=0.001), tot_loss_proj:2.680 [t=0.17s]
prediction: ['[CLS] slack been hollywood translation translationcut lost in lost translation routine hollywoodfest which routine frightalic the slack executionfest the slack routine a anotherized premise. [SEP]']
[ 300/2000] tot_loss=2.233 (perp=10.604, rec=0.111, cos=0.001), tot_loss_proj:2.822 [t=0.17s]
prediction: ['[CLS] slack been hollywood translations atcut lost in. translation routine hollywoodfest which routine frightalic the slack executionfest the slack routine a anotherizes premise. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.180 (perp=10.390, rec=0.101, cos=0.001), tot_loss_proj:2.864 [t=0.17s]
prediction: ['[CLS] slack been hollywood something at slip lost in. translation routine hollywoodfest which routine frightalicizes the slack executionfest the two routine the another premise. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.984 (perp=9.413, rec=0.100, cos=0.001), tot_loss_proj:2.500 [t=0.17s]
prediction: ['[CLS] slack has hollywood something publication slip lost in. translation.festfest which routine frightalicizes the slack executionfest the slack routine. another premise. [SEP]']
[ 450/2000] tot_loss=1.904 (perp=9.040, rec=0.094, cos=0.001), tot_loss_proj:2.559 [t=0.17s]
prediction: ['[CLS] slack has hollywood something of slip lost in. translation.festfest which routine frightalicizes the slack executionfest the slack routine. another premise. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.762 (perp=8.354, rec=0.090, cos=0.001), tot_loss_proj:2.424 [t=0.17s]
prediction: ['[CLS] slack has hollywood crazy of which. lost in translation.festfest which routine frightalicizes the slack executionfest the. routine. another premise. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.694 (perp=8.057, rec=0.082, cos=0.001), tot_loss_proj:2.322 [t=0.17s]
prediction: ['[CLS] slack has hollywood the ofer. lost in translation.festfest which routine frightalicizes the slack executionizes the routine. another. premise. [SEP]']
[ 600/2000] tot_loss=1.749 (perp=8.289, rec=0.090, cos=0.001), tot_loss_proj:2.267 [t=0.17s]
prediction: ['[CLS] slack has hollywood of ofer. lost in translation.festfest which routine frightalicizes the slack executionizes the the. another. premise. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.617 (perp=7.695, rec=0.076, cos=0.001), tot_loss_proj:2.225 [t=0.17s]
prediction: ['[CLS] slack has hollywood of ofer. lost in translation. absurdfest which routinealicizes the slack executionizes the the fright. another. premise. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.569 (perp=7.418, rec=0.084, cos=0.001), tot_loss_proj:2.021 [t=0.17s]
prediction: ['[CLS] slack has hollywood ofity which. lost in translation. absurdfest which routinealicizes the slack execution of the the fright. another. premise. [SEP]']
[ 750/2000] tot_loss=1.564 (perp=7.418, rec=0.079, cos=0.001), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] slack has hollywood ofity which. lost in translation. absurdfest which routinealicizes the slack execution of the the fright. another. premise. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.550 (perp=7.321, rec=0.084, cos=0.001), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] slack has hollywood ofity which. lost in translation. absurdfest which routinealicizes the slack execution of the fright. another. the premise. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.527 (perp=7.244, rec=0.077, cos=0.001), tot_loss_proj:2.034 [t=0.17s]
prediction: ['[CLS] slack has hollywood ofity which. lost in translation. absurdfest which routinealicizes the slack execution. the fright of another. the premise. [SEP]']
[ 900/2000] tot_loss=1.522 (perp=7.244, rec=0.071, cos=0.001), tot_loss_proj:2.034 [t=0.17s]
prediction: ['[CLS] slack has hollywood ofity which. lost in translation. absurdfest which routinealicizes the slack execution. the fright of another. the premise. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.440 (perp=6.809, rec=0.077, cos=0.001), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity which. lost in translation.fest which routinealicizes the slack execution. the fright of another. the premise. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.443 (perp=6.809, rec=0.080, cos=0.001), tot_loss_proj:1.901 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity which. lost in translation.fest which routinealicizes the slack execution. the fright of another. the premise. [SEP]']
[1050/2000] tot_loss=1.435 (perp=6.751, rec=0.084, cos=0.001), tot_loss_proj:1.879 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity.. lost in translation.fest which routinealicizes the slack execution. the fright of another. the premise. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.415 (perp=6.682, rec=0.077, cos=0.001), tot_loss_proj:1.869 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity. lost in translation..fest which routinealicizes the slack execution. the fright of another. the premise. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.377 (perp=6.495, rec=0.077, cos=0.001), tot_loss_proj:1.807 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity. lost in translation..fest whichalicizes the slack execution. the fright of another routine. the premise. [SEP]']
[1200/2000] tot_loss=1.379 (perp=6.495, rec=0.078, cos=0.001), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity. lost in translation..fest whichalicizes the slack execution. the fright of another routine. the premise. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.386 (perp=6.495, rec=0.085, cos=0.001), tot_loss_proj:1.818 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity. lost in translation..fest whichalicizes the slack execution. the fright of another routine. the premise. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.369 (perp=6.495, rec=0.069, cos=0.001), tot_loss_proj:1.815 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity. lost in translation..fest whichalicizes the slack execution. the fright of another routine. the premise. [SEP]']
[1350/2000] tot_loss=1.400 (perp=6.601, rec=0.078, cos=0.001), tot_loss_proj:1.843 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity. lost in translation. whichfest whichalicizes the slack execution. the fright of another routine. the premise. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.385 (perp=6.574, rec=0.069, cos=0.001), tot_loss_proj:1.825 [t=0.17s]
prediction: ['[CLS] slack has hollywood of absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright. another routine. the premise. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.386 (perp=6.501, rec=0.084, cos=0.002), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] slack has hollywood. absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
[1500/2000] tot_loss=1.446 (perp=6.854, rec=0.074, cos=0.001), tot_loss_proj:1.832 [t=0.17s]
prediction: ['[CLS] slack has hollywood been absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.384 (perp=6.568, rec=0.069, cos=0.001), tot_loss_proj:1.767 [t=0.17s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.392 (perp=6.568, rec=0.077, cos=0.001), tot_loss_proj:1.770 [t=0.17s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
[1650/2000] tot_loss=1.385 (perp=6.568, rec=0.070, cos=0.001), tot_loss_proj:1.772 [t=0.17s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.394 (perp=6.568, rec=0.079, cos=0.001), tot_loss_proj:1.767 [t=0.17s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.390 (perp=6.568, rec=0.075, cos=0.001), tot_loss_proj:1.773 [t=0.17s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
[1800/2000] tot_loss=1.396 (perp=6.568, rec=0.081, cos=0.001), tot_loss_proj:1.770 [t=0.17s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.391 (perp=6.568, rec=0.076, cos=0.001), tot_loss_proj:1.765 [t=0.17s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.393 (perp=6.568, rec=0.078, cos=0.002), tot_loss_proj:1.774 [t=0.19s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
[1950/2000] tot_loss=1.393 (perp=6.568, rec=0.078, cos=0.001), tot_loss_proj:1.761 [t=0.17s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.390 (perp=6.568, rec=0.075, cos=0.001), tot_loss_proj:1.767 [t=0.21s]
prediction: ['[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] slack has been hollywood absurdity. lost in translation. whichfest whichalicizes the slack execution of the fright of another routine. the premise. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 78.261 | r: 78.261
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 60.870 | p: 60.870 | r: 60.870
rougeLsum  | fm: 60.870 | p: 60.870 | r: 60.870
r1fm+r2fm = 114.625

[Aggregate metrics]:
rouge1     | fm: 90.040 | p: 89.697 | r: 90.348
rouge2     | fm: 62.824 | p: 62.722 | r: 62.947
rougeL     | fm: 79.354 | p: 79.159 | r: 79.661
rougeLsum  | fm: 79.281 | p: 79.000 | r: 79.590
r1fm+r2fm = 152.864

input #44 time: 0:07:39 | total time: 6:13:27


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9993986811377396
highest_index [0]
highest [0.9993986811377396]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9825860261917114 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.9404022693634033 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9185224771499634 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9133827090263367 for ['[CLS] look greater applications still decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing ł wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.903794527053833 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.9032831192016602 for ['[CLS] circussome nj lodge photoᅵ bioome kg morning. have interviewrcus account winfield letofan shy broken man floor sunday sack tuneenter station ll [SEP]']
[Init] best rec loss: 0.8698243498802185 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8686729073524475 for ['[CLS] skinlanda ( whoa tree ku entrance special five bore2 via curtis operated murmured v status letter few enclosed gentry joan around military single taste footballtiv [SEP]']
[Init] best perm rec loss: 0.8660717606544495 for ['[CLS] single (tiv tree around v entrance letter bore ku operated football enclosed curtislanda five military taste joan status murmured skin2 via few special gentry whoa [SEP]']
[Init] best perm rec loss: 0.8620867133140564 for ['[CLS] five footballtiv2 taste military ku via single skin status few enclosed special curtis murmured whoa entrancelanda ( tree joan around bore letter v gentry operated [SEP]']
[Init] best perm rec loss: 0.861274242401123 for ['[CLS] murmured2 single taste via skintiv curtis whoa tree v football entrancelanda ku joan five status bore letter few around ( enclosed special operated military gentry [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.957 (perp=12.821, rec=0.390, cos=0.003), tot_loss_proj:3.548 [t=0.17s]
prediction: ['[CLS] nme pickg airnic - than probably junk assistant if hide hole stupid paper pub synthetic on equipment train ago loan question die? shop traffic aloud [SEP]']
[ 100/2000] tot_loss=2.556 (perp=11.200, rec=0.315, cos=0.001), tot_loss_proj:3.518 [t=0.17s]
prediction: ['[CLS] mcmillan thang air eyed - than - junk fraud than shoot mp nec - much properly - equipment train than tag issue die - shop shoots aloud [SEP]']
[ 150/2000] tot_loss=2.324 (perp=10.245, rec=0.274, cos=0.001), tot_loss_proj:2.828 [t=0.17s]
prediction: ['[CLS] mcmillan -es getting wiener - than - junk exercise than shoot full bow - much use - shelf - for shelf issue - - surface movements aloud [SEP]']
[ 200/2000] tot_loss=2.196 (perp=9.754, rec=0.242, cos=0.003), tot_loss_proj:2.736 [t=0.17s]
prediction: ['[CLS] mcmillan - aa getting charley - than - junk exercise than shoot - bow - have use - shelf - for shelf issue - - surface movements than [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.102 (perp=9.526, rec=0.195, cos=0.001), tot_loss_proj:2.793 [t=0.17s]
prediction: ['[CLS] bow - aa getting wiener - than junk exercise than shoot - - bowel have this in shelf - always shelf issue - - shelf movements than [SEP]']
[ 300/2000] tot_loss=2.046 (perp=9.443, rec=0.157, cos=0.001), tot_loss_proj:2.599 [t=0.17s]
prediction: ['[CLS] bow - aa movementsel - than junk exercise than - - - bowel have this in shelf on long shelf bullet - - shelf movements than [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.881 (perp=8.695, rec=0.141, cos=0.001), tot_loss_proj:2.412 [t=0.17s]
prediction: ['[CLS] bow -el haveel - than junk exercise than shoot - - bowel movements this in shelf on long shelf bullet - - shelf movements than [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.901 (perp=8.833, rec=0.133, cos=0.001), tot_loss_proj:2.427 [t=0.17s]
prediction: ['[CLS] bow -ick dramael - than junk exercise than shoot - - bowel movements this in shelf on long shelf bullet - - than shelf movements [SEP]']
[ 450/2000] tot_loss=1.954 (perp=9.096, rec=0.132, cos=0.003), tot_loss_proj:2.479 [t=0.17s]
prediction: ['[CLS] gi -ick dramael - than junk exercise than shoot - - bowel movements this in shelf on long shelf bullet - - than shelf movements [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.010 (perp=9.436, rec=0.122, cos=0.001), tot_loss_proj:2.839 [t=0.17s]
prediction: ['[CLS] gi -mm shootel - than chip exercise than - - - bowel movements this in drama on long shelf point gi - than shelf movements [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.998 (perp=9.428, rec=0.112, cos=0.001), tot_loss_proj:2.640 [t=0.18s]
prediction: ['[CLS] gi - - shootel - than junk exercise than - - - bowel movements this in drama on long shelf pointickmm drama shelf movements [SEP]']
[ 600/2000] tot_loss=2.066 (perp=9.828, rec=0.100, cos=0.001), tot_loss_proj:2.900 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than chip exercise than - - the boweled this in drama on long shelf pointickmm drama shelf movements [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.012 (perp=9.547, rec=0.101, cos=0.001), tot_loss_proj:2.908 [t=0.18s]
prediction: ['[CLS] gi - - shootel - than chip exercise than - - the boweled this in drama on long shelf movementsickmm drama shelf point [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.914 (perp=9.098, rec=0.094, cos=0.001), tot_loss_proj:2.805 [t=0.19s]
prediction: ['[CLS] gi - - shootel - than chip exercise than - - the bowel movements this, drama on long shelfedickmm drama shelf point [SEP]']
[ 750/2000] tot_loss=1.964 (perp=9.366, rec=0.089, cos=0.001), tot_loss_proj:2.919 [t=0.19s]
prediction: ['[CLS] gi - - shootel - than chip exercise than - - the bowel movements this, drama on long shelfyickmm drama shelf point [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.950 (perp=9.286, rec=0.092, cos=0.001), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than chip exercise than - - the bow in movements, this drama on long shelfyickmm drama shelf point [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.755 (perp=8.367, rec=0.081, cos=0.001), tot_loss_proj:2.691 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot exercise than - - the bow in movements, this drama on longickmmicky drama shelf point [SEP]']
[ 900/2000] tot_loss=1.760 (perp=8.367, rec=0.086, cos=0.001), tot_loss_proj:2.692 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot exercise than - - the bow in movements, this drama on longickmmicky drama shelf point [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.689 (perp=7.987, rec=0.091, cos=0.001), tot_loss_proj:2.815 [t=0.18s]
prediction: ['[CLS] gi - - shootel - than shoot exercise long - - the bow in movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.659 (perp=7.849, rec=0.088, cos=0.001), tot_loss_proj:2.821 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot exercise - long - the bow in movements, this drama on thanickmmicky drama shelf point [SEP]']
[1050/2000] tot_loss=1.647 (perp=7.849, rec=0.076, cos=0.001), tot_loss_proj:2.818 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot exercise - long - the bow in movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.615 (perp=7.656, rec=0.082, cos=0.001), tot_loss_proj:2.661 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot exercise - long in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1150/2000] tot_loss=1.608 (perp=7.656, rec=0.075, cos=0.001), tot_loss_proj:2.655 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot exercise - long in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
[1200/2000] tot_loss=1.611 (perp=7.656, rec=0.078, cos=0.001), tot_loss_proj:2.656 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot exercise - long in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.589 (perp=7.516, rec=0.084, cos=0.001), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1300/2000] tot_loss=1.588 (perp=7.516, rec=0.083, cos=0.001), tot_loss_proj:2.564 [t=0.18s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
[1350/2000] tot_loss=1.581 (perp=7.516, rec=0.076, cos=0.001), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1400/2000] tot_loss=1.586 (perp=7.516, rec=0.082, cos=0.001), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1450/2000] tot_loss=1.582 (perp=7.516, rec=0.078, cos=0.001), tot_loss_proj:2.565 [t=0.18s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
[1500/2000] tot_loss=1.587 (perp=7.516, rec=0.082, cos=0.001), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1550/2000] tot_loss=1.579 (perp=7.516, rec=0.074, cos=0.001), tot_loss_proj:2.560 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1600/2000] tot_loss=1.581 (perp=7.516, rec=0.077, cos=0.001), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
[1650/2000] tot_loss=1.585 (perp=7.516, rec=0.080, cos=0.001), tot_loss_proj:2.566 [t=0.21s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1700/2000] tot_loss=1.584 (perp=7.516, rec=0.080, cos=0.001), tot_loss_proj:2.565 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1750/2000] tot_loss=1.588 (perp=7.516, rec=0.084, cos=0.001), tot_loss_proj:2.559 [t=0.18s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
[1800/2000] tot_loss=1.586 (perp=7.516, rec=0.082, cos=0.001), tot_loss_proj:2.560 [t=0.18s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1850/2000] tot_loss=1.583 (perp=7.516, rec=0.079, cos=0.001), tot_loss_proj:2.560 [t=0.17s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
[1900/2000] tot_loss=1.582 (perp=7.516, rec=0.077, cos=0.001), tot_loss_proj:2.561 [t=0.18s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.516, rec=0.082, cos=0.001), tot_loss_proj:2.563 [t=0.18s]
prediction: ['[CLS] gi - - shootel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.531 (perp=7.278, rec=0.075, cos=0.001), tot_loss_proj:2.578 [t=0.18s]
prediction: ['[CLS] shoot - - giel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] shoot - - giel - than shoot long - exercise in the bow - movements, this drama on thanickmmicky drama shelf point [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.676 | p: 73.684 | r: 77.778
rouge2     | fm: 11.429 | p: 11.111 | r: 11.765
rougeL     | fm: 37.838 | p: 36.842 | r: 38.889
rougeLsum  | fm: 37.838 | p: 36.842 | r: 38.889
r1fm+r2fm = 87.104

[Aggregate metrics]:
rouge1     | fm: 89.580 | p: 89.216 | r: 90.051
rouge2     | fm: 61.742 | p: 61.624 | r: 61.829
rougeL     | fm: 78.379 | p: 78.149 | r: 78.632
rougeLsum  | fm: 78.160 | p: 77.885 | r: 78.462
r1fm+r2fm = 151.322

input #45 time: 0:07:36 | total time: 6:21:03


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9992703548035418
highest_index [0]
highest [0.9992703548035418]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9911298155784607 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9792498350143433 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.9472112059593201 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9385618567466736 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9372692704200745 for ['[CLS] political m act paperrton fitz [SEP]']
[Init] best rec loss: 0.9318523406982422 for ['[CLS]tyn tillquisite inside chair fixed [SEP]']
[Init] best rec loss: 0.9173271059989929 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best perm rec loss: 0.9158892631530762 for ['[CLS] four donald canada reed and no [SEP]']
[Init] best perm rec loss: 0.9147517085075378 for ['[CLS] donald and four reed no canada [SEP]']
[Init] best perm rec loss: 0.9115938544273376 for ['[CLS] four reed canada and donald no [SEP]']
[Init] best perm rec loss: 0.9111836552619934 for ['[CLS] donald reed canada four no and [SEP]']
[Init] best perm rec loss: 0.9108540415763855 for ['[CLS] and reed donald four no canada [SEP]']
[Init] best perm rec loss: 0.9107707142829895 for ['[CLS] donald and canada no four reed [SEP]']
[Init] best perm rec loss: 0.9106481671333313 for ['[CLS] four reed no donald canada and [SEP]']
[Init] best perm rec loss: 0.9093884825706482 for ['[CLS] and reed no donald canada four [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.298 (perp=10.412, rec=0.213, cos=0.002), tot_loss_proj:2.462 [t=0.17s]
prediction: ['[CLS] striking visually striking teamed slick slick [SEP]']
[ 100/2000] tot_loss=1.873 (perp=8.653, rec=0.141, cos=0.002), tot_loss_proj:1.991 [t=0.17s]
prediction: ['[CLS]ly visually strikingly slick staged [SEP]']
[ 150/2000] tot_loss=1.828 (perp=8.653, rec=0.096, cos=0.001), tot_loss_proj:2.005 [t=0.17s]
prediction: ['[CLS]ly visually strikingly slick staged [SEP]']
[ 200/2000] tot_loss=1.801 (perp=8.653, rec=0.069, cos=0.001), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS]ly visually strikingly slick staged [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.244 (perp=5.916, rec=0.059, cos=0.001), tot_loss_proj:1.255 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 300/2000] tot_loss=1.252 (perp=5.916, rec=0.067, cos=0.001), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.235 (perp=5.916, rec=0.050, cos=0.001), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.247 (perp=5.916, rec=0.062, cos=0.001), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 450/2000] tot_loss=1.250 (perp=5.916, rec=0.065, cos=0.001), tot_loss_proj:1.245 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.244 (perp=5.916, rec=0.059, cos=0.001), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.253 (perp=5.916, rec=0.069, cos=0.001), tot_loss_proj:1.243 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 600/2000] tot_loss=1.253 (perp=5.916, rec=0.069, cos=0.001), tot_loss_proj:1.242 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.236 (perp=5.916, rec=0.052, cos=0.001), tot_loss_proj:1.249 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.231 (perp=5.916, rec=0.047, cos=0.001), tot_loss_proj:1.244 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 750/2000] tot_loss=1.238 (perp=5.916, rec=0.054, cos=0.001), tot_loss_proj:1.244 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.235 (perp=5.916, rec=0.050, cos=0.001), tot_loss_proj:1.256 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.228 (perp=5.916, rec=0.044, cos=0.001), tot_loss_proj:1.248 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[ 900/2000] tot_loss=1.239 (perp=5.916, rec=0.054, cos=0.001), tot_loss_proj:1.254 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.241 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.252 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1000/2000] tot_loss=1.244 (perp=5.916, rec=0.060, cos=0.001), tot_loss_proj:1.241 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1050/2000] tot_loss=1.241 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1100/2000] tot_loss=1.257 (perp=5.916, rec=0.072, cos=0.001), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1150/2000] tot_loss=1.242 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.243 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1200/2000] tot_loss=1.252 (perp=5.916, rec=0.068, cos=0.001), tot_loss_proj:1.241 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.248 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.251 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.248 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.236 (perp=5.916, rec=0.052, cos=0.001), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.240 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.247 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.244 (perp=5.916, rec=0.059, cos=0.001), tot_loss_proj:1.236 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.252 (perp=5.916, rec=0.068, cos=0.001), tot_loss_proj:1.245 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.247 (perp=5.916, rec=0.063, cos=0.001), tot_loss_proj:1.243 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.243 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.241 (perp=5.916, rec=0.056, cos=0.001), tot_loss_proj:1.242 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.237 (perp=5.916, rec=0.052, cos=0.001), tot_loss_proj:1.253 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.242 (perp=5.916, rec=0.058, cos=0.001), tot_loss_proj:1.247 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.233 (perp=5.916, rec=0.048, cos=0.001), tot_loss_proj:1.255 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.248 (perp=5.916, rec=0.064, cos=0.001), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.254 (perp=5.916, rec=0.070, cos=0.001), tot_loss_proj:1.236 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.246 (perp=5.916, rec=0.061, cos=0.001), tot_loss_proj:1.250 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.239 (perp=5.916, rec=0.054, cos=0.001), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.944 | p: 89.642 | r: 90.348
rouge2     | fm: 62.675 | p: 62.586 | r: 62.812
rougeL     | fm: 78.833 | p: 78.578 | r: 79.103
rougeLsum  | fm: 78.742 | p: 78.464 | r: 79.015
r1fm+r2fm = 152.619

input #46 time: 0:07:26 | total time: 6:28:30


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9992059059142622
highest_index [0]
highest [0.9992059059142622]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6953830718994141 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6925281286239624 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6903731226921082 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6853982210159302 for ['[CLS] purse divine rush [SEP]']
[Init] best rec loss: 0.6800500154495239 for ['[CLS] network biceps truth [SEP]']
[Init] best rec loss: 0.6800178289413452 for ['[CLS] circles hand school [SEP]']
[Init] best rec loss: 0.67453533411026 for ['[CLS] sky next sailed [SEP]']
[Init] best rec loss: 0.6720250844955444 for ['[CLS] salt reality poles [SEP]']
[Init] best perm rec loss: 0.668911337852478 for ['[CLS] poles salt reality [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.887 (perp=12.763, rec=0.321, cos=0.013), tot_loss_proj:3.537 [t=0.17s]
prediction: ['[CLS]right transparent translucent [SEP]']
[ 100/2000] tot_loss=2.710 (perp=12.488, rec=0.210, cos=0.003), tot_loss_proj:3.383 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.653 (perp=12.488, rec=0.153, cos=0.003), tot_loss_proj:3.384 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 200/2000] tot_loss=2.624 (perp=12.488, rec=0.125, cos=0.001), tot_loss_proj:3.402 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.615 (perp=12.488, rec=0.114, cos=0.004), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=2.610 (perp=12.488, rec=0.110, cos=0.003), tot_loss_proj:3.399 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.610 (perp=12.488, rec=0.109, cos=0.003), tot_loss_proj:3.411 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.612 (perp=12.488, rec=0.111, cos=0.003), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 450/2000] tot_loss=2.601 (perp=12.488, rec=0.102, cos=0.002), tot_loss_proj:3.408 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.604 (perp=12.488, rec=0.105, cos=0.002), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.598 (perp=12.488, rec=0.098, cos=0.002), tot_loss_proj:3.414 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 600/2000] tot_loss=2.582 (perp=12.488, rec=0.084, cos=0.001), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.603 (perp=12.488, rec=0.101, cos=0.004), tot_loss_proj:3.423 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.592 (perp=12.488, rec=0.092, cos=0.002), tot_loss_proj:3.421 [t=0.17s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 750/2000] tot_loss=2.517 (perp=12.147, rec=0.087, cos=0.001), tot_loss_proj:2.998 [t=0.17s]
prediction: ['[CLS]right down transparent [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.857 (perp=8.803, rec=0.095, cos=0.002), tot_loss_proj:1.834 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.836 (perp=8.803, rec=0.074, cos=0.001), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.848 (perp=8.803, rec=0.086, cos=0.002), tot_loss_proj:1.845 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.843 (perp=8.803, rec=0.081, cos=0.001), tot_loss_proj:1.827 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.835 (perp=8.803, rec=0.073, cos=0.001), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.839 (perp=8.803, rec=0.077, cos=0.001), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.840 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.834 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.831 (perp=8.803, rec=0.068, cos=0.002), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.822 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.824 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.820 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.825 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.816 (perp=8.803, rec=0.053, cos=0.002), tot_loss_proj:1.838 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.820 (perp=8.803, rec=0.058, cos=0.002), tot_loss_proj:1.823 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.830 (perp=8.803, rec=0.068, cos=0.002), tot_loss_proj:1.827 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.829 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.844 (perp=8.803, rec=0.082, cos=0.002), tot_loss_proj:1.831 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.810 (perp=8.803, rec=0.048, cos=0.002), tot_loss_proj:1.831 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.828 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.824 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.822 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.833 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.835 (perp=8.803, rec=0.073, cos=0.002), tot_loss_proj:1.827 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.828 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.829 (perp=8.803, rec=0.067, cos=0.002), tot_loss_proj:1.850 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.010 | p: 89.720 | r: 90.413
rouge2     | fm: 63.471 | p: 63.372 | r: 63.576
rougeL     | fm: 79.394 | p: 79.153 | r: 79.668
rougeLsum  | fm: 79.140 | p: 78.908 | r: 79.444
r1fm+r2fm = 153.481

input #47 time: 0:07:34 | total time: 6:36:05


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9993046234064709
highest_index [0]
highest [0.9993046234064709]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9481353759765625 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9344632625579834 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9107456207275391 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.893878161907196 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8840940594673157 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8556822538375854 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8369787931442261 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.796784520149231 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7961894869804382 for ['[CLS] runsdinetute graveyard [SEP]']
[Init] best perm rec loss: 0.7949187159538269 for ['[CLS]tutedine runs graveyard [SEP]']
[Init] best perm rec loss: 0.7926889657974243 for ['[CLS] graveyard runstutedine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.146 (perp=14.462, rec=0.251, cos=0.004), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS] rotting lateral assumed rotting [SEP]']
[ 100/2000] tot_loss=2.240 (perp=10.480, rec=0.142, cos=0.002), tot_loss_proj:2.474 [t=0.18s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 150/2000] tot_loss=2.791 (perp=13.327, rec=0.125, cos=0.001), tot_loss_proj:3.332 [t=0.17s]
prediction: ['[CLS] underbell under rotting [SEP]']
[ 200/2000] tot_loss=2.764 (perp=13.327, rec=0.097, cos=0.001), tot_loss_proj:3.335 [t=0.18s]
prediction: ['[CLS] underbell under rotting [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.257 (perp=10.774, rec=0.101, cos=0.001), tot_loss_proj:2.548 [t=0.17s]
prediction: ['[CLS] underybell rotting [SEP]']
[ 300/2000] tot_loss=2.241 (perp=10.774, rec=0.085, cos=0.001), tot_loss_proj:2.547 [t=0.17s]
prediction: ['[CLS] underybell rotting [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.510 (perp=7.028, rec=0.103, cos=0.001), tot_loss_proj:1.721 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.487 (perp=7.028, rec=0.080, cos=0.001), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.495 (perp=7.028, rec=0.088, cos=0.001), tot_loss_proj:1.724 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.497 (perp=7.028, rec=0.090, cos=0.001), tot_loss_proj:1.718 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.486 (perp=7.028, rec=0.079, cos=0.001), tot_loss_proj:1.724 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.485 (perp=7.028, rec=0.078, cos=0.001), tot_loss_proj:1.717 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.480 (perp=7.028, rec=0.073, cos=0.001), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.479 (perp=7.028, rec=0.072, cos=0.001), tot_loss_proj:1.732 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.480 (perp=7.028, rec=0.073, cos=0.001), tot_loss_proj:1.741 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.466 (perp=7.028, rec=0.059, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.459 (perp=7.028, rec=0.052, cos=0.001), tot_loss_proj:1.725 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.719 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.723 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.477 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.715 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.725 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.728 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.462 (perp=7.028, rec=0.055, cos=0.001), tot_loss_proj:1.726 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.720 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.723 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.728 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.726 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.728 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.460 (perp=7.028, rec=0.053, cos=0.001), tot_loss_proj:1.724 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.728 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.458 (perp=7.028, rec=0.052, cos=0.001), tot_loss_proj:1.717 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.480 (perp=7.028, rec=0.073, cos=0.001), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.476 (perp=7.028, rec=0.069, cos=0.001), tot_loss_proj:1.731 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.465 (perp=7.028, rec=0.058, cos=0.001), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.724 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.298 | p: 89.992 | r: 90.664
rouge2     | fm: 62.317 | p: 62.208 | r: 62.437
rougeL     | fm: 79.214 | p: 78.953 | r: 79.517
rougeLsum  | fm: 78.921 | p: 78.650 | r: 79.257
r1fm+r2fm = 152.616

input #48 time: 0:07:46 | total time: 6:43:51


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9992285770800434
highest_index [0]
highest [0.9992285770800434]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8349988460540771 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7890780568122864 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7884876728057861 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 0.7864314913749695 for ['[CLS] saline rang market aspects senate brothersona situation trafficking health follows tel [SEP]']
[Init] best rec loss: 0.7806379795074463 for ['[CLS] painted exactly tips haunt unknown going wrong matches until tamillaw ambulance [SEP]']
[Init] best rec loss: 0.7647554874420166 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7542374730110168 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7533898949623108 for ['[CLS] legs jose trick tongue gmina collegeiza during jockey patrick process baby [SEP]']
[Init] best perm rec loss: 0.7522913813591003 for ['[CLS] tongue during process gmina patrick baby legsiza jose trick college jockey [SEP]']
[Init] best perm rec loss: 0.7503772377967834 for ['[CLS]iza process gmina jose college tongue baby patrick jockey during trick legs [SEP]']
[Init] best perm rec loss: 0.7501202821731567 for ['[CLS] legs college patrick gmina jockey trick baby during jose processiza tongue [SEP]']
[Init] best perm rec loss: 0.74857497215271 for ['[CLS] tongue jose trick jockey legs gmina patrick college babyiza during process [SEP]']
[Init] best perm rec loss: 0.7482708692550659 for ['[CLS] college process legs during trick patrick jockeyiza jose tongue gmina baby [SEP]']
[Init] best perm rec loss: 0.7479612827301025 for ['[CLS] jose baby legs during patrick tongue college process gmina trickiza jockey [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.657 (perp=11.291, rec=0.396, cos=0.003), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS] blamed cause deserved. females anymore prostitutes than program for evidence prostitution [SEP]']
[ 100/2000] tot_loss=2.329 (perp=10.084, rec=0.309, cos=0.003), tot_loss_proj:3.172 [t=0.17s]
prediction: ['[CLS] more cause deserved. female contempt female types program for intelligence rape [SEP]']
[ 150/2000] tot_loss=2.696 (perp=12.211, rec=0.251, cos=0.003), tot_loss_proj:3.790 [t=0.19s]
prediction: ['[CLS] more restrictions deserved covent female contempt female types population. contempt vacant [SEP]']
[ 200/2000] tot_loss=2.716 (perp=12.453, rec=0.222, cos=0.004), tot_loss_proj:3.607 [t=0.17s]
prediction: ['[CLS] more restrictions deserved covent female contempt female types population. contempt becoming [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.405 (perp=10.897, rec=0.223, cos=0.003), tot_loss_proj:3.227 [t=0.20s]
prediction: ['[CLS] more being population covent female contempt female fewer deserved. contempt single [SEP]']
[ 300/2000] tot_loss=2.525 (perp=11.576, rec=0.207, cos=0.004), tot_loss_proj:3.482 [t=0.17s]
prediction: ['[CLS] possibly snake population covent female contempt female fewer deserved. contempt single [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.502 (perp=11.520, rec=0.196, cos=0.001), tot_loss_proj:3.446 [t=0.18s]
prediction: ['[CLS] possibly possibly population covent female contempt female fewer deserved single contempt of [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.510 (perp=11.628, rec=0.183, cos=0.001), tot_loss_proj:3.485 [t=0.17s]
prediction: ['[CLS] possibly bubble population against more contempt of vector deserved single contempt female [SEP]']
[ 450/2000] tot_loss=2.339 (perp=10.871, rec=0.165, cos=0.001), tot_loss_proj:3.341 [t=0.17s]
prediction: ['[CLS] possibly possibly population. more contempt of vector deserved single contempt female [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.289 (perp=10.725, rec=0.142, cos=0.002), tot_loss_proj:3.332 [t=0.17s]
prediction: ['[CLS] possibly possibly population the more contempt of femaleative single contempt vector [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.219 (perp=10.297, rec=0.158, cos=0.001), tot_loss_proj:3.096 [t=0.17s]
prediction: ['[CLS] possibly possibly deserve the more contempt of female population single contempt refer [SEP]']
[ 600/2000] tot_loss=2.211 (perp=10.297, rec=0.150, cos=0.001), tot_loss_proj:3.106 [t=0.17s]
prediction: ['[CLS] possibly possibly deserve the more contempt of female population single contempt refer [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.995 (perp=9.229, rec=0.148, cos=0.001), tot_loss_proj:2.866 [t=0.18s]
prediction: ['[CLS] possibly possibly deserve the more contempt of female population single refer contempt [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.755 (perp=8.083, rec=0.136, cos=0.002), tot_loss_proj:2.629 [t=0.17s]
prediction: ['[CLS] possibly possibly deserve the more contemptuous female population single refer. [SEP]']
[ 750/2000] tot_loss=1.913 (perp=8.879, rec=0.136, cos=0.001), tot_loss_proj:2.721 [t=0.17s]
prediction: ['[CLS] possibly possiblyuous the more contemptuous female population single refer. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.828 (perp=8.508, rec=0.125, cos=0.002), tot_loss_proj:2.772 [t=0.17s]
prediction: ['[CLS] possibly possibly noble the more contemptuous female population singleuous. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.666 (perp=7.716, rec=0.121, cos=0.002), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS] possibly possibly the more contemptuous noble female population single anticipated. [SEP]']
[ 900/2000] tot_loss=1.868 (perp=8.758, rec=0.115, cos=0.001), tot_loss_proj:2.766 [t=0.17s]
prediction: ['[CLS] could possibly the more contemptuous authors female population single anticipated. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.814 (perp=8.436, rec=0.125, cos=0.001), tot_loss_proj:2.841 [t=0.19s]
prediction: ['[CLS] could possibly noble the more contemptuous female population single anticipated. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.806 (perp=8.436, rec=0.118, cos=0.001), tot_loss_proj:2.839 [t=0.17s]
prediction: ['[CLS] could possibly noble the more contemptuous female population single anticipated. [SEP]']
[1050/2000] tot_loss=1.683 (perp=7.815, rec=0.118, cos=0.002), tot_loss_proj:2.250 [t=0.19s]
prediction: ['[CLS] could possibly associated the more contemptuous female population single be. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.560 (perp=7.196, rec=0.120, cos=0.002), tot_loss_proj:2.126 [t=0.19s]
prediction: ['[CLS] could possibly be the more contemptuous female population single associated. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.476 (perp=6.831, rec=0.109, cos=0.002), tot_loss_proj:2.012 [t=0.19s]
prediction: ['[CLS] could possibly be the more contemptuous female single population associated. [SEP]']
[1200/2000] tot_loss=1.477 (perp=6.831, rec=0.109, cos=0.002), tot_loss_proj:2.024 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous female single population associated. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.415 (perp=6.469, rec=0.120, cos=0.002), tot_loss_proj:1.956 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.404 (perp=6.469, rec=0.109, cos=0.002), tot_loss_proj:1.956 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
[1350/2000] tot_loss=1.409 (perp=6.469, rec=0.114, cos=0.002), tot_loss_proj:1.957 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.405 (perp=6.469, rec=0.109, cos=0.001), tot_loss_proj:1.960 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.388 (perp=6.469, rec=0.093, cos=0.002), tot_loss_proj:1.959 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
[1500/2000] tot_loss=1.394 (perp=6.469, rec=0.099, cos=0.002), tot_loss_proj:1.957 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.404 (perp=6.469, rec=0.108, cos=0.002), tot_loss_proj:1.957 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.401 (perp=6.469, rec=0.106, cos=0.002), tot_loss_proj:1.955 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
[1650/2000] tot_loss=1.399 (perp=6.469, rec=0.104, cos=0.002), tot_loss_proj:1.954 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.401 (perp=6.469, rec=0.106, cos=0.001), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.398 (perp=6.469, rec=0.103, cos=0.002), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
[1800/2000] tot_loss=1.396 (perp=6.469, rec=0.101, cos=0.002), tot_loss_proj:1.961 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.398 (perp=6.469, rec=0.103, cos=0.001), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.403 (perp=6.469, rec=0.108, cos=0.002), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population associated. [SEP]']
[1950/2000] tot_loss=1.460 (perp=6.737, rec=0.111, cos=0.002), tot_loss_proj:2.070 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single female population these. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.393 (perp=6.468, rec=0.097, cos=0.002), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] could possibly be the more contemptuous single these female population. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] could possibly be the more contemptuous single female population associated. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 146.212

[Aggregate metrics]:
rouge1     | fm: 90.301 | p: 90.010 | r: 90.660
rouge2     | fm: 62.149 | p: 62.063 | r: 62.248
rougeL     | fm: 79.276 | p: 79.014 | r: 79.553
rougeLsum  | fm: 79.226 | p: 79.050 | r: 79.498
r1fm+r2fm = 152.449

input #49 time: 0:09:13 | total time: 6:53:04


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9992840964591766
highest_index [0]
highest [0.9992840964591766]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.9206792116165161 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8376301527023315 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.7573332786560059 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7526006698608398 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best perm rec loss: 0.7520577311515808 for ['[CLS]ieving night byhamlent bridget accordance red crisis [SEP]']
[Init] best perm rec loss: 0.7493540644645691 for ['[CLS]lent accordance bridgethamieving by night crisis red [SEP]']
[Init] best perm rec loss: 0.7488336563110352 for ['[CLS]lent accordance redieving crisis night by bridgetham [SEP]']
[Init] best perm rec loss: 0.7483512163162231 for ['[CLS]hamievinglent accordance by red night bridget crisis [SEP]']
[Init] best perm rec loss: 0.7482115030288696 for ['[CLS] red accordance bridgetlent nightham byieving crisis [SEP]']
[Init] best perm rec loss: 0.7472875714302063 for ['[CLS]lentham accordance bridgetieving by night red crisis [SEP]']
[Init] best perm rec loss: 0.7451678514480591 for ['[CLS]lent crisis red by accordanceham nightieving bridget [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.075 (perp=13.003, rec=0.459, cos=0.015), tot_loss_proj:3.830 [t=0.17s]
prediction: ['[CLS] recurring wonder brilliant until clever by trying scout cape [SEP]']
[ 100/2000] tot_loss=2.856 (perp=12.332, rec=0.386, cos=0.003), tot_loss_proj:3.784 [t=0.17s]
prediction: ['[CLS] blake harper clever until clever standards basque scout than [SEP]']
[ 150/2000] tot_loss=2.684 (perp=11.644, rec=0.351, cos=0.004), tot_loss_proj:3.548 [t=0.17s]
prediction: ['[CLS] calls richard clever until clever what half dating than [SEP]']
[ 200/2000] tot_loss=2.536 (perp=11.028, rec=0.327, cos=0.004), tot_loss_proj:3.681 [t=0.17s]
prediction: ['[CLS] calls what clever by clever what half what than [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.328 (perp=10.059, rec=0.315, cos=0.002), tot_loss_proj:3.253 [t=0.17s]
prediction: ['[CLS] what clever by clever called what half what than [SEP]']
[ 300/2000] tot_loss=2.263 (perp=9.844, rec=0.293, cos=0.002), tot_loss_proj:3.273 [t=0.17s]
prediction: ['[CLS] what clever by clever calls what half what than [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.411 (perp=10.604, rec=0.280, cos=0.011), tot_loss_proj:3.494 [t=0.17s]
prediction: ['[CLS] what clever by clever call what half ` what [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.329 (perp=10.303, rec=0.266, cos=0.002), tot_loss_proj:3.387 [t=0.17s]
prediction: ['[CLS] what clever by clever call what ` half what [SEP]']
[ 450/2000] tot_loss=2.200 (perp=9.732, rec=0.249, cos=0.005), tot_loss_proj:3.063 [t=0.17s]
prediction: ['[CLS] english clever by clever call by ` half what [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.115 (perp=9.377, rec=0.238, cos=0.002), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] what by clever clever call by ` half what [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.017 (perp=8.897, rec=0.234, cos=0.004), tot_loss_proj:2.670 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
[ 600/2000] tot_loss=1.995 (perp=8.897, rec=0.214, cos=0.001), tot_loss_proj:2.682 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.991 (perp=8.897, rec=0.210, cos=0.002), tot_loss_proj:2.676 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.981 (perp=8.897, rec=0.200, cos=0.002), tot_loss_proj:2.680 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
[ 750/2000] tot_loss=1.978 (perp=8.897, rec=0.197, cos=0.002), tot_loss_proj:2.675 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.966 (perp=8.897, rec=0.184, cos=0.003), tot_loss_proj:2.681 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.968 (perp=8.897, rec=0.187, cos=0.001), tot_loss_proj:2.680 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
[ 900/2000] tot_loss=1.957 (perp=8.897, rec=0.176, cos=0.002), tot_loss_proj:2.681 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.948 (perp=8.897, rec=0.167, cos=0.002), tot_loss_proj:2.680 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
Attempt swap
[1000/2000] tot_loss=1.945 (perp=8.897, rec=0.164, cos=0.001), tot_loss_proj:2.680 [t=0.17s]
prediction: ['[CLS] what by clever call by clever ` half what [SEP]']
[1050/2000] tot_loss=2.060 (perp=9.510, rec=0.157, cos=0.001), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half what [SEP]']
Attempt swap
[1100/2000] tot_loss=2.104 (perp=9.735, rec=0.155, cos=0.001), tot_loss_proj:2.776 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1150/2000] tot_loss=2.098 (perp=9.735, rec=0.150, cos=0.001), tot_loss_proj:2.775 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
[1200/2000] tot_loss=2.098 (perp=9.735, rec=0.149, cos=0.001), tot_loss_proj:2.776 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1250/2000] tot_loss=2.092 (perp=9.735, rec=0.144, cos=0.001), tot_loss_proj:2.778 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1300/2000] tot_loss=2.086 (perp=9.735, rec=0.137, cos=0.001), tot_loss_proj:2.778 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
[1350/2000] tot_loss=2.088 (perp=9.735, rec=0.139, cos=0.001), tot_loss_proj:2.775 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1400/2000] tot_loss=2.083 (perp=9.735, rec=0.135, cos=0.001), tot_loss_proj:2.771 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1450/2000] tot_loss=2.085 (perp=9.735, rec=0.137, cos=0.001), tot_loss_proj:2.781 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
[1500/2000] tot_loss=2.077 (perp=9.735, rec=0.128, cos=0.001), tot_loss_proj:2.771 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1550/2000] tot_loss=2.083 (perp=9.735, rec=0.134, cos=0.001), tot_loss_proj:2.775 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1600/2000] tot_loss=2.073 (perp=9.735, rec=0.125, cos=0.001), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
[1650/2000] tot_loss=2.069 (perp=9.735, rec=0.121, cos=0.001), tot_loss_proj:2.772 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1700/2000] tot_loss=2.070 (perp=9.735, rec=0.121, cos=0.001), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1750/2000] tot_loss=2.061 (perp=9.735, rec=0.113, cos=0.001), tot_loss_proj:2.771 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
[1800/2000] tot_loss=2.060 (perp=9.735, rec=0.112, cos=0.001), tot_loss_proj:2.777 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1850/2000] tot_loss=2.059 (perp=9.735, rec=0.111, cos=0.001), tot_loss_proj:2.770 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[1900/2000] tot_loss=2.059 (perp=9.735, rec=0.110, cos=0.001), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
[1950/2000] tot_loss=2.056 (perp=9.735, rec=0.108, cos=0.001), tot_loss_proj:2.777 [t=0.17s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Attempt swap
[2000/2000] tot_loss=2.061 (perp=9.735, rec=0.113, cos=0.001), tot_loss_proj:2.774 [t=0.21s]
prediction: ['[CLS] what by clever call too clever ` half ` [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what by clever call too clever ` half ` [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 88.889 | r: 80.000
rouge2     | fm: 47.059 | p: 50.000 | r: 44.444
rougeL     | fm: 73.684 | p: 77.778 | r: 70.000
rougeLsum  | fm: 73.684 | p: 77.778 | r: 70.000
r1fm+r2fm = 131.269

[Aggregate metrics]:
rouge1     | fm: 90.220 | p: 90.030 | r: 90.521
rouge2     | fm: 61.842 | p: 61.832 | r: 61.875
rougeL     | fm: 79.209 | p: 79.053 | r: 79.392
rougeLsum  | fm: 79.164 | p: 79.017 | r: 79.362
r1fm+r2fm = 152.063

input #50 time: 0:08:15 | total time: 7:01:20


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9992548315433463
highest_index [0]
highest [0.9992548315433463]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.826704740524292 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7897737622261047 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7381834387779236 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7270974516868591 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7253291010856628 for ['[CLS] lying acceptance [MASK] longer fence hotel rocking view knocked iaaf [SEP]']
[Init] best rec loss: 0.7200135588645935 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7114751935005188 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.7108536958694458 for ['[CLS] symbol blanc australian civil front compact foundation doubt 2018 fitness [SEP]']
[Init] best rec loss: 0.7055902481079102 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7039530873298645 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7036332488059998 for ['[CLS]rak once watching literary renamed medium toured disappointed in market [SEP]']
[Init] best perm rec loss: 0.7021721601486206 for ['[CLS] disappointed toured renamed mediumrak once in watching market literary [SEP]']
[Init] best perm rec loss: 0.7017951011657715 for ['[CLS] toured disappointed in once medium renamed market literary watchingrak [SEP]']
[Init] best perm rec loss: 0.7002806663513184 for ['[CLS] medium market watching toured disappointedrak renamed in once literary [SEP]']
[Init] best perm rec loss: 0.7000938057899475 for ['[CLS] literary renamed toured watching disappointed medium market inrak once [SEP]']
[Init] best perm rec loss: 0.6998263597488403 for ['[CLS] medium toured disappointed once watching renamed marketrak literary in [SEP]']
[Init] best perm rec loss: 0.6994193196296692 for ['[CLS] medium in market watchingrak literary renamed toured disappointed once [SEP]']
[Init] best perm rec loss: 0.6993638277053833 for ['[CLS]rak renamed once watching medium toured disappointed in market literary [SEP]']
[Init] best perm rec loss: 0.6992019414901733 for ['[CLS] watching medium disappointed renamed marketrak in literary once toured [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.813 (perp=12.125, rec=0.384, cos=0.004), tot_loss_proj:3.844 [t=0.17s]
prediction: ['[CLS] laws least baritone let has flash between appears about sucks [SEP]']
[ 100/2000] tot_loss=2.739 (perp=12.250, rec=0.286, cos=0.003), tot_loss_proj:3.636 [t=0.17s]
prediction: ['[CLS] laws sucks baritone holds has funny moment drama or sucks [SEP]']
[ 150/2000] tot_loss=2.467 (perp=11.166, rec=0.228, cos=0.006), tot_loss_proj:3.224 [t=0.17s]
prediction: ['[CLS] sucks sucks laugh holds has funny moment and or sucks [SEP]']
[ 200/2000] tot_loss=2.255 (perp=10.224, rec=0.189, cos=0.022), tot_loss_proj:3.041 [t=0.17s]
prediction: ['[CLS] sucks sucks laugh but has funny moment and or sucks [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.261 (perp=10.544, rec=0.149, cos=0.003), tot_loss_proj:2.786 [t=0.17s]
prediction: ['[CLS] sucks sucks but has funny moment indie tonight or sucks [SEP]']
[ 300/2000] tot_loss=1.933 (perp=9.020, rec=0.128, cos=0.001), tot_loss_proj:2.796 [t=0.17s]
prediction: ['[CLS] sucks sucks but has funny moment. when or sucks [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.612 (perp=7.476, rec=0.114, cos=0.003), tot_loss_proj:2.205 [t=0.17s]
prediction: ['[CLS] two sucks but has funny moment. or sucks. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.576 (perp=7.284, rec=0.116, cos=0.003), tot_loss_proj:2.104 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[ 450/2000] tot_loss=1.567 (perp=7.284, rec=0.108, cos=0.002), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.559 (perp=7.284, rec=0.100, cos=0.002), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.559 (perp=7.284, rec=0.101, cos=0.002), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[ 600/2000] tot_loss=1.565 (perp=7.284, rec=0.106, cos=0.002), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.553 (perp=7.284, rec=0.095, cos=0.001), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.558 (perp=7.284, rec=0.097, cos=0.004), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[ 750/2000] tot_loss=1.559 (perp=7.284, rec=0.100, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.561 (perp=7.284, rec=0.103, cos=0.001), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.553 (perp=7.284, rec=0.095, cos=0.001), tot_loss_proj:2.096 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[ 900/2000] tot_loss=1.551 (perp=7.284, rec=0.093, cos=0.001), tot_loss_proj:2.097 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.550 (perp=7.284, rec=0.091, cos=0.001), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.553 (perp=7.284, rec=0.095, cos=0.001), tot_loss_proj:2.097 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[1050/2000] tot_loss=1.546 (perp=7.284, rec=0.087, cos=0.002), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.553 (perp=7.284, rec=0.095, cos=0.001), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.553 (perp=7.284, rec=0.095, cos=0.001), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[1200/2000] tot_loss=1.547 (perp=7.284, rec=0.088, cos=0.001), tot_loss_proj:2.097 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.553 (perp=7.284, rec=0.095, cos=0.001), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.548 (perp=7.284, rec=0.090, cos=0.001), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[1350/2000] tot_loss=1.545 (perp=7.284, rec=0.086, cos=0.001), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.544 (perp=7.284, rec=0.086, cos=0.001), tot_loss_proj:2.103 [t=0.19s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.553 (perp=7.284, rec=0.095, cos=0.001), tot_loss_proj:2.098 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[1500/2000] tot_loss=1.551 (perp=7.284, rec=0.093, cos=0.001), tot_loss_proj:2.098 [t=0.20s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.548 (perp=7.284, rec=0.089, cos=0.001), tot_loss_proj:2.095 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.547 (perp=7.284, rec=0.089, cos=0.001), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[1650/2000] tot_loss=1.548 (perp=7.284, rec=0.090, cos=0.001), tot_loss_proj:2.097 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.548 (perp=7.284, rec=0.090, cos=0.001), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.549 (perp=7.284, rec=0.090, cos=0.001), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[1800/2000] tot_loss=1.537 (perp=7.284, rec=0.079, cos=0.001), tot_loss_proj:2.098 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.538 (perp=7.284, rec=0.080, cos=0.001), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.549 (perp=7.284, rec=0.091, cos=0.001), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
[1950/2000] tot_loss=1.544 (perp=7.284, rec=0.085, cos=0.001), tot_loss_proj:2.096 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.548 (perp=7.284, rec=0.090, cos=0.001), tot_loss_proj:2.096 [t=0.17s]
prediction: ['[CLS] two sucks. but has funny moment or sucks. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] two sucks. but has funny moment or sucks. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 90.000 | r: 90.000
rouge2     | fm: 44.444 | p: 44.444 | r: 44.444
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 134.444

[Aggregate metrics]:
rouge1     | fm: 90.191 | p: 89.991 | r: 90.475
rouge2     | fm: 61.430 | p: 61.369 | r: 61.503
rougeL     | fm: 79.085 | p: 78.923 | r: 79.318
rougeLsum  | fm: 79.068 | p: 78.925 | r: 79.222
r1fm+r2fm = 151.621

input #51 time: 0:08:21 | total time: 7:09:42


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9992769471396806
highest_index [0]
highest [0.9992769471396806]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9633553624153137 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9276461005210876 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8949947357177734 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.8681666254997253 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.7894576191902161 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7760429382324219 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7046040296554565 for ['[CLS] vocabulary football expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.589 (perp=11.737, rec=0.237, cos=0.004), tot_loss_proj:2.667 [t=0.17s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 100/2000] tot_loss=2.502 (perp=11.737, rec=0.153, cos=0.002), tot_loss_proj:2.663 [t=0.18s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 150/2000] tot_loss=2.456 (perp=11.737, rec=0.107, cos=0.002), tot_loss_proj:2.659 [t=0.17s]
prediction: ['[CLS] trailer trash trash [SEP]']
[ 200/2000] tot_loss=2.443 (perp=11.737, rec=0.094, cos=0.001), tot_loss_proj:2.663 [t=0.17s]
prediction: ['[CLS] trailer trash trash [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.798 (perp=8.482, rec=0.099, cos=0.002), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.780 (perp=8.482, rec=0.082, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.776 (perp=8.482, rec=0.078, cos=0.001), tot_loss_proj:2.130 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.766 (perp=8.482, rec=0.068, cos=0.001), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.767 (perp=8.482, rec=0.069, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.768 (perp=8.482, rec=0.070, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.765 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.125 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.130 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.762 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.756 (perp=8.482, rec=0.058, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.769 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.767 (perp=8.482, rec=0.069, cos=0.001), tot_loss_proj:2.125 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.748 (perp=8.482, rec=0.050, cos=0.001), tot_loss_proj:2.125 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.747 (perp=8.482, rec=0.050, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.130 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.769 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.756 (perp=8.482, rec=0.058, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.755 (perp=8.482, rec=0.058, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.758 (perp=8.482, rec=0.060, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.769 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.130 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.757 (perp=8.482, rec=0.060, cos=0.001), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.130 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.764 (perp=8.482, rec=0.066, cos=0.001), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.757 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.770 (perp=8.482, rec=0.072, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.125 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.769 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.126 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.752 (perp=8.482, rec=0.054, cos=0.001), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 90.376 | p: 90.160 | r: 90.647
rouge2     | fm: 60.451 | p: 60.411 | r: 60.524
rougeL     | fm: 79.216 | p: 79.068 | r: 79.429
rougeLsum  | fm: 79.027 | p: 78.822 | r: 79.260
r1fm+r2fm = 150.827

input #52 time: 0:07:59 | total time: 7:17:41


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9993462296030828
highest_index [0]
highest [0.9993462296030828]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9457181096076965 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.862006664276123 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8316056728363037 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7958467602729797 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7199336886405945 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.6997024416923523 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6986270546913147 for ['[CLS] towerbal [SEP]']
[Init] best rec loss: 0.6915310621261597 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6842321157455444 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6748745441436768 for ['[CLS] el peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.807 (perp=12.384, rec=0.315, cos=0.015), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] flinch flinched [SEP]']
[ 100/2000] tot_loss=2.699 (perp=12.492, rec=0.197, cos=0.004), tot_loss_proj:3.328 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.640 (perp=12.492, rec=0.140, cos=0.002), tot_loss_proj:3.329 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=2.640 (perp=12.492, rec=0.140, cos=0.001), tot_loss_proj:3.351 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.631 (perp=12.492, rec=0.131, cos=0.002), tot_loss_proj:3.344 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 300/2000] tot_loss=2.635 (perp=12.492, rec=0.130, cos=0.007), tot_loss_proj:3.340 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.603 (perp=12.492, rec=0.103, cos=0.001), tot_loss_proj:3.335 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.717 (perp=8.090, rec=0.097, cos=0.003), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.690 (perp=8.090, rec=0.071, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.691 (perp=8.090, rec=0.072, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.680 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.685 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.689 (perp=8.090, rec=0.069, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.690 (perp=8.090, rec=0.071, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.665 (perp=8.090, rec=0.046, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.683 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.687 (perp=8.090, rec=0.068, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.690 (perp=8.090, rec=0.071, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.692 (perp=8.090, rec=0.073, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.668 (perp=8.090, rec=0.049, cos=0.001), tot_loss_proj:1.692 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.691 (perp=8.090, rec=0.072, cos=0.001), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.685 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.682 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.586 | p: 90.403 | r: 90.858
rouge2     | fm: 60.939 | p: 60.887 | r: 60.994
rougeL     | fm: 79.503 | p: 79.354 | r: 79.673
rougeLsum  | fm: 79.340 | p: 79.197 | r: 79.486
r1fm+r2fm = 151.525

input #53 time: 0:08:30 | total time: 7:26:12


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9991885466091153
highest_index [0]
highest [0.9991885466091153]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.9532368183135986 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.8024941086769104 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7537968754768372 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.7135902047157288 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7061654329299927 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.7006915807723999 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.352 (perp=9.350, rec=0.457, cos=0.025), tot_loss_proj:3.056 [t=0.17s]
prediction: ['[CLS] topics style [SEP]']
[ 100/2000] tot_loss=2.590 (perp=11.553, rec=0.274, cos=0.005), tot_loss_proj:2.857 [t=0.17s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.458 (perp=11.553, rec=0.145, cos=0.003), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.422 (perp=11.553, rec=0.109, cos=0.002), tot_loss_proj:2.889 [t=0.19s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.750 (perp=8.198, rec=0.106, cos=0.004), tot_loss_proj:1.753 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.722 (perp=8.198, rec=0.081, cos=0.002), tot_loss_proj:1.735 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.711 (perp=8.198, rec=0.070, cos=0.001), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.721 (perp=8.198, rec=0.079, cos=0.002), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.711 (perp=8.198, rec=0.068, cos=0.003), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.711 (perp=8.198, rec=0.070, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.708 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.711 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.713 (perp=8.198, rec=0.072, cos=0.002), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.712 (perp=8.198, rec=0.070, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.711 (perp=8.198, rec=0.070, cos=0.002), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.700 (perp=8.198, rec=0.059, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.704 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.706 (perp=8.198, rec=0.065, cos=0.002), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.713 (perp=8.198, rec=0.072, cos=0.002), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.696 (perp=8.198, rec=0.055, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.732 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.694 (perp=8.198, rec=0.053, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.714 (perp=8.198, rec=0.073, cos=0.002), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.708 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.707 (perp=8.198, rec=0.065, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.697 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.698 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.698 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.700 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.691 (perp=8.198, rec=0.050, cos=0.002), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.708 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.690 (perp=8.198, rec=0.049, cos=0.002), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.704 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.699 | p: 90.508 | r: 90.982
rouge2     | fm: 61.899 | p: 61.891 | r: 61.989
rougeL     | fm: 79.756 | p: 79.633 | r: 79.947
rougeLsum  | fm: 79.783 | p: 79.678 | r: 79.877
r1fm+r2fm = 152.598

input #54 time: 0:07:54 | total time: 7:34:07


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9991205863745829
highest_index [0]
highest [0.9991205863745829]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.9149343371391296 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8663113713264465 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7905805706977844 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7703065872192383 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7634938359260559 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7582106590270996 for ['[CLS] single argentine patent [SEP]']
[Init] best rec loss: 0.7517237663269043 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.712469220161438 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.703285276889801 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7019903659820557 for ['[CLS] post holly stride [SEP]']
[Init] best perm rec loss: 0.7008416652679443 for ['[CLS] stride post holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.959 (perp=12.362, rec=0.473, cos=0.014), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS] slipping reverted bc [SEP]']
[ 100/2000] tot_loss=2.373 (perp=10.151, rec=0.339, cos=0.004), tot_loss_proj:3.963 [t=0.17s]
prediction: ['[CLS] easily settled settled [SEP]']
[ 150/2000] tot_loss=2.167 (perp=9.485, rec=0.261, cos=0.010), tot_loss_proj:3.805 [t=0.17s]
prediction: ['[CLS] easily settles easily [SEP]']
[ 200/2000] tot_loss=2.119 (perp=9.485, rec=0.219, cos=0.003), tot_loss_proj:3.801 [t=0.17s]
prediction: ['[CLS] easily settles easily [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.017 (perp=9.088, rec=0.196, cos=0.003), tot_loss_proj:3.666 [t=0.17s]
prediction: ['[CLS] settles easily easily [SEP]']
[ 300/2000] tot_loss=1.990 (perp=9.088, rec=0.171, cos=0.002), tot_loss_proj:3.680 [t=0.17s]
prediction: ['[CLS] settles easily easily [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.827 (perp=8.671, rec=0.092, cos=0.002), tot_loss_proj:1.803 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.815 (perp=8.671, rec=0.079, cos=0.002), tot_loss_proj:1.804 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.799 (perp=8.671, rec=0.063, cos=0.002), tot_loss_proj:1.805 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.806 (perp=8.671, rec=0.070, cos=0.002), tot_loss_proj:1.802 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.795 (perp=8.671, rec=0.059, cos=0.002), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.803 (perp=8.671, rec=0.067, cos=0.002), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.803 (perp=8.671, rec=0.067, cos=0.002), tot_loss_proj:1.807 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.806 (perp=8.671, rec=0.071, cos=0.002), tot_loss_proj:1.807 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.807 (perp=8.671, rec=0.071, cos=0.002), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.808 (perp=8.671, rec=0.072, cos=0.002), tot_loss_proj:1.803 [t=0.19s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.788 (perp=8.671, rec=0.052, cos=0.002), tot_loss_proj:1.809 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.801 (perp=8.671, rec=0.066, cos=0.002), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.803 (perp=8.671, rec=0.067, cos=0.002), tot_loss_proj:1.805 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.002), tot_loss_proj:1.816 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.797 (perp=8.671, rec=0.061, cos=0.002), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.791 (perp=8.671, rec=0.055, cos=0.002), tot_loss_proj:1.801 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.002), tot_loss_proj:1.803 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.793 (perp=8.671, rec=0.057, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.794 (perp=8.671, rec=0.059, cos=0.002), tot_loss_proj:1.792 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.808 (perp=8.671, rec=0.072, cos=0.002), tot_loss_proj:1.815 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.799 (perp=8.671, rec=0.064, cos=0.002), tot_loss_proj:1.807 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.793 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.803 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.002), tot_loss_proj:1.788 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.799 (perp=8.671, rec=0.063, cos=0.002), tot_loss_proj:1.809 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.798 (perp=8.671, rec=0.062, cos=0.002), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.788 (perp=8.671, rec=0.052, cos=0.002), tot_loss_proj:1.801 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.798 (perp=8.671, rec=0.062, cos=0.002), tot_loss_proj:1.803 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.799 (perp=8.671, rec=0.063, cos=0.002), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.787 (perp=8.671, rec=0.051, cos=0.002), tot_loss_proj:1.805 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.795 (perp=8.671, rec=0.059, cos=0.002), tot_loss_proj:1.805 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.805 (perp=8.671, rec=0.069, cos=0.002), tot_loss_proj:1.805 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.801 (perp=8.671, rec=0.065, cos=0.002), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.886 | p: 90.688 | r: 91.121
rouge2     | fm: 62.603 | p: 62.597 | r: 62.644
rougeL     | fm: 80.140 | p: 80.021 | r: 80.372
rougeLsum  | fm: 80.041 | p: 79.914 | r: 80.213
r1fm+r2fm = 153.489

input #55 time: 0:08:30 | total time: 7:42:37


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.9992743912224646
highest_index [0]
highest [0.9992743912224646]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.932321310043335 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9175447821617126 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9035267233848572 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.8958414793014526 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.8944609761238098 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8827247619628906 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.8799951076507568 for ['[CLS] almost wall up emotional defeated leadership acquainted variables spectroscopy dive realm with consolation households cas potential obsidian handed existing been organization [SEP]']
[Init] best perm rec loss: 0.8781517744064331 for ['[CLS] organization almost been emotional consolation defeated existing obsidian households acquainted with spectroscopy dive wall leadership up cas handed potential realm variables [SEP]']
[Init] best perm rec loss: 0.8778687119483948 for ['[CLS] cas variables wall emotional potential dive spectroscopy leadership organization obsidian existing consolation with almost defeated realm handed up been acquainted households [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.733 (perp=11.962, rec=0.338, cos=0.003), tot_loss_proj:3.415 [t=0.18s]
prediction: ['[CLS] hospital windshieldes old analysis to damaged else law recording over damage absolutely quit stupid ads poll that diane concept obvious [SEP]']
[ 100/2000] tot_loss=2.457 (perp=11.000, rec=0.254, cos=0.003), tot_loss_proj:3.198 [t=0.17s]
prediction: ['[CLS] films hitshouse costly analysis films damaged after law films obviously damage films whom costly films costlystream inability project damage [SEP]']
[ 150/2000] tot_loss=2.656 (perp=12.251, rec=0.204, cos=0.001), tot_loss_proj:3.470 [t=0.17s]
prediction: ['[CLS] films causeload costly analysis pradesh damage worth loads films kansas damage never whom costly films costly whichtruct project never [SEP]']
[ 200/2000] tot_loss=2.451 (perp=11.385, rec=0.172, cos=0.001), tot_loss_proj:3.118 [t=0.17s]
prediction: ['[CLS] films cause loads costly fix deposits damage that loads films decades damage years whom costly films costly whichiness analysis never [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.302 (perp=10.754, rec=0.150, cos=0.002), tot_loss_proj:2.905 [t=0.17s]
prediction: ['[CLS] years cause loads costly fix consumption damage that loads films years damage years considered costly costly films whichred analysis never [SEP]']
[ 300/2000] tot_loss=2.149 (perp=10.078, rec=0.133, cos=0.001), tot_loss_proj:2.821 [t=0.17s]
prediction: ['[CLS] years cause loads costly fix cause damage that loads films years damage years of costly costly films whichred analysis never [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.131 (perp=10.067, rec=0.117, cos=0.001), tot_loss_proj:2.812 [t=0.17s]
prediction: ['[CLS] years cause loads costly fix years damage that loads films cause damage years of costly costly films whichpara analysis never [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.073 (perp=9.771, rec=0.118, cos=0.001), tot_loss_proj:2.738 [t=0.17s]
prediction: ['[CLS] years cause loads costly damage fix years that loads films cause damage years of costly costly films whichpara analysis never [SEP]']
[ 450/2000] tot_loss=2.116 (perp=10.044, rec=0.106, cos=0.001), tot_loss_proj:2.765 [t=0.17s]
prediction: ['[CLS] years cause loads costly damage fix years that loads films of damage years of costly costly films whichpara analysis never [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.160 (perp=10.304, rec=0.098, cos=0.001), tot_loss_proj:2.805 [t=0.17s]
prediction: ['[CLS] years cause loads costly damage fix films that loads years of damage years and costlyble films whichpara analysis never [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.044 (perp=9.733, rec=0.096, cos=0.001), tot_loss_proj:2.717 [t=0.17s]
prediction: ['[CLS] years cause will costly damage fix decades that loads of of damage years andparable films which costly analysis never [SEP]']
[ 600/2000] tot_loss=2.039 (perp=9.733, rec=0.091, cos=0.001), tot_loss_proj:2.713 [t=0.22s]
prediction: ['[CLS] years cause will costly damage fix decades that loads of of damage years andparable films which costly analysis never [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.945 (perp=9.283, rec=0.087, cos=0.001), tot_loss_proj:2.750 [t=0.18s]
prediction: ['[CLS] years cause will of damage fix decades that loads of costly damage years andparable films which costly analysis never [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.812 (perp=8.612, rec=0.088, cos=0.001), tot_loss_proj:2.765 [t=0.17s]
prediction: ['[CLS] years will of damage fix films that loads of costly damage cause years andparable films which costly analysis never [SEP]']
[ 750/2000] tot_loss=1.809 (perp=8.612, rec=0.085, cos=0.001), tot_loss_proj:2.763 [t=0.18s]
prediction: ['[CLS] years will of damage fix films that loads of costly damage cause years andparable films which costly analysis never [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.761 (perp=8.378, rec=0.084, cos=0.001), tot_loss_proj:3.336 [t=0.17s]
prediction: ['[CLS] years will fix damage of films that loads of costly damage cause years andparable films which costly analysis never [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.762 (perp=8.408, rec=0.079, cos=0.001), tot_loss_proj:3.129 [t=0.17s]
prediction: ['[CLS] ir will fix damage of films that loads of costly damage cause years andparable films which costly analysis never [SEP]']
[ 900/2000] tot_loss=1.763 (perp=8.408, rec=0.080, cos=0.001), tot_loss_proj:3.130 [t=0.17s]
prediction: ['[CLS] ir will fix damage of films that loads of costly damage cause years andparable films which costly analysis never [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.723 (perp=8.198, rec=0.082, cos=0.001), tot_loss_proj:2.949 [t=0.17s]
prediction: ['[CLS] ir will fix damage of films which loads of costly damage cause years andparable films that costly analysis never [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.700 (perp=8.084, rec=0.082, cos=0.001), tot_loss_proj:2.858 [t=0.17s]
prediction: ['[CLS] ir will fix damage of costly films which loads of damage cause years andparable films that costly analysis never [SEP]']
[1050/2000] tot_loss=1.698 (perp=8.084, rec=0.079, cos=0.001), tot_loss_proj:2.857 [t=0.17s]
prediction: ['[CLS] ir will fix damage of costly films which loads of damage cause years andparable films that costly analysis never [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.682 (perp=7.990, rec=0.082, cos=0.001), tot_loss_proj:2.900 [t=0.17s]
prediction: ['[CLS] ir will fix damage of costly films which cause loads of damage years andparable films that costly analysis never [SEP]']
Attempt swap
[1150/2000] tot_loss=1.673 (perp=7.990, rec=0.074, cos=0.001), tot_loss_proj:2.900 [t=0.17s]
prediction: ['[CLS] ir will fix damage of costly films which cause loads of damage years andparable films that costly analysis never [SEP]']
[1200/2000] tot_loss=1.679 (perp=7.990, rec=0.080, cos=0.001), tot_loss_proj:2.898 [t=0.17s]
prediction: ['[CLS] ir will fix damage of costly films which cause loads of damage years andparable films that costly analysis never [SEP]']
Attempt swap
[1250/2000] tot_loss=1.678 (perp=7.990, rec=0.079, cos=0.001), tot_loss_proj:2.901 [t=0.19s]
prediction: ['[CLS] ir will fix damage of costly films which cause loads of damage years andparable films that costly analysis never [SEP]']
Attempt swap
[1300/2000] tot_loss=1.675 (perp=7.990, rec=0.075, cos=0.001), tot_loss_proj:2.903 [t=0.17s]
prediction: ['[CLS] ir will fix damage of costly films which cause loads of damage years andparable films that costly analysis never [SEP]']
[1350/2000] tot_loss=1.673 (perp=7.990, rec=0.073, cos=0.001), tot_loss_proj:2.902 [t=0.18s]
prediction: ['[CLS] ir will fix damage of costly films which cause loads of damage years andparable films that costly analysis never [SEP]']
Attempt swap
[1400/2000] tot_loss=1.679 (perp=7.990, rec=0.080, cos=0.001), tot_loss_proj:2.898 [t=0.18s]
prediction: ['[CLS] ir will fix damage of costly films which cause loads of damage years andparable films that costly analysis never [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.669 (perp=7.935, rec=0.080, cos=0.001), tot_loss_proj:2.941 [t=0.18s]
prediction: ['[CLS] ir will fix damage of films which cause costly loads of damage years andparable films that costly analysis never [SEP]']
[1500/2000] tot_loss=1.660 (perp=7.935, rec=0.072, cos=0.001), tot_loss_proj:2.944 [t=0.18s]
prediction: ['[CLS] ir will fix damage of films which cause costly loads of damage years andparable films that costly analysis never [SEP]']
Attempt swap
[1550/2000] tot_loss=1.666 (perp=7.935, rec=0.077, cos=0.001), tot_loss_proj:2.950 [t=0.18s]
prediction: ['[CLS] ir will fix damage of films which cause costly loads of damage years andparable films that costly analysis never [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.612 (perp=7.690, rec=0.072, cos=0.001), tot_loss_proj:2.880 [t=0.20s]
prediction: ['[CLS] ir will fix damage of films which cause costly damage loads of years andparable films that costly analysis never [SEP]']
[1650/2000] tot_loss=1.617 (perp=7.690, rec=0.077, cos=0.001), tot_loss_proj:2.879 [t=0.19s]
prediction: ['[CLS] ir will fix damage of films which cause costly damage loads of years andparable films that costly analysis never [SEP]']
Attempt swap
[1700/2000] tot_loss=1.613 (perp=7.690, rec=0.074, cos=0.001), tot_loss_proj:2.883 [t=0.17s]
prediction: ['[CLS] ir will fix damage of films which cause costly damage loads of years andparable films that costly analysis never [SEP]']
Attempt swap
[1750/2000] tot_loss=1.612 (perp=7.690, rec=0.072, cos=0.001), tot_loss_proj:2.881 [t=0.17s]
prediction: ['[CLS] ir will fix damage of films which cause costly damage loads of years andparable films that costly analysis never [SEP]']
[1800/2000] tot_loss=1.613 (perp=7.690, rec=0.074, cos=0.001), tot_loss_proj:2.880 [t=0.19s]
prediction: ['[CLS] ir will fix damage of films which cause costly damage loads of years andparable films that costly analysis never [SEP]']
Attempt swap
[1850/2000] tot_loss=1.616 (perp=7.690, rec=0.076, cos=0.001), tot_loss_proj:2.883 [t=0.17s]
prediction: ['[CLS] ir will fix damage of films which cause costly damage loads of years andparable films that costly analysis never [SEP]']
Attempt swap
[1900/2000] tot_loss=1.619 (perp=7.690, rec=0.080, cos=0.001), tot_loss_proj:2.881 [t=0.17s]
prediction: ['[CLS] ir will fix damage of films which cause costly damage loads of years andparable films that costly analysis never [SEP]']
[1950/2000] tot_loss=1.774 (perp=8.490, rec=0.074, cos=0.001), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] ir will fix damage of films which causere damage loads of years andparable films that costly analysis never [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.648 (perp=7.859, rec=0.075, cos=0.001), tot_loss_proj:3.187 [t=0.17s]
prediction: ['[CLS] will fix damage of films which cause irre damage loads of years andparable films that costly analysis never [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] years will of damage fix films that loads of costly damage cause years andparable films which costly analysis never [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.927 | p: 80.952 | r: 85.000
rouge2     | fm: 20.513 | p: 20.000 | r: 21.053
rougeL     | fm: 48.780 | p: 47.619 | r: 50.000
rougeLsum  | fm: 48.780 | p: 47.619 | r: 50.000
r1fm+r2fm = 103.440

[Aggregate metrics]:
rouge1     | fm: 90.790 | p: 90.571 | r: 91.108
rouge2     | fm: 61.711 | p: 61.691 | r: 61.794
rougeL     | fm: 79.817 | p: 79.639 | r: 80.016
rougeLsum  | fm: 79.544 | p: 79.396 | r: 79.721
r1fm+r2fm = 152.501

input #56 time: 0:09:19 | total time: 7:51:57


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9993815950585874
highest_index [0]
highest [0.9993815950585874]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8631657361984253 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.7994511723518372 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.705524206161499 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6581541299819946 for ['[CLS] expressed [SEP]']
[Init] best rec loss: 0.643149733543396 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.796 (perp=12.282, rec=0.312, cos=0.028), tot_loss_proj:2.517 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.553 (perp=12.282, rec=0.092, cos=0.005), tot_loss_proj:2.510 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.537 (perp=12.282, rec=0.079, cos=0.001), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.522 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.526 (perp=12.282, rec=0.069, cos=0.001), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.551 (perp=12.282, rec=0.071, cos=0.023), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.521 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.511 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.525 (perp=12.282, rec=0.068, cos=0.001), tot_loss_proj:2.510 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.504 (perp=12.282, rec=0.047, cos=0.001), tot_loss_proj:2.517 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.529 (perp=12.282, rec=0.071, cos=0.001), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.512 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.506 (perp=12.282, rec=0.048, cos=0.001), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.500 (perp=12.282, rec=0.043, cos=0.001), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.526 (perp=12.282, rec=0.069, cos=0.001), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.530 (perp=12.282, rec=0.072, cos=0.001), tot_loss_proj:2.522 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.529 (perp=12.282, rec=0.072, cos=0.001), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.517 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.528 (perp=12.282, rec=0.070, cos=0.001), tot_loss_proj:2.527 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.512 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.517 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.514 (perp=12.282, rec=0.056, cos=0.001), tot_loss_proj:2.530 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.521 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.519 (perp=12.282, rec=0.062, cos=0.001), tot_loss_proj:2.522 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.512 (perp=12.282, rec=0.055, cos=0.001), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.517 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.518 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.522 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.531 (perp=12.282, rec=0.073, cos=0.001), tot_loss_proj:2.527 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.516 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.519 (perp=12.282, rec=0.062, cos=0.001), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.512 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.526 (perp=12.282, rec=0.068, cos=0.001), tot_loss_proj:2.511 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.531 (perp=12.282, rec=0.074, cos=0.001), tot_loss_proj:2.506 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.525 (perp=12.282, rec=0.067, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.507 (perp=12.282, rec=0.049, cos=0.001), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.538 (perp=12.282, rec=0.080, cos=0.001), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.499 (perp=12.282, rec=0.041, cos=0.001), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.523 (perp=12.282, rec=0.066, cos=0.001), tot_loss_proj:2.532 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.914 | p: 90.723 | r: 91.160
rouge2     | fm: 62.682 | p: 62.635 | r: 62.732
rougeL     | fm: 80.112 | p: 79.889 | r: 80.315
rougeLsum  | fm: 79.851 | p: 79.719 | r: 80.050
r1fm+r2fm = 153.595

input #57 time: 0:08:13 | total time: 8:00:11


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9992685151622416
highest_index [0]
highest [0.9992685151622416]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.9649522304534912 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9525012969970703 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9179250597953796 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9173662066459656 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 0.9167462587356567 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.8904667496681213 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.8734395503997803 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.872577428817749 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est herself [SEP]']
[Init] best perm rec loss: 0.872272789478302 for ['[CLS] verde finishedager thighs beauty estitical trade zack herselfuration apart chieftyle down serious [SEP]']
[Init] best perm rec loss: 0.8679993748664856 for ['[CLS] down herselfitical verde zack finished apart serious chiefuration thighs tradetyle beauty estager [SEP]']
[Init] best perm rec loss: 0.8665047287940979 for ['[CLS]itical est trade zack serioustyle herself down thighs finished beauty apart chiefageruration verde [SEP]']
[Init] best perm rec loss: 0.8653094172477722 for ['[CLS] beauty aparturation thighs trade verde zack down chief finished herself serioustyle estiticalager [SEP]']
[Init] best perm rec loss: 0.8635257482528687 for ['[CLS] est chief beauty down zack serious tradetyle verde thighsurationitical apartager herself finished [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.590 (perp=14.351, rec=0.706, cos=0.014), tot_loss_proj:4.783 [t=0.17s]
prediction: ['[CLS] creepy saving banned about endure archduke pie structure some lasting never shoes less cruiser tristan player [SEP]']
[ 100/2000] tot_loss=3.496 (perp=14.188, rec=0.637, cos=0.022), tot_loss_proj:4.313 [t=0.17s]
prediction: ['[CLS] ass tub banned from bryan indiana curriculum context some an non shoes wayrral mundane fight [SEP]']
[ 150/2000] tot_loss=3.104 (perp=12.540, rec=0.575, cos=0.021), tot_loss_proj:4.484 [t=0.17s]
prediction: ['[CLS]qual tub necessity from • indiana curriculum context some an non land way stormed ideal story [SEP]']
[ 200/2000] tot_loss=2.815 (perp=11.429, rec=0.525, cos=0.004), tot_loss_proj:4.223 [t=0.17s]
prediction: ['[CLS] corruption tub necessity from capturing indiana curriculum fact some an disappeared touching that of ideal story [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.792 (perp=11.383, rec=0.511, cos=0.005), tot_loss_proj:4.164 [t=0.17s]
prediction: ['[CLS] corruption his necessity behind capturing indiana curriculumjured of an disappeared encounter and touchingitia story [SEP]']
[ 300/2000] tot_loss=3.123 (perp=13.150, rec=0.488, cos=0.005), tot_loss_proj:4.535 [t=0.17s]
prediction: ['[CLS] goo his constructed behind capturing indiana boundaryjured story an disappeared encounter a touchingitia story [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.891 (perp=12.068, rec=0.475, cos=0.002), tot_loss_proj:4.324 [t=0.17s]
prediction: ['[CLS] hisided constructed behind o indiana layersjured story an disappeared love a touchingitia story [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=3.011 (perp=12.633, rec=0.483, cos=0.002), tot_loss_proj:4.441 [t=0.17s]
prediction: ['[CLS] his goo constructed story o indiana layersjured conduct an disappeared love an shootitia story [SEP]']
[ 450/2000] tot_loss=2.883 (perp=12.053, rec=0.470, cos=0.001), tot_loss_proj:4.313 [t=0.17s]
prediction: ['[CLS] his goo constructed story ideal indiana layersjured conduct an disappeared love an shoot emerged story [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.743 (perp=11.434, rec=0.453, cos=0.004), tot_loss_proj:4.157 [t=0.17s]
prediction: ['[CLS] his goo constructed an ideal indiana layersjured the is disappeared love story workplaceitia story [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.568 (perp=10.552, rec=0.455, cos=0.002), tot_loss_proj:3.967 [t=0.19s]
prediction: ['[CLS] his fraud constructed an inspirational indiana layers generated the disappeared love story workplace isitia story [SEP]']
[ 600/2000] tot_loss=2.648 (perp=10.993, rec=0.445, cos=0.004), tot_loss_proj:3.433 [t=0.19s]
prediction: ['[CLS] arranged fraud constructed an inspirational indiana twenty generated the disappeared love story workplace is sensual story [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.577 (perp=10.656, rec=0.441, cos=0.005), tot_loss_proj:3.270 [t=0.17s]
prediction: ['[CLS] arranged fraud constructed an inspirational fact twenty generated disappeared love story the workplace is sensual story [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.632 (perp=11.009, rec=0.428, cos=0.002), tot_loss_proj:3.260 [t=0.17s]
prediction: ['[CLS] arranged fraud constructed an capturing twenty fact generated disappeared love story the workplace is sensual story [SEP]']
[ 750/2000] tot_loss=2.829 (perp=12.025, rec=0.422, cos=0.003), tot_loss_proj:3.612 [t=0.17s]
prediction: ['[CLS] arranged fraud constructed an capturing twenty fact charley disappeared love story establishment packaging is sensual story [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.744 (perp=11.473, rec=0.430, cos=0.019), tot_loss_proj:3.222 [t=0.17s]
prediction: ['[CLS] twenty arranged luxurious constructed an capturing fact charley disappeared love story establishment packaging is sensual story [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.525 (perp=10.478, rec=0.427, cos=0.002), tot_loss_proj:3.276 [t=0.17s]
prediction: ['[CLS] fact arranged luxurious constructed an inspirational twenty charley disappeared love story establishment packaging is sensual story [SEP]']
[ 900/2000] tot_loss=2.512 (perp=10.429, rec=0.424, cos=0.003), tot_loss_proj:3.167 [t=0.17s]
prediction: ['[CLS] fact arranged identity constructed an inspirational twenty charley disappeared love story establishment packaging is sensual story [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.603 (perp=10.925, rec=0.416, cos=0.002), tot_loss_proj:3.079 [t=0.17s]
prediction: ['[CLS] fact arranged identity constructed an capturing charley twenty disappeared love story establishmentbard is sensual story [SEP]']
Attempt swap
[1000/2000] tot_loss=2.660 (perp=11.243, rec=0.410, cos=0.001), tot_loss_proj:3.023 [t=0.17s]
prediction: ['[CLS] including arranged identity constructed an capturing charley twenty disappeared love story establishmentbard is sensual story [SEP]']
[1050/2000] tot_loss=2.664 (perp=11.243, rec=0.410, cos=0.006), tot_loss_proj:3.019 [t=0.17s]
prediction: ['[CLS] including arranged identity constructed an capturing charley twenty disappeared love story establishmentbard is sensual story [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.595 (perp=10.923, rec=0.409, cos=0.001), tot_loss_proj:2.960 [t=0.17s]
prediction: ['[CLS] including arranged identity constructed an charley capturing twenty disappeared love story establishmentbard is sensual story [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.585 (perp=10.798, rec=0.423, cos=0.002), tot_loss_proj:2.948 [t=0.17s]
prediction: ['[CLS] plus arranged identity inspirational an establishment capturing twenty disappeared love story charleybard is sensual story [SEP]']
[1200/2000] tot_loss=2.559 (perp=10.746, rec=0.407, cos=0.002), tot_loss_proj:3.835 [t=0.17s]
prediction: ['[CLS] plus arranged identity constructed an experience capturing twenty disappeared love story charleybard is obtain story [SEP]']
Attempt swap
[1250/2000] tot_loss=2.559 (perp=10.746, rec=0.409, cos=0.001), tot_loss_proj:3.838 [t=0.17s]
prediction: ['[CLS] plus arranged identity constructed an experience capturing twenty disappeared love story charleybard is obtain story [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.501 (perp=10.467, rec=0.406, cos=0.002), tot_loss_proj:3.748 [t=0.17s]
prediction: ['[CLS] plus arranged identity constructed an experience capturing twenty disappeared love story charley isbard obtain story [SEP]']
[1350/2000] tot_loss=2.472 (perp=10.328, rec=0.406, cos=0.001), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] plus arranged identity constructed an experience capturing twenty is love story charley isbard obtain story [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.582 (perp=10.865, rec=0.407, cos=0.001), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] charley arranged identity inspirational the experience capturing twenty is love story fact isbard obtain story [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=2.547 (perp=10.658, rec=0.414, cos=0.002), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] charley inspirational identity arranged the experience capturing twenty is love story fact isbard obtain story [SEP]']
[1500/2000] tot_loss=2.534 (perp=10.658, rec=0.401, cos=0.001), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] charley inspirational identity arranged the experience capturing twenty is love story fact isbard obtain story [SEP]']
Attempt swap
[1550/2000] tot_loss=2.535 (perp=10.658, rec=0.402, cos=0.000), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] charley inspirational identity arranged the experience capturing twenty is love story fact isbard obtain story [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.502 (perp=10.425, rec=0.413, cos=0.004), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] charley inspirational plus arranged the experience capturing twenty is love story identity isbard obtain story [SEP]']
[1650/2000] tot_loss=2.492 (perp=10.425, rec=0.406, cos=0.001), tot_loss_proj:3.181 [t=0.17s]
prediction: ['[CLS] charley inspirational plus arranged the experience capturing twenty is love story identity isbard obtain story [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.447 (perp=10.172, rec=0.411, cos=0.001), tot_loss_proj:3.019 [t=0.17s]
prediction: ['[CLS] charley inspirational plus arranged the experience capturing twenty is love story isbard obtain identity story [SEP]']
Attempt swap
[1750/2000] tot_loss=2.445 (perp=10.172, rec=0.409, cos=0.001), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] charley inspirational plus arranged the experience capturing twenty is love story isbard obtain identity story [SEP]']
[1800/2000] tot_loss=2.444 (perp=10.172, rec=0.408, cos=0.001), tot_loss_proj:3.012 [t=0.17s]
prediction: ['[CLS] charley inspirational plus arranged the experience capturing twenty is love story isbard obtain identity story [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.394 (perp=9.946, rec=0.404, cos=0.001), tot_loss_proj:2.922 [t=0.17s]
prediction: ['[CLS] charley twenty plus arranged the experience capturing inspirational is love story isbard obtain identity story [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.401 (perp=9.950, rec=0.410, cos=0.001), tot_loss_proj:3.483 [t=0.17s]
prediction: ['[CLS] charley twenty plus arranged the experience capturing constructed is love story obtainbard is identity story [SEP]']
[1950/2000] tot_loss=2.404 (perp=9.950, rec=0.412, cos=0.001), tot_loss_proj:3.482 [t=0.17s]
prediction: ['[CLS] charley twenty plus arranged the experience capturing constructed is love story obtainbard is identity story [SEP]']
Attempt swap
[2000/2000] tot_loss=2.396 (perp=9.950, rec=0.405, cos=0.001), tot_loss_proj:3.486 [t=0.23s]
prediction: ['[CLS] charley twenty plus arranged the experience capturing constructed is love story obtainbard is identity story [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] charley inspirational plus arranged the experience capturing twenty is love story isbard obtain identity story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 48.485 | p: 47.059 | r: 50.000
rouge2     | fm: 6.452 | p: 6.250 | r: 6.667
rougeL     | fm: 30.303 | p: 29.412 | r: 31.250
rougeLsum  | fm: 30.303 | p: 29.412 | r: 31.250
r1fm+r2fm = 54.936

[Aggregate metrics]:
rouge1     | fm: 90.233 | p: 90.014 | r: 90.516
rouge2     | fm: 61.535 | p: 61.506 | r: 61.578
rougeL     | fm: 79.240 | p: 79.060 | r: 79.415
rougeLsum  | fm: 79.022 | p: 78.857 | r: 79.199
r1fm+r2fm = 151.768

input #58 time: 0:08:25 | total time: 8:08:36


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9992224669689527
highest_index [0]
highest [0.9992224669689527]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9151541590690613 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.9016127586364746 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.8955602645874023 for ['[CLS] clutch sports meridian placed weekly dixonwords up⁄ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.865580677986145 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.857191801071167 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8294965028762817 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8291977643966675 for ['[CLS] wasby temperament awhile noah information bologna 1993 fleet thus pump bobo races tunnel stuffak [SEP]']
[Init] best perm rec loss: 0.8291869163513184 for ['[CLS] awhile pump bobo tunnel fleet thus was temperamentak races stuff noah 1993by bologna information [SEP]']
[Init] best perm rec loss: 0.8275994658470154 for ['[CLS] thus information pump temperament awhile bobo races stuff fleetby was 1993 noah tunnelak bologna [SEP]']
[Init] best perm rec loss: 0.8272705078125 for ['[CLS] fleet temperament pumpak information noah bologna races tunnelby awhile thus stuff bobo 1993 was [SEP]']
[Init] best perm rec loss: 0.8271450400352478 for ['[CLS] bologna tunnel pump thus noah races information bobo stuff fleet 1993 temperament wasakby awhile [SEP]']
[Init] best perm rec loss: 0.8269852995872498 for ['[CLS] bologna pump 1993 information awhile stuffbyak bobo fleet races temperament thus was noah tunnel [SEP]']
[Init] best perm rec loss: 0.8267932534217834 for ['[CLS] thus 1993 bologna stuff pump temperament fleet tunnel was awhile noahakby races bobo information [SEP]']
[Init] best perm rec loss: 0.8258228898048401 for ['[CLS] bobo stuff temperamentby tunnel 1993 informationak thus races awhile noah bologna pump was fleet [SEP]']
[Init] best perm rec loss: 0.8244286775588989 for ['[CLS]by fleet thus information bologna tunnel temperament races awhile stuff pump noah bobo was 1993ak [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.217 (perp=14.124, rec=0.377, cos=0.015), tot_loss_proj:3.555 [t=0.17s]
prediction: ['[CLS] amazing script barefoot confident neillhn strong motorcycleona keith skilled outstandingist woman new touch [SEP]']
[ 100/2000] tot_loss=2.815 (perp=12.686, rec=0.274, cos=0.004), tot_loss_proj:3.265 [t=0.17s]
prediction: ['[CLS] amazing screen intently succeeds maritime mor the who ruthsky skilled young team woman has of [SEP]']
[ 150/2000] tot_loss=2.631 (perp=12.001, rec=0.230, cos=0.001), tot_loss_proj:3.824 [t=0.17s]
prediction: ['[CLS] amazing screen how succeeds died of theism screen county an young holding woman has logic [SEP]']
[ 200/2000] tot_loss=2.515 (perp=11.567, rec=0.200, cos=0.002), tot_loss_proj:3.711 [t=0.19s]
prediction: ['[CLS] char screen howism william of theism screen who a young holding woman has char [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.187 (perp=10.001, rec=0.185, cos=0.002), tot_loss_proj:3.245 [t=0.19s]
prediction: ['[CLS] char screen hasism or of the of screenism a young holding woman knows char [SEP]']
[ 300/2000] tot_loss=2.433 (perp=11.169, rec=0.197, cos=0.003), tot_loss_proj:3.544 [t=0.18s]
prediction: ['[CLS] char screen hasism aa the of screenism a young holding woman knowsism [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.266 (perp=10.689, rec=0.127, cos=0.001), tot_loss_proj:3.052 [t=0.19s]
prediction: ['[CLS] charism hasism aa of screen theism a young hold woman knowsism [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.950 (perp=9.144, rec=0.120, cos=0.001), tot_loss_proj:2.618 [t=0.21s]
prediction: ['[CLS] charism hasisma of a screen theism a young hold woman knowsism [SEP]']
[ 450/2000] tot_loss=1.937 (perp=9.144, rec=0.106, cos=0.001), tot_loss_proj:2.632 [t=0.17s]
prediction: ['[CLS] charism hasisma of a screen theism a young hold woman knowsism [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.877 (perp=8.874, rec=0.100, cos=0.002), tot_loss_proj:2.497 [t=0.17s]
prediction: ['[CLS] charism hasisma of a screen theismism a young hold woman knows [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.762 (perp=8.332, rec=0.094, cos=0.002), tot_loss_proj:2.311 [t=0.17s]
prediction: ['[CLS] charism hasisma of a screen theismism a hold young woman knows [SEP]']
[ 600/2000] tot_loss=1.769 (perp=8.332, rec=0.101, cos=0.001), tot_loss_proj:2.309 [t=0.17s]
prediction: ['[CLS] charism hasisma of a screen theismism a hold young woman knows [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.728 (perp=8.176, rec=0.092, cos=0.001), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] char screen hasisma of aism theismism a hold young woman knows [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.733 (perp=8.176, rec=0.097, cos=0.002), tot_loss_proj:2.426 [t=0.17s]
prediction: ['[CLS] char screen hasisma of aism theismism a hold young woman knows [SEP]']
[ 750/2000] tot_loss=1.752 (perp=8.289, rec=0.092, cos=0.001), tot_loss_proj:2.638 [t=0.17s]
prediction: ['[CLS] char screen hasisma of aism theism who a hold young woman knows [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.662 (perp=7.884, rec=0.084, cos=0.001), tot_loss_proj:2.624 [t=0.17s]
prediction: ['[CLS] char screen hasisma of aism theism hold who a young woman knows [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.624 (perp=7.627, rec=0.097, cos=0.001), tot_loss_proj:2.203 [t=0.17s]
prediction: ['[CLS] screen has charisma of aism theism hold who a young woman knows [SEP]']
[ 900/2000] tot_loss=1.641 (perp=7.763, rec=0.087, cos=0.001), tot_loss_proj:2.223 [t=0.17s]
prediction: ['[CLS] screen has charisma of aism theism hold how a young woman knows [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.498 (perp=7.030, rec=0.090, cos=0.001), tot_loss_proj:2.060 [t=0.17s]
prediction: ['[CLS]ism has charisma of a screen theism hold how a young woman knows [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.479 (perp=6.946, rec=0.088, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS]ism has charisma of a screen theism knows how a young woman hold [SEP]']
[1050/2000] tot_loss=1.558 (perp=7.361, rec=0.084, cos=0.001), tot_loss_proj:2.068 [t=0.17s]
prediction: ['[CLS]ism has charisma of of screen theism knows how a young woman hold [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.516 (perp=7.149, rec=0.085, cos=0.001), tot_loss_proj:2.207 [t=0.17s]
prediction: ['[CLS]ism has charisma of screen of theism knows how a young woman hold [SEP]']
Attempt swap
[1150/2000] tot_loss=1.508 (perp=7.149, rec=0.077, cos=0.001), tot_loss_proj:2.211 [t=0.17s]
prediction: ['[CLS]ism has charisma of screen of theism knows how a young woman hold [SEP]']
[1200/2000] tot_loss=1.519 (perp=7.149, rec=0.087, cos=0.001), tot_loss_proj:2.207 [t=0.17s]
prediction: ['[CLS]ism has charisma of screen of theism knows how a young woman hold [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.489 (perp=7.049, rec=0.078, cos=0.001), tot_loss_proj:2.162 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen ofism knows how a young woman hold [SEP]']
Attempt swap
[1300/2000] tot_loss=1.501 (perp=7.049, rec=0.090, cos=0.001), tot_loss_proj:2.157 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen ofism knows how a young woman hold [SEP]']
[1350/2000] tot_loss=1.511 (perp=7.049, rec=0.100, cos=0.001), tot_loss_proj:2.154 [t=0.18s]
prediction: ['[CLS]ism has charisma of the screen ofism knows how a young woman hold [SEP]']
Attempt swap
[1400/2000] tot_loss=1.504 (perp=7.049, rec=0.093, cos=0.001), tot_loss_proj:2.156 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen ofism knows how a young woman hold [SEP]']
Attempt swap
[1450/2000] tot_loss=1.490 (perp=7.049, rec=0.079, cos=0.001), tot_loss_proj:2.167 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen ofism knows how a young woman hold [SEP]']
[1500/2000] tot_loss=1.826 (perp=8.683, rec=0.088, cos=0.001), tot_loss_proj:2.878 [t=0.17s]
prediction: ['[CLS]ism has char thea of the screen ofism knows how a young woman hold [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.449 (perp=6.789, rec=0.090, cos=0.001), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen of the knows how a young woman hold [SEP]']
Attempt swap
[1600/2000] tot_loss=1.445 (perp=6.789, rec=0.086, cos=0.001), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen of the knows how a young woman hold [SEP]']
[1650/2000] tot_loss=1.447 (perp=6.789, rec=0.087, cos=0.001), tot_loss_proj:2.005 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen of the knows how a young woman hold [SEP]']
Attempt swap
Moved sequence
[1700/2000] tot_loss=1.388 (perp=6.460, rec=0.094, cos=0.001), tot_loss_proj:1.771 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen of the young woman knows how a hold [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.345 (perp=6.259, rec=0.092, cos=0.002), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen of a young woman knows how the hold [SEP]']
[1800/2000] tot_loss=1.331 (perp=6.259, rec=0.078, cos=0.001), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS]ism has charisma of the screen of a young woman knows how the hold [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.265 (perp=5.875, rec=0.089, cos=0.001), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS]ism has the charisma of the screen of a young woman knows how hold [SEP]']
Attempt swap
[1900/2000] tot_loss=1.269 (perp=5.875, rec=0.093, cos=0.001), tot_loss_proj:1.883 [t=0.17s]
prediction: ['[CLS]ism has the charisma of the screen of a young woman knows how hold [SEP]']
[1950/2000] tot_loss=1.277 (perp=5.875, rec=0.101, cos=0.001), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS]ism has the charisma of the screen of a young woman knows how hold [SEP]']
Attempt swap
[2000/2000] tot_loss=1.256 (perp=5.875, rec=0.080, cos=0.001), tot_loss_proj:1.882 [t=0.17s]
prediction: ['[CLS]ism has the charisma of the screen of a young woman knows how hold [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS]ism has charisma of the screen ofism knows how a young woman hold [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.871 | p: 86.667 | r: 81.250
rouge2     | fm: 34.483 | p: 35.714 | r: 33.333
rougeL     | fm: 58.065 | p: 60.000 | r: 56.250
rougeLsum  | fm: 58.065 | p: 60.000 | r: 56.250
r1fm+r2fm = 118.354

[Aggregate metrics]:
rouge1     | fm: 90.185 | p: 89.969 | r: 90.419
rouge2     | fm: 60.980 | p: 60.979 | r: 61.024
rougeL     | fm: 78.890 | p: 78.759 | r: 79.049
rougeLsum  | fm: 78.711 | p: 78.599 | r: 78.865
r1fm+r2fm = 151.165

input #59 time: 0:08:04 | total time: 8:16:40


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.999371813039142
highest_index [0]
highest [0.999371813039142]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9299472570419312 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9130843281745911 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8701856732368469 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8695709109306335 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8544469475746155 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.842263400554657 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.8397374749183655 for ['[CLS] constitutionitude upsetshaw coverlby strungouring majority plenty / through [SEP]']
[Init] best perm rec loss: 0.8392449617385864 for ['[CLS] majorityitudelby upsetouring plentyshaw constitution cover strung through / [SEP]']
[Init] best perm rec loss: 0.8391808867454529 for ['[CLS]itude coverouring majoritylbyshaw through / plenty upset strung constitution [SEP]']
[Init] best perm rec loss: 0.8388378024101257 for ['[CLS]lby / upsetouring constitutionshaw cover strung majorityitude through plenty [SEP]']
[Init] best perm rec loss: 0.838720440864563 for ['[CLS] throughlby / majority upset strungitude constitutionshaw plentyouring cover [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.047 (perp=13.570, rec=0.329, cos=0.004), tot_loss_proj:3.382 [t=0.17s]
prediction: ['[CLS] legs leasttext television clip player awkwardly awkwardly pretended shaft seminary plain [SEP]']
[ 100/2000] tot_loss=2.642 (perp=12.008, rec=0.239, cos=0.001), tot_loss_proj:2.926 [t=0.17s]
prediction: ['[CLS]station awkwardly paced records clip story awkwardly awkwardly sitcom story seminary. [SEP]']
[ 150/2000] tot_loss=2.247 (perp=10.286, rec=0.188, cos=0.001), tot_loss_proj:2.672 [t=0.19s]
prediction: ['[CLS] circuit awkwardly paced is clip story awkwardly awkwardly sitcom story circuit. [SEP]']
[ 200/2000] tot_loss=2.310 (perp=10.651, rec=0.176, cos=0.004), tot_loss_proj:2.655 [t=0.19s]
prediction: ['[CLS] circuit awkwardly paced is clip story awkwardly awkwardly soap story circuit. [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.946 (perp=8.994, rec=0.146, cos=0.001), tot_loss_proj:2.333 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera paced is paced story awkwardly story circuit. [SEP]']
[ 300/2000] tot_loss=1.931 (perp=8.994, rec=0.131, cos=0.002), tot_loss_proj:2.341 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera paced is paced story awkwardly story circuit. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.981 (perp=9.256, rec=0.128, cos=0.001), tot_loss_proj:2.313 [t=0.19s]
prediction: ['[CLS] circuit awkwardly soap opera paced story is season awkwardly storyh. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.898 (perp=8.859, rec=0.125, cos=0.001), tot_loss_proj:2.229 [t=0.19s]
prediction: ['[CLS] circuit awkwardly soap opera paced story is story awkwardly operah. [SEP]']
[ 450/2000] tot_loss=1.884 (perp=8.859, rec=0.111, cos=0.001), tot_loss_proj:2.228 [t=0.19s]
prediction: ['[CLS] circuit awkwardly soap opera paced story is story awkwardly operah. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.869 (perp=8.757, rec=0.116, cos=0.001), tot_loss_proj:2.208 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera paced story story is awkwardly operah. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.865 (perp=8.757, rec=0.113, cos=0.001), tot_loss_proj:2.213 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera paced story story is awkwardly operah. [SEP]']
[ 600/2000] tot_loss=1.857 (perp=8.757, rec=0.105, cos=0.001), tot_loss_proj:2.210 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera paced story story is awkwardly operah. [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.009 (perp=9.490, rec=0.110, cos=0.001), tot_loss_proj:2.356 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera paced story story is awkwardly operah - [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.012 (perp=9.490, rec=0.113, cos=0.001), tot_loss_proj:2.361 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera paced story story is awkwardly operah - [SEP]']
[ 750/2000] tot_loss=2.012 (perp=9.490, rec=0.113, cos=0.001), tot_loss_proj:2.355 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera paced story story is awkwardly operah - [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.006 (perp=9.490, rec=0.106, cos=0.001), tot_loss_proj:2.356 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera paced story story is awkwardly operah - [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.018 (perp=9.613, rec=0.094, cos=0.001), tot_loss_proj:2.409 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera pacedh story is awkwardly operah - [SEP]']
[ 900/2000] tot_loss=2.023 (perp=9.613, rec=0.099, cos=0.001), tot_loss_proj:2.406 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera pacedh story is awkwardly operah - [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.995 (perp=9.452, rec=0.103, cos=0.001), tot_loss_proj:2.361 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap operah paced story is awkwardly operah - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.986 (perp=9.452, rec=0.094, cos=0.001), tot_loss_proj:2.363 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap operah paced story is awkwardly operah - [SEP]']
[1050/2000] tot_loss=2.340 (perp=11.209, rec=0.096, cos=0.001), tot_loss_proj:2.749 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap theh paced story is awkwardly operah - [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.099 (perp=10.045, rec=0.088, cos=0.001), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap the awkwardly paced story ish operah - [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.896 (perp=8.995, rec=0.096, cos=0.001), tot_loss_proj:2.234 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story ishh - [SEP]']
[1200/2000] tot_loss=1.893 (perp=8.995, rec=0.092, cos=0.001), tot_loss_proj:2.236 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story ishh - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.888 (perp=8.995, rec=0.088, cos=0.001), tot_loss_proj:2.227 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story ishh - [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.825 (perp=8.637, rec=0.097, cos=0.001), tot_loss_proj:2.151 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
[1350/2000] tot_loss=1.821 (perp=8.637, rec=0.092, cos=0.001), tot_loss_proj:2.156 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Attempt swap
[1400/2000] tot_loss=1.819 (perp=8.637, rec=0.090, cos=0.001), tot_loss_proj:2.151 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Attempt swap
[1450/2000] tot_loss=1.814 (perp=8.637, rec=0.085, cos=0.001), tot_loss_proj:2.151 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
[1500/2000] tot_loss=1.815 (perp=8.637, rec=0.087, cos=0.001), tot_loss_proj:2.149 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.820 (perp=8.637, rec=0.092, cos=0.001), tot_loss_proj:2.156 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Attempt swap
[1600/2000] tot_loss=1.809 (perp=8.637, rec=0.081, cos=0.001), tot_loss_proj:2.151 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
[1650/2000] tot_loss=1.819 (perp=8.637, rec=0.090, cos=0.001), tot_loss_proj:2.146 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Attempt swap
[1700/2000] tot_loss=1.820 (perp=8.637, rec=0.091, cos=0.001), tot_loss_proj:2.161 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.818 (perp=8.637, rec=0.089, cos=0.001), tot_loss_proj:2.149 [t=0.19s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
[1800/2000] tot_loss=1.817 (perp=8.637, rec=0.088, cos=0.001), tot_loss_proj:2.147 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Attempt swap
[1850/2000] tot_loss=1.812 (perp=8.637, rec=0.083, cos=0.001), tot_loss_proj:2.146 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.806 (perp=8.637, rec=0.078, cos=0.001), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
[1950/2000] tot_loss=1.811 (perp=8.637, rec=0.082, cos=0.001), tot_loss_proj:2.147 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Attempt swap
[2000/2000] tot_loss=1.808 (perp=8.637, rec=0.080, cos=0.001), tot_loss_proj:2.150 [t=0.17s]
prediction: ['[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] circuit awkwardly soap opera the awkwardly paced story - ishh [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 121.818

[Aggregate metrics]:
rouge1     | fm: 89.980 | p: 89.752 | r: 90.273
rouge2     | fm: 60.944 | p: 60.919 | r: 60.970
rougeL     | fm: 78.505 | p: 78.373 | r: 78.699
rougeLsum  | fm: 78.571 | p: 78.433 | r: 78.717
r1fm+r2fm = 150.924

input #60 time: 0:07:46 | total time: 8:24:27


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.999284746941759
highest_index [0]
highest [0.999284746941759]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9795893430709839 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9741564989089966 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9512136578559875 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9470409154891968 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9432965517044067 for ['[CLS] conscious baptizedness [SEP]']
[Init] best rec loss: 0.9347224831581116 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.9169871807098389 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9168724417686462 for ['[CLS] joint flamingual [SEP]']
[Init] best rec loss: 0.9121196269989014 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.9106317162513733 for ['[CLS] installed equipped unlike [SEP]']
[Init] best rec loss: 0.8808217644691467 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.8280910849571228 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 0.8269730806350708 for ['[CLS] lets mini request [SEP]']
[Init] best perm rec loss: 0.8244650959968567 for ['[CLS] mini request lets [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.216 (perp=9.683, rec=0.272, cos=0.007), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 100/2000] tot_loss=2.124 (perp=9.683, rec=0.182, cos=0.006), tot_loss_proj:2.396 [t=0.17s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 150/2000] tot_loss=2.091 (perp=9.683, rec=0.150, cos=0.005), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 200/2000] tot_loss=2.080 (perp=9.683, rec=0.140, cos=0.004), tot_loss_proj:2.397 [t=0.17s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.686 (perp=7.752, rec=0.132, cos=0.004), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] beautiful beautiful scene [SEP]']
[ 300/2000] tot_loss=1.674 (perp=8.032, rec=0.066, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.490 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.493 (perp=7.101, rec=0.071, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.492 (perp=7.101, rec=0.070, cos=0.001), tot_loss_proj:1.628 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.484 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.486 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.476 (perp=7.101, rec=0.055, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.479 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.492 (perp=7.101, rec=0.070, cos=0.001), tot_loss_proj:1.628 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.484 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.631 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.474 (perp=7.101, rec=0.053, cos=0.001), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.505 (perp=7.101, rec=0.083, cos=0.001), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.482 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.493 (perp=7.101, rec=0.072, cos=0.001), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.493 (perp=7.101, rec=0.071, cos=0.001), tot_loss_proj:1.629 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.478 (perp=7.101, rec=0.056, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.489 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.491 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.497 (perp=7.101, rec=0.075, cos=0.001), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.490 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.491 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.630 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.489 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.638 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.484 (perp=7.101, rec=0.062, cos=0.001), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.483 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.480 (perp=7.101, rec=0.059, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.490 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.175 | p: 89.993 | r: 90.403
rouge2     | fm: 61.389 | p: 61.360 | r: 61.441
rougeL     | fm: 78.949 | p: 78.836 | r: 79.082
rougeLsum  | fm: 78.820 | p: 78.678 | r: 78.966
r1fm+r2fm = 151.564

input #61 time: 0:07:36 | total time: 8:32:03


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.999255650346929
highest_index [0]
highest [0.999255650346929]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9540637731552124 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9288767576217651 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.927240788936615 for ['[CLS] gem longer congregationiq commemorate members police later pm drawing [MASK]ly onwards drops team senator access head wrath miss shane [SEP]']
[Init] best rec loss: 0.9213613867759705 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best rec loss: 0.9167788624763489 for ['[CLS] girl plain followedion recalls間 by spread fight sioux 2002 test origins humanitarian peck reed forumnce tooth closely mccarthy [SEP]']
[Init] best perm rec loss: 0.9164981842041016 for ['[CLS]nce followed mccarthy sioux by forum fight closely origins peckion humanitarian 2002 recalls reed spread tooth plain test girl間 [SEP]']
[Init] best perm rec loss: 0.914860188961029 for ['[CLS] girl by tooth forum followednce test reed sioux plain fight 2002 origins spread recalls closely humanitarian mccarthy間 peckion [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.304 (perp=12.444, rec=0.764, cos=0.051), tot_loss_proj:4.062 [t=0.17s]
prediction: ['[CLS] virginia through war drawer campaign toward ass high confederatetight qu. sir hot necessity throat accident been game were hardly [SEP]']
[ 100/2000] tot_loss=2.634 (perp=10.102, rec=0.610, cos=0.003), tot_loss_proj:3.610 [t=0.17s]
prediction: ['[CLS] our to war hallway any to ass slow wartight clips.. hot dollars of next he game were shrugged [SEP]']
[ 150/2000] tot_loss=3.019 (perp=11.744, rec=0.653, cos=0.017), tot_loss_proj:3.992 [t=0.21s]
prediction: ['[CLS] vampires to prevention prevention any communist bad among war courts audition /. hot dollars of next she game were none [SEP]']
[ 200/2000] tot_loss=2.701 (perp=10.763, rec=0.547, cos=0.001), tot_loss_proj:3.848 [t=0.17s]
prediction: ['[CLS] grace to prevention prevention orchestra sawmill fashion among war parts making, major hot dollars of next she gore were shrugged [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.823 (perp=11.219, rec=0.555, cos=0.025), tot_loss_proj:4.185 [t=0.18s]
prediction: ['[CLS] grace to prevention prevention especially sawmill best among war making parts, major hot challenge of next movies gore were shrugged [SEP]']
[ 300/2000] tot_loss=2.797 (perp=11.417, rec=0.506, cos=0.008), tot_loss_proj:4.242 [t=0.17s]
prediction: ['[CLS] grace to prevention prevention pradesh sawmill best among war making against, major hot challenge of task movies ever were shrugged [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.535 (perp=10.218, rec=0.489, cos=0.002), tot_loss_proj:3.876 [t=0.19s]
prediction: ['[CLS] grace to prevention prevention against without 《 best among war making, major in challenge of task movies ever best shrugged [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.473 (perp=10.037, rec=0.464, cos=0.002), tot_loss_proj:3.829 [t=0.17s]
prediction: ['[CLS] grace to prevention prevention against without 《 best among war making and in grayson you of kylie movies ever best shrugged [SEP]']
[ 450/2000] tot_loss=2.752 (perp=11.465, rec=0.456, cos=0.002), tot_loss_proj:3.974 [t=0.17s]
prediction: ['[CLS] grace to prevention prevention weather especially 《 best among war making of in grayson considering of kylie movies ever best shrugged [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.592 (perp=10.760, rec=0.437, cos=0.003), tot_loss_proj:3.667 [t=0.17s]
prediction: ['[CLS] grace to prevention making weather especially hp best biggest war making prevention when far things of chase movies ever best shrugged [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.590 (perp=10.789, rec=0.430, cos=0.002), tot_loss_proj:3.610 [t=0.17s]
prediction: ['[CLS] grace to prevention making weather especially hp best biggest war prevention albums when far things of chase movies ever best shrugged [SEP]']
[ 600/2000] tot_loss=2.552 (perp=10.652, rec=0.419, cos=0.002), tot_loss_proj:3.618 [t=0.17s]
prediction: ['[CLS] grace to prevention making weather especially their best biggest war prevention making when far things of began movies ever best shrugged [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.555 (perp=10.598, rec=0.431, cos=0.004), tot_loss_proj:3.594 [t=0.17s]
prediction: ['[CLS] grace to prevention an weather especially hp best biggest war prevention grossing when far ones " best movies ever began probably [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.480 (perp=10.263, rec=0.417, cos=0.011), tot_loss_proj:3.507 [t=0.17s]
prediction: ['[CLS] grace to prevention weather an especially hp movies biggest war prevention grossing when far ones of best movies ever began probably [SEP]']
[ 750/2000] tot_loss=2.635 (perp=11.130, rec=0.406, cos=0.003), tot_loss_proj:3.927 [t=0.17s]
prediction: ['[CLS] grace to prevention weather of especially hp movies biggest war prevention grossing whenna ones of best movies ever began probably [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.599 (perp=10.967, rec=0.403, cos=0.003), tot_loss_proj:3.809 [t=0.17s]
prediction: ['[CLS] grace to prevention weather movies especially hp an biggest war prevention grossing whenna ones of best movies ever began probably [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.445 (perp=10.103, rec=0.419, cos=0.005), tot_loss_proj:3.678 [t=0.17s]
prediction: ['[CLS] grace to prevention weather movies especially hp of biggest war preventionna when grossing ones of best movies ever began probably [SEP]']
[ 900/2000] tot_loss=2.425 (perp=10.131, rec=0.398, cos=0.001), tot_loss_proj:3.684 [t=0.17s]
prediction: ['[CLS] grace to prevention manner movies especially hp of biggest war preventionna when grossing ones of best movies ever think probably [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.478 (perp=10.435, rec=0.391, cos=0.001), tot_loss_proj:4.061 [t=0.17s]
prediction: ['[CLS] grace to prevention manner movies rather hp of biggest war preventionna when makes ones of best film ever think probably [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.477 (perp=10.377, rec=0.399, cos=0.003), tot_loss_proj:4.024 [t=0.17s]
prediction: ['[CLS] grace to prevention manner movies rather hp of biggest war preventionna probably grossing ones " best film ever think when [SEP]']
[1050/2000] tot_loss=2.462 (perp=10.362, rec=0.387, cos=0.002), tot_loss_proj:4.066 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse movies rather hp of biggest war preventionna probably grossing ones of best film ever think when [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.350 (perp=9.805, rec=0.386, cos=0.004), tot_loss_proj:3.914 [t=0.17s]
prediction: ['[CLS] grace to prevention manner movies rather biggest hp of war preventionna probably makes ones of best film ever think when [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=2.400 (perp=10.097, rec=0.379, cos=0.001), tot_loss_proj:4.022 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse movies rather biggest hp of war prevention grossingna probably ones of best film ever think when [SEP]']
[1200/2000] tot_loss=2.405 (perp=10.097, rec=0.380, cos=0.005), tot_loss_proj:4.026 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse movies rather biggest hp of war prevention grossingna probably ones of best film ever think when [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.355 (perp=9.846, rec=0.384, cos=0.002), tot_loss_proj:3.964 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse movies rather biggest hpna of war prevention grossing exactly ones of best film ever think when [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.578 (perp=10.673, rec=0.431, cos=0.013), tot_loss_proj:3.877 [t=0.17s]
prediction: ['[CLS] grace to prevention weather prevention because biggest hp far of war movies grossing probably ones war best film ever think when [SEP]']
[1350/2000] tot_loss=2.448 (perp=10.269, rec=0.393, cos=0.001), tot_loss_proj:3.631 [t=0.17s]
prediction: ['[CLS] grace to prevention weather prevention because biggest hp yet the war movies makes probably ones war best film ever think when [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.273 (perp=9.396, rec=0.393, cos=0.001), tot_loss_proj:3.666 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse prevention rather biggest hp yet the war movies makes probably ones when war best film ever think [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.256 (perp=9.325, rec=0.390, cos=0.001), tot_loss_proj:3.654 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse prevention rather biggest hp yet the war movies makes probably ones when war think best film ever [SEP]']
[1500/2000] tot_loss=2.256 (perp=9.383, rec=0.377, cos=0.002), tot_loss_proj:3.635 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse prevention rather biggest hp yet the war movies makes probably ones when war buck best film ever [SEP]']
Attempt swap
[1550/2000] tot_loss=2.250 (perp=9.383, rec=0.372, cos=0.001), tot_loss_proj:3.637 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse prevention rather biggest hp yet the war movies makes probably ones when war buck best film ever [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.240 (perp=9.280, rec=0.381, cos=0.003), tot_loss_proj:3.573 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse prevention rather biggest yet hp the war movies makes probably ones when war buck best film ever [SEP]']
[1650/2000] tot_loss=2.233 (perp=9.280, rec=0.375, cos=0.001), tot_loss_proj:3.578 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse prevention rather biggest yet hp the war movies makes probably ones when war buck best film ever [SEP]']
Attempt swap
[1700/2000] tot_loss=2.364 (perp=9.952, rec=0.373, cos=0.001), tot_loss_proj:3.799 [t=0.17s]
prediction: ['[CLS] grace to prevention defense prevention rather biggest yetght the war movies grossing probably ones when war buck best film ever [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.326 (perp=9.755, rec=0.374, cos=0.001), tot_loss_proj:3.787 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse prevention rather biggest yetght the war grossing movies probably ones when war buck best film ever [SEP]']
[1800/2000] tot_loss=2.341 (perp=9.814, rec=0.377, cos=0.001), tot_loss_proj:3.736 [t=0.17s]
prediction: ['[CLS] grace to prevention defense prevention rather biggest yetght the war grossing movies probably ones when war buck best film ever [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=2.323 (perp=9.729, rec=0.376, cos=0.001), tot_loss_proj:3.768 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse prevention rather biggest yetght the grossing war movies probably ones when war buck best film ever [SEP]']
Attempt swap
[1900/2000] tot_loss=2.321 (perp=9.729, rec=0.374, cos=0.001), tot_loss_proj:3.770 [t=0.17s]
prediction: ['[CLS] grace to prevention abuse prevention rather biggest yetght the grossing war movies probably ones when war buck best film ever [SEP]']
[1950/2000] tot_loss=2.313 (perp=9.698, rec=0.373, cos=0.001), tot_loss_proj:3.714 [t=0.17s]
prediction: ['[CLS] grace to prevention defense prevention rather biggest yetght the grossing war movies probably ones when war buck best film ever [SEP]']
Attempt swap
[2000/2000] tot_loss=2.317 (perp=9.698, rec=0.377, cos=0.001), tot_loss_proj:3.709 [t=0.17s]
prediction: ['[CLS] grace to prevention defense prevention rather biggest yetght the grossing war movies probably ones when war buck best film ever [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] grace to prevention defense prevention rather biggest yetght the grossing war movies probably ones when war buck best film ever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 50.000 | r: 50.000
rouge2     | fm: 19.048 | p: 19.048 | r: 19.048
rougeL     | fm: 45.455 | p: 45.455 | r: 45.455
rougeLsum  | fm: 45.455 | p: 45.455 | r: 45.455
r1fm+r2fm = 69.048

[Aggregate metrics]:
rouge1     | fm: 89.501 | p: 89.315 | r: 89.765
rouge2     | fm: 60.491 | p: 60.455 | r: 60.532
rougeL     | fm: 78.495 | p: 78.329 | r: 78.670
rougeLsum  | fm: 78.280 | p: 78.150 | r: 78.418
r1fm+r2fm = 149.992

input #62 time: 0:07:54 | total time: 8:39:57


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9992646432214791
highest_index [0]
highest [0.9992646432214791]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9565043449401855 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.9048953652381897 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.7484632730484009 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7433376908302307 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 0.739037811756134 for ['[CLS] diploma catalogue honors knee skirt [SEP]']
[Init] best rec loss: 0.7285273671150208 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.7276551127433777 for ['[CLS] solutions forces offense... civil [SEP]']
[Init] best perm rec loss: 0.7259407639503479 for ['[CLS] solutions civil forces... offense [SEP]']
[Init] best perm rec loss: 0.7244595885276794 for ['[CLS] forces... offense solutions civil [SEP]']
[Init] best perm rec loss: 0.7240341901779175 for ['[CLS] forces solutions... civil offense [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.736 (perp=11.389, rec=0.445, cos=0.013), tot_loss_proj:3.444 [t=0.17s]
prediction: ['[CLS] failed fleeing lost money solidarity [SEP]']
[ 100/2000] tot_loss=2.685 (perp=12.086, rec=0.264, cos=0.004), tot_loss_proj:3.792 [t=0.17s]
prediction: ['[CLS] failed seek di ticket ticket [SEP]']
[ 150/2000] tot_loss=2.321 (perp=10.701, rec=0.179, cos=0.002), tot_loss_proj:3.192 [t=0.17s]
prediction: ['[CLS] return looking a ticket ticket [SEP]']
[ 200/2000] tot_loss=2.368 (perp=11.116, rec=0.144, cos=0.002), tot_loss_proj:3.545 [t=0.24s]
prediction: ['[CLS] return looking a ticket return [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.959 (perp=9.290, rec=0.099, cos=0.001), tot_loss_proj:2.976 [t=0.17s]
prediction: ['[CLS] looking return a ticket return [SEP]']
[ 300/2000] tot_loss=1.948 (perp=9.290, rec=0.089, cos=0.001), tot_loss_proj:2.983 [t=0.17s]
prediction: ['[CLS] looking return a ticket return [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.940 (perp=9.290, rec=0.081, cos=0.001), tot_loss_proj:2.975 [t=0.17s]
prediction: ['[CLS] looking return a ticket return [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.947 (perp=9.290, rec=0.088, cos=0.001), tot_loss_proj:2.973 [t=0.17s]
prediction: ['[CLS] looking return a ticket return [SEP]']
[ 450/2000] tot_loss=1.945 (perp=9.290, rec=0.086, cos=0.001), tot_loss_proj:2.969 [t=0.17s]
prediction: ['[CLS] looking return a ticket return [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.935 (perp=9.290, rec=0.076, cos=0.001), tot_loss_proj:2.977 [t=0.17s]
prediction: ['[CLS] looking return a ticket return [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.849 (perp=8.851, rec=0.077, cos=0.001), tot_loss_proj:2.934 [t=0.17s]
prediction: ['[CLS] looking return a ticket for [SEP]']
[ 600/2000] tot_loss=1.839 (perp=8.851, rec=0.068, cos=0.002), tot_loss_proj:2.930 [t=0.17s]
prediction: ['[CLS] looking return a ticket for [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.267 (perp=5.941, rec=0.077, cos=0.001), tot_loss_proj:1.461 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.260 (perp=5.941, rec=0.070, cos=0.001), tot_loss_proj:1.456 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 750/2000] tot_loss=1.256 (perp=5.941, rec=0.066, cos=0.001), tot_loss_proj:1.467 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.255 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.459 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.256 (perp=5.941, rec=0.066, cos=0.001), tot_loss_proj:1.474 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 900/2000] tot_loss=1.251 (perp=5.941, rec=0.061, cos=0.001), tot_loss_proj:1.453 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.254 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.463 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1000/2000] tot_loss=1.253 (perp=5.941, rec=0.064, cos=0.001), tot_loss_proj:1.463 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1050/2000] tot_loss=1.255 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.467 [t=0.19s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1100/2000] tot_loss=1.255 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.469 [t=0.19s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1150/2000] tot_loss=1.255 (perp=5.941, rec=0.066, cos=0.001), tot_loss_proj:1.459 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1200/2000] tot_loss=1.251 (perp=5.941, rec=0.061, cos=0.001), tot_loss_proj:1.453 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1250/2000] tot_loss=1.249 (perp=5.941, rec=0.059, cos=0.001), tot_loss_proj:1.455 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1300/2000] tot_loss=1.255 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.455 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1350/2000] tot_loss=1.245 (perp=5.941, rec=0.055, cos=0.001), tot_loss_proj:1.459 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1400/2000] tot_loss=1.261 (perp=5.941, rec=0.071, cos=0.001), tot_loss_proj:1.466 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1450/2000] tot_loss=1.255 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.463 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1500/2000] tot_loss=1.266 (perp=5.941, rec=0.076, cos=0.001), tot_loss_proj:1.464 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1550/2000] tot_loss=1.258 (perp=5.941, rec=0.068, cos=0.001), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1600/2000] tot_loss=1.255 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.461 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1650/2000] tot_loss=1.250 (perp=5.941, rec=0.061, cos=0.001), tot_loss_proj:1.452 [t=0.19s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1700/2000] tot_loss=1.253 (perp=5.941, rec=0.063, cos=0.001), tot_loss_proj:1.455 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1750/2000] tot_loss=1.251 (perp=5.941, rec=0.061, cos=0.001), tot_loss_proj:1.465 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1800/2000] tot_loss=1.254 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.468 [t=0.18s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1850/2000] tot_loss=1.258 (perp=5.941, rec=0.068, cos=0.001), tot_loss_proj:1.464 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1900/2000] tot_loss=1.256 (perp=5.941, rec=0.067, cos=0.001), tot_loss_proj:1.461 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1950/2000] tot_loss=1.251 (perp=5.941, rec=0.061, cos=0.001), tot_loss_proj:1.463 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[2000/2000] tot_loss=1.249 (perp=5.941, rec=0.059, cos=0.001), tot_loss_proj:1.458 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a ticket return [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 89.673 | p: 89.487 | r: 89.895
rouge2     | fm: 60.470 | p: 60.448 | r: 60.472
rougeL     | fm: 78.464 | p: 78.340 | r: 78.621
rougeLsum  | fm: 78.382 | p: 78.256 | r: 78.558
r1fm+r2fm = 150.143

input #63 time: 0:07:31 | total time: 8:47:29


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.999160846219472
highest_index [0]
highest [0.999160846219472]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8796932697296143 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8693087697029114 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.728920042514801 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.675671398639679 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6740126609802246 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 0.6711879372596741 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.974 (perp=8.653, rec=0.230, cos=0.013), tot_loss_proj:2.060 [t=0.17s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.886 (perp=8.653, rec=0.152, cos=0.003), tot_loss_proj:2.068 [t=0.17s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.884 (perp=8.653, rec=0.151, cos=0.003), tot_loss_proj:2.062 [t=0.17s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=2.065 (perp=9.634, rec=0.133, cos=0.005), tot_loss_proj:2.548 [t=0.17s]
prediction: ['[CLS] strange horror strange [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.940 (perp=9.190, rec=0.099, cos=0.002), tot_loss_proj:2.221 [t=0.17s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 300/2000] tot_loss=1.689 (perp=8.065, rec=0.075, cos=0.002), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.682 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.681 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.719 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.685 (perp=8.065, rec=0.070, cos=0.002), tot_loss_proj:1.708 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.672 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.686 (perp=8.065, rec=0.071, cos=0.002), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.681 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.674 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.714 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.667 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.685 (perp=8.065, rec=0.071, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.712 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.666 (perp=8.065, rec=0.051, cos=0.002), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.666 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.680 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.713 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.664 (perp=8.065, rec=0.049, cos=0.002), tot_loss_proj:1.713 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.671 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.714 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.685 (perp=8.065, rec=0.070, cos=0.002), tot_loss_proj:1.715 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.674 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.712 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.664 (perp=8.065, rec=0.050, cos=0.002), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.812 | p: 89.625 | r: 90.065
rouge2     | fm: 61.283 | p: 61.247 | r: 61.340
rougeL     | fm: 78.782 | p: 78.659 | r: 78.964
rougeLsum  | fm: 78.872 | p: 78.771 | r: 79.020
r1fm+r2fm = 151.096

input #64 time: 0:07:29 | total time: 8:54:58


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9992260466615117
highest_index [0]
highest [0.9992260466615117]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.0258606672286987 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9586822390556335 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9518215656280518 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9477682113647461 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.8876939415931702 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8789583444595337 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8788501620292664 for ['[CLS] evenhoff overs pu newsmament general fun someday [SEP]']
[Init] best perm rec loss: 0.875924289226532 for ['[CLS]hoff someday general even pumament news fun overs [SEP]']
[Init] best perm rec loss: 0.8755142688751221 for ['[CLS] general news evenmament puhoff overs fun someday [SEP]']
[Init] best perm rec loss: 0.8745706081390381 for ['[CLS] even general news pumament somedayhoff fun overs [SEP]']
[Init] best perm rec loss: 0.8732827305793762 for ['[CLS] somedaymamenthoff general overs pu news even fun [SEP]']
[Init] best perm rec loss: 0.8718383312225342 for ['[CLS]mament news general even pu overs fun somedayhoff [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.511 (perp=10.688, rec=0.367, cos=0.007), tot_loss_proj:2.865 [t=0.17s]
prediction: ['[CLS] joy newsy, national leading sensation cases joy [SEP]']
[ 100/2000] tot_loss=2.433 (perp=10.969, rec=0.237, cos=0.002), tot_loss_proj:2.720 [t=0.17s]
prediction: ['[CLS] joyousous, show area sensation investigation joy [SEP]']
[ 150/2000] tot_loss=2.224 (perp=10.206, rec=0.181, cos=0.001), tot_loss_proj:2.502 [t=0.17s]
prediction: ['[CLS] joyousous, film film of investigation joy [SEP]']
[ 200/2000] tot_loss=2.149 (perp=9.943, rec=0.158, cos=0.002), tot_loss_proj:2.458 [t=0.17s]
prediction: ['[CLS] joyous,, film film of investigation joy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.653 (perp=7.532, rec=0.145, cos=0.001), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] joyous, investigation, film film of joy [SEP]']
[ 300/2000] tot_loss=1.804 (perp=8.225, rec=0.157, cos=0.001), tot_loss_proj:2.151 [t=0.17s]
prediction: ['[CLS] joyous, host, film film of joy [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.874 (perp=8.694, rec=0.134, cos=0.002), tot_loss_proj:2.231 [t=0.17s]
prediction: ['[CLS] joyous of seem film, film of joy [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.717 (perp=7.978, rec=0.119, cos=0.002), tot_loss_proj:2.586 [t=0.17s]
prediction: ['[CLS] seem joyous of film, film of rom [SEP]']
[ 450/2000] tot_loss=1.720 (perp=8.092, rec=0.100, cos=0.002), tot_loss_proj:2.566 [t=0.17s]
prediction: ['[CLS] seem joyous of film,. of rom [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.542 (perp=7.126, rec=0.115, cos=0.001), tot_loss_proj:2.475 [t=0.17s]
prediction: ['[CLS] seem joyous of film, of rom. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.518 (perp=7.126, rec=0.092, cos=0.002), tot_loss_proj:2.479 [t=0.17s]
prediction: ['[CLS] seem joyous of film, of rom. [SEP]']
[ 600/2000] tot_loss=1.747 (perp=8.219, rec=0.102, cos=0.002), tot_loss_proj:2.348 [t=0.17s]
prediction: ['[CLS] realm joyous the film, of rom. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.777 (perp=8.362, rec=0.103, cos=0.001), tot_loss_proj:2.223 [t=0.17s]
prediction: ['[CLS] joyous the film,y of rom. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.508 (perp=7.012, rec=0.104, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] joyous of the film,y rom. [SEP]']
[ 750/2000] tot_loss=1.514 (perp=7.012, rec=0.110, cos=0.002), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] joyous of the film,y rom. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.541 (perp=7.207, rec=0.098, cos=0.002), tot_loss_proj:2.187 [t=0.17s]
prediction: ['[CLS] joyous of of film, romy. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.431 (perp=6.683, rec=0.093, cos=0.002), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] joyous of film, of romy. [SEP]']
[ 900/2000] tot_loss=1.437 (perp=6.683, rec=0.099, cos=0.002), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] joyous of film, of romy. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.601 (perp=7.548, rec=0.089, cos=0.002), tot_loss_proj:2.663 [t=0.17s]
prediction: ['[CLS] joyousp film, of romy. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.655 (perp=7.816, rec=0.091, cos=0.001), tot_loss_proj:2.156 [t=0.17s]
prediction: ['[CLS] joyousy film, a rom of. [SEP]']
[1050/2000] tot_loss=1.656 (perp=7.816, rec=0.092, cos=0.002), tot_loss_proj:2.154 [t=0.17s]
prediction: ['[CLS] joyousy film, a rom of. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.320 (perp=6.192, rec=0.080, cos=0.002), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] joyous of film, a romy. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.257 (perp=5.795, rec=0.096, cos=0.001), tot_loss_proj:1.864 [t=0.17s]
prediction: ['[CLS] joyousp, a romy film. [SEP]']
[1200/2000] tot_loss=1.232 (perp=5.795, rec=0.071, cos=0.002), tot_loss_proj:1.868 [t=0.17s]
prediction: ['[CLS] joyousp, a romy film. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.412 (perp=6.666, rec=0.077, cos=0.002), tot_loss_proj:1.923 [t=0.17s]
prediction: ['[CLS] joyousy, a rom of film. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.126 (perp=5.232, rec=0.078, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
[1350/2000] tot_loss=1.131 (perp=5.232, rec=0.083, cos=0.002), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.130 (perp=5.232, rec=0.082, cos=0.002), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.122 (perp=5.232, rec=0.074, cos=0.002), tot_loss_proj:1.504 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
[1500/2000] tot_loss=1.129 (perp=5.232, rec=0.081, cos=0.002), tot_loss_proj:1.503 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.129 (perp=5.232, rec=0.081, cos=0.002), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.138 (perp=5.232, rec=0.090, cos=0.002), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
[1650/2000] tot_loss=1.124 (perp=5.232, rec=0.076, cos=0.002), tot_loss_proj:1.504 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.127 (perp=5.232, rec=0.080, cos=0.002), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.122 (perp=5.232, rec=0.074, cos=0.002), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
[1800/2000] tot_loss=1.122 (perp=5.232, rec=0.074, cos=0.002), tot_loss_proj:1.503 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.124 (perp=5.232, rec=0.076, cos=0.002), tot_loss_proj:1.497 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.125 (perp=5.232, rec=0.077, cos=0.002), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
[1950/2000] tot_loss=1.126 (perp=5.232, rec=0.078, cos=0.002), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.119 (perp=5.232, rec=0.071, cos=0.002), tot_loss_proj:1.504 [t=0.17s]
prediction: ['[CLS]y joyous, a romp film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS]y joyous, a romp film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 89.751 | p: 89.569 | r: 90.033
rouge2     | fm: 60.484 | p: 60.511 | r: 60.528
rougeL     | fm: 78.704 | p: 78.587 | r: 78.863
rougeLsum  | fm: 78.706 | p: 78.594 | r: 78.867
r1fm+r2fm = 150.235

input #65 time: 0:07:28 | total time: 9:02:27


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9992330092949469
highest_index [0]
highest [0.9992330092949469]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.973792552947998 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9307570457458496 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9160336256027222 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8862890601158142 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.8742782473564148 for ['[CLS]beersa bryce two [SEP]']
[Init] best perm rec loss: 0.8719822764396667 for ['[CLS]beersa two bryce [SEP]']
[Init] best perm rec loss: 0.8696925640106201 for ['[CLS]rsa two brycebee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.288 (perp=10.258, rec=0.230, cos=0.006), tot_loss_proj:3.298 [t=0.17s]
prediction: ['[CLS] executive tolkien tolkien fan [SEP]']
[ 100/2000] tot_loss=1.639 (perp=7.673, rec=0.103, cos=0.002), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 150/2000] tot_loss=1.612 (perp=7.673, rec=0.076, cos=0.002), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 200/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.614 (perp=7.673, rec=0.078, cos=0.001), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.002), tot_loss_proj:1.604 [t=0.19s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.590 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.588 (perp=7.673, rec=0.052, cos=0.001), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.592 (perp=7.673, rec=0.057, cos=0.001), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.597 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.593 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.596 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.614 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.586 (perp=7.673, rec=0.050, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.606 (perp=7.673, rec=0.070, cos=0.002), tot_loss_proj:1.598 [t=0.20s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.588 (perp=7.673, rec=0.051, cos=0.002), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.607 (perp=7.673, rec=0.071, cos=0.002), tot_loss_proj:1.610 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.591 (perp=7.673, rec=0.055, cos=0.002), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.583 (perp=7.673, rec=0.047, cos=0.002), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.588 (perp=7.673, rec=0.052, cos=0.002), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.607 (perp=7.673, rec=0.071, cos=0.002), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.002), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.002), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.583 (perp=7.673, rec=0.047, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.593 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.585 (perp=7.673, rec=0.049, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.601 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.590 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.589 (perp=7.673, rec=0.053, cos=0.002), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.594 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.934 | p: 89.771 | r: 90.209
rouge2     | fm: 61.224 | p: 61.214 | r: 61.285
rougeL     | fm: 79.068 | p: 78.963 | r: 79.200
rougeLsum  | fm: 79.024 | p: 78.916 | r: 79.180
r1fm+r2fm = 151.158

input #66 time: 0:07:28 | total time: 9:09:55


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.999292690019056
highest_index [0]
highest [0.999292690019056]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.005807638168335 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9567444324493408 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.9554714560508728 for ['[CLS] repeat well rv strikes combined leaned written itself welsh bunch [SEP]']
[Init] best rec loss: 0.9473316669464111 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9436708688735962 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9336733222007751 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9325234889984131 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best rec loss: 0.9268360137939453 for ['[CLS] wild tribes upon cone home enough promotion mural courtney ） [SEP]']
[Init] best perm rec loss: 0.9241943955421448 for ['[CLS] ） cone home mural courtney promotion upon enough wild tribes [SEP]']
[Init] best perm rec loss: 0.9226720929145813 for ['[CLS] promotion tribes home cone enough ） wild courtney upon mural [SEP]']
[Init] best perm rec loss: 0.9221352934837341 for ['[CLS] upon home tribes courtney cone mural ） wild promotion enough [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.928 (perp=13.221, rec=0.281, cos=0.003), tot_loss_proj:4.571 [t=0.17s]
prediction: ['[CLS]manshed kind max nascarentationur kind cooperative kind [SEP]']
[ 100/2000] tot_loss=2.820 (perp=13.190, rec=0.180, cos=0.001), tot_loss_proj:4.023 [t=0.17s]
prediction: ['[CLS] heartwar kind ne heartentationurmingental kind [SEP]']
[ 150/2000] tot_loss=2.667 (perp=12.728, rec=0.120, cos=0.001), tot_loss_proj:3.981 [t=0.17s]
prediction: ['[CLS] heartwar kind non heartgm nonmingental kind [SEP]']
[ 200/2000] tot_loss=2.461 (perp=11.714, rec=0.117, cos=0.001), tot_loss_proj:3.754 [t=0.19s]
prediction: ['[CLS] heartwar, non heartgm nonmingental kind [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.109 (perp=9.486, rec=0.209, cos=0.003), tot_loss_proj:3.181 [t=0.17s]
prediction: ['[CLS] heartwar, non heart nonminggmental kind [SEP]']
[ 300/2000] tot_loss=2.032 (perp=9.486, rec=0.133, cos=0.001), tot_loss_proj:3.214 [t=0.17s]
prediction: ['[CLS] heartwar, non heart nonminggmental kind [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.095 (perp=9.666, rec=0.160, cos=0.001), tot_loss_proj:3.109 [t=0.17s]
prediction: ['[CLS] [SEP]warming non heart non,gmental kind [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.632 (perp=7.467, rec=0.138, cos=0.001), tot_loss_proj:1.782 [t=0.17s]
prediction: ['[CLS] heartwarming, heart non nongmental kind [SEP]']
[ 450/2000] tot_loss=1.620 (perp=7.467, rec=0.125, cos=0.001), tot_loss_proj:1.780 [t=0.17s]
prediction: ['[CLS] heartwarming, heart non nongmental kind [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.574 (perp=7.310, rec=0.110, cos=0.001), tot_loss_proj:1.826 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nongmgmental [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.559 (perp=7.310, rec=0.095, cos=0.001), tot_loss_proj:1.832 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nongmgmental [SEP]']
[ 600/2000] tot_loss=1.556 (perp=7.310, rec=0.093, cos=0.001), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nongmgmental [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.552 (perp=7.310, rec=0.089, cos=0.001), tot_loss_proj:1.825 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nongmgmental [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.513 (perp=7.119, rec=0.088, cos=0.001), tot_loss_proj:1.781 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
[ 750/2000] tot_loss=1.522 (perp=7.119, rec=0.097, cos=0.001), tot_loss_proj:1.779 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.502 (perp=7.119, rec=0.077, cos=0.001), tot_loss_proj:1.784 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.517 (perp=7.119, rec=0.092, cos=0.001), tot_loss_proj:1.775 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
[ 900/2000] tot_loss=1.514 (perp=7.119, rec=0.089, cos=0.001), tot_loss_proj:1.782 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.518 (perp=7.119, rec=0.093, cos=0.001), tot_loss_proj:1.771 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1000/2000] tot_loss=1.513 (perp=7.119, rec=0.088, cos=0.001), tot_loss_proj:1.778 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
[1050/2000] tot_loss=1.506 (perp=7.119, rec=0.081, cos=0.001), tot_loss_proj:1.784 [t=0.18s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1100/2000] tot_loss=1.509 (perp=7.119, rec=0.084, cos=0.001), tot_loss_proj:1.781 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1150/2000] tot_loss=1.515 (perp=7.119, rec=0.090, cos=0.001), tot_loss_proj:1.780 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
[1200/2000] tot_loss=1.507 (perp=7.119, rec=0.082, cos=0.001), tot_loss_proj:1.774 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1250/2000] tot_loss=1.712 (perp=8.164, rec=0.078, cos=0.001), tot_loss_proj:2.187 [t=0.17s]
prediction: ['[CLS] [SEP]warming, heart kind nonjugmental [SEP]']
Attempt swap
[1300/2000] tot_loss=1.498 (perp=7.119, rec=0.073, cos=0.001), tot_loss_proj:1.772 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
[1350/2000] tot_loss=1.502 (perp=7.119, rec=0.076, cos=0.001), tot_loss_proj:1.781 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1400/2000] tot_loss=1.510 (perp=7.119, rec=0.085, cos=0.001), tot_loss_proj:1.784 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1450/2000] tot_loss=1.497 (perp=7.119, rec=0.072, cos=0.001), tot_loss_proj:1.783 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
[1500/2000] tot_loss=1.505 (perp=7.119, rec=0.079, cos=0.001), tot_loss_proj:1.778 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1550/2000] tot_loss=1.492 (perp=7.119, rec=0.067, cos=0.001), tot_loss_proj:1.785 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1600/2000] tot_loss=1.509 (perp=7.119, rec=0.084, cos=0.001), tot_loss_proj:1.772 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
[1650/2000] tot_loss=1.500 (perp=7.119, rec=0.075, cos=0.001), tot_loss_proj:1.775 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1700/2000] tot_loss=1.504 (perp=7.119, rec=0.078, cos=0.001), tot_loss_proj:1.775 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1750/2000] tot_loss=1.490 (perp=7.119, rec=0.065, cos=0.001), tot_loss_proj:1.775 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
[1800/2000] tot_loss=1.498 (perp=7.119, rec=0.073, cos=0.001), tot_loss_proj:1.778 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1850/2000] tot_loss=1.505 (perp=7.119, rec=0.079, cos=0.001), tot_loss_proj:1.776 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[1900/2000] tot_loss=1.504 (perp=7.119, rec=0.079, cos=0.001), tot_loss_proj:1.782 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
[1950/2000] tot_loss=1.504 (perp=7.119, rec=0.079, cos=0.001), tot_loss_proj:1.781 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Attempt swap
[2000/2000] tot_loss=1.504 (perp=7.119, rec=0.079, cos=0.001), tot_loss_proj:1.774 [t=0.17s]
prediction: ['[CLS] heartwarming, heart kind nonjugmental [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarming, heart kind nonjugmental [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 66.667 | r: 80.000
rouge2     | fm: 22.222 | p: 20.000 | r: 25.000
rougeL     | fm: 72.727 | p: 66.667 | r: 80.000
rougeLsum  | fm: 72.727 | p: 66.667 | r: 80.000
r1fm+r2fm = 94.949

[Aggregate metrics]:
rouge1     | fm: 89.681 | p: 89.387 | r: 90.002
rouge2     | fm: 60.653 | p: 60.595 | r: 60.716
rougeL     | fm: 78.932 | p: 78.707 | r: 79.139
rougeLsum  | fm: 78.935 | p: 78.757 | r: 79.157
r1fm+r2fm = 150.333

input #67 time: 0:07:52 | total time: 9:17:47


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9992789242841313
highest_index [0]
highest [0.9992789242841313]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.989619255065918 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9645585417747498 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9424722194671631 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9253563284873962 for ['[CLS] neutron acrosswas 2005 security tip fa— identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8706526756286621 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8648829460144043 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8608188629150391 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8541148900985718 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8531020283699036 for ['[CLS]iferous comfortyn form medal died floor. beth possibly riding view councils [SEP]']
[Init] best perm rec loss: 0.8519254326820374 for ['[CLS] possibly councils comfortiferousyn floor died form view beth. medal riding [SEP]']
[Init] best perm rec loss: 0.8488271236419678 for ['[CLS]iferous flooryn form possibly medal riding view beth councils. died comfort [SEP]']
[Init] best perm rec loss: 0.8450530767440796 for ['[CLS] beth comfortyn died form riding councils possibly medal floor. viewiferous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.463 (perp=11.060, rec=0.249, cos=0.002), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] absurd, oftlement disastrous ( painful barrel ridiculous stupid - derivative [SEP] [SEP]']
[ 100/2000] tot_loss=2.161 (perp=9.944, rec=0.168, cos=0.004), tot_loss_proj:2.432 [t=0.17s]
prediction: ['[CLS] absurd, unsiblesible, absurdigate absurd vicious and absurd of [SEP]']
[ 150/2000] tot_loss=2.190 (perp=10.243, rec=0.140, cos=0.001), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS] absurd, unsiblesible, vicious 貝 absurd vicious and vicious un [SEP]']
[ 200/2000] tot_loss=2.077 (perp=9.765, rec=0.123, cos=0.001), tot_loss_proj:2.404 [t=0.17s]
prediction: ['[CLS] absurd, unsiblesible, viciousdictsible vicious and vicious un [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.893 (perp=8.926, rec=0.107, cos=0.001), tot_loss_proj:2.181 [t=0.17s]
prediction: ['[CLS] absurd, uncosible, viciousompsibleuth and vicious vicious [SEP]']
[ 300/2000] tot_loss=1.877 (perp=8.926, rec=0.090, cos=0.001), tot_loss_proj:2.173 [t=0.17s]
prediction: ['[CLS] absurd, uncosible, viciousompsibleuth and vicious vicious [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.858 (perp=8.384, rec=0.179, cos=0.002), tot_loss_proj:2.076 [t=0.17s]
prediction: ['[CLS] absurd, uncouth and vicioussible, viciousomp un vicious [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.726 (perp=7.934, rec=0.138, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] vicious, uncouth and vicioussible, absurdomp un absurd [SEP]']
[ 450/2000] tot_loss=1.700 (perp=7.934, rec=0.111, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] vicious, uncouth and vicioussible, absurdomp un absurd [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.628 (perp=7.677, rec=0.091, cos=0.001), tot_loss_proj:1.902 [t=0.17s]
prediction: ['[CLS] viciousomp uncouth and vicioussible, absurd, un absurd [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.782 (perp=8.434, rec=0.094, cos=0.001), tot_loss_proj:2.185 [t=0.17s]
prediction: ['[CLS] vicious, uncouth and vicioussible,ompomp un absurd [SEP]']
[ 600/2000] tot_loss=1.778 (perp=8.434, rec=0.090, cos=0.001), tot_loss_proj:2.186 [t=0.17s]
prediction: ['[CLS] vicious, uncouth and vicioussible,ompomp un absurd [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.737 (perp=8.107, rec=0.114, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] vicious, uncouth and vicioussible, unompomp absurd [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.577 (perp=7.172, rec=0.141, cos=0.002), tot_loss_proj:1.771 [t=0.17s]
prediction: ['[CLS] vicioussible, unompomp vicious, uncouth and absurd [SEP]']
[ 750/2000] tot_loss=1.545 (perp=7.172, rec=0.109, cos=0.001), tot_loss_proj:1.762 [t=0.17s]
prediction: ['[CLS] vicioussible, unompomp vicious, uncouth and absurd [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.537 (perp=7.172, rec=0.102, cos=0.001), tot_loss_proj:1.767 [t=0.17s]
prediction: ['[CLS] vicioussible, unompomp vicious, uncouth and absurd [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.530 (perp=7.172, rec=0.094, cos=0.001), tot_loss_proj:1.762 [t=0.17s]
prediction: ['[CLS] vicioussible, unompomp vicious, uncouth and absurd [SEP]']
[ 900/2000] tot_loss=1.527 (perp=7.172, rec=0.091, cos=0.001), tot_loss_proj:1.762 [t=0.17s]
prediction: ['[CLS] vicioussible, unompomp vicious, uncouth and absurd [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.529 (perp=7.172, rec=0.094, cos=0.001), tot_loss_proj:1.769 [t=0.17s]
prediction: ['[CLS] vicioussible, unompomp vicious, uncouth and absurd [SEP]']
Attempt swap
[1000/2000] tot_loss=1.528 (perp=7.172, rec=0.092, cos=0.001), tot_loss_proj:1.770 [t=0.17s]
prediction: ['[CLS] vicioussible, unompomp vicious, uncouth and absurd [SEP]']
[1050/2000] tot_loss=1.834 (perp=8.755, rec=0.082, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] vicioussible, unompomp vicious,cocouth and absurd [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.713 (perp=8.129, rec=0.086, cos=0.001), tot_loss_proj:1.989 [t=0.17s]
prediction: ['[CLS] vicioussible,coompomp vicious, uncouth and absurd [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.761 (perp=8.304, rec=0.099, cos=0.001), tot_loss_proj:2.027 [t=0.17s]
prediction: ['[CLS] vicioussibleomp unomp, vicious, uncouth and absurd [SEP]']
[1200/2000] tot_loss=1.756 (perp=8.304, rec=0.094, cos=0.001), tot_loss_proj:2.028 [t=0.17s]
prediction: ['[CLS] vicioussibleomp unomp, vicious, uncouth and absurd [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.617 (perp=7.623, rec=0.091, cos=0.001), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] unsibleomp viciousomp, vicious, uncouth and absurd [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.570 (perp=7.335, rec=0.101, cos=0.001), tot_loss_proj:1.856 [t=0.17s]
prediction: ['[CLS] unsibleompomp, vicious, vicious uncouth and absurd [SEP]']
[1350/2000] tot_loss=1.565 (perp=7.335, rec=0.096, cos=0.001), tot_loss_proj:1.855 [t=0.17s]
prediction: ['[CLS] unsibleompomp, vicious, vicious uncouth and absurd [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.626 (perp=7.658, rec=0.093, cos=0.001), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS]cosibleompomp, vicious vicious, uncouth and absurd [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.555 (perp=7.304, rec=0.093, cos=0.001), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
[1500/2000] tot_loss=1.545 (perp=7.304, rec=0.083, cos=0.001), tot_loss_proj:1.805 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=1.547 (perp=7.304, rec=0.085, cos=0.001), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
Attempt swap
[1600/2000] tot_loss=1.553 (perp=7.304, rec=0.091, cos=0.001), tot_loss_proj:1.805 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
[1650/2000] tot_loss=1.551 (perp=7.304, rec=0.089, cos=0.001), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.546 (perp=7.304, rec=0.084, cos=0.001), tot_loss_proj:1.809 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=1.547 (perp=7.304, rec=0.085, cos=0.001), tot_loss_proj:1.813 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
[1800/2000] tot_loss=1.548 (perp=7.304, rec=0.085, cos=0.001), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=1.545 (perp=7.304, rec=0.082, cos=0.001), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.553 (perp=7.304, rec=0.091, cos=0.001), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
[1950/2000] tot_loss=1.542 (perp=7.304, rec=0.080, cos=0.001), tot_loss_proj:1.807 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.539 (perp=7.304, rec=0.077, cos=0.001), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] viciouscosibleompomp, vicious, uncouth and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 119.048

[Aggregate metrics]:
rouge1     | fm: 89.616 | p: 89.343 | r: 89.930
rouge2     | fm: 60.133 | p: 60.081 | r: 60.199
rougeL     | fm: 78.712 | p: 78.485 | r: 78.995
rougeLsum  | fm: 78.771 | p: 78.613 | r: 79.001
r1fm+r2fm = 149.749

input #68 time: 0:07:36 | total time: 9:25:23


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9992908222867736
highest_index [0]
highest [0.9992908222867736]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.086551547050476 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9466122388839722 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.925304114818573 for ['[CLS] meetings bells mountain bloody technical script⁄ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9242345690727234 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.9170600771903992 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9078761339187622 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.8832088112831116 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8760436773300171 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8714134693145752 for ['[CLS] ferris main case african gross tray adelaide burnham port unopposedest [MASK] platformmission downacio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.944 (perp=13.264, rec=0.288, cos=0.003), tot_loss_proj:3.887 [t=0.17s]
prediction: ['[CLS] selling electric touched amazing of, food traction $eborg strongor teamasurable powerful stimuli [SEP]']
[ 100/2000] tot_loss=2.000 (perp=8.903, rec=0.218, cos=0.001), tot_loss_proj:2.585 [t=0.17s]
prediction: ['[CLS] smart finally funny strong -, - : - - smart and team winner team stimuli [SEP]']
[ 150/2000] tot_loss=1.844 (perp=8.354, rec=0.172, cos=0.001), tot_loss_proj:2.357 [t=0.17s]
prediction: ['[CLS] real real subtle smart -, - and - - subtle, ; winner team real [SEP]']
[ 200/2000] tot_loss=1.766 (perp=8.083, rec=0.148, cos=0.001), tot_loss_proj:2.359 [t=0.17s]
prediction: ['[CLS] real real subtle smart -, - and - - subtle,. winner - real [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.614 (perp=7.417, rec=0.129, cos=0.001), tot_loss_proj:2.075 [t=0.17s]
prediction: ['[CLS] a real subtle - smart, - and - - subtle,. winner - real [SEP]']
[ 300/2000] tot_loss=1.807 (perp=8.467, rec=0.113, cos=0.001), tot_loss_proj:2.409 [t=0.17s]
prediction: ['[CLS] a real subtle - smart,ona and - - subtle,. winner - des [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.733 (perp=8.104, rec=0.111, cos=0.001), tot_loss_proj:2.469 [t=0.17s]
prediction: ['[CLS] a real winner - smart,ona and - - res,. subtle - des [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.602 (perp=7.468, rec=0.107, cos=0.001), tot_loss_proj:2.461 [t=0.17s]
prediction: ['[CLS] a real winner - smart,ona. and - - res, subtle - des [SEP]']
[ 450/2000] tot_loss=1.779 (perp=8.431, rec=0.091, cos=0.001), tot_loss_proj:2.816 [t=0.17s]
prediction: ['[CLS] a real winner - smart,ona. and - - res, subtlepeed des [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.818 (perp=8.600, rec=0.096, cos=0.001), tot_loss_proj:2.678 [t=0.17s]
prediction: ['[CLS] a real winner - smart,ona. and res, subtle very - -ona [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.671 (perp=7.815, rec=0.106, cos=0.001), tot_loss_proj:2.325 [t=0.17s]
prediction: ['[CLS] a real winner - smart,ona. and res, very subtle - -ona [SEP]']
[ 600/2000] tot_loss=1.659 (perp=7.815, rec=0.095, cos=0.001), tot_loss_proj:2.331 [t=0.17s]
prediction: ['[CLS] a real winner - smart,ona. and res, very subtle - -ona [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.626 (perp=7.656, rec=0.093, cos=0.001), tot_loss_proj:2.058 [t=0.17s]
prediction: ['[CLS] a real winner - res,ona. and smart, very subtle - -ona [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.575 (perp=7.417, rec=0.090, cos=0.001), tot_loss_proj:2.075 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
[ 750/2000] tot_loss=1.584 (perp=7.417, rec=0.099, cos=0.001), tot_loss_proj:2.072 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.584 (perp=7.417, rec=0.099, cos=0.001), tot_loss_proj:2.071 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.573 (perp=7.417, rec=0.088, cos=0.001), tot_loss_proj:2.078 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
[ 900/2000] tot_loss=1.573 (perp=7.417, rec=0.088, cos=0.001), tot_loss_proj:2.071 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.570 (perp=7.417, rec=0.085, cos=0.001), tot_loss_proj:2.076 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.585 (perp=7.417, rec=0.100, cos=0.001), tot_loss_proj:2.077 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
[1050/2000] tot_loss=1.574 (perp=7.417, rec=0.089, cos=0.001), tot_loss_proj:2.079 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1100/2000] tot_loss=1.571 (perp=7.417, rec=0.086, cos=0.001), tot_loss_proj:2.082 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.566 (perp=7.417, rec=0.081, cos=0.001), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
[1200/2000] tot_loss=1.566 (perp=7.417, rec=0.081, cos=0.001), tot_loss_proj:2.078 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.566 (perp=7.417, rec=0.081, cos=0.001), tot_loss_proj:2.075 [t=0.22s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1300/2000] tot_loss=1.566 (perp=7.417, rec=0.082, cos=0.001), tot_loss_proj:2.073 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
[1350/2000] tot_loss=1.572 (perp=7.417, rec=0.087, cos=0.001), tot_loss_proj:2.086 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1400/2000] tot_loss=1.566 (perp=7.417, rec=0.081, cos=0.001), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1450/2000] tot_loss=1.560 (perp=7.417, rec=0.075, cos=0.001), tot_loss_proj:2.074 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
[1500/2000] tot_loss=1.567 (perp=7.417, rec=0.082, cos=0.001), tot_loss_proj:2.076 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1550/2000] tot_loss=1.574 (perp=7.417, rec=0.089, cos=0.001), tot_loss_proj:2.082 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1600/2000] tot_loss=1.567 (perp=7.417, rec=0.082, cos=0.001), tot_loss_proj:2.083 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
[1650/2000] tot_loss=1.564 (perp=7.417, rec=0.079, cos=0.001), tot_loss_proj:2.081 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1700/2000] tot_loss=1.566 (perp=7.417, rec=0.081, cos=0.001), tot_loss_proj:2.079 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1750/2000] tot_loss=1.565 (perp=7.417, rec=0.081, cos=0.001), tot_loss_proj:2.081 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
[1800/2000] tot_loss=1.577 (perp=7.417, rec=0.092, cos=0.001), tot_loss_proj:2.087 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1850/2000] tot_loss=1.559 (perp=7.417, rec=0.074, cos=0.001), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[1900/2000] tot_loss=1.575 (perp=7.417, rec=0.090, cos=0.001), tot_loss_proj:2.084 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
[1950/2000] tot_loss=1.561 (perp=7.417, rec=0.076, cos=0.001), tot_loss_proj:2.079 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Attempt swap
[2000/2000] tot_loss=1.565 (perp=7.417, rec=0.080, cos=0.001), tot_loss_proj:2.084 [t=0.17s]
prediction: ['[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] a real winner -nt, smart. andona, very subtle - -ona [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 63.636 | r: 70.000
rouge2     | fm: 31.579 | p: 30.000 | r: 33.333
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 98.246

[Aggregate metrics]:
rouge1     | fm: 89.256 | p: 88.982 | r: 89.665
rouge2     | fm: 59.650 | p: 59.622 | r: 59.803
rougeL     | fm: 78.662 | p: 78.437 | r: 78.945
rougeLsum  | fm: 78.597 | p: 78.396 | r: 78.945
r1fm+r2fm = 148.906

input #69 time: 0:07:18 | total time: 9:32:41


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9993748902467187
highest_index [0]
highest [0.9993748902467187]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8451830148696899 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.81871098279953 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7903928160667419 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7371676564216614 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.7334622144699097 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7315616607666016 for ['[CLS] blood sharma herself effects mark detention technological [SEP]']
[Init] best perm rec loss: 0.7313181161880493 for ['[CLS] detention sharma effects mark herself blood technological [SEP]']
[Init] best perm rec loss: 0.7305154204368591 for ['[CLS] sharma blood herself detention technological effects mark [SEP]']
[Init] best perm rec loss: 0.730158805847168 for ['[CLS] mark blood herself effects technological detention sharma [SEP]']
[Init] best perm rec loss: 0.7293766736984253 for ['[CLS] detention blood effects sharma herself technological mark [SEP]']
[Init] best perm rec loss: 0.7282413840293884 for ['[CLS] detention herself mark sharma technological effects blood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.766 (perp=11.763, rec=0.402, cos=0.011), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS] destroyed state jingle asteroid break friday crater [SEP]']
[ 100/2000] tot_loss=2.683 (perp=11.738, rec=0.331, cos=0.004), tot_loss_proj:3.631 [t=0.17s]
prediction: ['[CLS] off stateunk throughunk getsunk [SEP]']
[ 150/2000] tot_loss=2.742 (perp=12.355, rec=0.269, cos=0.002), tot_loss_proj:3.700 [t=0.17s]
prediction: ['[CLS] off theirunk throughunk gets screen [SEP]']
[ 200/2000] tot_loss=2.579 (perp=11.736, rec=0.230, cos=0.002), tot_loss_proj:3.669 [t=0.21s]
prediction: ['[CLS] cl getsunk clunk gets screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.088 (perp=9.220, rec=0.219, cos=0.026), tot_loss_proj:2.713 [t=0.17s]
prediction: ['[CLS] clunk gets clunk gets screen [SEP]']
[ 300/2000] tot_loss=2.653 (perp=12.479, rec=0.156, cos=0.002), tot_loss_proj:3.696 [t=0.17s]
prediction: ['[CLS] clunk getsyunk gets screen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.193 (perp=10.225, rec=0.146, cos=0.002), tot_loss_proj:2.750 [t=0.17s]
prediction: ['[CLS] clunkunky gets gets screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.681 (perp=7.851, rec=0.110, cos=0.001), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 450/2000] tot_loss=1.657 (perp=7.851, rec=0.086, cos=0.001), tot_loss_proj:2.487 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.652 (perp=7.851, rec=0.081, cos=0.001), tot_loss_proj:2.483 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.663 (perp=7.851, rec=0.092, cos=0.001), tot_loss_proj:2.475 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 600/2000] tot_loss=1.645 (perp=7.851, rec=0.073, cos=0.001), tot_loss_proj:2.483 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.645 (perp=7.851, rec=0.074, cos=0.001), tot_loss_proj:2.483 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.646 (perp=7.851, rec=0.074, cos=0.001), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 750/2000] tot_loss=1.641 (perp=7.851, rec=0.070, cos=0.001), tot_loss_proj:2.485 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.651 (perp=7.851, rec=0.080, cos=0.001), tot_loss_proj:2.475 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.649 (perp=7.851, rec=0.078, cos=0.001), tot_loss_proj:2.478 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 900/2000] tot_loss=1.647 (perp=7.851, rec=0.075, cos=0.001), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.658 (perp=7.851, rec=0.087, cos=0.001), tot_loss_proj:2.476 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.652 (perp=7.851, rec=0.080, cos=0.001), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1050/2000] tot_loss=1.655 (perp=7.851, rec=0.083, cos=0.001), tot_loss_proj:2.481 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.647 (perp=7.851, rec=0.075, cos=0.001), tot_loss_proj:2.474 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.647 (perp=7.851, rec=0.076, cos=0.001), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1200/2000] tot_loss=1.650 (perp=7.851, rec=0.079, cos=0.001), tot_loss_proj:2.486 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.640 (perp=7.851, rec=0.069, cos=0.001), tot_loss_proj:2.479 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.646 (perp=7.851, rec=0.075, cos=0.001), tot_loss_proj:2.477 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1350/2000] tot_loss=1.645 (perp=7.851, rec=0.074, cos=0.001), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.650 (perp=7.851, rec=0.079, cos=0.001), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.641 (perp=7.851, rec=0.069, cos=0.001), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1500/2000] tot_loss=1.638 (perp=7.851, rec=0.067, cos=0.001), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.642 (perp=7.851, rec=0.071, cos=0.001), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.648 (perp=7.851, rec=0.076, cos=0.001), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1650/2000] tot_loss=1.647 (perp=7.851, rec=0.075, cos=0.001), tot_loss_proj:2.479 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.644 (perp=7.851, rec=0.072, cos=0.001), tot_loss_proj:2.477 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.647 (perp=7.851, rec=0.075, cos=0.001), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1800/2000] tot_loss=1.641 (perp=7.851, rec=0.070, cos=0.001), tot_loss_proj:2.492 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.648 (perp=7.851, rec=0.076, cos=0.001), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.641 (perp=7.851, rec=0.069, cos=0.001), tot_loss_proj:2.479 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1950/2000] tot_loss=1.648 (perp=7.851, rec=0.077, cos=0.001), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.636 (perp=7.851, rec=0.065, cos=0.001), tot_loss_proj:2.487 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] clunkunky gets on screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 18.182 | p: 20.000 | r: 16.667
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 89.115 | p: 88.884 | r: 89.379
rouge2     | fm: 58.934 | p: 58.861 | r: 59.034
rougeL     | fm: 78.620 | p: 78.455 | r: 78.846
rougeLsum  | fm: 78.561 | p: 78.421 | r: 78.778
r1fm+r2fm = 148.049

input #70 time: 0:07:39 | total time: 9:40:21


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9993403548184047
highest_index [0]
highest [0.9993403548184047]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8840630650520325 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.847382128238678 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8406677842140198 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8305583596229553 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8247600197792053 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8176411986351013 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best rec loss: 0.813213050365448 for ['[CLS] knock lily combinedzh times soundfinger assist chains kylie most asha? industryico [SEP]']
[Init] best rec loss: 0.8101482391357422 for ['[CLS]. coursearth acids south gogh beyond stage reservoir until little tombathlontered wright [SEP]']
[Init] best perm rec loss: 0.8090407252311707 for ['[CLS] tomb gogharth acids course beyond littletered wright until south. reservoir stageathlon [SEP]']
[Init] best perm rec loss: 0.8082916736602783 for ['[CLS] beyond gogh southarth wright stage course acidstered. little until tombathlon reservoir [SEP]']
[Init] best perm rec loss: 0.8073354363441467 for ['[CLS] reservoir beyond.athlon little acids tombarth wright south course stage until goghtered [SEP]']
[Init] best perm rec loss: 0.8070156574249268 for ['[CLS]. reservoir wright beyondathlon tombarth stage acids south gogh course littletered until [SEP]']
[Init] best perm rec loss: 0.8070120215415955 for ['[CLS]athlon. reservoir southarth stagetered tomb beyond wright until little gogh acids course [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.519 (perp=10.524, rec=0.404, cos=0.009), tot_loss_proj:3.425 [t=0.17s]
prediction: ["[CLS] single only route notio britainter meeting section thuss seat without'seat [SEP]"]
[ 100/2000] tot_loss=2.389 (perp=10.566, rec=0.272, cos=0.004), tot_loss_proj:3.288 [t=0.17s]
prediction: ["[CLS] single not road not single townter meeting short bys moment without'moment [SEP]"]
[ 150/2000] tot_loss=2.188 (perp=9.901, rec=0.204, cos=0.003), tot_loss_proj:2.940 [t=0.17s]
prediction: ['[CLS] single not road not single hard - moment head iss seat single / moment [SEP]']
[ 200/2000] tot_loss=2.083 (perp=9.517, rec=0.179, cos=0.001), tot_loss_proj:3.280 [t=0.17s]
prediction: ['[CLS] single - road not singlebe - moment jump is your seat single - moment [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.949 (perp=8.627, rec=0.219, cos=0.004), tot_loss_proj:2.811 [t=0.17s]
prediction: ["[CLS] single there been - not single'- moment jump your seat minded - moment [SEP]"]
[ 300/2000] tot_loss=1.824 (perp=8.306, rec=0.161, cos=0.001), tot_loss_proj:2.828 [t=0.17s]
prediction: ['[CLS] single there been - not single jump - moment jump your seat minded - moment [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.698 (perp=7.829, rec=0.131, cos=0.001), tot_loss_proj:2.758 [t=0.17s]
prediction: ['[CLS] there been a - not single jump - jump jump your seat minded - moment [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.702 (perp=7.790, rec=0.143, cos=0.001), tot_loss_proj:2.848 [t=0.17s]
prediction: ['[CLS] and been a moment not single jump - jump jump your seat minded - - [SEP]']
[ 450/2000] tot_loss=1.708 (perp=8.007, rec=0.104, cos=0.002), tot_loss_proj:2.493 [t=0.17s]
prediction: ['[CLS] and is a moment not single jump - jump jump your seat minded there - [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.529 (perp=7.130, rec=0.102, cos=0.001), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] there is a moment not single jump - jump jump your seat minded and - [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.681 (perp=7.892, rec=0.101, cos=0.001), tot_loss_proj:3.176 [t=0.19s]
prediction: ['[CLS] there s - moment not single jump - - jump your seat minded and jump [SEP]']
[ 600/2000] tot_loss=1.683 (perp=7.986, rec=0.084, cos=0.001), tot_loss_proj:3.084 [t=0.22s]
prediction: ['[CLS] there s - moment not single in - - jump your seat drop and jump [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.612 (perp=7.626, rec=0.085, cos=0.001), tot_loss_proj:2.689 [t=0.19s]
prediction: ['[CLS] there s - moment not single jump - - in your seat bullshit and jump [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.471 (perp=6.949, rec=0.081, cos=0.001), tot_loss_proj:3.073 [t=0.19s]
prediction: ['[CLS] there s - moment not single drop - - in your seat jump and jump [SEP]']
[ 750/2000] tot_loss=1.594 (perp=7.565, rec=0.080, cos=0.001), tot_loss_proj:2.882 [t=0.19s]
prediction: ['[CLS] there s - moment not single your - - in your seat jump and jump [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.509 (perp=7.074, rec=0.093, cos=0.001), tot_loss_proj:3.139 [t=0.20s]
prediction: ['[CLS] there s - your not single moment - - in your seat jump and jump [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.436 (perp=6.816, rec=0.072, cos=0.001), tot_loss_proj:3.032 [t=0.17s]
prediction: ['[CLS] there your s a not single moment - - in your seat jump and jump [SEP]']
[ 900/2000] tot_loss=1.436 (perp=6.816, rec=0.072, cos=0.001), tot_loss_proj:3.035 [t=0.17s]
prediction: ['[CLS] there your s a not single moment - - in your seat jump and jump [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.469 (perp=6.909, rec=0.086, cos=0.001), tot_loss_proj:2.859 [t=0.17s]
prediction: ['[CLS] there s s not single a moment - - in your seat jump and jump [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.303 (perp=6.137, rec=0.075, cos=0.001), tot_loss_proj:2.597 [t=0.17s]
prediction: ['[CLS] there s s not a single moment - - in your seat jump and jump [SEP]']
[1050/2000] tot_loss=1.296 (perp=6.137, rec=0.067, cos=0.001), tot_loss_proj:2.604 [t=0.17s]
prediction: ['[CLS] there s s not a single moment - - in your seat jump and jump [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.293 (perp=6.052, rec=0.082, cos=0.001), tot_loss_proj:2.555 [t=0.17s]
prediction: ['[CLS] there - s not a single moment - your in your seat jump and jump [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.246 (perp=5.844, rec=0.076, cos=0.001), tot_loss_proj:2.737 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - - in your seat jump and jump [SEP]']
[1200/2000] tot_loss=1.250 (perp=5.844, rec=0.081, cos=0.001), tot_loss_proj:2.731 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - - in your seat jump and jump [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.234 (perp=5.792, rec=0.074, cos=0.001), tot_loss_proj:2.788 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat - and jump [SEP]']
Attempt swap
[1300/2000] tot_loss=1.232 (perp=5.792, rec=0.073, cos=0.001), tot_loss_proj:2.786 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat - and jump [SEP]']
[1350/2000] tot_loss=1.219 (perp=5.792, rec=0.060, cos=0.001), tot_loss_proj:2.777 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat - and jump [SEP]']
Attempt swap
[1400/2000] tot_loss=1.229 (perp=5.792, rec=0.069, cos=0.001), tot_loss_proj:2.775 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat - and jump [SEP]']
Attempt swap
[1450/2000] tot_loss=1.221 (perp=5.792, rec=0.061, cos=0.001), tot_loss_proj:2.785 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat - and jump [SEP]']
[1500/2000] tot_loss=1.236 (perp=5.792, rec=0.076, cos=0.001), tot_loss_proj:2.779 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat - and jump [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.236 (perp=5.748, rec=0.085, cos=0.001), tot_loss_proj:2.758 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat and jump - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.221 (perp=5.748, rec=0.071, cos=0.001), tot_loss_proj:2.756 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat and jump - [SEP]']
[1650/2000] tot_loss=1.272 (perp=5.956, rec=0.079, cos=0.001), tot_loss_proj:2.496 [t=0.17s]
prediction: ['[CLS] there s s not a single moment - jump in your seat and jump - [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.401 (perp=6.588, rec=0.082, cos=0.001), tot_loss_proj:2.384 [t=0.17s]
prediction: ['[CLS] there jump s not a single moment - your in your seat and jump - [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.214 (perp=5.748, rec=0.064, cos=0.001), tot_loss_proj:2.754 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat and jump - [SEP]']
[1800/2000] tot_loss=1.218 (perp=5.748, rec=0.067, cos=0.001), tot_loss_proj:2.756 [t=0.17s]
prediction: ['[CLS] there your s not a single moment - jump in your seat and jump - [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.197 (perp=5.620, rec=0.072, cos=0.001), tot_loss_proj:2.882 [t=0.17s]
prediction: ['[CLS] there - s not a single moment - jump in your seat and jump your [SEP]']
Attempt swap
[1900/2000] tot_loss=1.200 (perp=5.620, rec=0.075, cos=0.001), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] there - s not a single moment - jump in your seat and jump your [SEP]']
[1950/2000] tot_loss=1.202 (perp=5.620, rec=0.077, cos=0.001), tot_loss_proj:2.878 [t=0.17s]
prediction: ['[CLS] there - s not a single moment - jump in your seat and jump your [SEP]']
Attempt swap
[2000/2000] tot_loss=1.202 (perp=5.620, rec=0.076, cos=0.001), tot_loss_proj:2.886 [t=0.17s]
prediction: ['[CLS] there - s not a single moment - jump in your seat and jump your [SEP]']
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] there your s not a single moment - jump in your seat and jump - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.857 | p: 86.667 | r: 100.000
rouge2     | fm: 53.846 | p: 50.000 | r: 58.333
rougeL     | fm: 85.714 | p: 80.000 | r: 92.308
rougeLsum  | fm: 85.714 | p: 80.000 | r: 92.308
r1fm+r2fm = 146.703

[Aggregate metrics]:
rouge1     | fm: 89.134 | p: 88.826 | r: 89.490
rouge2     | fm: 59.220 | p: 59.161 | r: 59.380
rougeL     | fm: 78.711 | p: 78.524 | r: 78.955
rougeLsum  | fm: 78.804 | p: 78.563 | r: 79.109
r1fm+r2fm = 148.354

input #71 time: 0:07:55 | total time: 9:48:16


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9992329827199963
highest_index [0]
highest [0.9992329827199963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7871954441070557 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.756220817565918 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7524415254592896 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7376322150230408 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.736792266368866 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7195456624031067 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7185581922531128 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.7164209485054016 for ['[CLS] except orbitalungen lifeboat dna walking nonetheless support van! pork zone ta reserve accidentally [SEP]']
[Init] best perm rec loss: 0.713283896446228 for ['[CLS] except pork zone! lifeboat nonetheless accidentally ta orbital support walking dnaungen reserve van [SEP]']
[Init] best perm rec loss: 0.7122484445571899 for ['[CLS] porkungen lifeboat support accidentally nonetheless except walking dna reserve ta! zone orbital van [SEP]']
[Init] best perm rec loss: 0.7111414074897766 for ['[CLS] orbital except pork lifeboat! accidentally support reserve walkingungen ta van dna zone nonetheless [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.149 (perp=13.609, rec=0.425, cos=0.002), tot_loss_proj:3.757 [t=0.17s]
prediction: ['[CLS] attack facing anal toughneck attack a losers sold intervenedpoint ¨ gut? yer [SEP]']
[ 100/2000] tot_loss=2.853 (perp=12.556, rec=0.338, cos=0.004), tot_loss_proj:3.540 [t=0.17s]
prediction: ['[CLS] bad faced bloody tough humor muscle a girlfriend sold comparedal playoff toughestinal an [SEP]']
[ 150/2000] tot_loss=2.718 (perp=12.176, rec=0.281, cos=0.002), tot_loss_proj:4.258 [t=0.17s]
prediction: ['[CLS] rough policies bloody tough humorerty a decentzed compared more britney tough relationship an [SEP]']
[ 200/2000] tot_loss=2.485 (perp=11.167, rec=0.248, cos=0.004), tot_loss_proj:3.564 [t=0.17s]
prediction: ['[CLS] tough has a tough time panzer a philosophersedpre more 花 tough balancing time [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.348 (perp=10.856, rec=0.175, cos=0.001), tot_loss_proj:3.148 [t=0.17s]
prediction: ['[CLS] tough has its tough time spend violence philosophersism difficulter a tough balancing time [SEP]']
[ 300/2000] tot_loss=2.098 (perp=9.757, rec=0.143, cos=0.003), tot_loss_proj:3.423 [t=0.17s]
prediction: ['[CLS] tough has its tough philosophy influenced violence philosophy from difficulter a tough balancing time [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.008 (perp=9.401, rec=0.126, cos=0.002), tot_loss_proj:3.496 [t=0.17s]
prediction: ['[CLS] tough has its tough philosophy influenced difficulter violence philosophy to a tough balancing time [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.950 (perp=9.186, rec=0.111, cos=0.002), tot_loss_proj:3.232 [t=0.17s]
prediction: ['[CLS] tough has its tough philosophy influenced difficulter philosophy to violence - tough balancing time [SEP]']
[ 450/2000] tot_loss=1.957 (perp=9.268, rec=0.102, cos=0.002), tot_loss_proj:3.140 [t=0.17s]
prediction: ['[CLS] violence has its tough philosophy influenced difficulter philosophy with violence - tough balancing time [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.894 (perp=8.991, rec=0.095, cos=0.001), tot_loss_proj:3.386 [t=0.19s]
prediction: ['[CLS] philosophy has its tough philosophy influenced difficulter violence with violence - tough balancing time [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.812 (perp=8.545, rec=0.100, cos=0.002), tot_loss_proj:3.454 [t=0.19s]
prediction: ['[CLS] philosophy has its tough philosophy influenced balancing difficulter violence with violence - tough time [SEP]']
[ 600/2000] tot_loss=1.813 (perp=8.545, rec=0.102, cos=0.002), tot_loss_proj:3.453 [t=0.19s]
prediction: ['[CLS] philosophy has its tough philosophy influenced balancing difficulter violence with violence - tough time [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.797 (perp=8.508, rec=0.094, cos=0.002), tot_loss_proj:3.476 [t=0.17s]
prediction: ['[CLS] philosophy has its tough philosophyfk balancing tougher violence with violence - difficult time [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.705 (perp=8.089, rec=0.086, cos=0.001), tot_loss_proj:3.117 [t=0.17s]
prediction: ['[CLS] philosophy has its tough timefk balancing tougher violence with violence - difficult philosophy [SEP]']
[ 750/2000] tot_loss=1.704 (perp=8.089, rec=0.085, cos=0.001), tot_loss_proj:3.118 [t=0.17s]
prediction: ['[CLS] philosophy has its tough timefk balancing tougher violence with violence - difficult philosophy [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.806 (perp=8.590, rec=0.087, cos=0.001), tot_loss_proj:3.389 [t=0.18s]
prediction: ['[CLS] philosophy has its tough time sufficient balancing tougher violence with violence -fk philosophy [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.663 (perp=7.890, rec=0.084, cos=0.001), tot_loss_proj:2.741 [t=0.19s]
prediction: ['[CLS] philosophy has its tough time balancing tougher violence with sufficient violence -fk philosophy [SEP]']
[ 900/2000] tot_loss=1.668 (perp=7.890, rec=0.089, cos=0.002), tot_loss_proj:2.727 [t=0.17s]
prediction: ['[CLS] philosophy has its tough time balancing tougher violence with sufficient violence -fk philosophy [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.593 (perp=7.497, rec=0.092, cos=0.002), tot_loss_proj:2.617 [t=0.21s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.593 (perp=7.497, rec=0.092, cos=0.002), tot_loss_proj:2.617 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
[1050/2000] tot_loss=1.586 (perp=7.497, rec=0.085, cos=0.002), tot_loss_proj:2.616 [t=0.19s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.588 (perp=7.497, rec=0.087, cos=0.002), tot_loss_proj:2.609 [t=0.19s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.585 (perp=7.497, rec=0.084, cos=0.001), tot_loss_proj:2.612 [t=0.19s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
[1200/2000] tot_loss=1.578 (perp=7.497, rec=0.077, cos=0.001), tot_loss_proj:2.621 [t=0.19s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.592 (perp=7.497, rec=0.091, cos=0.002), tot_loss_proj:2.617 [t=0.19s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.582 (perp=7.497, rec=0.082, cos=0.001), tot_loss_proj:2.614 [t=0.19s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
[1350/2000] tot_loss=1.585 (perp=7.497, rec=0.084, cos=0.001), tot_loss_proj:2.617 [t=0.19s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.591 (perp=7.497, rec=0.090, cos=0.002), tot_loss_proj:2.625 [t=0.19s]
prediction: ['[CLS]fk has its tough time balancing tougher violence with sufficient violence - philosophy philosophy [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.697 (perp=8.064, rec=0.082, cos=0.002), tot_loss_proj:2.782 [t=0.19s]
prediction: ['[CLS]fk has its tough time balancingyaer violence with tough violence - philosophy philosophy [SEP]']
[1500/2000] tot_loss=1.696 (perp=8.064, rec=0.082, cos=0.001), tot_loss_proj:2.778 [t=0.20s]
prediction: ['[CLS]fk has its tough time balancingyaer violence with tough violence - philosophy philosophy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.696 (perp=8.064, rec=0.082, cos=0.002), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancingyaer violence with tough violence - philosophy philosophy [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.663 (perp=7.868, rec=0.088, cos=0.001), tot_loss_proj:2.656 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]']
[1650/2000] tot_loss=1.649 (perp=7.868, rec=0.074, cos=0.001), tot_loss_proj:2.653 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.656 (perp=7.868, rec=0.081, cos=0.002), tot_loss_proj:2.649 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.658 (perp=7.868, rec=0.083, cos=0.001), tot_loss_proj:2.652 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]']
[1800/2000] tot_loss=1.663 (perp=7.868, rec=0.088, cos=0.002), tot_loss_proj:2.647 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.655 (perp=7.868, rec=0.080, cos=0.001), tot_loss_proj:2.655 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.656 (perp=7.868, rec=0.081, cos=0.002), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]']
[1950/2000] tot_loss=1.654 (perp=7.868, rec=0.079, cos=0.002), tot_loss_proj:2.655 [t=0.17s]
prediction: ['[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.654 (perp=7.868, rec=0.079, cos=0.002), tot_loss_proj:2.648 [t=0.22s]
prediction: ['[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]fk has its tough time balancing toughyaer violence with violence - philosophy philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 64.286 | r: 69.231
rouge2     | fm: 24.000 | p: 23.077 | r: 25.000
rougeL     | fm: 59.259 | p: 57.143 | r: 61.538
rougeLsum  | fm: 59.259 | p: 57.143 | r: 61.538
r1fm+r2fm = 90.667

[Aggregate metrics]:
rouge1     | fm: 88.817 | p: 88.529 | r: 89.239
rouge2     | fm: 58.616 | p: 58.518 | r: 58.789
rougeL     | fm: 78.459 | p: 78.186 | r: 78.832
rougeLsum  | fm: 78.482 | p: 78.235 | r: 78.777
r1fm+r2fm = 147.433

input #72 time: 0:08:23 | total time: 9:56:39


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9991746597716884
highest_index [0]
highest [0.9991746597716884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9928975701332092 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9657580256462097 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9560467600822449 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9083574414253235 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.8474614024162292 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 0.8438819646835327 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.185 (perp=9.723, rec=0.234, cos=0.007), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.026 (perp=9.723, rec=0.079, cos=0.002), tot_loss_proj:2.024 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.036 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.026 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.020 (perp=9.723, rec=0.074, cos=0.002), tot_loss_proj:2.029 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.025 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.016 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:2.038 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.003 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.020 (perp=9.723, rec=0.073, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.004 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.028 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.024 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.027 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.024 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.007 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.017 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.004 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.013 (perp=9.723, rec=0.067, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.012 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.025 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.010 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.013 (perp=9.723, rec=0.067, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=1.996 (perp=9.723, rec=0.049, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.001 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.021 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.014 (perp=9.723, rec=0.068, cos=0.002), tot_loss_proj:2.024 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.014 (perp=9.723, rec=0.068, cos=0.002), tot_loss_proj:2.027 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=1.995 (perp=9.723, rec=0.049, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.022 (perp=9.723, rec=0.076, cos=0.002), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.003 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=1.995 (perp=9.723, rec=0.049, cos=0.002), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.021 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=1.999 (perp=9.723, rec=0.053, cos=0.002), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.015 (perp=9.723, rec=0.069, cos=0.002), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=1.999 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.025 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.007 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.974 | p: 88.652 | r: 89.415
rouge2     | fm: 59.147 | p: 59.043 | r: 59.249
rougeL     | fm: 78.798 | p: 78.533 | r: 79.116
rougeLsum  | fm: 78.658 | p: 78.406 | r: 78.957
r1fm+r2fm = 148.121

input #73 time: 0:07:47 | total time: 10:04:27


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9992591939462341
highest_index [0]
highest [0.9992591939462341]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0006722211837769 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6869400143623352 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6835439205169678 for ['[CLS] answering [SEP]']
[Init] best rec loss: 0.6572129726409912 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.045 (perp=9.381, rec=0.876, cos=0.293), tot_loss_proj:3.049 [t=0.18s]
prediction: ['[CLS] change [SEP]']
[ 100/2000] tot_loss=2.640 (perp=9.152, rec=0.777, cos=0.033), tot_loss_proj:2.814 [t=0.18s]
prediction: ['[CLS] memory [SEP]']
[ 150/2000] tot_loss=2.640 (perp=9.152, rec=0.748, cos=0.062), tot_loss_proj:2.868 [t=0.18s]
prediction: ['[CLS] memory [SEP]']
[ 200/2000] tot_loss=2.823 (perp=10.498, rec=0.700, cos=0.024), tot_loss_proj:3.725 [t=0.18s]
prediction: ['[CLS] blank [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.659 (perp=9.921, rec=0.670, cos=0.005), tot_loss_proj:2.887 [t=0.17s]
prediction: ['[CLS] shares [SEP]']
[ 300/2000] tot_loss=2.644 (perp=9.921, rec=0.657, cos=0.003), tot_loss_proj:2.879 [t=0.18s]
prediction: ['[CLS] shares [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.630 (perp=9.921, rec=0.644, cos=0.002), tot_loss_proj:2.889 [t=0.17s]
prediction: ['[CLS] shares [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.279 (perp=8.178, rec=0.635, cos=0.008), tot_loss_proj:1.897 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=2.272 (perp=8.178, rec=0.633, cos=0.003), tot_loss_proj:1.891 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.260 (perp=8.178, rec=0.623, cos=0.002), tot_loss_proj:1.879 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.262 (perp=8.178, rec=0.621, cos=0.006), tot_loss_proj:1.860 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=2.264 (perp=8.178, rec=0.618, cos=0.010), tot_loss_proj:1.851 [t=0.20s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.254 (perp=8.178, rec=0.614, cos=0.004), tot_loss_proj:1.855 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.255 (perp=8.178, rec=0.609, cos=0.011), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=2.247 (perp=8.178, rec=0.604, cos=0.008), tot_loss_proj:1.827 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.239 (perp=8.178, rec=0.601, cos=0.002), tot_loss_proj:1.818 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.246 (perp=8.178, rec=0.606, cos=0.004), tot_loss_proj:1.825 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=2.248 (perp=8.178, rec=0.607, cos=0.006), tot_loss_proj:1.818 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.236 (perp=8.178, rec=0.598, cos=0.002), tot_loss_proj:1.822 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=2.240 (perp=8.178, rec=0.601, cos=0.003), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=2.237 (perp=8.178, rec=0.599, cos=0.002), tot_loss_proj:1.822 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=2.236 (perp=8.178, rec=0.596, cos=0.005), tot_loss_proj:1.820 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=2.238 (perp=8.178, rec=0.599, cos=0.004), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=2.237 (perp=8.178, rec=0.598, cos=0.003), tot_loss_proj:1.815 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=2.232 (perp=8.178, rec=0.595, cos=0.001), tot_loss_proj:1.812 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=2.229 (perp=8.178, rec=0.593, cos=0.001), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=2.230 (perp=8.178, rec=0.593, cos=0.001), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=2.232 (perp=8.178, rec=0.593, cos=0.004), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=2.234 (perp=8.178, rec=0.598, cos=0.001), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=2.227 (perp=8.178, rec=0.591, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=2.236 (perp=8.178, rec=0.598, cos=0.003), tot_loss_proj:1.790 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=2.233 (perp=8.178, rec=0.597, cos=0.001), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=2.227 (perp=8.178, rec=0.590, cos=0.001), tot_loss_proj:1.798 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=2.232 (perp=8.178, rec=0.593, cos=0.003), tot_loss_proj:1.787 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=2.228 (perp=8.178, rec=0.591, cos=0.002), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=2.227 (perp=8.178, rec=0.591, cos=0.001), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=2.231 (perp=8.178, rec=0.593, cos=0.003), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=2.222 (perp=8.178, rec=0.585, cos=0.001), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=2.232 (perp=8.178, rec=0.596, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=2.231 (perp=8.178, rec=0.594, cos=0.002), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.232 | p: 88.943 | r: 89.602
rouge2     | fm: 59.697 | p: 59.583 | r: 59.815
rougeL     | fm: 79.019 | p: 78.779 | r: 79.347
rougeLsum  | fm: 79.022 | p: 78.794 | r: 79.314
r1fm+r2fm = 148.929

input #74 time: 0:07:44 | total time: 10:12:12


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9993458403755586
highest_index [0]
highest [0.9993458403755586]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9583500623703003 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9476472735404968 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.9449086785316467 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.904586672782898 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8991710543632507 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.8988634347915649 for ['[CLS] gas harbour jobs primarily indy starts smile colorado spirit mach [MASK] academy breakingmetonic ling readerimum millennium [SEP]']
[Init] best rec loss: 0.8913002014160156 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8875274658203125 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8863378167152405 for ['[CLS]thermal howbara single free better coats younger which against goddess portion 2018 octopus managed hu honoraryom compares [SEP]']
[Init] best rec loss: 0.8637418150901794 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8630682826042175 for ['[CLS] magic eachrate apollo stood royalties resultedmmel loopcl skill crown fact viewed auxiliary left regardedception to [SEP]']
[Init] best perm rec loss: 0.8622175455093384 for ['[CLS] stood loop crownrate auxiliarymmel left apollo each royalties to magic viewedcl skillception resulted fact regarded [SEP]']
[Init] best perm rec loss: 0.8622075319290161 for ['[CLS]mmel loop royalties regarded fact magic to left apollo stoodcl skill resultedception viewedrate each crown auxiliary [SEP]']
[Init] best perm rec loss: 0.8609483242034912 for ['[CLS]ceptionmmel auxiliary stood fact apollo regarded viewed eachclrate royalties skill magic crown resulted loop to left [SEP]']
[Init] best perm rec loss: 0.8605997562408447 for ['[CLS] resulted skill apollocl to crown stood auxiliary fact each regardedmmelception loop magic royalties viewed leftrate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.007 (perp=12.581, rec=0.486, cos=0.005), tot_loss_proj:3.724 [t=0.21s]
prediction: ['[CLS] builttead induced champion - endangered wil wonderful. libertadores anthony passingdy breeding energy legal hotel arrivalplify [SEP]']
[ 100/2000] tot_loss=2.720 (perp=11.788, rec=0.362, cos=0.001), tot_loss_proj:4.256 [t=0.19s]
prediction: ['[CLS] buildtead credibility views - cathedral conservatory saved. avoid need acquainted. breeding society easily hotel ignoreplify [SEP]']
[ 150/2000] tot_loss=2.654 (perp=11.748, rec=0.300, cos=0.005), tot_loss_proj:4.263 [t=0.19s]
prediction: ['[CLS] buildtead invariant students into humidity forgotten awarded. avoid need not forgotten unpredictable suffered easily gets forgottenplify [SEP]']
[ 200/2000] tot_loss=2.651 (perp=12.146, rec=0.220, cos=0.001), tot_loss_proj:4.195 [t=0.19s]
prediction: ['[CLS] excursiontead withdrew students into collapse forgotten awarded. dismissed forgotten not forgotten somewhat suffered easily is forgottenwritten [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.396 (perp=11.011, rec=0.192, cos=0.003), tot_loss_proj:4.047 [t=0.19s]
prediction: ['[CLS] excursion is refugees into instability forgottenible raise. easily instability not forgotten easily immunity easily is forgotten everyone [SEP]']
[ 300/2000] tot_loss=2.464 (perp=11.490, rec=0.164, cos=0.001), tot_loss_proj:4.192 [t=0.19s]
prediction: ['[CLS] excursion is into into instabilityenterenter mistress. easily instability not forgotten easily immunity easily is forgotten everyone [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.474 (perp=11.662, rec=0.141, cos=0.001), tot_loss_proj:4.218 [t=0.19s]
prediction: ['[CLS] excursion this into into instability mentalenterenter. dismissed instability not forgotten easily immunity easily is forgotten everyone [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.535 (perp=11.934, rec=0.147, cos=0.001), tot_loss_proj:4.229 [t=0.19s]
prediction: ['[CLS] excursion this into into instability mentalenterenter. dismissed instability not dismissed indeed easily is eaten forgotten everyone [SEP]']
[ 450/2000] tot_loss=2.337 (perp=11.059, rec=0.124, cos=0.001), tot_loss_proj:4.047 [t=0.20s]
prediction: ['[CLS] excursion this into into or mentalenterenter. dismissed instability not dismissed indeed easily is or forgotten everyone [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.171 (perp=10.322, rec=0.105, cos=0.001), tot_loss_proj:3.891 [t=0.17s]
prediction: ['[CLS] this excursion into into or mentalenterenter. dismissed instability not dismissed indeed easily is or forgotten everyone [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.078 (perp=9.854, rec=0.106, cos=0.001), tot_loss_proj:3.838 [t=0.17s]
prediction: ['[CLS] this excursion into into or mentalenterenter everyone dismissed instability not dismissed immunity easily is or forgotten. [SEP]']
[ 600/2000] tot_loss=2.074 (perp=9.854, rec=0.102, cos=0.001), tot_loss_proj:3.841 [t=0.17s]
prediction: ['[CLS] this excursion into into or mentalenterenter everyone dismissed instability not dismissed immunity easily is or forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.999 (perp=9.466, rec=0.105, cos=0.001), tot_loss_proj:3.704 [t=0.17s]
prediction: ['[CLS] this excursion into into or mentalenterenter everyone dismissed instability not dismissed immunity easily or is forgotten. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.902 (perp=9.087, rec=0.084, cos=0.001), tot_loss_proj:3.565 [t=0.17s]
prediction: ['[CLS] this excursion into into enjoyment or mentalenterenter everyone dismissed instability not dismissed easily or is forgotten. [SEP]']
[ 750/2000] tot_loss=2.036 (perp=9.777, rec=0.080, cos=0.001), tot_loss_proj:3.579 [t=0.17s]
prediction: ['[CLS] this excursioned into enjoyment mental mentalenterenter everyone dismissed instability not dismissed easily or is forgotten. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.947 (perp=9.256, rec=0.094, cos=0.001), tot_loss_proj:3.540 [t=0.17s]
prediction: ['[CLS] this excursioned into enjoyment mentalenterenter everyone dismissed mental instability not dismissed easily or is forgotten. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.920 (perp=9.256, rec=0.068, cos=0.001), tot_loss_proj:3.545 [t=0.17s]
prediction: ['[CLS] this excursioned into enjoyment mentalenterenter everyone dismissed mental instability not dismissed easily or is forgotten. [SEP]']
[ 900/2000] tot_loss=1.927 (perp=9.256, rec=0.074, cos=0.001), tot_loss_proj:3.546 [t=0.17s]
prediction: ['[CLS] this excursioned into enjoyment mentalenterenter everyone dismissed mental instability not dismissed easily or is forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.789 (perp=8.543, rec=0.079, cos=0.001), tot_loss_proj:3.534 [t=0.17s]
prediction: ['[CLS] this excursioned into enjoyment mentalenterenter from dismissed mental instability not easily dismissed or is forgotten. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.746 (perp=8.319, rec=0.081, cos=0.001), tot_loss_proj:3.428 [t=0.17s]
prediction: ['[CLS] this excursion into enjoymented mentalenterenter from dismissed mental instability not easily dismissed or is forgotten. [SEP]']
[1050/2000] tot_loss=1.753 (perp=8.319, rec=0.088, cos=0.001), tot_loss_proj:3.432 [t=0.17s]
prediction: ['[CLS] this excursion into enjoymented mentalenterenter from dismissed mental instability not easily dismissed or is forgotten. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.685 (perp=7.987, rec=0.087, cos=0.001), tot_loss_proj:3.375 [t=0.17s]
prediction: ['[CLS] this excursion into enjoymented mentalenterenter is from dismissed mental instability not easily dismissed or forgotten. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.647 (perp=7.836, rec=0.079, cos=0.001), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoymentedenterenter is from dismissed mental instability not easily dismissed or forgotten. [SEP]']
[1200/2000] tot_loss=1.638 (perp=7.836, rec=0.070, cos=0.001), tot_loss_proj:3.371 [t=0.22s]
prediction: ['[CLS] this mental excursion into enjoymentedenterenter is from dismissed mental instability not easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.575 (perp=7.465, rec=0.081, cos=0.001), tot_loss_proj:3.351 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment isenterentered from dismissed mental instability not easily dismissed or forgotten. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.581 (perp=7.465, rec=0.087, cos=0.001), tot_loss_proj:3.353 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment isenterentered from dismissed mental instability not easily dismissed or forgotten. [SEP]']
[1350/2000] tot_loss=1.566 (perp=7.465, rec=0.072, cos=0.001), tot_loss_proj:3.350 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment isenterentered from dismissed mental instability not easily dismissed or forgotten. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.502 (perp=7.154, rec=0.070, cos=0.001), tot_loss_proj:3.161 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily dismissed or forgotten. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.482 (perp=6.973, rec=0.086, cos=0.001), tot_loss_proj:3.155 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
[1500/2000] tot_loss=1.476 (perp=6.973, rec=0.080, cos=0.001), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.473 (perp=6.973, rec=0.078, cos=0.001), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.480 (perp=6.973, rec=0.085, cos=0.001), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
[1650/2000] tot_loss=1.484 (perp=6.973, rec=0.088, cos=0.001), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.468 (perp=6.973, rec=0.072, cos=0.001), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.475 (perp=6.973, rec=0.080, cos=0.001), tot_loss_proj:3.150 [t=0.18s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
[1800/2000] tot_loss=1.471 (perp=6.973, rec=0.076, cos=0.001), tot_loss_proj:3.157 [t=0.19s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.483 (perp=6.973, rec=0.087, cos=0.001), tot_loss_proj:3.148 [t=0.17s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.471 (perp=6.973, rec=0.075, cos=0.001), tot_loss_proj:3.153 [t=0.21s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
[1950/2000] tot_loss=1.475 (perp=6.973, rec=0.079, cos=0.001), tot_loss_proj:3.154 [t=0.21s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.470 (perp=6.973, rec=0.074, cos=0.001), tot_loss_proj:3.152 [t=0.19s]
prediction: ['[CLS] this mental excursion into enjoyment is dismissedenterentered from mental instability not easily forgotten or dismissed. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this mental excursion into enjoyment isenterentered from dismissed mental instability not easily dismissed or forgotten. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.588 | p: 70.588 | r: 70.588
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 70.588 | p: 70.588 | r: 70.588
rougeLsum  | fm: 70.588 | p: 70.588 | r: 70.588
r1fm+r2fm = 120.588

[Aggregate metrics]:
rouge1     | fm: 88.886 | p: 88.594 | r: 89.297
rouge2     | fm: 59.661 | p: 59.548 | r: 59.786
rougeL     | fm: 78.789 | p: 78.575 | r: 79.099
rougeLsum  | fm: 78.885 | p: 78.637 | r: 79.238
r1fm+r2fm = 148.547

input #75 time: 0:08:40 | total time: 10:20:52


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9991386602126575
highest_index [0]
highest [0.9991386602126575]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9212543964385986 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.9036272764205933 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.8987579345703125 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.892052412033081 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8654380440711975 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8489521741867065 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 0.8485825657844543 for ['[CLS] surreal onwardsoning hard ab tauthaw mangoˣ purse left ( pushed backward [SEP]']
[Init] best perm rec loss: 0.8479114174842834 for ['[CLS] purse left hard abˣ backward mango ( surreal tautoning pushed onwardshaw [SEP]']
[Init] best perm rec loss: 0.8466055393218994 for ['[CLS] left mango onwards ( ab hard surreal taut backwardoning purse pushedˣhaw [SEP]']
[Init] best perm rec loss: 0.8464253544807434 for ['[CLS] (haw surreal purse onwards backward hardˣ taut pushedoning mango ab left [SEP]']
[Init] best perm rec loss: 0.846075177192688 for ['[CLS]oning onwards purse left ( taut pushedhaw hard mango backward abˣ surreal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.803 (perp=12.113, rec=0.376, cos=0.004), tot_loss_proj:3.603 [t=0.17s]
prediction: ['[CLS], boss towards attack his. appeared heavily deadgeddents stopped neck abbott [SEP]']
[ 100/2000] tot_loss=2.204 (perp=9.738, rec=0.254, cos=0.002), tot_loss_proj:3.226 [t=0.17s]
prediction: ['[CLS], difficulty tracy attack himself. if heavily stoppedging, stopped challenging s [SEP]']
[ 150/2000] tot_loss=2.066 (perp=9.231, rec=0.213, cos=0.006), tot_loss_proj:2.883 [t=0.17s]
prediction: ["[CLS], allen whenmer himself. as heavily stopped have, stopped has'[SEP]"]
[ 200/2000] tot_loss=2.134 (perp=9.750, rec=0.181, cos=0.003), tot_loss_proj:3.611 [t=0.25s]
prediction: ["[CLS], challenging when system himself, as heavily stopped challenging, stopped has'[SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=1.999 (perp=9.062, rec=0.185, cos=0.002), tot_loss_proj:3.554 [t=0.19s]
prediction: ['[CLS], challenging roll himself, if when against stopped at, stopped has challenging [SEP]']
[ 300/2000] tot_loss=2.072 (perp=8.843, rec=0.270, cos=0.033), tot_loss_proj:3.491 [t=0.19s]
prediction: ['[CLS], challenging without himself, if when 17 stopped ) ; stopped has challenging [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.027 (perp=8.896, rec=0.245, cos=0.003), tot_loss_proj:3.469 [t=0.19s]
prediction: ['[CLS] his challenging him himself, if at be book,, stopped has challenging [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.956 (perp=8.790, rec=0.197, cos=0.002), tot_loss_proj:2.644 [t=0.20s]
prediction: ['[CLS] his challenging early himself, if at at sometimes,, has stopped challenging [SEP]']
[ 450/2000] tot_loss=1.864 (perp=8.478, rec=0.167, cos=0.002), tot_loss_proj:2.549 [t=0.18s]
prediction: ['[CLS] at challenging early himself, if at at 67,, has stopped challenging [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.719 (perp=7.845, rec=0.148, cos=0.002), tot_loss_proj:3.306 [t=0.17s]
prediction: ['[CLS] was challenging his himself if, at at 66,, has stopped challenging [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.682 (perp=7.604, rec=0.159, cos=0.002), tot_loss_proj:2.975 [t=0.17s]
prediction: ['[CLS] was challenging his himself at if, at 66,, has stopped challenging [SEP]']
[ 600/2000] tot_loss=1.653 (perp=7.604, rec=0.130, cos=0.002), tot_loss_proj:2.976 [t=0.17s]
prediction: ['[CLS] was challenging his himself at if, at 66,, has stopped challenging [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.629 (perp=7.434, rec=0.141, cos=0.002), tot_loss_proj:3.429 [t=0.17s]
prediction: ['[CLS] is challenging if, at 66, allen himself at, has stopped challenging [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.605 (perp=7.298, rec=0.143, cos=0.002), tot_loss_proj:3.404 [t=0.17s]
prediction: ['[CLS] is challenging if, at 66, allen at himself, has stopped challenging [SEP]']
[ 750/2000] tot_loss=1.596 (perp=7.298, rec=0.135, cos=0.002), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS] is challenging if, at 66, allen at himself, has stopped challenging [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.588 (perp=7.298, rec=0.127, cos=0.002), tot_loss_proj:3.405 [t=0.17s]
prediction: ['[CLS] is challenging if, at 66, allen at himself, has stopped challenging [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.548 (perp=7.153, rec=0.115, cos=0.002), tot_loss_proj:3.352 [t=0.17s]
prediction: ['[CLS] is challenging if, at 66, at himself, allen has stopped challenging [SEP]']
[ 900/2000] tot_loss=1.549 (perp=7.153, rec=0.117, cos=0.002), tot_loss_proj:3.349 [t=0.17s]
prediction: ['[CLS] is challenging if, at 66, at himself, allen has stopped challenging [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.476 (perp=6.796, rec=0.115, cos=0.002), tot_loss_proj:3.320 [t=0.17s]
prediction: ['[CLS] is challenging if, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
[1000/2000] tot_loss=1.481 (perp=6.796, rec=0.120, cos=0.002), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] is challenging if, at 66, at, allen has stopped challenging himself [SEP]']
[1050/2000] tot_loss=1.466 (perp=6.718, rec=0.120, cos=0.002), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
[1100/2000] tot_loss=1.465 (perp=6.718, rec=0.120, cos=0.002), tot_loss_proj:2.775 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
[1150/2000] tot_loss=1.462 (perp=6.718, rec=0.116, cos=0.002), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
[1200/2000] tot_loss=1.461 (perp=6.718, rec=0.116, cos=0.002), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.465 (perp=6.718, rec=0.119, cos=0.002), tot_loss_proj:2.770 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.459 (perp=6.718, rec=0.114, cos=0.002), tot_loss_proj:2.773 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
[1350/2000] tot_loss=1.458 (perp=6.718, rec=0.113, cos=0.002), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
[1400/2000] tot_loss=1.459 (perp=6.718, rec=0.113, cos=0.002), tot_loss_proj:2.770 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
[1450/2000] tot_loss=1.462 (perp=6.718, rec=0.117, cos=0.002), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
[1500/2000] tot_loss=1.454 (perp=6.718, rec=0.108, cos=0.002), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
[1550/2000] tot_loss=1.441 (perp=6.718, rec=0.095, cos=0.002), tot_loss_proj:2.776 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
[1600/2000] tot_loss=1.459 (perp=6.718, rec=0.114, cos=0.002), tot_loss_proj:2.770 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
[1650/2000] tot_loss=1.448 (perp=6.718, rec=0.102, cos=0.002), tot_loss_proj:2.772 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
[1700/2000] tot_loss=1.453 (perp=6.718, rec=0.107, cos=0.002), tot_loss_proj:2.770 [t=0.17s]
prediction: ['[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=1.449 (perp=6.523, rec=0.139, cos=0.005), tot_loss_proj:2.065 [t=0.17s]
prediction: ['[CLS] as, at 66, at s challenging, allen has stopped challenging himself [SEP]']
[1800/2000] tot_loss=1.429 (perp=6.523, rec=0.122, cos=0.002), tot_loss_proj:2.058 [t=0.17s]
prediction: ['[CLS] as, at 66, at s challenging, allen has stopped challenging himself [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.436 (perp=6.523, rec=0.129, cos=0.002), tot_loss_proj:2.073 [t=0.17s]
prediction: ['[CLS] as, at 66, at s challenging, allen has stopped challenging himself [SEP]']
Attempt swap
[1900/2000] tot_loss=1.424 (perp=6.523, rec=0.118, cos=0.002), tot_loss_proj:2.066 [t=0.17s]
prediction: ['[CLS] as, at 66, at s challenging, allen has stopped challenging himself [SEP]']
[1950/2000] tot_loss=1.420 (perp=6.523, rec=0.114, cos=0.002), tot_loss_proj:2.059 [t=0.17s]
prediction: ['[CLS] as, at 66, at s challenging, allen has stopped challenging himself [SEP]']
Attempt swap
[2000/2000] tot_loss=1.411 (perp=6.523, rec=0.105, cos=0.002), tot_loss_proj:2.063 [t=0.17s]
prediction: ['[CLS] as, at 66, at s challenging, allen has stopped challenging himself [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] is challenging as, at 66, at, allen has stopped challenging himself [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 76.923 | r: 83.333
rouge2     | fm: 43.478 | p: 41.667 | r: 45.455
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 123.478

[Aggregate metrics]:
rouge1     | fm: 88.741 | p: 88.379 | r: 89.163
rouge2     | fm: 59.479 | p: 59.335 | r: 59.652
rougeL     | fm: 78.753 | p: 78.516 | r: 79.134
rougeLsum  | fm: 78.802 | p: 78.542 | r: 79.109
r1fm+r2fm = 148.220

input #76 time: 0:08:24 | total time: 10:29:17


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9992013460879874
highest_index [0]
highest [0.9992013460879874]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.9127402305603027 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8795410990715027 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.8759706020355225 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.8712755441665649 for ['[CLS]yana daylight matthewlson blacksmithdrop county endless rural tel gallery pencil poet something yugoslav [SEP]']
[Init] best perm rec loss: 0.8703407049179077 for ['[CLS] ruraldrop endless yugoslavlson countyyana pencil tel poet something daylight gallery blacksmith matthew [SEP]']
[Init] best perm rec loss: 0.8697276711463928 for ['[CLS] county somethingdropyana gallery rural daylight tellson matthew blacksmith pencil yugoslav endless poet [SEP]']
[Init] best perm rec loss: 0.8681926727294922 for ['[CLS] gallerydrop endless tel matthewyana countylson blacksmith yugoslav rural poet something daylight pencil [SEP]']
[Init] best perm rec loss: 0.8674351572990417 for ['[CLS] pencildrop yugoslav endless something matthew gallery tel ruralyanalson daylight county blacksmith poet [SEP]']
[Init] best perm rec loss: 0.8671553730964661 for ['[CLS] blacksmith countyyana daylight endless yugoslav gallerydrop matthew pencil rural poetlson tel something [SEP]']
[Init] best perm rec loss: 0.8659143447875977 for ['[CLS] poet yugoslav county daylight matthewyanadrop something pencil gallery tel blacksmith endlesslson rural [SEP]']
[Init] best perm rec loss: 0.8652167916297913 for ['[CLS]lson gallery matthewdrop pencil something daylight yugoslav county endless tel rural blacksmith poetyana [SEP]']
[Init] best perm rec loss: 0.8632962107658386 for ['[CLS]yana poet county something matthew blacksmithdrop endless rural pencil tel daylightlson gallery yugoslav [SEP]']
[Init] best perm rec loss: 0.863000750541687 for ['[CLS] poet daylightdrop county something gallery blacksmithlson rural pencil tel yugoslav matthewyana endless [SEP]']
[Init] best perm rec loss: 0.862393856048584 for ['[CLS] poet matthewdrop yugoslav endless galleryyana something countylson tel blacksmith rural pencil daylight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.938 (perp=12.851, rec=0.362, cos=0.006), tot_loss_proj:3.309 [t=0.17s]
prediction: ['[CLS] wilder songigen mary beautiful charlie it rise beacon abbey above kelly eastern revealed recognition [SEP]']
[ 100/2000] tot_loss=2.207 (perp=9.636, rec=0.278, cos=0.001), tot_loss_proj:2.593 [t=0.20s]
prediction: ['[CLS] realm promise above life places above its rise above with above with of making believe [SEP]']
[ 150/2000] tot_loss=2.335 (perp=10.390, rec=0.253, cos=0.004), tot_loss_proj:3.059 [t=0.17s]
prediction: ['[CLS] realm promise above life la above is life above that abovears of making realm [SEP]']
[ 200/2000] tot_loss=2.185 (perp=9.898, rec=0.203, cos=0.002), tot_loss_proj:2.914 [t=0.17s]
prediction: ['[CLS] realm promise above life his above is life above that abovears material their realm [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.979 (perp=8.994, rec=0.179, cos=0.002), tot_loss_proj:2.696 [t=0.17s]
prediction: ['[CLS] promise promise above life the above is life their above that isars material believe [SEP]']
[ 300/2000] tot_loss=2.120 (perp=9.797, rec=0.159, cos=0.001), tot_loss_proj:2.863 [t=0.17s]
prediction: ['[CLS] promise promise above make life above is life make above that itsars material realm [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.887 (perp=8.729, rec=0.140, cos=0.001), tot_loss_proj:2.670 [t=0.17s]
prediction: ['[CLS] make promise above make life above is life make above thatars its material realm [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.863 (perp=8.588, rec=0.143, cos=0.003), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] make promise above make life above is life above their thatars its material realm [SEP]']
[ 450/2000] tot_loss=1.926 (perp=8.994, rec=0.125, cos=0.002), tot_loss_proj:2.670 [t=0.17s]
prediction: ['[CLS] make promise above make life above is life above their thatars its material believe [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.781 (perp=8.198, rec=0.140, cos=0.002), tot_loss_proj:2.586 [t=0.17s]
prediction: ['[CLS] make the promise above make life above is life above thatars its material believe [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.696 (perp=7.797, rec=0.135, cos=0.002), tot_loss_proj:2.267 [t=0.17s]
prediction: ['[CLS] make the promise of is life above thatars above make the its material believe [SEP]']
[ 600/2000] tot_loss=1.672 (perp=7.797, rec=0.112, cos=0.002), tot_loss_proj:2.267 [t=0.17s]
prediction: ['[CLS] make the promise of is life above thatars above make the its material believe [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.788 (perp=8.377, rec=0.111, cos=0.001), tot_loss_proj:2.325 [t=0.17s]
prediction: ['[CLS] make - promise of is life above thatars its above make the material believe [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.672 (perp=7.759, rec=0.118, cos=0.002), tot_loss_proj:2.154 [t=0.17s]
prediction: ['[CLS] make - is promise of life above thatars its above make the material believe [SEP]']
[ 750/2000] tot_loss=1.655 (perp=7.759, rec=0.101, cos=0.002), tot_loss_proj:2.159 [t=0.17s]
prediction: ['[CLS] make - is promise of life above thatars its above make the material believe [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.597 (perp=7.474, rec=0.101, cos=0.002), tot_loss_proj:2.221 [t=0.17s]
prediction: ['[CLS] make - is promise of life above itsars that above make the material believe [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.599 (perp=7.474, rec=0.103, cos=0.002), tot_loss_proj:2.222 [t=0.17s]
prediction: ['[CLS] make - is promise of life above itsars that above make the material believe [SEP]']
[ 900/2000] tot_loss=1.852 (perp=8.752, rec=0.100, cos=0.002), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] make - is promise of life realm itsars that above make the material believe [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.759 (perp=8.278, rec=0.102, cos=0.002), tot_loss_proj:2.303 [t=0.17s]
prediction: ['[CLS] make - is promise of lifears its realm that above make the material believe [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.592 (perp=7.450, rec=0.100, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] make - is promise of lifears above its realm that make the material believe [SEP]']
[1050/2000] tot_loss=1.574 (perp=7.450, rec=0.083, cos=0.002), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] make - is promise of lifears above its realm that make the material believe [SEP]']
Attempt swap
[1100/2000] tot_loss=1.591 (perp=7.450, rec=0.099, cos=0.002), tot_loss_proj:2.098 [t=0.17s]
prediction: ['[CLS] make - is promise of lifears above its realm that make the material believe [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.552 (perp=7.273, rec=0.096, cos=0.001), tot_loss_proj:2.035 [t=0.17s]
prediction: ['[CLS] make is promise of lifears above its realm - that make the material believe [SEP]']
[1200/2000] tot_loss=1.548 (perp=7.273, rec=0.092, cos=0.002), tot_loss_proj:2.037 [t=0.17s]
prediction: ['[CLS] make is promise of lifears above its realm - that make the material believe [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.516 (perp=7.137, rec=0.087, cos=0.002), tot_loss_proj:2.070 [t=0.17s]
prediction: ['[CLS] is make promise of lifears above its realm - that make the material believe [SEP]']
Attempt swap
[1300/2000] tot_loss=1.659 (perp=7.851, rec=0.087, cos=0.002), tot_loss_proj:2.447 [t=0.17s]
prediction: ['[CLS] is make promise of lifears above its realm - that realm the material believe [SEP]']
[1350/2000] tot_loss=1.661 (perp=7.851, rec=0.089, cos=0.002), tot_loss_proj:2.448 [t=0.17s]
prediction: ['[CLS] is make promise of lifears above its realm - that realm the material believe [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.529 (perp=7.176, rec=0.092, cos=0.002), tot_loss_proj:2.275 [t=0.17s]
prediction: ['[CLS] is make promise of lifears above its realm - that the material realm believe [SEP]']
Attempt swap
[1450/2000] tot_loss=1.522 (perp=7.176, rec=0.086, cos=0.002), tot_loss_proj:2.268 [t=0.17s]
prediction: ['[CLS] is make promise of lifears above its realm - that the material realm believe [SEP]']
[1500/2000] tot_loss=1.524 (perp=7.176, rec=0.087, cos=0.002), tot_loss_proj:2.273 [t=0.17s]
prediction: ['[CLS] is make promise of lifears above its realm - that the material realm believe [SEP]']
Attempt swap
[1550/2000] tot_loss=1.519 (perp=7.176, rec=0.082, cos=0.002), tot_loss_proj:2.265 [t=0.17s]
prediction: ['[CLS] is make promise of lifears above its realm - that the material realm believe [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.482 (perp=6.888, rec=0.103, cos=0.002), tot_loss_proj:2.329 [t=0.17s]
prediction: ['[CLS] is make believe promise of lifears above its realm - that the material realm [SEP]']
[1650/2000] tot_loss=1.465 (perp=6.888, rec=0.086, cos=0.002), tot_loss_proj:2.324 [t=0.17s]
prediction: ['[CLS] is make believe promise of lifears above its realm - that the material realm [SEP]']
Attempt swap
Put prefix at the end
[1700/2000] tot_loss=1.367 (perp=6.394, rec=0.086, cos=0.001), tot_loss_proj:2.235 [t=0.17s]
prediction: ['[CLS] make believe promise of lifears above its realm - that the material realm is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.369 (perp=6.394, rec=0.089, cos=0.001), tot_loss_proj:2.225 [t=0.17s]
prediction: ['[CLS] make believe promise of lifears above its realm - that the material realm is [SEP]']
[1800/2000] tot_loss=1.363 (perp=6.394, rec=0.083, cos=0.001), tot_loss_proj:2.225 [t=0.17s]
prediction: ['[CLS] make believe promise of lifears above its realm - that the material realm is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.366 (perp=6.394, rec=0.085, cos=0.002), tot_loss_proj:2.229 [t=0.17s]
prediction: ['[CLS] make believe promise of lifears above its realm - that the material realm is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.368 (perp=6.394, rec=0.088, cos=0.002), tot_loss_proj:2.234 [t=0.17s]
prediction: ['[CLS] make believe promise of lifears above its realm - that the material realm is [SEP]']
[1950/2000] tot_loss=1.371 (perp=6.394, rec=0.090, cos=0.002), tot_loss_proj:2.228 [t=0.20s]
prediction: ['[CLS] make believe promise of lifears above its realm - that the material realm is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.367 (perp=6.394, rec=0.086, cos=0.002), tot_loss_proj:2.233 [t=0.20s]
prediction: ['[CLS] make believe promise of lifears above its realm - that the material realm is [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] is make promise of lifears above its realm - that the material realm believe [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 86.667 | r: 86.667
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 115.238

[Aggregate metrics]:
rouge1     | fm: 88.678 | p: 88.335 | r: 89.224
rouge2     | fm: 58.837 | p: 58.711 | r: 58.990
rougeL     | fm: 78.630 | p: 78.330 | r: 79.004
rougeLsum  | fm: 78.662 | p: 78.377 | r: 79.032
r1fm+r2fm = 147.515

input #77 time: 0:09:36 | total time: 10:38:54


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9992696483604169
highest_index [0]
highest [0.9992696483604169]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9868218302726746 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9798540472984314 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8532800674438477 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8239110112190247 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.8230682015419006 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.513 (perp=10.730, rec=0.356, cos=0.011), tot_loss_proj:3.496 [t=0.17s]
prediction: ['[CLS] collapse exit arrest [SEP]']
[ 100/2000] tot_loss=2.066 (perp=9.346, rec=0.192, cos=0.004), tot_loss_proj:2.608 [t=0.17s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 150/2000] tot_loss=1.992 (perp=9.346, rec=0.121, cos=0.002), tot_loss_proj:2.607 [t=0.17s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 200/2000] tot_loss=1.966 (perp=9.346, rec=0.095, cos=0.002), tot_loss_proj:2.608 [t=0.17s]
prediction: ['[CLS] exit exit theater [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.894 (perp=8.923, rec=0.107, cos=0.002), tot_loss_proj:2.703 [t=0.17s]
prediction: ['[CLS] theater exit exit [SEP]']
[ 300/2000] tot_loss=1.872 (perp=8.923, rec=0.086, cos=0.002), tot_loss_proj:2.706 [t=0.17s]
prediction: ['[CLS] theater exit exit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.869 (perp=8.923, rec=0.083, cos=0.002), tot_loss_proj:2.702 [t=0.17s]
prediction: ['[CLS] theater exit exit [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.711 (perp=8.145, rec=0.081, cos=0.002), tot_loss_proj:2.428 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[ 450/2000] tot_loss=1.703 (perp=8.145, rec=0.073, cos=0.001), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.693 (perp=8.145, rec=0.062, cos=0.001), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.692 (perp=8.145, rec=0.062, cos=0.001), tot_loss_proj:2.438 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[ 600/2000] tot_loss=1.701 (perp=8.145, rec=0.071, cos=0.001), tot_loss_proj:2.441 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.695 (perp=8.145, rec=0.065, cos=0.001), tot_loss_proj:2.443 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.691 (perp=8.145, rec=0.060, cos=0.001), tot_loss_proj:2.441 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[ 750/2000] tot_loss=1.692 (perp=8.145, rec=0.062, cos=0.001), tot_loss_proj:2.444 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.686 (perp=8.145, rec=0.055, cos=0.001), tot_loss_proj:2.440 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.688 (perp=8.145, rec=0.058, cos=0.001), tot_loss_proj:2.436 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[ 900/2000] tot_loss=1.702 (perp=8.145, rec=0.071, cos=0.001), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.685 (perp=8.145, rec=0.055, cos=0.001), tot_loss_proj:2.444 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.700 (perp=8.145, rec=0.070, cos=0.001), tot_loss_proj:2.442 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[1050/2000] tot_loss=1.703 (perp=8.145, rec=0.073, cos=0.001), tot_loss_proj:2.442 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.699 (perp=8.145, rec=0.069, cos=0.001), tot_loss_proj:2.440 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.690 (perp=8.145, rec=0.059, cos=0.001), tot_loss_proj:2.438 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[1200/2000] tot_loss=1.696 (perp=8.145, rec=0.066, cos=0.001), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.707 (perp=8.145, rec=0.076, cos=0.001), tot_loss_proj:2.440 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.708 (perp=8.145, rec=0.078, cos=0.001), tot_loss_proj:2.433 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[1350/2000] tot_loss=1.685 (perp=8.145, rec=0.054, cos=0.001), tot_loss_proj:2.445 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.709 (perp=8.145, rec=0.078, cos=0.001), tot_loss_proj:2.441 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.696 (perp=8.145, rec=0.065, cos=0.001), tot_loss_proj:2.439 [t=0.18s]
prediction: ['[CLS] the theater exit [SEP]']
[1500/2000] tot_loss=1.689 (perp=8.145, rec=0.059, cos=0.001), tot_loss_proj:2.440 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.694 (perp=8.145, rec=0.064, cos=0.001), tot_loss_proj:2.438 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.694 (perp=8.145, rec=0.064, cos=0.001), tot_loss_proj:2.435 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[1650/2000] tot_loss=1.694 (perp=8.145, rec=0.064, cos=0.001), tot_loss_proj:2.442 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.696 (perp=8.145, rec=0.066, cos=0.001), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.692 (perp=8.145, rec=0.062, cos=0.001), tot_loss_proj:2.445 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[1800/2000] tot_loss=1.703 (perp=8.145, rec=0.073, cos=0.001), tot_loss_proj:2.436 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.693 (perp=8.145, rec=0.063, cos=0.001), tot_loss_proj:2.444 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.702 (perp=8.145, rec=0.071, cos=0.001), tot_loss_proj:2.435 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
[1950/2000] tot_loss=1.684 (perp=8.145, rec=0.054, cos=0.001), tot_loss_proj:2.447 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.700 (perp=8.145, rec=0.070, cos=0.001), tot_loss_proj:2.432 [t=0.17s]
prediction: ['[CLS] the theater exit [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] the theater exit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.859 | p: 88.539 | r: 89.330
rouge2     | fm: 58.457 | p: 58.378 | r: 58.680
rougeL     | fm: 78.643 | p: 78.370 | r: 78.977
rougeLsum  | fm: 78.684 | p: 78.435 | r: 79.021
r1fm+r2fm = 147.316

input #78 time: 0:07:57 | total time: 10:46:51


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.9993343381444821
highest_index [0]
highest [0.9993343381444821]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.97676020860672 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8503931164741516 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.8493977189064026 for ['[CLS]rna into [SEP]']
[Init] best rec loss: 0.8459595441818237 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.8386962413787842 for ['[CLS] funslow [SEP]']
[Init] best rec loss: 0.8356737494468689 for ['[CLS] gray should [SEP]']
[Init] best rec loss: 0.8324992060661316 for ['[CLS] comte sculptor [SEP]']
[Init] best perm rec loss: 0.8268929123878479 for ['[CLS] sculptor comte [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.502 (perp=11.428, rec=0.212, cos=0.004), tot_loss_proj:2.630 [t=0.17s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.458 (perp=11.428, rec=0.169, cos=0.003), tot_loss_proj:2.621 [t=0.17s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.436 (perp=11.428, rec=0.147, cos=0.003), tot_loss_proj:2.620 [t=0.17s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=2.435 (perp=11.428, rec=0.147, cos=0.003), tot_loss_proj:2.624 [t=0.17s]
prediction: ['[CLS] fascinating fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.815 (perp=8.695, rec=0.075, cos=0.001), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.814 (perp=8.695, rec=0.074, cos=0.001), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.805 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.807 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.815 (perp=8.695, rec=0.075, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.811 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.807 (perp=8.695, rec=0.067, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.815 (perp=8.695, rec=0.075, cos=0.001), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.970 [t=0.20s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.813 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.800 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.802 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.811 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.033 | p: 88.702 | r: 89.468
rouge2     | fm: 57.724 | p: 57.583 | r: 57.920
rougeL     | fm: 78.530 | p: 78.318 | r: 78.870
rougeLsum  | fm: 78.639 | p: 78.374 | r: 78.970
r1fm+r2fm = 146.757

input #79 time: 0:08:07 | total time: 10:54:59


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9992812106805644
highest_index [0]
highest [0.9992812106805644]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9617707133293152 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9375922083854675 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9287824034690857 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.9259979724884033 for ['[CLS] western area whilepres took [SEP]']
[Init] best rec loss: 0.9242680668830872 for ['[CLS] close blonde form parks pussy [SEP]']
[Init] best rec loss: 0.9182730913162231 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9177989959716797 for ["[CLS] jubilee incense'kraft it [SEP]"]
[Init] best perm rec loss: 0.9138138294219971 for ["[CLS] jubilee'kraft it incense [SEP]"]
[Init] best perm rec loss: 0.913648784160614 for ["[CLS] incense it'jubilee kraft [SEP]"]
[Init] best perm rec loss: 0.9132492542266846 for ["[CLS] kraft jubilee it incense'[SEP]"]
[Init] best perm rec loss: 0.9125822186470032 for ["[CLS] it incense kraft jubilee'[SEP]"]
[Init] best perm rec loss: 0.9123266935348511 for ["[CLS] kraft it'incense jubilee [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=3.437 (perp=13.282, rec=0.770, cos=0.011), tot_loss_proj:4.235 [t=0.17s]
prediction: ['[CLS] phone mine towardbling nowhere [SEP]']
[ 100/2000] tot_loss=2.775 (perp=10.301, rec=0.678, cos=0.037), tot_loss_proj:3.761 [t=0.17s]
prediction: ['[CLS] greenlter wibling, [SEP]']
[ 150/2000] tot_loss=2.910 (perp=11.249, rec=0.636, cos=0.025), tot_loss_proj:4.054 [t=0.17s]
prediction: ['[CLS]nic rhodes wizen, [SEP]']
[ 200/2000] tot_loss=2.673 (perp=10.386, rec=0.592, cos=0.004), tot_loss_proj:3.819 [t=0.17s]
prediction: ['[CLS]zen puzzle wizen, [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.439 (perp=9.078, rec=0.619, cos=0.004), tot_loss_proj:3.268 [t=0.17s]
prediction: ['[CLS] blue, wizen puzzle [SEP]']
[ 300/2000] tot_loss=2.395 (perp=9.078, rec=0.577, cos=0.002), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] blue, wizen puzzle [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.376 (perp=9.078, rec=0.556, cos=0.004), tot_loss_proj:3.245 [t=0.19s]
prediction: ['[CLS] blue, wizen puzzle [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.473 (perp=9.587, rec=0.550, cos=0.006), tot_loss_proj:3.415 [t=0.17s]
prediction: ['[CLS]zen, wizen puzzle [SEP]']
[ 450/2000] tot_loss=2.459 (perp=9.587, rec=0.540, cos=0.002), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS]zen, wizen puzzle [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.485 (perp=9.587, rec=0.555, cos=0.013), tot_loss_proj:3.411 [t=0.17s]
prediction: ['[CLS]zen, wizen puzzle [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.443 (perp=9.587, rec=0.522, cos=0.003), tot_loss_proj:3.417 [t=0.17s]
prediction: ['[CLS]zen, wizen puzzle [SEP]']
[ 600/2000] tot_loss=2.389 (perp=9.230, rec=0.527, cos=0.017), tot_loss_proj:3.404 [t=0.17s]
prediction: ['[CLS]zen, wizen homework [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.368 (perp=9.230, rec=0.516, cos=0.005), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS]zen, wizen homework [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.369 (perp=9.230, rec=0.521, cos=0.002), tot_loss_proj:3.405 [t=0.17s]
prediction: ['[CLS]zen, wizen homework [SEP]']
[ 750/2000] tot_loss=2.361 (perp=9.230, rec=0.512, cos=0.002), tot_loss_proj:3.408 [t=0.17s]
prediction: ['[CLS]zen, wizen homework [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.364 (perp=9.230, rec=0.509, cos=0.008), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS]zen, wizen homework [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.396 (perp=9.432, rec=0.509, cos=0.001), tot_loss_proj:3.588 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
[ 900/2000] tot_loss=2.392 (perp=9.432, rec=0.504, cos=0.001), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.392 (perp=9.432, rec=0.505, cos=0.001), tot_loss_proj:3.581 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1000/2000] tot_loss=2.390 (perp=9.432, rec=0.500, cos=0.004), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
[1050/2000] tot_loss=2.389 (perp=9.432, rec=0.501, cos=0.001), tot_loss_proj:3.588 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1100/2000] tot_loss=2.399 (perp=9.432, rec=0.500, cos=0.012), tot_loss_proj:3.591 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1150/2000] tot_loss=2.393 (perp=9.432, rec=0.505, cos=0.001), tot_loss_proj:3.583 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
[1200/2000] tot_loss=2.392 (perp=9.432, rec=0.502, cos=0.004), tot_loss_proj:3.592 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1250/2000] tot_loss=2.386 (perp=9.432, rec=0.498, cos=0.001), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1300/2000] tot_loss=2.386 (perp=9.432, rec=0.497, cos=0.003), tot_loss_proj:3.590 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
[1350/2000] tot_loss=2.390 (perp=9.432, rec=0.500, cos=0.004), tot_loss_proj:3.589 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1400/2000] tot_loss=2.382 (perp=9.432, rec=0.495, cos=0.001), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1450/2000] tot_loss=2.384 (perp=9.432, rec=0.495, cos=0.002), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
[1500/2000] tot_loss=2.385 (perp=9.432, rec=0.497, cos=0.001), tot_loss_proj:3.580 [t=0.23s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1550/2000] tot_loss=2.382 (perp=9.432, rec=0.494, cos=0.001), tot_loss_proj:3.587 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1600/2000] tot_loss=2.378 (perp=9.432, rec=0.491, cos=0.001), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
[1650/2000] tot_loss=2.382 (perp=9.432, rec=0.494, cos=0.001), tot_loss_proj:3.581 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1700/2000] tot_loss=2.378 (perp=9.432, rec=0.491, cos=0.001), tot_loss_proj:3.589 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1750/2000] tot_loss=2.375 (perp=9.432, rec=0.487, cos=0.001), tot_loss_proj:3.585 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
[1800/2000] tot_loss=2.373 (perp=9.432, rec=0.486, cos=0.001), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1850/2000] tot_loss=2.377 (perp=9.432, rec=0.489, cos=0.001), tot_loss_proj:3.589 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[1900/2000] tot_loss=2.382 (perp=9.432, rec=0.494, cos=0.002), tot_loss_proj:3.581 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
[1950/2000] tot_loss=2.384 (perp=9.432, rec=0.496, cos=0.001), tot_loss_proj:3.583 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Attempt swap
[2000/2000] tot_loss=2.379 (perp=9.432, rec=0.491, cos=0.001), tot_loss_proj:3.582 [t=0.17s]
prediction: ['[CLS] wi, wizen homework [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wi, wizen homework [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 44.444 | p: 40.000 | r: 50.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 44.444 | p: 40.000 | r: 50.000
rougeLsum  | fm: 44.444 | p: 40.000 | r: 50.000
r1fm+r2fm = 44.444

[Aggregate metrics]:
rouge1     | fm: 88.412 | p: 88.058 | r: 88.978
rouge2     | fm: 57.080 | p: 56.968 | r: 57.226
rougeL     | fm: 78.108 | p: 77.794 | r: 78.543
rougeLsum  | fm: 78.239 | p: 77.952 | r: 78.576
r1fm+r2fm = 145.492

input #80 time: 0:07:59 | total time: 11:02:58


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9992879299948307
highest_index [0]
highest [0.9992879299948307]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9063941836357117 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.85554039478302 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8432484865188599 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8243643641471863 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8131975531578064 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8085715174674988 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.794321596622467 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.790020227432251 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 0.7895707488059998 for ['[CLS] ivy proceededplate donaldsondownvik [SEP]']
[Init] best perm rec loss: 0.7880122065544128 for ['[CLS]down ivyvik proceeded donaldsonplate [SEP]']
[Init] best perm rec loss: 0.786943256855011 for ['[CLS] ivy donaldson proceededvikplatedown [SEP]']
[Init] best perm rec loss: 0.7865198850631714 for ['[CLS]vik ivy donaldsondown proceededplate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.725 (perp=11.134, rec=0.488, cos=0.010), tot_loss_proj:3.335 [t=0.17s]
prediction: ['[CLS] t suffered ineffective rate sickms [SEP]']
[ 100/2000] tot_loss=2.823 (perp=12.179, rec=0.383, cos=0.004), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] mikhail suffered poorly rate player products [SEP]']
[ 150/2000] tot_loss=2.594 (perp=11.405, rec=0.310, cos=0.003), tot_loss_proj:3.239 [t=0.17s]
prediction: ['[CLS] sent scores poorly player not best [SEP]']
[ 200/2000] tot_loss=1.997 (perp=8.875, rec=0.220, cos=0.002), tot_loss_proj:2.686 [t=0.17s]
prediction: ['[CLS] z is his player not best [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.851 (perp=8.054, rec=0.233, cos=0.007), tot_loss_proj:2.652 [t=0.17s]
prediction: ['[CLS] item is not not best player [SEP]']
[ 300/2000] tot_loss=2.059 (perp=9.360, rec=0.185, cos=0.002), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] greg is not not most player [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.935 (perp=8.837, rec=0.166, cos=0.002), tot_loss_proj:2.732 [t=0.17s]
prediction: ['[CLS] not most player quite is not [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.491 (perp=6.617, rec=0.166, cos=0.002), tot_loss_proj:2.434 [t=0.17s]
prediction: ['[CLS] not the most player is not [SEP]']
[ 450/2000] tot_loss=1.470 (perp=6.617, rec=0.145, cos=0.001), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] not the most player is not [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.505 (perp=6.859, rec=0.132, cos=0.001), tot_loss_proj:2.180 [t=0.17s]
prediction: ['[CLS] not the most player is impressive [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.007 (perp=9.239, rec=0.157, cos=0.002), tot_loss_proj:2.613 [t=0.17s]
prediction: ['[CLS] player is not quite most his [SEP]']
[ 600/2000] tot_loss=1.542 (perp=7.027, rec=0.135, cos=0.001), tot_loss_proj:1.917 [t=0.17s]
prediction: ['[CLS] player is not a most impressive [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.407 (perp=6.337, rec=0.139, cos=0.001), tot_loss_proj:1.533 [t=0.17s]
prediction: ['[CLS] is not a most impressive player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.403 (perp=6.337, rec=0.134, cos=0.001), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] is not a most impressive player [SEP]']
[ 750/2000] tot_loss=1.315 (perp=5.977, rec=0.118, cos=0.001), tot_loss_proj:1.335 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.308 (perp=5.977, rec=0.111, cos=0.001), tot_loss_proj:1.336 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.291 (perp=5.977, rec=0.094, cos=0.001), tot_loss_proj:1.334 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[ 900/2000] tot_loss=1.296 (perp=5.977, rec=0.099, cos=0.001), tot_loss_proj:1.330 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.285 (perp=5.977, rec=0.088, cos=0.001), tot_loss_proj:1.338 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.281 (perp=5.977, rec=0.084, cos=0.001), tot_loss_proj:1.334 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1050/2000] tot_loss=1.288 (perp=5.977, rec=0.091, cos=0.001), tot_loss_proj:1.332 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.277 (perp=5.977, rec=0.080, cos=0.001), tot_loss_proj:1.338 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.273 (perp=5.977, rec=0.076, cos=0.001), tot_loss_proj:1.332 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1200/2000] tot_loss=1.275 (perp=5.977, rec=0.078, cos=0.001), tot_loss_proj:1.329 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.273 (perp=5.977, rec=0.076, cos=0.001), tot_loss_proj:1.332 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.270 (perp=5.977, rec=0.073, cos=0.001), tot_loss_proj:1.332 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1350/2000] tot_loss=1.261 (perp=5.977, rec=0.064, cos=0.001), tot_loss_proj:1.337 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.278 (perp=5.977, rec=0.081, cos=0.001), tot_loss_proj:1.336 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.267 (perp=5.977, rec=0.070, cos=0.001), tot_loss_proj:1.331 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1500/2000] tot_loss=1.270 (perp=5.977, rec=0.074, cos=0.001), tot_loss_proj:1.331 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.266 (perp=5.977, rec=0.069, cos=0.001), tot_loss_proj:1.332 [t=0.19s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.263 (perp=5.977, rec=0.066, cos=0.001), tot_loss_proj:1.333 [t=0.20s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1650/2000] tot_loss=1.260 (perp=5.977, rec=0.063, cos=0.001), tot_loss_proj:1.326 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.263 (perp=5.977, rec=0.067, cos=0.001), tot_loss_proj:1.330 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.268 (perp=5.977, rec=0.071, cos=0.001), tot_loss_proj:1.327 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1800/2000] tot_loss=1.253 (perp=5.977, rec=0.056, cos=0.001), tot_loss_proj:1.334 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.267 (perp=5.977, rec=0.070, cos=0.001), tot_loss_proj:1.333 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.266 (perp=5.977, rec=0.070, cos=0.001), tot_loss_proj:1.332 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
[1950/2000] tot_loss=1.270 (perp=5.977, rec=0.073, cos=0.001), tot_loss_proj:1.340 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.263 (perp=5.977, rec=0.066, cos=0.001), tot_loss_proj:1.334 [t=0.17s]
prediction: ['[CLS] is not the most impressive player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] is not the most impressive player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.579 | p: 88.219 | r: 89.049
rouge2     | fm: 57.409 | p: 57.275 | r: 57.604
rougeL     | fm: 78.422 | p: 78.123 | r: 78.771
rougeLsum  | fm: 78.466 | p: 78.195 | r: 78.899
r1fm+r2fm = 145.988

input #81 time: 0:08:01 | total time: 11:11:00


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.9992801011451229
highest_index [0]
highest [0.9992801011451229]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.98771733045578 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9761659502983093 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9474851489067078 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9335925579071045 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9326500296592712 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.8672366738319397 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.8271898627281189 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8216337561607361 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8212171196937561 for ['[CLS]basket plumage whoeverach respective role recordfur [SEP]']
[Init] best perm rec loss: 0.8198072910308838 for ['[CLS] respectivebasket record plumagefurach role whoever [SEP]']
[Init] best perm rec loss: 0.819161593914032 for ['[CLS] respectiveach whoeverfur role record plumagebasket [SEP]']
[Init] best perm rec loss: 0.81831294298172 for ['[CLS]fur respective rolebasketach plumage whoever record [SEP]']
[Init] best perm rec loss: 0.8175076842308044 for ['[CLS] whoeverbasket role respective plumagefurach record [SEP]']
[Init] best perm rec loss: 0.8163747787475586 for ['[CLS]furbasket respective roleach plumage record whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.738 (perp=12.284, rec=0.279, cos=0.003), tot_loss_proj:3.381 [t=0.20s]
prediction: ['[CLS] wasted undone mates shows undone timing unanimous [SEP]']
[ 100/2000] tot_loss=2.407 (perp=11.136, rec=0.179, cos=0.001), tot_loss_proj:2.912 [t=0.17s]
prediction: ['[CLS] undone undone itses by undone script it [SEP]']
[ 150/2000] tot_loss=2.263 (perp=10.693, rec=0.123, cos=0.002), tot_loss_proj:2.754 [t=0.17s]
prediction: ['[CLS] undone undone s s by undone script it [SEP]']
[ 200/2000] tot_loss=2.312 (perp=11.081, rec=0.094, cos=0.001), tot_loss_proj:2.847 [t=0.17s]
prediction: ['[CLS] undone sloppy a s by undone script it [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.053 (perp=9.865, rec=0.079, cos=0.001), tot_loss_proj:2.541 [t=0.17s]
prediction: ['[CLS] a sloppy undone s by undone script it [SEP]']
[ 300/2000] tot_loss=2.033 (perp=9.865, rec=0.059, cos=0.001), tot_loss_proj:2.539 [t=0.17s]
prediction: ['[CLS] a sloppy undone s by undone script it [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.814 (perp=8.711, rec=0.071, cos=0.001), tot_loss_proj:2.145 [t=0.17s]
prediction: ['[CLS] a sloppy undone s script undone by it [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.680 (perp=8.013, rec=0.077, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[ 450/2000] tot_loss=1.672 (perp=8.013, rec=0.068, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.667 (perp=8.013, rec=0.063, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.668 (perp=8.013, rec=0.065, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[ 600/2000] tot_loss=1.664 (perp=8.013, rec=0.061, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.669 (perp=8.013, rec=0.065, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.675 (perp=8.013, rec=0.071, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[ 750/2000] tot_loss=1.679 (perp=8.013, rec=0.076, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.670 (perp=8.013, rec=0.066, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.668 (perp=8.013, rec=0.064, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[ 900/2000] tot_loss=1.679 (perp=8.013, rec=0.075, cos=0.001), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.676 (perp=8.013, rec=0.072, cos=0.001), tot_loss_proj:1.963 [t=0.18s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1000/2000] tot_loss=1.677 (perp=8.013, rec=0.073, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[1050/2000] tot_loss=1.682 (perp=8.013, rec=0.079, cos=0.001), tot_loss_proj:1.970 [t=0.18s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1100/2000] tot_loss=1.679 (perp=8.013, rec=0.075, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1150/2000] tot_loss=1.671 (perp=8.013, rec=0.067, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[1200/2000] tot_loss=1.668 (perp=8.013, rec=0.064, cos=0.001), tot_loss_proj:1.965 [t=0.18s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1250/2000] tot_loss=1.662 (perp=8.013, rec=0.058, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1300/2000] tot_loss=1.675 (perp=8.013, rec=0.071, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[1350/2000] tot_loss=1.669 (perp=8.013, rec=0.065, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1400/2000] tot_loss=1.675 (perp=8.013, rec=0.071, cos=0.001), tot_loss_proj:1.969 [t=0.19s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1450/2000] tot_loss=1.671 (perp=8.013, rec=0.067, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[1500/2000] tot_loss=1.669 (perp=8.013, rec=0.065, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1550/2000] tot_loss=1.674 (perp=8.013, rec=0.070, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1600/2000] tot_loss=1.668 (perp=8.013, rec=0.065, cos=0.001), tot_loss_proj:1.961 [t=0.19s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[1650/2000] tot_loss=1.669 (perp=8.013, rec=0.065, cos=0.001), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1700/2000] tot_loss=1.673 (perp=8.013, rec=0.069, cos=0.001), tot_loss_proj:1.974 [t=0.19s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1750/2000] tot_loss=1.674 (perp=8.013, rec=0.070, cos=0.001), tot_loss_proj:1.964 [t=0.20s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[1800/2000] tot_loss=1.671 (perp=8.013, rec=0.067, cos=0.001), tot_loss_proj:1.968 [t=0.20s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1850/2000] tot_loss=1.674 (perp=8.013, rec=0.070, cos=0.001), tot_loss_proj:1.969 [t=0.19s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[1900/2000] tot_loss=1.666 (perp=8.013, rec=0.062, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
[1950/2000] tot_loss=1.673 (perp=8.013, rec=0.069, cos=0.001), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Attempt swap
[2000/2000] tot_loss=1.675 (perp=8.013, rec=0.071, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] a sloppy script undone s undone by it [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] a sloppy script undone s undone by it [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 52.632 | p: 50.000 | r: 55.556
rougeLsum  | fm: 52.632 | p: 50.000 | r: 55.556
r1fm+r2fm = 141.796

[Aggregate metrics]:
rouge1     | fm: 88.737 | p: 88.332 | r: 89.257
rouge2     | fm: 57.493 | p: 57.315 | r: 57.656
rougeL     | fm: 78.084 | p: 77.818 | r: 78.499
rougeLsum  | fm: 78.169 | p: 77.857 | r: 78.611
r1fm+r2fm = 146.230

input #82 time: 0:08:35 | total time: 11:19:35


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9992427003793516
highest_index [0]
highest [0.9992427003793516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9601501822471619 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9566210508346558 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9550451636314392 for ['[CLS] ben tawork position naked map because sort been season [SEP]']
[Init] best rec loss: 0.9463936686515808 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.887312650680542 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8696892261505127 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8692896366119385 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.8648756146430969 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.8604941964149475 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8593842387199402 for ['[CLS] ut sighed another tex predicted hooper alsoов toes personally [SEP]']
[Init] best rec loss: 0.8368008732795715 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8151112198829651 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8039038181304932 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.8021044135093689 for ['[CLS] vice neck pitch comprehensive stew follows boys nearly residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.812 (perp=12.006, rec=0.394, cos=0.017), tot_loss_proj:3.445 [t=0.17s]
prediction: ['[CLS] develop pretty becoming the captain doctor region paradise desmond parliament [SEP]']
[ 100/2000] tot_loss=2.325 (perp=10.208, rec=0.281, cos=0.003), tot_loss_proj:3.193 [t=0.17s]
prediction: ['[CLS] know about growing the young writer became grown know inherited [SEP]']
[ 150/2000] tot_loss=2.235 (perp=9.982, rec=0.236, cos=0.002), tot_loss_proj:3.209 [t=0.17s]
prediction: ['[CLS] know when growing when being gets when grown know grows [SEP]']
[ 200/2000] tot_loss=2.108 (perp=9.600, rec=0.186, cos=0.002), tot_loss_proj:2.915 [t=0.17s]
prediction: ['[CLS] know get what when it wants grows grows soon grows [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.771 (perp=8.083, rec=0.153, cos=0.002), tot_loss_proj:2.685 [t=0.17s]
prediction: ['[CLS] know what grown when it wants grows what soon becomes [SEP]']
[ 300/2000] tot_loss=1.627 (perp=7.444, rec=0.136, cos=0.001), tot_loss_proj:2.509 [t=0.17s]
prediction: ['[CLS] know what grows when it wants grows what soon becomes [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.889 (perp=8.844, rec=0.119, cos=0.002), tot_loss_proj:2.549 [t=0.17s]
prediction: ['[CLS] know what grow when it grows wants be up becomes [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.690 (perp=7.926, rec=0.103, cos=0.001), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS] know what grows when it grows up wants be becomes [SEP]']
[ 450/2000] tot_loss=1.656 (perp=7.807, rec=0.093, cos=0.001), tot_loss_proj:2.068 [t=0.17s]
prediction: ['[CLS] know what it when it grows up wants be up [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.347 (perp=6.316, rec=0.082, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] know what it wants when it grows up be up [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.340 (perp=6.316, rec=0.076, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] know what it wants when it grows up be up [SEP]']
[ 600/2000] tot_loss=1.337 (perp=6.316, rec=0.073, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] know what it wants when it grows up be up [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.343 (perp=6.316, rec=0.078, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] know what it wants when it grows up be up [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.343 (perp=6.316, rec=0.078, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] know what it wants when it grows up be up [SEP]']
[ 750/2000] tot_loss=1.342 (perp=6.316, rec=0.078, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] know what it wants when it grows up be up [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.303 (perp=6.129, rec=0.076, cos=0.001), tot_loss_proj:1.468 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.302 (perp=6.129, rec=0.075, cos=0.001), tot_loss_proj:1.465 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[ 900/2000] tot_loss=1.302 (perp=6.129, rec=0.075, cos=0.001), tot_loss_proj:1.476 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.304 (perp=6.129, rec=0.076, cos=0.001), tot_loss_proj:1.472 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.292 (perp=6.129, rec=0.065, cos=0.001), tot_loss_proj:1.475 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[1050/2000] tot_loss=1.298 (perp=6.129, rec=0.070, cos=0.001), tot_loss_proj:1.469 [t=0.19s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.305 (perp=6.129, rec=0.077, cos=0.001), tot_loss_proj:1.471 [t=0.21s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.294 (perp=6.129, rec=0.067, cos=0.001), tot_loss_proj:1.469 [t=0.19s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[1200/2000] tot_loss=1.297 (perp=6.129, rec=0.070, cos=0.001), tot_loss_proj:1.468 [t=0.19s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.292 (perp=6.129, rec=0.065, cos=0.001), tot_loss_proj:1.476 [t=0.19s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.304 (perp=6.129, rec=0.076, cos=0.001), tot_loss_proj:1.477 [t=0.19s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[1350/2000] tot_loss=1.294 (perp=6.129, rec=0.067, cos=0.001), tot_loss_proj:1.476 [t=0.19s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.300 (perp=6.129, rec=0.073, cos=0.001), tot_loss_proj:1.467 [t=0.19s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.292 (perp=6.129, rec=0.064, cos=0.001), tot_loss_proj:1.463 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[1500/2000] tot_loss=1.295 (perp=6.129, rec=0.067, cos=0.001), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.305 (perp=6.129, rec=0.078, cos=0.001), tot_loss_proj:1.478 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.290 (perp=6.129, rec=0.063, cos=0.001), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[1650/2000] tot_loss=1.293 (perp=6.129, rec=0.066, cos=0.001), tot_loss_proj:1.474 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.300 (perp=6.129, rec=0.073, cos=0.001), tot_loss_proj:1.480 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.294 (perp=6.129, rec=0.067, cos=0.001), tot_loss_proj:1.474 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[1800/2000] tot_loss=1.291 (perp=6.129, rec=0.064, cos=0.001), tot_loss_proj:1.472 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.299 (perp=6.129, rec=0.071, cos=0.001), tot_loss_proj:1.472 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.299 (perp=6.129, rec=0.072, cos=0.001), tot_loss_proj:1.474 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
[1950/2000] tot_loss=1.295 (perp=6.129, rec=0.068, cos=0.001), tot_loss_proj:1.468 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.294 (perp=6.129, rec=0.067, cos=0.001), tot_loss_proj:1.472 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants be when it grows up up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 81.818 | p: 81.818 | r: 81.818
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 173.485

[Aggregate metrics]:
rouge1     | fm: 88.734 | p: 88.293 | r: 89.277
rouge2     | fm: 57.670 | p: 57.496 | r: 57.854
rougeL     | fm: 78.302 | p: 77.984 | r: 78.760
rougeLsum  | fm: 78.297 | p: 77.923 | r: 78.735
r1fm+r2fm = 146.405

input #83 time: 0:08:17 | total time: 11:27:52


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9991125724774641
highest_index [0]
highest [0.9991125724774641]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9286046624183655 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.9211990833282471 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.8995694518089294 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8926138281822205 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8923629522323608 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8866891264915466 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8839888572692871 for ['[CLS]oglaise catholicur prototype issues cheered [SEP]']
[Init] best rec loss: 0.8611317276954651 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best perm rec loss: 0.8604739904403687 for ['[CLS] sar block is whetherness project dark [SEP]']
[Init] best perm rec loss: 0.8604679703712463 for ['[CLS] block dark sar whether isness project [SEP]']
[Init] best perm rec loss: 0.85843825340271 for ['[CLS] whether sar project block is darkness [SEP]']
[Init] best perm rec loss: 0.8576532006263733 for ['[CLS] whether is block projectness dark sar [SEP]']
[Init] best perm rec loss: 0.8570180535316467 for ['[CLS] sar block project dark is whetherness [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.920 (perp=12.704, rec=0.375, cos=0.004), tot_loss_proj:3.512 [t=0.17s]
prediction: ['[CLS] pair lostinkles shape hang off lost [SEP]']
[ 100/2000] tot_loss=2.055 (perp=9.036, rec=0.243, cos=0.005), tot_loss_proj:2.431 [t=0.17s]
prediction: ['[CLS] people lost people think ability to lost [SEP]']
[ 150/2000] tot_loss=1.960 (perp=9.022, rec=0.153, cos=0.003), tot_loss_proj:2.448 [t=0.17s]
prediction: ['[CLS] people lost people think ability have lost [SEP]']
[ 200/2000] tot_loss=1.915 (perp=9.022, rec=0.109, cos=0.002), tot_loss_proj:2.474 [t=0.17s]
prediction: ['[CLS] people lost people think ability have lost [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.638 (perp=7.657, rec=0.105, cos=0.002), tot_loss_proj:2.247 [t=0.17s]
prediction: ['[CLS] people lost ability think people have lost [SEP]']
[ 300/2000] tot_loss=1.624 (perp=7.657, rec=0.091, cos=0.002), tot_loss_proj:2.241 [t=0.17s]
prediction: ['[CLS] people lost ability think people have lost [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.632 (perp=7.657, rec=0.099, cos=0.002), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS] people lost ability think people have lost [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.718 (perp=8.136, rec=0.089, cos=0.002), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] people lost the ability think have lost [SEP]']
[ 450/2000] tot_loss=1.710 (perp=8.136, rec=0.081, cos=0.002), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] people lost the ability think have lost [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.582 (perp=7.545, rec=0.071, cos=0.002), tot_loss_proj:1.989 [t=0.17s]
prediction: ['[CLS] people have lost the ability think lost [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.560 (perp=7.432, rec=0.072, cos=0.002), tot_loss_proj:1.845 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 600/2000] tot_loss=1.559 (perp=7.432, rec=0.071, cos=0.002), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.560 (perp=7.432, rec=0.072, cos=0.002), tot_loss_proj:1.843 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.559 (perp=7.432, rec=0.071, cos=0.002), tot_loss_proj:1.846 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 750/2000] tot_loss=1.559 (perp=7.432, rec=0.071, cos=0.002), tot_loss_proj:1.844 [t=0.19s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.557 (perp=7.432, rec=0.069, cos=0.002), tot_loss_proj:1.842 [t=0.18s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.571 (perp=7.432, rec=0.083, cos=0.002), tot_loss_proj:1.847 [t=0.18s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[ 900/2000] tot_loss=1.573 (perp=7.432, rec=0.085, cos=0.002), tot_loss_proj:1.844 [t=0.18s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.565 (perp=7.432, rec=0.077, cos=0.002), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1000/2000] tot_loss=1.555 (perp=7.432, rec=0.067, cos=0.002), tot_loss_proj:1.840 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1050/2000] tot_loss=1.568 (perp=7.432, rec=0.080, cos=0.002), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.554 (perp=7.432, rec=0.066, cos=0.002), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1150/2000] tot_loss=1.561 (perp=7.432, rec=0.073, cos=0.002), tot_loss_proj:1.840 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1200/2000] tot_loss=1.554 (perp=7.432, rec=0.065, cos=0.002), tot_loss_proj:1.840 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.562 (perp=7.432, rec=0.074, cos=0.002), tot_loss_proj:1.834 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.563 (perp=7.432, rec=0.075, cos=0.002), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1350/2000] tot_loss=1.566 (perp=7.432, rec=0.078, cos=0.002), tot_loss_proj:1.837 [t=0.19s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.571 (perp=7.432, rec=0.083, cos=0.002), tot_loss_proj:1.833 [t=0.18s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.569 (perp=7.432, rec=0.081, cos=0.002), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1500/2000] tot_loss=1.549 (perp=7.432, rec=0.061, cos=0.002), tot_loss_proj:1.831 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.574 (perp=7.432, rec=0.086, cos=0.002), tot_loss_proj:1.832 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1600/2000] tot_loss=1.557 (perp=7.432, rec=0.069, cos=0.002), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1650/2000] tot_loss=1.563 (perp=7.432, rec=0.075, cos=0.002), tot_loss_proj:1.830 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.563 (perp=7.432, rec=0.075, cos=0.002), tot_loss_proj:1.838 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.557 (perp=7.432, rec=0.069, cos=0.002), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1800/2000] tot_loss=1.558 (perp=7.432, rec=0.070, cos=0.002), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.568 (perp=7.432, rec=0.079, cos=0.002), tot_loss_proj:1.830 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.561 (perp=7.432, rec=0.073, cos=0.002), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
[1950/2000] tot_loss=1.566 (perp=7.432, rec=0.077, cos=0.002), tot_loss_proj:1.829 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.560 (perp=7.432, rec=0.072, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] people have lost the lost ability think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the lost ability think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 151.389

[Aggregate metrics]:
rouge1     | fm: 88.726 | p: 88.265 | r: 89.300
rouge2     | fm: 57.658 | p: 57.525 | r: 57.844
rougeL     | fm: 78.401 | p: 78.088 | r: 78.803
rougeLsum  | fm: 78.441 | p: 78.105 | r: 78.883
r1fm+r2fm = 146.384

input #84 time: 0:09:40 | total time: 11:37:32


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9992374406339235
highest_index [0]
highest [0.9992374406339235]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9699996709823608 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9557927250862122 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.933201789855957 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8898030519485474 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8735714554786682 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.8669417500495911 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8647000193595886 for ['[CLS]lein laps roadrman indian background indiesthing defender fallen [SEP]']
[Init] best perm rec loss: 0.8642165064811707 for ['[CLS]rmanlein indies lapsthing fallen defender background road indian [SEP]']
[Init] best perm rec loss: 0.8628117442131042 for ['[CLS] indiesleinthing lapsrman indian defender background fallen road [SEP]']
[Init] best perm rec loss: 0.8601159453392029 for ['[CLS] indieslein fallen road background laps indianthing defenderrman [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.718 (perp=11.460, rec=0.422, cos=0.004), tot_loss_proj:3.093 [t=0.17s]
prediction: ['[CLS] maria junk extremelyiful parts least valuable unfortunately, unfortunately [SEP]']
[ 100/2000] tot_loss=2.225 (perp=9.623, rec=0.299, cos=0.002), tot_loss_proj:2.704 [t=0.18s]
prediction: ['[CLS] unfortunately un alsoiful little not good unfortunately, unfortunately [SEP]']
[ 150/2000] tot_loss=1.937 (perp=8.766, rec=0.182, cos=0.002), tot_loss_proj:2.436 [t=0.21s]
prediction: ['[CLS] unfortunately un also extremely not also good unfortunately, unfortunately [SEP]']
[ 200/2000] tot_loss=1.516 (perp=6.813, rec=0.152, cos=0.002), tot_loss_proj:1.920 [t=0.20s]
prediction: ['[CLS] unfortunately is also extremely not very good unfortunately. unfortunately [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.589 (perp=7.328, rec=0.122, cos=0.001), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] unfortunately s also extremely unfortunately not very good unfortunately. [SEP]']
[ 300/2000] tot_loss=1.571 (perp=7.328, rec=0.104, cos=0.002), tot_loss_proj:2.203 [t=0.21s]
prediction: ['[CLS] unfortunately s also extremely unfortunately not very good unfortunately. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.611 (perp=7.570, rec=0.095, cos=0.002), tot_loss_proj:2.040 [t=0.17s]
prediction: ['[CLS] unfortunately s also not unfortunately unfortunately not very good. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.494 (perp=7.000, rec=0.093, cos=0.001), tot_loss_proj:1.920 [t=0.17s]
prediction: ['[CLS] unfortunately s also unfortunately not unfortunately not very good. [SEP]']
[ 450/2000] tot_loss=1.481 (perp=7.000, rec=0.080, cos=0.001), tot_loss_proj:1.922 [t=0.17s]
prediction: ['[CLS] unfortunately s also unfortunately not unfortunately not very good. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.486 (perp=7.000, rec=0.084, cos=0.002), tot_loss_proj:1.921 [t=0.17s]
prediction: ['[CLS] unfortunately s also unfortunately not unfortunately not very good. [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.443 (perp=6.737, rec=0.094, cos=0.002), tot_loss_proj:1.860 [t=0.17s]
prediction: ['[CLS] unfortunately also s unfortunately not unfortunately not very good. [SEP]']
[ 600/2000] tot_loss=1.429 (perp=6.737, rec=0.080, cos=0.002), tot_loss_proj:1.862 [t=0.17s]
prediction: ['[CLS] unfortunately also s unfortunately not unfortunately not very good. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.713 (perp=8.140, rec=0.083, cos=0.001), tot_loss_proj:2.124 [t=0.19s]
prediction: ['[CLS] photon also s unfortunately not unfortunately not very good. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.593 (perp=7.554, rec=0.080, cos=0.002), tot_loss_proj:2.026 [t=0.19s]
prediction: ['[CLS] photon s also unfortunately not unfortunately not very good. [SEP]']
[ 750/2000] tot_loss=1.556 (perp=7.373, rec=0.080, cos=0.002), tot_loss_proj:2.072 [t=0.19s]
prediction: ['[CLS] photon s also, not unfortunately not very good. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.532 (perp=7.248, rec=0.080, cos=0.002), tot_loss_proj:1.988 [t=0.19s]
prediction: ['[CLS] ς s, not unfortunately also not very good. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.548 (perp=6.846, rec=0.174, cos=0.005), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] s, not unfortunately also not very good ª. [SEP]']
[ 900/2000] tot_loss=1.489 (perp=6.846, rec=0.118, cos=0.002), tot_loss_proj:1.954 [t=0.17s]
prediction: ['[CLS] s, not unfortunately also not very good ª. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.427 (perp=6.597, rec=0.106, cos=0.002), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.415 (perp=6.597, rec=0.094, cos=0.002), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
[1050/2000] tot_loss=1.424 (perp=6.597, rec=0.103, cos=0.002), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.421 (perp=6.597, rec=0.100, cos=0.002), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.411 (perp=6.597, rec=0.091, cos=0.002), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
[1200/2000] tot_loss=1.407 (perp=6.597, rec=0.086, cos=0.002), tot_loss_proj:1.911 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.409 (perp=6.597, rec=0.088, cos=0.002), tot_loss_proj:1.911 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.400 (perp=6.597, rec=0.079, cos=0.002), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
[1350/2000] tot_loss=1.418 (perp=6.597, rec=0.097, cos=0.002), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.407 (perp=6.597, rec=0.086, cos=0.002), tot_loss_proj:1.898 [t=0.18s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.400 (perp=6.597, rec=0.079, cos=0.002), tot_loss_proj:1.910 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
[1500/2000] tot_loss=1.408 (perp=6.597, rec=0.088, cos=0.002), tot_loss_proj:1.912 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.399 (perp=6.597, rec=0.078, cos=0.002), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.399 (perp=6.597, rec=0.079, cos=0.002), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
[1650/2000] tot_loss=1.405 (perp=6.597, rec=0.084, cos=0.002), tot_loss_proj:1.903 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.398 (perp=6.597, rec=0.077, cos=0.002), tot_loss_proj:1.910 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.404 (perp=6.597, rec=0.083, cos=0.002), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
[1800/2000] tot_loss=1.402 (perp=6.597, rec=0.081, cos=0.002), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.397 (perp=6.597, rec=0.076, cos=0.002), tot_loss_proj:1.909 [t=0.17s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.409 (perp=6.597, rec=0.088, cos=0.002), tot_loss_proj:1.904 [t=0.19s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
[1950/2000] tot_loss=1.398 (perp=6.597, rec=0.077, cos=0.002), tot_loss_proj:1.906 [t=0.19s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.401 (perp=6.597, rec=0.080, cos=0.002), tot_loss_proj:1.912 [t=0.19s]
prediction: ['[CLS] s, unfortunately not also not very good ª. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] ς s, not unfortunately also not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 138.889

[Aggregate metrics]:
rouge1     | fm: 88.734 | p: 88.324 | r: 89.282
rouge2     | fm: 57.477 | p: 57.304 | r: 57.670
rougeL     | fm: 78.410 | p: 78.102 | r: 78.848
rougeLsum  | fm: 78.464 | p: 78.174 | r: 78.855
r1fm+r2fm = 146.211

input #85 time: 0:09:57 | total time: 11:47:30


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9993327117168653
highest_index [0]
highest [0.9993327117168653]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9209051132202148 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9168149828910828 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8586238026618958 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7911268472671509 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7695991396903992 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.7565065622329712 for ['[CLS] liberated round alright [SEP]']
[Init] best perm rec loss: 0.7532469630241394 for ['[CLS] alright round liberated [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.447 (perp=5.953, rec=0.252, cos=0.005), tot_loss_proj:1.398 [t=0.17s]
prediction: ['[CLS] clarity and clarity [SEP]']
[ 100/2000] tot_loss=2.207 (perp=10.257, rec=0.154, cos=0.002), tot_loss_proj:2.407 [t=0.17s]
prediction: ['[CLS] clarity emotional emotional [SEP]']
[ 150/2000] tot_loss=1.752 (perp=8.317, rec=0.087, cos=0.001), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 200/2000] tot_loss=1.760 (perp=8.317, rec=0.095, cos=0.001), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.735 (perp=8.317, rec=0.071, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 300/2000] tot_loss=1.736 (perp=8.317, rec=0.072, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.725 (perp=8.317, rec=0.060, cos=0.001), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.735 (perp=8.317, rec=0.070, cos=0.001), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 450/2000] tot_loss=1.732 (perp=8.317, rec=0.067, cos=0.001), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.729 (perp=8.317, rec=0.064, cos=0.001), tot_loss_proj:1.749 [t=0.21s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.725 (perp=8.317, rec=0.060, cos=0.001), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 600/2000] tot_loss=1.722 (perp=8.317, rec=0.057, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.734 (perp=8.317, rec=0.069, cos=0.001), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.738 (perp=8.317, rec=0.073, cos=0.001), tot_loss_proj:1.744 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 750/2000] tot_loss=1.725 (perp=8.317, rec=0.061, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.719 (perp=8.317, rec=0.054, cos=0.001), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.723 (perp=8.317, rec=0.059, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 900/2000] tot_loss=1.726 (perp=8.317, rec=0.062, cos=0.001), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.720 (perp=8.317, rec=0.055, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1000/2000] tot_loss=1.725 (perp=8.317, rec=0.061, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1050/2000] tot_loss=1.731 (perp=8.317, rec=0.066, cos=0.001), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1100/2000] tot_loss=1.720 (perp=8.317, rec=0.056, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1150/2000] tot_loss=1.734 (perp=8.317, rec=0.069, cos=0.001), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1200/2000] tot_loss=1.729 (perp=8.317, rec=0.064, cos=0.001), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1250/2000] tot_loss=1.722 (perp=8.317, rec=0.057, cos=0.001), tot_loss_proj:1.744 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1300/2000] tot_loss=1.733 (perp=8.317, rec=0.068, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1350/2000] tot_loss=1.725 (perp=8.317, rec=0.060, cos=0.001), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1400/2000] tot_loss=1.727 (perp=8.317, rec=0.062, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1450/2000] tot_loss=1.730 (perp=8.317, rec=0.065, cos=0.001), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1500/2000] tot_loss=1.722 (perp=8.317, rec=0.057, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1550/2000] tot_loss=1.738 (perp=8.317, rec=0.073, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1600/2000] tot_loss=1.725 (perp=8.317, rec=0.060, cos=0.001), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1650/2000] tot_loss=1.722 (perp=8.317, rec=0.057, cos=0.001), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1700/2000] tot_loss=1.727 (perp=8.317, rec=0.062, cos=0.001), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1750/2000] tot_loss=1.730 (perp=8.317, rec=0.065, cos=0.001), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1800/2000] tot_loss=1.724 (perp=8.317, rec=0.059, cos=0.001), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1850/2000] tot_loss=1.723 (perp=8.317, rec=0.058, cos=0.001), tot_loss_proj:1.744 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[1900/2000] tot_loss=1.730 (perp=8.317, rec=0.065, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[1950/2000] tot_loss=1.716 (perp=8.317, rec=0.051, cos=0.001), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Attempt swap
[2000/2000] tot_loss=1.726 (perp=8.317, rec=0.061, cos=0.001), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] clarity and emotional [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.850 | p: 88.455 | r: 89.329
rouge2     | fm: 58.002 | p: 57.886 | r: 58.217
rougeL     | fm: 78.711 | p: 78.416 | r: 79.107
rougeLsum  | fm: 78.695 | p: 78.401 | r: 79.135
r1fm+r2fm = 146.852

input #86 time: 0:09:02 | total time: 11:56:32


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9992553760665845
highest_index [0]
highest [0.9992553760665845]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8846666812896729 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7553390860557556 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7130892872810364 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7034943103790283 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6935102939605713 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6770039796829224 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6745697855949402 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.816 (perp=12.535, rec=0.298, cos=0.011), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=2.701 (perp=12.535, rec=0.190, cos=0.004), tot_loss_proj:3.373 [t=0.17s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 150/2000] tot_loss=1.659 (perp=7.258, rec=0.201, cos=0.006), tot_loss_proj:1.511 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.567 (perp=7.258, rec=0.114, cos=0.001), tot_loss_proj:1.523 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.541 (perp=7.258, rec=0.088, cos=0.001), tot_loss_proj:1.529 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.528 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.527 (perp=7.258, rec=0.074, cos=0.001), tot_loss_proj:1.544 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.942 (perp=7.258, rec=0.384, cos=0.107), tot_loss_proj:1.514 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.599 (perp=7.258, rec=0.143, cos=0.004), tot_loss_proj:1.528 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.550 (perp=7.258, rec=0.097, cos=0.001), tot_loss_proj:1.532 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.538 (perp=7.258, rec=0.085, cos=0.001), tot_loss_proj:1.544 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.523 (perp=7.258, rec=0.070, cos=0.001), tot_loss_proj:1.534 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.530 (perp=7.258, rec=0.077, cos=0.001), tot_loss_proj:1.553 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.523 (perp=7.258, rec=0.070, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.550 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.522 (perp=7.258, rec=0.069, cos=0.001), tot_loss_proj:1.540 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.534 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.522 (perp=7.258, rec=0.069, cos=0.001), tot_loss_proj:1.546 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.527 [t=0.20s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.530 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.526 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.495 (perp=7.258, rec=0.042, cos=0.001), tot_loss_proj:1.545 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.550 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.527 (perp=7.258, rec=0.074, cos=0.001), tot_loss_proj:1.546 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.521 (perp=7.258, rec=0.068, cos=0.001), tot_loss_proj:1.556 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.509 (perp=7.258, rec=0.056, cos=0.001), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.535 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.530 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.547 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.547 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.512 (perp=7.258, rec=0.059, cos=0.001), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.502 (perp=7.258, rec=0.049, cos=0.001), tot_loss_proj:1.545 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.520 (perp=7.258, rec=0.067, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.510 (perp=7.258, rec=0.057, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.502 (perp=7.258, rec=0.049, cos=0.001), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.004 | p: 88.592 | r: 89.524
rouge2     | fm: 58.509 | p: 58.342 | r: 58.685
rougeL     | fm: 78.923 | p: 78.616 | r: 79.366
rougeLsum  | fm: 78.982 | p: 78.657 | r: 79.356
r1fm+r2fm = 147.514

input #87 time: 0:08:52 | total time: 12:05:25


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9992358071326222
highest_index [0]
highest [0.9992358071326222]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9809058904647827 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.944068431854248 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9212347269058228 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.917607307434082 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.9161702394485474 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9086971879005432 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.9049574136734009 for ['[CLS] towards scene too tram beetle vice updated being west grips above.olaignment golden gloss hot boundaries slave satellite warm reasons meant chord antagonist now trick migration part pennsylvania julius following embraced center rebound miss together hero bail museum days four rash [SEP]']
[Init] best rec loss: 0.9017528891563416 for ["[CLS]⁺'ship socialist knightlines trapped golden vital rail soil or accepted seasonal behind mall tickets american fallon https word appearedminated break people familiar bornllie serious once wealth are ll protector caterizedest trade masspina berlin flavortine [SEP]"]
[Init] best rec loss: 0.8954169154167175 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8942180275917053 for ['[CLS] pondered allowed where! aunt never designated starting demi as programs home hadn piston spanning legitimate engine exodusbbed? insanity machine immortality [UNK] reform harmon network elevated nets today according baronet ki exchanged ) signed employees mandarin force close won landing observation [SEP]']
[Init] best perm rec loss: 0.8933555483818054 for ['[CLS] landing signed? ki legitimate network harmon starting demi observation! exchanged where aunt programs exodus insanity ) never today nets pistonbbed mandarin allowed baronet close won [UNK] reform force pondered employees home engine designated as spanning according elevated machine hadn immortality [SEP]']
[Init] best perm rec loss: 0.8925676345825195 for ['[CLS] machine? never immortality exodus landing exchanged! harmon force spanning according as reform [UNK] won where programs auntbbed home employees pondered insanity observation piston today network allowed close ) starting hadn mandarin nets demi elevated legitimate signed engine baronet designated ki [SEP]']
[Init] best perm rec loss: 0.8924002051353455 for ['[CLS] harmon today piston? [UNK] won legitimate machine designated where landing starting allowed demibbed close engine elevated baronet nets ) hadn aunt exchanged never! according employees spanning mandarin insanity exodus immortality signed reform observation as force pondered programs network ki home [SEP]']
[Init] best perm rec loss: 0.8921587467193604 for ['[CLS] allowed hadn legitimate signed piston mandarin exodus reform pondered as observation ) ki engine never network insanitybbed aunt? immortality force demi starting today! where nets machine landing [UNK] home close spanning exchanged designated won employees baronet programs elevated according harmon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.546 (perp=11.107, rec=0.321, cos=0.003), tot_loss_proj:3.516 [t=0.17s]
prediction: ['[CLS] emotionsness return gustave joseph love breaking love love the good social positively estate browning love larger artifacts, hunter that heritageross inner beyond lovefaran be with cool start explore / understood understood loved amazingasurable misery understanding both synonymous [SEP]']
[ 100/2000] tot_loss=2.217 (perp=9.897, rec=0.236, cos=0.002), tot_loss_proj:3.769 [t=0.17s]
prediction: ['[CLS] mattersness. [SEP] anderson love breaking love love the that great. appleoted love heat likely and. that our that the with! nothings who understands how is grand especially calm understands loved great our ignorance were that still [SEP]']
[ 150/2000] tot_loss=2.023 (perp=9.088, rec=0.204, cos=0.002), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] mattersness love p anderson romance breaking love love the great great. romance meantime romantic h ill and. that our that the of! nothings is understands how and grand especially calm understands in great our ignorance. that. [SEP]']
[ 200/2000] tot_loss=1.995 (perp=9.013, rec=0.191, cos=0.002), tot_loss_proj:3.089 [t=0.17s]
prediction: ['[CLS] alrightness love p anderson romance breaking love love the great grand. romance t grand p ill and. that our us the of daily whichs when understands how and grand especially calm understands in daily our ill. that. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.913 (perp=8.702, rec=0.171, cos=0.001), tot_loss_proj:3.203 [t=0.19s]
prediction: ['[CLS] thatness love p anderson romance might love romance the great grand. romance t grand p ill and. alright our us the of daily alls is understands how was grand : calm understands in daily our ill. that. [SEP]']
[ 300/2000] tot_loss=2.030 (perp=9.293, rec=0.170, cos=0.001), tot_loss_proj:3.355 [t=0.22s]
prediction: ['[CLS] thatness. p anderson romance increasing love romance the great grand. romance t grand p ill and. loves our us the of daily nevers signs understands how and grand especially calm knowing in daily our ill were that. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.965 (perp=9.045, rec=0.155, cos=0.001), tot_loss_proj:3.405 [t=0.18s]
prediction: ['[CLS] illness. p anderson romances joy romance the great grand. romance t grand p ill and.izer our us the of daily all growing are understands how and grand especially calm understand in daily our ill were that. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.874 (perp=8.620, rec=0.148, cos=0.002), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] illness. p anderson romances joy romance the great grand. romance t our p ill especially.izer our us the of daily all is are understands how was grand and calm understand in daily our ill were that. [SEP]']
[ 450/2000] tot_loss=1.874 (perp=8.602, rec=0.152, cos=0.001), tot_loss_proj:3.434 [t=0.17s]
prediction: ['[CLS] illness. p anderson romances joy romance the great grand. romance t our p ill especially.izer our us the of daily all is are understands how were grand and calm experience in daily our ill were that. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.854 (perp=8.559, rec=0.140, cos=0.001), tot_loss_proj:3.429 [t=0.17s]
prediction: ['[CLS] illness. t anderson romances joy romance the great grand. romance t our p ill that.izer our us the of daily never iss understands how grand and calm experience were in daily our ill were that. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.810 (perp=8.342, rec=0.140, cos=0.001), tot_loss_proj:3.240 [t=0.18s]
prediction: ['[CLS] illness. t anderson romances joy romance the great grand. p p our p equal who. is our us the of daily neverizers understands how grand and calm experience were in daily our ill were that. [SEP]']
[ 600/2000] tot_loss=1.779 (perp=8.257, rec=0.126, cos=0.001), tot_loss_proj:3.163 [t=0.18s]
prediction: ['[CLS] illness. t anderson romances joy romance the grand grand.. p our p equal can. is our us the of daily thereizers understands how grand and calm experience were in daily our ill were that. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.700 (perp=7.829, rec=0.133, cos=0.001), tot_loss_proj:3.120 [t=0.17s]
prediction: ['[CLS] illness. t anderson romances joy of the grand grand.. p our p equal can. is our us the romance daily thereizers understands how grand and calm experience were in daily our ill were that. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.620 (perp=7.477, rec=0.124, cos=0.001), tot_loss_proj:2.426 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p equal can. is our us the love daily thereizers understands how grand and calm experience were in daily our ill were that. [SEP]']
[ 750/2000] tot_loss=1.609 (perp=7.425, rec=0.123, cos=0.001), tot_loss_proj:2.581 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p equal can. is our us the love daily neverizers understands how grand and calm experience were in daily our ill were that. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.543 (perp=7.105, rec=0.121, cos=0.001), tot_loss_proj:2.568 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p equal can. is our us the love daily neverizers understands how joy and calm experience were daily in our ill were that. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.541 (perp=7.105, rec=0.118, cos=0.001), tot_loss_proj:2.567 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p equal can. is our us the love daily neverizers understands how joy and calm experience were daily in our ill were that. [SEP]']
[ 900/2000] tot_loss=1.616 (perp=7.404, rec=0.133, cos=0.002), tot_loss_proj:2.544 [t=0.18s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p equal can. is our us the love daily neverizers understands how joy and calm experience were daily bring our ill were that. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.519 (perp=6.993, rec=0.119, cos=0.001), tot_loss_proj:2.428 [t=0.18s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p equal can. is our that the love daily thereizers understands how joy and calm experience were daily in our ill were us. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.522 (perp=7.037, rec=0.113, cos=0.001), tot_loss_proj:2.607 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p equal can. is our that the love daily neverizers understands how joy and calm experience could daily in our ill were us. [SEP]']
[1050/2000] tot_loss=1.519 (perp=7.037, rec=0.110, cos=0.001), tot_loss_proj:2.603 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p equal can. is our that the love daily neverizers understands how joy and calm experience could daily in our ill were us. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.539 (perp=7.129, rec=0.112, cos=0.001), tot_loss_proj:2.532 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p equal can. is our that the love daily neverizers understands how joy and calm experience could daily bring our ill were us. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.505 (perp=6.966, rec=0.111, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p can. is our equal that the love daily neverizers understands how joy and calm experience could daily bring our ill were us. [SEP]']
[1200/2000] tot_loss=1.503 (perp=6.966, rec=0.108, cos=0.001), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand. grand. p our p can. is our equal that the love daily neverizers understands how joy and calm experience could daily bring our ill were us. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.486 (perp=6.849, rec=0.115, cos=0.001), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand our grand. p. p can. is our equal that the love daily neverizers understands how joy and calm experience could daily bring our ill were us. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.474 (perp=6.796, rec=0.113, cos=0.001), tot_loss_proj:2.485 [t=0.19s]
prediction: ['[CLS] thatness. t anderson romances joy of the grand our grand. p. p can. that our equal is the love daily neverizers understands how joy and calm experience could daily bring our ill were us. [SEP]']
[1350/2000] tot_loss=1.482 (perp=6.848, rec=0.111, cos=0.001), tot_loss_proj:2.512 [t=0.19s]
prediction: ['[CLS] andness. t anderson romances joy of the grand our grand. p. p can. that our equal is the love daily neverizers understands how joy and calm experience could daily bring our ill were us. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.481 (perp=6.848, rec=0.110, cos=0.001), tot_loss_proj:2.510 [t=0.19s]
prediction: ['[CLS] andness. t anderson romances joy of the grand our grand. p. p can. that our equal is the love daily neverizers understands how joy and calm experience could daily bring our ill were us. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.466 (perp=6.738, rec=0.117, cos=0.001), tot_loss_proj:2.523 [t=0.19s]
prediction: ['[CLS] andness. t anderson romances joy of the grand our grand. p. p can. that our equal is the love daily neverizers understands how joy and calm daily experience could bring our ill were us. [SEP]']
[1500/2000] tot_loss=1.454 (perp=6.738, rec=0.105, cos=0.001), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] andness. t anderson romances joy of the grand our grand. p. p can. that our equal is the love daily neverizers understands how joy and calm daily experience could bring our ill were us. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.444 (perp=6.641, rec=0.115, cos=0.001), tot_loss_proj:2.508 [t=0.17s]
prediction: ['[CLS] andness. t anderson romances joy of the grand our grand. p. p. can that our equal is the love daily neverizers understands how joy and calm daily experience could bring our ill were us. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.408 (perp=6.492, rec=0.109, cos=0.001), tot_loss_proj:2.449 [t=0.20s]
prediction: ['[CLS] calmness. t anderson romances joy of the grand our grand. p. p. can that our equal is the love daily neverizers understands how joy and and daily experience could bring our ill were us. [SEP]']
[1650/2000] tot_loss=1.362 (perp=6.269, rec=0.107, cos=0.001), tot_loss_proj:2.498 [t=0.17s]
prediction: ['[CLS] calmness. t anderson romances joy of the grand our grand. p. p. can that our equal is the love daily neverizers understands how joy and that daily experience could bring our ill were us. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.366 (perp=6.269, rec=0.111, cos=0.001), tot_loss_proj:2.497 [t=0.17s]
prediction: ['[CLS] calmness. t anderson romances joy of the grand our grand. p. p. can that our equal is the love daily neverizers understands how joy and that daily experience could bring our ill were us. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.364 (perp=6.269, rec=0.109, cos=0.001), tot_loss_proj:2.498 [t=0.17s]
prediction: ['[CLS] calmness. t anderson romances joy of the grand our grand. p. p. can that our equal is the love daily neverizers understands how joy and that daily experience could bring our ill were us. [SEP]']
[1800/2000] tot_loss=1.359 (perp=6.228, rec=0.111, cos=0.001), tot_loss_proj:2.338 [t=0.17s]
prediction: ['[CLS] calmness. t anderson romances joy of the grand our grand. p. p. can that our equal is the love daily joyizers understands how joy and that daily experience could bring our ill were us. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.359 (perp=6.228, rec=0.112, cos=0.001), tot_loss_proj:2.338 [t=0.20s]
prediction: ['[CLS] calmness. t anderson romances joy of the grand our grand. p. p. can that our equal is the love daily joyizers understands how joy and that daily experience could bring our ill were us. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.341 (perp=6.118, rec=0.116, cos=0.001), tot_loss_proj:2.267 [t=0.17s]
prediction: ['[CLS] calmness. t anderson romances joy of the grand our grand. p. p. joy that our equal is the love daily canizers understands how joy and that daily experience could bring our ill were us. [SEP]']
[1950/2000] tot_loss=1.340 (perp=6.118, rec=0.115, cos=0.001), tot_loss_proj:2.270 [t=0.17s]
prediction: ['[CLS] calmness. t anderson romances joy of the grand our grand. p. p. joy that our equal is the love daily canizers understands how joy and that daily experience could bring our ill were us. [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.339 (perp=6.118, rec=0.114, cos=0.001), tot_loss_proj:2.263 [t=0.17s]
prediction: ['[CLS] calmness. t anderson romances joy of the grand our grand. p. p. joy that our equal is the love daily canizers understands how joy and that daily experience could bring our ill were us. [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] calmness. t anderson romances joy of the grand our grand. p. p. can that our equal is the love daily neverizers understands how joy and that daily experience could bring our ill were us. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 59.459 | p: 61.111 | r: 57.895
rouge2     | fm: 5.556 | p: 5.714 | r: 5.405
rougeL     | fm: 35.135 | p: 36.111 | r: 34.211
rougeLsum  | fm: 35.135 | p: 36.111 | r: 34.211
r1fm+r2fm = 65.015

[Aggregate metrics]:
rouge1     | fm: 88.599 | p: 88.238 | r: 89.076
rouge2     | fm: 57.919 | p: 57.794 | r: 58.077
rougeL     | fm: 78.365 | p: 78.047 | r: 78.769
rougeLsum  | fm: 78.378 | p: 78.109 | r: 78.803
r1fm+r2fm = 146.517

input #88 time: 0:08:48 | total time: 12:14:13


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9993426143386362
highest_index [0]
highest [0.9993426143386362]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9663888216018677 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9524359107017517 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9456372857093811 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9341058135032654 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.933344841003418 for ['[CLS] trusting weight blood boysmediafultte donfoot muttered happenedats atari document practicing photograph eight leon watt cutler gps jp brokenuded credited wish relatively promisepateuating deaths atomic [SEP]']
[Init] best perm rec loss: 0.9307798743247986 for ['[CLS] happenedtte atari promiseats gps leon relatively blood broken weight deathsfootmedia jp wish atomic cutleruating eight watt boys practicing muttereduded document creditedpate donful photograph trusting [SEP]']
[Init] best perm rec loss: 0.9285004734992981 for ['[CLS]ats jp practicing blood trustingmediauating donfulpate promise boysfoot broken happened document relatively weight muttered atomic wish deaths credited photographtte atariuded leon cutler gps watt eight [SEP]']
[Init] best perm rec loss: 0.9245237708091736 for ['[CLS]pate watt weight gpsats eight boys document cutler jptte deathsuating blood trusting atari atomic credited wish donuded mutteredfoot happenedful photograph broken practicingmedia promise relatively leon [SEP]']
[Init] best perm rec loss: 0.9240761399269104 for ['[CLS]foot credited blooduded document atomic promise cutler boysats relatively photographmedia ataripate broken watt gps jp deathsful trustinguating weight don happenedtte practicing eight wish leon muttered [SEP]']
[Init] best perm rec loss: 0.9212810397148132 for ['[CLS] eight documentpateuating deaths blood boys muttered donuded photographfoot relatively broken cutler atomic practicing atari watt jpats happened trusting wish weight credited gpsmedia leonfultte promise [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.825 (perp=12.432, rec=0.336, cos=0.002), tot_loss_proj:3.522 [t=0.17s]
prediction: ['[CLS] guilt on least blouse josie routine shoved apparently - tope - organization worsefe worse worried other maybe military distraction no tactic somehow committee real notedes maybe defensive technology [SEP]']
[ 100/2000] tot_loss=2.346 (perp=10.275, rec=0.288, cos=0.003), tot_loss_proj:3.088 [t=0.17s]
prediction: ['[CLS] tactic on proposed screen res the worse apparently - nonetle - somehow worse telies type party genre no covering, tactic not committee real worse? things constructed any ideas [SEP]']
[ 150/2000] tot_loss=2.133 (perp=9.518, rec=0.228, cos=0.001), tot_loss_proj:3.018 [t=0.17s]
prediction: ['[CLS] tactic to heap fact res the worse apparently - nonexi - is worse tel - / -udence - cover or tactic - - real worse so things built the ideas [SEP]']
[ 200/2000] tot_loss=2.012 (perp=9.039, rec=0.202, cos=0.002), tot_loss_proj:3.460 [t=0.17s]
prediction: ['[CLS] tactic to out fact res fact that apparently - nonexi, completely worse tel - - of aback - cover or tactic - - all worse so things built the ideas [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.878 (perp=8.465, rec=0.183, cos=0.002), tot_loss_proj:2.474 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact ar fact that apparently - nonexi yet relatively presents telies - - fact - or worse - - all worse so - built the ideas [SEP]']
[ 300/2000] tot_loss=1.813 (perp=8.256, rec=0.160, cos=0.001), tot_loss_proj:2.800 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact vantage fact that pleas - nonexi yet relatively between tel - - a fact - or worse - action yet worse so - constructed the ideas [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.818 (perp=8.389, rec=0.139, cos=0.001), tot_loss_proj:2.338 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact uc fact that pleas - - nonexi yet is constructed tel of / the fact or worse - picture yet worse so - constructed the ideas [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.698 (perp=7.866, rec=0.124, cos=0.001), tot_loss_proj:2.139 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact uc that that pleas - - nonexi yet is constructed - of / the fact or worse - picture, worse so - constructed the ideas [SEP]']
[ 450/2000] tot_loss=1.691 (perp=7.866, rec=0.117, cos=0.001), tot_loss_proj:2.138 [t=0.18s]
prediction: ['[CLS] tactic to cover up fact uc that that pleas - - nonexi yet is constructed - of / the fact or worse - picture, worse so - constructed the ideas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.765 (perp=8.265, rec=0.111, cos=0.001), tot_loss_proj:2.436 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact uc that that pleas - - nonexi yet issy - ofim the fact or worse constructed picture, worse so - - the ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.793 (perp=8.431, rec=0.106, cos=0.001), tot_loss_proj:2.220 [t=0.17s]
prediction: ["[CLS] tactic to cover up fact fact that thatrh - - nonexi yet issy - ofim the'or worse constructed picture, worse so -im the ideas [SEP]"]
[ 600/2000] tot_loss=1.788 (perp=8.431, rec=0.100, cos=0.001), tot_loss_proj:2.224 [t=0.17s]
prediction: ["[CLS] tactic to cover up fact fact that thatrh - - nonexi yet issy - ofim the'or worse constructed picture, worse so -im the ideas [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.748 (perp=8.207, rec=0.106, cos=0.001), tot_loss_proj:2.187 [t=0.19s]
prediction: ["[CLS] tactic to cover up fact fact that thatpore - - - nonexi yet issy - of the'or worse constructed picture, worse so -im a ideas [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.599 (perp=7.485, rec=0.100, cos=0.001), tot_loss_proj:2.189 [t=0.19s]
prediction: ["[CLS] tactic to cover up fact fact thatimwhile - - - nonexi yet issy - of the'or worse constructed picture, worse so - that a ideas [SEP]"]
[ 750/2000] tot_loss=1.595 (perp=7.485, rec=0.097, cos=0.001), tot_loss_proj:2.190 [t=0.19s]
prediction: ["[CLS] tactic to cover up fact fact thatimwhile - - - nonexi yet issy - of the'or worse constructed picture, worse so - that a ideas [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.564 (perp=7.315, rec=0.100, cos=0.001), tot_loss_proj:2.188 [t=0.21s]
prediction: ["[CLS] tactic to cover up fact that factimwhile - - - nonexi yet issy - of the'or worse constructed picture, worse so - that a ideas [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.538 (perp=7.199, rec=0.097, cos=0.001), tot_loss_proj:2.085 [t=0.19s]
prediction: ["[CLS] tactic to cover up fact that factimwhile is - - - nonexi yetsy - of the'or worse constructed picture, worse so - that a ideas [SEP]"]
[ 900/2000] tot_loss=1.531 (perp=7.199, rec=0.090, cos=0.001), tot_loss_proj:2.084 [t=0.21s]
prediction: ["[CLS] tactic to cover up fact that factimwhile is - - - nonexi yetsy - of the'or worse constructed picture, worse so - that a ideas [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.578 (perp=7.394, rec=0.098, cos=0.001), tot_loss_proj:2.065 [t=0.19s]
prediction: ["[CLS] tactic to cover up fact that factimsten'is - - - nonexi yetsy - of the or worse constructed picture, worse so - that a ideas [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.556 (perp=7.306, rec=0.093, cos=0.001), tot_loss_proj:2.054 [t=0.17s]
prediction: ["[CLS] tactic to cover up fact that factimsten'is - - - nonexi sosy - of the or worse constructed picture, worse yet - that a ideas [SEP]"]
[1050/2000] tot_loss=1.552 (perp=7.306, rec=0.090, cos=0.001), tot_loss_proj:2.051 [t=0.17s]
prediction: ["[CLS] tactic to cover up fact that factimsten'is - - - nonexi sosy - of the or worse constructed picture, worse yet - that a ideas [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.524 (perp=7.150, rec=0.093, cos=0.001), tot_loss_proj:1.974 [t=0.17s]
prediction: ["[CLS] tactic to cover up'fact that factimsten is - - - nonexi sosy - of the or worse constructed picture, worse yet - that a ideas [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.480 (perp=6.941, rec=0.091, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ["[CLS] tactic to cover up'fact that fact sosten is - - - nonexiimsy - of the or worse constructed picture, worse yet - that a ideas [SEP]"]
[1200/2000] tot_loss=1.540 (perp=7.222, rec=0.095, cos=0.001), tot_loss_proj:2.067 [t=0.17s]
prediction: ['[CLS] tactic to cover up core fact that fact sosten is - - - nonexiimsy - of the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.510 (perp=7.104, rec=0.088, cos=0.001), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS] tactic to cover up core fact that sosten fact is - - - nonexiimsy - of the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.502 (perp=7.060, rec=0.089, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact fact that sosten core is - - - nonexiimsy - of the or worse constructed picture, worse yet - that a ideas [SEP]']
[1350/2000] tot_loss=1.637 (perp=7.731, rec=0.090, cos=0.001), tot_loss_proj:2.346 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact fact that sosten core is - - - nonexiimsy - fl the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.558 (perp=7.334, rec=0.090, cos=0.001), tot_loss_proj:2.123 [t=0.20s]
prediction: ['[CLS] tactic to cover up fact fact that flsten core is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.542 (perp=7.272, rec=0.087, cos=0.001), tot_loss_proj:2.043 [t=0.19s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
[1500/2000] tot_loss=1.548 (perp=7.272, rec=0.093, cos=0.001), tot_loss_proj:2.037 [t=0.20s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
[1550/2000] tot_loss=1.544 (perp=7.272, rec=0.088, cos=0.001), tot_loss_proj:2.037 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
[1600/2000] tot_loss=1.542 (perp=7.272, rec=0.087, cos=0.001), tot_loss_proj:2.046 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
[1650/2000] tot_loss=1.546 (perp=7.272, rec=0.090, cos=0.001), tot_loss_proj:2.045 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
[1700/2000] tot_loss=1.538 (perp=7.272, rec=0.082, cos=0.001), tot_loss_proj:2.045 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
[1750/2000] tot_loss=1.540 (perp=7.272, rec=0.084, cos=0.001), tot_loss_proj:2.045 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
[1800/2000] tot_loss=1.544 (perp=7.272, rec=0.088, cos=0.001), tot_loss_proj:2.041 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
[1850/2000] tot_loss=1.542 (perp=7.272, rec=0.087, cos=0.001), tot_loss_proj:2.040 [t=0.17s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that a ideas [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.575 (perp=7.424, rec=0.089, cos=0.001), tot_loss_proj:2.059 [t=0.18s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that core ideas [SEP]']
[1950/2000] tot_loss=1.575 (perp=7.424, rec=0.089, cos=0.001), tot_loss_proj:2.067 [t=0.19s]
prediction: ['[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that core ideas [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.549 (perp=7.322, rec=0.084, cos=0.001), tot_loss_proj:2.141 [t=0.19s]
prediction: ['[CLS] tactic to cover up fact fact that core flsten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that core ideas [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] tactic to cover up fact fact that fl coresten is - - - nonexiimsy - so the or worse constructed picture, worse yet - that core ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.340 | p: 70.833 | r: 73.913
rouge2     | fm: 35.556 | p: 34.783 | r: 36.364
rougeL     | fm: 55.319 | p: 54.167 | r: 56.522
rougeLsum  | fm: 55.319 | p: 54.167 | r: 56.522
r1fm+r2fm = 107.896

[Aggregate metrics]:
rouge1     | fm: 88.482 | p: 88.086 | r: 88.976
rouge2     | fm: 57.764 | p: 57.612 | r: 57.918
rougeL     | fm: 78.172 | p: 77.898 | r: 78.577
rougeLsum  | fm: 78.158 | p: 77.852 | r: 78.540
r1fm+r2fm = 146.246

input #89 time: 0:09:10 | total time: 12:23:23


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9993650968600143
highest_index [0]
highest [0.9993650968600143]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9487876892089844 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9457016587257385 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9307820200920105 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.9131976962089539 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8914667963981628 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8844628930091858 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.874426543712616 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8734989166259766 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.8714959025382996 for ['[CLS] when entourage spirited male released cannot [SEP]']
[Init] best perm rec loss: 0.8705925345420837 for ['[CLS] cannot male spirited entourage released when [SEP]']
[Init] best perm rec loss: 0.8705049157142639 for ['[CLS] cannot entourage spirited male released when [SEP]']
[Init] best perm rec loss: 0.8698896765708923 for ['[CLS] male cannot when spirited released entourage [SEP]']
[Init] best perm rec loss: 0.8698087334632874 for ['[CLS] entourage released spirited male cannot when [SEP]']
[Init] best perm rec loss: 0.8679990172386169 for ['[CLS] cannot released male spirited when entourage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.777 (perp=12.165, rec=0.335, cos=0.009), tot_loss_proj:3.213 [t=0.19s]
prediction: ['[CLS] price ridiculous rack attacks money mega [SEP]']
[ 100/2000] tot_loss=2.797 (perp=13.038, rec=0.188, cos=0.002), tot_loss_proj:3.303 [t=0.17s]
prediction: ['[CLS] stupid ridiculous oriented killing money how [SEP]']
[ 150/2000] tot_loss=2.525 (perp=11.929, rec=0.136, cos=0.003), tot_loss_proj:3.534 [t=0.19s]
prediction: ['[CLS] insane ridiculous oriented and money how [SEP]']
[ 200/2000] tot_loss=2.286 (perp=10.962, rec=0.092, cos=0.001), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] crazy ridiculous oriented and money how [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.896 (perp=9.059, rec=0.083, cos=0.001), tot_loss_proj:2.335 [t=0.19s]
prediction: ['[CLS] how ridiculous oriented and money insane [SEP]']
[ 300/2000] tot_loss=1.929 (perp=9.059, rec=0.109, cos=0.008), tot_loss_proj:2.345 [t=0.19s]
prediction: ['[CLS] how ridiculous oriented and money insane [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.472 (perp=6.923, rec=0.086, cos=0.001), tot_loss_proj:1.623 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented insane [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.450 (perp=6.870, rec=0.074, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.452 (perp=6.870, rec=0.077, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.448 (perp=6.870, rec=0.072, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.446 (perp=6.870, rec=0.071, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.434 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.714 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.427 (perp=6.870, rec=0.052, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.415 (perp=6.870, rec=0.040, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.715 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.445 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.705 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.709 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.445 (perp=6.870, rec=0.069, cos=0.001), tot_loss_proj:1.710 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.442 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.708 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.710 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.446 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.703 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.706 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.422 (perp=6.870, rec=0.047, cos=0.001), tot_loss_proj:1.713 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.447 (perp=6.870, rec=0.072, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.433 (perp=6.870, rec=0.057, cos=0.001), tot_loss_proj:1.712 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.700 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.702 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.713 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.446 (perp=6.870, rec=0.071, cos=0.001), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.588 | p: 88.182 | r: 89.076
rouge2     | fm: 58.175 | p: 58.018 | r: 58.369
rougeL     | fm: 78.448 | p: 78.137 | r: 78.814
rougeLsum  | fm: 78.364 | p: 78.099 | r: 78.753
r1fm+r2fm = 146.763

input #90 time: 0:08:13 | total time: 12:31:37


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9993538374859834
highest_index [0]
highest [0.9993538374859834]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9367198944091797 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.8268771767616272 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.8143160343170166 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.77603679895401 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7621927261352539 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.7398632168769836 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7303189039230347 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 0.7301856279373169 for ['[CLS]dern pony revolutionpment unknownlip hard shelter [SEP]']
[Init] best perm rec loss: 0.7299460172653198 for ['[CLS]lippment hard unknown pony shelterdern revolution [SEP]']
[Init] best perm rec loss: 0.7278955578804016 for ['[CLS] hard unknown revolutiondernlip shelter ponypment [SEP]']
[Init] best perm rec loss: 0.7267093658447266 for ['[CLS] pony hard shelterpmentlip unknowndern revolution [SEP]']
[Init] best perm rec loss: 0.7247644662857056 for ['[CLS] hard unknown revolutionpmentlipdern shelter pony [SEP]']
[Init] best perm rec loss: 0.7247127890586853 for ['[CLS] hard shelterpmentlip revolution unknowndern pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.551 (perp=10.894, rec=0.368, cos=0.004), tot_loss_proj:3.018 [t=0.17s]
prediction: ['[CLS] yellow freeces crazy ridiculous? shelter controversy [SEP]']
[ 100/2000] tot_loss=2.513 (perp=11.246, rec=0.262, cos=0.002), tot_loss_proj:3.768 [t=0.17s]
prediction: ['[CLS] loco loco " no ridiculous moreiled rumor [SEP]']
[ 150/2000] tot_loss=2.410 (perp=11.029, rec=0.201, cos=0.003), tot_loss_proj:2.795 [t=0.17s]
prediction: ['[CLS] loco loco but no ridiculous moreiled ridiculous [SEP]']
[ 200/2000] tot_loss=2.326 (perp=10.885, rec=0.147, cos=0.001), tot_loss_proj:2.800 [t=0.17s]
prediction: ['[CLS] mu loco but no ridiculous moreuse loco [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.016 (perp=9.266, rec=0.158, cos=0.005), tot_loss_proj:2.474 [t=0.17s]
prediction: ['[CLS] mu loco but noy more ridiculous loco [SEP]']
[ 300/2000] tot_loss=1.977 (perp=9.266, rec=0.123, cos=0.001), tot_loss_proj:2.471 [t=0.17s]
prediction: ['[CLS] mu loco but noy more ridiculous loco [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.884 (perp=8.836, rec=0.116, cos=0.001), tot_loss_proj:2.197 [t=0.17s]
prediction: ['[CLS] mu locoy but no more ridiculous loco [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.824 (perp=8.538, rec=0.115, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[ 450/2000] tot_loss=1.818 (perp=8.538, rec=0.109, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.811 (perp=8.538, rec=0.102, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.799 (perp=8.538, rec=0.090, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[ 600/2000] tot_loss=1.807 (perp=8.538, rec=0.098, cos=0.001), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.805 (perp=8.538, rec=0.096, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.790 (perp=8.538, rec=0.081, cos=0.001), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[ 750/2000] tot_loss=1.806 (perp=8.538, rec=0.098, cos=0.001), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.813 (perp=8.538, rec=0.103, cos=0.002), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.800 (perp=8.538, rec=0.091, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[ 900/2000] tot_loss=1.795 (perp=8.538, rec=0.086, cos=0.001), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.796 (perp=8.538, rec=0.087, cos=0.001), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.791 (perp=8.538, rec=0.082, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1050/2000] tot_loss=1.802 (perp=8.538, rec=0.093, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1100/2000] tot_loss=1.809 (perp=8.538, rec=0.100, cos=0.001), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1150/2000] tot_loss=1.793 (perp=8.538, rec=0.084, cos=0.001), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1200/2000] tot_loss=1.795 (perp=8.538, rec=0.086, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1250/2000] tot_loss=1.800 (perp=8.538, rec=0.091, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1300/2000] tot_loss=1.801 (perp=8.538, rec=0.092, cos=0.001), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1350/2000] tot_loss=1.797 (perp=8.538, rec=0.088, cos=0.001), tot_loss_proj:2.132 [t=0.18s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1400/2000] tot_loss=1.790 (perp=8.538, rec=0.082, cos=0.001), tot_loss_proj:2.140 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1450/2000] tot_loss=1.799 (perp=8.538, rec=0.090, cos=0.001), tot_loss_proj:2.139 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1500/2000] tot_loss=1.789 (perp=8.538, rec=0.080, cos=0.001), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1550/2000] tot_loss=1.784 (perp=8.538, rec=0.075, cos=0.001), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1600/2000] tot_loss=1.778 (perp=8.538, rec=0.069, cos=0.001), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1650/2000] tot_loss=1.781 (perp=8.538, rec=0.072, cos=0.001), tot_loss_proj:2.130 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1700/2000] tot_loss=1.783 (perp=8.538, rec=0.074, cos=0.001), tot_loss_proj:2.125 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1750/2000] tot_loss=1.788 (perp=8.538, rec=0.079, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1800/2000] tot_loss=1.790 (perp=8.538, rec=0.081, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1850/2000] tot_loss=1.782 (perp=8.538, rec=0.073, cos=0.001), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.777 (perp=8.538, rec=0.068, cos=0.001), tot_loss_proj:2.138 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
[1950/2000] tot_loss=1.789 (perp=8.538, rec=0.081, cos=0.001), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.783 (perp=8.538, rec=0.074, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] mu locoy but no loco more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] mu locoy but no loco more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 77.778 | r: 87.500
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 122.353

[Aggregate metrics]:
rouge1     | fm: 88.566 | p: 88.110 | r: 89.092
rouge2     | fm: 58.000 | p: 57.801 | r: 58.212
rougeL     | fm: 78.268 | p: 77.949 | r: 78.693
rougeLsum  | fm: 78.390 | p: 78.054 | r: 78.812
r1fm+r2fm = 146.566

input #91 time: 0:08:40 | total time: 12:40:18


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9993137310302476
highest_index [0]
highest [0.9993137310302476]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8797468543052673 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8783625364303589 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8693297505378723 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8594153523445129 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8578515648841858 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.8554595112800598 for ['[CLS] edge island [SEP]']
[Init] best rec loss: 0.7936431765556335 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7916328310966492 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.677 (perp=12.265, rec=0.219, cos=0.004), tot_loss_proj:3.205 [t=0.17s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=2.591 (perp=12.265, rec=0.137, cos=0.002), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS] erroreit [SEP]']
[ 150/2000] tot_loss=1.623 (perp=7.646, rec=0.093, cos=0.001), tot_loss_proj:1.610 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.608 (perp=7.646, rec=0.077, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.588 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.589 (perp=7.646, rec=0.059, cos=0.001), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.586 (perp=7.646, rec=0.055, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.592 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.591 (perp=7.646, rec=0.061, cos=0.001), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.583 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.590 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.579 (perp=7.646, rec=0.048, cos=0.001), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.599 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.589 (perp=7.646, rec=0.058, cos=0.001), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.587 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.594 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.599 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.579 (perp=7.646, rec=0.048, cos=0.001), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.588 (perp=7.646, rec=0.058, cos=0.001), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.584 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.583 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.610 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.591 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.590 (perp=7.646, rec=0.059, cos=0.001), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.594 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.601 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.579 (perp=7.646, rec=0.049, cos=0.001), tot_loss_proj:1.597 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.597 (perp=7.646, rec=0.067, cos=0.001), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.584 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.584 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.606 (perp=7.646, rec=0.075, cos=0.001), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.580 (perp=7.646, rec=0.050, cos=0.001), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.600 (perp=7.646, rec=0.069, cos=0.001), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.587 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.588 (perp=7.646, rec=0.058, cos=0.001), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.602 (perp=7.646, rec=0.071, cos=0.001), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.603 (perp=7.646, rec=0.073, cos=0.001), tot_loss_proj:1.592 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.592 (perp=7.646, rec=0.061, cos=0.001), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.673 | p: 88.252 | r: 89.188
rouge2     | fm: 58.302 | p: 58.111 | r: 58.554
rougeL     | fm: 78.575 | p: 78.229 | r: 78.991
rougeLsum  | fm: 78.554 | p: 78.234 | r: 78.984
r1fm+r2fm = 146.974

input #92 time: 0:08:47 | total time: 12:49:06


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9993323263895038
highest_index [0]
highest [0.9993323263895038]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0078084468841553 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8302108645439148 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8220402598381042 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.8074820637702942 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.8070929646492004 for ['[CLS]ball lad specific shrinking judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.807031512260437 for ['[CLS] lad specific shrinkingball judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.806305468082428 for ['[CLS] lad shrinkingball solo 1970s judicial specific [SEP]']
[Init] best perm rec loss: 0.8061965107917786 for ['[CLS] solo 1970s shrinkingball lad judicial specific [SEP]']
[Init] best perm rec loss: 0.8059419989585876 for ['[CLS] 1970s specificball shrinking judicial lad solo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.265 (perp=12.634, rec=0.733, cos=0.005), tot_loss_proj:4.003 [t=0.17s]
prediction: ['[CLS] security insufficient organization specification oldʊ listening [SEP]']
[ 100/2000] tot_loss=3.610 (perp=14.870, rec=0.628, cos=0.007), tot_loss_proj:4.875 [t=0.17s]
prediction: ['[CLS]flict says nfl specification old tatum unlike [SEP]']
[ 150/2000] tot_loss=3.601 (perp=14.652, rec=0.654, cos=0.017), tot_loss_proj:4.722 [t=0.17s]
prediction: ['[CLS] recurring replied pga funny understandingος unlike [SEP]']
[ 200/2000] tot_loss=3.368 (perp=13.430, rec=0.669, cos=0.013), tot_loss_proj:4.491 [t=0.17s]
prediction: ['[CLS] puts saysional idea wayος tobacco [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=3.223 (perp=12.869, rec=0.625, cos=0.024), tot_loss_proj:4.584 [t=0.17s]
prediction: ['[CLS] idea stainless funny pga wayος tobacco [SEP]']
[ 300/2000] tot_loss=3.053 (perp=12.450, rec=0.549, cos=0.013), tot_loss_proj:3.742 [t=0.18s]
prediction: ['[CLS] idea stainless funny pga wayος funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.943 (perp=12.090, rec=0.522, cos=0.003), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] funny stainless pga way funny how funny [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.644 (perp=10.658, rec=0.509, cos=0.003), tot_loss_proj:2.678 [t=0.17s]
prediction: ['[CLS] understanding clinic pga way funny how funny [SEP]']
[ 450/2000] tot_loss=2.636 (perp=10.658, rec=0.499, cos=0.005), tot_loss_proj:2.678 [t=0.17s]
prediction: ['[CLS] understanding clinic pga way funny how funny [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.624 (perp=10.658, rec=0.491, cos=0.001), tot_loss_proj:2.681 [t=0.17s]
prediction: ['[CLS] understanding clinic pga way funny how funny [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.393 (perp=9.459, rec=0.498, cos=0.003), tot_loss_proj:3.806 [t=0.17s]
prediction: ['[CLS] without understanding pga way funny how funny [SEP]']
[ 600/2000] tot_loss=2.524 (perp=10.209, rec=0.481, cos=0.001), tot_loss_proj:4.079 [t=0.17s]
prediction: ['[CLS] without understanding pga way funny ways funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.515 (perp=10.209, rec=0.472, cos=0.001), tot_loss_proj:4.083 [t=0.17s]
prediction: ['[CLS] without understanding pga way funny ways funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.520 (perp=10.209, rec=0.471, cos=0.008), tot_loss_proj:4.084 [t=0.17s]
prediction: ['[CLS] without understanding pga way funny ways funny [SEP]']
[ 750/2000] tot_loss=2.509 (perp=10.209, rec=0.463, cos=0.004), tot_loss_proj:4.081 [t=0.17s]
prediction: ['[CLS] without understanding pga way funny ways funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.541 (perp=10.432, rec=0.454, cos=0.001), tot_loss_proj:4.081 [t=0.17s]
prediction: ['[CLS] without understanding nascar way funny ways funny [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.550 (perp=10.307, rec=0.484, cos=0.005), tot_loss_proj:4.114 [t=0.17s]
prediction: ['[CLS] without understanding pga ways funny way funny [SEP]']
[ 900/2000] tot_loss=2.526 (perp=10.307, rec=0.463, cos=0.002), tot_loss_proj:4.110 [t=0.17s]
prediction: ['[CLS] without understanding pga ways funny way funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.459 (perp=10.019, rec=0.454, cos=0.001), tot_loss_proj:3.978 [t=0.17s]
prediction: ['[CLS] without understanding nascar ways funny way funny [SEP]']
Attempt swap
[1000/2000] tot_loss=2.461 (perp=10.019, rec=0.453, cos=0.005), tot_loss_proj:3.974 [t=0.17s]
prediction: ['[CLS] without understanding nascar ways funny way funny [SEP]']
[1050/2000] tot_loss=2.459 (perp=10.019, rec=0.453, cos=0.002), tot_loss_proj:3.984 [t=0.17s]
prediction: ['[CLS] without understanding nascar ways funny way funny [SEP]']
Attempt swap
[1100/2000] tot_loss=2.464 (perp=10.019, rec=0.452, cos=0.009), tot_loss_proj:3.979 [t=0.17s]
prediction: ['[CLS] without understanding nascar ways funny way funny [SEP]']
Attempt swap
[1150/2000] tot_loss=2.362 (perp=9.567, rec=0.447, cos=0.001), tot_loss_proj:3.758 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
[1200/2000] tot_loss=2.363 (perp=9.567, rec=0.448, cos=0.002), tot_loss_proj:3.758 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1250/2000] tot_loss=2.359 (perp=9.567, rec=0.445, cos=0.001), tot_loss_proj:3.757 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1300/2000] tot_loss=2.357 (perp=9.567, rec=0.442, cos=0.002), tot_loss_proj:3.753 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
[1350/2000] tot_loss=2.351 (perp=9.567, rec=0.437, cos=0.000), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1400/2000] tot_loss=2.353 (perp=9.567, rec=0.439, cos=0.001), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1450/2000] tot_loss=2.354 (perp=9.567, rec=0.440, cos=0.001), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
[1500/2000] tot_loss=2.353 (perp=9.567, rec=0.438, cos=0.001), tot_loss_proj:3.758 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1550/2000] tot_loss=2.353 (perp=9.567, rec=0.440, cos=0.000), tot_loss_proj:3.754 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1600/2000] tot_loss=2.350 (perp=9.567, rec=0.436, cos=0.001), tot_loss_proj:3.761 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
[1650/2000] tot_loss=2.351 (perp=9.567, rec=0.437, cos=0.001), tot_loss_proj:3.761 [t=0.19s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1700/2000] tot_loss=2.350 (perp=9.567, rec=0.436, cos=0.001), tot_loss_proj:3.761 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1750/2000] tot_loss=2.356 (perp=9.567, rec=0.442, cos=0.000), tot_loss_proj:3.757 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
[1800/2000] tot_loss=2.350 (perp=9.567, rec=0.436, cos=0.001), tot_loss_proj:3.759 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1850/2000] tot_loss=2.344 (perp=9.567, rec=0.430, cos=0.001), tot_loss_proj:3.758 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[1900/2000] tot_loss=2.350 (perp=9.567, rec=0.434, cos=0.002), tot_loss_proj:3.756 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
[1950/2000] tot_loss=2.351 (perp=9.567, rec=0.435, cos=0.002), tot_loss_proj:3.760 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Attempt swap
[2000/2000] tot_loss=2.349 (perp=9.567, rec=0.434, cos=0.001), tot_loss_proj:3.757 [t=0.17s]
prediction: ['[CLS] without understanding nascar how funny way funny [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] without understanding nascar how funny way funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 58.824 | p: 55.556 | r: 62.500
rouge2     | fm: 13.333 | p: 12.500 | r: 14.286
rougeL     | fm: 58.824 | p: 55.556 | r: 62.500
rougeLsum  | fm: 58.824 | p: 55.556 | r: 62.500
r1fm+r2fm = 72.157

[Aggregate metrics]:
rouge1     | fm: 88.339 | p: 87.877 | r: 88.924
rouge2     | fm: 57.916 | p: 57.782 | r: 58.111
rougeL     | fm: 78.331 | p: 77.892 | r: 78.827
rougeLsum  | fm: 78.382 | p: 78.019 | r: 78.855
r1fm+r2fm = 146.255

input #93 time: 0:10:15 | total time: 12:59:21


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9993168061064917
highest_index [0]
highest [0.9993168061064917]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9727807641029358 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9545496106147766 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9148076176643372 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9085803627967834 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8869084715843201 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8795130848884583 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.879210889339447 for ['[CLS] internal plum rockwell expedition crushed flowering shocks territorialventing chronic centre [SEP]']
[Init] best perm rec loss: 0.8783528804779053 for ['[CLS] internalventing territorial shocks expedition centre crushed plum flowering chronic rockwell [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.694 (perp=11.198, rec=0.448, cos=0.006), tot_loss_proj:3.065 [t=0.17s]
prediction: ['[CLS] radio game banas pileit kills bug processing nor statements [SEP]']
[ 100/2000] tot_loss=2.445 (perp=10.576, rec=0.328, cos=0.002), tot_loss_proj:2.869 [t=0.17s]
prediction: ['[CLS] extra division neitheric cubans illegal neither sherlock nor funny [SEP]']
[ 150/2000] tot_loss=2.160 (perp=9.765, rec=0.205, cos=0.002), tot_loss_proj:2.591 [t=0.17s]
prediction: ['[CLS] as yao neither a cape of palestinian neither original nor funny [SEP]']
[ 200/2000] tot_loss=2.114 (perp=9.785, rec=0.156, cos=0.001), tot_loss_proj:2.561 [t=0.17s]
prediction: ['[CLS] as yao neither a caperthic neither original nor funny [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.175 (perp=10.012, rec=0.170, cos=0.003), tot_loss_proj:2.552 [t=0.17s]
prediction: ['[CLS] a route neither a caped robe neither original nor funny [SEP]']
[ 300/2000] tot_loss=1.874 (perp=8.685, rec=0.136, cos=0.001), tot_loss_proj:2.257 [t=0.17s]
prediction: ['[CLS] a s neither a caper robe neither original nor funny [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.730 (perp=7.983, rec=0.133, cos=0.001), tot_loss_proj:2.090 [t=0.17s]
prediction: ['[CLS] s a awful a caper robe neither original nor funny [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.889 (perp=8.755, rec=0.136, cos=0.002), tot_loss_proj:2.278 [t=0.17s]
prediction: ['[CLS] that a grady a caperish neither original nor funny [SEP]']
[ 450/2000] tot_loss=1.919 (perp=9.091, rec=0.099, cos=0.001), tot_loss_proj:2.302 [t=0.17s]
prediction: ['[CLS] that a grady s caperish neither original nor funny [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.926 (perp=9.091, rec=0.106, cos=0.001), tot_loss_proj:2.309 [t=0.17s]
prediction: ['[CLS] that a grady s caperish neither original nor funny [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.908 (perp=9.091, rec=0.089, cos=0.001), tot_loss_proj:2.302 [t=0.17s]
prediction: ['[CLS] that a grady s caperish neither original nor funny [SEP]']
[ 600/2000] tot_loss=1.910 (perp=9.091, rec=0.090, cos=0.001), tot_loss_proj:2.306 [t=0.17s]
prediction: ['[CLS] that a grady s caperish neither original nor funny [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.910 (perp=8.883, rec=0.133, cos=0.001), tot_loss_proj:2.237 [t=0.17s]
prediction: ['[CLS] that grady s a caperish neither original nor funny [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.814 (perp=8.507, rec=0.111, cos=0.001), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS] that funny s a caperish neither original nor grady [SEP]']
[ 750/2000] tot_loss=1.805 (perp=8.507, rec=0.102, cos=0.001), tot_loss_proj:3.605 [t=0.17s]
prediction: ['[CLS] that funny s a caperish neither original nor grady [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.679 (perp=7.904, rec=0.097, cos=0.001), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.679 (perp=7.904, rec=0.096, cos=0.001), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
[ 900/2000] tot_loss=1.679 (perp=7.904, rec=0.097, cos=0.001), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.681 (perp=7.904, rec=0.099, cos=0.001), tot_loss_proj:3.495 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1000/2000] tot_loss=1.674 (perp=7.904, rec=0.092, cos=0.001), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
[1050/2000] tot_loss=1.666 (perp=7.904, rec=0.084, cos=0.001), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1100/2000] tot_loss=1.683 (perp=7.904, rec=0.101, cos=0.001), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1150/2000] tot_loss=1.676 (perp=7.904, rec=0.094, cos=0.001), tot_loss_proj:3.503 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
[1200/2000] tot_loss=1.674 (perp=7.904, rec=0.092, cos=0.001), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1250/2000] tot_loss=1.675 (perp=7.904, rec=0.093, cos=0.001), tot_loss_proj:3.504 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1300/2000] tot_loss=1.665 (perp=7.904, rec=0.083, cos=0.001), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
[1350/2000] tot_loss=1.674 (perp=7.904, rec=0.092, cos=0.001), tot_loss_proj:3.498 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1400/2000] tot_loss=1.674 (perp=7.904, rec=0.092, cos=0.001), tot_loss_proj:3.503 [t=0.21s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1450/2000] tot_loss=1.679 (perp=7.904, rec=0.097, cos=0.001), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
[1500/2000] tot_loss=1.675 (perp=7.904, rec=0.093, cos=0.001), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1550/2000] tot_loss=1.672 (perp=7.904, rec=0.090, cos=0.001), tot_loss_proj:3.498 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1600/2000] tot_loss=1.673 (perp=7.904, rec=0.091, cos=0.001), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
[1650/2000] tot_loss=1.674 (perp=7.904, rec=0.092, cos=0.001), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1700/2000] tot_loss=1.682 (perp=7.904, rec=0.100, cos=0.001), tot_loss_proj:3.498 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1750/2000] tot_loss=1.659 (perp=7.904, rec=0.077, cos=0.001), tot_loss_proj:3.500 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
[1800/2000] tot_loss=1.670 (perp=7.904, rec=0.088, cos=0.001), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1850/2000] tot_loss=1.661 (perp=7.904, rec=0.079, cos=0.001), tot_loss_proj:3.497 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor grady [SEP]']
Attempt swap
[1900/2000] tot_loss=1.594 (perp=7.540, rec=0.085, cos=0.001), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor terribly [SEP]']
[1950/2000] tot_loss=1.599 (perp=7.540, rec=0.090, cos=0.001), tot_loss_proj:3.503 [t=0.18s]
prediction: ['[CLS] that s a funny caperish neither original nor terribly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.595 (perp=7.540, rec=0.086, cos=0.001), tot_loss_proj:3.505 [t=0.17s]
prediction: ['[CLS] that s a funny caperish neither original nor terribly [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] that s a funny caperish neither original nor terribly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 130.909

[Aggregate metrics]:
rouge1     | fm: 88.351 | p: 87.906 | r: 88.886
rouge2     | fm: 57.618 | p: 57.438 | r: 57.877
rougeL     | fm: 78.239 | p: 77.877 | r: 78.736
rougeLsum  | fm: 78.305 | p: 77.959 | r: 78.752
r1fm+r2fm = 145.968

input #94 time: 0:10:26 | total time: 13:09:48


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9991574288984811
highest_index [0]
highest [0.9991574288984811]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9695915579795837 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9447000622749329 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9425680041313171 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9293648600578308 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9289979338645935 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.9244387745857239 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.8965775966644287 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.8573101758956909 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8477544188499451 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 0.8469237089157104 for ['[CLS] cut pressure ]ے wire complete sister block monty hanging damp tech trailer privatenne [SEP]']
[Init] best perm rec loss: 0.8467367887496948 for ['[CLS] wireے pressure ] damp trailer cut private block sister complete hanging tech montynne [SEP]']
[Init] best perm rec loss: 0.8459979295730591 for ['[CLS] complete trailer pressure private damp sister hanging wire block monty cutnneے ] tech [SEP]']
[Init] best perm rec loss: 0.8446309566497803 for ['[CLS] sister damp trailer cut private monty complete pressure tech wire hangingے ] blocknne [SEP]']
[Init] best perm rec loss: 0.8437495231628418 for ['[CLS]ے ] wire tech private pressure trailer monty completenne cut block damp sister hanging [SEP]']
[Init] best perm rec loss: 0.8430407643318176 for ['[CLS] trailer sister wire monty blockے hanging private cut complete pressure damp ] technne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.598 (perp=11.319, rec=0.330, cos=0.004), tot_loss_proj:3.092 [t=0.17s]
prediction: ['[CLS] badly collapse victims worst rate a hopeless private victim or its might hopeless worm unsuccessful [SEP]']
[ 100/2000] tot_loss=2.835 (perp=13.023, rec=0.229, cos=0.002), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] an shell money worst became became hopeless thinown hopeless, hopeless hopelessbook hopeless [SEP]']
[ 150/2000] tot_loss=2.797 (perp=13.075, rec=0.181, cos=0.002), tot_loss_proj:3.140 [t=0.18s]
prediction: ['[CLS] an shell equipment sad became becomes hopelesssatdle hopeless, hopeless hopeless storydle [SEP]']
[ 200/2000] tot_loss=2.313 (perp=10.857, rec=0.140, cos=0.002), tot_loss_proj:2.677 [t=0.18s]
prediction: ['[CLS] " mud clothing\'becomes a hopelesssatdle hopeless, hopeless shillings storydle [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.459 (perp=11.582, rec=0.141, cos=0.002), tot_loss_proj:2.866 [t=0.18s]
prediction: ["[CLS] ( mud clothing'becomes a hopeless hopeless,fying geraissatdle storydle [SEP]"]
[ 300/2000] tot_loss=2.202 (perp=10.377, rec=0.125, cos=0.002), tot_loss_proj:2.535 [t=0.17s]
prediction: ["[CLS] ( mud') becomes a hopelesssat,fying denissatdle story becomes [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=1.990 (perp=9.322, rec=0.124, cos=0.002), tot_loss_proj:2.345 [t=0.19s]
prediction: ["[CLS] (') becomes a hopeless mudsat,fying denissatdle storydle [SEP]"]
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.037 (perp=9.623, rec=0.111, cos=0.002), tot_loss_proj:2.367 [t=0.17s]
prediction: ["[CLS] (') becomes a hopeless mudsat,fying denisdlesatdle story [SEP]"]
[ 450/2000] tot_loss=2.065 (perp=9.793, rec=0.105, cos=0.002), tot_loss_proj:2.416 [t=0.17s]
prediction: ["[CLS] (') becomes a hopeless mudsat,fying denissatsatdle story [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.982 (perp=9.400, rec=0.100, cos=0.002), tot_loss_proj:2.380 [t=0.17s]
prediction: ["[CLS] (') becomes a hopeless mudsat,fying denissatdle storysat [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.968 (perp=9.400, rec=0.086, cos=0.002), tot_loss_proj:2.386 [t=0.17s]
prediction: ["[CLS] (') becomes a hopeless mudsat,fying denissatdle storysat [SEP]"]
[ 600/2000] tot_loss=1.964 (perp=9.400, rec=0.083, cos=0.002), tot_loss_proj:2.379 [t=0.17s]
prediction: ["[CLS] (') becomes a hopeless mudsat,fying denissatdle storysat [SEP]"]
Attempt swap
[ 650/2000] tot_loss=2.070 (perp=9.926, rec=0.083, cos=0.002), tot_loss_proj:2.463 [t=0.17s]
prediction: ["[CLS] (') becomes a hopeless mudis,fying denissatdle storysat [SEP]"]
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.886 (perp=8.984, rec=0.088, cos=0.002), tot_loss_proj:2.195 [t=0.17s]
prediction: ["[CLS] (') becomes a hopeless, mudisfying denissatdle storysat [SEP]"]
[ 750/2000] tot_loss=1.878 (perp=8.984, rec=0.079, cos=0.002), tot_loss_proj:2.204 [t=0.17s]
prediction: ["[CLS] (') becomes a hopeless, mudisfying denissatdle storysat [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.725 (perp=8.233, rec=0.077, cos=0.002), tot_loss_proj:2.084 [t=0.19s]
prediction: ["[CLS] (') becomes a hopeless,satisfying denis muddle storysat [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.610 (perp=7.693, rec=0.070, cos=0.001), tot_loss_proj:1.894 [t=0.17s]
prediction: ["[CLS] (') denis becomes a hopeless,satisfying muddle storysat [SEP]"]
[ 900/2000] tot_loss=1.616 (perp=7.693, rec=0.076, cos=0.002), tot_loss_proj:1.896 [t=0.17s]
prediction: ["[CLS] (') denis becomes a hopeless,satisfying muddle storysat [SEP]"]
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.557 (perp=7.467, rec=0.062, cos=0.002), tot_loss_proj:1.827 [t=0.23s]
prediction: ["[CLS] (')sat denis becomes a hopeless,satisfying muddle story [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.572 (perp=7.467, rec=0.076, cos=0.002), tot_loss_proj:1.823 [t=0.17s]
prediction: ["[CLS] (')sat denis becomes a hopeless,satisfying muddle story [SEP]"]
[1050/2000] tot_loss=1.412 (perp=6.684, rec=0.073, cos=0.002), tot_loss_proj:1.668 [t=0.17s]
prediction: ["[CLS] (') un denis becomes a hopeless,satisfying muddle story [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.394 (perp=6.601, rec=0.072, cos=0.002), tot_loss_proj:1.640 [t=0.17s]
prediction: ["[CLS] ( )'un denis becomes a hopeless,satisfying muddle story [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.397 (perp=6.601, rec=0.075, cos=0.002), tot_loss_proj:1.644 [t=0.19s]
prediction: ["[CLS] ( )'un denis becomes a hopeless,satisfying muddle story [SEP]"]
[1200/2000] tot_loss=1.390 (perp=6.601, rec=0.068, cos=0.002), tot_loss_proj:1.648 [t=0.17s]
prediction: ["[CLS] ( )'un denis becomes a hopeless,satisfying muddle story [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.390 (perp=6.601, rec=0.068, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ["[CLS] ( )'un denis becomes a hopeless,satisfying muddle story [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.388 (perp=6.601, rec=0.066, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ["[CLS] ( )'un denis becomes a hopeless,satisfying muddle story [SEP]"]
[1350/2000] tot_loss=1.393 (perp=6.601, rec=0.071, cos=0.002), tot_loss_proj:1.628 [t=0.17s]
prediction: ["[CLS] ( )'un denis becomes a hopeless,satisfying muddle story [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.393 (perp=6.601, rec=0.071, cos=0.002), tot_loss_proj:1.638 [t=0.17s]
prediction: ["[CLS] ( )'un denis becomes a hopeless,satisfying muddle story [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.262 (perp=5.914, rec=0.078, cos=0.002), tot_loss_proj:1.487 [t=0.17s]
prediction: ["[CLS] ( )'denis becomes a hopeless, unsatisfying muddle story [SEP]"]
[1500/2000] tot_loss=1.265 (perp=5.914, rec=0.080, cos=0.002), tot_loss_proj:1.492 [t=0.17s]
prediction: ["[CLS] ( )'denis becomes a hopeless, unsatisfying muddle story [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.252 (perp=5.876, rec=0.076, cos=0.002), tot_loss_proj:1.463 [t=0.17s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.246 (perp=5.876, rec=0.069, cos=0.002), tot_loss_proj:1.461 [t=0.19s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
[1650/2000] tot_loss=1.250 (perp=5.876, rec=0.073, cos=0.002), tot_loss_proj:1.467 [t=0.19s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.248 (perp=5.876, rec=0.071, cos=0.002), tot_loss_proj:1.470 [t=0.17s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.254 (perp=5.876, rec=0.077, cos=0.002), tot_loss_proj:1.468 [t=0.19s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
[1800/2000] tot_loss=1.244 (perp=5.876, rec=0.068, cos=0.002), tot_loss_proj:1.469 [t=0.19s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.243 (perp=5.876, rec=0.067, cos=0.002), tot_loss_proj:1.460 [t=0.17s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.240 (perp=5.876, rec=0.063, cos=0.002), tot_loss_proj:1.467 [t=0.17s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
[1950/2000] tot_loss=1.250 (perp=5.876, rec=0.073, cos=0.002), tot_loss_proj:1.462 [t=0.17s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.243 (perp=5.876, rec=0.066, cos=0.002), tot_loss_proj:1.466 [t=0.17s]
prediction: ["[CLS] (') denis becomes a hopeless, unsatisfying muddle story [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] ( )'un denis becomes a hopeless,satisfying muddle story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 23.529 | p: 22.222 | r: 25.000
rougeL     | fm: 73.684 | p: 70.000 | r: 77.778
rougeLsum  | fm: 73.684 | p: 70.000 | r: 77.778
r1fm+r2fm = 107.740

[Aggregate metrics]:
rouge1     | fm: 88.259 | p: 87.793 | r: 88.923
rouge2     | fm: 57.377 | p: 57.176 | r: 57.596
rougeL     | fm: 78.225 | p: 77.827 | r: 78.689
rougeLsum  | fm: 78.246 | p: 77.820 | r: 78.745
r1fm+r2fm = 145.636

input #95 time: 0:11:09 | total time: 13:20:57


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9992866562400882
highest_index [0]
highest [0.9992866562400882]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8909018635749817 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8791100382804871 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.8585579991340637 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8257309794425964 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8243802189826965 for ['[CLS] lighter dunbar y itself phantom gen pickflowerled record margaret failed living giles stake [SEP]']
[Init] best rec loss: 0.8242563605308533 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.8184889554977417 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade β [SEP]']
[Init] best rec loss: 0.8130791187286377 for ['[CLS]culus teacher robson colonies now world over enables who obsidianrlerving peacehwa contract [SEP]']
[Init] best rec loss: 0.7910962700843811 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.7895482182502747 for ['[CLS] wig memoir pondered save august typical smashwords statue sounding projectile spent era livinggn time [SEP]']
[Init] best perm rec loss: 0.7892841100692749 for ['[CLS] living statue sounding eragn pondered smashwords typical projectile time spent save august memoir wig [SEP]']
[Init] best perm rec loss: 0.7874389290809631 for ['[CLS] typical living save sounding wig smashwords august statue time spent projectile era ponderedgn memoir [SEP]']
[Init] best perm rec loss: 0.7851721048355103 for ['[CLS] typical era spent statue smashwords memoir wig sounding august timegn save living pondered projectile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.190 (perp=14.006, rec=0.386, cos=0.002), tot_loss_proj:4.055 [t=0.19s]
prediction: ['[CLS] authority worthy spent medley memorial in exercisediscorp mitchell lacey would human grasp father [SEP]']
[ 100/2000] tot_loss=2.571 (perp=11.378, rec=0.293, cos=0.001), tot_loss_proj:3.441 [t=0.18s]
prediction: ['[CLS] authority worthy honor medley 11 into person, around australia wallet made people force father [SEP]']
[ 150/2000] tot_loss=2.448 (perp=10.964, rec=0.253, cos=0.002), tot_loss_proj:3.546 [t=0.17s]
prediction: ['[CLS] authority cover upon 6 monument into simply and around australia someone lesser men force himself [SEP]']
[ 200/2000] tot_loss=2.408 (perp=10.886, rec=0.229, cos=0.002), tot_loss_proj:3.680 [t=0.17s]
prediction: ['[CLS] authority cover originally arise territory into simply and on himself wanting lesser men force himself [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.098 (perp=9.467, rec=0.203, cos=0.001), tot_loss_proj:2.843 [t=0.17s]
prediction: ['[CLS] into cover and situations giving individuals simply and on immediately would lesser men force himself [SEP]']
[ 300/2000] tot_loss=2.070 (perp=9.541, rec=0.161, cos=0.001), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] for cover on situations which situations less and on into would lesser men force himself [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.879 (perp=8.639, rec=0.149, cos=0.002), tot_loss_proj:2.812 [t=0.17s]
prediction: ['[CLS] for cover on situations for situations lesser and on into lesser men would force himself [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.955 (perp=9.037, rec=0.146, cos=0.001), tot_loss_proj:2.998 [t=0.17s]
prediction: ['[CLS] into cover on situations for situations they into on lesser men would force himself and [SEP]']
[ 450/2000] tot_loss=1.880 (perp=8.733, rec=0.132, cos=0.002), tot_loss_proj:2.919 [t=0.17s]
prediction: ['[CLS] would cover on situations for people they into on lesser men would force himself and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.857 (perp=8.616, rec=0.133, cos=0.001), tot_loss_proj:2.659 [t=0.17s]
prediction: ['[CLS] would force on situations for people situations into on lesser men would cover himself and [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.726 (perp=7.977, rec=0.129, cos=0.001), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] would force on situations for situations into people on lesser men would cover himself and [SEP]']
[ 600/2000] tot_loss=1.705 (perp=7.977, rec=0.108, cos=0.001), tot_loss_proj:2.579 [t=0.17s]
prediction: ['[CLS] would force on situations for situations into people on lesser men would cover himself and [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.610 (perp=7.490, rec=0.111, cos=0.001), tot_loss_proj:2.426 [t=0.17s]
prediction: ['[CLS] would force on situations for people into situations on lesser men would cover himself and [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.605 (perp=7.529, rec=0.098, cos=0.001), tot_loss_proj:2.467 [t=0.17s]
prediction: ['[CLS] would force and situations and people into situations on lesser men would cover himself for [SEP]']
[ 750/2000] tot_loss=1.607 (perp=7.529, rec=0.100, cos=0.001), tot_loss_proj:2.458 [t=0.17s]
prediction: ['[CLS] would force and situations and people into situations on lesser men would cover himself for [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.453 (perp=6.738, rec=0.104, cos=0.001), tot_loss_proj:2.151 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men would cover himself for [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.445 (perp=6.738, rec=0.096, cos=0.001), tot_loss_proj:2.144 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men would cover himself for [SEP]']
[ 900/2000] tot_loss=1.448 (perp=6.738, rec=0.099, cos=0.001), tot_loss_proj:2.148 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men would cover himself for [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.411 (perp=6.542, rec=0.102, cos=0.001), tot_loss_proj:2.126 [t=0.19s]
prediction: ['[CLS] would force on situations and people into situations and lesser men would cover for himself [SEP]']
Attempt swap
[1000/2000] tot_loss=1.425 (perp=6.655, rec=0.092, cos=0.001), tot_loss_proj:2.075 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
[1050/2000] tot_loss=1.425 (perp=6.655, rec=0.093, cos=0.001), tot_loss_proj:2.082 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1100/2000] tot_loss=1.434 (perp=6.655, rec=0.102, cos=0.001), tot_loss_proj:2.075 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1150/2000] tot_loss=1.429 (perp=6.655, rec=0.097, cos=0.001), tot_loss_proj:2.072 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
[1200/2000] tot_loss=1.432 (perp=6.655, rec=0.100, cos=0.001), tot_loss_proj:2.079 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1250/2000] tot_loss=1.433 (perp=6.655, rec=0.101, cos=0.001), tot_loss_proj:2.075 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1300/2000] tot_loss=1.425 (perp=6.655, rec=0.092, cos=0.001), tot_loss_proj:2.082 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
[1350/2000] tot_loss=1.426 (perp=6.655, rec=0.093, cos=0.001), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1400/2000] tot_loss=1.430 (perp=6.655, rec=0.098, cos=0.001), tot_loss_proj:2.081 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1450/2000] tot_loss=1.427 (perp=6.655, rec=0.095, cos=0.001), tot_loss_proj:2.076 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
[1500/2000] tot_loss=1.426 (perp=6.655, rec=0.094, cos=0.001), tot_loss_proj:2.081 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1550/2000] tot_loss=1.428 (perp=6.655, rec=0.096, cos=0.001), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1600/2000] tot_loss=1.426 (perp=6.655, rec=0.094, cos=0.001), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
[1650/2000] tot_loss=1.421 (perp=6.655, rec=0.089, cos=0.001), tot_loss_proj:2.071 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1700/2000] tot_loss=1.429 (perp=6.655, rec=0.096, cos=0.001), tot_loss_proj:2.082 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1750/2000] tot_loss=1.431 (perp=6.655, rec=0.098, cos=0.001), tot_loss_proj:2.078 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
[1800/2000] tot_loss=1.423 (perp=6.655, rec=0.091, cos=0.001), tot_loss_proj:2.074 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1850/2000] tot_loss=1.423 (perp=6.655, rec=0.091, cos=0.001), tot_loss_proj:2.076 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[1900/2000] tot_loss=1.433 (perp=6.655, rec=0.101, cos=0.001), tot_loss_proj:2.080 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
[1950/2000] tot_loss=1.421 (perp=6.655, rec=0.089, cos=0.001), tot_loss_proj:2.081 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Attempt swap
[2000/2000] tot_loss=1.419 (perp=6.655, rec=0.086, cos=0.001), tot_loss_proj:2.076 [t=0.17s]
prediction: ['[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] would force on situations and people into situations and lesser men make cover for himself [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.235 | p: 88.235 | r: 88.235
rouge2     | fm: 12.500 | p: 12.500 | r: 12.500
rougeL     | fm: 58.824 | p: 58.824 | r: 58.824
rougeLsum  | fm: 58.824 | p: 58.824 | r: 58.824
r1fm+r2fm = 100.735

[Aggregate metrics]:
rouge1     | fm: 88.305 | p: 87.819 | r: 88.855
rouge2     | fm: 56.842 | p: 56.663 | r: 57.069
rougeL     | fm: 77.930 | p: 77.536 | r: 78.459
rougeLsum  | fm: 77.997 | p: 77.627 | r: 78.531
r1fm+r2fm = 145.147

input #96 time: 0:10:59 | total time: 13:31:56


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9991660915875735
highest_index [0]
highest [0.9991660915875735]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8396337628364563 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.8173046708106995 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8006014823913574 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.7802342772483826 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.7502726316452026 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7448185682296753 for ['[CLS] working perfectet 140 cam channel [SEP]']
[Init] best perm rec loss: 0.7447396516799927 for ['[CLS] channel cam perfect working 140et [SEP]']
[Init] best perm rec loss: 0.7446287870407104 for ['[CLS] cam channel perfect workinget 140 [SEP]']
[Init] best perm rec loss: 0.7441828846931458 for ['[CLS] cam perfect working 140et channel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.288 (perp=9.168, rec=0.442, cos=0.013), tot_loss_proj:2.987 [t=0.19s]
prediction: ['[CLS] any unique global culture action unique [SEP]']
[ 100/2000] tot_loss=2.945 (perp=13.178, rec=0.306, cos=0.003), tot_loss_proj:3.644 [t=0.19s]
prediction: ['[CLS]get changed global touch action artists [SEP]']
[ 150/2000] tot_loss=2.535 (perp=11.464, rec=0.238, cos=0.003), tot_loss_proj:3.687 [t=0.17s]
prediction: ['[CLS]gettableforerenceget phenomenon [SEP]']
[ 200/2000] tot_loss=2.251 (perp=10.235, rec=0.201, cos=0.002), tot_loss_proj:3.423 [t=0.17s]
prediction: ['[CLS]gettable untableget and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.900 (perp=8.545, rec=0.188, cos=0.003), tot_loss_proj:2.402 [t=0.19s]
prediction: ['[CLS]forgettable untable and [SEP]']
[ 300/2000] tot_loss=1.865 (perp=8.545, rec=0.154, cos=0.002), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS]forgettable untable and [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.248 (perp=5.520, rec=0.143, cos=0.002), tot_loss_proj:1.289 [t=0.17s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.216 (perp=5.520, rec=0.110, cos=0.002), tot_loss_proj:1.285 [t=0.17s]
prediction: ['[CLS] unforgettable characters and [SEP]']
[ 450/2000] tot_loss=1.199 (perp=5.520, rec=0.094, cos=0.002), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.184 (perp=5.514, rec=0.080, cos=0.002), tot_loss_proj:1.378 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.179 (perp=5.514, rec=0.075, cos=0.002), tot_loss_proj:1.376 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 600/2000] tot_loss=1.193 (perp=5.514, rec=0.089, cos=0.002), tot_loss_proj:1.376 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.191 (perp=5.514, rec=0.087, cos=0.002), tot_loss_proj:1.380 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.170 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.376 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 750/2000] tot_loss=1.165 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.382 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.180 (perp=5.514, rec=0.076, cos=0.002), tot_loss_proj:1.369 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.177 (perp=5.514, rec=0.073, cos=0.002), tot_loss_proj:1.373 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 900/2000] tot_loss=1.175 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.374 [t=0.18s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.179 (perp=5.514, rec=0.075, cos=0.002), tot_loss_proj:1.374 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.169 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.384 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1050/2000] tot_loss=1.164 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.374 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.164 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.367 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.168 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.376 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1200/2000] tot_loss=1.161 (perp=5.514, rec=0.056, cos=0.002), tot_loss_proj:1.376 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.157 (perp=5.514, rec=0.053, cos=0.002), tot_loss_proj:1.370 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.180 (perp=5.514, rec=0.076, cos=0.002), tot_loss_proj:1.372 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1350/2000] tot_loss=1.173 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.388 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.185 (perp=5.514, rec=0.080, cos=0.002), tot_loss_proj:1.378 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.178 (perp=5.514, rec=0.074, cos=0.002), tot_loss_proj:1.379 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1500/2000] tot_loss=1.163 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.369 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.163 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.373 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.176 (perp=5.514, rec=0.072, cos=0.002), tot_loss_proj:1.374 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1650/2000] tot_loss=1.173 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.374 [t=0.18s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.176 (perp=5.514, rec=0.072, cos=0.002), tot_loss_proj:1.374 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.179 (perp=5.514, rec=0.074, cos=0.002), tot_loss_proj:1.380 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1800/2000] tot_loss=1.174 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.379 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.383 [t=0.19s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.180 (perp=5.514, rec=0.076, cos=0.002), tot_loss_proj:1.373 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1950/2000] tot_loss=1.169 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.380 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.163 (perp=5.514, rec=0.058, cos=0.002), tot_loss_proj:1.369 [t=0.20s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] unforgettable and characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 88.400 | p: 87.934 | r: 89.008
rouge2     | fm: 56.715 | p: 56.498 | r: 56.896
rougeL     | fm: 78.049 | p: 77.698 | r: 78.564
rougeLsum  | fm: 78.102 | p: 77.706 | r: 78.612
r1fm+r2fm = 145.115

input #97 time: 0:11:49 | total time: 13:43:46


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9991916976323436
highest_index [0]
highest [0.9991916976323436]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7122125029563904 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7120754718780518 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.709286630153656 for ['[CLS] jed ada nos prohibited [SEP]']
[Init] best perm rec loss: 0.7076743245124817 for ['[CLS] prohibited nos ada jed [SEP]']
[Init] best perm rec loss: 0.7051839828491211 for ['[CLS] nos ada jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.827 (perp=12.242, rec=0.359, cos=0.020), tot_loss_proj:3.381 [t=0.17s]
prediction: ['[CLS] emptyfulful attachment [SEP]']
[ 100/2000] tot_loss=2.800 (perp=12.926, rec=0.211, cos=0.004), tot_loss_proj:3.432 [t=0.17s]
prediction: ['[CLS] unfulful purchase [SEP]']
[ 150/2000] tot_loss=2.447 (perp=11.412, rec=0.162, cos=0.003), tot_loss_proj:3.236 [t=0.19s]
prediction: ['[CLS] unllingful purchase [SEP]']
[ 200/2000] tot_loss=2.404 (perp=11.412, rec=0.119, cos=0.003), tot_loss_proj:3.245 [t=0.17s]
prediction: ['[CLS] unllingful purchase [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.123 (perp=4.948, rec=0.130, cos=0.003), tot_loss_proj:1.056 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.080 (perp=4.948, rec=0.089, cos=0.002), tot_loss_proj:1.061 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.081 (perp=4.948, rec=0.090, cos=0.001), tot_loss_proj:1.062 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.082 (perp=4.948, rec=0.091, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.061 (perp=4.948, rec=0.070, cos=0.002), tot_loss_proj:1.068 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.065 (perp=4.948, rec=0.074, cos=0.002), tot_loss_proj:1.071 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.056 (perp=4.948, rec=0.065, cos=0.002), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.061 (perp=4.948, rec=0.070, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.041 (perp=4.948, rec=0.050, cos=0.002), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.057 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.058 (perp=4.948, rec=0.067, cos=0.002), tot_loss_proj:1.068 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.053 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.054 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.067 (perp=4.948, rec=0.076, cos=0.002), tot_loss_proj:1.057 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.064 (perp=4.948, rec=0.073, cos=0.002), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.058 (perp=4.948, rec=0.067, cos=0.002), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.038 (perp=4.948, rec=0.047, cos=0.002), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.056 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.056 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.057 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.056 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.066 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.048 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.054 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.051 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.055 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.050 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.044 (perp=4.948, rec=0.053, cos=0.002), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.048 (perp=4.948, rec=0.057, cos=0.002), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.520 | p: 88.050 | r: 89.109
rouge2     | fm: 57.105 | p: 56.933 | r: 57.288
rougeL     | fm: 78.276 | p: 77.899 | r: 78.759
rougeLsum  | fm: 78.231 | p: 77.835 | r: 78.729
r1fm+r2fm = 145.624

input #98 time: 0:09:57 | total time: 13:53:43


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9993095816453154
highest_index [0]
highest [0.9993095816453154]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8722755908966064 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8668547868728638 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8600996136665344 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8582916855812073 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.8477660417556763 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8349575400352478 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8292847275733948 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.823960542678833 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8212921023368835 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.820878267288208 for ['[CLS]ˈ ferns opposedaging actually orient taste earliest claire slight thunder ratings currently temps bet te distance whente cushion services bearing re barbie knowledgets garcia synonym harper still screens [MASK] dental forced himself right [SEP]']
[Init] best perm rec loss: 0.8208308815956116 for ['[CLS] knowledge ratings re synonym slight currently taste ferns claire actuallyˈ forced garcia bet opposed screens right when orient himself thunder services temps earliest dental cushionts te still harperagingte distance barbie [MASK] bearing [SEP]']
[Init] best perm rec loss: 0.8205059766769409 for ['[CLS] cushionts garcia opposed distance ratings synonym thunder slight bearing ferns when services knowledge taste harper orient clairete forced bet [MASK] temps te currently actually re himself screensˈ rightaging still earliest barbie dental [SEP]']
[Init] best perm rec loss: 0.8195905089378357 for ['[CLS] distance cushion knowledge right services re screens still claire orient dentalaging [MASK] garcia thunder harper synonym taste fernsˈte forced barbie ratings tempsts bet actually when te bearing slight earliest opposed currently himself [SEP]']
[Init] best perm rec loss: 0.818151593208313 for ['[CLS] temps taste re fernsaging forced ratings dentalˈ cushion right claire te garcia slight earliest thunder knowledge actually services himself harper bet screens still orient when [MASK] opposed synonym currently barbiete distance bearingts [SEP]']
[Init] best perm rec loss: 0.8180760741233826 for ['[CLS] ratingsˈ claire thunder betts taste ferns temps garcia still re [MASK] himself slight cushion opposed actuallyte currently screensaging bearing te harper dental right orient services barbie forced distance earliest knowledge when synonym [SEP]']
[Init] best perm rec loss: 0.8174036741256714 for ['[CLS] opposed screens forcedagingts synonym earliest [MASK] garcia claire dental actually barbie orient currently harper thunder ferns slight bearing rete still right temps ratings when cushion te taste distance knowledge himself bet servicesˈ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.766 (perp=12.010, rec=0.362, cos=0.002), tot_loss_proj:3.184 [t=0.19s]
prediction: ['[CLS] mob stupid sanctions blame alternative or idiots were stupid test mouth prefecture ruined congress stupid death bombings damn. bargaining it - badly apparentlyed dump damage ruling chemical google crank, moines finland ass evans [SEP]']
[ 100/2000] tot_loss=2.577 (perp=11.390, rec=0.297, cos=0.003), tot_loss_proj:3.073 [t=0.17s]
prediction: ["[CLS] mob stupid software thorough alternative his idiots were fake bad out prefecture ruined owner # death.'di tamil assing still unpleasant suspicious pile damage ruling military ideas that, walked fun ass playing [SEP]"]
[ 150/2000] tot_loss=2.562 (perp=11.525, rec=0.255, cos=0.002), tot_loss_proj:3.075 [t=0.17s]
prediction: ["[CLS] mob nobody software thorough but his idiots was an bad film prefecture awful ownerxie death.'` regretted dissing cesare idiotsssing filmhu walked military recording that, walked fun constructed planned [SEP]"]
[ 200/2000] tot_loss=2.487 (perp=11.282, rec=0.225, cos=0.006), tot_loss_proj:3.406 [t=0.17s]
prediction: ["[CLS] mob nobodyurbed thorough but his idiots was ` bad film problem awful party'death'' di enjoying dissing cesaressingssing filmhu walked ] singing that, walked fun constructed film [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.298 (perp=10.510, rec=0.194, cos=0.002), tot_loss_proj:2.977 [t=0.17s]
prediction: ["[CLS] mob somebody was thorough but the cost [SEP] ` bad film problem awful party'stupid'' di missed dissing deadssingssing filmhu walked your singing that, walked fun plumage film [SEP]"]
[ 300/2000] tot_loss=2.294 (perp=10.593, rec=0.173, cos=0.002), tot_loss_proj:3.126 [t=0.17s]
prediction: ["[CLS] thus somebody had muttering but the ticket [SEP] ` bad'problem awful they'''' di missed dissing crazyssingssing film film walked ] singing that, walked fun plumage film [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.014 (perp=9.327, rec=0.147, cos=0.001), tot_loss_proj:2.719 [t=0.17s]
prediction: ["[CLS] thus somebody had muttering but the ticket ` so bad'horrible horrible'''they'di mind dissing ressingssing the film walked'singing that, walked fun ticket film [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.084 (perp=9.753, rec=0.133, cos=0.001), tot_loss_proj:2.669 [t=0.17s]
prediction: ["[CLS] thus somebody had muttering but the ticket ` so bad ` horrible that'''they'di mind dissing moressingssing the ` walked ` singing horrible, walked fun ticket film [SEP]"]
[ 450/2000] tot_loss=2.109 (perp=9.896, rec=0.128, cos=0.002), tot_loss_proj:2.708 [t=0.17s]
prediction: ["[CLS] thus somebody had muttering but the ticket ` so bad ` horrible that'' ` they'di mind dissing moressingssing the ` walked ` muttering horrible, walked fun ticket film [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.024 (perp=9.494, rec=0.124, cos=0.001), tot_loss_proj:2.589 [t=0.17s]
prediction: ["[CLS] thus somebody had muttering but the ticket out so terrible ` horrible that'' ` they'much mind dissing moressingssing the ` walked'muttering horrible, walked fun ticket film [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.985 (perp=9.322, rec=0.120, cos=0.001), tot_loss_proj:2.532 [t=0.17s]
prediction: ["[CLS] thus somebody had muttering but the ticket out so terrible ` horrible that'`'they'much mind dissing moressingssing the ` walked'muttering horrible, walked fun ticket film [SEP]"]
[ 600/2000] tot_loss=1.976 (perp=9.312, rec=0.112, cos=0.002), tot_loss_proj:2.543 [t=0.17s]
prediction: ["[CLS] thus somebody had muttering but the ticket out so terrible ` terrible that'`'they'much mind dissing moressingssing the ` walked'muttering horrible, walked fun ticket film [SEP]"]
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.930 (perp=9.111, rec=0.106, cos=0.001), tot_loss_proj:2.511 [t=0.17s]
prediction: ["[CLS] thus somebody had muttering but the ticket out so terrible ` terrible that'`'they much mind'dissing moressingssing the ` walked'muttering horrible, walked fun ticket film [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.992 (perp=9.270, rec=0.136, cos=0.002), tot_loss_proj:2.511 [t=0.17s]
prediction: ["[CLS] large somebody had muttering but the ticket out so horrible `ssing that'`'they much mind'dissing chair terriblessing the ` walked'muttering horrible, walked fun ticket film [SEP]"]
[ 750/2000] tot_loss=2.011 (perp=9.512, rec=0.108, cos=0.001), tot_loss_proj:2.599 [t=0.17s]
prediction: ["[CLS] thus ` had muttering but the ticket out so terrible `ssing that'`'they much mind'dissing chair terriblessing the ` walked'muttering horrible, walked fun ticket film [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.898 (perp=8.940, rec=0.109, cos=0.001), tot_loss_proj:2.540 [t=0.17s]
prediction: ["[CLS] thus ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing just'ssing the ` walked'like horrible, walked fun ticket film [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.855 (perp=8.698, rec=0.114, cos=0.001), tot_loss_proj:2.524 [t=0.20s]
prediction: ["[CLS] large ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing just'ssing the fun walked'like horrible, walked fun'film [SEP]"]
[ 900/2000] tot_loss=1.846 (perp=8.658, rec=0.113, cos=0.001), tot_loss_proj:2.431 [t=0.17s]
prediction: ["[CLS] large ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any'ssing the fun walked'like horrible, walked fun'film [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.784 (perp=8.406, rec=0.101, cos=0.001), tot_loss_proj:2.462 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any'ssing the large walked'like horrible, walked fun'film [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.791 (perp=8.426, rec=0.104, cos=0.001), tot_loss_proj:2.690 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any'ssing the walked walked'like horrible, large fun ` film [SEP]"]
[1050/2000] tot_loss=1.789 (perp=8.410, rec=0.106, cos=0.001), tot_loss_proj:2.708 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing more'ssing the walked walked'like horrible, large fun ` film [SEP]"]
Attempt swap
Moved token
[1100/2000] tot_loss=1.769 (perp=8.358, rec=0.096, cos=0.001), tot_loss_proj:2.700 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing more'ssing the walked large walked'like horrible, fun ` film [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.769 (perp=8.316, rec=0.105, cos=0.001), tot_loss_proj:2.661 [t=0.19s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any walked'ssing the large walked'like horrible, fun ` film [SEP]"]
[1200/2000] tot_loss=1.764 (perp=8.316, rec=0.100, cos=0.001), tot_loss_proj:2.658 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any walked'ssing the large walked'like horrible, fun ` film [SEP]"]
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.761 (perp=8.330, rec=0.094, cos=0.001), tot_loss_proj:2.573 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any walked'ssing large the walked'like horrible, fun ` film [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.765 (perp=8.307, rec=0.103, cos=0.001), tot_loss_proj:2.641 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any large walked'ssing the walked'like horrible, fun ` film [SEP]"]
[1350/2000] tot_loss=1.768 (perp=8.307, rec=0.105, cos=0.001), tot_loss_proj:2.643 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any large walked'ssing the walked'like horrible, fun ` film [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.754 (perp=8.307, rec=0.091, cos=0.001), tot_loss_proj:2.645 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any large walked'ssing the walked'like horrible, fun ` film [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.783 (perp=8.400, rec=0.102, cos=0.001), tot_loss_proj:2.658 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing more large walked ', the walked'like horriblessing fun ` film [SEP]"]
[1500/2000] tot_loss=1.780 (perp=8.385, rec=0.102, cos=0.001), tot_loss_proj:2.596 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing any large walked ', the walked'like horriblessing fun ` film [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.773 (perp=8.367, rec=0.098, cos=0.001), tot_loss_proj:2.594 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing more large walked, the walked'like horriblessing'fun ` film [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.760 (perp=8.307, rec=0.097, cos=0.001), tot_loss_proj:2.568 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing large more walked, the walked'like horriblessing'fun ` film [SEP]"]
[1650/2000] tot_loss=1.770 (perp=8.307, rec=0.107, cos=0.001), tot_loss_proj:2.570 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing large more walked, the walked'like horriblessing'fun ` film [SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=1.738 (perp=8.167, rec=0.104, cos=0.001), tot_loss_proj:2.681 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing large more walked the walked,'like horriblessing'fun ` film [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.728 (perp=8.167, rec=0.093, cos=0.001), tot_loss_proj:2.681 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing large more walked the walked,'like horriblessing'fun ` film [SEP]"]
[1800/2000] tot_loss=1.733 (perp=8.167, rec=0.099, cos=0.001), tot_loss_proj:2.681 [t=0.17s]
prediction: ["[CLS] fun ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing large more walked the walked,'like horriblessing'fun ` film [SEP]"]
Attempt swap
Moved token
[1850/2000] tot_loss=1.847 (perp=8.779, rec=0.089, cos=0.001), tot_loss_proj:2.696 [t=0.17s]
prediction: ["[CLS] ticket ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing large walked the walked,'more like horriblessing'fun ` film [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.821 (perp=8.635, rec=0.093, cos=0.001), tot_loss_proj:2.643 [t=0.17s]
prediction: ["[CLS]ssing ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing large walked the walked,'more like horrible ticket'fun ` film [SEP]"]
[1950/2000] tot_loss=1.811 (perp=8.583, rec=0.094, cos=0.001), tot_loss_proj:2.715 [t=0.17s]
prediction: ["[CLS]ssing ` had muttering but the ticket out so terrible ` problem that terrible `'they much mind'dissing large walked the walked,'more like horrible ticket'fun ` film [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.758 (perp=8.273, rec=0.102, cos=0.001), tot_loss_proj:2.328 [t=0.17s]
prediction: ["[CLS]ssing ` had muttering but the ticket out so terrible ` problem that terrible ` like'they much mind'dissing large walked the walked,'more horrible ticket'fun ` film [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS]ssing ` had muttering but the ticket out so terrible `ssing that terrible `'they much mind'dissing large walked the walked,'more like horrible ticket'fun ` film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 75.000 | r: 80.769
rouge2     | fm: 7.692 | p: 7.407 | r: 8.000
rougeL     | fm: 37.037 | p: 35.714 | r: 38.462
rougeLsum  | fm: 37.037 | p: 35.714 | r: 38.462
r1fm+r2fm = 85.470

[Aggregate metrics]:
rouge1     | fm: 88.413 | p: 87.925 | r: 89.042
rouge2     | fm: 56.506 | p: 56.286 | r: 56.702
rougeL     | fm: 77.858 | p: 77.445 | r: 78.335
rougeLsum  | fm: 77.911 | p: 77.503 | r: 78.452
r1fm+r2fm = 144.919

input #99 time: 0:10:25 | total time: 14:04:09


Average Cosine Similarity: 0.9992812683158312
Done with all.
