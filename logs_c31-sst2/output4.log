


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.0 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization no --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 1251.91it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9992715259422633
highest_index [0]
highest [0.9992715259422633]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.0055351257324219 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.9447663426399231 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.9361805319786072 for ['[CLS] ronnie huff [SEP]']
[Init] best rec loss: 0.9271856546401978 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 0.9249287247657776 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 0.8513282537460327 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.194 (perp=9.874, rec=0.202, cos=0.017), tot_loss_proj:2.547 [t=0.17s]
prediction: ['[CLS] bishop disappointed [SEP]']
[ 100/2000] tot_loss=2.204 (perp=10.251, rec=0.143, cos=0.012), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.184 (perp=10.251, rec=0.123, cos=0.010), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.136 (perp=10.251, rec=0.083, cos=0.003), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.118 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.095 (perp=10.251, rec=0.044, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.117 (perp=10.251, rec=0.065, cos=0.001), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.107 (perp=10.251, rec=0.055, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.116 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.101 (perp=10.251, rec=0.050, cos=0.001), tot_loss_proj:2.133 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.110 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.104 (perp=10.251, rec=0.053, cos=0.001), tot_loss_proj:2.118 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.096 (perp=10.251, rec=0.044, cos=0.001), tot_loss_proj:2.123 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.114 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.124 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.118 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.115 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.124 (perp=10.251, rec=0.072, cos=0.001), tot_loss_proj:2.121 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.127 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.107 (perp=10.251, rec=0.055, cos=0.001), tot_loss_proj:2.127 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.103 (perp=10.251, rec=0.051, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.112 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.093 (perp=10.251, rec=0.042, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.104 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.104 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.107 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.100 (perp=10.251, rec=0.048, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.115 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.106 (perp=10.251, rec=0.054, cos=0.001), tot_loss_proj:2.118 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.101 (perp=10.251, rec=0.050, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.108 (perp=10.251, rec=0.057, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.114 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.106 (perp=10.251, rec=0.054, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.120 (perp=10.251, rec=0.069, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.099 (perp=10.251, rec=0.047, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.109 (perp=10.251, rec=0.057, cos=0.001), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.120 (perp=10.251, rec=0.068, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:07:47 | total time: 0:07:47


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9993548278348494
highest_index [0]
highest [0.9993548278348494]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.0210397243499756 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9793888926506042 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.8951830267906189 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 0.864271879196167 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8217445015907288 for ['[CLS] passage erupted [SEP]']
[Init] best rec loss: 0.8215807676315308 for ['[CLS] siam presidents [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.395 (perp=10.892, rec=0.213, cos=0.003), tot_loss_proj:2.534 [t=0.17s]
prediction: ['[CLS] wonderful splendid [SEP]']
[ 100/2000] tot_loss=2.221 (perp=10.288, rec=0.162, cos=0.002), tot_loss_proj:2.344 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.139 (perp=10.288, rec=0.080, cos=0.001), tot_loss_proj:2.349 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.137 (perp=10.288, rec=0.078, cos=0.001), tot_loss_proj:2.344 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.904 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.911 (perp=9.171, rec=0.076, cos=0.001), tot_loss_proj:1.897 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.913 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.900 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.896 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.902 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.893 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.884 (perp=9.171, rec=0.048, cos=0.001), tot_loss_proj:1.901 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.903 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.908 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.906 (perp=9.171, rec=0.071, cos=0.001), tot_loss_proj:1.900 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.902 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.904 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.883 (perp=9.171, rec=0.048, cos=0.001), tot_loss_proj:1.901 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.895 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.902 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.903 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.909 (perp=9.171, rec=0.073, cos=0.001), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.901 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.900 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.902 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.901 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.901 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.908 (perp=9.171, rec=0.073, cos=0.001), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.899 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.904 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.900 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.912 [t=0.17s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.899 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.898 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:08:03 | total time: 0:15:50


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9994340582458305
highest_index [0]
highest [0.9994340582458305]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.8397367596626282 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 0.8254684805870056 for ['[CLS] otherwise [SEP]b [SEP]']
[Init] best rec loss: 0.8126578330993652 for ['[CLS] dailypol food [SEP]']
[Init] best rec loss: 0.805020809173584 for ['[CLS] just percussion universal [SEP]']
[Init] best rec loss: 0.7947117686271667 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 0.7828556895256042 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 0.7795121073722839 for ['[CLS] would we working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.449 (perp=10.279, rec=0.353, cos=0.040), tot_loss_proj:2.931 [t=0.18s]
prediction: ['[CLS] culture technology momentum [SEP]']
[ 100/2000] tot_loss=1.921 (perp=8.515, rec=0.208, cos=0.010), tot_loss_proj:1.799 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=1.798 (perp=8.515, rec=0.093, cos=0.002), tot_loss_proj:1.799 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=1.789 (perp=8.515, rec=0.084, cos=0.002), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.804 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.788 (perp=8.515, rec=0.083, cos=0.002), tot_loss_proj:1.795 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.783 (perp=8.515, rec=0.079, cos=0.001), tot_loss_proj:1.799 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.774 (perp=8.515, rec=0.069, cos=0.002), tot_loss_proj:1.795 [t=0.20s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.754 (perp=8.515, rec=0.050, cos=0.001), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.774 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.756 (perp=8.515, rec=0.052, cos=0.001), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.788 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.765 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.807 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.790 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.762 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.799 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.779 (perp=8.515, rec=0.075, cos=0.001), tot_loss_proj:1.788 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.755 (perp=8.515, rec=0.051, cos=0.001), tot_loss_proj:1.788 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.793 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.799 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.795 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.792 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.754 (perp=8.515, rec=0.050, cos=0.001), tot_loss_proj:1.789 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.790 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.793 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.792 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.789 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:07:43 | total time: 0:23:34


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9993001481006445
highest_index [0]
highest [0.9993001481006445]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.0116136074066162 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9035081267356873 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.8794226050376892 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8757002949714661 for ['[CLS] role bart [SEP]']
[Init] best rec loss: 0.8483982086181641 for ['[CLS] gallons professor [SEP]']
[Init] best rec loss: 0.8467844724655151 for ['[CLS] canterbury havoc [SEP]']
[Init] best rec loss: 0.8355522155761719 for ['[CLS] anthony robin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.272 (perp=10.224, rec=0.222, cos=0.005), tot_loss_proj:2.376 [t=0.17s]
prediction: ['[CLS] film flawless [SEP]']
[ 100/2000] tot_loss=2.126 (perp=10.224, rec=0.080, cos=0.001), tot_loss_proj:2.366 [t=0.17s]
prediction: ['[CLS] film flawless [SEP]']
[ 150/2000] tot_loss=2.114 (perp=10.224, rec=0.068, cos=0.001), tot_loss_proj:2.374 [t=0.17s]
prediction: ['[CLS] film flawless [SEP]']
[ 200/2000] tot_loss=2.114 (perp=10.224, rec=0.068, cos=0.001), tot_loss_proj:2.374 [t=0.17s]
prediction: ['[CLS] film flawless [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.764 (perp=8.385, rec=0.085, cos=0.002), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.736 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.748 (perp=8.385, rec=0.070, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.742 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.758 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.730 (perp=8.385, rec=0.051, cos=0.001), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.758 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.730 (perp=8.385, rec=0.051, cos=0.001), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.746 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.745 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.740 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.731 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.758 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.761 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.758 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.728 (perp=8.385, rec=0.050, cos=0.001), tot_loss_proj:1.757 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.744 (perp=8.385, rec=0.066, cos=0.001), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.735 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.732 (perp=8.385, rec=0.053, cos=0.001), tot_loss_proj:1.758 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.726 (perp=8.385, rec=0.048, cos=0.001), tot_loss_proj:1.766 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.760 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.728 (perp=8.385, rec=0.049, cos=0.001), tot_loss_proj:1.748 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.728 (perp=8.385, rec=0.050, cos=0.001), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:08:24 | total time: 0:31:58


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.9992301171062454
highest_index [0]
highest [0.9992301171062454]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.0361230373382568 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9819928407669067 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.963243842124939 for ['[CLS]qi fates ju [SEP]']
[Init] best rec loss: 0.9556242823600769 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 0.9394267797470093 for ['[CLS] who table christ [SEP]']
[Init] best rec loss: 0.9341257810592651 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.9212238788604736 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.9182291030883789 for ['[CLS] troupe stopped clayton [SEP]']
[Init] best rec loss: 0.8931007385253906 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.120 (perp=9.706, rec=0.172, cos=0.007), tot_loss_proj:2.156 [t=0.22s]
prediction: ['[CLS] tiresomently [SEP]']
[ 100/2000] tot_loss=1.585 (perp=7.516, rec=0.079, cos=0.002), tot_loss_proj:1.579 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.573 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.579 (perp=7.516, rec=0.075, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.573 (perp=7.516, rec=0.068, cos=0.001), tot_loss_proj:1.574 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.560 (perp=7.516, rec=0.056, cos=0.001), tot_loss_proj:1.578 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.001), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.561 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.578 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.001), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.568 (perp=7.516, rec=0.063, cos=0.001), tot_loss_proj:1.573 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.563 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.566 (perp=7.516, rec=0.062, cos=0.002), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.562 (perp=7.516, rec=0.057, cos=0.002), tot_loss_proj:1.561 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.568 (perp=7.516, rec=0.064, cos=0.002), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.570 (perp=7.516, rec=0.065, cos=0.002), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.553 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.572 (perp=7.516, rec=0.067, cos=0.002), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.574 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.564 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.563 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.573 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.559 (perp=7.516, rec=0.054, cos=0.002), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.558 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.568 (perp=7.516, rec=0.063, cos=0.002), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.556 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.567 (perp=7.516, rec=0.063, cos=0.002), tot_loss_proj:1.552 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.560 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.561 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.576 (perp=7.516, rec=0.071, cos=0.002), tot_loss_proj:1.559 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.556 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.568 (perp=7.516, rec=0.063, cos=0.002), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.574 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.570 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.555 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:09:30 | total time: 0:41:28


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9993649146105028
highest_index [0]
highest [0.9993649146105028]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9572856426239014 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9517245292663574 for ['[CLS] stay orgasm [SEP]']
[Init] best rec loss: 0.9491873979568481 for ['[CLS] territorial half [SEP]']
[Init] best rec loss: 0.9308651685714722 for ['[CLS] pleasant favorable [SEP]']
[Init] best rec loss: 0.927051305770874 for ['[CLS]iv fl [SEP]']
[Init] best rec loss: 0.9123218059539795 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 0.8898680210113525 for ['[CLS] quiet. [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.480 (perp=11.370, rec=0.201, cos=0.005), tot_loss_proj:3.532 [t=0.17s]
prediction: ['[CLS] ease ease [SEP]']
[ 100/2000] tot_loss=2.410 (perp=11.370, rec=0.134, cos=0.002), tot_loss_proj:3.501 [t=0.17s]
prediction: ['[CLS] ease ease [SEP]']
[ 150/2000] tot_loss=2.370 (perp=11.370, rec=0.094, cos=0.002), tot_loss_proj:3.510 [t=0.17s]
prediction: ['[CLS] ease ease [SEP]']
[ 200/2000] tot_loss=2.545 (perp=12.316, rec=0.080, cos=0.001), tot_loss_proj:2.534 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.529 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.521 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 300/2000] tot_loss=2.523 (perp=12.316, rec=0.059, cos=0.001), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.529 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.526 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.530 (perp=12.316, rec=0.066, cos=0.001), tot_loss_proj:2.521 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 450/2000] tot_loss=2.528 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.524 (perp=12.316, rec=0.059, cos=0.001), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.526 (perp=12.316, rec=0.061, cos=0.001), tot_loss_proj:2.537 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 600/2000] tot_loss=2.516 (perp=12.316, rec=0.051, cos=0.001), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.511 (perp=12.316, rec=0.046, cos=0.001), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.530 (perp=12.316, rec=0.065, cos=0.001), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 750/2000] tot_loss=2.523 (perp=12.316, rec=0.058, cos=0.001), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.537 (perp=12.316, rec=0.073, cos=0.001), tot_loss_proj:2.530 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.539 (perp=12.316, rec=0.075, cos=0.001), tot_loss_proj:2.516 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 900/2000] tot_loss=2.518 (perp=12.316, rec=0.053, cos=0.001), tot_loss_proj:2.537 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.517 (perp=12.316, rec=0.052, cos=0.001), tot_loss_proj:2.521 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1000/2000] tot_loss=2.531 (perp=12.316, rec=0.066, cos=0.001), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1050/2000] tot_loss=2.526 (perp=12.316, rec=0.062, cos=0.001), tot_loss_proj:2.531 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1100/2000] tot_loss=2.528 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.506 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1150/2000] tot_loss=2.524 (perp=12.316, rec=0.059, cos=0.001), tot_loss_proj:2.516 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1200/2000] tot_loss=2.522 (perp=12.316, rec=0.057, cos=0.001), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1250/2000] tot_loss=2.528 (perp=12.316, rec=0.063, cos=0.001), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1300/2000] tot_loss=2.517 (perp=12.316, rec=0.052, cos=0.001), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1350/2000] tot_loss=2.521 (perp=12.316, rec=0.056, cos=0.001), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1400/2000] tot_loss=2.514 (perp=12.316, rec=0.050, cos=0.001), tot_loss_proj:2.533 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1450/2000] tot_loss=2.532 (perp=12.316, rec=0.067, cos=0.001), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1500/2000] tot_loss=2.525 (perp=12.316, rec=0.060, cos=0.001), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1550/2000] tot_loss=2.525 (perp=12.316, rec=0.060, cos=0.001), tot_loss_proj:2.540 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1600/2000] tot_loss=2.532 (perp=12.316, rec=0.068, cos=0.001), tot_loss_proj:2.526 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1650/2000] tot_loss=2.521 (perp=12.316, rec=0.056, cos=0.001), tot_loss_proj:2.536 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1700/2000] tot_loss=2.529 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.531 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1750/2000] tot_loss=2.529 (perp=12.316, rec=0.064, cos=0.001), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1800/2000] tot_loss=2.520 (perp=12.316, rec=0.055, cos=0.001), tot_loss_proj:2.521 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1850/2000] tot_loss=2.520 (perp=12.316, rec=0.055, cos=0.001), tot_loss_proj:2.510 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[1900/2000] tot_loss=2.526 (perp=12.316, rec=0.061, cos=0.001), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
[1950/2000] tot_loss=2.523 (perp=12.316, rec=0.058, cos=0.001), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
[2000/2000] tot_loss=2.532 (perp=12.316, rec=0.068, cos=0.001), tot_loss_proj:2.534 [t=0.17s]
prediction: ['[CLS] enjoyable ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] enjoyable ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #5 time: 0:08:20 | total time: 0:49:49


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.999250469444722
highest_index [0]
highest [0.999250469444722]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9556694626808167 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.9542555809020996 for ['[CLS] lutheran commercial [SEP]']
[Init] best rec loss: 0.9281026721000671 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.870527982711792 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.8636731505393982 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.8084701895713806 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7869214415550232 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.7772212028503418 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 0.7523331046104431 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 0.7494601011276245 for ['[CLS] too u2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.599 (perp=6.813, rec=0.222, cos=0.015), tot_loss_proj:2.724 [t=0.18s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.724 (perp=8.089, rec=0.103, cos=0.003), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.672 (perp=8.089, rec=0.052, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.691 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.002), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.666 (perp=8.089, rec=0.047, cos=0.002), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.692 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.002), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.686 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.674 (perp=8.089, rec=0.055, cos=0.002), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.670 (perp=8.089, rec=0.051, cos=0.002), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.688 (perp=8.089, rec=0.069, cos=0.002), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.689 (perp=8.089, rec=0.070, cos=0.002), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.674 (perp=8.089, rec=0.055, cos=0.002), tot_loss_proj:1.694 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.691 (perp=8.089, rec=0.072, cos=0.002), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.691 (perp=8.089, rec=0.072, cos=0.002), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.681 (perp=8.089, rec=0.062, cos=0.002), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.676 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.673 (perp=8.089, rec=0.054, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.679 (perp=8.089, rec=0.059, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.695 (perp=8.089, rec=0.075, cos=0.001), tot_loss_proj:1.685 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.667 (perp=8.089, rec=0.048, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.686 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.698 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.694 (perp=8.089, rec=0.074, cos=0.001), tot_loss_proj:1.686 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.673 (perp=8.089, rec=0.054, cos=0.002), tot_loss_proj:1.679 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.681 (perp=8.089, rec=0.062, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.697 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.687 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.684 (perp=8.089, rec=0.065, cos=0.001), tot_loss_proj:1.688 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.668 (perp=8.089, rec=0.048, cos=0.002), tot_loss_proj:1.685 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #6 time: 0:08:57 | total time: 0:58:47


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9991768686555793
highest_index [0]
highest [0.9991768686555793]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9112632274627686 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8373158574104309 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8293389678001404 for ['[CLS] minor bonnetmme near routine cluster confirmed pray mail guy smooth us empty bleeding interior [CLS] relegated seen tapes in beast risk contributingds addedores [SEP]']
[Init] best rec loss: 0.7947319149971008 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best perm rec loss: 0.7944874167442322 for ['[CLS] manual main disease mukherjee pacific animal battalion classics careernies gold 17th none ranide on blow depending sony alec madagascar tourismzed moffat consisting life [SEP]']
[Init] best perm rec loss: 0.7915330529212952 for ['[CLS] blow animal disease manual consistingzedidenies battalion main pacific on career gold madagascar 17th mukherjee sony alec none depending classics ran life tourism moffat [SEP]']
[Init] best perm rec loss: 0.7903832793235779 for ['[CLS] ran tourism career 17th consisting battalionzed classics madagascar depending manual none gold blowide disease life mainnies animal alec pacific sony mukherjee moffat on [SEP]']
[Init] best perm rec loss: 0.790372371673584 for ['[CLS] none consistingnies depending tourism main moffat classics 17th animal blow alec battalion life ran manual on sony madagascar career goldzed diseaseide mukherjee pacific [SEP]']
[Init] best perm rec loss: 0.790019154548645 for ['[CLS] tourism aleczedidenies depending moffat blow 17th none ran pacific sony main gold madagascar mukherjee manual life classics consisting on disease battalion career animal [SEP]']
[Init] best perm rec loss: 0.7886852025985718 for ['[CLS] tourism disease mainide battalionnies 17th moffat on animal madagascar consistingzed life career sony ran pacific gold alec depending mukherjee manual blow none classics [SEP]']
[Init] best perm rec loss: 0.7882210612297058 for ['[CLS] gold 17th on classics sony blow career pacific battalionzed depending tourismnies ran mukherjee animal consisting diseaseide main madagascar life manual moffat alec none [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.555 (perp=10.912, rec=0.342, cos=0.031), tot_loss_proj:3.304 [t=0.17s]
prediction: ['[CLS] problem none that quite lacking notroid so defense problem asshole currently. ( unfortunately bad drug made sector sexual. or understand no ugly giving [SEP]']
[ 100/2000] tot_loss=2.059 (perp=8.903, rec=0.264, cos=0.014), tot_loss_proj:2.914 [t=0.17s]
prediction: ['[CLS] problem problem was problem ugly not ugly that wrong no character ; no ( unfortunately problem is love meant love. or sure has ugly or [SEP]']
[ 150/2000] tot_loss=1.976 (perp=8.829, rec=0.202, cos=0.008), tot_loss_proj:2.816 [t=0.19s]
prediction: ['[CLS] problem problem was problem ugly not ugly that problem no character ; no he involves problem is loveiness love. or sure has ugly or [SEP]']
[ 200/2000] tot_loss=1.834 (perp=8.271, rec=0.173, cos=0.007), tot_loss_proj:3.124 [t=0.17s]
prediction: ['[CLS] cute problemr is ugly not ugly no i i mind ; no he is problem is loveable love character or sure has ugly. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.844 (perp=8.371, rec=0.164, cos=0.006), tot_loss_proj:3.453 [t=0.17s]
prediction: ['[CLS] cute deposits problem is not not ugly no mind i mind ; no he is problem is loveable love character or problem has ugly why [SEP]']
[ 300/2000] tot_loss=1.792 (perp=8.248, rec=0.137, cos=0.005), tot_loss_proj:3.431 [t=0.17s]
prediction: ['[CLS] cute deposits problem is not not ugly that mind i mind ; no he is problem is loveable love character or really has ugly or [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.646 (perp=7.558, rec=0.130, cos=0.004), tot_loss_proj:2.386 [t=0.17s]
prediction: ['[CLS] cute deposits he is not not cute. mind i mind ; no problem the problem is loveable love character or really has ugly or [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.643 (perp=7.511, rec=0.137, cos=0.004), tot_loss_proj:3.016 [t=0.17s]
prediction: ['[CLS] cutea he is here not cute not mind i mind ; no problem the problem is loveable character or love though has ugly or [SEP]']
[ 450/2000] tot_loss=1.646 (perp=7.616, rec=0.119, cos=0.004), tot_loss_proj:2.969 [t=0.17s]
prediction: ['[CLS] cutea he is here not cute that mind i factor ; no problem the problem is loveable character or love though has ugly. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.633 (perp=7.515, rec=0.126, cos=0.004), tot_loss_proj:3.154 [t=0.17s]
prediction: ['[CLS] cute. he is here not i - mind cute factor ; no problem the problem is loveable character or love though has ugly or [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.543 (perp=7.111, rec=0.118, cos=0.003), tot_loss_proj:3.182 [t=0.20s]
prediction: ['[CLS] cute. he is here not i. mind cute factor ; no problem the problem is loveable character or though love has ugly or [SEP]']
[ 600/2000] tot_loss=1.569 (perp=7.265, rec=0.113, cos=0.003), tot_loss_proj:3.335 [t=0.22s]
prediction: ['[CLS] cute. he is here not i. mind cute factor ; no no the problem is,able character or though love has ugly or [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.695 (perp=7.855, rec=0.121, cos=0.003), tot_loss_proj:3.451 [t=0.17s]
prediction: ['[CLS] cute. he is here not i. mind the that factor ; no no problem beatles,able character or though love has ugly or [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.594 (perp=7.417, rec=0.108, cos=0.003), tot_loss_proj:3.234 [t=0.17s]
prediction: ['[CLS] cute. he is here. i not mind the that factor ; no no problem wants,able character or question love has ugly. [SEP]']
[ 750/2000] tot_loss=1.574 (perp=7.417, rec=0.088, cos=0.002), tot_loss_proj:3.237 [t=0.18s]
prediction: ['[CLS] cute. he is here. i not mind the that factor ; no no problem wants,able character or question love has ugly. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.472 (perp=6.909, rec=0.088, cos=0.002), tot_loss_proj:3.281 [t=0.18s]
prediction: ['[CLS] cute. he is here. i not mindable that factor ; no no problem wants, the character or otherwise love has ugly. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.425 (perp=6.662, rec=0.090, cos=0.003), tot_loss_proj:3.163 [t=0.18s]
prediction: ['[CLS] cute. he is here. i not mindable that love factor ; no no problem if, the character or otherwise has ugly. [SEP]']
[ 900/2000] tot_loss=1.421 (perp=6.662, rec=0.087, cos=0.002), tot_loss_proj:3.166 [t=0.18s]
prediction: ['[CLS] cute. he is here. i not mindable that love factor ; no no problem if, the character or otherwise has ugly. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.359 (perp=6.329, rec=0.091, cos=0.002), tot_loss_proj:3.118 [t=0.19s]
prediction: ['[CLS] cute. he is here. i not mindable that love factor ; no no problem, or the character or otherwise has ugly. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.352 (perp=6.329, rec=0.084, cos=0.002), tot_loss_proj:3.121 [t=0.17s]
prediction: ['[CLS] cute. he is here. i not mindable that love factor ; no no problem, or the character or otherwise has ugly. [SEP]']
[1050/2000] tot_loss=1.349 (perp=6.329, rec=0.081, cos=0.002), tot_loss_proj:3.117 [t=0.17s]
prediction: ['[CLS] cute. he is here. i not mindable that love factor ; no no problem, or the character or otherwise has ugly. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.345 (perp=6.329, rec=0.077, cos=0.002), tot_loss_proj:3.120 [t=0.17s]
prediction: ['[CLS] cute. he is here. i not mindable that love factor ; no no problem, or the character or otherwise has ugly. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.349 (perp=6.329, rec=0.081, cos=0.002), tot_loss_proj:3.113 [t=0.20s]
prediction: ['[CLS] cute. he is here. i not mindable that love factor ; no no problem, or the character or otherwise has ugly. [SEP]']
[1200/2000] tot_loss=1.352 (perp=6.329, rec=0.084, cos=0.002), tot_loss_proj:3.113 [t=0.17s]
prediction: ['[CLS] cute. he is here. i not mindable that love factor ; no no problem, or the character or otherwise has ugly. [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.488 (perp=6.648, rec=0.149, cos=0.010), tot_loss_proj:3.233 [t=0.17s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem, or the character or [ is ugly. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.443 (perp=6.550, rec=0.126, cos=0.007), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
[1350/2000] tot_loss=1.435 (perp=6.550, rec=0.119, cos=0.006), tot_loss_proj:3.197 [t=0.17s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.434 (perp=6.550, rec=0.119, cos=0.005), tot_loss_proj:3.200 [t=0.18s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.426 (perp=6.550, rec=0.111, cos=0.005), tot_loss_proj:3.202 [t=0.17s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
[1500/2000] tot_loss=1.427 (perp=6.550, rec=0.113, cos=0.004), tot_loss_proj:3.203 [t=0.19s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.424 (perp=6.550, rec=0.109, cos=0.004), tot_loss_proj:3.198 [t=0.18s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.424 (perp=6.550, rec=0.110, cos=0.004), tot_loss_proj:3.199 [t=0.18s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
[1650/2000] tot_loss=1.425 (perp=6.550, rec=0.111, cos=0.004), tot_loss_proj:3.198 [t=0.17s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.421 (perp=6.550, rec=0.107, cos=0.004), tot_loss_proj:3.200 [t=0.19s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.418 (perp=6.550, rec=0.104, cos=0.004), tot_loss_proj:3.197 [t=0.19s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
[1800/2000] tot_loss=1.426 (perp=6.550, rec=0.113, cos=0.004), tot_loss_proj:3.201 [t=0.19s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem or the character, or [ is ugly. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.434 (perp=6.616, rec=0.107, cos=0.004), tot_loss_proj:3.213 [t=0.19s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no no problem thing the character, or or is ugly. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.407 (perp=6.435, rec=0.116, cos=0.004), tot_loss_proj:3.175 [t=0.17s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no problem no thing the character, or or is ugly. [SEP]']
[1950/2000] tot_loss=1.402 (perp=6.435, rec=0.111, cos=0.004), tot_loss_proj:3.174 [t=0.17s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no problem no thing the character, or or is ugly. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.393 (perp=6.435, rec=0.102, cos=0.004), tot_loss_proj:3.174 [t=0.18s]
prediction: ['[CLS] cute. he has here. i not mindable that love factor ; no problem no thing the character, or or is ugly. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] cute. he is here. i not mindable that love factor ; no no problem, or the character or otherwise has ugly. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.372 | p: 86.364 | r: 90.476
rouge2     | fm: 4.878 | p: 4.762 | r: 5.000
rougeL     | fm: 46.512 | p: 45.455 | r: 47.619
rougeLsum  | fm: 46.512 | p: 45.455 | r: 47.619
r1fm+r2fm = 93.250

[Aggregate metrics]:
rouge1     | fm: 98.547 | p: 98.295 | r: 98.810
rouge2     | fm: 88.110 | p: 88.095 | r: 88.125
rougeL     | fm: 93.314 | p: 93.182 | r: 93.452
rougeLsum  | fm: 93.314 | p: 93.182 | r: 93.452
r1fm+r2fm = 186.656

input #7 time: 0:08:23 | total time: 1:07:11


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9994032830483026
highest_index [0]
highest [0.9994032830483026]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.7545608878135681 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.7099087834358215 for ['[CLS] assassins able a bowled palace times drive camequal happens silver only foreign shelley pumping nbc camp easy payyo bigutounded meaning [SEP]']
[Init] best rec loss: 0.6953709125518799 for ['[CLS]dry pace hash mike parker guard defence disease relief studentquest steiner downdin dance domain briefly crystal beech reason newcastle kai prenostic [SEP]']
[Init] best rec loss: 0.6868163347244263 for ['[CLS] air namely fourjun nkend neitherdf rich ; bit healthcare formula noon abdul drill parks pr daylight longitude tent milo usaas [SEP]']
[Init] best rec loss: 0.6856463551521301 for ['[CLS] shouts guards germany space establishments sometimes flags dead rear protestant floyd breed article gut id occupational development institute loss joint hull meat mode required [SEP]']
[Init] best rec loss: 0.6826488375663757 for ['[CLS] normal bo set supreme something justified brahms mmmering age forward deafting wins backchen growth frozeere romney fighting crawl popularity copy [SEP]']
[Init] best rec loss: 0.6799412369728088 for ['[CLS] labordant lindsey checkpoint judge roots lined americas cases dated discus think treated perspective awesomeencies quotameric won prize virginia conference frowned colour [SEP]']
[Init] best rec loss: 0.6793580651283264 for ['[CLS] sense bc dani actually ceased look thunder launch old doin translated ordainedrk case legal privately vatican pilot language sqldine turing midnight guard [SEP]']
[Init] best rec loss: 0.6682642102241516 for ['[CLS] eisenhower plaque arkansas screens sweat adventuremei wanda productey dna prison canontta tail franchise facts res si february season sociallydent badminton [SEP]']
[Init] best perm rec loss: 0.6651372313499451 for ['[CLS]dentey simei sweat franchise arkansas plaque facts canon february product res badminton screens adventuretta socially wanda prison eisenhower season tail dna [SEP]']
[Init] best perm rec loss: 0.6647960543632507 for ['[CLS] si socially tail dna wanda res arkansas february eisenhower screens sweat season franchiseey prison adventure product canonmeitta facts badminton plaquedent [SEP]']
[Init] best perm rec loss: 0.6633939146995544 for ['[CLS] dna sweat factsttadent sociallymei arkansas eisenhower si franchise canon adventure plaque season product tail res prison screens badminton wanda februaryey [SEP]']
[Init] best perm rec loss: 0.6628186106681824 for ['[CLS]mei si franchise wanda sweat product dna adventure eisenhowertta arkansas seasoney canon plaquedent tail february facts screens badminton res prison socially [SEP]']
[Init] best perm rec loss: 0.6616048216819763 for ['[CLS] res product socially badminton tail arkansas february facts sweat wandameident prison plaque eisenhower franchise adventure sitta dna seasoney screens canon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.494 (perp=13.996, rec=0.450, cos=0.244), tot_loss_proj:4.168 [t=0.17s]
prediction: ['[CLS] fee surely first fission free lucien [SEP] dollars this relax fee fay vanity terrorists manor dared debt gets rico fools hector wish streets madame [SEP]']
[ 100/2000] tot_loss=3.138 (perp=13.820, rec=0.307, cos=0.067), tot_loss_proj:4.129 [t=0.17s]
prediction: ['[CLS] pays s only fission free film [SEP] paid which au benefactor vanity vanity fright film metro debt pays whatever fools janet debt dick island [SEP]']
[ 150/2000] tot_loss=3.199 (perp=14.109, rec=0.268, cos=0.109), tot_loss_proj:4.096 [t=0.17s]
prediction: ['[CLS] vanity s vanity fission of films [SEP] vanity which¨ landmark vanity vanity fright film quietly debt pays what fools owed debt tumors y [SEP]']
[ 200/2000] tot_loss=3.022 (perp=13.239, rec=0.229, cos=0.145), tot_loss_proj:3.968 [t=0.17s]
prediction: ['[CLS] vanity s vanity vanity old film [SEP] vanity that \\ thing doubt vanity vanity film quietly debt pays what fools owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.623 (perp=12.085, rec=0.186, cos=0.020), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] vanity film vanity vanity rights film [SEP] vanity that \\ says doubt vanity fright s quietly debt pays what fools owed off benigni [SEP]']
[ 300/2000] tot_loss=2.630 (perp=12.282, rec=0.161, cos=0.013), tot_loss_proj:3.699 [t=0.17s]
prediction: ['[CLS] vanity film vanity carmine fleet film [SEP] vanity that \\, doubt vanity fright s quietly debt pays whatা owed off benigni [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.640 (perp=12.357, rec=0.160, cos=0.008), tot_loss_proj:3.671 [t=0.17s]
prediction: ['[CLS] kanye twenty film [SEP] a that \\ vanitymax vanity frowned doubt vanity vanity s comfortably debt pays what vanity owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.480 (perp=11.554, rec=0.140, cos=0.029), tot_loss_proj:3.731 [t=0.17s]
prediction: ['[CLS] kanye indo film [SEP] a vanity ¨ vanitymax vanity! doubt that fright s comfortably debt pays what vanity owed off benigni [SEP]']
[ 450/2000] tot_loss=2.387 (perp=11.222, rec=0.136, cos=0.007), tot_loss_proj:3.502 [t=0.17s]
prediction: ['[CLS] carmine indo film [SEP] a vanity ¨ vanitymax vanity, doubt that fright s quietly debt pays what vanity owed off benigni [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.402 (perp=11.308, rec=0.130, cos=0.011), tot_loss_proj:3.721 [t=0.17s]
prediction: ['[CLS] carmine indo film [SEP] a ¨ vanity vanitymax vanity, doubt that fright s mira debt pays what vanity owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.289 (perp=10.787, rec=0.125, cos=0.007), tot_loss_proj:3.586 [t=0.17s]
prediction: ['[CLS] carmine indo film [SEP] a ¨ vanity miramax vanity, doubt that fright s vanity debt pays what vanity owed off benigni [SEP]']
[ 600/2000] tot_loss=2.279 (perp=10.787, rec=0.115, cos=0.007), tot_loss_proj:3.580 [t=0.17s]
prediction: ['[CLS] carmine indo film [SEP] a ¨ vanity miramax vanity, doubt that fright s vanity debt pays what vanity owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.247 (perp=10.631, rec=0.114, cos=0.007), tot_loss_proj:3.568 [t=0.17s]
prediction: ['[CLS] something fright film [SEP] a ¨ vanity miramax fright, doubt that vanity s vanity debt pays what vanity owed off benigni [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.235 (perp=10.576, rec=0.114, cos=0.006), tot_loss_proj:3.517 [t=0.21s]
prediction: ['[CLS] a fright film [SEP] a ¡ vanity feltmax fright, doubt that vanity debt s vanity pays what vanity owed off benigni [SEP]']
[ 750/2000] tot_loss=2.591 (perp=10.667, rec=0.345, cos=0.112), tot_loss_proj:3.277 [t=0.17s]
prediction: ['[CLS] danny dangerous film [SEP] a cannot vanity weremax fright, doubt that vanity debt s vanity pays what - owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.372 (perp=10.158, rec=0.272, cos=0.069), tot_loss_proj:3.177 [t=0.21s]
prediction: ['[CLS] a breakers film [SEP] a cannot vanity were - fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.267 (perp=9.848, rec=0.246, cos=0.051), tot_loss_proj:3.116 [t=0.20s]
prediction: ['[CLS] a breakers film [SEP] - cannot vanity were a fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
[ 900/2000] tot_loss=2.232 (perp=9.848, rec=0.226, cos=0.036), tot_loss_proj:3.110 [t=0.21s]
prediction: ['[CLS] a breakers film [SEP] - cannot vanity were a fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=2.185 (perp=9.711, rec=0.215, cos=0.028), tot_loss_proj:3.132 [t=0.19s]
prediction: ['[CLS] a breakers - cannot vanity film [SEP] were a fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.125 (perp=9.548, rec=0.190, cos=0.025), tot_loss_proj:3.436 [t=0.19s]
prediction: ['[CLS] a breakers - cannot film vanity [SEP] were a fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
[1050/2000] tot_loss=2.161 (perp=9.759, rec=0.188, cos=0.021), tot_loss_proj:3.565 [t=0.19s]
prediction: ['[CLS] a stark - cannot film vanity [SEP] were a fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.122 (perp=9.589, rec=0.186, cos=0.019), tot_loss_proj:3.407 [t=0.19s]
prediction: ['[CLS] a stark [SEP] cannot film vanity - were a fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.139 (perp=9.701, rec=0.179, cos=0.019), tot_loss_proj:3.371 [t=0.19s]
prediction: ['[CLS] a breakers [SEP] cannot film himself vanity - a fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
[1200/2000] tot_loss=2.227 (perp=10.200, rec=0.170, cos=0.018), tot_loss_proj:3.505 [t=0.19s]
prediction: ['[CLS] a stark [SEP] cannot film himself vanityli a fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.217 (perp=10.176, rec=0.165, cos=0.017), tot_loss_proj:3.493 [t=0.19s]
prediction: ['[CLS] a stark pays cannot film were vanity [SEP] a fright, doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.153 (perp=9.792, rec=0.178, cos=0.017), tot_loss_proj:2.851 [t=0.18s]
prediction: ['[CLS] a stark pays film himself vanity [SEP] a fright, cannot doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
[1350/2000] tot_loss=2.089 (perp=9.487, rec=0.178, cos=0.014), tot_loss_proj:2.894 [t=0.17s]
prediction: ['[CLS] a breakers - film himself vanity [SEP] a fright, cannot doubt that vanity debt s vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.129 (perp=9.748, rec=0.165, cos=0.014), tot_loss_proj:3.070 [t=0.18s]
prediction: ['[CLS] a defeating - s himself vanity [SEP] a fright, cannot doubt that vanity debt film vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.094 (perp=9.582, rec=0.165, cos=0.013), tot_loss_proj:3.084 [t=0.18s]
prediction: ['[CLS] a defeating - s himself [SEP] vanity a fright, cannot doubt that vanity debt film vanity pays whatmax owed off benigni [SEP]']
[1500/2000] tot_loss=2.151 (perp=9.912, rec=0.156, cos=0.012), tot_loss_proj:2.938 [t=0.17s]
prediction: ['[CLS] a stark pays s himself [SEP] vanity a fright, cannot doubt that vanity debt film vanity pays whatmax owed off benigni [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.039 (perp=9.282, rec=0.169, cos=0.014), tot_loss_proj:2.899 [t=0.17s]
prediction: ['[CLS] a frightmax s himself [SEP] vanity a fright, cannot doubt that vanity debt film vanity pays what pays owed off benigni [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.023 (perp=9.242, rec=0.162, cos=0.013), tot_loss_proj:2.771 [t=0.17s]
prediction: ['[CLS] a frightmax s himself [SEP] vanity a fright, cannot doubt that vanity debt film pays pays what vanity owed off benigni [SEP]']
[1650/2000] tot_loss=2.019 (perp=9.242, rec=0.158, cos=0.013), tot_loss_proj:2.773 [t=0.17s]
prediction: ['[CLS] a frightmax s himself [SEP] vanity a fright, cannot doubt that vanity debt film pays pays what vanity owed off benigni [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.999 (perp=9.136, rec=0.159, cos=0.013), tot_loss_proj:2.776 [t=0.19s]
prediction: ['[CLS] a frightmax [SEP] s himself vanity a fright, cannot doubt that vanity debt film pays pays what vanity owed off benigni [SEP]']
Attempt swap
[1750/2000] tot_loss=1.999 (perp=9.136, rec=0.160, cos=0.012), tot_loss_proj:2.781 [t=0.17s]
prediction: ['[CLS] a frightmax [SEP] s himself vanity a fright, cannot doubt that vanity debt film pays pays what vanity owed off benigni [SEP]']
[1800/2000] tot_loss=1.966 (perp=8.978, rec=0.158, cos=0.012), tot_loss_proj:2.715 [t=0.17s]
prediction: ['[CLS] afulmax [SEP] s himself vanity a fright, cannot doubt that vanity debt film pays pays what vanity owed off benigni [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.962 (perp=8.983, rec=0.154, cos=0.012), tot_loss_proj:2.671 [t=0.17s]
prediction: ['[CLS] afulmax [SEP] himself s vanity a fright, cannot doubt that vanity debt film pays pays what vanity owed off benigni [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.936 (perp=8.839, rec=0.153, cos=0.016), tot_loss_proj:2.645 [t=0.17s]
prediction: ['[CLS] afulmax [SEP] himself s a vanity fright, cannot doubt that vanity debt film pays pays what vanity owed off benigni [SEP]']
[1950/2000] tot_loss=1.936 (perp=8.839, rec=0.155, cos=0.013), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS] afulmax [SEP] himself s a vanity fright, cannot doubt that vanity debt film pays pays what vanity owed off benigni [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.923 (perp=8.705, rec=0.168, cos=0.014), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] afulmax [SEP] himself s a vanity fright, cannot doubt that vanity debt film pays owed what vanity pays off benigni [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] a fright film [SEP] a ¡ vanity feltmax fright, doubt that vanity debt s vanity pays what vanity owed off benigni [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 66.667 | p: 63.636 | r: 70.000
rouge2     | fm: 5.000 | p: 4.762 | r: 5.263
rougeL     | fm: 42.857 | p: 40.909 | r: 45.000
rougeLsum  | fm: 42.857 | p: 40.909 | r: 45.000
r1fm+r2fm = 71.667

[Aggregate metrics]:
rouge1     | fm: 95.004 | p: 94.444 | r: 95.608
rouge2     | fm: 78.875 | p: 78.836 | r: 78.918
rougeL     | fm: 87.708 | p: 87.374 | r: 88.069
rougeLsum  | fm: 87.708 | p: 87.374 | r: 88.069
r1fm+r2fm = 173.880

input #8 time: 0:10:06 | total time: 1:17:17


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9993981275486599
highest_index [0]
highest [0.9993981275486599]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.8187081217765808 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.7782889604568481 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.7333240509033203 for ['[CLS] [SEP]ware audit how ) qualified adrian yet [SEP]']
[Init] best rec loss: 0.7192718386650085 for ['[CLS] owners pad there arena da rico weekly family [SEP]']
[Init] best rec loss: 0.6858556866645813 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 0.6808661222457886 for ['[CLS] red sh dipped in outstretched hour go imagine [SEP]']
[Init] best rec loss: 0.6510923504829407 for ['[CLS] cody outlaw edward arsenal deccadden luck deaths [SEP]']
[Init] best perm rec loss: 0.6500662565231323 for ['[CLS] cody luck deaths outlaw decca arsenaldden edward [SEP]']
[Init] best perm rec loss: 0.6491195559501648 for ['[CLS]dden deaths arsenal luck decca outlaw cody edward [SEP]']
[Init] best perm rec loss: 0.648005485534668 for ['[CLS] outlaw deaths luckdden cody edward arsenal decca [SEP]']
[Init] best perm rec loss: 0.6462655663490295 for ['[CLS] decca cody luck edward deaths outlawdden arsenal [SEP]']
[Init] best perm rec loss: 0.6440391540527344 for ['[CLS] cody decca deaths arsenal luck edwarddden outlaw [SEP]']
[Init] best perm rec loss: 0.6436610221862793 for ['[CLS] cody decca outlaw luck arsenal edwarddden deaths [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.755 (perp=11.724, rec=0.290, cos=0.120), tot_loss_proj:3.520 [t=0.17s]
prediction: ['[CLS] neill quantum garagehead metaphysical metaphysical claptra [SEP]']
[ 100/2000] tot_loss=2.477 (perp=11.170, rec=0.210, cos=0.033), tot_loss_proj:3.038 [t=0.17s]
prediction: ['[CLS] of soft claphead metaphysical metaphysical claptra [SEP]']
[ 150/2000] tot_loss=2.568 (perp=12.132, rec=0.137, cos=0.005), tot_loss_proj:3.038 [t=0.17s]
prediction: ['[CLS] of softheadheadhead metaphysical claptra [SEP]']
[ 200/2000] tot_loss=2.559 (perp=12.132, rec=0.122, cos=0.011), tot_loss_proj:3.027 [t=0.17s]
prediction: ['[CLS] of softheadheadhead metaphysical claptra [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.251 (perp=10.214, rec=0.189, cos=0.019), tot_loss_proj:2.771 [t=0.17s]
prediction: ['[CLS] metaphysical claptra of softheadheadhead [SEP]']
[ 300/2000] tot_loss=2.382 (perp=11.323, rec=0.113, cos=0.004), tot_loss_proj:3.002 [t=0.18s]
prediction: ['[CLS] metaphysical claptra of softtraheaded [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.028 (perp=9.611, rec=0.103, cos=0.003), tot_loss_proj:2.570 [t=0.18s]
prediction: ['[CLS] metaphysical claptra of softheadedtra [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.015 (perp=9.611, rec=0.088, cos=0.004), tot_loss_proj:2.567 [t=0.19s]
prediction: ['[CLS] metaphysical claptra of softheadedtra [SEP]']
[ 450/2000] tot_loss=2.016 (perp=9.611, rec=0.092, cos=0.002), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] metaphysical claptra of softheadedtra [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.014 (perp=9.611, rec=0.090, cos=0.002), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] metaphysical claptra of softheadedtra [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.006 (perp=9.611, rec=0.083, cos=0.002), tot_loss_proj:2.567 [t=0.17s]
prediction: ['[CLS] metaphysical claptra of softheadedtra [SEP]']
[ 600/2000] tot_loss=1.952 (perp=9.325, rec=0.085, cos=0.002), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS] metaphysical clapp of softheadedtra [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.877 (perp=8.902, rec=0.094, cos=0.002), tot_loss_proj:2.673 [t=0.17s]
prediction: ['[CLS] metaphysical clap of softheadedtrap [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.635 (perp=7.706, rec=0.089, cos=0.005), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] metaphysical of softheaded claptrap [SEP]']
[ 750/2000] tot_loss=1.619 (perp=7.706, rec=0.076, cos=0.002), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] metaphysical of softheaded claptrap [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.551 (perp=7.384, rec=0.073, cos=0.002), tot_loss_proj:1.647 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.551 (perp=7.384, rec=0.072, cos=0.001), tot_loss_proj:1.651 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 900/2000] tot_loss=1.560 (perp=7.384, rec=0.082, cos=0.001), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.548 (perp=7.384, rec=0.070, cos=0.001), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.539 (perp=7.384, rec=0.061, cos=0.001), tot_loss_proj:1.643 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1050/2000] tot_loss=1.549 (perp=7.384, rec=0.071, cos=0.001), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.540 (perp=7.384, rec=0.062, cos=0.001), tot_loss_proj:1.650 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.533 (perp=7.384, rec=0.055, cos=0.001), tot_loss_proj:1.655 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1200/2000] tot_loss=1.540 (perp=7.384, rec=0.062, cos=0.001), tot_loss_proj:1.654 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.384, rec=0.072, cos=0.001), tot_loss_proj:1.645 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.541 (perp=7.384, rec=0.063, cos=0.001), tot_loss_proj:1.658 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1350/2000] tot_loss=1.537 (perp=7.384, rec=0.059, cos=0.001), tot_loss_proj:1.652 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.554 (perp=7.384, rec=0.076, cos=0.001), tot_loss_proj:1.652 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.541 (perp=7.384, rec=0.063, cos=0.001), tot_loss_proj:1.661 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1500/2000] tot_loss=1.545 (perp=7.384, rec=0.067, cos=0.001), tot_loss_proj:1.655 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.534 (perp=7.384, rec=0.056, cos=0.001), tot_loss_proj:1.651 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.549 (perp=7.384, rec=0.071, cos=0.001), tot_loss_proj:1.647 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1650/2000] tot_loss=1.544 (perp=7.384, rec=0.066, cos=0.001), tot_loss_proj:1.654 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.542 (perp=7.384, rec=0.064, cos=0.001), tot_loss_proj:1.653 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.536 (perp=7.384, rec=0.058, cos=0.001), tot_loss_proj:1.643 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.545 (perp=7.384, rec=0.067, cos=0.001), tot_loss_proj:1.650 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.532 (perp=7.384, rec=0.053, cos=0.001), tot_loss_proj:1.658 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.547 (perp=7.384, rec=0.069, cos=0.001), tot_loss_proj:1.656 [t=0.20s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=1.534 (perp=7.384, rec=0.056, cos=0.001), tot_loss_proj:1.639 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.549 (perp=7.384, rec=0.071, cos=0.001), tot_loss_proj:1.648 [t=0.17s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical softheaded claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 95.504 | p: 95.000 | r: 96.048
rouge2     | fm: 74.988 | p: 74.952 | r: 75.026
rougeL     | fm: 87.619 | p: 87.424 | r: 87.833
rougeLsum  | fm: 87.636 | p: 87.424 | r: 87.857
r1fm+r2fm = 170.492

input #9 time: 0:08:02 | total time: 1:25:20


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9991472052153934
highest_index [0]
highest [0.9991472052153934]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.8814778923988342 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.8704736828804016 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.8242684602737427 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best rec loss: 0.8198046684265137 for ['[CLS] memory gen dona lifetime riseientworthy factor subcommittee sun gregorian read hips [SEP]']
[Init] best rec loss: 0.8065224885940552 for ['[CLS] hidelin swing reacher immediately championship nervous accompaniedcar eva pounded besides help [SEP]']
[Init] best perm rec loss: 0.8059665560722351 for ['[CLS] help reachercar hid championship immediately besideselin accompanied eva nervous pounded swing [SEP]']
[Init] best perm rec loss: 0.8049544095993042 for ['[CLS] help nervouscarelin besides reacher championship swing pounded hid immediately accompanied eva [SEP]']
[Init] best perm rec loss: 0.8048099279403687 for ['[CLS] hid helpcar pounded eva immediately besideselin swing reacher championship accompanied nervous [SEP]']
[Init] best perm rec loss: 0.8033286333084106 for ['[CLS] besides nervous immediately eva hid swing pounded reacherelincar accompanied help championship [SEP]']
[Init] best perm rec loss: 0.8032909035682678 for ['[CLS]car championship hid accompanied reacher swing evaelin immediately nervous help pounded besides [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.953 (perp=12.834, rec=0.358, cos=0.028), tot_loss_proj:4.379 [t=0.17s]
prediction: ['[CLS] anders 6fully ends differently percussion eva in songs freelytrayignant very [SEP]']
[ 100/2000] tot_loss=2.388 (perp=10.733, rec=0.234, cos=0.008), tot_loss_proj:3.945 [t=0.17s]
prediction: ['[CLS] ab doggly balances rhythmtime in months abtrayulsively [SEP]']
[ 150/2000] tot_loss=2.593 (perp=11.712, rec=0.242, cos=0.008), tot_loss_proj:3.552 [t=0.17s]
prediction: ['[CLS] ab 2005ly balance real rhythms with from months ab soundtrackulsive ab [SEP]']
[ 200/2000] tot_loss=2.389 (perp=11.073, rec=0.166, cos=0.008), tot_loss_proj:3.508 [t=0.17s]
prediction: ['[CLS] ab 2005ly balance real rhythms with. days ab rhythmsulsive ab [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.038 (perp=9.421, rec=0.148, cos=0.006), tot_loss_proj:3.142 [t=0.17s]
prediction: ['[CLS] ab 2005ly balance real rhythms with days. abulsive. ab [SEP]']
[ 300/2000] tot_loss=2.030 (perp=9.438, rec=0.137, cos=0.005), tot_loss_proj:2.700 [t=0.20s]
prediction: ['[CLS]ly famously balance real rhythms with moments. abulsive. ab [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.058 (perp=9.500, rec=0.146, cos=0.012), tot_loss_proj:2.745 [t=0.17s]
prediction: ['[CLS] rhythms starly balance really with moments. ab incident. ab [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.942 (perp=9.064, rec=0.125, cos=0.005), tot_loss_proj:2.696 [t=0.17s]
prediction: ['[CLS] rhythms starly balance real incident with moments. ably. ab [SEP]']
[ 450/2000] tot_loss=1.969 (perp=9.189, rec=0.126, cos=0.005), tot_loss_proj:2.544 [t=0.17s]
prediction: ['[CLS] rhythms classicly balance real incident with moments. ably. ab [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.059 (perp=9.571, rec=0.140, cos=0.005), tot_loss_proj:2.902 [t=0.17s]
prediction: ['[CLS] rhythms patrol ably balance real incident with days. ablyulsive [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.957 (perp=9.089, rec=0.134, cos=0.005), tot_loss_proj:2.855 [t=0.17s]
prediction: ['[CLS] week rhythms ably balance real incident with days. ablyulsive [SEP]']
[ 600/2000] tot_loss=1.680 (perp=7.716, rec=0.132, cos=0.005), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] week rhythms ably balance real incident with moves. ably. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.717 (perp=7.975, rec=0.118, cos=0.004), tot_loss_proj:2.287 [t=0.17s]
prediction: ['[CLS] stars rhythms ably balance real moments with incident. ably. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.661 (perp=7.671, rec=0.122, cos=0.005), tot_loss_proj:2.315 [t=0.17s]
prediction: ['[CLS] rhythms ably balance real moments with incident. ably stars. [SEP]']
[ 750/2000] tot_loss=1.652 (perp=7.671, rec=0.114, cos=0.004), tot_loss_proj:2.305 [t=0.17s]
prediction: ['[CLS] rhythms ably balance real moments with incident. ably stars. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.546 (perp=7.145, rec=0.113, cos=0.004), tot_loss_proj:2.195 [t=0.17s]
prediction: ['[CLS] stars ably balance real moments with incident. ably rhythms. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.001 (perp=9.379, rec=0.120, cos=0.005), tot_loss_proj:2.741 [t=0.17s]
prediction: ['[CLS]ulsive ably balance real stars with incident. ably rhythmsulsive [SEP]']
[ 900/2000] tot_loss=1.778 (perp=8.310, rec=0.112, cos=0.004), tot_loss_proj:2.340 [t=0.17s]
prediction: ['[CLS]ulsive ably balance real scene with incident. ably rhythms. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.648 (perp=7.674, rec=0.110, cos=0.004), tot_loss_proj:2.071 [t=0.17s]
prediction: ['[CLS]. ably balance real scene with incidentulsive ably rhythms. [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.585 (perp=7.348, rec=0.112, cos=0.004), tot_loss_proj:2.327 [t=0.17s]
prediction: ['[CLS]. ably scene balance real with incidentulsive ably rhythms. [SEP]']
[1050/2000] tot_loss=1.650 (perp=7.675, rec=0.111, cos=0.004), tot_loss_proj:2.426 [t=0.17s]
prediction: ['[CLS]. ably stars balance real with incidentulsive ably rhythms. [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.630 (perp=7.595, rec=0.108, cos=0.003), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS]. ably balance real stars with incidentulsive ably rhythms. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.590 (perp=7.348, rec=0.117, cos=0.003), tot_loss_proj:2.328 [t=0.17s]
prediction: ['[CLS]. ably scene balance real with incidentulsive ably rhythms. [SEP]']
[1200/2000] tot_loss=1.661 (perp=7.675, rec=0.123, cos=0.003), tot_loss_proj:2.433 [t=0.17s]
prediction: ['[CLS]. ably stars balance real with incidentulsive ably rhythms. [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.643 (perp=7.595, rec=0.121, cos=0.003), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS]. ably balance real stars with incidentulsive ably rhythms. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.585 (perp=7.348, rec=0.112, cos=0.003), tot_loss_proj:2.326 [t=0.17s]
prediction: ['[CLS]. ably scene balance real with incidentulsive ably rhythms. [SEP]']
[1350/2000] tot_loss=1.656 (perp=7.675, rec=0.118, cos=0.003), tot_loss_proj:2.420 [t=0.17s]
prediction: ['[CLS]. ably stars balance real with incidentulsive ably rhythms. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.840 (perp=8.604, rec=0.116, cos=0.004), tot_loss_proj:2.472 [t=0.17s]
prediction: ['[CLS] stars ably. balance real with incidentulsive proply rhythms. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.615 (perp=7.540, rec=0.104, cos=0.003), tot_loss_proj:2.234 [t=0.19s]
prediction: ['[CLS] stars ably. balance real with incidently propulsive rhythms. [SEP]']
[1500/2000] tot_loss=1.631 (perp=7.540, rec=0.119, cos=0.003), tot_loss_proj:2.230 [t=0.19s]
prediction: ['[CLS] stars ably. balance real with incidently propulsive rhythms. [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.577 (perp=7.324, rec=0.109, cos=0.003), tot_loss_proj:2.239 [t=0.17s]
prediction: ['[CLS] stars ably. balance real with incident propulsively rhythms. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.579 (perp=7.324, rec=0.111, cos=0.003), tot_loss_proj:2.239 [t=0.17s]
prediction: ['[CLS] stars ably. balance real with incident propulsively rhythms. [SEP]']
[1650/2000] tot_loss=1.582 (perp=7.324, rec=0.114, cos=0.003), tot_loss_proj:2.243 [t=0.17s]
prediction: ['[CLS] stars ably. balance real with incident propulsively rhythms. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.532 (perp=7.101, rec=0.108, cos=0.003), tot_loss_proj:2.156 [t=0.17s]
prediction: ['[CLS] stars ably. balance really with incident propulsive rhythms. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.527 (perp=7.101, rec=0.104, cos=0.003), tot_loss_proj:2.154 [t=0.17s]
prediction: ['[CLS] stars ably. balance really with incident propulsive rhythms. [SEP]']
[1800/2000] tot_loss=1.540 (perp=7.101, rec=0.116, cos=0.003), tot_loss_proj:2.156 [t=0.20s]
prediction: ['[CLS] stars ably. balance really with incident propulsive rhythms. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.534 (perp=7.101, rec=0.111, cos=0.003), tot_loss_proj:2.153 [t=0.19s]
prediction: ['[CLS] stars ably. balance really with incident propulsive rhythms. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.539 (perp=7.101, rec=0.115, cos=0.003), tot_loss_proj:2.156 [t=0.19s]
prediction: ['[CLS] stars ably. balance really with incident propulsive rhythms. [SEP]']
[1950/2000] tot_loss=1.538 (perp=7.101, rec=0.114, cos=0.003), tot_loss_proj:2.157 [t=0.19s]
prediction: ['[CLS] stars ably. balance really with incident propulsive rhythms. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.471 (perp=6.762, rec=0.114, cos=0.004), tot_loss_proj:2.040 [t=0.19s]
prediction: ['[CLS] stars incident ably. balance really with propulsive rhythms. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] stars ably. balance really with incident propulsive rhythms. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.000 | p: 70.000 | r: 70.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 70.000

[Aggregate metrics]:
rouge1     | fm: 93.185 | p: 92.727 | r: 93.680
rouge2     | fm: 68.182 | p: 68.139 | r: 68.230
rougeL     | fm: 83.882 | p: 83.609 | r: 84.177
rougeLsum  | fm: 84.214 | p: 84.022 | r: 84.416
r1fm+r2fm = 161.367

input #10 time: 0:10:21 | total time: 1:35:41


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9992849825911105
highest_index [0]
highest [0.9992849825911105]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.9119930863380432 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.9002856016159058 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.8241632580757141 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.8143832683563232 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.8102236986160278 for ['[CLS]ture inlandvd tal me platform drawngu mile familiar [SEP]']
[Init] best perm rec loss: 0.8092162609100342 for ['[CLS] inlandture drawngu platform tal familiar mevd mile [SEP]']
[Init] best perm rec loss: 0.8080193400382996 for ['[CLS] inland mevdgu mile tal drawn familiarture platform [SEP]']
[Init] best perm rec loss: 0.8064080476760864 for ['[CLS] inland me milevd platformture familiar talgu drawn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.379 (perp=10.238, rec=0.304, cos=0.027), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS] that attempted gel that refused was refused gel （ refused [SEP]']
[ 100/2000] tot_loss=2.268 (perp=10.415, rec=0.177, cos=0.008), tot_loss_proj:3.027 [t=0.17s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel attempted stubborn [SEP]']
[ 150/2000] tot_loss=2.253 (perp=10.660, rec=0.118, cos=0.003), tot_loss_proj:2.941 [t=0.17s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel here stubborn [SEP]']
[ 200/2000] tot_loss=2.226 (perp=10.660, rec=0.091, cos=0.002), tot_loss_proj:2.948 [t=0.17s]
prediction: ['[CLS] was attempted gel that stubbornly refused gel here stubborn [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.807 (perp=8.529, rec=0.099, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] was attempted here that stubbornly refused to gel stubborn [SEP]']
[ 300/2000] tot_loss=1.794 (perp=8.529, rec=0.086, cos=0.002), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] was attempted here that stubbornly refused to gel stubborn [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.715 (perp=8.177, rec=0.078, cos=0.002), tot_loss_proj:1.943 [t=0.17s]
prediction: ['[CLS] was attempted here that stubborn stubbornly refused to gel [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.597 (perp=7.590, rec=0.077, cos=0.002), tot_loss_proj:1.913 [t=0.17s]
prediction: ['[CLS] here was attempted that stubborn stubbornly refused to gel [SEP]']
[ 450/2000] tot_loss=1.466 (perp=6.985, rec=0.068, cos=0.001), tot_loss_proj:2.060 [t=0.17s]
prediction: ['[CLS] here was attempted that being stubbornly refused to gel [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.468 (perp=6.985, rec=0.070, cos=0.001), tot_loss_proj:2.056 [t=0.17s]
prediction: ['[CLS] here was attempted that being stubbornly refused to gel [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.337 (perp=6.291, rec=0.078, cos=0.002), tot_loss_proj:1.563 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[ 600/2000] tot_loss=1.324 (perp=6.291, rec=0.064, cos=0.002), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.330 (perp=6.291, rec=0.071, cos=0.001), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.317 (perp=6.291, rec=0.057, cos=0.001), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[ 750/2000] tot_loss=1.329 (perp=6.291, rec=0.070, cos=0.001), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.321 (perp=6.291, rec=0.061, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.317 (perp=6.291, rec=0.058, cos=0.001), tot_loss_proj:1.559 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[ 900/2000] tot_loss=1.322 (perp=6.291, rec=0.063, cos=0.001), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.318 (perp=6.291, rec=0.058, cos=0.001), tot_loss_proj:1.560 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.338 (perp=6.291, rec=0.079, cos=0.001), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1050/2000] tot_loss=1.321 (perp=6.291, rec=0.062, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.324 (perp=6.291, rec=0.064, cos=0.001), tot_loss_proj:1.556 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.325 (perp=6.291, rec=0.066, cos=0.001), tot_loss_proj:1.569 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1200/2000] tot_loss=1.330 (perp=6.291, rec=0.070, cos=0.001), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.325 (perp=6.291, rec=0.065, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.321 (perp=6.291, rec=0.061, cos=0.001), tot_loss_proj:1.563 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1350/2000] tot_loss=1.321 (perp=6.291, rec=0.061, cos=0.001), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.327 (perp=6.291, rec=0.067, cos=0.001), tot_loss_proj:1.562 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.320 (perp=6.291, rec=0.061, cos=0.001), tot_loss_proj:1.570 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1500/2000] tot_loss=1.319 (perp=6.291, rec=0.060, cos=0.001), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.313 (perp=6.291, rec=0.053, cos=0.001), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.324 (perp=6.291, rec=0.065, cos=0.001), tot_loss_proj:1.564 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1650/2000] tot_loss=1.326 (perp=6.291, rec=0.066, cos=0.001), tot_loss_proj:1.571 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.326 (perp=6.291, rec=0.066, cos=0.001), tot_loss_proj:1.568 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.324 (perp=6.291, rec=0.064, cos=0.001), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1800/2000] tot_loss=1.326 (perp=6.291, rec=0.066, cos=0.001), tot_loss_proj:1.561 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.324 (perp=6.291, rec=0.065, cos=0.001), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.331 (perp=6.291, rec=0.071, cos=0.001), tot_loss_proj:1.557 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1950/2000] tot_loss=1.318 (perp=6.291, rec=0.058, cos=0.001), tot_loss_proj:1.561 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.325 (perp=6.291, rec=0.065, cos=0.001), tot_loss_proj:1.567 [t=0.17s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was being attempted that stubbornly refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 94.031 | p: 93.561 | r: 94.206
rouge2     | fm: 68.740 | p: 68.690 | r: 68.772
rougeL     | fm: 84.638 | p: 84.407 | r: 84.957
rougeLsum  | fm: 85.063 | p: 84.848 | r: 85.334
r1fm+r2fm = 162.771

input #11 time: 0:08:15 | total time: 1:43:56


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.99934391763152
highest_index [0]
highest [0.99934391763152]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.867132842540741 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.861339807510376 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 0.799628496170044 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7725229263305664 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7675877213478088 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.743887186050415 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best perm rec loss: 0.7403388023376465 for ['[CLS] ha guess shades margin office series bethitasyn few victor laynction translate [SEP]']
[Init] best perm rec loss: 0.7387611269950867 for ['[CLS] guess beth ha few series shadesitas translate office marginnction layyn victor [SEP]']
[Init] best perm rec loss: 0.7375137805938721 for ['[CLS]nction translate few victor beth office margin series shades haitas guessyn lay [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.133 (perp=9.226, rec=0.257, cos=0.031), tot_loss_proj:2.738 [t=0.17s]
prediction: ['[CLS] cable cable barely better to advantage advantage as would to exceptional cable rule cable [SEP]']
[ 100/2000] tot_loss=2.245 (perp=10.247, rec=0.173, cos=0.023), tot_loss_proj:2.885 [t=0.17s]
prediction: ['[CLS] cable cable barely better to seen advantage on will its especially cable internal cable [SEP]']
[ 150/2000] tot_loss=2.180 (perp=10.102, rec=0.148, cos=0.011), tot_loss_proj:2.886 [t=0.17s]
prediction: ['[CLS] cable its barely better to seen advantage on will its especially cable internal cable [SEP]']
[ 200/2000] tot_loss=2.222 (perp=10.450, rec=0.125, cos=0.008), tot_loss_proj:3.161 [t=0.17s]
prediction: ['[CLS] cable on barely better to seen advantage on will its especially cable its especially [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.007 (perp=9.463, rec=0.107, cos=0.007), tot_loss_proj:2.868 [t=0.17s]
prediction: ['[CLS] especially on barely better to seen advantage on will its cable cable its especially [SEP]']
[ 300/2000] tot_loss=2.067 (perp=9.814, rec=0.099, cos=0.005), tot_loss_proj:2.861 [t=0.17s]
prediction: ['[CLS] especially on barely better to seen advantage considering will its cable cable its especially [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.944 (perp=9.227, rec=0.093, cos=0.005), tot_loss_proj:2.777 [t=0.20s]
prediction: ['[CLS] especially on barely better to seen advantage considering will its cable especially its cable [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.938 (perp=9.227, rec=0.088, cos=0.005), tot_loss_proj:2.776 [t=0.17s]
prediction: ['[CLS] especially on barely better to seen advantage considering will its cable especially its cable [SEP]']
[ 450/2000] tot_loss=2.027 (perp=9.671, rec=0.088, cos=0.005), tot_loss_proj:2.916 [t=0.17s]
prediction: ['[CLS] especially on barely better to seen advantage considering will its cable especially its its [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.020 (perp=9.671, rec=0.081, cos=0.005), tot_loss_proj:2.906 [t=0.17s]
prediction: ['[CLS] especially on barely better to seen advantage considering will its cable especially its its [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.226 (perp=10.642, rec=0.092, cos=0.006), tot_loss_proj:3.033 [t=0.17s]
prediction: ['[CLS] especiallyum barely better to seen advantage considering will its cable especially on its [SEP]']
[ 600/2000] tot_loss=2.217 (perp=10.642, rec=0.084, cos=0.005), tot_loss_proj:3.040 [t=0.17s]
prediction: ['[CLS] especiallyum barely better to seen advantage considering will its cable especially on its [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.018 (perp=9.602, rec=0.093, cos=0.005), tot_loss_proj:2.853 [t=0.17s]
prediction: ['[CLS] especially considering barely better to seen advantageum will its cable especially on its [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.008 (perp=9.602, rec=0.084, cos=0.004), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] especially considering barely better to seen advantageum will its cable especially on its [SEP]']
[ 750/2000] tot_loss=2.027 (perp=9.698, rec=0.084, cos=0.004), tot_loss_proj:2.834 [t=0.17s]
prediction: ['[CLS] especially considering barely better to seen advantageum will its cable that on its [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.846 (perp=8.748, rec=0.091, cos=0.005), tot_loss_proj:2.675 [t=0.17s]
prediction: ['[CLS] especially considering barely better to its advantageum will seen cable that on its [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.760 (perp=8.400, rec=0.077, cos=0.003), tot_loss_proj:2.615 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen cable that on its [SEP]']
[ 900/2000] tot_loss=1.757 (perp=8.400, rec=0.074, cos=0.003), tot_loss_proj:2.612 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen cable that on its [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.710 (perp=8.181, rec=0.071, cos=0.003), tot_loss_proj:2.607 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen that cable on its [SEP]']
Attempt swap
[1000/2000] tot_loss=1.711 (perp=8.181, rec=0.072, cos=0.003), tot_loss_proj:2.608 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen that cable on its [SEP]']
[1050/2000] tot_loss=1.704 (perp=8.181, rec=0.065, cos=0.003), tot_loss_proj:2.610 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen that cable on its [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.646 (perp=7.867, rec=0.070, cos=0.003), tot_loss_proj:2.436 [t=0.19s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1150/2000] tot_loss=1.651 (perp=7.867, rec=0.075, cos=0.003), tot_loss_proj:2.436 [t=0.19s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
[1200/2000] tot_loss=1.649 (perp=7.867, rec=0.073, cos=0.003), tot_loss_proj:2.439 [t=0.19s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1250/2000] tot_loss=1.645 (perp=7.867, rec=0.069, cos=0.003), tot_loss_proj:2.437 [t=0.24s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1300/2000] tot_loss=1.656 (perp=7.867, rec=0.080, cos=0.003), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
[1350/2000] tot_loss=1.649 (perp=7.867, rec=0.072, cos=0.003), tot_loss_proj:2.438 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1400/2000] tot_loss=1.653 (perp=7.867, rec=0.077, cos=0.003), tot_loss_proj:2.435 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1450/2000] tot_loss=1.660 (perp=7.867, rec=0.084, cos=0.003), tot_loss_proj:2.433 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
[1500/2000] tot_loss=1.651 (perp=7.867, rec=0.075, cos=0.003), tot_loss_proj:2.443 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1550/2000] tot_loss=1.645 (perp=7.867, rec=0.068, cos=0.003), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1600/2000] tot_loss=1.657 (perp=7.867, rec=0.081, cos=0.003), tot_loss_proj:2.442 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
[1650/2000] tot_loss=1.643 (perp=7.867, rec=0.066, cos=0.003), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1700/2000] tot_loss=1.645 (perp=7.867, rec=0.069, cos=0.003), tot_loss_proj:2.441 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1750/2000] tot_loss=1.647 (perp=7.867, rec=0.071, cos=0.003), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
[1800/2000] tot_loss=1.652 (perp=7.867, rec=0.075, cos=0.003), tot_loss_proj:2.438 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1850/2000] tot_loss=1.650 (perp=7.867, rec=0.074, cos=0.003), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[1900/2000] tot_loss=1.655 (perp=7.867, rec=0.078, cos=0.003), tot_loss_proj:2.443 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
[1950/2000] tot_loss=1.657 (perp=7.867, rec=0.081, cos=0.003), tot_loss_proj:2.435 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Attempt swap
[2000/2000] tot_loss=1.647 (perp=7.867, rec=0.071, cos=0.003), tot_loss_proj:2.435 [t=0.17s]
prediction: ['[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] especially considering its better to barely advantageum will seen on cable that its [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.667 | p: 86.667 | r: 86.667
rouge2     | fm: 21.429 | p: 21.429 | r: 21.429
rougeL     | fm: 46.667 | p: 46.667 | r: 46.667
rougeLsum  | fm: 46.667 | p: 46.667 | r: 46.667
r1fm+r2fm = 108.095

[Aggregate metrics]:
rouge1     | fm: 93.333 | p: 93.030 | r: 93.626
rouge2     | fm: 64.885 | p: 64.872 | r: 64.890
rougeL     | fm: 81.932 | p: 81.772 | r: 82.179
rougeLsum  | fm: 81.566 | p: 81.329 | r: 81.883
r1fm+r2fm = 158.219

input #12 time: 0:09:52 | total time: 1:53:49


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9992538394516878
highest_index [0]
highest [0.9992538394516878]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.8887738585472107 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.8844950199127197 for ['[CLS] te saw thunder fame ambulance concerts pinch [SEP]']
[Init] best rec loss: 0.8545551896095276 for ['[CLS] established chloeerine taylor fiscal level cohen [SEP]']
[Init] best rec loss: 0.7818396091461182 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 0.7813502550125122 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 0.7700784802436829 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 0.7579190731048584 for ['[CLS]typic malice avenue andy rightart brought [SEP]']
[Init] best rec loss: 0.7517123222351074 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best rec loss: 0.7473309636116028 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 0.7472784519195557 for ['[CLS] permanent defeat arm cardinal roweional precision [SEP]']
[Init] best perm rec loss: 0.7453463077545166 for ['[CLS] cardinal arm defeat rowe permanent precisionional [SEP]']
[Init] best perm rec loss: 0.7436425089836121 for ['[CLS]ional precision arm cardinal permanent rowe defeat [SEP]']
[Init] best perm rec loss: 0.7426804900169373 for ['[CLS] rowe cardinal defeat armional permanent precision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.506 (perp=10.953, rec=0.271, cos=0.044), tot_loss_proj:3.438 [t=0.17s]
prediction: ['[CLS] point flame flame entity explode contract point [SEP]']
[ 100/2000] tot_loss=2.480 (perp=11.578, rec=0.156, cos=0.008), tot_loss_proj:3.300 [t=0.17s]
prediction: ['[CLS] at flame flame things into explode point [SEP]']
[ 150/2000] tot_loss=2.430 (perp=11.578, rec=0.109, cos=0.005), tot_loss_proj:3.322 [t=0.17s]
prediction: ['[CLS] at flame flame things into explode point [SEP]']
[ 200/2000] tot_loss=2.421 (perp=11.578, rec=0.102, cos=0.003), tot_loss_proj:3.325 [t=0.17s]
prediction: ['[CLS] at flame flame things into explode point [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.947 (perp=9.127, rec=0.115, cos=0.006), tot_loss_proj:2.675 [t=0.17s]
prediction: ['[CLS] at point flame flame things into explode [SEP]']
[ 300/2000] tot_loss=1.920 (perp=9.127, rec=0.092, cos=0.003), tot_loss_proj:2.666 [t=0.17s]
prediction: ['[CLS] at point flame flame things into explode [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.801 (perp=8.611, rec=0.076, cos=0.003), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] at point flame explode things into flame [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.818 (perp=8.676, rec=0.081, cos=0.003), tot_loss_proj:2.657 [t=0.17s]
prediction: ['[CLS] at point flame things explode into things [SEP]']
[ 450/2000] tot_loss=1.815 (perp=8.676, rec=0.078, cos=0.002), tot_loss_proj:2.665 [t=0.17s]
prediction: ['[CLS] at point flame things explode into things [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.819 (perp=8.676, rec=0.082, cos=0.002), tot_loss_proj:2.662 [t=0.17s]
prediction: ['[CLS] at point flame things explode into things [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.805 (perp=8.676, rec=0.068, cos=0.002), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS] at point flame things explode into things [SEP]']
[ 600/2000] tot_loss=2.078 (perp=10.041, rec=0.068, cos=0.002), tot_loss_proj:3.098 [t=0.17s]
prediction: ['[CLS] at point flame that explode into things [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.812 (perp=8.720, rec=0.066, cos=0.002), tot_loss_proj:2.354 [t=0.17s]
prediction: ['[CLS] at point things that explode into flame [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.434 (perp=6.423, rec=0.136, cos=0.013), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 750/2000] tot_loss=1.394 (perp=6.423, rec=0.103, cos=0.007), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.364 (perp=6.423, rec=0.077, cos=0.003), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.375 (perp=6.423, rec=0.088, cos=0.002), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[ 900/2000] tot_loss=1.370 (perp=6.423, rec=0.083, cos=0.002), tot_loss_proj:2.108 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.363 (perp=6.423, rec=0.077, cos=0.002), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.359 (perp=6.423, rec=0.072, cos=0.002), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1050/2000] tot_loss=1.359 (perp=6.423, rec=0.073, cos=0.002), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.358 (perp=6.423, rec=0.071, cos=0.002), tot_loss_proj:2.128 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.364 (perp=6.423, rec=0.078, cos=0.002), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1200/2000] tot_loss=1.348 (perp=6.423, rec=0.061, cos=0.002), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.350 (perp=6.423, rec=0.064, cos=0.002), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.349 (perp=6.423, rec=0.063, cos=0.002), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1350/2000] tot_loss=1.341 (perp=6.423, rec=0.054, cos=0.002), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.350 (perp=6.423, rec=0.063, cos=0.002), tot_loss_proj:2.118 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.352 (perp=6.423, rec=0.066, cos=0.002), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1500/2000] tot_loss=1.347 (perp=6.423, rec=0.061, cos=0.002), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.346 (perp=6.423, rec=0.059, cos=0.002), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.346 (perp=6.423, rec=0.059, cos=0.002), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1650/2000] tot_loss=1.349 (perp=6.423, rec=0.063, cos=0.002), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.362 (perp=6.423, rec=0.076, cos=0.002), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.347 (perp=6.423, rec=0.060, cos=0.002), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1800/2000] tot_loss=1.357 (perp=6.423, rec=0.071, cos=0.002), tot_loss_proj:2.120 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.355 (perp=6.423, rec=0.069, cos=0.002), tot_loss_proj:2.117 [t=0.19s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.354 (perp=6.423, rec=0.068, cos=0.002), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
[1950/2000] tot_loss=1.353 (perp=6.423, rec=0.066, cos=0.002), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.353 (perp=6.423, rec=0.067, cos=0.002), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] at that point things explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] at that point things explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 93.873 | p: 93.550 | r: 94.320
rouge2     | fm: 62.772 | p: 62.738 | r: 62.799
rougeL     | fm: 81.458 | p: 81.295 | r: 81.713
rougeLsum  | fm: 81.437 | p: 81.194 | r: 81.666
r1fm+r2fm = 156.645

input #13 time: 0:09:04 | total time: 2:02:53


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9993219682705545
highest_index [0]
highest [0.9993219682705545]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9556125998497009 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9368494749069214 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9233089089393616 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9153460264205933 for ['[CLS] bar these catch arms state [SEP]']
[Init] best rec loss: 0.9128281474113464 for ['[CLS] models cordytness gun [SEP]']
[Init] best rec loss: 0.8928517699241638 for ['[CLS] return him always kolkata frame [SEP]']
[Init] best rec loss: 0.8734212517738342 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720963597297668 for ['[CLS] myers sprayed harold [MASK] tom [SEP]']
[Init] best perm rec loss: 0.8720387816429138 for ['[CLS] [MASK] harold sprayed tom myers [SEP]']
[Init] best perm rec loss: 0.8698037266731262 for ['[CLS] tom [MASK] harold myers sprayed [SEP]']
[Init] best perm rec loss: 0.8688009977340698 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.659 (perp=12.090, rec=0.237, cos=0.005), tot_loss_proj:2.776 [t=0.17s]
prediction: ['[CLS] intriguingbly genuinely film film [SEP]']
[ 100/2000] tot_loss=2.804 (perp=13.344, rec=0.133, cos=0.002), tot_loss_proj:3.716 [t=0.17s]
prediction: ['[CLS] intriguingblyenia film film [SEP]']
[ 150/2000] tot_loss=2.769 (perp=13.344, rec=0.098, cos=0.002), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] intriguingblyenia film film [SEP]']
[ 200/2000] tot_loss=2.762 (perp=13.344, rec=0.091, cos=0.002), tot_loss_proj:3.715 [t=0.17s]
prediction: ['[CLS] intriguingblyenia film film [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.897 (perp=8.954, rec=0.104, cos=0.002), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] intriguing filmeniably film [SEP]']
[ 300/2000] tot_loss=1.888 (perp=8.954, rec=0.095, cos=0.002), tot_loss_proj:2.134 [t=0.20s]
prediction: ['[CLS] intriguing filmeniably film [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.768 (perp=8.412, rec=0.084, cos=0.002), tot_loss_proj:1.873 [t=0.17s]
prediction: ['[CLS] filmeniably intriguing film [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.433 (perp=6.728, rec=0.086, cos=0.002), tot_loss_proj:1.409 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 450/2000] tot_loss=1.419 (perp=6.728, rec=0.072, cos=0.001), tot_loss_proj:1.411 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.415 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.416 (perp=6.728, rec=0.069, cos=0.001), tot_loss_proj:1.404 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.418 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.408 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.411 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.421 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.414 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.411 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.404 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.398 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.416 (perp=6.728, rec=0.069, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.405 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.414 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.411 [t=0.21s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.410 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.408 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.406 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.397 (perp=6.728, rec=0.050, cos=0.001), tot_loss_proj:1.406 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.411 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.408 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.420 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.418 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.412 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.413 (perp=6.728, rec=0.066, cos=0.001), tot_loss_proj:1.400 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.411 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.407 (perp=6.728, rec=0.060, cos=0.001), tot_loss_proj:1.411 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.408 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.412 [t=0.17s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.227 | p: 93.990 | r: 94.698
rouge2     | fm: 65.476 | p: 65.468 | r: 65.503
rougeL     | fm: 82.840 | p: 82.640 | r: 83.021
rougeLsum  | fm: 82.352 | p: 82.138 | r: 82.596
r1fm+r2fm = 159.704

input #14 time: 0:08:34 | total time: 2:11:28


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9992724874303516
highest_index [0]
highest [0.9992724874303516]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.9709395170211792 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.9276955127716064 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 0.9179652333259583 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.9067785143852234 for ['[CLS] society worth jobsuit brick winrained circuit [SEP]']
[Init] best rec loss: 0.9063056707382202 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8998844623565674 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8911759257316589 for ['[CLS]che carolezard multi zone rhythmic watervating [SEP]']
[Init] best rec loss: 0.8846814036369324 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8817172050476074 for ['[CLS] 0 humanities metaphor olivia easily fetch first sweden [SEP]']
[Init] best perm rec loss: 0.8800804018974304 for ['[CLS] easily first olivia metaphor fetch 0 humanities sweden [SEP]']
[Init] best perm rec loss: 0.879218578338623 for ['[CLS] easily sweden humanities first olivia 0 fetch metaphor [SEP]']
[Init] best perm rec loss: 0.879126250743866 for ['[CLS] easily sweden humanities 0 olivia first fetch metaphor [SEP]']
[Init] best perm rec loss: 0.8768956065177917 for ['[CLS] fetch humanities first 0 sweden olivia easily metaphor [SEP]']
[Init] best perm rec loss: 0.8764843344688416 for ['[CLS] 0 first humanities sweden olivia metaphor easily fetch [SEP]']
[Init] best perm rec loss: 0.8753165006637573 for ['[CLS] 0 sweden fetch metaphor humanities olivia first easily [SEP]']
[Init] best perm rec loss: 0.8751561641693115 for ['[CLS] metaphor 0 first humanities sweden olivia easily fetch [SEP]']
[Init] best perm rec loss: 0.8732092976570129 for ['[CLS] metaphor first sweden fetch 0 easily olivia humanities [SEP]']
[Init] best perm rec loss: 0.8722246885299683 for ['[CLS] first easily 0 sweden metaphor olivia humanities fetch [SEP]']
[Init] best perm rec loss: 0.8716493844985962 for ['[CLS] metaphor humanities first sweden olivia fetch easily 0 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.867 (perp=12.962, rec=0.265, cos=0.009), tot_loss_proj:3.551 [t=0.17s]
prediction: ['[CLS] solid intendedably efficient suit meet suit pink [SEP]']
[ 100/2000] tot_loss=2.739 (perp=12.664, rec=0.199, cos=0.007), tot_loss_proj:4.235 [t=0.17s]
prediction: ['[CLS] chill acceptableably efficienter chill suit chill [SEP]']
[ 150/2000] tot_loss=2.992 (perp=14.260, rec=0.134, cos=0.005), tot_loss_proj:4.612 [t=0.17s]
prediction: ['[CLS] chill anonymousably efficienter chill suit chill [SEP]']
[ 200/2000] tot_loss=2.897 (perp=13.852, rec=0.122, cos=0.004), tot_loss_proj:4.415 [t=0.17s]
prediction: ['[CLS]stein anonymousably efficienter chill suit chill [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.223 (perp=10.534, rec=0.112, cos=0.004), tot_loss_proj:2.824 [t=0.17s]
prediction: ['[CLS]. anonymousably efficient chill chill suiter [SEP]']
[ 300/2000] tot_loss=2.194 (perp=10.534, rec=0.085, cos=0.002), tot_loss_proj:2.807 [t=0.17s]
prediction: ['[CLS]. anonymousably efficient chill chill suiter [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.050 (perp=9.824, rec=0.083, cos=0.002), tot_loss_proj:2.698 [t=0.17s]
prediction: ['[CLS]. anonymousably efficient chill chiller suit [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.799 (perp=8.483, rec=0.100, cos=0.003), tot_loss_proj:2.380 [t=0.17s]
prediction: ['[CLS]. anonymous suitably efficient anonymous chiller [SEP]']
[ 450/2000] tot_loss=1.777 (perp=8.483, rec=0.079, cos=0.002), tot_loss_proj:2.375 [t=0.17s]
prediction: ['[CLS]. anonymous suitably efficient anonymous chiller [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.779 (perp=8.483, rec=0.080, cos=0.002), tot_loss_proj:2.452 [t=0.26s]
prediction: ['[CLS]. anonymous suitably efficient anonymous chiller [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.659 (perp=7.817, rec=0.094, cos=0.002), tot_loss_proj:1.990 [t=0.17s]
prediction: ['[CLS] anonymous suitably efficient, anonymous chiller [SEP]']
[ 600/2000] tot_loss=1.656 (perp=7.817, rec=0.091, cos=0.002), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] anonymous suitably efficient, anonymous chiller [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.626 (perp=7.676, rec=0.089, cos=0.002), tot_loss_proj:1.771 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.613 (perp=7.676, rec=0.076, cos=0.002), tot_loss_proj:1.781 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[ 750/2000] tot_loss=1.613 (perp=7.676, rec=0.076, cos=0.002), tot_loss_proj:1.770 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.653 (perp=7.910, rec=0.069, cos=0.002), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] suitably efficient,. anonymous chiller [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.615 (perp=7.676, rec=0.078, cos=0.002), tot_loss_proj:1.782 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[ 900/2000] tot_loss=1.608 (perp=7.676, rec=0.071, cos=0.002), tot_loss_proj:1.780 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.617 (perp=7.676, rec=0.080, cos=0.002), tot_loss_proj:1.766 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[1000/2000] tot_loss=1.616 (perp=7.676, rec=0.079, cos=0.002), tot_loss_proj:1.777 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[1050/2000] tot_loss=1.618 (perp=7.676, rec=0.081, cos=0.002), tot_loss_proj:1.774 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[1100/2000] tot_loss=1.612 (perp=7.676, rec=0.075, cos=0.002), tot_loss_proj:1.778 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.608 (perp=7.676, rec=0.071, cos=0.002), tot_loss_proj:1.776 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[1200/2000] tot_loss=1.604 (perp=7.676, rec=0.067, cos=0.002), tot_loss_proj:1.777 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.613 (perp=7.676, rec=0.076, cos=0.002), tot_loss_proj:1.779 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[1300/2000] tot_loss=1.619 (perp=7.676, rec=0.082, cos=0.002), tot_loss_proj:1.770 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[1350/2000] tot_loss=1.622 (perp=7.676, rec=0.085, cos=0.002), tot_loss_proj:1.775 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.606 (perp=7.676, rec=0.069, cos=0.002), tot_loss_proj:1.778 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[1450/2000] tot_loss=1.616 (perp=7.676, rec=0.079, cos=0.002), tot_loss_proj:1.768 [t=0.19s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[1500/2000] tot_loss=1.613 (perp=7.676, rec=0.076, cos=0.002), tot_loss_proj:1.779 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.615 (perp=7.676, rec=0.078, cos=0.002), tot_loss_proj:1.766 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
[1600/2000] tot_loss=1.605 (perp=7.676, rec=0.068, cos=0.002), tot_loss_proj:1.772 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[1650/2000] tot_loss=1.613 (perp=7.676, rec=0.076, cos=0.002), tot_loss_proj:1.776 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.613 (perp=7.676, rec=0.076, cos=0.002), tot_loss_proj:1.767 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.624 (perp=7.676, rec=0.087, cos=0.002), tot_loss_proj:1.772 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
[1800/2000] tot_loss=1.605 (perp=7.676, rec=0.068, cos=0.002), tot_loss_proj:1.766 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.615 (perp=7.676, rec=0.078, cos=0.002), tot_loss_proj:1.775 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous anonymous chiller [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.840 (perp=8.790, rec=0.081, cos=0.002), tot_loss_proj:2.023 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller ・ [SEP]']
[1950/2000] tot_loss=1.845 (perp=8.790, rec=0.085, cos=0.002), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller ・ [SEP]']
Attempt swap
[2000/2000] tot_loss=1.417 (perp=6.697, rec=0.075, cos=0.002), tot_loss_proj:1.514 [t=0.17s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous anonymous chiller [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 128.671

[Aggregate metrics]:
rouge1     | fm: 94.247 | p: 93.482 | r: 95.060
rouge2     | fm: 63.522 | p: 63.237 | r: 63.806
rougeL     | fm: 82.386 | p: 81.923 | r: 82.982
rougeLsum  | fm: 82.171 | p: 81.626 | r: 82.738
r1fm+r2fm = 157.769

input #15 time: 0:09:12 | total time: 2:20:41


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9993411698074052
highest_index [0]
highest [0.9993411698074052]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.018147349357605 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.9020346403121948 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7366529107093811 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best perm rec loss: 0.7362502217292786 for ['[CLS]athi alta lord film slowly various [SEP]']
[Init] best perm rec loss: 0.7362011075019836 for ['[CLS] lord slowly film variousathi alta [SEP]']
[Init] best perm rec loss: 0.7361390590667725 for ['[CLS] various slowly film lordathi alta [SEP]']
[Init] best perm rec loss: 0.7351789474487305 for ['[CLS]athi alta lord slowly various film [SEP]']
[Init] best perm rec loss: 0.7351776957511902 for ['[CLS] various film lord slowlyathi alta [SEP]']
[Init] best perm rec loss: 0.7336527705192566 for ['[CLS] various film lord slowly altaathi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.419 (perp=12.256, rec=0.595, cos=0.373), tot_loss_proj:4.073 [t=0.17s]
prediction: ['[CLS] rope up bedroom christmas county you [SEP]']
[ 100/2000] tot_loss=3.224 (perp=12.711, rec=0.478, cos=0.204), tot_loss_proj:3.976 [t=0.17s]
prediction: ['[CLS] rope up latest christmas county you [SEP]']
[ 150/2000] tot_loss=2.611 (perp=10.619, rec=0.400, cos=0.087), tot_loss_proj:3.563 [t=0.17s]
prediction: ['[CLS] brian all data christmas more everything [SEP]']
[ 200/2000] tot_loss=2.283 (perp=9.583, rec=0.320, cos=0.046), tot_loss_proj:3.169 [t=0.17s]
prediction: ['[CLS] her all data christmas more that [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.129 (perp=9.157, rec=0.261, cos=0.036), tot_loss_proj:3.330 [t=0.17s]
prediction: ['[CLS] her all this christmas more data [SEP]']
[ 300/2000] tot_loss=1.880 (perp=8.148, rec=0.219, cos=0.031), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS] her all this christmas of data [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.662 (perp=7.109, rec=0.211, cos=0.030), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] all this and of her data [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.425 (perp=5.964, rec=0.202, cos=0.030), tot_loss_proj:2.546 [t=0.17s]
prediction: ['[CLS] this and all of her data [SEP]']
[ 450/2000] tot_loss=1.518 (perp=6.508, rec=0.190, cos=0.026), tot_loss_proj:2.158 [t=0.17s]
prediction: ['[CLS] this and all of more later [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.342 (perp=5.640, rec=0.187, cos=0.027), tot_loss_proj:1.946 [t=0.17s]
prediction: ['[CLS] all of this and more later [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.328 (perp=5.640, rec=0.175, cos=0.025), tot_loss_proj:1.952 [t=0.17s]
prediction: ['[CLS] all of this and more later [SEP]']
[ 600/2000] tot_loss=1.329 (perp=5.640, rec=0.176, cos=0.024), tot_loss_proj:1.948 [t=0.17s]
prediction: ['[CLS] all of this and more later [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.325 (perp=5.640, rec=0.173, cos=0.024), tot_loss_proj:1.948 [t=0.17s]
prediction: ['[CLS] all of this and more later [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.439 (perp=6.243, rec=0.167, cos=0.023), tot_loss_proj:2.289 [t=0.17s]
prediction: ['[CLS] all of this coming and more [SEP]']
[ 750/2000] tot_loss=1.438 (perp=6.243, rec=0.166, cos=0.023), tot_loss_proj:2.287 [t=0.17s]
prediction: ['[CLS] all of this coming and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.438 (perp=6.243, rec=0.168, cos=0.022), tot_loss_proj:2.291 [t=0.17s]
prediction: ['[CLS] all of this coming and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.433 (perp=6.243, rec=0.163, cos=0.021), tot_loss_proj:2.291 [t=0.17s]
prediction: ['[CLS] all of this coming and more [SEP]']
[ 900/2000] tot_loss=1.437 (perp=6.243, rec=0.167, cos=0.021), tot_loss_proj:2.287 [t=0.17s]
prediction: ['[CLS] all of this coming and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.430 (perp=6.243, rec=0.161, cos=0.020), tot_loss_proj:2.291 [t=0.17s]
prediction: ['[CLS] all of this coming and more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.339 (perp=5.770, rec=0.165, cos=0.020), tot_loss_proj:2.243 [t=0.17s]
prediction: ['[CLS] all of this better and more [SEP]']
[1050/2000] tot_loss=1.333 (perp=5.770, rec=0.160, cos=0.019), tot_loss_proj:2.242 [t=0.17s]
prediction: ['[CLS] all of this better and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.187 (perp=5.084, rec=0.151, cos=0.019), tot_loss_proj:2.065 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.192 (perp=5.084, rec=0.156, cos=0.019), tot_loss_proj:2.065 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
[1200/2000] tot_loss=1.191 (perp=5.084, rec=0.156, cos=0.018), tot_loss_proj:2.061 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.188 (perp=5.084, rec=0.153, cos=0.018), tot_loss_proj:2.062 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.191 (perp=5.084, rec=0.157, cos=0.018), tot_loss_proj:2.065 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
[1350/2000] tot_loss=1.177 (perp=5.084, rec=0.143, cos=0.017), tot_loss_proj:2.064 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.184 (perp=5.084, rec=0.150, cos=0.017), tot_loss_proj:2.066 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.192 (perp=5.084, rec=0.159, cos=0.017), tot_loss_proj:2.063 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
[1500/2000] tot_loss=1.174 (perp=5.084, rec=0.141, cos=0.016), tot_loss_proj:2.069 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.170 (perp=5.084, rec=0.138, cos=0.015), tot_loss_proj:2.059 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.178 (perp=5.084, rec=0.146, cos=0.015), tot_loss_proj:2.063 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
[1650/2000] tot_loss=1.184 (perp=5.084, rec=0.153, cos=0.015), tot_loss_proj:2.058 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.172 (perp=5.084, rec=0.141, cos=0.014), tot_loss_proj:2.066 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.174 (perp=5.084, rec=0.143, cos=0.014), tot_loss_proj:2.063 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
[1800/2000] tot_loss=1.169 (perp=5.084, rec=0.139, cos=0.014), tot_loss_proj:2.069 [t=0.21s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.172 (perp=5.084, rec=0.142, cos=0.013), tot_loss_proj:2.058 [t=0.21s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.164 (perp=5.084, rec=0.134, cos=0.013), tot_loss_proj:2.068 [t=0.22s]
prediction: ['[CLS] all of this more and more [SEP]']
[1950/2000] tot_loss=1.168 (perp=5.084, rec=0.138, cos=0.013), tot_loss_proj:2.062 [t=0.21s]
prediction: ['[CLS] all of this more and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.168 (perp=5.084, rec=0.138, cos=0.013), tot_loss_proj:2.060 [t=0.17s]
prediction: ['[CLS] all of this more and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this more and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 87.500 | r: 100.000
rouge2     | fm: 76.923 | p: 71.429 | r: 83.333
rougeL     | fm: 93.333 | p: 87.500 | r: 100.000
rougeLsum  | fm: 93.333 | p: 87.500 | r: 100.000
r1fm+r2fm = 170.256

[Aggregate metrics]:
rouge1     | fm: 94.060 | p: 93.023 | r: 95.210
rouge2     | fm: 64.761 | p: 64.125 | r: 65.369
rougeL     | fm: 83.352 | p: 82.441 | r: 84.294
rougeLsum  | fm: 83.004 | p: 82.045 | r: 83.987
r1fm+r2fm = 158.820

input #16 time: 0:09:19 | total time: 2:30:00


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9992301552937229
highest_index [0]
highest [0.9992301552937229]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8486641645431519 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8205068111419678 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.8189647197723389 for ['[CLS] santa bourneity church jacence move nativeburnub early [SEP]']
[Init] best rec loss: 0.8072818517684937 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 0.7922393679618835 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 0.7693865895271301 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 0.7615459561347961 for ['[CLS] lieutenant magazineuin miss grey marius honestly pressure saved meeting i [SEP]']
[Init] best perm rec loss: 0.7598406076431274 for ['[CLS] meeting marius miss pressure greyuin i magazine saved lieutenant honestly [SEP]']
[Init] best perm rec loss: 0.7584831714630127 for ['[CLS] marius missuin lieutenant grey magazine honestly i saved meeting pressure [SEP]']
[Init] best perm rec loss: 0.7562015652656555 for ['[CLS] pressure marius honestly magazine saved meeting grey lieutenant iuin miss [SEP]']
[Init] best perm rec loss: 0.7561701536178589 for ['[CLS] i pressure marius lieutenant magazine miss greyuin meeting saved honestly [SEP]']
[Init] best perm rec loss: 0.7556576132774353 for ['[CLS]uin lieutenant honestly i pressure marius miss meeting grey saved magazine [SEP]']
[Init] best perm rec loss: 0.7535409927368164 for ['[CLS] i meetinguin pressure honestly magazine grey lieutenant marius saved miss [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.990 (perp=12.291, rec=0.402, cos=0.131), tot_loss_proj:3.878 [t=0.20s]
prediction: ['[CLS] too brain drawer case covered were problem put want bleak disappearance [SEP]']
[ 100/2000] tot_loss=2.441 (perp=11.111, rec=0.195, cos=0.024), tot_loss_proj:3.309 [t=0.19s]
prediction: ['[CLS] too much hitter too again much s about want think much [SEP]']
[ 150/2000] tot_loss=2.114 (perp=9.870, rec=0.132, cos=0.008), tot_loss_proj:3.006 [t=0.17s]
prediction: ['[CLS] too much enough too around much what about want think think [SEP]']
[ 200/2000] tot_loss=2.071 (perp=9.863, rec=0.095, cos=0.004), tot_loss_proj:2.892 [t=0.17s]
prediction: ['[CLS] too much on too going much what about want think think [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.865 (perp=8.718, rec=0.115, cos=0.006), tot_loss_proj:2.809 [t=0.17s]
prediction: ['[CLS] too much going to going much what about want on think [SEP]']
[ 300/2000] tot_loss=1.836 (perp=8.718, rec=0.089, cos=0.003), tot_loss_proj:2.818 [t=0.17s]
prediction: ['[CLS] too much going to going much what about want on think [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.618 (perp=7.648, rec=0.086, cos=0.003), tot_loss_proj:2.648 [t=0.17s]
prediction: ['[CLS] too much going to going much think about want on what [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.701 (perp=8.053, rec=0.085, cos=0.005), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] too what going on going much think about want to what [SEP]']
[ 450/2000] tot_loss=1.695 (perp=8.053, rec=0.082, cos=0.003), tot_loss_proj:3.333 [t=0.17s]
prediction: ['[CLS] too what going on going much think about want to what [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.560 (perp=7.418, rec=0.074, cos=0.002), tot_loss_proj:3.188 [t=0.17s]
prediction: ['[CLS] too what going on going much think about what to want [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.424 (perp=6.645, rec=0.091, cos=0.004), tot_loss_proj:2.213 [t=0.17s]
prediction: ['[CLS] too much think about what going on going s to want [SEP]']
[ 600/2000] tot_loss=1.516 (perp=7.189, rec=0.076, cos=0.002), tot_loss_proj:2.324 [t=0.17s]
prediction: ['[CLS] too much think about what to on going s to want [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.296 (perp=6.040, rec=0.086, cos=0.002), tot_loss_proj:2.033 [t=0.17s]
prediction: ['[CLS] too much think about what going on to s to want [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.204 (perp=5.666, rec=0.069, cos=0.002), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS] too much think about what going on to want to s [SEP]']
[ 750/2000] tot_loss=1.195 (perp=5.666, rec=0.060, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] too much think about what going on to want to s [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.125 (perp=5.262, rec=0.071, cos=0.002), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] too much think about what s going on to want to [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.134 (perp=5.262, rec=0.080, cos=0.002), tot_loss_proj:1.828 [t=0.18s]
prediction: ['[CLS] too much think about what s going on to want to [SEP]']
[ 900/2000] tot_loss=1.120 (perp=5.262, rec=0.066, cos=0.002), tot_loss_proj:1.836 [t=0.19s]
prediction: ['[CLS] too much think about what s going on to want to [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.121 (perp=5.262, rec=0.067, cos=0.002), tot_loss_proj:1.835 [t=0.17s]
prediction: ['[CLS] too much think about what s going on to want to [SEP]']
Attempt swap
[1000/2000] tot_loss=1.121 (perp=5.262, rec=0.067, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] too much think about what s going on to want to [SEP]']
[1050/2000] tot_loss=1.127 (perp=5.262, rec=0.073, cos=0.002), tot_loss_proj:1.831 [t=0.17s]
prediction: ['[CLS] too much think about what s going on to want to [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.023 (perp=4.762, rec=0.069, cos=0.002), tot_loss_proj:1.865 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1150/2000] tot_loss=1.023 (perp=4.762, rec=0.069, cos=0.002), tot_loss_proj:1.860 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
[1200/2000] tot_loss=1.025 (perp=4.762, rec=0.071, cos=0.002), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1250/2000] tot_loss=1.015 (perp=4.762, rec=0.061, cos=0.002), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1300/2000] tot_loss=1.019 (perp=4.762, rec=0.065, cos=0.002), tot_loss_proj:1.865 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
[1350/2000] tot_loss=1.017 (perp=4.762, rec=0.063, cos=0.002), tot_loss_proj:1.863 [t=0.19s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1400/2000] tot_loss=1.024 (perp=4.762, rec=0.070, cos=0.002), tot_loss_proj:1.861 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1450/2000] tot_loss=1.019 (perp=4.762, rec=0.065, cos=0.002), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
[1500/2000] tot_loss=1.028 (perp=4.762, rec=0.074, cos=0.002), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1550/2000] tot_loss=1.021 (perp=4.762, rec=0.067, cos=0.002), tot_loss_proj:1.865 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1600/2000] tot_loss=1.026 (perp=4.762, rec=0.072, cos=0.002), tot_loss_proj:1.866 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
[1650/2000] tot_loss=1.015 (perp=4.762, rec=0.061, cos=0.002), tot_loss_proj:1.859 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1700/2000] tot_loss=1.016 (perp=4.762, rec=0.062, cos=0.002), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1750/2000] tot_loss=1.020 (perp=4.762, rec=0.066, cos=0.002), tot_loss_proj:1.861 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
[1800/2000] tot_loss=1.008 (perp=4.762, rec=0.054, cos=0.002), tot_loss_proj:1.862 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1850/2000] tot_loss=1.025 (perp=4.762, rec=0.071, cos=0.002), tot_loss_proj:1.862 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[1900/2000] tot_loss=1.011 (perp=4.762, rec=0.057, cos=0.002), tot_loss_proj:1.867 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
[1950/2000] tot_loss=1.009 (perp=4.762, rec=0.055, cos=0.002), tot_loss_proj:1.868 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Attempt swap
[2000/2000] tot_loss=1.013 (perp=4.762, rec=0.059, cos=0.002), tot_loss_proj:1.862 [t=0.17s]
prediction: ['[CLS] too much to think about what s going on to want [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] too much to think about what s going on to want [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 52.174 | p: 50.000 | r: 54.545
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 148.174

[Aggregate metrics]:
rouge1     | fm: 94.139 | p: 92.908 | r: 95.397
rouge2     | fm: 63.586 | p: 62.903 | r: 64.374
rougeL     | fm: 82.770 | p: 81.784 | r: 83.782
rougeLsum  | fm: 82.459 | p: 81.416 | r: 83.489
r1fm+r2fm = 157.724

input #17 time: 0:08:34 | total time: 2:38:35


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9993194147820215
highest_index [0]
highest [0.9993194147820215]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 0.9796279072761536 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9423751831054688 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9344695806503296 for ['[CLS] deportivo suspect usual aston [SEP]']
[Init] best rec loss: 0.9258310198783875 for ['[CLS] water global accreditation originally [SEP]']
[Init] best rec loss: 0.8895648717880249 for ['[CLS] press lose hunger tracks [SEP]']
[Init] best rec loss: 0.8812242150306702 for ['[CLS] affectionately character hundreds team [SEP]']
[Init] best rec loss: 0.869970977306366 for ['[CLS] oniest α department [SEP]']
[Init] best rec loss: 0.8667334318161011 for ['[CLS] middle away mc reserves [SEP]']
[Init] best rec loss: 0.8235080242156982 for ['[CLS] dual circle duodle [SEP]']
[Init] best perm rec loss: 0.8209102153778076 for ['[CLS]odle circle du dual [SEP]']
[Init] best perm rec loss: 0.8185354471206665 for ['[CLS] dual duodle circle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.090 (perp=9.278, rec=0.231, cos=0.004), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS]vigoratingating [SEP]']
[ 100/2000] tot_loss=2.350 (perp=10.971, rec=0.153, cos=0.003), tot_loss_proj:2.702 [t=0.17s]
prediction: ['[CLS]vigorgorating [SEP]']
[ 150/2000] tot_loss=2.294 (perp=10.971, rec=0.098, cos=0.002), tot_loss_proj:2.735 [t=0.17s]
prediction: ['[CLS]vigorgorating [SEP]']
[ 200/2000] tot_loss=1.942 (perp=9.401, rec=0.061, cos=0.001), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS]vi ingorating [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.184 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.180 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.177 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.187 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.175 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.184 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.169 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.184 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.190 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.167 (perp=5.588, rec=0.048, cos=0.001), tot_loss_proj:1.184 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.175 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.180 (perp=5.588, rec=0.061, cos=0.001), tot_loss_proj:1.182 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.174 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.173 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.185 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.185 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.197 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.176 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.190 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.177 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.175 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.181 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.177 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.187 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.179 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.179 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.182 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.188 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.187 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.170 (perp=5.588, rec=0.051, cos=0.001), tot_loss_proj:1.188 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.169 (perp=5.588, rec=0.050, cos=0.001), tot_loss_proj:1.184 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.189 (perp=5.588, rec=0.070, cos=0.001), tot_loss_proj:1.183 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.177 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.175 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.182 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.171 (perp=5.588, rec=0.052, cos=0.001), tot_loss_proj:1.177 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.171 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.180 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.512 | p: 93.386 | r: 95.639
rouge2     | fm: 65.692 | p: 65.107 | r: 66.393
rougeL     | fm: 83.439 | p: 82.619 | r: 84.420
rougeLsum  | fm: 83.328 | p: 82.387 | r: 84.279
r1fm+r2fm = 160.204

input #18 time: 0:07:31 | total time: 2:46:06


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9993635209107408
highest_index [0]
highest [0.9993635209107408]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7703872323036194 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.7632964253425598 for ['[CLS] scout pitch huge teaching [SEP]']
[Init] best rec loss: 0.7431591749191284 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7254143357276917 for ['[CLS] target jessica episode ling [SEP]']
[Init] best rec loss: 0.7071809768676758 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 0.7017049789428711 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.688244640827179 for ['[CLS] centers recordtion difficult [SEP]']
[Init] best rec loss: 0.680355966091156 for ['[CLS]lving different sign ins [SEP]']
[Init] best rec loss: 0.6743445992469788 for ['[CLS] intra raf soviet events [SEP]']
[Init] best rec loss: 0.6420117020606995 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6395600438117981 for ['[CLS] reaching pin orderyna [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.927 (perp=12.311, rec=0.362, cos=0.102), tot_loss_proj:3.739 [t=0.17s]
prediction: ['[CLS] alley education violent in [SEP]']
[ 100/2000] tot_loss=2.668 (perp=12.367, rec=0.184, cos=0.011), tot_loss_proj:3.833 [t=0.17s]
prediction: ['[CLS]mymy tofa [SEP]']
[ 150/2000] tot_loss=2.587 (perp=12.367, rec=0.111, cos=0.003), tot_loss_proj:3.859 [t=0.17s]
prediction: ['[CLS]mymy tofa [SEP]']
[ 200/2000] tot_loss=2.492 (perp=11.902, rec=0.097, cos=0.014), tot_loss_proj:3.998 [t=0.17s]
prediction: ['[CLS] inmy tofa [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.382 (perp=6.522, rec=0.074, cos=0.004), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] infamy to [SEP]']
[ 300/2000] tot_loss=1.371 (perp=6.522, rec=0.066, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] infamy to [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.296 (perp=6.110, rec=0.073, cos=0.001), tot_loss_proj:1.300 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.297 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.282 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.311 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.287 (perp=6.110, rec=0.064, cos=0.001), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.301 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.290 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.303 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.271 (perp=6.110, rec=0.048, cos=0.001), tot_loss_proj:1.301 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.291 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.295 (perp=6.110, rec=0.072, cos=0.001), tot_loss_proj:1.297 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.283 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.296 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.272 (perp=6.110, rec=0.049, cos=0.001), tot_loss_proj:1.304 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.290 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.281 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.298 (perp=6.110, rec=0.075, cos=0.001), tot_loss_proj:1.304 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.285 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.270 (perp=6.110, rec=0.047, cos=0.001), tot_loss_proj:1.311 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.286 (perp=6.110, rec=0.063, cos=0.001), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.276 (perp=6.110, rec=0.053, cos=0.001), tot_loss_proj:1.293 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.306 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.300 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.281 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.301 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.297 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.283 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.301 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.292 (perp=6.110, rec=0.068, cos=0.001), tot_loss_proj:1.315 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.289 (perp=6.110, rec=0.066, cos=0.001), tot_loss_proj:1.300 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.307 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.271 (perp=6.110, rec=0.047, cos=0.001), tot_loss_proj:1.290 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.279 (perp=6.110, rec=0.055, cos=0.001), tot_loss_proj:1.310 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.277 (perp=6.110, rec=0.053, cos=0.001), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.281 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.286 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 94.685 | p: 93.608 | r: 95.857
rouge2     | fm: 67.129 | p: 66.652 | r: 67.794
rougeL     | fm: 84.392 | p: 83.582 | r: 85.332
rougeLsum  | fm: 84.171 | p: 83.323 | r: 85.140
r1fm+r2fm = 161.814

input #19 time: 0:07:26 | total time: 2:53:33


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9992466071766843
highest_index [0]
highest [0.9992466071766843]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.813522219657898 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8018914461135864 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7928059697151184 for ['[CLS] york match causearu [SEP]']
[Init] best rec loss: 0.7927916049957275 for ['[CLS] airport exists internationally role [SEP]']
[Init] best rec loss: 0.7916965484619141 for ['[CLS] glad home gentlemanboard [SEP]']
[Init] best rec loss: 0.765182614326477 for ['[CLS] poorpid african forming [SEP]']
[Init] best perm rec loss: 0.7627440690994263 for ['[CLS]pid poor forming african [SEP]']
[Init] best perm rec loss: 0.7611280083656311 for ['[CLS] african poor formingpid [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.753 (perp=11.724, rec=0.349, cos=0.060), tot_loss_proj:3.702 [t=0.17s]
prediction: ['[CLS]verse [ pleasureverse [SEP]']
[ 100/2000] tot_loss=2.635 (perp=11.845, rec=0.235, cos=0.031), tot_loss_proj:4.078 [t=0.17s]
prediction: ['[CLS]verse her pleasureverse [SEP]']
[ 150/2000] tot_loss=2.425 (perp=10.923, rec=0.207, cos=0.033), tot_loss_proj:3.612 [t=0.17s]
prediction: ['[CLS]verse per pleasureverse [SEP]']
[ 200/2000] tot_loss=2.310 (perp=10.783, rec=0.139, cos=0.015), tot_loss_proj:3.313 [t=0.17s]
prediction: ['[CLS]verse the pleasure per [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.706 (perp=7.784, rec=0.137, cos=0.012), tot_loss_proj:1.931 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
[ 300/2000] tot_loss=1.657 (perp=7.784, rec=0.096, cos=0.004), tot_loss_proj:1.948 [t=0.17s]
prediction: ['[CLS] the pleasure perverse [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.606 (perp=7.610, rec=0.082, cos=0.002), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.600 (perp=7.610, rec=0.076, cos=0.002), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 450/2000] tot_loss=1.595 (perp=7.610, rec=0.072, cos=0.002), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.610 (perp=7.610, rec=0.086, cos=0.002), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 600/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.587 (perp=7.610, rec=0.063, cos=0.002), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.590 (perp=7.610, rec=0.066, cos=0.002), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.593 (perp=7.610, rec=0.069, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.594 (perp=7.610, rec=0.071, cos=0.002), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.592 (perp=7.610, rec=0.068, cos=0.002), tot_loss_proj:1.747 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.731 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.578 (perp=7.610, rec=0.054, cos=0.002), tot_loss_proj:1.741 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.598 (perp=7.610, rec=0.074, cos=0.002), tot_loss_proj:1.729 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.587 (perp=7.610, rec=0.063, cos=0.002), tot_loss_proj:1.734 [t=0.20s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.728 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.587 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.731 [t=0.20s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.580 (perp=7.610, rec=0.056, cos=0.002), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.736 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.580 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.733 [t=0.22s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.585 (perp=7.610, rec=0.061, cos=0.002), tot_loss_proj:1.737 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.598 (perp=7.610, rec=0.075, cos=0.002), tot_loss_proj:1.725 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.581 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.575 (perp=7.610, rec=0.052, cos=0.002), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.577 (perp=7.610, rec=0.053, cos=0.002), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.597 (perp=7.610, rec=0.074, cos=0.002), tot_loss_proj:1.731 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.593 (perp=7.610, rec=0.070, cos=0.002), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.579 (perp=7.610, rec=0.055, cos=0.002), tot_loss_proj:1.724 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.583 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.729 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.573 (perp=7.610, rec=0.049, cos=0.002), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.583 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.721 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.582 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.002 | p: 93.972 | r: 96.168
rouge2     | fm: 68.947 | p: 68.433 | r: 69.626
rougeL     | fm: 85.228 | p: 84.301 | r: 86.134
rougeLsum  | fm: 84.836 | p: 84.038 | r: 85.732
r1fm+r2fm = 163.950

input #20 time: 0:08:04 | total time: 3:01:37


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.999323347023505
highest_index [0]
highest [0.999323347023505]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.9415550231933594 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.881145179271698 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8719595670700073 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 0.8715744018554688 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.8490786552429199 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.8239164352416992 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best rec loss: 0.820530891418457 for ['[CLS]westock displays lock [MASK] peg potatoes precious sarajevo tomorrow gingerhis offers extension recently part lake pena comedy punjabhraors hardware alabama chemical [SEP]']
[Init] best rec loss: 0.8185598850250244 for ['[CLS] chamber firm returnfying evidence commission clear sq extra above episodeoom [SEP] brows ashland odd viva range surgical waters village right daddy speed jin [SEP]']
[Init] best perm rec loss: 0.8150901794433594 for ['[CLS] jin [SEP] brows return clear firm ashland evidence villageoom daddy speed extra sq chamberfying above odd episode viva surgical commission right range waters [SEP]']
[Init] best perm rec loss: 0.8130291700363159 for ['[CLS] daddy odd range surgical firm chamber jinoom [SEP] above viva extra brows speed ashland clear episode evidence returnfying sq village waters right commission [SEP]']
[Init] best perm rec loss: 0.8112152814865112 for ['[CLS] extra brows odd speedoom commission daddy range clear surgical evidence firm episode [SEP] viva waters above returnfying village jin ashland right chamber sq [SEP]']
[Init] best perm rec loss: 0.8100186586380005 for ['[CLS] right evidence ashland extra range speed return odd surgical episodeoom commissionfying viva [SEP] daddy brows jin waters sq village above firm chamber clear [SEP]']
[Init] best perm rec loss: 0.8091968297958374 for ['[CLS] speed evidenceoom extra commission return ashland chamber firm daddy episodefying right jin brows [SEP] above village clear viva sq surgical odd range waters [SEP]']
[Init] best perm rec loss: 0.8089424967765808 for ['[CLS] surgical sq odd return vivafying browsoom village [SEP] jin chamber firm clear daddy range ashland waters extra above commission evidence speed right episode [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.534 (perp=10.915, rec=0.330, cos=0.021), tot_loss_proj:3.203 [t=0.17s]
prediction: ['[CLS] women another least reduced bribe drills caused rather worker workers looks teamsus de accordingp poster continue crimes. until. a a system [SEP]']
[ 100/2000] tot_loss=2.611 (perp=11.722, rec=0.253, cos=0.013), tot_loss_proj:3.876 [t=0.17s]
prediction: ['[CLS] women this outs better situation athletes makestypical really beat looks different independent de moral lines instead instead leads is ultimately. only the crisis [SEP]']
[ 150/2000] tot_loss=2.536 (perp=11.373, rec=0.242, cos=0.020), tot_loss_proj:3.340 [t=0.17s]
prediction: ['[CLS] women thisiating more situation athletes makestypical really more lookara into viable caretaker out instead insteadses is way. only serious teachers [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.315, rec=0.193, cos=0.007), tot_loss_proj:3.347 [t=0.17s]
prediction: ['[CLS] women this out works way athletes makestypical look people look work into commonly caretaker works instead caretaker wrong is just. only serious teachers [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.202 (perp=9.981, rec=0.198, cos=0.008), tot_loss_proj:3.624 [t=0.17s]
prediction: ['[CLS] women this out works way athletes makestypical more people look work into caretaker works instead caretaker competitions how just. allows like serious teachers [SEP]']
[ 300/2000] tot_loss=2.196 (perp=10.164, rec=0.157, cos=0.006), tot_loss_proj:3.867 [t=0.17s]
prediction: ['[CLS] women this out all out athletes makestypical more less look work into caretaker works instead caretaker moral way way. allows like serious teachers [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.139 (perp=9.944, rec=0.145, cos=0.006), tot_loss_proj:3.261 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes more alone look stereo out caretaker works instead caretaker moral way way. the like serious teachers [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.896 (perp=8.880, rec=0.116, cos=0.004), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes more. look stereotypical caretaker works instead the caretaker moral way just, like serious teachers [SEP]']
[ 450/2000] tot_loss=1.886 (perp=8.880, rec=0.106, cos=0.004), tot_loss_proj:2.883 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes more. look stereotypical caretaker works instead the caretaker moral way just, like serious teachers [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.820 (perp=8.557, rec=0.104, cos=0.005), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes more look stereotypical. caretaker works instead the caretaker moral way if, like serious teachers [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.774 (perp=8.342, rec=0.102, cos=0.004), tot_loss_proj:2.562 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes look more stereotypical. caretaker works instead the caretaker moral way if, like serious teachers [SEP]']
[ 600/2000] tot_loss=1.768 (perp=8.342, rec=0.095, cos=0.004), tot_loss_proj:2.559 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes look more stereotypical. caretaker works instead the caretaker moral way if, like serious teachers [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.740 (perp=8.230, rec=0.091, cos=0.004), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes look more stereotypical. caretaker works instead the caretaker moral way, if like serious teachers [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.710 (perp=8.026, rec=0.101, cos=0.004), tot_loss_proj:2.379 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes look more stereotypical. caretaker works instead the way caretaker moral, if like serious teachers [SEP]']
[ 750/2000] tot_loss=1.713 (perp=8.026, rec=0.104, cos=0.004), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes look more stereotypical. caretaker works instead the way caretaker moral, if like serious teachers [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.644 (perp=7.774, rec=0.086, cos=0.004), tot_loss_proj:2.365 [t=0.17s]
prediction: ['[CLS]typical women this way all out athletes makes look more stereotypical. caretaker works instead the way serious moral, if like caretaker teachers [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.615 (perp=7.589, rec=0.094, cos=0.003), tot_loss_proj:2.275 [t=0.25s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereotypical. caretaker works instead the way serious moral, if like caretaker teachers [SEP]']
[ 900/2000] tot_loss=1.717 (perp=8.099, rec=0.094, cos=0.003), tot_loss_proj:2.397 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo and. caretaker works instead the way serious moral, if like caretaker teachers [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.817 (perp=8.599, rec=0.094, cos=0.003), tot_loss_proj:2.472 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo disciples and caretaker works instead the way serious moral, if like caretaker teachers [SEP]']
Attempt swap
[1000/2000] tot_loss=1.814 (perp=8.599, rec=0.091, cos=0.004), tot_loss_proj:2.466 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo disciples and caretaker works instead the way serious moral, if like caretaker teachers [SEP]']
[1050/2000] tot_loss=1.818 (perp=8.599, rec=0.095, cos=0.003), tot_loss_proj:2.473 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo disciples and caretaker works instead the way serious moral, if like caretaker teachers [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.785 (perp=8.452, rec=0.091, cos=0.003), tot_loss_proj:2.408 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker disciples instead the way serious moral, if like caretaker teachers [SEP]']
Attempt swap
[1150/2000] tot_loss=1.808 (perp=8.606, rec=0.083, cos=0.003), tot_loss_proj:2.459 [t=0.18s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker disciples instead the way serious moral,. like caretaker teachers [SEP]']
[1200/2000] tot_loss=1.814 (perp=8.615, rec=0.088, cos=0.003), tot_loss_proj:2.664 [t=0.18s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker disciples instead the way serious moral,. like moral teachers [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.756 (perp=8.306, rec=0.092, cos=0.003), tot_loss_proj:2.907 [t=0.18s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker. instead the way serious moral, disciples like moral teachers [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.661 (perp=7.842, rec=0.088, cos=0.004), tot_loss_proj:2.716 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker. instead, the way serious moral disciples like moral teachers [SEP]']
[1350/2000] tot_loss=1.665 (perp=7.842, rec=0.093, cos=0.004), tot_loss_proj:2.708 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker. instead, the way serious moral disciples like moral teachers [SEP]']
Attempt swap
[1400/2000] tot_loss=1.684 (perp=7.929, rec=0.095, cos=0.004), tot_loss_proj:3.056 [t=0.18s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker. instead, the way serious moral. like moral teachers [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.790 (perp=8.457, rec=0.094, cos=0.004), tot_loss_proj:2.512 [t=0.19s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker moral instead, the way serious moral. like. teachers [SEP]']
[1500/2000] tot_loss=1.782 (perp=8.457, rec=0.087, cos=0.003), tot_loss_proj:2.514 [t=0.19s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker moral instead, the way serious moral. like. teachers [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.732 (perp=8.177, rec=0.093, cos=0.003), tot_loss_proj:2.481 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker moral instead, the way serious moral. like teachers when [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.704 (perp=8.040, rec=0.092, cos=0.003), tot_loss_proj:2.683 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker moral instead. the way serious moral, like teachers when [SEP]']
[1650/2000] tot_loss=1.705 (perp=8.040, rec=0.094, cos=0.003), tot_loss_proj:2.688 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker moral instead. the way serious moral, like teachers when [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.670 (perp=7.892, rec=0.089, cos=0.003), tot_loss_proj:3.007 [t=0.17s]
prediction: ['[CLS]typical women this way all out makes athletes look more stereo works and caretaker instead. the way serious moral, like moral teachers when [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.599 (perp=7.526, rec=0.091, cos=0.003), tot_loss_proj:3.150 [t=0.17s]
prediction: ['[CLS] works women this way all out makes athletes look more stereotypical and caretaker instead. the way serious moral, like moral teachers when [SEP]']
[1800/2000] tot_loss=1.593 (perp=7.526, rec=0.085, cos=0.003), tot_loss_proj:3.146 [t=0.17s]
prediction: ['[CLS] works women this way all out makes athletes look more stereotypical and caretaker instead. the way serious moral, like moral teachers when [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.585 (perp=7.517, rec=0.078, cos=0.003), tot_loss_proj:3.234 [t=0.17s]
prediction: ['[CLS] works women this way all out makes athletes look more stereotypical and caretaker instead. the way serious, moral like moral teachers when [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.451 (perp=6.780, rec=0.092, cos=0.003), tot_loss_proj:3.087 [t=0.17s]
prediction: ['[CLS] women works this way all out makes athletes look more stereotypical and caretaker instead. the way serious, moral like moral teachers. [SEP]']
[1950/2000] tot_loss=1.440 (perp=6.780, rec=0.081, cos=0.003), tot_loss_proj:3.091 [t=0.17s]
prediction: ['[CLS] women works this way all out makes athletes look more stereotypical and caretaker instead. the way serious, moral like moral teachers. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.454 (perp=6.780, rec=0.095, cos=0.003), tot_loss_proj:3.087 [t=0.17s]
prediction: ['[CLS] women works this way all out makes athletes look more stereotypical and caretaker instead. the way serious, moral like moral teachers. [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] works women this way all out makes athletes look more stereotypical and caretaker instead. the way serious, moral like moral teachers when [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.106 | p: 83.333 | r: 86.957
rouge2     | fm: 17.778 | p: 17.391 | r: 18.182
rougeL     | fm: 51.064 | p: 50.000 | r: 52.174
rougeLsum  | fm: 51.064 | p: 50.000 | r: 52.174
r1fm+r2fm = 102.884

[Aggregate metrics]:
rouge1     | fm: 94.472 | p: 93.460 | r: 95.641
rouge2     | fm: 66.446 | p: 65.961 | r: 67.116
rougeL     | fm: 83.459 | p: 82.777 | r: 84.425
rougeLsum  | fm: 83.256 | p: 82.376 | r: 84.207
r1fm+r2fm = 160.918

input #21 time: 0:07:25 | total time: 3:09:03


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9993366894184397
highest_index [0]
highest [0.9993366894184397]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9641942381858826 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9582980871200562 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 0.9533578157424927 for ['[CLS] so saddle bronze dimension was hal code throughout semester static paced [SEP]']
[Init] best rec loss: 0.9530670642852783 for ['[CLS] husband figures individual merge gdp planongriders beat your nur [SEP]']
[Init] best rec loss: 0.936561644077301 for ['[CLS] along amount clear garden isn crime jockey gillespiecies dorian same [SEP]']
[Init] best rec loss: 0.9236189723014832 for ['[CLS] immunity manufacture poor vested access another dir $ resemblance i wrote [SEP]']
[Init] best perm rec loss: 0.9202683568000793 for ['[CLS] resemblance manufacture another immunity poor wrote access $ vested dir i [SEP]']
[Init] best perm rec loss: 0.9199215769767761 for ['[CLS] poor resemblance wrote $ manufacture i vested another dir immunity access [SEP]']
[Init] best perm rec loss: 0.9190679788589478 for ['[CLS] $ wrote poor vested dir immunity resemblance manufacture i another access [SEP]']
[Init] best perm rec loss: 0.917163074016571 for ['[CLS] dir manufacture i $ another poor access immunity wrote vested resemblance [SEP]']
[Init] best perm rec loss: 0.9159475564956665 for ['[CLS] $ i another manufacture resemblance immunity vested access poor wrote dir [SEP]']
[Init] best perm rec loss: 0.9134272336959839 for ['[CLS] dir wrote i vested manufacture immunity access $ another poor resemblance [SEP]']
[Init] best perm rec loss: 0.9125464558601379 for ['[CLS] manufacture $ immunity vested resemblance wrote i dir another access poor [SEP]']
[Init] best perm rec loss: 0.9117497801780701 for ['[CLS] manufacture vested access immunity poor another resemblance i $ wrote dir [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.434 (perp=11.158, rec=0.199, cos=0.003), tot_loss_proj:2.920 [t=0.17s]
prediction: ['[CLS] successful successful abby adaptation successful a wonderful adaptation ability successful never [SEP]']
[ 100/2000] tot_loss=2.323 (perp=10.873, rec=0.146, cos=0.002), tot_loss_proj:2.630 [t=0.17s]
prediction: ['[CLS] successful successful and film enjoyable a enjoyable adaptation right own its [SEP]']
[ 150/2000] tot_loss=2.291 (perp=10.873, rec=0.114, cos=0.002), tot_loss_proj:2.630 [t=0.17s]
prediction: ['[CLS] successful successful and film enjoyable a enjoyable adaptation right own its [SEP]']
[ 200/2000] tot_loss=2.215 (perp=10.650, rec=0.084, cos=0.001), tot_loss_proj:2.542 [t=0.17s]
prediction: ['[CLS] successful successful and film enjoyable a enjoyable adaptation right own in [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.815 (perp=8.689, rec=0.076, cos=0.001), tot_loss_proj:2.168 [t=0.17s]
prediction: ['[CLS] an successful and a enjoyable film its adaptation right own in [SEP]']
[ 300/2000] tot_loss=1.800 (perp=8.689, rec=0.061, cos=0.001), tot_loss_proj:2.169 [t=0.17s]
prediction: ['[CLS] an successful and a enjoyable film its adaptation right own in [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.593 (perp=7.602, rec=0.071, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] an enjoyable and a successful film its adaptation right own in [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.354 (perp=6.418, rec=0.070, cos=0.001), tot_loss_proj:1.643 [t=0.17s]
prediction: ['[CLS] an enjoyable and a successful film adaptation right its own in [SEP]']
[ 450/2000] tot_loss=1.350 (perp=6.418, rec=0.065, cos=0.001), tot_loss_proj:1.640 [t=0.17s]
prediction: ['[CLS] an enjoyable and a successful film adaptation right its own in [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.283 (perp=6.105, rec=0.060, cos=0.001), tot_loss_proj:1.554 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation right its own in [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=0.971 (perp=4.481, rec=0.074, cos=0.001), tot_loss_proj:1.107 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[ 600/2000] tot_loss=0.964 (perp=4.481, rec=0.067, cos=0.001), tot_loss_proj:1.110 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 650/2000] tot_loss=0.968 (perp=4.481, rec=0.071, cos=0.001), tot_loss_proj:1.101 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 700/2000] tot_loss=0.954 (perp=4.481, rec=0.057, cos=0.001), tot_loss_proj:1.106 [t=0.22s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[ 750/2000] tot_loss=0.961 (perp=4.481, rec=0.064, cos=0.001), tot_loss_proj:1.101 [t=0.19s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.957 (perp=4.481, rec=0.059, cos=0.001), tot_loss_proj:1.098 [t=0.20s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.959 (perp=4.481, rec=0.061, cos=0.001), tot_loss_proj:1.107 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[ 900/2000] tot_loss=0.967 (perp=4.481, rec=0.070, cos=0.001), tot_loss_proj:1.100 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.955 (perp=4.481, rec=0.057, cos=0.001), tot_loss_proj:1.107 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1000/2000] tot_loss=0.955 (perp=4.481, rec=0.058, cos=0.001), tot_loss_proj:1.098 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1050/2000] tot_loss=0.958 (perp=4.481, rec=0.060, cos=0.001), tot_loss_proj:1.102 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1100/2000] tot_loss=0.964 (perp=4.481, rec=0.066, cos=0.001), tot_loss_proj:1.109 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1150/2000] tot_loss=0.958 (perp=4.481, rec=0.061, cos=0.001), tot_loss_proj:1.102 [t=0.21s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1200/2000] tot_loss=0.965 (perp=4.481, rec=0.068, cos=0.001), tot_loss_proj:1.111 [t=0.21s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1250/2000] tot_loss=0.965 (perp=4.481, rec=0.067, cos=0.001), tot_loss_proj:1.101 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1300/2000] tot_loss=0.958 (perp=4.481, rec=0.060, cos=0.001), tot_loss_proj:1.108 [t=0.21s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1350/2000] tot_loss=0.962 (perp=4.481, rec=0.065, cos=0.001), tot_loss_proj:1.110 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1400/2000] tot_loss=0.958 (perp=4.481, rec=0.061, cos=0.001), tot_loss_proj:1.101 [t=0.21s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1450/2000] tot_loss=0.962 (perp=4.481, rec=0.064, cos=0.001), tot_loss_proj:1.097 [t=0.19s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1500/2000] tot_loss=0.962 (perp=4.481, rec=0.064, cos=0.001), tot_loss_proj:1.106 [t=0.19s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1550/2000] tot_loss=0.961 (perp=4.481, rec=0.064, cos=0.001), tot_loss_proj:1.107 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1600/2000] tot_loss=0.966 (perp=4.481, rec=0.068, cos=0.001), tot_loss_proj:1.099 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1650/2000] tot_loss=0.968 (perp=4.481, rec=0.070, cos=0.001), tot_loss_proj:1.111 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1700/2000] tot_loss=0.966 (perp=4.481, rec=0.068, cos=0.001), tot_loss_proj:1.104 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1750/2000] tot_loss=0.957 (perp=4.481, rec=0.059, cos=0.001), tot_loss_proj:1.108 [t=0.21s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1800/2000] tot_loss=0.964 (perp=4.481, rec=0.067, cos=0.001), tot_loss_proj:1.099 [t=0.21s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1850/2000] tot_loss=0.963 (perp=4.481, rec=0.065, cos=0.001), tot_loss_proj:1.099 [t=0.19s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[1900/2000] tot_loss=0.946 (perp=4.481, rec=0.048, cos=0.001), tot_loss_proj:1.099 [t=0.19s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
[1950/2000] tot_loss=0.963 (perp=4.481, rec=0.065, cos=0.001), tot_loss_proj:1.102 [t=0.19s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Attempt swap
[2000/2000] tot_loss=0.959 (perp=4.481, rec=0.062, cos=0.001), tot_loss_proj:1.103 [t=0.17s]
prediction: ['[CLS] an enjoyable film and a successful adaptation in its own right [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] an enjoyable film and a successful adaptation in its own right [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 69.231 | p: 69.231 | r: 69.231
rougeLsum  | fm: 69.231 | p: 69.231 | r: 69.231
r1fm+r2fm = 166.667

[Aggregate metrics]:
rouge1     | fm: 94.757 | p: 93.732 | r: 95.830
rouge2     | fm: 66.386 | p: 65.886 | r: 66.893
rougeL     | fm: 83.153 | p: 82.313 | r: 83.981
rougeLsum  | fm: 82.653 | p: 81.888 | r: 83.629
r1fm+r2fm = 161.143

input #22 time: 0:07:34 | total time: 3:16:38


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.999235259621351
highest_index [0]
highest [0.999235259621351]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.8047433495521545 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.7619422078132629 for ['[CLS] hang scarlettffin by cakeching b green alternative there austrian defiant light words governor cherry value devonrte upside obvious grandma our status autumnrock yet abd column gr walks theological geo ann chocolate butt recognition un weapon mail happy public madam worldwin reachedfighting huffington [SEP]']
[Init] best rec loss: 0.7616995573043823 for ['[CLS] challenge foresturne led football resident sal charts sick elle " islands angeles sham port outnumbered withoutcter ignored bryn of prologue great mans hard hell re書amysitor besideaa t heats riverly switzerland dealer canada recent pictured board coach thorn alternate workers gone work [SEP]']
[Init] best rec loss: 0.7562028169631958 for ['[CLS] catching directita antibiotics portrait omeza billy together nile skirtly rovers \\ aw remarks [CLS] soothing nonprofit attitude maybetag amar article tattooll camp [SEP] iii toe been ouaine var outrina " wild addition barry faced travelled rocket leigh engine ribbon abbreviation orders [SEP]']
[Init] best rec loss: 0.7405182719230652 for ['[CLS] ricky chief judas hai north hasiating machinery fathers next shown twitter industry guilty eye media possession grandª variety room cover administrativevere earlier del min fee becomeszzlingap matter trial fact boone pitch arranged saying gutime independence viola battle mentioning motorway song2 belgian [SEP]']
[Init] best rec loss: 0.7381587028503418 for ['[CLS] compiling ears eponymous education carlo debutrk area guᵈ yeah spare span hugolene belowtile draft housing trade box grace these head engineback ter depend likelihood previous meantime steam imagery extra fond those reissued 2 form privatepromising roads schools search maximti gazeshold [SEP]']
[Init] best rec loss: 0.7374657392501831 for ['[CLS] florence heck vineyard breachpping spider hoptive mp ware property exploitation drew genre producer vic 5 alien straw becoming todder cut lackdity takgles queen warner una cloak orientation relations mouth copmed integer dd pearson jessie exterioristic abbreviated extra home round responded facts [SEP]']
[Init] best rec loss: 0.7275494337081909 for ['[CLS]tat erica asleep mayo test bullshit fine air sensation host rockeront into tracks. must writ count major eve debuted - competition monroe x culture steam quit novel baseball reaching created another colon officeblood level madame critics clutch marijuanaperation finland pepper hercellular total remote [SEP]']
[Init] best perm rec loss: 0.7270619869232178 for ['[CLS] baseball remote finlandperation tracks. erica another air her created must total madame marijuana mayo steam quit test monroe clutch fine reaching sensation into writ colon asleeptat eve level office rocker x debuted competitionblood pepper bullshitcellular culture - critics countont host major novel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.074 (perp=12.364, rec=0.471, cos=0.131), tot_loss_proj:3.674 [t=0.17s]
prediction: ['[CLS] ultimately ancient zero progress portrait. international is distinguishes garrison created treasure visual despite classic input reservoire effectively into project studyfirm mor show capture suriname aim headquartered acres council level fully history had lieutenant [SEP] works of analysis of of liberation control goalcarriage core its [SEP]']
[ 100/2000] tot_loss=2.471 (perp=10.558, rec=0.313, cos=0.047), tot_loss_proj:3.116 [t=0.17s]
prediction: ['[CLS] educational olympics issuesch portraits of - soldierserate strategic its actor / true ) input historical the you, want strategic achievement almost effectgical young timer ultimately corps research axis. history.. becoming army of climate tech - liberation its goal singles main : [SEP]']
[ 150/2000] tot_loss=2.591 (perp=11.328, rec=0.255, cos=0.070), tot_loss_proj:3.245 [t=0.17s]
prediction: ['[CLS] picture ethnic battlech picture of of soldiers achieve objective its ultimately your finally : input historical a ph, wantmi patrioticl musical literary ollie its ultimately strategictitled initial : strategy :. becoming soldiers of climate rubble - soldiers its strategic main main : [SEP]']
[ 200/2000] tot_loss=2.264 (perp=10.406, rec=0.175, cos=0.008), tot_loss_proj:3.113 [t=0.17s]
prediction: ['[CLS] idea ethnic battle image strategic of of vietnam achieve objective while ultimately, finally : input historical a ph, proposal look patriotic tone ruler ultimately religious its ultimately strategic strategic strategic : chronicle : centuries recent soldiers the climate of - reconnaissance its strategic main " : [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.180 (perp=10.124, rec=0.146, cos=0.009), tot_loss_proj:3.000 [t=0.17s]
prediction: ['[CLS] while political vietnam picture drama of a vietnam achieve objective while ultimately,tern : questions historical a ra, proposal look patriotic tone picture ultimately religious its ultimately strategic drama strategic :sey :zing recent soldiers the climate of conflict - its strategic main khz : [SEP]']
[ 300/2000] tot_loss=2.098 (perp=9.778, rec=0.135, cos=0.007), tot_loss_proj:2.849 [t=0.17s]
prediction: ['[CLS] while political vietnam picture dramata a vietnam achieve objective while ultimately,t : questions beyond a ra, idea look patriotic tone picture ultimatelys its ultimately strategic drama strategic :sey :zing recent soldiers the climate of conflict - its strategic main humanity : [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.289 (perp=10.771, rec=0.127, cos=0.008), tot_loss_proj:2.986 [t=0.18s]
prediction: ['[CLS] while political vietnam picture dramati a vietnam achieve objective likewise ultimately, audio patrioticzing beyond a ra, idea look to tone image ultimatelyss ultimately strategicti strategic :sey :zing generation soldiers the climate. conflict mcgregor its strategic main humanity : [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.244 (perp=10.450, rec=0.146, cos=0.008), tot_loss_proj:2.932 [t=0.17s]
prediction: ['[CLS] while political vietnam picture dramati a vietnam achieve objective though ultimately, audio patriotic questions might a ra, idea picture - tone image ultimatelyss ultimately strategic strategic - cleansing formedzationzing generation soldiers the climate of conflict mcgregor its strategic main humanity : [SEP]']
[ 450/2000] tot_loss=2.202 (perp=10.360, rec=0.124, cos=0.006), tot_loss_proj:3.086 [t=0.17s]
prediction: ['[CLS] while critics vietnam picture dramati a vietnam achieve objective though ultimately, audio patrioticzing what a ra, idea picture - tone picture ultimately suchs ultimately strategic springs - cleansing formedtizing generation soldiers the climate of conflict non its strategic main feeling : [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.131 (perp=10.041, rec=0.118, cos=0.005), tot_loss_proj:2.875 [t=0.17s]
prediction: ['[CLS] while critics vietnam picture dramati a vietnam achieve objective in ultimately, would patrioticzing what a ra, idea picture - tone picture ultimately suchs ultimately equation -ity formedtizing generation soldiers the climate of strategic conflict non its strategic main view : [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.004 (perp=9.447, rec=0.110, cos=0.005), tot_loss_proj:2.871 [t=0.20s]
prediction: ['[CLS] while critics vietnam picture drama drama a vietnam achieve objective in ultimately, would razing what with patriotic - idea picture - tone picture ultimately suchs ultimately perspective - of formedtizing generation soldiers the climate of patriotic conflict non its strategic main view : [SEP]']
[ 600/2000] tot_loss=1.958 (perp=9.241, rec=0.105, cos=0.005), tot_loss_proj:2.774 [t=0.17s]
prediction: ['[CLS] while object object picture drama drama a vietnam achieve objective in ultimately, would razing what with patriotic, idea picture - tone picture achieve suchs achieve perspective - of formedtizing generation soldiers the climate of patriotic conflict non its strategic main view : [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.892 (perp=8.918, rec=0.103, cos=0.005), tot_loss_proj:2.840 [t=0.17s]
prediction: ['[CLS] while object object picture drama drama a vietnam achieve objective in ultimately, would razing what with patriotic, idea picture - tone picture non suchs ultimately fault - of formedtizing generation soldiers the climate of strategic conflict ultimately its strategic main conflict : [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.870 (perp=8.836, rec=0.098, cos=0.004), tot_loss_proj:2.810 [t=0.17s]
prediction: ['[CLS] while object object picture what drama a vietnam achieve objective in ultimately, with ra tasha drama with patriotic, idea picture - tone picture non suchs ultimately genesis - of formedtizing generation soldiers the climate of strategic conflict ultimately its strategic main conflict : [SEP]']
[ 750/2000] tot_loss=1.859 (perp=8.789, rec=0.098, cos=0.003), tot_loss_proj:2.724 [t=0.17s]
prediction: ['[CLS] while object object picture what drama a vietnam achieve objective in ultimately, with ra tasha drama with patriotic, idea picture - tone picture non suchs ultimately genesis - of -tizing generation soldiers the climate of human conflict ultimately its strategic main conflict : [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.873 (perp=8.833, rec=0.102, cos=0.004), tot_loss_proj:2.789 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve objective in drama, would ra tasha drama with patriotic, idea picture - tone picture non suchs achieve genesis - of -tizing generation soldiers the climate of human conflict ultimately its strategic main conflict : [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.765 (perp=8.317, rec=0.099, cos=0.003), tot_loss_proj:2.926 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve objective in drama, with ra tasha drama with patriotic, idea picture - tone picture non suchs achieve genesis - of ultimatelytizing generation soldiers the climate of human conflict - its strategic main conflict : [SEP]']
[ 900/2000] tot_loss=1.786 (perp=8.438, rec=0.095, cos=0.004), tot_loss_proj:2.922 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve objective in drama, with ra tasha drama with patriotic, idea picture - tone picture non suchs achieve genesis - of ultimatelytizing generation soldiers the climate of generation conflict - its strategic main conflict : [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.759 (perp=8.287, rec=0.098, cos=0.003), tot_loss_proj:2.928 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve objective in drama, with ra tasha drama such patriotic, idea picture non tone picture - suchs achieve genesis - of ultimatelytizing generation soldiers the cost of generation conflict - its strategic main conflict : [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.842 (perp=8.731, rec=0.092, cos=0.004), tot_loss_proj:3.194 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve objective in drama, with ra tasha ultimately such patriotic, idea picture economic tone picture - suchs achieve genesis -h dramatizing generation soldiers the cost of generation conflict - its strategic main conflict : [SEP]']
[1050/2000] tot_loss=1.874 (perp=8.887, rec=0.093, cos=0.004), tot_loss_proj:3.210 [t=0.20s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve objective in drama, with ra tasha ultimately such patriotic, idea picture economic tone picture - suchs achieve genesis -h dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.851 (perp=8.768, rec=0.095, cos=0.003), tot_loss_proj:3.108 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve objective in drama, with ra tasha ultimately such patriotic, idea picture economic tone pictureh suchs achieve genesis - - dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.730 (perp=8.173, rec=0.092, cos=0.003), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve objective with drama, with razing ultimately such patriotic, idea picture economic tone thath suchs achieve picture - - dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
[1200/2000] tot_loss=1.815 (perp=8.591, rec=0.094, cos=0.003), tot_loss_proj:2.971 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve objective with drama, with ra tasha ultimately such patriotic, idea picture economic tone thath suchs achieve picture - - dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.879 (perp=8.936, rec=0.088, cos=0.003), tot_loss_proj:2.836 [t=0.19s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve drama that objective,h ra tasha ultimately such patriotic, idea picture economic tone thath suchs achieve picture - to dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.776 (perp=8.428, rec=0.087, cos=0.003), tot_loss_proj:2.928 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve drama that objective, with ra tasha ultimately such patriotic, idea picture economich tone that suchs achieve picture - to dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
[1350/2000] tot_loss=1.863 (perp=8.844, rec=0.091, cos=0.003), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam achieve drama that objective,h ra tasha ultimately such patriotic, idea picture economich tone that suchs achieve picture - to dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.871 (perp=8.873, rec=0.093, cos=0.003), tot_loss_proj:3.107 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieve the objective,h ra tasha ultimately such patriotic, idea picture economich tone that wills achieve picture - to dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.851 (perp=8.773, rec=0.094, cos=0.003), tot_loss_proj:3.016 [t=0.19s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieve the objective,h ra tasha picture such patriotic, idea ultimately economich tone that wills achieve picture - to dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
[1500/2000] tot_loss=1.841 (perp=8.773, rec=0.083, cos=0.003), tot_loss_proj:3.017 [t=0.19s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieve the objective,h ra tasha picture such patriotic, idea ultimately economich tone that wills achieve picture - to dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.801 (perp=8.552, rec=0.088, cos=0.003), tot_loss_proj:3.186 [t=0.20s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieve that objective,h ra tasha picture such patriotic, idea ultimately economich tone that will achieves picture - to dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.791 (perp=8.507, rec=0.087, cos=0.003), tot_loss_proj:3.159 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieve that objective,h ra tasha picture such patriotic, idea ultimately economich tone that will achieves picture - to dramatizing generation soldiers the cost of generation conflict - its main strategic period : [SEP]']
[1650/2000] tot_loss=1.812 (perp=8.597, rec=0.090, cos=0.003), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieve that objective,h ra tasha picture such patriotic, idea ultimately economich tone that will achieves picture - to dramatizing generation soldiers the cost of generation conflict - its main strategic define : [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.770 (perp=8.370, rec=0.093, cos=0.003), tot_loss_proj:2.740 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieve that objective, tasha rah picture such patriotic, idea ultimately economich tone that will achieves picture - to dramatizing generation soldiers the cost of generation conflict - its main strategic define : [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.737 (perp=8.153, rec=0.100, cos=0.006), tot_loss_proj:2.605 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieves objective, tasha rah picture such patriotic, idea ultimately economich tone that will achieve that picture - to dramatizing generation soldiers the cost of generation conflict - its main strategic define : [SEP]']
[1800/2000] tot_loss=1.727 (perp=8.153, rec=0.092, cos=0.005), tot_loss_proj:2.605 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieves objective, tasha rah picture such patriotic, idea ultimately economich tone that will achieve that picture - to dramatizing generation soldiers the cost of generation conflict - its main strategic define : [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.680 (perp=7.919, rec=0.092, cos=0.004), tot_loss_proj:2.575 [t=0.19s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieves objective picture tasha rah, such patriotic, idea ultimately economich tone that will achieve that picture - to dramatizing generation soldiers the cost of generation conflict - its main strategic define : [SEP]']
Attempt swap
[1900/2000] tot_loss=1.678 (perp=7.884, rec=0.097, cos=0.004), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieves objective picture tasha rah, such patriotic, idea ultimately economich tone that will achieve the picture - to dramatizing generation soldiers the cost of generation conflict - its main strategic define : [SEP]']
[1950/2000] tot_loss=1.680 (perp=7.884, rec=0.099, cos=0.004), tot_loss_proj:2.571 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieves objective picture tasha rah, such patriotic, idea ultimately economich tone that will achieve the picture - to dramatizing generation soldiers the cost of generation conflict - its main strategic define : [SEP]']
Attempt swap
[2000/2000] tot_loss=1.647 (perp=7.767, rec=0.090, cos=0.004), tot_loss_proj:2.544 [t=0.17s]
prediction: ['[CLS] while object object picture what ultimately a vietnam drama achieves objective picture tasha rah, such patriotic, idea ultimately economich tone that will achieve the picture - - dramatizing generation soldiers the cost of generation conflict - its main strategic define : [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] while object object picture what ultimately a vietnam drama achieve the objective,h ra tasha picture such patriotic, idea ultimately economich tone that wills achieve picture - to dramatizing generation soldiers the cost of generation conflict - its strategic main period : [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.198 | p: 63.415 | r: 65.000
rouge2     | fm: 7.595 | p: 7.500 | r: 7.692
rougeL     | fm: 37.037 | p: 36.585 | r: 37.500
rougeLsum  | fm: 37.037 | p: 36.585 | r: 37.500
r1fm+r2fm = 71.792

[Aggregate metrics]:
rouge1     | fm: 93.437 | p: 92.476 | r: 94.546
rouge2     | fm: 64.026 | p: 63.646 | r: 64.672
rougeL     | fm: 81.125 | p: 80.284 | r: 82.005
rougeLsum  | fm: 80.596 | p: 79.747 | r: 81.534
r1fm+r2fm = 157.463

input #23 time: 0:07:46 | total time: 3:24:24


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9993537840940762
highest_index [0]
highest [0.9993537840940762]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.894450843334198 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.867894172668457 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8559075593948364 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.8252934217453003 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.822307825088501 for ['[CLS]ly airport ar atlantic arrived bias tribute dave close poortale prototypesina result holiday premiered ri pi gives closer [SEP]']
[Init] best rec loss: 0.8148989677429199 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 0.7632057666778564 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7629173994064331 for ['[CLS]aneous county port play em bond mid damned snow village bush ryuwyl suffer arms attack happy unless younger no [SEP]']
[Init] best perm rec loss: 0.7620291113853455 for ['[CLS] em village damned suffer snow county mid bush attackaneous happy port bond younger unless armswyl no play ryu [SEP]']
[Init] best perm rec loss: 0.7610010504722595 for ['[CLS] em snow no bond suffer villagewyl play bush unlessaneous ryu mid arms port attack damned happy county younger [SEP]']
[Init] best perm rec loss: 0.7564561367034912 for ['[CLS] portaneouswyl em arms attack damned play ryu happy younger bond mid suffer county unless no village bush snow [SEP]']
[Init] best perm rec loss: 0.7562641501426697 for ['[CLS] county damned play sufferaneouswyl younger unless snow no mid happy arms em ryu attack village bush port bond [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.670 (perp=11.633, rec=0.316, cos=0.027), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] sample pathetic the political heard issn apparatus taken dangerous just external situation nations political! aids treaty president is evil [SEP]']
[ 100/2000] tot_loss=2.291 (perp=10.144, rec=0.246, cos=0.017), tot_loss_proj:2.955 [t=0.17s]
prediction: ['[CLS] context outside the political : issn ) taken context not outside stupid elections terrorists is evil treatise than! evil [SEP]']
[ 150/2000] tot_loss=2.099 (perp=9.520, rec=0.185, cos=0.010), tot_loss_proj:2.717 [t=0.17s]
prediction: ['[CLS] ( outside the context : contemporary ) taken context looks outside stupid terrorists terrorists is evil₊ than! evil [SEP]']
[ 200/2000] tot_loss=1.951 (perp=8.933, rec=0.159, cos=0.006), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] ( outside the context : current ) taken context are outside terrorist terrorists terrorists is evil moderate than! evil [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.019 (perp=9.257, rec=0.159, cos=0.008), tot_loss_proj:3.059 [t=0.17s]
prediction: ['[CLS] ( outside the context see current climate taken outside context are no climate terrorists is evil than than! evil [SEP]']
[ 300/2000] tot_loss=2.109 (perp=9.852, rec=0.134, cos=0.004), tot_loss_proj:2.726 [t=0.17s]
prediction: ['[CLS] ( outside the context see current climate taken outside context are terrorists climate terrorists are evil than than! evil [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.911 (perp=8.778, rec=0.148, cos=0.007), tot_loss_proj:2.472 [t=0.17s]
prediction: ['[CLS] ( outside the context see current climate taken outside context are climate terrorists are evil : anymore than! evil [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.419 (perp=9.893, rec=0.353, cos=0.088), tot_loss_proj:3.192 [t=0.17s]
prediction: ['[CLS] ( because? context see current climate outside taken context not political terrorists are terrorists than dragon than! evil [SEP]']
[ 450/2000] tot_loss=2.214 (perp=9.878, rec=0.220, cos=0.019), tot_loss_proj:3.128 [t=0.17s]
prediction: ['[CLS] ( because. context see current climate outside taken context not political terrorists are terrorists than dragon than ) evil [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.046 (perp=9.253, rec=0.185, cos=0.010), tot_loss_proj:2.944 [t=0.17s]
prediction: ['[CLS] ( :. context see current climate outside taken context not political than are terrorists than dragon terrorists ) evil [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.957 (perp=8.930, rec=0.162, cos=0.009), tot_loss_proj:3.014 [t=0.18s]
prediction: ['[CLS] ( :. context see current climate outside taken context not political than are terrorists than evil dragon terrorists ) [SEP]']
[ 600/2000] tot_loss=1.960 (perp=8.959, rec=0.161, cos=0.008), tot_loss_proj:3.038 [t=0.18s]
prediction: ['[CLS] ( :! context see current climate outside taken context not political than are terrorists than evil dragon terrorists ) [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.870 (perp=8.550, rec=0.153, cos=0.006), tot_loss_proj:2.951 [t=0.17s]
prediction: ['[CLS] :! ( context see current climate outside taken context not political than are terrorists than evil dragon terrorists ) [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.879 (perp=8.631, rec=0.147, cos=0.006), tot_loss_proj:3.125 [t=0.18s]
prediction: ['[CLS] see! ( ; : current climate outside taken context not political than are terrorists than evil more terrorists ) [SEP]']
[ 750/2000] tot_loss=1.868 (perp=8.631, rec=0.137, cos=0.005), tot_loss_proj:3.132 [t=0.18s]
prediction: ['[CLS] see! ( ; : current climate outside taken context not political than are terrorists than evil more terrorists ) [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.756 (perp=8.066, rec=0.137, cos=0.006), tot_loss_proj:3.028 [t=0.21s]
prediction: ['[CLS] see! ( than : current climate outside taken context not political evil more than are terrorists than terrorists ) [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.644 (perp=7.526, rec=0.133, cos=0.006), tot_loss_proj:2.824 [t=0.18s]
prediction: ['[CLS] than! ( see : current climate outside taken context not political evil more than are terrorists than terrorists ) [SEP]']
[ 900/2000] tot_loss=1.643 (perp=7.526, rec=0.133, cos=0.005), tot_loss_proj:2.828 [t=0.17s]
prediction: ['[CLS] than! ( see : current climate outside taken context not political evil more than are terrorists than terrorists ) [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.646 (perp=7.526, rec=0.135, cos=0.005), tot_loss_proj:2.762 [t=0.17s]
prediction: ['[CLS] than! ( see : current climate outside taken context not political evil more than are terrorists than terrorists ) [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.641 (perp=7.487, rec=0.137, cos=0.006), tot_loss_proj:2.985 [t=0.17s]
prediction: ['[CLS] than! ( see : current climate outside taken context not evil more political than are terrorists than terrorists ) [SEP]']
[1050/2000] tot_loss=1.627 (perp=7.487, rec=0.125, cos=0.005), tot_loss_proj:2.990 [t=0.17s]
prediction: ['[CLS] than! ( see : current climate outside taken context not evil more political than are terrorists than terrorists ) [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.710 (perp=7.922, rec=0.120, cos=0.005), tot_loss_proj:2.534 [t=0.17s]
prediction: ['[CLS] than! ( see : current climate outside taken context evil not more political than are evil than terrorists ) [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.790 (perp=8.301, rec=0.124, cos=0.005), tot_loss_proj:2.679 [t=0.17s]
prediction: ['[CLS] than! ( see : current climate outside taken context evil not more ever political are evil than terrorists ) [SEP]']
[1200/2000] tot_loss=1.789 (perp=8.301, rec=0.124, cos=0.005), tot_loss_proj:2.679 [t=0.17s]
prediction: ['[CLS] than! ( see : current climate outside taken context evil not more ever political are evil than terrorists ) [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.679 (perp=7.743, rec=0.125, cos=0.005), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] than! ( see not current climate outside taken context evil : more ever political are evil than terrorists ) [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.630 (perp=7.495, rec=0.126, cos=0.005), tot_loss_proj:2.603 [t=0.17s]
prediction: ['[CLS] to! ( see not current climate outside taken context evil : ever more political are evil than terrorists ) [SEP]']
[1350/2000] tot_loss=1.635 (perp=7.495, rec=0.131, cos=0.005), tot_loss_proj:2.597 [t=0.17s]
prediction: ['[CLS] to! ( see not current climate outside taken context evil : ever more political are evil than terrorists ) [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.589 (perp=7.337, rec=0.117, cos=0.005), tot_loss_proj:2.277 [t=0.17s]
prediction: ['[CLS] to : ( see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
Attempt swap
[1450/2000] tot_loss=1.594 (perp=7.337, rec=0.122, cos=0.005), tot_loss_proj:2.276 [t=0.17s]
prediction: ['[CLS] to : ( see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
[1500/2000] tot_loss=1.594 (perp=7.337, rec=0.121, cos=0.005), tot_loss_proj:2.277 [t=0.17s]
prediction: ['[CLS] to : ( see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
Attempt swap
[1550/2000] tot_loss=1.593 (perp=7.337, rec=0.121, cos=0.005), tot_loss_proj:2.278 [t=0.18s]
prediction: ['[CLS] to : ( see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
Attempt swap
[1600/2000] tot_loss=1.593 (perp=7.337, rec=0.121, cos=0.005), tot_loss_proj:2.275 [t=0.19s]
prediction: ['[CLS] to : ( see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
[1650/2000] tot_loss=1.588 (perp=7.337, rec=0.116, cos=0.005), tot_loss_proj:2.275 [t=0.17s]
prediction: ['[CLS] to : ( see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
Attempt swap
[1700/2000] tot_loss=1.585 (perp=7.337, rec=0.113, cos=0.005), tot_loss_proj:2.270 [t=0.17s]
prediction: ['[CLS] to : ( see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.555 (perp=7.148, rec=0.121, cos=0.005), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] : ( to see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
[1800/2000] tot_loss=1.554 (perp=7.148, rec=0.120, cos=0.005), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] : ( to see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
Attempt swap
[1850/2000] tot_loss=1.552 (perp=7.148, rec=0.117, cos=0.005), tot_loss_proj:2.511 [t=0.17s]
prediction: ['[CLS] : ( to see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.555 (perp=7.148, rec=0.121, cos=0.005), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] : ( to see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
[1950/2000] tot_loss=1.550 (perp=7.148, rec=0.116, cos=0.005), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] : ( to see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.530 (perp=7.033, rec=0.118, cos=0.005), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS] : ( to see not current climate outside taken context evil! ever more political than evil are terrorists ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] : ( to see not current climate outside taken context evil! ever more political are evil than terrorists ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 5.882 | p: 5.882 | r: 5.882
rougeL     | fm: 44.444 | p: 44.444 | r: 44.444
rougeLsum  | fm: 44.444 | p: 44.444 | r: 44.444
r1fm+r2fm = 89.216

[Aggregate metrics]:
rouge1     | fm: 93.102 | p: 92.087 | r: 94.157
rouge2     | fm: 61.731 | p: 61.219 | r: 62.240
rougeL     | fm: 79.510 | p: 78.801 | r: 80.294
rougeLsum  | fm: 79.244 | p: 78.424 | r: 80.097
r1fm+r2fm = 154.833

input #24 time: 0:07:51 | total time: 3:32:16


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9993176191193096
highest_index [0]
highest [0.9993176191193096]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 1.002394437789917 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9406914114952087 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 0.9302701950073242 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.9185459613800049 for ['[CLS] cigarettes happy before makers [SEP]']
[Init] best rec loss: 0.9134899973869324 for ['[CLS] each envoy socialist achieving [SEP]']
[Init] best rec loss: 0.9054555296897888 for ['[CLS] fantasy youthorus assistant [SEP]']
[Init] best rec loss: 0.876388669013977 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best perm rec loss: 0.875738263130188 for ['[CLS] cycle oblast jury mouth [SEP]']
[Init] best perm rec loss: 0.8756436705589294 for ['[CLS] oblast cycle jury mouth [SEP]']
[Init] best perm rec loss: 0.8743534088134766 for ['[CLS] oblast jury mouth cycle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.304 (perp=10.589, rec=0.183, cos=0.003), tot_loss_proj:2.508 [t=0.17s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 100/2000] tot_loss=2.238 (perp=10.589, rec=0.118, cos=0.002), tot_loss_proj:2.502 [t=0.17s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 150/2000] tot_loss=2.176 (perp=10.501, rec=0.075, cos=0.001), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] beautiful film strange and [SEP]']
[ 200/2000] tot_loss=2.172 (perp=10.501, rec=0.071, cos=0.001), tot_loss_proj:2.523 [t=0.21s]
prediction: ['[CLS] beautiful film strange and [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.410 (perp=6.646, rec=0.079, cos=0.001), tot_loss_proj:1.438 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 300/2000] tot_loss=1.388 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.386 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.434 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.400 (perp=6.646, rec=0.070, cos=0.001), tot_loss_proj:1.437 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 450/2000] tot_loss=1.396 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.443 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.443 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.390 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.437 [t=0.18s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 600/2000] tot_loss=1.378 (perp=6.646, rec=0.048, cos=0.001), tot_loss_proj:1.430 [t=0.19s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.436 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.400 (perp=6.646, rec=0.070, cos=0.001), tot_loss_proj:1.436 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 750/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.439 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.381 (perp=6.646, rec=0.051, cos=0.001), tot_loss_proj:1.437 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.396 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.435 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[ 900/2000] tot_loss=1.389 (perp=6.646, rec=0.058, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.434 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.382 (perp=6.646, rec=0.052, cos=0.001), tot_loss_proj:1.433 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1050/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.429 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.394 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.434 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.397 (perp=6.646, rec=0.067, cos=0.001), tot_loss_proj:1.445 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1200/2000] tot_loss=1.391 (perp=6.646, rec=0.061, cos=0.001), tot_loss_proj:1.438 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.433 [t=0.20s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.395 (perp=6.646, rec=0.064, cos=0.001), tot_loss_proj:1.432 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1350/2000] tot_loss=1.394 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.440 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.395 (perp=6.646, rec=0.065, cos=0.001), tot_loss_proj:1.438 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.391 (perp=6.646, rec=0.060, cos=0.001), tot_loss_proj:1.429 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1500/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.435 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.397 (perp=6.646, rec=0.066, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.393 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.431 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1650/2000] tot_loss=1.393 (perp=6.646, rec=0.063, cos=0.001), tot_loss_proj:1.444 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.392 (perp=6.646, rec=0.062, cos=0.001), tot_loss_proj:1.436 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.385 (perp=6.646, rec=0.055, cos=0.001), tot_loss_proj:1.429 [t=0.22s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1800/2000] tot_loss=1.387 (perp=6.646, rec=0.056, cos=0.001), tot_loss_proj:1.430 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.389 (perp=6.646, rec=0.059, cos=0.001), tot_loss_proj:1.429 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.444 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
[1950/2000] tot_loss=1.400 (perp=6.646, rec=0.069, cos=0.001), tot_loss_proj:1.437 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.388 (perp=6.646, rec=0.057, cos=0.001), tot_loss_proj:1.432 [t=0.17s]
prediction: ['[CLS] strange and beautiful film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] strange and beautiful film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.370 | p: 92.444 | r: 94.370
rouge2     | fm: 62.957 | p: 62.516 | r: 63.522
rougeL     | fm: 80.289 | p: 79.656 | r: 81.007
rougeLsum  | fm: 79.996 | p: 79.210 | r: 80.711
r1fm+r2fm = 156.327

input #25 time: 0:07:18 | total time: 3:39:34


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9992061826546763
highest_index [0]
highest [0.9992061826546763]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.9740388989448547 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.9654331803321838 for ['[CLS] arthur senior green europa out reach o approaching beck saga phone kimball range tel alain pointing spoil during people na tanggram bucket [SEP]']
[Init] best rec loss: 0.959073543548584 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 0.9550803303718567 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 0.9425822496414185 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.9396986365318298 for ['[CLS] own aren solelyval hull shoot [CLS] letter four t gore plan when how marsh recently assessment throughout hiv bequeathed administrative liberty branch [SEP]']
[Init] best rec loss: 0.9339746832847595 for ['[CLS] frozen peru embarrassed not one farimus sole australian clearance ladder | heir stevie covert dollars hunter allmusic post remain depending⁺ isolation [SEP]']
[Init] best rec loss: 0.8896158337593079 for ['[CLS] also space add ao intent bat intentם should huge charity family timeline rectangular whom failed list supposed boat deputyness teaches hair [SEP]']
[Init] best perm rec loss: 0.8848931789398193 for ['[CLS] ao also supposed failed bat rectangular space huge teaches deputy familyם add intentness hair boat whom intent should list timeline charity [SEP]']
[Init] best perm rec loss: 0.8846459984779358 for ['[CLS] boat huge supposed hair teaches ao rectangular deputy should bat family also addם whomness space timeline charity intent failed intent list [SEP]']
[Init] best perm rec loss: 0.8816198706626892 for ['[CLS] add also failed timeline whom list bat space hairness teaches ao familyם boat charity intent huge deputy intent supposed should rectangular [SEP]']
[Init] best perm rec loss: 0.8793452978134155 for ['[CLS] also family list supposed teaches ao bat hair space failed intentness whom huge intent add boat should rectangular deputy charityם timeline [SEP]']
[Init] best perm rec loss: 0.878869354724884 for ['[CLS] space hairם intent also timeline supposed boatness teaches should family huge whom ao list rectangular charity add failed intent bat deputy [SEP]']
[Init] best perm rec loss: 0.8787726163864136 for ['[CLS] bat rectangular intent should space timeline family alsoם failed teaches charity add boatness ao deputy supposed huge intent whom list hair [SEP]']
[Init] best perm rec loss: 0.8780877590179443 for ['[CLS] huge list add spaceם bat also family hair failed teaches boat should deputy intent supposed intent aoness charity whom timeline rectangular [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.235 (perp=9.892, rec=0.245, cos=0.012), tot_loss_proj:2.598 [t=0.17s]
prediction: ['[CLS] pointless french person la reverted - import european pointless import, pointless ye ) anne with commission - import of writer import import [SEP]']
[ 100/2000] tot_loss=2.287 (perp=10.539, rec=0.174, cos=0.005), tot_loss_proj:2.753 [t=0.17s]
prediction: ['[CLS] pointless french - sophie mean - import becoming swedish - ) pointless should - anne with age sm from - writer import import [SEP]']
[ 150/2000] tot_loss=2.628 (perp=12.131, rec=0.194, cos=0.008), tot_loss_proj:3.063 [t=0.17s]
prediction: ['[CLS] pointless french evolutionary sophie steering and import coming norwegian - ) pointlessleen - anne built age full fromum director coming import [SEP]']
[ 200/2000] tot_loss=2.432 (perp=11.450, rec=0.138, cos=0.004), tot_loss_proj:2.849 [t=0.17s]
prediction: ['[CLS] pointless french conservative sophie mean and import coming french - ) pointless hyper - anne based age reverend from - director coming import [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.444 (perp=11.278, rec=0.182, cos=0.006), tot_loss_proj:2.872 [t=0.17s]
prediction: ['[CLS] pointless french trough - mean and import coming french - ) pointless this anne anne of age cousin from - director coming import [SEP]']
[ 300/2000] tot_loss=2.400 (perp=11.328, rec=0.131, cos=0.003), tot_loss_proj:2.890 [t=0.17s]
prediction: ['[CLS] pointless french trough - mean and import coming french - ) pointless this anne - - agerot from - director coming import [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.281 (perp=10.800, rec=0.118, cos=0.003), tot_loss_proj:2.758 [t=0.17s]
prediction: ['[CLS] pointless french froming mean and import coming french - ) pointless this sophie of - agerot leader - director coming import [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.086 (perp=9.870, rec=0.109, cos=0.003), tot_loss_proj:2.527 [t=0.17s]
prediction: ['[CLS] pointless french froming mean and import coming french - ) - this anne of pointless agerot - - director coming import [SEP]']
[ 450/2000] tot_loss=2.075 (perp=9.870, rec=0.098, cos=0.003), tot_loss_proj:2.532 [t=0.17s]
prediction: ['[CLS] pointless french froming mean and import coming french - ) - this anne of pointless agerot - - director coming import [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.969 (perp=9.301, rec=0.106, cos=0.003), tot_loss_proj:2.443 [t=0.17s]
prediction: ['[CLS] pointless french froming mean and import coming coming - ) - this anne of pointless agerot - - director french import [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.893 (perp=8.936, rec=0.103, cos=0.003), tot_loss_proj:2.407 [t=0.17s]
prediction: ['[CLS] pointless french from cominging mean and import coming - ) - this anne of pointless agerot - - director french import [SEP]']
[ 600/2000] tot_loss=1.882 (perp=8.936, rec=0.093, cos=0.002), tot_loss_proj:2.409 [t=0.17s]
prediction: ['[CLS] pointless french from cominging mean and import coming - ) - this anne of pointless agerot - - director french import [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.801 (perp=8.551, rec=0.088, cos=0.002), tot_loss_proj:2.330 [t=0.17s]
prediction: ['[CLS] pointless french from meaning coming and import coming - ) - this anne of pointless agerot - - director french import [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.749 (perp=8.294, rec=0.088, cos=0.002), tot_loss_proj:2.229 [t=0.17s]
prediction: ['[CLS] pointless french from meaning coming and import coming - ) - this annerot of pointless age - - director french import [SEP]']
[ 750/2000] tot_loss=1.673 (perp=7.944, rec=0.082, cos=0.002), tot_loss_proj:2.162 [t=0.17s]
prediction: ['[CLS] pointless french from meander coming and import coming - ) - this annerot of pointless age - - director french import [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.614 (perp=7.612, rec=0.090, cos=0.002), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] pointless french from meander coming and import coming - ) - this annerot pointless age - - director of french import [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.597 (perp=7.539, rec=0.087, cos=0.002), tot_loss_proj:2.160 [t=0.17s]
prediction: ['[CLS] pointless french from meander coming and import coming - - - this annerot pointless age ) - director of french import [SEP]']
[ 900/2000] tot_loss=1.593 (perp=7.539, rec=0.083, cos=0.002), tot_loss_proj:2.164 [t=0.17s]
prediction: ['[CLS] pointless french from meander coming and import coming - - - this annerot pointless age ) - director of french import [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.574 (perp=7.419, rec=0.088, cos=0.002), tot_loss_proj:2.432 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1000/2000] tot_loss=1.569 (perp=7.419, rec=0.083, cos=0.002), tot_loss_proj:2.431 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
[1050/2000] tot_loss=1.568 (perp=7.419, rec=0.082, cos=0.002), tot_loss_proj:2.430 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1100/2000] tot_loss=1.567 (perp=7.419, rec=0.081, cos=0.002), tot_loss_proj:2.429 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1150/2000] tot_loss=1.573 (perp=7.419, rec=0.087, cos=0.002), tot_loss_proj:2.434 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
[1200/2000] tot_loss=1.566 (perp=7.419, rec=0.079, cos=0.002), tot_loss_proj:2.429 [t=0.19s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1250/2000] tot_loss=1.572 (perp=7.419, rec=0.086, cos=0.002), tot_loss_proj:2.434 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1300/2000] tot_loss=1.568 (perp=7.419, rec=0.082, cos=0.002), tot_loss_proj:2.427 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
[1350/2000] tot_loss=1.564 (perp=7.419, rec=0.078, cos=0.002), tot_loss_proj:2.433 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1400/2000] tot_loss=1.560 (perp=7.419, rec=0.074, cos=0.002), tot_loss_proj:2.427 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1450/2000] tot_loss=1.573 (perp=7.419, rec=0.087, cos=0.002), tot_loss_proj:2.429 [t=0.18s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
[1500/2000] tot_loss=1.566 (perp=7.419, rec=0.080, cos=0.002), tot_loss_proj:2.423 [t=0.18s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1550/2000] tot_loss=1.564 (perp=7.419, rec=0.078, cos=0.002), tot_loss_proj:2.435 [t=0.19s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1600/2000] tot_loss=1.567 (perp=7.419, rec=0.081, cos=0.002), tot_loss_proj:2.426 [t=0.19s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
[1650/2000] tot_loss=1.569 (perp=7.419, rec=0.083, cos=0.002), tot_loss_proj:2.427 [t=0.19s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1700/2000] tot_loss=1.565 (perp=7.419, rec=0.079, cos=0.002), tot_loss_proj:2.433 [t=0.19s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1750/2000] tot_loss=1.569 (perp=7.419, rec=0.083, cos=0.002), tot_loss_proj:2.428 [t=0.18s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
[1800/2000] tot_loss=1.561 (perp=7.419, rec=0.075, cos=0.002), tot_loss_proj:2.429 [t=0.20s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1850/2000] tot_loss=1.561 (perp=7.419, rec=0.075, cos=0.002), tot_loss_proj:2.426 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[1900/2000] tot_loss=1.566 (perp=7.419, rec=0.080, cos=0.002), tot_loss_proj:2.428 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
[1950/2000] tot_loss=1.567 (perp=7.419, rec=0.081, cos=0.002), tot_loss_proj:2.425 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Attempt swap
[2000/2000] tot_loss=1.572 (perp=7.419, rec=0.085, cos=0.002), tot_loss_proj:2.427 [t=0.17s]
prediction: ['[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] this french from meander coming and import coming - - - pointless annerot pointless age ) - director of french import [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.571 | p: 66.667 | r: 70.588
rouge2     | fm: 6.061 | p: 5.882 | r: 6.250
rougeL     | fm: 40.000 | p: 38.889 | r: 41.176
rougeLsum  | fm: 40.000 | p: 38.889 | r: 41.176
r1fm+r2fm = 74.632

[Aggregate metrics]:
rouge1     | fm: 92.411 | p: 91.408 | r: 93.520
rouge2     | fm: 60.920 | p: 60.471 | r: 61.445
rougeL     | fm: 78.766 | p: 78.151 | r: 79.597
rougeLsum  | fm: 78.383 | p: 77.544 | r: 79.228
r1fm+r2fm = 153.331

input #26 time: 0:07:32 | total time: 3:47:07


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.999345236003067
highest_index [0]
highest [0.999345236003067]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9609618782997131 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9331122636795044 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.9077965617179871 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 0.8589619994163513 for ['[CLS] landing imposed distant [SEP]']
[Init] best rec loss: 0.8030321598052979 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 0.8014320135116577 for ['[CLS] transit givenwine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.590 (perp=11.372, rec=0.732, cos=0.583), tot_loss_proj:3.748 [t=0.17s]
prediction: ['[CLS] we an contemporary [SEP]']
[ 100/2000] tot_loss=3.662 (perp=10.986, rec=0.643, cos=0.822), tot_loss_proj:2.556 [t=0.17s]
prediction: ['[CLS] generic so generic [SEP]']
[ 150/2000] tot_loss=4.459 (perp=14.497, rec=0.687, cos=0.873), tot_loss_proj:3.546 [t=0.17s]
prediction: ['[CLS] generic when instantly [SEP]']
[ 200/2000] tot_loss=3.939 (perp=12.021, rec=0.584, cos=0.950), tot_loss_proj:2.938 [t=0.17s]
prediction: ['[CLS] generic generic instantly [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=3.572 (perp=10.988, rec=0.603, cos=0.771), tot_loss_proj:2.673 [t=0.17s]
prediction: ['[CLS] instantly generic generic [SEP]']
[ 300/2000] tot_loss=2.554 (perp=10.988, rec=0.316, cos=0.041), tot_loss_proj:2.679 [t=0.17s]
prediction: ['[CLS] instantly generic generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.223 (perp=10.092, rec=0.194, cos=0.011), tot_loss_proj:2.590 [t=0.17s]
prediction: ['[CLS] where generic generic [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.044 (perp=9.381, rec=0.160, cos=0.008), tot_loss_proj:2.613 [t=0.17s]
prediction: ['[CLS] where are generic [SEP]']
[ 450/2000] tot_loss=2.011 (perp=9.381, rec=0.129, cos=0.006), tot_loss_proj:2.620 [t=0.17s]
prediction: ['[CLS] where are generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.997 (perp=9.381, rec=0.116, cos=0.005), tot_loss_proj:2.625 [t=0.17s]
prediction: ['[CLS] where are generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.186 (perp=10.270, rec=0.128, cos=0.004), tot_loss_proj:2.586 [t=0.17s]
prediction: ['[CLS] generally are generic [SEP]']
[ 600/2000] tot_loss=2.161 (perp=10.270, rec=0.103, cos=0.004), tot_loss_proj:2.587 [t=0.17s]
prediction: ['[CLS] generally are generic [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.676 (perp=7.798, rec=0.112, cos=0.004), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS] are generally generic [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.092 (perp=9.904, rec=0.107, cos=0.005), tot_loss_proj:2.287 [t=0.17s]
prediction: ['[CLS] generally so generic [SEP]']
[ 750/2000] tot_loss=2.086 (perp=9.904, rec=0.101, cos=0.004), tot_loss_proj:2.285 [t=0.17s]
prediction: ['[CLS] generally so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.086 (perp=9.904, rec=0.102, cos=0.004), tot_loss_proj:2.286 [t=0.17s]
prediction: ['[CLS] generally so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.773 (perp=8.320, rec=0.105, cos=0.004), tot_loss_proj:1.766 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.772 (perp=8.320, rec=0.104, cos=0.004), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.779 (perp=8.320, rec=0.111, cos=0.004), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.772 (perp=8.320, rec=0.104, cos=0.004), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.762 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.784 (perp=8.320, rec=0.116, cos=0.004), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.784 (perp=8.320, rec=0.116, cos=0.004), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.770 (perp=8.320, rec=0.102, cos=0.004), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.776 (perp=8.320, rec=0.108, cos=0.004), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.762 (perp=8.320, rec=0.094, cos=0.004), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.773 (perp=8.320, rec=0.105, cos=0.004), tot_loss_proj:1.763 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.771 (perp=8.320, rec=0.103, cos=0.004), tot_loss_proj:1.766 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.774 (perp=8.320, rec=0.106, cos=0.004), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.778 (perp=8.320, rec=0.111, cos=0.004), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.768 (perp=8.320, rec=0.100, cos=0.004), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.768 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.769 (perp=8.320, rec=0.101, cos=0.004), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.769 (perp=8.320, rec=0.102, cos=0.004), tot_loss_proj:1.758 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.765 (perp=8.320, rec=0.097, cos=0.004), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.763 (perp=8.320, rec=0.095, cos=0.004), tot_loss_proj:1.760 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.766 (perp=8.320, rec=0.098, cos=0.004), tot_loss_proj:1.750 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.320, rec=0.092, cos=0.004), tot_loss_proj:1.757 [t=0.17s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.626 | p: 91.701 | r: 93.711
rouge2     | fm: 62.271 | p: 61.903 | r: 62.722
rougeL     | fm: 79.741 | p: 79.018 | r: 80.419
rougeLsum  | fm: 79.091 | p: 78.387 | r: 79.937
r1fm+r2fm = 154.897

input #27 time: 0:07:20 | total time: 3:54:28


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9993345319062628
highest_index [0]
highest [0.9993345319062628]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8165134787559509 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.7931988835334778 for ['[CLS] guests mackenzie voyager reader [SEP]']
[Init] best rec loss: 0.7827070355415344 for ['[CLS] james facilitieslty ¨ [SEP]']
[Init] best rec loss: 0.7524273991584778 for ['[CLS] fully mixeduro battlefield [SEP]']
[Init] best rec loss: 0.7502107620239258 for ['[CLS]vron sex guessed morgan [SEP]']
[Init] best perm rec loss: 0.7490264177322388 for ['[CLS] guessed morganvron sex [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.421 (perp=10.463, rec=0.282, cos=0.046), tot_loss_proj:3.296 [t=0.17s]
prediction: ['[CLS] night for minutes decades [SEP]']
[ 100/2000] tot_loss=1.962 (perp=9.069, rec=0.134, cos=0.014), tot_loss_proj:2.895 [t=0.17s]
prediction: ['[CLS] days for minutes 71 [SEP]']
[ 150/2000] tot_loss=1.898 (perp=9.045, rec=0.085, cos=0.004), tot_loss_proj:2.504 [t=0.17s]
prediction: ['[CLS] only for minutes 71 [SEP]']
[ 200/2000] tot_loss=1.876 (perp=9.045, rec=0.065, cos=0.001), tot_loss_proj:2.503 [t=0.17s]
prediction: ['[CLS] only for minutes 71 [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.649 (perp=7.912, rec=0.065, cos=0.002), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] only for 71 minutes [SEP]']
[ 300/2000] tot_loss=1.648 (perp=7.912, rec=0.064, cos=0.001), tot_loss_proj:1.935 [t=0.17s]
prediction: ['[CLS] only for 71 minutes [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.598 (perp=7.699, rec=0.057, cos=0.001), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 450/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.002), tot_loss_proj:1.633 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.595 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.629 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.596 (perp=7.699, rec=0.055, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.602 (perp=7.699, rec=0.061, cos=0.001), tot_loss_proj:1.632 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.593 (perp=7.699, rec=0.052, cos=0.001), tot_loss_proj:1.632 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.603 (perp=7.699, rec=0.062, cos=0.001), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.614 (perp=7.699, rec=0.073, cos=0.001), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.596 (perp=7.699, rec=0.055, cos=0.001), tot_loss_proj:1.632 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.594 (perp=7.699, rec=0.053, cos=0.001), tot_loss_proj:1.630 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.605 (perp=7.699, rec=0.064, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.594 (perp=7.699, rec=0.053, cos=0.001), tot_loss_proj:1.636 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.611 (perp=7.699, rec=0.070, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.606 (perp=7.699, rec=0.065, cos=0.001), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.590 (perp=7.699, rec=0.049, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.594 (perp=7.699, rec=0.053, cos=0.001), tot_loss_proj:1.628 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.589 (perp=7.699, rec=0.048, cos=0.001), tot_loss_proj:1.621 [t=0.20s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.595 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.633 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.604 (perp=7.699, rec=0.062, cos=0.001), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.596 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.632 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.583 (perp=7.699, rec=0.042, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.631 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.595 (perp=7.699, rec=0.054, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.605 (perp=7.699, rec=0.064, cos=0.001), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.591 (perp=7.699, rec=0.050, cos=0.001), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.962 | p: 92.096 | r: 93.980
rouge2     | fm: 63.863 | p: 63.427 | r: 64.235
rougeL     | fm: 80.328 | p: 79.711 | r: 81.069
rougeLsum  | fm: 79.846 | p: 79.123 | r: 80.672
r1fm+r2fm = 156.824

input #28 time: 0:07:29 | total time: 4:01:57


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9992943703711437
highest_index [0]
highest [0.9992943703711437]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9436143040657043 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.9236282706260681 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.9098904132843018 for ['[CLS] persons carmenworm virtualack gems grand likes fries southern [SEP]']
[Init] best rec loss: 0.8565943837165833 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8468968868255615 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 0.8464521765708923 for ['[CLS] lordship buckingham rather postsbor we home wildlife valleygan [SEP]']
[Init] best rec loss: 0.844285249710083 for ['[CLS] downke his heir wantedø degree opposition march head [SEP]']
[Init] best rec loss: 0.8212891221046448 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 0.8188213109970093 for ['[CLS] type attack www estate ambulance + chelsealand out todd [SEP]']
[Init] best rec loss: 0.8150292038917542 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 0.8131462931632996 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 0.8110625147819519 for ['[CLS] tv oil envelope administration taste this engagementuted runs landed [SEP]']
[Init] best perm rec loss: 0.8109373450279236 for ['[CLS] runs administration tv oil this taste landed engagement envelopeuted [SEP]']
[Init] best perm rec loss: 0.8048712015151978 for ['[CLS] taste landed tv this engagementuted runs oil administration envelope [SEP]']
[Init] best perm rec loss: 0.8036940097808838 for ['[CLS] runs taste engagementuted envelope oil this tv landed administration [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.835 (perp=12.317, rec=0.324, cos=0.048), tot_loss_proj:3.952 [t=0.17s]
prediction: ['[CLS] think. faction aspects. meredith sanctions is attraction wasn [SEP]']
[ 100/2000] tot_loss=1.791 (perp=7.744, rec=0.219, cos=0.023), tot_loss_proj:2.983 [t=0.17s]
prediction: ['[CLS] think. believe resident. believe is that evil not [SEP]']
[ 150/2000] tot_loss=1.841 (perp=8.128, rec=0.201, cos=0.015), tot_loss_proj:3.068 [t=0.17s]
prediction: ['[CLS] also. believe resident. believe is that evil not [SEP]']
[ 200/2000] tot_loss=1.744 (perp=7.841, rec=0.168, cos=0.008), tot_loss_proj:3.044 [t=0.17s]
prediction: ['[CLS] i also believe resident. believe is that evil not [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.599 (perp=7.246, rec=0.140, cos=0.010), tot_loss_proj:2.734 [t=0.17s]
prediction: ['[CLS] i also believe that believe believe it resident evil not [SEP]']
[ 300/2000] tot_loss=1.555 (perp=7.246, rec=0.100, cos=0.006), tot_loss_proj:2.720 [t=0.17s]
prediction: ['[CLS] i also believe that believe believe it resident evil not [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.810 (perp=8.521, rec=0.100, cos=0.005), tot_loss_proj:2.590 [t=0.19s]
prediction: ['[CLS] i also faction that believe it believe resident evil not [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.713 (perp=8.024, rec=0.103, cos=0.006), tot_loss_proj:2.449 [t=0.21s]
prediction: ['[CLS] i also believe that faction it believe resident evil not [SEP]']
[ 450/2000] tot_loss=1.461 (perp=6.817, rec=0.094, cos=0.004), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] i also believe that. it believe resident evil not [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.331 (perp=6.191, rec=0.088, cos=0.004), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] i also believe that believe it. resident evil not [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.576 (perp=7.331, rec=0.104, cos=0.007), tot_loss_proj:2.559 [t=0.17s]
prediction: ['[CLS] i also believe that believe it faction not resident evil [SEP]']
[ 600/2000] tot_loss=1.301 (perp=6.036, rec=0.090, cos=0.004), tot_loss_proj:2.789 [t=0.17s]
prediction: ['[CLS] i also believe that believe it! not resident evil [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.274 (perp=5.877, rec=0.095, cos=0.004), tot_loss_proj:2.635 [t=0.17s]
prediction: ['[CLS] i also believe that believe it. not resident evil [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.167 (perp=5.383, rec=0.086, cos=0.004), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
[ 750/2000] tot_loss=1.167 (perp=5.383, rec=0.086, cos=0.004), tot_loss_proj:2.386 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.168 (perp=5.383, rec=0.087, cos=0.004), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.162 (perp=5.383, rec=0.082, cos=0.004), tot_loss_proj:2.377 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
[ 900/2000] tot_loss=1.159 (perp=5.383, rec=0.079, cos=0.004), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.166 (perp=5.383, rec=0.086, cos=0.004), tot_loss_proj:2.383 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.162 (perp=5.383, rec=0.082, cos=0.004), tot_loss_proj:2.384 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
[1050/2000] tot_loss=1.156 (perp=5.383, rec=0.076, cos=0.004), tot_loss_proj:2.378 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.162 (perp=5.383, rec=0.082, cos=0.004), tot_loss_proj:2.375 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.164 (perp=5.383, rec=0.084, cos=0.004), tot_loss_proj:2.386 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
[1200/2000] tot_loss=1.154 (perp=5.383, rec=0.073, cos=0.004), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.160 (perp=5.383, rec=0.079, cos=0.004), tot_loss_proj:2.379 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.152 (perp=5.383, rec=0.072, cos=0.004), tot_loss_proj:2.381 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
[1350/2000] tot_loss=1.164 (perp=5.383, rec=0.084, cos=0.004), tot_loss_proj:2.378 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.154 (perp=5.383, rec=0.074, cos=0.004), tot_loss_proj:2.378 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.160 (perp=5.383, rec=0.080, cos=0.004), tot_loss_proj:2.381 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
[1500/2000] tot_loss=1.163 (perp=5.383, rec=0.083, cos=0.004), tot_loss_proj:2.377 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.160 (perp=5.383, rec=0.080, cos=0.004), tot_loss_proj:2.375 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.158 (perp=5.383, rec=0.078, cos=0.003), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
[1650/2000] tot_loss=1.161 (perp=5.383, rec=0.081, cos=0.003), tot_loss_proj:2.381 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.153 (perp=5.383, rec=0.073, cos=0.003), tot_loss_proj:2.379 [t=0.19s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.152 (perp=5.383, rec=0.072, cos=0.003), tot_loss_proj:2.381 [t=0.19s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
[1800/2000] tot_loss=1.166 (perp=5.383, rec=0.086, cos=0.003), tot_loss_proj:2.374 [t=0.19s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.162 (perp=5.383, rec=0.081, cos=0.003), tot_loss_proj:2.372 [t=0.19s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.156 (perp=5.383, rec=0.076, cos=0.003), tot_loss_proj:2.375 [t=0.17s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
[1950/2000] tot_loss=1.163 (perp=5.383, rec=0.083, cos=0.003), tot_loss_proj:2.369 [t=0.18s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.151 (perp=5.383, rec=0.071, cos=0.003), tot_loss_proj:2.379 [t=0.19s]
prediction: ['[CLS] i also believe that believe it not resident evil. [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that believe it not resident evil. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 140.909

[Aggregate metrics]:
rouge1     | fm: 92.899 | p: 91.999 | r: 93.828
rouge2     | fm: 63.185 | p: 62.837 | r: 63.735
rougeL     | fm: 79.962 | p: 79.426 | r: 80.709
rougeLsum  | fm: 79.595 | p: 78.905 | r: 80.308
r1fm+r2fm = 156.085

input #29 time: 0:07:31 | total time: 4:09:29


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.999272099459075
highest_index [0]
highest [0.999272099459075]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.9139088988304138 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.8701140880584717 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 0.8681485652923584 for ['[CLS] superior vary lynne [SEP]']
[Init] best rec loss: 0.8041428923606873 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7869581580162048 for ['[CLS] turning expelled squeak [SEP]']
[Init] best rec loss: 0.7338038682937622 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.7189111113548279 for ['[CLS] acceleration council lizard [SEP]']
[Init] best perm rec loss: 0.7150062918663025 for ['[CLS] lizard acceleration council [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.606 (perp=11.807, rec=0.231, cos=0.013), tot_loss_proj:3.726 [t=0.18s]
prediction: ['[CLS]zzability check [SEP]']
[ 100/2000] tot_loss=2.737 (perp=12.949, rec=0.137, cos=0.010), tot_loss_proj:3.721 [t=0.17s]
prediction: ['[CLS]zzability fi [SEP]']
[ 150/2000] tot_loss=2.685 (perp=12.949, rec=0.091, cos=0.005), tot_loss_proj:3.710 [t=0.19s]
prediction: ['[CLS]zzability fi [SEP]']
[ 200/2000] tot_loss=2.693 (perp=12.949, rec=0.100, cos=0.003), tot_loss_proj:3.702 [t=0.19s]
prediction: ['[CLS]zzability fi [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.998 (perp=9.540, rec=0.086, cos=0.005), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.972 (perp=9.540, rec=0.063, cos=0.002), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.002), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.987 (perp=9.540, rec=0.076, cos=0.003), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.973 (perp=9.540, rec=0.064, cos=0.002), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.976 (perp=9.540, rec=0.067, cos=0.002), tot_loss_proj:1.965 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.962 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.972 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.975 (perp=9.540, rec=0.066, cos=0.001), tot_loss_proj:1.978 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.976 (perp=9.540, rec=0.066, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.972 (perp=9.540, rec=0.062, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.965 (perp=9.540, rec=0.055, cos=0.001), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.989 (perp=9.540, rec=0.080, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.966 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.963 (perp=9.540, rec=0.054, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.981 (perp=9.540, rec=0.071, cos=0.001), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.984 (perp=9.540, rec=0.075, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.969 (perp=9.540, rec=0.060, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.972 (perp=9.540, rec=0.063, cos=0.001), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.973 (perp=9.540, rec=0.063, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.968 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.961 (perp=9.540, rec=0.052, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.958 (perp=9.540, rec=0.049, cos=0.001), tot_loss_proj:1.975 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.965 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.968 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.986 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.978 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.962 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.971 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.965 (perp=9.540, rec=0.055, cos=0.001), tot_loss_proj:1.974 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.955 (perp=9.540, rec=0.045, cos=0.001), tot_loss_proj:1.963 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.950 (perp=9.540, rec=0.041, cos=0.001), tot_loss_proj:1.978 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.966 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.968 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.956 (perp=9.540, rec=0.047, cos=0.001), tot_loss_proj:1.962 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.096 | p: 92.281 | r: 94.010
rouge2     | fm: 64.623 | p: 64.241 | r: 64.997
rougeL     | fm: 80.625 | p: 80.014 | r: 81.353
rougeLsum  | fm: 80.132 | p: 79.466 | r: 80.865
r1fm+r2fm = 157.719

input #30 time: 0:07:30 | total time: 4:16:59


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.999339325216174
highest_index [0]
highest [0.999339325216174]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.9432398676872253 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.920174777507782 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8837398290634155 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.8651828765869141 for ['[CLS] billiel arms [SEP]']
[Init] best rec loss: 0.8041785955429077 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 0.8038828372955322 for ['[CLS] robin running artwork [SEP]']
[Init] best perm rec loss: 0.8038730621337891 for ['[CLS] artwork running robin [SEP]']
[Init] best perm rec loss: 0.7982505559921265 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.427 (perp=10.683, rec=0.266, cos=0.024), tot_loss_proj:2.933 [t=0.18s]
prediction: ['[CLS] better vehicle ideas [SEP]']
[ 100/2000] tot_loss=2.105 (perp=9.658, rec=0.159, cos=0.014), tot_loss_proj:2.395 [t=0.19s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.041 (perp=9.638, rec=0.105, cos=0.008), tot_loss_proj:2.549 [t=0.19s]
prediction: ['[CLS] better vehicle a [SEP]']
[ 200/2000] tot_loss=2.010 (perp=9.638, rec=0.081, cos=0.002), tot_loss_proj:2.554 [t=0.19s]
prediction: ['[CLS] better vehicle a [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.602 (perp=7.603, rec=0.078, cos=0.003), tot_loss_proj:1.717 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.594 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.701 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.695 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.702 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.721 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.702 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.704 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.576 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.706 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.703 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.700 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.703 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.704 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.712 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.593 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.586 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.339 | p: 92.521 | r: 94.198
rouge2     | fm: 65.735 | p: 65.356 | r: 66.100
rougeL     | fm: 81.248 | p: 80.630 | r: 81.950
rougeLsum  | fm: 81.024 | p: 80.378 | r: 81.665
r1fm+r2fm = 159.074

input #31 time: 0:07:58 | total time: 4:24:58


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9992521630934186
highest_index [0]
highest [0.9992521630934186]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 1.0409706830978394 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9490888714790344 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 0.8853940367698669 for ['[CLS] ring tracks peculiarzingplay de robinson lay iv elders experience wing [SEP]']
[Init] best rec loss: 0.8810258507728577 for ['[CLS]le force cheers discarded replicateباد clash lighthouse direct remarried narrative words [SEP]']
[Init] best rec loss: 0.8623101115226746 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.8531050086021423 for ['[CLS]ono harlem auckland hanna organization rex force riot back decker mud tune [SEP]']
[Init] best rec loss: 0.8450931906700134 for ['[CLS] palaceshire athletic th funds lilith bio circlecting thomas cake natalie [SEP]']
[Init] best perm rec loss: 0.8438608646392822 for ['[CLS] athletic palace th thomasshire bio cake circle lilith fundscting natalie [SEP]']
[Init] best perm rec loss: 0.842842161655426 for ['[CLS] cake funds lilith athletic thshire biocting natalie palace circle thomas [SEP]']
[Init] best perm rec loss: 0.8413686156272888 for ['[CLS] th natalie circlecting thomas funds bio lilith palace cakeshire athletic [SEP]']
[Init] best perm rec loss: 0.8397578001022339 for ['[CLS]cting lilith thomas cake bio athleticshire natalie th circle palace funds [SEP]']
[Init] best perm rec loss: 0.8387935161590576 for ['[CLS] cakecting natalie bio lilith athletic th thomas circle palaceshire funds [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.683 (perp=12.117, rec=0.255, cos=0.004), tot_loss_proj:3.513 [t=0.17s]
prediction: ['[CLS] brandful release accessible to com accessible stories easily installations absolutely emotion [SEP]']
[ 100/2000] tot_loss=2.529 (perp=11.638, rec=0.197, cos=0.004), tot_loss_proj:3.728 [t=0.17s]
prediction: ['[CLS] brand with easily accessibleonate withonate storiesel installations almostonate [SEP]']
[ 150/2000] tot_loss=2.325 (perp=10.885, rec=0.145, cos=0.002), tot_loss_proj:3.484 [t=0.17s]
prediction: ['[CLS] pull together easily accessibleonate withonate stories pull installations resonate [SEP]']
[ 200/2000] tot_loss=2.489 (perp=11.765, rec=0.133, cos=0.002), tot_loss_proj:3.333 [t=0.17s]
prediction: ['[CLS] pull together easily accessibleonate thatonate stories pull writer resonate [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.390 (perp=11.366, rec=0.115, cos=0.002), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS] pull together easily accessibleonateonate stories that pull writerundonate [SEP]']
[ 300/2000] tot_loss=2.227 (perp=10.596, rec=0.105, cos=0.002), tot_loss_proj:2.762 [t=0.17s]
prediction: ['[CLS] pull together easily accessible withonate stories that pull writerundonate [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.158 (perp=10.348, rec=0.087, cos=0.002), tot_loss_proj:3.572 [t=0.17s]
prediction: ['[CLS] pull together easily accessible writer withity stories that pullundonate [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.049 (perp=9.708, rec=0.105, cos=0.002), tot_loss_proj:2.367 [t=0.17s]
prediction: ['[CLS] pull together easily accessible writer with stories that resundityonate [SEP]']
[ 450/2000] tot_loss=2.024 (perp=9.708, rec=0.080, cos=0.002), tot_loss_proj:2.371 [t=0.17s]
prediction: ['[CLS] pull together easily accessible writer with stories that resundityonate [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.745 (perp=8.300, rec=0.084, cos=0.002), tot_loss_proj:2.300 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories with stories that resonateityund [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.605 (perp=7.612, rec=0.081, cos=0.002), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories with stories that resonateundity [SEP]']
[ 600/2000] tot_loss=1.595 (perp=7.612, rec=0.071, cos=0.002), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories with stories that resonateundity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.889 (perp=9.058, rec=0.076, cos=0.002), tot_loss_proj:2.305 [t=0.17s]
prediction: ['[CLS] pull together easily accessible prof with stories that resonateundity [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.823 (perp=8.716, rec=0.078, cos=0.002), tot_loss_proj:2.623 [t=0.17s]
prediction: ['[CLS] pull together easily accessible with stories that resonateologiesundity [SEP]']
[ 750/2000] tot_loss=1.879 (perp=9.019, rec=0.074, cos=0.002), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] pull together easily accessible with stories that resonatelaidundity [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.757 (perp=8.405, rec=0.075, cos=0.002), tot_loss_proj:2.349 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate withlaidundity [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.729 (perp=8.315, rec=0.064, cos=0.002), tot_loss_proj:2.173 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonatelaid withundity [SEP]']
[ 900/2000] tot_loss=1.733 (perp=8.315, rec=0.068, cos=0.002), tot_loss_proj:2.170 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonatelaid withundity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.732 (perp=8.315, rec=0.067, cos=0.002), tot_loss_proj:2.176 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonatelaid withundity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.730 (perp=8.315, rec=0.065, cos=0.002), tot_loss_proj:2.174 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonatelaid withundity [SEP]']
[1050/2000] tot_loss=1.741 (perp=8.315, rec=0.077, cos=0.002), tot_loss_proj:2.172 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonatelaid withundity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.850 (perp=8.920, rec=0.064, cos=0.002), tot_loss_proj:2.187 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate prof withundity [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.764 (perp=8.448, rec=0.073, cos=0.002), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] pull together easily prof accessible stories that resonate withundity [SEP]']
[1200/2000] tot_loss=1.766 (perp=8.448, rec=0.075, cos=0.002), tot_loss_proj:2.132 [t=0.17s]
prediction: ['[CLS] pull together easily prof accessible stories that resonate withundity [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.399 (perp=6.627, rec=0.072, cos=0.002), tot_loss_proj:1.409 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.392 (perp=6.627, rec=0.065, cos=0.002), tot_loss_proj:1.395 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[1350/2000] tot_loss=1.408 (perp=6.627, rec=0.081, cos=0.002), tot_loss_proj:1.396 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.398 (perp=6.627, rec=0.071, cos=0.002), tot_loss_proj:1.398 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.391 (perp=6.627, rec=0.064, cos=0.002), tot_loss_proj:1.390 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[1500/2000] tot_loss=1.398 (perp=6.627, rec=0.071, cos=0.002), tot_loss_proj:1.406 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.397 (perp=6.627, rec=0.070, cos=0.002), tot_loss_proj:1.398 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.399 (perp=6.627, rec=0.072, cos=0.002), tot_loss_proj:1.403 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[1650/2000] tot_loss=1.398 (perp=6.627, rec=0.071, cos=0.002), tot_loss_proj:1.402 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.393 (perp=6.627, rec=0.066, cos=0.002), tot_loss_proj:1.401 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.390 (perp=6.627, rec=0.063, cos=0.002), tot_loss_proj:1.401 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[1800/2000] tot_loss=1.400 (perp=6.627, rec=0.073, cos=0.002), tot_loss_proj:1.398 [t=0.21s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.391 (perp=6.627, rec=0.064, cos=0.002), tot_loss_proj:1.401 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.403 (perp=6.627, rec=0.076, cos=0.002), tot_loss_proj:1.391 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[1950/2000] tot_loss=1.388 (perp=6.627, rec=0.061, cos=0.002), tot_loss_proj:1.404 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.388 (perp=6.627, rec=0.061, cos=0.002), tot_loss_proj:1.400 [t=0.17s]
prediction: ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.538 | p: 92.801 | r: 94.415
rouge2     | fm: 66.697 | p: 66.335 | r: 67.084
rougeL     | fm: 81.727 | p: 81.109 | r: 82.402
rougeLsum  | fm: 81.756 | p: 81.126 | r: 82.462
r1fm+r2fm = 160.235

input #32 time: 0:07:50 | total time: 4:32:48


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9992763851579931
highest_index [0]
highest [0.9992763851579931]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9998520612716675 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.9732957482337952 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.9511236548423767 for ['[CLS] parent [SEP]']
[Init] best rec loss: 0.9041293859481812 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8212264180183411 for ['[CLS] attributed [SEP]']
[Init] best rec loss: 0.7986159920692444 for ['[CLS] showing [SEP]']
[Init] best rec loss: 0.7904055118560791 for ['[CLS] manifold [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.379 (perp=11.231, rec=0.126, cos=0.007), tot_loss_proj:3.013 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.002), tot_loss_proj:2.403 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.330 (perp=11.231, rec=0.082, cos=0.001), tot_loss_proj:2.404 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.002), tot_loss_proj:2.397 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.002), tot_loss_proj:2.383 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.002), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.305 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.312 (perp=11.231, rec=0.064, cos=0.001), tot_loss_proj:2.387 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.397 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.315 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.403 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.310 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.391 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.317 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.308 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.381 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.396 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.316 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.401 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.316 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.389 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.305 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.402 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.402 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.311 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.403 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.300 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.310 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.400 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.313 (perp=11.231, rec=0.065, cos=0.001), tot_loss_proj:2.399 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.296 (perp=11.231, rec=0.048, cos=0.001), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.314 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.403 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.385 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.293 (perp=11.231, rec=0.045, cos=0.001), tot_loss_proj:2.400 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.317 (perp=11.231, rec=0.069, cos=0.001), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.320 (perp=11.231, rec=0.072, cos=0.001), tot_loss_proj:2.402 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.301 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.404 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.321 (perp=11.231, rec=0.073, cos=0.001), tot_loss_proj:2.398 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.402 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.403 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.394 [t=0.16s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.303 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.395 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.001), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.400 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.758 | p: 92.976 | r: 94.561
rouge2     | fm: 67.437 | p: 67.168 | r: 67.801
rougeL     | fm: 82.251 | p: 81.671 | r: 82.910
rougeLsum  | fm: 82.112 | p: 81.620 | r: 82.777
r1fm+r2fm = 161.195

input #33 time: 0:07:53 | total time: 4:40:42


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9992091879502123
highest_index [0]
highest [0.9992091879502123]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8935192823410034 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8888072967529297 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8439813256263733 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.8383127450942993 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.813098132610321 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.8127062320709229 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.8103282451629639 for ['[CLS] who slightask founderibe field lissa along ship drivers statue worth okay [SEP]']
[Init] best perm rec loss: 0.8098567128181458 for ['[CLS] field slight who statueibe founder lissa shipask drivers okay along worth [SEP]']
[Init] best perm rec loss: 0.808777928352356 for ['[CLS] okayibe statueask slight founder along drivers field worth ship who lissa [SEP]']
[Init] best perm rec loss: 0.8087007999420166 for ['[CLS] okay field ship slight alongask statue lissa founder worth driversibe who [SEP]']
[Init] best perm rec loss: 0.8083059787750244 for ['[CLS] who along lissa ship statue okay slight field driversibe worth founderask [SEP]']
[Init] best perm rec loss: 0.8071286082267761 for ['[CLS] worth founder drivers okay along ship lissa field whoask statueibe slight [SEP]']
[Init] best perm rec loss: 0.8067096471786499 for ['[CLS] founder worth okayaskibe lissa who statue along drivers ship slight field [SEP]']
[Init] best perm rec loss: 0.8060021996498108 for ['[CLS] slight founder fieldaskibe okay lissa ship statue who worth along drivers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.565 (perp=11.182, rec=0.306, cos=0.023), tot_loss_proj:4.072 [t=0.17s]
prediction: ['[CLS] russell confines energy team visual urgency capture overwhelmed viewer. urgency the clinical [SEP]']
[ 100/2000] tot_loss=2.592 (perp=12.039, rec=0.178, cos=0.007), tot_loss_proj:3.535 [t=0.17s]
prediction: ['[CLS] primera in urgency viewer visual urgency build take viewer. urgency extreme extreme [SEP]']
[ 150/2000] tot_loss=2.319 (perp=10.867, rec=0.140, cos=0.005), tot_loss_proj:3.525 [t=0.17s]
prediction: ['[CLS] spider in mind viewer viewer urgency build take viewer and urgency extreme extreme [SEP]']
[ 200/2000] tot_loss=2.412 (perp=11.452, rec=0.118, cos=0.003), tot_loss_proj:3.601 [t=0.17s]
prediction: ['[CLS] spider in mind mind viewer urgency build take viewer and urgency extreme extreme [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.807 (perp=8.536, rec=0.098, cos=0.002), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] mind in mind take the inner urgency build viewer and urgency extreme. [SEP]']
[ 300/2000] tot_loss=1.789 (perp=8.536, rec=0.080, cos=0.002), tot_loss_proj:2.567 [t=0.19s]
prediction: ['[CLS] mind in mind take the inner urgency build viewer and urgency extreme. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.659 (perp=7.917, rec=0.074, cos=0.002), tot_loss_proj:2.183 [t=0.17s]
prediction: ['[CLS] mind in mind take the viewer urgency build viewer and extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.703 (perp=8.109, rec=0.079, cos=0.002), tot_loss_proj:2.313 [t=0.17s]
prediction: ['[CLS] build in mind take the viewer urgency john viewer and extreme urgency. [SEP]']
[ 450/2000] tot_loss=1.706 (perp=8.135, rec=0.078, cos=0.002), tot_loss_proj:2.256 [t=0.19s]
prediction: ['[CLS] build in mind take the inner urgency john viewer and extreme urgency. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.662 (perp=7.805, rec=0.097, cos=0.004), tot_loss_proj:2.496 [t=0.17s]
prediction: ['[CLS] john viewer build in mind take the on urgency and extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.413 (perp=6.536, rec=0.103, cos=0.003), tot_loss_proj:1.936 [t=0.17s]
prediction: ['[CLS] john on build in mind take the viewer urgency and extreme urgency. [SEP]']
[ 600/2000] tot_loss=1.488 (perp=6.959, rec=0.093, cos=0.003), tot_loss_proj:2.098 [t=0.17s]
prediction: ['[CLS] commander on build in mind take the viewer urgency and extreme urgency. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.363 (perp=6.421, rec=0.076, cos=0.003), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.355 (perp=6.421, rec=0.068, cos=0.003), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
[ 750/2000] tot_loss=1.358 (perp=6.421, rec=0.071, cos=0.003), tot_loss_proj:1.904 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.367 (perp=6.421, rec=0.080, cos=0.003), tot_loss_proj:1.897 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.353 (perp=6.421, rec=0.066, cos=0.003), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
[ 900/2000] tot_loss=1.361 (perp=6.421, rec=0.074, cos=0.003), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.353 (perp=6.421, rec=0.066, cos=0.003), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.359 (perp=6.421, rec=0.072, cos=0.003), tot_loss_proj:1.900 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
[1050/2000] tot_loss=1.361 (perp=6.421, rec=0.074, cos=0.003), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.360 (perp=6.421, rec=0.074, cos=0.003), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer urgency and extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.419 (perp=6.720, rec=0.073, cos=0.003), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
[1200/2000] tot_loss=1.418 (perp=6.720, rec=0.071, cos=0.003), tot_loss_proj:1.956 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.414 (perp=6.720, rec=0.067, cos=0.003), tot_loss_proj:1.959 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.415 (perp=6.720, rec=0.068, cos=0.003), tot_loss_proj:1.959 [t=0.20s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
[1350/2000] tot_loss=1.407 (perp=6.720, rec=0.061, cos=0.003), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.423 (perp=6.720, rec=0.076, cos=0.003), tot_loss_proj:1.960 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.408 (perp=6.720, rec=0.062, cos=0.003), tot_loss_proj:1.956 [t=0.19s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
[1500/2000] tot_loss=1.410 (perp=6.720, rec=0.063, cos=0.003), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.411 (perp=6.720, rec=0.065, cos=0.003), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.414 (perp=6.720, rec=0.068, cos=0.003), tot_loss_proj:1.960 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
[1650/2000] tot_loss=1.427 (perp=6.720, rec=0.081, cos=0.003), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.426 (perp=6.720, rec=0.080, cos=0.003), tot_loss_proj:1.956 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.416 (perp=6.720, rec=0.069, cos=0.003), tot_loss_proj:1.954 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
[1800/2000] tot_loss=1.412 (perp=6.720, rec=0.066, cos=0.003), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.421 (perp=6.720, rec=0.074, cos=0.003), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.412 (perp=6.720, rec=0.065, cos=0.003), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
[1950/2000] tot_loss=1.411 (perp=6.720, rec=0.065, cos=0.003), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.415 (perp=6.720, rec=0.069, cos=0.003), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] on john build in mind take the viewer mind and extreme urgency. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 30.769 | p: 30.769 | r: 30.769
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 116.484

[Aggregate metrics]:
rouge1     | fm: 93.536 | p: 92.798 | r: 94.322
rouge2     | fm: 66.417 | p: 66.075 | r: 66.771
rougeL     | fm: 81.931 | p: 81.440 | r: 82.526
rougeLsum  | fm: 81.877 | p: 81.305 | r: 82.487
r1fm+r2fm = 159.953

input #34 time: 0:07:45 | total time: 4:48:28


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9993278544896083
highest_index [0]
highest [0.9993278544896083]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9250960350036621 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.9220249056816101 for ['[CLS] nightstand locality shall shifted pdfish migrated reason features happy statisticsbant medium singled anti but least [SEP] contemptness second mia architecture nonsense departments order deserved ا guardian [MASK] hospitaluts itsried direction soc christmas merely sodiummeral score because [SEP]']
[Init] best rec loss: 0.9155790209770203 for ['[CLS] thousand lack alternative energy fae deservevil denied field outside pages province beauty fade actsar dynamic sole one organized folk ms primary appointment devicedran part zion nightmaresdrive isabellaght intervals singer published sleeper signs lynch, somehow position flow [SEP]']
[Init] best perm rec loss: 0.9139524698257446 for ['[CLS] field thousand published nightmares alternative organized position primary energy one appointment act sole device flow,sardrive somehow lack intervals outside denied sleeper singerght beauty isabella signs fae part lynch zion pages provincevil ms folk fadedran deserve dynamic [SEP]']
[Init] best perm rec loss: 0.9106967449188232 for ['[CLS] province nightmares deserve energy act fae ms singer device field alternative folk denied signs flow thousand outsidedrive beauty intervals somehow published isabella part organized lack primaryght sleeper position lynch,dran solesar zion pages appointment dynamicvil one fade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.592 (perp=11.037, rec=0.369, cos=0.016), tot_loss_proj:3.754 [t=0.17s]
prediction: ['[CLS]... growing 1960s amazing passion bouquet we charles magic they. this felt state creative looks about at 2013 experience with of visual visual perfect your education religion great lead because its john coward " eight especially ramsey great [SEP]. hate [SEP]']
[ 100/2000] tot_loss=2.407 (perp=10.666, rec=0.268, cos=0.006), tot_loss_proj:3.858 [t=0.17s]
prediction: ["[CLS] but : tells'care shape we by hank they'before but andrew beam shown'of greatest experience with about visual director perfect recent makes critic great'about its john coward care'' republic important [SEP], hate [SEP]"]
[ 150/2000] tot_loss=2.187 (perp=9.771, rec=0.229, cos=0.004), tot_loss_proj:3.461 [t=0.17s]
prediction: ["[CLS] but has his'care shape we by before we'before but except will'' of greatest before it of pictures director handsome help makes source great'about itsnation coward care'' position 'nation, ve [SEP]"]
[ 200/2000] tot_loss=2.134 (perp=9.614, rec=0.207, cos=0.004), tot_loss_proj:3.380 [t=0.17s]
prediction: ["[CLS] we has his'seen all us'before we'before but of will'' of latest before clearly from pictures director superb help makesnation great'about hisnation coward care'' rein 'nation, ve [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.936 (perp=8.685, rec=0.196, cos=0.003), tot_loss_proj:2.943 [t=0.17s]
prediction: ["[CLS] we ve his'seen all us'before we'before but and a'' of latest before clearly., director superb help makesnation great'about treenation. care'' rein 'nation, ve [SEP]"]
[ 300/2000] tot_loss=2.040 (perp=9.300, rec=0.177, cos=0.003), tot_loss_proj:3.354 [t=0.17s]
prediction: ["[CLS] we ve his'seen all us'before we'before but directornation'' of latest before still through - director with help makesnation great'about fountainnation from care'' rein 'nation, ve [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.062 (perp=9.259, rec=0.207, cos=0.003), tot_loss_proj:3.481 [t=0.17s]
prediction: ["[CLS] we ve this'seen all us go before we'before but coward the'' when latest or'director ) director with help makes clarity great'about foundernation from care'' rein 'nation. ve [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.797 (perp=8.074, rec=0.178, cos=0.004), tot_loss_proj:3.372 [t=0.17s]
prediction: ["[CLS], makes that'seen all us go without we'before but through the'' of latest or'director. director with help ve teacher great'about foundernation. care'' rein.nation, ve [SEP]"]
[ 450/2000] tot_loss=1.846 (perp=8.395, rec=0.164, cos=0.003), tot_loss_proj:3.459 [t=0.17s]
prediction: ["[CLS], makes this'seen all us go without we'before but throughnation'' extent latest before'director. director with help ve. great'aboutnationnation. care'' rein.nation, ve [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.010 (perp=9.160, rec=0.174, cos=0.004), tot_loss_proj:3.447 [t=0.17s]
prediction: ["[CLS], makes this'seen what us milos without we'before butcture narrative'' ( latest of''. director with help ve. great'aboutnationnation from care'director rein 'nation, ve [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.952 (perp=8.971, rec=0.154, cos=0.003), tot_loss_proj:3.370 [t=0.17s]
prediction: ["[CLS], makes that'seen all us pastor without we'before butcture the'' of latest of'' of director with help ve gift great'aboutnationnation from care'director reinnation., ve [SEP]"]
[ 600/2000] tot_loss=2.079 (perp=9.267, rec=0.223, cos=0.003), tot_loss_proj:3.490 [t=0.17s]
prediction: ["[CLS], makes that'seen what us controls component we'before butndra the'' ( latest before'', director with help ve gift great'aboutnationnation from care'director wouldnation'to ve [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.942 (perp=8.726, rec=0.194, cos=0.003), tot_loss_proj:3.133 [t=0.17s]
prediction: ["[CLS], makes this'seen what us hoffman before we'before butndra the'' ( latest'before ', director with help ve gift great'aboutnationnation from care'director beyondnation'to ve [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.932 (perp=8.713, rec=0.186, cos=0.003), tot_loss_proj:3.125 [t=0.17s]
prediction: ["[CLS], makes this'seen all us hoffman before we'before but emotions beyond'' ( latest'before ', director with help ve gift great'aboutnationnation from care'director thenation. to ve [SEP]"]
[ 750/2000] tot_loss=2.006 (perp=9.130, rec=0.177, cos=0.004), tot_loss_proj:3.485 [t=0.17s]
prediction: ["[CLS] we makes this'seen all us hoffman before we'before but'rein'' ( latest'in ', director with help ve gift great'aboutnationnation from care'darren classicnation. to ve [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.945 (perp=8.844, rec=0.172, cos=0.004), tot_loss_proj:3.069 [t=0.17s]
prediction: ["[CLS] we makes this gift seen all us hoffman before we'before but'rein'' ) latest'in ', director with help ve'great'aboutnationnation from care'darren classicnation. to ve [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.884 (perp=8.617, rec=0.157, cos=0.004), tot_loss_proj:3.019 [t=0.17s]
prediction: ["[CLS] we makes this gift seen all us before we hoffman'before but'rein'' ) latest recent in ', director with help ve'great'aboutnationnation from care'darren thenation. to ve [SEP]"]
[ 900/2000] tot_loss=1.881 (perp=8.617, rec=0.154, cos=0.004), tot_loss_proj:3.020 [t=0.17s]
prediction: ["[CLS] we makes this gift seen all us before we hoffman'before but'rein'' ) latest recent in ', director with help ve'great'aboutnationnation from care'darren thenation. to ve [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.855 (perp=8.522, rec=0.147, cos=0.004), tot_loss_proj:3.033 [t=0.17s]
prediction: ["[CLS] we makes this gift seen all us before we hoffman'before but'rein'' ( latest recent darren ', director with help ve'great'aboutnationnation from care'in classicnation. to ve [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.797 (perp=8.190, rec=0.155, cos=0.004), tot_loss_proj:3.102 [t=0.17s]
prediction: ["[CLS] we makes this gift seen all us before we hoffman'before but'rein'' ('recent darren latest, director with help ve'great'aboutnationnation from care'in thenation. to ve [SEP]"]
[1050/2000] tot_loss=1.970 (perp=8.550, rec=0.255, cos=0.006), tot_loss_proj:3.020 [t=0.17s]
prediction: ["[CLS] we makes this gift seen what us before we hoffman'before but'thumbs'' )'recent ellen latest of director with help ve'great'aboutnationnation from care'in thenation.. ve [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.898 (perp=8.446, rec=0.204, cos=0.004), tot_loss_proj:3.074 [t=0.17s]
prediction: ["[CLS] we makes this gift seen what us before we hoffman'before but'ethics'' anything'recent offices latest with director of help ve'great'aboutnationnation from care'in thenation.. ve [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.850 (perp=8.262, rec=0.194, cos=0.004), tot_loss_proj:3.291 [t=0.17s]
prediction: ["[CLS] we makes this gift seen what us before we hoffman'before but'ethics'anything'recent offices latest with director of'help ve'great'aboutnationnation from care'in thenation.. ve [SEP]"]
[1200/2000] tot_loss=1.832 (perp=8.262, rec=0.175, cos=0.004), tot_loss_proj:3.294 [t=0.17s]
prediction: ["[CLS] we makes this gift seen what us before we hoffman'before but'ethics'anything'recent offices latest with director of'help ve'great'aboutnationnation from care'in thenation.. ve [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.832 (perp=8.254, rec=0.178, cos=0.004), tot_loss_proj:3.080 [t=0.17s]
prediction: ["[CLS] we makes this gift seen what us, we hoffman'before but'ethics'anything. recent. latest with director.'help ve'great'aboutnationnation from care'in classicnation.'ve [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.814 (perp=8.169, rec=0.176, cos=0.004), tot_loss_proj:3.034 [t=0.17s]
prediction: ["[CLS] we makes this gift seen what us, we hoffman'before but'ethics'anything. recent. latest with director ve'help.'great'aboutnationnation from care'in classicnation.'ve [SEP]"]
[1350/2000] tot_loss=1.801 (perp=8.151, rec=0.167, cos=0.004), tot_loss_proj:3.056 [t=0.17s]
prediction: ["[CLS] we makes this gift seen what us, we hoffman'before but'ethics'anything, recent. latest with director ve'help.'great'aboutnationnation from care'in classicnation.'ve [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.739 (perp=7.833, rec=0.169, cos=0.004), tot_loss_proj:3.176 [t=0.17s]
prediction: ["[CLS] we makes this gift seen before us, we hoffman'what but'ethics'anything, recent. latest with director ve'help.'great'aboutnationnation from care'in classicnation.'ve [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.708 (perp=7.689, rec=0.166, cos=0.004), tot_loss_proj:3.301 [t=0.17s]
prediction: ["[CLS] we makes this gift seen before us, we hoffman'what but'ethics'anything, recent. latest with director ve'help.'greatnation'aboutnation from care'in classicnation.'ve [SEP]"]
[1500/2000] tot_loss=1.705 (perp=7.636, rec=0.174, cos=0.004), tot_loss_proj:3.224 [t=0.17s]
prediction: ["[CLS] we makes this gift seen before us, we hoffman'what but'abraham'anything, recent. latest with director ve'help.'greatnation'aboutnation from care'in classicnation.'ve [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.669 (perp=7.538, rec=0.158, cos=0.004), tot_loss_proj:3.211 [t=0.17s]
prediction: ["[CLS] we makes this gift seen before us, we hoffman'what but'abraham'anything. recent, latest with director ve'help.'greatnation'aboutnation from care'in classicnation.'ve [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.666 (perp=7.474, rec=0.167, cos=0.004), tot_loss_proj:3.199 [t=0.19s]
prediction: ["[CLS]'makes this gift seen before us, we hoffman'what but'mouth'anything. recent, latest with director ve'help. we greatnation'aboutnation from care'in classicnation.'ve [SEP]"]
[1650/2000] tot_loss=1.656 (perp=7.474, rec=0.158, cos=0.004), tot_loss_proj:3.201 [t=0.19s]
prediction: ["[CLS]'makes this gift seen before us, we hoffman'what but'mouth'anything. recent, latest with director ve'help. we greatnation'aboutnation from care'in classicnation.'ve [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.687 (perp=7.632, rec=0.157, cos=0.004), tot_loss_proj:3.274 [t=0.17s]
prediction: ["[CLS]'makes this gift seen before us, we hoffman'what but'mouth'anything.yard latest, with director ve'help. we greatnation'aboutnation from care'in classicnation.'ve [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.669 (perp=7.509, rec=0.164, cos=0.004), tot_loss_proj:3.260 [t=0.17s]
prediction: ["[CLS]'makes this gift seen before us, we hoffman'what but'mouth'anything.yard latest, with've'help. we greatnation'aboutnation from care director in classicnation.'ve [SEP]"]
[1800/2000] tot_loss=1.668 (perp=7.576, rec=0.149, cos=0.004), tot_loss_proj:3.237 [t=0.17s]
prediction: ["[CLS]'makes this gift seen before us, we hoffman'what but'abraham'anything.yard latest, with've'help. we greatnation'aboutnation from care director in classicnation.'ve [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.687 (perp=7.576, rec=0.168, cos=0.003), tot_loss_proj:3.239 [t=0.17s]
prediction: ["[CLS]'makes this gift seen before us, we hoffman'what but'abraham'anything.yard latest, with've'help. we greatnation'aboutnation from care director in classicnation.'ve [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.673 (perp=7.576, rec=0.155, cos=0.003), tot_loss_proj:3.236 [t=0.17s]
prediction: ["[CLS]'makes this gift seen before us, we hoffman'what but'abraham'anything.yard latest, with've'help. we greatnation'aboutnation from care director in classicnation.'ve [SEP]"]
[1950/2000] tot_loss=1.679 (perp=7.576, rec=0.160, cos=0.003), tot_loss_proj:3.236 [t=0.17s]
prediction: ["[CLS]'makes this gift seen before us, we hoffman'what but'abraham'anything.yard latest, with've'help. we greatnation'aboutnation from care director in classicnation.'ve [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.671 (perp=7.576, rec=0.153, cos=0.003), tot_loss_proj:3.234 [t=0.17s]
prediction: ["[CLS]'makes this gift seen before us, we hoffman'what but'abraham'anything.yard latest, with've'help. we greatnation'aboutnation from care director in classicnation.'ve [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS], makes that'seen all us pastor without we'before butcture the'' of latest of'' of director with help ve gift great'aboutnationnation from care'director reinnation ', ve [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.250 | p: 62.069 | r: 51.429
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 31.250 | p: 34.483 | r: 28.571
rougeLsum  | fm: 31.250 | p: 34.483 | r: 28.571
r1fm+r2fm = 56.250

[Aggregate metrics]:
rouge1     | fm: 92.550 | p: 92.002 | r: 93.140
rouge2     | fm: 64.448 | p: 64.130 | r: 64.771
rougeL     | fm: 80.615 | p: 80.161 | r: 81.093
rougeLsum  | fm: 80.566 | p: 80.147 | r: 81.051
r1fm+r2fm = 156.998

input #35 time: 0:07:42 | total time: 4:56:11


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.9992842743865827
highest_index [0]
highest [0.9992842743865827]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9986883401870728 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9958099126815796 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 0.9545882940292358 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9252082705497742 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.9223971962928772 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.9177457690238953 for ['[CLS] papa sinclairevsky perhaps [SEP]']
[Init] best rec loss: 0.8233659863471985 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8216447234153748 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 0.8213571906089783 for ['[CLS] bates harassment ramsey cornelius [SEP]']
[Init] best perm rec loss: 0.8175345659255981 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.032 (perp=9.529, rec=0.120, cos=0.006), tot_loss_proj:2.293 [t=0.17s]
prediction: ['[CLS] horribly horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=1.901 (perp=9.148, rec=0.070, cos=0.002), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=1.899 (perp=9.148, rec=0.068, cos=0.002), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=1.898 (perp=9.148, rec=0.067, cos=0.002), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.903 (perp=9.148, rec=0.072, cos=0.002), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 300/2000] tot_loss=1.903 (perp=9.148, rec=0.071, cos=0.002), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.901 (perp=9.148, rec=0.069, cos=0.002), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.545 (perp=7.159, rec=0.110, cos=0.004), tot_loss_proj:1.824 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 450/2000] tot_loss=1.511 (perp=7.159, rec=0.078, cos=0.002), tot_loss_proj:1.837 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.513 (perp=7.159, rec=0.080, cos=0.002), tot_loss_proj:1.829 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.492 (perp=7.159, rec=0.059, cos=0.002), tot_loss_proj:1.821 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 600/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.002), tot_loss_proj:1.842 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.002), tot_loss_proj:1.839 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.501 (perp=7.159, rec=0.068, cos=0.002), tot_loss_proj:1.831 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 750/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.833 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.507 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.836 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.501 (perp=7.159, rec=0.068, cos=0.001), tot_loss_proj:1.824 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 900/2000] tot_loss=1.490 (perp=7.159, rec=0.057, cos=0.001), tot_loss_proj:1.822 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.821 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.500 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.829 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1050/2000] tot_loss=1.498 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.823 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.820 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.827 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1200/2000] tot_loss=1.507 (perp=7.159, rec=0.074, cos=0.001), tot_loss_proj:1.827 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.493 (perp=7.159, rec=0.060, cos=0.001), tot_loss_proj:1.820 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.827 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1350/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.825 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.827 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.494 (perp=7.159, rec=0.061, cos=0.001), tot_loss_proj:1.828 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1500/2000] tot_loss=1.496 (perp=7.159, rec=0.063, cos=0.001), tot_loss_proj:1.827 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.502 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.830 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.503 (perp=7.159, rec=0.070, cos=0.001), tot_loss_proj:1.820 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1650/2000] tot_loss=1.500 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.824 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.503 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.823 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.827 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1800/2000] tot_loss=1.500 (perp=7.159, rec=0.067, cos=0.001), tot_loss_proj:1.818 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.494 (perp=7.159, rec=0.060, cos=0.001), tot_loss_proj:1.821 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.503 (perp=7.159, rec=0.070, cos=0.001), tot_loss_proj:1.822 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1950/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.824 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.501 (perp=7.159, rec=0.067, cos=0.001), tot_loss_proj:1.821 [t=0.17s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] horribly wrong's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.691 | p: 92.121 | r: 93.303
rouge2     | fm: 63.334 | p: 63.021 | r: 63.700
rougeL     | fm: 80.548 | p: 80.125 | r: 81.061
rougeLsum  | fm: 80.485 | p: 79.969 | r: 81.030
r1fm+r2fm = 156.025

input #36 time: 0:07:47 | total time: 5:03:58


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9993688501312639
highest_index [0]
highest [0.9993688501312639]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.9638330340385437 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.9471154808998108 for ['[CLS]quest medical [SEP]']
[Init] best rec loss: 0.8868577480316162 for ['[CLS] fish cape [SEP]']
[Init] best rec loss: 0.809199333190918 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 0.8002374172210693 for ['[CLS] living metacritic [SEP]']
[Init] best rec loss: 0.7850696444511414 for ['[CLS] housemple [SEP]']
[Init] best rec loss: 0.7521161437034607 for ['[CLS] year clarissa [SEP]']
[Init] best rec loss: 0.7474158406257629 for ['[CLS]atal purpose [SEP]']
[Init] best rec loss: 0.7218530774116516 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.7020721435546875 for ['[CLS] cousin many [SEP]']
[Init] best rec loss: 0.6827971339225769 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.6734248399734497 for ['[CLS] cassidystream [SEP]']
[Init] best rec loss: 0.6440885663032532 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6402079463005066 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.044 (perp=12.719, rec=0.340, cos=0.160), tot_loss_proj:4.341 [t=0.17s]
prediction: ['[CLS] eccentric whatsoever [SEP]']
[ 100/2000] tot_loss=2.344 (perp=10.822, rec=0.149, cos=0.030), tot_loss_proj:2.548 [t=0.17s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=2.003 (perp=9.583, rec=0.083, cos=0.003), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.016 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 300/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.987 (perp=9.583, rec=0.069, cos=0.001), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 450/2000] tot_loss=1.972 (perp=9.583, rec=0.054, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.971 (perp=9.583, rec=0.053, cos=0.001), tot_loss_proj:2.003 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 600/2000] tot_loss=1.975 (perp=9.583, rec=0.057, cos=0.001), tot_loss_proj:1.999 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.975 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 750/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.982 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[ 900/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.005 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.985 (perp=9.583, rec=0.067, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.964 (perp=9.583, rec=0.046, cos=0.001), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[1050/2000] tot_loss=1.967 (perp=9.583, rec=0.049, cos=0.001), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1100/2000] tot_loss=1.986 (perp=9.583, rec=0.068, cos=0.001), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1150/2000] tot_loss=1.990 (perp=9.583, rec=0.072, cos=0.001), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[1200/2000] tot_loss=1.973 (perp=9.583, rec=0.056, cos=0.001), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1250/2000] tot_loss=1.981 (perp=9.583, rec=0.063, cos=0.001), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1300/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.017 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
[1350/2000] tot_loss=1.969 (perp=9.583, rec=0.051, cos=0.001), tot_loss_proj:2.019 [t=0.19s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1400/2000] tot_loss=1.989 (perp=9.583, rec=0.071, cos=0.001), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1450/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[1500/2000] tot_loss=1.970 (perp=9.583, rec=0.052, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1550/2000] tot_loss=1.983 (perp=9.583, rec=0.065, cos=0.001), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1600/2000] tot_loss=1.982 (perp=9.583, rec=0.064, cos=0.001), tot_loss_proj:2.014 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
[1650/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1700/2000] tot_loss=1.978 (perp=9.583, rec=0.060, cos=0.001), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1750/2000] tot_loss=1.977 (perp=9.583, rec=0.059, cos=0.001), tot_loss_proj:2.021 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
[1800/2000] tot_loss=1.976 (perp=9.583, rec=0.058, cos=0.001), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1850/2000] tot_loss=1.973 (perp=9.583, rec=0.055, cos=0.001), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[1900/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.013 [t=0.21s]
prediction: ['[CLS] eccentric and [SEP]']
[1950/2000] tot_loss=1.979 (perp=9.583, rec=0.061, cos=0.001), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
[2000/2000] tot_loss=1.980 (perp=9.583, rec=0.062, cos=0.001), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS] eccentric and [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] eccentric and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.935 | p: 92.374 | r: 93.576
rouge2     | fm: 64.023 | p: 63.720 | r: 64.413
rougeL     | fm: 81.106 | p: 80.672 | r: 81.598
rougeLsum  | fm: 81.064 | p: 80.605 | r: 81.617
r1fm+r2fm = 156.959

input #37 time: 0:07:43 | total time: 5:11:41


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9992650714710192
highest_index [0]
highest [0.9992650714710192]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8147767186164856 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8102814555168152 for ['[CLS]st [SEP]']
[Init] best rec loss: 0.8013331294059753 for ['[CLS] federation [SEP]']
[Init] best rec loss: 0.767846405506134 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7035160064697266 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.6697532534599304 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.6317602396011353 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.904 (perp=14.069, rec=0.084, cos=0.006), tot_loss_proj:2.873 [t=0.16s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.882 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.876 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.877 (perp=14.069, rec=0.060, cos=0.003), tot_loss_proj:2.878 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.875 (perp=14.069, rec=0.058, cos=0.002), tot_loss_proj:2.880 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.885 (perp=14.069, rec=0.068, cos=0.003), tot_loss_proj:2.881 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.880 (perp=14.069, rec=0.064, cos=0.002), tot_loss_proj:2.879 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.874 (perp=14.069, rec=0.058, cos=0.002), tot_loss_proj:2.866 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.002), tot_loss_proj:2.864 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.002), tot_loss_proj:2.878 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.870 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.879 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.867 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.879 (perp=14.069, rec=0.064, cos=0.001), tot_loss_proj:2.877 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.871 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.867 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.885 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.882 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.889 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.885 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.870 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.869 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.882 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.876 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.877 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.869 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.864 (perp=14.069, rec=0.049, cos=0.001), tot_loss_proj:2.877 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.876 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.882 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.891 (perp=14.069, rec=0.076, cos=0.001), tot_loss_proj:2.883 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.867 (perp=14.069, rec=0.051, cos=0.001), tot_loss_proj:2.880 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.879 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.892 (perp=14.069, rec=0.077, cos=0.001), tot_loss_proj:2.871 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.881 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.858 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.878 (perp=14.069, rec=0.062, cos=0.001), tot_loss_proj:2.875 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.877 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.868 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.874 (perp=14.069, rec=0.058, cos=0.001), tot_loss_proj:2.875 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.873 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.887 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.865 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.881 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.882 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.884 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.865 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.893 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.869 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.884 (perp=14.069, rec=0.069, cos=0.001), tot_loss_proj:2.870 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.084 | p: 92.573 | r: 93.666
rouge2     | fm: 65.070 | p: 64.775 | r: 65.354
rougeL     | fm: 81.416 | p: 81.077 | r: 81.931
rougeLsum  | fm: 81.533 | p: 81.096 | r: 82.001
r1fm+r2fm = 158.155

input #38 time: 0:08:08 | total time: 5:19:50


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9992526747729698
highest_index [0]
highest [0.9992526747729698]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 1.0125712156295776 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 1.0075626373291016 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 0.9883815050125122 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.9328680038452148 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.9286262392997742 for ['[CLS] ira estimate rabbi relegationbiotic request veronica his baby firedusia property management spring gone dub related location cd age eastern drove than kelly parking [SEP]']
[Init] best rec loss: 0.9213950037956238 for ['[CLS] mutual peopleュ stone intimate reeve templeming freak shores over they sprinterous pro dedication harbour along ll minority [CLS] class raise issue need [SEP]']
[Init] best rec loss: 0.9183960556983948 for ['[CLS] will press caseztty never crimson bohemia journal search band relations behind formula cells main commissioner quick palmer present bible backs duty sogh [SEP]']
[Init] best rec loss: 0.9107301235198975 for ['[CLS] townwind hurt main thenney cassidyowa position jury southpher wash sailhy gordon lab happened bepettive in etc sometimes event [SEP]']
[Init] best perm rec loss: 0.9091352820396423 for ['[CLS]pher happened sailowa jury cassidy gordon main etcwind thentivehy event south sometimes positionney lab be hurtpet wash town in [SEP]']
[Init] best perm rec loss: 0.9068863391876221 for ['[CLS]hy jurypet wash then townney sometimestive hurt eventpher position main happened etc south bewind gordon cassidy labowa sail in [SEP]']
[Init] best perm rec loss: 0.9056861400604248 for ['[CLS] cassidypher eventneypet southowa in gordonwind position sail town thentive wash sometimeshy etc be happened jury lab main hurt [SEP]']
[Init] best perm rec loss: 0.9048677086830139 for ['[CLS] happened event hurt lab be gordonwind in sometimeshy south wash thenney etc cassidy position sailpetpherowa main towntive jury [SEP]']
[Init] best perm rec loss: 0.9048073887825012 for ['[CLS]owa south sailpetneytive main hurt sometimes cassidy town in gordon etc happened be labhy then positionwind jury washpher event [SEP]']
[Init] best perm rec loss: 0.902324914932251 for ['[CLS] be jurypher etc wash position gordon cassidy happened southney sometimesowa in mainhytive lab then eventpet sailwind hurt town [SEP]']
[Init] best perm rec loss: 0.9018852710723877 for ['[CLS] position labney gordon happened mainpher wash thenowa south sail jury inpet cassidy etctive eventwind be hurt sometimes townhy [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.962 (perp=12.609, rec=0.405, cos=0.035), tot_loss_proj:4.107 [t=0.17s]
prediction: ['[CLS] my documentary nothingopsis eliot laboratory styles white natezi glad undergraduate love instantly - power warner each conquest black new culture reforms beta image [SEP]']
[ 100/2000] tot_loss=2.552 (perp=11.324, rec=0.276, cos=0.011), tot_loss_proj:4.231 [t=0.18s]
prediction: ['[CLS] kiss documentary indeed bother bourgeois fully harmony∘ bob strict most conservative ranked find - vice, literally saxon, new culture gives believe once [SEP]']
[ 150/2000] tot_loss=2.756 (perp=12.548, rec=0.238, cos=0.009), tot_loss_proj:4.299 [t=0.19s]
prediction: ['[CLS] kiss documentary conservative julia old give texture ₊ bob hide most conservative conservative finds - variable, monuments hide, new culture gives hide conservative [SEP]']
[ 200/2000] tot_loss=2.353 (perp=10.661, rec=0.213, cos=0.007), tot_loss_proj:4.039 [t=0.21s]
prediction: ['[CLS] my documentary relatively most conservative give texture movie bob hidebound conservative conservative finds - variable, its hide, new texture gives hide conservative [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.062 (perp=9.324, rec=0.191, cos=0.007), tot_loss_proj:3.800 [t=0.21s]
prediction: ['[CLS]. documentary conservative our conservative give texture work then hidebound conservative conservative finds - features, movie hide, new texture gives hide. [SEP]']
[ 300/2000] tot_loss=2.151 (perp=9.911, rec=0.164, cos=0.005), tot_loss_proj:3.888 [t=0.17s]
prediction: ['[CLS] my documentary conservative our conservative give texture book then hidebound conservative conservative finds - effects, movie hide, new texture givesbound. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.886 (perp=8.670, rec=0.148, cos=0.004), tot_loss_proj:3.650 [t=0.17s]
prediction: ['[CLS]. movie conservative our conservative give texture movie then hidebound conservative conservative finds it effects, movie, new reality gives hidebound. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.772 (perp=8.055, rec=0.156, cos=0.006), tot_loss_proj:3.530 [t=0.17s]
prediction: ['[CLS] movie movie conservative our conservative give texture. then hidebound conservative conservative finds it effects, movie, new reality gives hidebound. [SEP]']
[ 450/2000] tot_loss=1.896 (perp=8.728, rec=0.146, cos=0.005), tot_loss_proj:3.558 [t=0.17s]
prediction: ['[CLS] making movie conservative our conservative give texture time then hidebound tradition conservative finds it reality, movie, new reality gives hidebound. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.932 (perp=8.966, rec=0.134, cos=0.005), tot_loss_proj:3.455 [t=0.17s]
prediction: ['[CLS] making movie among our conservative texture. then give andbound tradition conservative finds it reality, movie, new reality gives hidebound. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.847 (perp=8.607, rec=0.123, cos=0.003), tot_loss_proj:3.341 [t=0.17s]
prediction: ['[CLS] making movie one our conservative texture. / give conservativebound tradition and finds it reality, movie, new reality gives hidebound. [SEP]']
[ 600/2000] tot_loss=1.802 (perp=8.469, rec=0.106, cos=0.003), tot_loss_proj:3.205 [t=0.17s]
prediction: ['[CLS] making movie one our conservative texture. and give conservativebound traditions and finds it reality, movie, new reality gives hidebound. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.729 (perp=8.119, rec=0.102, cos=0.003), tot_loss_proj:3.078 [t=0.17s]
prediction: ['[CLS] making movie one our conservative conservative. and give texturebound traditions and finds it reality, movie, new reality gives hidebound. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.745 (perp=8.178, rec=0.106, cos=0.004), tot_loss_proj:3.196 [t=0.17s]
prediction: ['[CLS] making movie one our conservative traditions. and give texture most conservative and finds it reality, movie, new reality gives hidebound and [SEP]']
[ 750/2000] tot_loss=1.736 (perp=8.178, rec=0.098, cos=0.002), tot_loss_proj:3.198 [t=0.17s]
prediction: ['[CLS] making movie one our conservative traditions. and give texture most conservative and finds it reality, movie, new reality gives hidebound and [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.700 (perp=8.052, rec=0.088, cos=0.002), tot_loss_proj:3.108 [t=0.17s]
prediction: ['[CLS] making movie one our conservative traditions. and give texture most conservative and finds it reality, reality, new movie gives hidebound and [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.682 (perp=7.969, rec=0.086, cos=0.002), tot_loss_proj:3.123 [t=0.17s]
prediction: ['[CLS] making movie one our conservative traditions. and give texture most conservative and finds it reality. reality, new movie gives hidebound and [SEP]']
[ 900/2000] tot_loss=1.689 (perp=7.969, rec=0.093, cos=0.002), tot_loss_proj:3.125 [t=0.17s]
prediction: ['[CLS] making movie one our conservative traditions. and give texture most conservative and finds it reality. reality, new movie gives hidebound and [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.578 (perp=7.475, rec=0.081, cos=0.002), tot_loss_proj:2.682 [t=0.17s]
prediction: ['[CLS] making movie one our most conservative and conservative traditions. and give texture finds it reality. reality, new movie gives hidebound and [SEP]']
Attempt swap
[1000/2000] tot_loss=1.578 (perp=7.475, rec=0.081, cos=0.002), tot_loss_proj:2.688 [t=0.17s]
prediction: ['[CLS] making movie one our most conservative and conservative traditions. and give texture finds it reality. reality, new movie gives hidebound and [SEP]']
[1050/2000] tot_loss=1.581 (perp=7.475, rec=0.084, cos=0.002), tot_loss_proj:2.684 [t=0.17s]
prediction: ['[CLS] making movie one our most conservative and conservative traditions. and give texture finds it reality. reality, new movie gives hidebound and [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.549 (perp=7.319, rec=0.083, cos=0.002), tot_loss_proj:2.355 [t=0.17s]
prediction: ['[CLS] gives movie one our most conservative and conservative traditions. and give texture finds it reality. reality, new movie making hidebound and [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.447 (perp=6.754, rec=0.094, cos=0.002), tot_loss_proj:2.303 [t=0.17s]
prediction: ['[CLS] gives movie one our most conservative and conservative traditions. and give texture finds it reality and reality, new movie making hidebound. [SEP]']
[1200/2000] tot_loss=1.436 (perp=6.754, rec=0.083, cos=0.002), tot_loss_proj:2.293 [t=0.17s]
prediction: ['[CLS] gives movie one our most conservative and conservative traditions. and give texture finds it reality and reality, new movie making hidebound. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.423 (perp=6.715, rec=0.078, cos=0.002), tot_loss_proj:2.340 [t=0.19s]
prediction: ['[CLS] movie gives one our most conservative and conservative traditions. and give texture finds it reality and reality, new movie making hidebound. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.421 (perp=6.715, rec=0.076, cos=0.002), tot_loss_proj:2.343 [t=0.17s]
prediction: ['[CLS] movie gives one our most conservative and conservative traditions. and give texture finds it reality and reality, new movie making hidebound. [SEP]']
[1350/2000] tot_loss=1.419 (perp=6.715, rec=0.074, cos=0.002), tot_loss_proj:2.342 [t=0.17s]
prediction: ['[CLS] movie gives one our most conservative and conservative traditions. and give texture finds it reality and reality, new movie making hidebound. [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.431 (perp=6.715, rec=0.086, cos=0.002), tot_loss_proj:2.353 [t=0.17s]
prediction: ['[CLS] movie gives one our most conservative and conservative traditions. and give texture finds it reality and reality, new movie making hidebound. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.428 (perp=6.705, rec=0.085, cos=0.002), tot_loss_proj:2.362 [t=0.17s]
prediction: ['[CLS] gives one movie our most conservative and conservative traditions. and give texture finds it reality and reality, new movie making hidebound. [SEP]']
[1500/2000] tot_loss=1.419 (perp=6.705, rec=0.076, cos=0.002), tot_loss_proj:2.357 [t=0.23s]
prediction: ['[CLS] gives one movie our most conservative and conservative traditions. and give texture finds it reality and reality, new movie making hidebound. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.406 (perp=6.625, rec=0.079, cos=0.002), tot_loss_proj:2.517 [t=0.18s]
prediction: ['[CLS] one movie gives our most conservative and conservative traditions. and give texture finds it reality and reality, new movie making hidebound. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.482 (perp=6.958, rec=0.088, cos=0.002), tot_loss_proj:2.823 [t=0.17s]
prediction: ['[CLS] one gives our most conservative and conservative traditions. and give texture finds it movie reality and reality, new movie making hidebound. [SEP]']
[1650/2000] tot_loss=1.429 (perp=6.763, rec=0.074, cos=0.002), tot_loss_proj:2.856 [t=0.17s]
prediction: ['[CLS] one gives our most conservative and conservative traditions. and give texture finds it - reality and reality, new movie making hidebound. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.433 (perp=6.763, rec=0.078, cos=0.002), tot_loss_proj:2.855 [t=0.17s]
prediction: ['[CLS] one gives our most conservative and conservative traditions. and give texture finds it - reality and reality, new movie making hidebound. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.442 (perp=6.763, rec=0.088, cos=0.002), tot_loss_proj:2.851 [t=0.17s]
prediction: ['[CLS] one gives our most conservative and conservative traditions. and give texture finds it - reality and reality, new movie making hidebound. [SEP]']
[1800/2000] tot_loss=1.434 (perp=6.763, rec=0.079, cos=0.002), tot_loss_proj:2.854 [t=0.19s]
prediction: ['[CLS] one gives our most conservative and conservative traditions. and give texture finds it - reality and reality, new movie making hidebound. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.434 (perp=6.763, rec=0.080, cos=0.002), tot_loss_proj:2.857 [t=0.17s]
prediction: ['[CLS] one gives our most conservative and conservative traditions. and give texture finds it - reality and reality, new movie making hidebound. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.433 (perp=6.763, rec=0.079, cos=0.002), tot_loss_proj:2.856 [t=0.17s]
prediction: ['[CLS] one gives our most conservative and conservative traditions. and give texture finds it - reality and reality, new movie making hidebound. [SEP]']
[1950/2000] tot_loss=1.431 (perp=6.763, rec=0.077, cos=0.002), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] one gives our most conservative and conservative traditions. and give texture finds it - reality and reality, new movie making hidebound. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.428 (perp=6.763, rec=0.073, cos=0.002), tot_loss_proj:2.855 [t=0.17s]
prediction: ['[CLS] one gives our most conservative and conservative traditions. and give texture finds it - reality and reality, new movie making hidebound. [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] one gives our most conservative and conservative traditions. and give texture finds it - reality and reality, new movie making hidebound. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.818 | p: 81.818 | r: 81.818
rouge2     | fm: 23.810 | p: 23.810 | r: 23.810
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 105.628

[Aggregate metrics]:
rouge1     | fm: 92.768 | p: 92.260 | r: 93.370
rouge2     | fm: 64.230 | p: 63.995 | r: 64.545
rougeL     | fm: 80.678 | p: 80.238 | r: 81.180
rougeLsum  | fm: 80.615 | p: 80.151 | r: 81.148
r1fm+r2fm = 156.999

input #39 time: 0:08:20 | total time: 5:28:11


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9993178197074233
highest_index [0]
highest [0.9993178197074233]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9942196607589722 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9584137797355652 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.9366960525512695 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 0.935725748538971 for ['[CLS] alive represents adelaide cinder majestymersfordthes s [SEP]']
[Init] best rec loss: 0.9297330379486084 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 0.9249941110610962 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 0.9139153957366943 for ['[CLS] formula expression groundsoft written used ⇒ution murray [SEP]']
[Init] best rec loss: 0.9052402973175049 for ['[CLS] alloid courtesy [MASK]blood mean gownrarm [SEP]']
[Init] best rec loss: 0.8458519577980042 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.8345496654510498 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.8326913118362427 for ['[CLS] but already lady° georgian kent deciding abd many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.828 (perp=12.673, rec=0.282, cos=0.011), tot_loss_proj:3.544 [t=0.17s]
prediction: ["[CLS] usmmelony horneonyered evidence'sorry [SEP]"]
[ 100/2000] tot_loss=2.406 (perp=11.116, rec=0.171, cos=0.012), tot_loss_proj:3.393 [t=0.17s]
prediction: ['[CLS] usmmelony withony imagery imagery orony [SEP]']
[ 150/2000] tot_loss=2.281 (perp=10.916, rec=0.096, cos=0.002), tot_loss_proj:3.612 [t=0.17s]
prediction: ['[CLS] usmmelony with ph imagery imagery or pu [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.916, rec=0.077, cos=0.002), tot_loss_proj:3.608 [t=0.17s]
prediction: ['[CLS] usmmelony with ph imagery imagery or pu [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.119 (perp=10.139, rec=0.089, cos=0.002), tot_loss_proj:3.499 [t=0.17s]
prediction: ['[CLS] usmmelony with ph pu imagery or music [SEP]']
[ 300/2000] tot_loss=2.105 (perp=10.139, rec=0.075, cos=0.002), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS] usmmelony with ph pu imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.845 (perp=8.843, rec=0.075, cos=0.002), tot_loss_proj:2.139 [t=0.17s]
prediction: ['[CLS] usmmel pu with phony imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.510 (perp=7.172, rec=0.074, cos=0.002), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 450/2000] tot_loss=1.500 (perp=7.172, rec=0.065, cos=0.001), tot_loss_proj:1.504 [t=0.17s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.455 (perp=6.973, rec=0.059, cos=0.001), tot_loss_proj:1.501 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.466 (perp=6.973, rec=0.070, cos=0.001), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 600/2000] tot_loss=1.461 (perp=6.973, rec=0.065, cos=0.001), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.462 (perp=6.973, rec=0.066, cos=0.001), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.453 (perp=6.973, rec=0.057, cos=0.001), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 750/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.451 (perp=6.973, rec=0.055, cos=0.001), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.453 (perp=6.973, rec=0.057, cos=0.001), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 900/2000] tot_loss=1.458 (perp=6.973, rec=0.062, cos=0.001), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.467 (perp=6.973, rec=0.071, cos=0.001), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.466 (perp=6.973, rec=0.070, cos=0.001), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1050/2000] tot_loss=1.455 (perp=6.973, rec=0.059, cos=0.001), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.452 (perp=6.973, rec=0.056, cos=0.001), tot_loss_proj:1.511 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.454 (perp=6.973, rec=0.058, cos=0.001), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1200/2000] tot_loss=1.459 (perp=6.973, rec=0.063, cos=0.001), tot_loss_proj:1.490 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.509 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.458 (perp=6.973, rec=0.062, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1350/2000] tot_loss=1.458 (perp=6.973, rec=0.062, cos=0.001), tot_loss_proj:1.492 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1500/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.463 (perp=6.973, rec=0.067, cos=0.001), tot_loss_proj:1.506 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.454 (perp=6.973, rec=0.058, cos=0.001), tot_loss_proj:1.503 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1650/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.458 (perp=6.973, rec=0.062, cos=0.001), tot_loss_proj:1.492 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.459 (perp=6.973, rec=0.063, cos=0.001), tot_loss_proj:1.502 [t=0.18s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1800/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.505 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.454 (perp=6.973, rec=0.058, cos=0.001), tot_loss_proj:1.504 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.450 (perp=6.973, rec=0.054, cos=0.001), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1950/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.499 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.455 (perp=6.973, rec=0.059, cos=0.001), tot_loss_proj:1.503 [t=0.17s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony music or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 92.973 | p: 92.489 | r: 93.538
rouge2     | fm: 63.832 | p: 63.496 | r: 64.177
rougeL     | fm: 80.454 | p: 80.101 | r: 80.989
rougeLsum  | fm: 80.518 | p: 80.157 | r: 81.016
r1fm+r2fm = 156.805

input #40 time: 0:07:45 | total time: 5:35:56


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.999304507364323
highest_index [0]
highest [0.999304507364323]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9788511395454407 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9516528844833374 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 0.9389455914497375 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 0.9341390132904053 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.928720235824585 for ['[CLS]grapher pr [SEP]']
[Init] best rec loss: 0.924547553062439 for ['[CLS]mler previously [SEP]']
[Init] best rec loss: 0.9216023683547974 for ['[CLS] style tomorrow [SEP]']
[Init] best rec loss: 0.9001919627189636 for ['[CLS] electors mediterranean [SEP]']
[Init] best rec loss: 0.8952876925468445 for ['[CLS] meetswr [SEP]']
[Init] best rec loss: 0.8542567491531372 for ['[CLS] bolivar satisfied [SEP]']
[Init] best rec loss: 0.8272965550422668 for ['[CLS] ways whether [SEP]']
[Init] best perm rec loss: 0.8260568976402283 for ['[CLS] whether ways [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.154 (perp=10.212, rec=0.109, cos=0.003), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.109 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.110 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.107 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.002), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.107 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.088 (perp=10.212, rec=0.045, cos=0.001), tot_loss_proj:2.110 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.110 (perp=10.212, rec=0.066, cos=0.001), tot_loss_proj:2.099 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.117 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.090 (perp=10.212, rec=0.046, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.095 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.116 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.103 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.111 (perp=10.212, rec=0.067, cos=0.001), tot_loss_proj:2.117 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.110 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.102 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.102 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.120 (perp=10.212, rec=0.077, cos=0.001), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.095 (perp=10.212, rec=0.051, cos=0.001), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.096 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.108 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.091 (perp=10.212, rec=0.047, cos=0.001), tot_loss_proj:2.109 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.093 (perp=10.212, rec=0.049, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.119 (perp=10.212, rec=0.075, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.106 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.098 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.096 (perp=10.212, rec=0.052, cos=0.001), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.116 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.097 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.090 (perp=10.212, rec=0.046, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.112 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.114 [t=0.17s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.149 | p: 92.688 | r: 93.699
rouge2     | fm: 64.704 | p: 64.395 | r: 65.042
rougeL     | fm: 81.073 | p: 80.686 | r: 81.539
rougeLsum  | fm: 81.131 | p: 80.724 | r: 81.604
r1fm+r2fm = 157.853

input #41 time: 0:07:17 | total time: 5:43:14


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9993257960966828
highest_index [0]
highest [0.9993257960966828]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9041017889976501 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8518991470336914 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8484532237052917 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.8162120580673218 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.8055222630500793 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.8025503158569336 for ['[CLS] liftedures ever dare kitchenrs attracted scale enough ran cut mapletaking bandabe treatygible international wishpling superseded stages larger assignmentctric offended [SEP]']
[Init] best perm rec loss: 0.7999148368835449 for ['[CLS] wishtakingctric enoughurespling dare maple supersededbe stages ran offended larger treaty scale assignment bandagiblers international kitchen attracted lifted cut ever [SEP]']
[Init] best perm rec loss: 0.7986771464347839 for ['[CLS]be assignment lifted stages largerrs attracted maplepling enough banda offended daretaking treaty ever ran cutures international wish kitchen scalectric supersededgible [SEP]']
[Init] best perm rec loss: 0.7972655892372131 for ['[CLS] wish ran larger kitchen treaty assignmentpling maple offendedures attracted supersededctrictaking ever stages scale bandabe cut enough lifted darersgible international [SEP]']
[Init] best perm rec loss: 0.7947720885276794 for ['[CLS]ctric dare wish treaty stages superseded international scalebegible largerpling banda offendedures kitchen ever cut liftedtakingrs maple ran attracted enough assignment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.829 (perp=12.536, rec=0.304, cos=0.017), tot_loss_proj:3.689 [t=0.17s]
prediction: ['[CLS] stanford thinking forgot forgot on slash runner citesnier mightfarlane suffered obama forgot the / fact cemetery crypt shirt inauguration military japanese video jail assignment [SEP]']
[ 100/2000] tot_loss=2.714 (perp=12.463, rec=0.212, cos=0.009), tot_loss_proj:3.466 [t=0.17s]
prediction: ['[CLS] stanford thinking forgot forgot grabsctable opener include ideas whatever filmmakers poorlyuously forgot as / cu installation back school museum into schoolound civil attraction [SEP]']
[ 150/2000] tot_loss=2.549 (perp=11.866, rec=0.170, cos=0.006), tot_loss_proj:3.337 [t=0.17s]
prediction: ['[CLS] stanford involving forgot forgot anything anything genuine projects honestly anything they poorlyuously forgot as poorlygger project back they attraction into school political posted setting [SEP]']
[ 200/2000] tot_loss=2.452 (perp=11.518, rec=0.144, cos=0.005), tot_loss_proj:3.295 [t=0.17s]
prediction: ['[CLS] stanford involving forgot forgot to anything anything filmmakers honestly anything they poorlyuously forgot as poorlygger project re school attraction into school its posted setting [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.467 (perp=11.029, rec=0.248, cos=0.013), tot_loss_proj:2.992 [t=0.17s]
prediction: ["[CLS] method include forgot to a halfway aimee filmmakers people anything they poorly'forgot as poorly school projectjigger attraction into school political full setting [SEP]"]
[ 300/2000] tot_loss=2.494 (perp=11.656, rec=0.159, cos=0.004), tot_loss_proj:3.276 [t=0.17s]
prediction: ["[CLS] haley include forgot to a halfway halfway filmmakers animals anything they poorly'forgot as poorly school projectjigger attraction into school maximum full setting [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.323 (perp=10.946, rec=0.131, cos=0.003), tot_loss_proj:3.025 [t=0.17s]
prediction: ["[CLS]ered include forgot to a maximum halfway filmmakers animals anything they poorly'forgot asjinery projectjigger attraction into school halfway insane setting [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.410 (perp=11.421, rec=0.123, cos=0.003), tot_loss_proj:3.098 [t=0.17s]
prediction: ["[CLS]gger include forgot to a scary halfway filmmakers animals anything they poorly'forgot asji ′ projectjigger attraction into halfway insane school setting [SEP]"]
[ 450/2000] tot_loss=2.434 (perp=11.563, rec=0.119, cos=0.003), tot_loss_proj:3.406 [t=0.17s]
prediction: ['[CLS]gger include forgot to a scary halfway filmmakers animals anything they poorly s forgot asjieptive project regger attraction into halfway insane school setting [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.391 (perp=11.384, rec=0.112, cos=0.003), tot_loss_proj:3.162 [t=0.17s]
prediction: ['[CLS]gger include forgot to a scary halfway filmmakers animals anything they s forgot poorly asji sox project regger attraction into halfway insane school setting [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.290 (perp=10.873, rec=0.113, cos=0.003), tot_loss_proj:3.179 [t=0.17s]
prediction: ['[CLS]gger forgot to include a scary halfway filmmakers animals anything they s forgot poorly asji skater project regger attraction into fatal insane school setting [SEP]']
[ 600/2000] tot_loss=2.268 (perp=10.841, rec=0.097, cos=0.003), tot_loss_proj:3.193 [t=0.17s]
prediction: ['[CLS]gger forgot to include a scary halfway filmmakers animals anything they s forgot poorly asji concerto project regger attraction into fatal insane school setting [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.221 (perp=10.594, rec=0.099, cos=0.002), tot_loss_proj:3.231 [t=0.17s]
prediction: ['[CLS]gger forgot to include a fatal halfway filmmakers animals anything they s forgot poorly asji concerto project regger attraction into scary insane school setting [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.201 (perp=10.516, rec=0.095, cos=0.002), tot_loss_proj:3.237 [t=0.17s]
prediction: ['[CLS]gger forgot to include a fatal halfway filmmakers animals anything they s forgot poorly asji concerto project regger attraction into scary school insane setting [SEP]']
[ 750/2000] tot_loss=2.163 (perp=10.324, rec=0.096, cos=0.002), tot_loss_proj:3.191 [t=0.17s]
prediction: ['[CLS]gger forgot to include a fatal halfway filmmakers animals anything they s forgot poorly asji concerto project regger attraction into scary school. setting [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.127 (perp=10.168, rec=0.091, cos=0.002), tot_loss_proj:3.272 [t=0.17s]
prediction: ['[CLS]gger forgot to include a fatal halfway filmmakers. anything they s forgot poorly asji concerto project regger attraction into scary school animals setting [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.115 (perp=10.083, rec=0.096, cos=0.003), tot_loss_proj:3.226 [t=0.17s]
prediction: ['[CLS] attraction forgot to include a fatal halfway filmmakers. anything they s forgot poorly asji concerto project regger attraction into scary animals school setting [SEP]']
[ 900/2000] tot_loss=2.110 (perp=10.083, rec=0.091, cos=0.003), tot_loss_proj:3.229 [t=0.17s]
prediction: ['[CLS] attraction forgot to include a fatal halfway filmmakers. anything they s forgot poorly asji concerto project regger attraction into scary animals school setting [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.037 (perp=9.692, rec=0.096, cos=0.003), tot_loss_proj:2.886 [t=0.17s]
prediction: ['[CLS] attraction forgot to include a fatal attraction filmmakers. anything they s forgot poorly asjilellan project regger halfway into scary animals school setting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.997 (perp=9.539, rec=0.086, cos=0.002), tot_loss_proj:2.893 [t=0.17s]
prediction: ['[CLS] attraction forgot to include a fatal attraction filmmakers. anything they s forgot poorly asji concerto project regger halfway into scary animals school setting [SEP]']
[1050/2000] tot_loss=2.002 (perp=9.539, rec=0.092, cos=0.002), tot_loss_proj:2.891 [t=0.17s]
prediction: ['[CLS] attraction forgot to include a fatal attraction filmmakers. anything they s forgot poorly asji concerto project regger halfway into scary animals school setting [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.970 (perp=9.414, rec=0.085, cos=0.002), tot_loss_proj:2.738 [t=0.17s]
prediction: ['[CLS] attraction. forgot to include a fatal attraction filmmakers anything they s forgot poorly asji concerto project regger halfway into scary animals school setting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.975 (perp=9.414, rec=0.089, cos=0.002), tot_loss_proj:2.736 [t=0.17s]
prediction: ['[CLS] attraction. forgot to include a fatal attraction filmmakers anything they s forgot poorly asji concerto project regger halfway into scary animals school setting [SEP]']
[1200/2000] tot_loss=1.977 (perp=9.414, rec=0.091, cos=0.002), tot_loss_proj:2.738 [t=0.17s]
prediction: ['[CLS] attraction. forgot to include a fatal attraction filmmakers anything they s forgot poorly asji concerto project regger halfway into scary animals school setting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.972 (perp=9.414, rec=0.087, cos=0.002), tot_loss_proj:2.737 [t=0.17s]
prediction: ['[CLS] attraction. forgot to include a fatal attraction filmmakers anything they s forgot poorly asji concerto project regger halfway into scary animals school setting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.965 (perp=9.380, rec=0.087, cos=0.002), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] attraction. forgot to include a fatal attraction filmmakers anything they s forgot poorly asjiicient project regger halfway into scary animals school setting [SEP]']
[1350/2000] tot_loss=1.967 (perp=9.380, rec=0.089, cos=0.002), tot_loss_proj:2.730 [t=0.17s]
prediction: ['[CLS] attraction. forgot to include a fatal attraction filmmakers anything they s forgot poorly asjiicient project regger halfway into scary animals school setting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.968 (perp=9.380, rec=0.090, cos=0.002), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] attraction. forgot to include a fatal attraction filmmakers anything they s forgot poorly asjiicient project regger halfway into scary animals school setting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.962 (perp=9.380, rec=0.084, cos=0.002), tot_loss_proj:2.730 [t=0.17s]
prediction: ['[CLS] attraction. forgot to include a fatal attraction filmmakers anything they s forgot poorly asjiicient project regger halfway into scary animals school setting [SEP]']
[1500/2000] tot_loss=1.963 (perp=9.380, rec=0.085, cos=0.002), tot_loss_proj:2.727 [t=0.17s]
prediction: ['[CLS] attraction. forgot to include a fatal attraction filmmakers anything they s forgot poorly asjiicient project regger halfway into scary animals school setting [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.896 (perp=9.010, rec=0.092, cos=0.002), tot_loss_proj:2.751 [t=0.17s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot poorly asjiicient project regger halfway into scary animals school setting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.900 (perp=9.010, rec=0.096, cos=0.002), tot_loss_proj:2.735 [t=0.17s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot poorly asjiicient project regger halfway into scary animals school setting [SEP]']
[1650/2000] tot_loss=1.885 (perp=9.010, rec=0.081, cos=0.002), tot_loss_proj:2.736 [t=0.17s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot poorly asjiicient project regger halfway into scary animals school setting [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.862 (perp=8.889, rec=0.082, cos=0.002), tot_loss_proj:2.700 [t=0.22s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot as poorlyjiicient project regger halfway into scary animals school setting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.868 (perp=8.889, rec=0.088, cos=0.002), tot_loss_proj:2.698 [t=0.17s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot as poorlyjiicient project regger halfway into scary animals school setting [SEP]']
[1800/2000] tot_loss=1.872 (perp=8.889, rec=0.091, cos=0.002), tot_loss_proj:2.700 [t=0.17s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot as poorlyjiicient project regger halfway into scary animals school setting [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.860 (perp=8.838, rec=0.090, cos=0.002), tot_loss_proj:2.587 [t=0.17s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot as poorlyjigger project reicient halfway into scary animals school setting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.852 (perp=8.838, rec=0.083, cos=0.002), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot as poorlyjigger project reicient halfway into scary animals school setting [SEP]']
[1950/2000] tot_loss=1.857 (perp=8.838, rec=0.087, cos=0.002), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot as poorlyjigger project reicient halfway into scary animals school setting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.857 (perp=8.838, rec=0.087, cos=0.002), tot_loss_proj:2.591 [t=0.17s]
prediction: ['[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot as poorlyjigger project reicient halfway into scary animals school setting [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] attraction filmmakers forgot to include a fatal attraction. anything they s forgot poorly asjiicient project regger halfway into scary animals school setting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 79.167 | p: 79.167 | r: 79.167
rouge2     | fm: 26.087 | p: 26.087 | r: 26.087
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 105.254

[Aggregate metrics]:
rouge1     | fm: 92.813 | p: 92.339 | r: 93.416
rouge2     | fm: 63.915 | p: 63.662 | r: 64.201
rougeL     | fm: 80.410 | p: 79.990 | r: 80.816
rougeLsum  | fm: 80.284 | p: 79.841 | r: 80.702
r1fm+r2fm = 156.728

input #42 time: 0:07:33 | total time: 5:50:48


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9992732655805339
highest_index [0]
highest [0.9992732655805339]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9607493281364441 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.9227121472358704 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8925204873085022 for ['[CLS] art window emperor ] [SEP]']
[Init] best rec loss: 0.8689665198326111 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.8586649298667908 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.846950888633728 for ['[CLS] carested royals erica [SEP]']
[Init] best rec loss: 0.8364328742027283 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 0.7888320684432983 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.7853228449821472 for ['[CLS] secondck climbbus [SEP]']
[Init] best rec loss: 0.7806761264801025 for ['[CLS] deserved oxidation council enrollment [SEP]']
[Init] best perm rec loss: 0.7801570892333984 for ['[CLS] oxidation enrollment deserved council [SEP]']
[Init] best perm rec loss: 0.7796530723571777 for ['[CLS] oxidation council enrollment deserved [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.037 (perp=8.970, rec=0.236, cos=0.006), tot_loss_proj:2.800 [t=0.17s]
prediction: ['[CLS] offrcissistic [SEP]']
[ 100/2000] tot_loss=1.132 (perp=5.048, rec=0.118, cos=0.004), tot_loss_proj:1.078 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 150/2000] tot_loss=1.085 (perp=5.048, rec=0.073, cos=0.002), tot_loss_proj:1.084 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 200/2000] tot_loss=1.068 (perp=5.048, rec=0.056, cos=0.002), tot_loss_proj:1.081 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.091 (perp=5.048, rec=0.080, cos=0.002), tot_loss_proj:1.086 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.002), tot_loss_proj:1.070 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.062 (perp=5.048, rec=0.050, cos=0.002), tot_loss_proj:1.082 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.083 (perp=5.048, rec=0.072, cos=0.001), tot_loss_proj:1.092 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.077 (perp=5.048, rec=0.065, cos=0.002), tot_loss_proj:1.082 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.071 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.002), tot_loss_proj:1.071 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.079 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.097 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.077 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.074 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.085 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.074 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.069 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.079 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.076 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.088 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.072 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.062 (perp=5.048, rec=0.051, cos=0.001), tot_loss_proj:1.076 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.074 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.057 (perp=5.048, rec=0.046, cos=0.001), tot_loss_proj:1.075 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.086 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.084 (perp=5.048, rec=0.072, cos=0.001), tot_loss_proj:1.085 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.076 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.001), tot_loss_proj:1.072 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.072 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.081 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.080 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.063 (perp=5.048, rec=0.051, cos=0.001), tot_loss_proj:1.076 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.085 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.076 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.071 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.068 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.085 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.066 (perp=5.048, rec=0.055, cos=0.001), tot_loss_proj:1.076 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.973 | p: 92.540 | r: 93.545
rouge2     | fm: 64.714 | p: 64.437 | r: 65.004
rougeL     | fm: 80.936 | p: 80.574 | r: 81.347
rougeLsum  | fm: 80.816 | p: 80.422 | r: 81.319
r1fm+r2fm = 157.687

input #43 time: 0:07:54 | total time: 5:58:43


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9992417534706349
highest_index [0]
highest [0.9992417534706349]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9856536388397217 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9538675546646118 for ['[CLS] photo led breath sound coin day opponents allies joycevel move throne doin head huge guest perhaps ; his gaze saddle decide willise new great ¡wark grand [SEP]']
[Init] best rec loss: 0.9338456988334656 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.9291354417800903 for ['[CLS]hat since shotsisance morning her wound ji living appealing fifapis aus braun filmed james saved ian service person alias motion inclination age storage hyper heard wind any [SEP]']
[Init] best rec loss: 0.9056149125099182 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best perm rec loss: 0.904999852180481 for ['[CLS] fatty formerly haley ltd raceway nation brow harbor slavehair intent contact hello ; contains contestants heeosi data graphic capacity settled landon blue comedy rock s co illustrated [SEP]']
[Init] best perm rec loss: 0.9043598175048828 for ['[CLS] s comedyosi slave ltd co contestants contains hello graphic settled capacity hee intent ; contact formerly brow landon blue data illustrated rock nationhair harbor haley fatty raceway [SEP]']
[Init] best perm rec loss: 0.903514564037323 for ['[CLS] comedyhair settled intent contestants capacity contact contains hello rock data nation brow formerly ; hee co blueosi graphic fatty illustrated raceway ltd slave s landon haley harbor [SEP]']
[Init] best perm rec loss: 0.90308678150177 for ['[CLS] graphic contains comedy settled raceway ; intent hee hello slave contact fatty brow ltd s capacityosi formerly rock co data illustratedhair harbor contestants landon haley blue nation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.496 (perp=11.224, rec=0.242, cos=0.008), tot_loss_proj:3.141 [t=0.17s]
prediction: ['[CLS]nesian the super. in translation common translation is on actually lostness another lost execution details pretended lost when felony / loses fright routine delay unfortunate routine translation [SEP]']
[ 100/2000] tot_loss=2.121 (perp=9.844, rec=0.148, cos=0.004), tot_loss_proj:2.790 [t=0.17s]
prediction: ['[CLS]mony in routine. translation translation.. is it routine lost. been lost execution. execution lost months fright. slack fright routine ofized premise translation [SEP]']
[ 150/2000] tot_loss=2.023 (perp=9.516, rec=0.116, cos=0.003), tot_loss_proj:2.461 [t=0.17s]
prediction: ['[CLS] hollywood in routine. translation translation.. has which routine lost. been lost execution the executionalic execution fright. slackfest routineizesized premise. [SEP]']
[ 200/2000] tot_loss=2.021 (perp=9.585, rec=0.101, cos=0.003), tot_loss_proj:2.497 [t=0.17s]
prediction: ['[CLS] hollywood in another. execution translation.. has whichalic lost. been lost execution the executionalic execution fright in slackfest routineizesized premise. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.932 (perp=9.208, rec=0.087, cos=0.003), tot_loss_proj:2.495 [t=0.17s]
prediction: ['[CLS] hollywood in another.izes translation.. has whichalic been lost. lostfest the executionalic execution fright in slackfest routineizesizes premise. [SEP]']
[ 300/2000] tot_loss=1.939 (perp=9.238, rec=0.089, cos=0.002), tot_loss_proj:2.517 [t=0.17s]
prediction: ['[CLS] hollywood in another. execution translation.. has whichalic been lost. lostfest the executionalic execution fright in slackfest routineizesizes premise. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.853 (perp=8.897, rec=0.072, cos=0.002), tot_loss_proj:2.368 [t=0.17s]
prediction: ['[CLS] hollywood in another. execution translation.. has whichalic been lost. lostfest the premisealic execution fright in slackfest routineizes absurd execution. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.927 (perp=8.646, rec=0.190, cos=0.008), tot_loss_proj:2.351 [t=0.17s]
prediction: ['[CLS] hollywood in another the translation business.. has which having been lost. lostfest the premisealic execution fright in slack fright routineizes absurd execution. [SEP]']
[ 450/2000] tot_loss=1.834 (perp=8.596, rec=0.111, cos=0.003), tot_loss_proj:2.323 [t=0.21s]
prediction: ['[CLS] hollywood in another the translation business.. has which it been lost. lostfest the premisealic execution fright in slack fright routineizes absurd execution. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.755 (perp=8.244, rec=0.104, cos=0.003), tot_loss_proj:2.208 [t=0.18s]
prediction: ['[CLS] hollywood in another the translation business.. ) which has been lost. lostfest the premisealic execution fright in slack fright routineizes absurd execution. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.776 (perp=8.397, rec=0.094, cos=0.002), tot_loss_proj:2.232 [t=0.19s]
prediction: ['[CLS] hollywood in another the translation fright.. it which has been lost. lostfest the premisealic execution frightizes slack fright routine in absurd execution. [SEP]']
[ 600/2000] tot_loss=1.780 (perp=8.397, rec=0.098, cos=0.002), tot_loss_proj:2.239 [t=0.19s]
prediction: ['[CLS] hollywood in another the translation fright.. it which has been lost. lostfest the premisealic execution frightizes slack fright routine in absurd execution. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.764 (perp=8.348, rec=0.092, cos=0.002), tot_loss_proj:2.213 [t=0.17s]
prediction: ['[CLS] hollywood in another the translation fright.. it which has been lost. lostfest the premisealicizes fright execution slack fright routine in absurd execution. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.735 (perp=8.217, rec=0.090, cos=0.002), tot_loss_proj:2.245 [t=0.17s]
prediction: ['[CLS] hollywood in another the translation fright.. it which has been lost. lostfest absurd premisealicizes fright execution slack fright routine in the execution. [SEP]']
[ 750/2000] tot_loss=1.733 (perp=8.217, rec=0.088, cos=0.002), tot_loss_proj:2.249 [t=0.17s]
prediction: ['[CLS] hollywood in another the translation fright.. it which has been lost. lostfest absurd premisealicizes fright execution slack fright routine in the execution. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.687 (perp=8.015, rec=0.082, cos=0.002), tot_loss_proj:2.227 [t=0.17s]
prediction: ['[CLS] hollywood in another the translationfest.. it which has been lost. lost fright absurd premisealicizes fright execution slack fright routine in the execution. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.671 (perp=7.959, rec=0.078, cos=0.002), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost it absurd premisealicizes fright execution slack fright routine in the the. [SEP]']
[ 900/2000] tot_loss=1.689 (perp=7.959, rec=0.096, cos=0.002), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost it absurd premisealicizes fright execution slack fright routine in the the. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.621 (perp=7.695, rec=0.080, cos=0.002), tot_loss_proj:2.094 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes fright execution slack fright routine in the the. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.530 (perp=7.273, rec=0.073, cos=0.002), tot_loss_proj:1.991 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes the fright execution slack fright routine in the. [SEP]']
[1050/2000] tot_loss=1.546 (perp=7.273, rec=0.089, cos=0.002), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes the fright execution slack fright routine in the. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.489 (perp=7.025, rec=0.082, cos=0.002), tot_loss_proj:1.960 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes the fright execution fright routine in the slack. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.477 (perp=7.025, rec=0.070, cos=0.002), tot_loss_proj:1.946 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes the fright execution fright routine in the slack. [SEP]']
[1200/2000] tot_loss=1.486 (perp=7.025, rec=0.079, cos=0.002), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes the fright execution fright routine in the slack. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.482 (perp=7.025, rec=0.075, cos=0.002), tot_loss_proj:1.952 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes the fright execution fright routine in the slack. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.443 (perp=6.888, rec=0.063, cos=0.002), tot_loss_proj:1.890 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes the fright slack fright routine in the execution. [SEP]']
[1350/2000] tot_loss=1.463 (perp=6.888, rec=0.084, cos=0.002), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes the fright slack fright routine in the execution. [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.450 (perp=6.814, rec=0.085, cos=0.002), tot_loss_proj:1.809 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd premise italicizes the fright slack fright routine in the execution. [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.418 (perp=6.680, rec=0.080, cos=0.002), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost premise absurd italicizes the fright slack fright routine in the execution. [SEP]']
[1500/2000] tot_loss=1.412 (perp=6.680, rec=0.074, cos=0.002), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost premise absurd italicizes the fright slack fright routine in the execution. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.406 (perp=6.680, rec=0.068, cos=0.002), tot_loss_proj:1.790 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost premise absurd italicizes the fright slack fright routine in the execution. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.385 (perp=6.551, rec=0.073, cos=0.002), tot_loss_proj:1.761 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost premise absurd italicizes the fright slack fright in the routine execution. [SEP]']
[1650/2000] tot_loss=1.389 (perp=6.551, rec=0.077, cos=0.002), tot_loss_proj:1.767 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the lost premise absurd italicizes the fright slack fright in the routine execution. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.385 (perp=6.535, rec=0.076, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. it which has been lost. the absurd premise lost italicizes the fright slack fright in the routine execution. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.383 (perp=6.530, rec=0.075, cos=0.002), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. which it has been lost. the absurd premise lost italicizes the fright slack fright in the routine execution. [SEP]']
[1800/2000] tot_loss=1.387 (perp=6.530, rec=0.080, cos=0.002), tot_loss_proj:1.845 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. which it has been lost. the absurd premise lost italicizes the fright slack fright in the routine execution. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.373 (perp=6.502, rec=0.070, cos=0.002), tot_loss_proj:1.785 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. which it has been lost. the lost premise absurd italicizes the fright slack fright in the routine execution. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.368 (perp=6.502, rec=0.066, cos=0.002), tot_loss_proj:1.785 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. which it has been lost. the lost premise absurd italicizes the fright slack fright in the routine execution. [SEP]']
[1950/2000] tot_loss=1.384 (perp=6.502, rec=0.082, cos=0.002), tot_loss_proj:1.782 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. which it has been lost. the lost premise absurd italicizes the fright slack fright in the routine execution. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.379 (perp=6.502, rec=0.076, cos=0.002), tot_loss_proj:1.789 [t=0.17s]
prediction: ['[CLS] hollywood in another translationfest.. which it has been lost. the lost premise absurd italicizes the fright slack fright in the routine execution. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] hollywood in another translationfest.. it which has been lost. the lost absurd it premisealicizes the fright execution fright routine in the slack. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.085 | p: 66.667 | r: 69.565
rouge2     | fm: 17.778 | p: 17.391 | r: 18.182
rougeL     | fm: 42.553 | p: 41.667 | r: 43.478
rougeLsum  | fm: 42.553 | p: 41.667 | r: 43.478
r1fm+r2fm = 85.863

[Aggregate metrics]:
rouge1     | fm: 92.394 | p: 91.930 | r: 92.977
rouge2     | fm: 63.673 | p: 63.475 | r: 63.932
rougeL     | fm: 80.051 | p: 79.628 | r: 80.481
rougeLsum  | fm: 79.971 | p: 79.667 | r: 80.487
r1fm+r2fm = 156.067

input #44 time: 0:07:44 | total time: 6:06:28


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9993986811377396
highest_index [0]
highest [0.9993986811377396]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.9825860261917114 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.9404022693634033 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.9185224771499634 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 0.9133827090263367 for ['[CLS] look greater applications still decay line learning reagan ata alley fact isn starboard thorne portion stepped women5 bee defense producing ł wingtlestation hold net festival [SEP]']
[Init] best rec loss: 0.903794527053833 for ['[CLS] need invitation small cross hot no sk cello deep leader motions harry slide guest pity ash nepal rather ashleyinsman previous walt mclean prix van zoneition [SEP]']
[Init] best rec loss: 0.9032831192016602 for ['[CLS] circussome nj lodge photoᅵ bioome kg morning. have interviewrcus account winfield letofan shy broken man floor sunday sack tuneenter station ll [SEP]']
[Init] best rec loss: 0.8698243498802185 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.8686729073524475 for ['[CLS] skinlanda ( whoa tree ku entrance special five bore2 via curtis operated murmured v status letter few enclosed gentry joan around military single taste footballtiv [SEP]']
[Init] best perm rec loss: 0.8660717606544495 for ['[CLS] single (tiv tree around v entrance letter bore ku operated football enclosed curtislanda five military taste joan status murmured skin2 via few special gentry whoa [SEP]']
[Init] best perm rec loss: 0.8620867133140564 for ['[CLS] five footballtiv2 taste military ku via single skin status few enclosed special curtis murmured whoa entrancelanda ( tree joan around bore letter v gentry operated [SEP]']
[Init] best perm rec loss: 0.861274242401123 for ['[CLS] murmured2 single taste via skintiv curtis whoa tree v football entrancelanda ku joan five status bore letter few around ( enclosed special operated military gentry [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.703 (perp=11.809, rec=0.323, cos=0.019), tot_loss_proj:3.877 [t=0.17s]
prediction: ['[CLS] than× snap fox instructor - movements campaign program sometimes than -lashtylete - than high shelf meetsootevic bowel -. local generally [SEP]']
[ 100/2000] tot_loss=2.391 (perp=10.496, rec=0.282, cos=0.010), tot_loss_proj:2.854 [t=0.17s]
prediction: ['[CLS] than - their fox headlines - movements than program piece than - - nhspe - than - shelf -oot months bowel - - crime exercise [SEP]']
[ 150/2000] tot_loss=2.369 (perp=10.108, rec=0.326, cos=0.022), tot_loss_proj:3.026 [t=0.17s]
prediction: ['[CLS] - - - was gossip - movements than? installation and program - linear ( - than da shelf andliness gi bowelae / scenes exercise [SEP]']
[ 200/2000] tot_loss=2.357 (perp=10.583, rec=0.228, cos=0.012), tot_loss_proj:3.741 [t=0.17s]
prediction: ['[CLS] - - - guns cockpit - movements than? parker elf back - this adventure - than da shelf andious gi bowel eveninged shooting exercise [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.983 (perp=9.030, rec=0.173, cos=0.004), tot_loss_proj:2.917 [t=0.17s]
prediction: ['[CLS] - - - guns boom - movements than? this - on - this shoot - than da shelf,ious gi bowely literary shooting exercise [SEP]']
[ 300/2000] tot_loss=2.090 (perp=9.215, rec=0.240, cos=0.007), tot_loss_proj:2.553 [t=0.17s]
prediction: ['[CLS] - - - kill carry - movements than? this - on - this wearing - this - shelf, long gi boweling physics shooting exercise [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.936 (perp=8.766, rec=0.179, cos=0.004), tot_loss_proj:2.610 [t=0.17s]
prediction: ['[CLS] - - - shoot bow - movements than? this - on - iny - this long shelf, long gi bowel drama technical shoot exercise [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.137 (perp=9.330, rec=0.260, cos=0.011), tot_loss_proj:3.163 [t=0.17s]
prediction: ['[CLS] - - - - shoot - movements than bow this - on, iny - this - shelf, shirleymm?el drama jokes crime exercise [SEP]']
[ 450/2000] tot_loss=1.939 (perp=8.756, rec=0.183, cos=0.004), tot_loss_proj:2.828 [t=0.17s]
prediction: ['[CLS] - - - - shoot - movements than bow this - on - ining - this - shelf, shirleymmickel drama jonah shooting exercise [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.855 (perp=8.429, rec=0.166, cos=0.003), tot_loss_proj:2.602 [t=0.17s]
prediction: ['[CLS] - - - arrow shoot - movements than bow this - on - iny - this - drama, rivalrymmickel shelf shelf shoot exercise [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.819 (perp=8.316, rec=0.153, cos=0.003), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] - - - arrow shoot - movements than in this - on - bowy - this long drama, rivalrymmickel shelf shelf shoot exercise [SEP]']
[ 600/2000] tot_loss=1.807 (perp=8.316, rec=0.141, cos=0.003), tot_loss_proj:2.462 [t=0.17s]
prediction: ['[CLS] - - - arrow shoot - movements than in this - on - bowy - this long drama, rivalrymmickel shelf shelf shoot exercise [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.780 (perp=8.155, rec=0.147, cos=0.003), tot_loss_proj:2.527 [t=0.17s]
prediction: ['[CLS] - - - arrow shoot - movements than in this - on - bowy - this long shoot, rivalrymmickel shelf shelf drama exercise [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.679 (perp=7.601, rec=0.155, cos=0.003), tot_loss_proj:2.347 [t=0.17s]
prediction: ['[CLS] - - - bow shoot - movements than in this - on - bow drama - long long shoot, rivalrymmickel shelf shelfy exercise [SEP]']
[ 750/2000] tot_loss=1.660 (perp=7.601, rec=0.137, cos=0.003), tot_loss_proj:2.352 [t=0.17s]
prediction: ['[CLS] - - - bow shoot - movements than in this - on - bow drama - long long shoot, rivalrymmickel shelf shelfy exercise [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.697 (perp=7.833, rec=0.128, cos=0.002), tot_loss_proj:2.431 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than - this - on - bow drama - bow long shoot, rivalrymmickel shelf shelfy exercise [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.617 (perp=7.385, rec=0.137, cos=0.002), tot_loss_proj:2.452 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow this - on - bow drama - - long shoot, rivalrymmickel shelf shelfy exercise [SEP]']
[ 900/2000] tot_loss=1.605 (perp=7.385, rec=0.126, cos=0.002), tot_loss_proj:2.452 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow this - on - bow drama - - long shoot, rivalrymmickel shelf shelfy exercise [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.596 (perp=7.328, rec=0.128, cos=0.002), tot_loss_proj:2.436 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long shoot, rivalrymmickel shelf shelf - exercise [SEP]']
Attempt swap
[1000/2000] tot_loss=1.663 (perp=7.721, rec=0.117, cos=0.002), tot_loss_proj:2.531 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long crime, rivalrymmickel shelf shelf - exercise [SEP]']
[1050/2000] tot_loss=1.654 (perp=7.721, rec=0.108, cos=0.002), tot_loss_proj:2.534 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long crime, rivalrymmickel shelf shelf - exercise [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.634 (perp=7.589, rec=0.114, cos=0.002), tot_loss_proj:2.499 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
[1150/2000] tot_loss=1.635 (perp=7.589, rec=0.115, cos=0.002), tot_loss_proj:2.503 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
[1200/2000] tot_loss=1.634 (perp=7.589, rec=0.114, cos=0.002), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.633 (perp=7.589, rec=0.113, cos=0.002), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
[1300/2000] tot_loss=1.631 (perp=7.589, rec=0.111, cos=0.002), tot_loss_proj:2.509 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
[1350/2000] tot_loss=1.627 (perp=7.589, rec=0.107, cos=0.002), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
[1400/2000] tot_loss=1.635 (perp=7.589, rec=0.115, cos=0.002), tot_loss_proj:2.516 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
[1450/2000] tot_loss=1.632 (perp=7.589, rec=0.112, cos=0.002), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
[1500/2000] tot_loss=1.623 (perp=7.589, rec=0.103, cos=0.002), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.629 (perp=7.589, rec=0.109, cos=0.002), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
[1600/2000] tot_loss=1.626 (perp=7.589, rec=0.106, cos=0.002), tot_loss_proj:2.519 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
[1650/2000] tot_loss=1.631 (perp=7.589, rec=0.111, cos=0.002), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
[1700/2000] tot_loss=1.626 (perp=7.589, rec=0.107, cos=0.002), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
[1750/2000] tot_loss=1.623 (perp=7.589, rec=0.103, cos=0.002), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
[1800/2000] tot_loss=1.622 (perp=7.589, rec=0.103, cos=0.002), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf shelf - exercise [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.623 (perp=7.566, rec=0.108, cos=0.002), tot_loss_proj:2.472 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf - shelf exercise [SEP]']
Attempt swap
[1900/2000] tot_loss=1.620 (perp=7.566, rec=0.105, cos=0.002), tot_loss_proj:2.471 [t=0.17s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf - shelf exercise [SEP]']
[1950/2000] tot_loss=1.623 (perp=7.566, rec=0.108, cos=0.002), tot_loss_proj:2.474 [t=0.19s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf - shelf exercise [SEP]']
Attempt swap
[2000/2000] tot_loss=1.615 (perp=7.566, rec=0.100, cos=0.002), tot_loss_proj:2.472 [t=0.18s]
prediction: ['[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf - shelf exercise [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] - - - long shoot - movements than bow thisy on - bow drama - - long rivalry, crimemmickel shelf - shelf exercise [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 58.824 | r: 55.556
rouge2     | fm: 6.061 | p: 6.250 | r: 5.882
rougeL     | fm: 40.000 | p: 41.176 | r: 38.889
rougeLsum  | fm: 40.000 | p: 41.176 | r: 38.889
r1fm+r2fm = 63.203

[Aggregate metrics]:
rouge1     | fm: 91.639 | p: 91.211 | r: 92.165
rouge2     | fm: 62.445 | p: 62.212 | r: 62.708
rougeL     | fm: 79.103 | p: 78.719 | r: 79.480
rougeLsum  | fm: 79.053 | p: 78.688 | r: 79.424
r1fm+r2fm = 154.084

input #45 time: 0:07:34 | total time: 6:14:02


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9992703548035418
highest_index [0]
highest [0.9992703548035418]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9911298155784607 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9792498350143433 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 0.9472112059593201 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9385618567466736 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.9372692704200745 for ['[CLS] political m act paperrton fitz [SEP]']
[Init] best rec loss: 0.9318523406982422 for ['[CLS]tyn tillquisite inside chair fixed [SEP]']
[Init] best rec loss: 0.9173271059989929 for ['[CLS] four no and canada reed donald [SEP]']
[Init] best perm rec loss: 0.9158892631530762 for ['[CLS] four donald canada reed and no [SEP]']
[Init] best perm rec loss: 0.9147517085075378 for ['[CLS] donald and four reed no canada [SEP]']
[Init] best perm rec loss: 0.9115938544273376 for ['[CLS] four reed canada and donald no [SEP]']
[Init] best perm rec loss: 0.9111836552619934 for ['[CLS] donald reed canada four no and [SEP]']
[Init] best perm rec loss: 0.9108540415763855 for ['[CLS] and reed donald four no canada [SEP]']
[Init] best perm rec loss: 0.9107707142829895 for ['[CLS] donald and canada no four reed [SEP]']
[Init] best perm rec loss: 0.9106481671333313 for ['[CLS] four reed no donald canada and [SEP]']
[Init] best perm rec loss: 0.9093884825706482 for ['[CLS] and reed no donald canada four [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.749 (perp=12.679, rec=0.209, cos=0.005), tot_loss_proj:3.913 [t=0.17s]
prediction: ['[CLS] slick maryly ensuretitled slick [SEP]']
[ 100/2000] tot_loss=2.240 (perp=10.398, rec=0.158, cos=0.003), tot_loss_proj:2.481 [t=0.17s]
prediction: ['[CLS] slick visually striking slick visually staged [SEP]']
[ 150/2000] tot_loss=2.057 (perp=9.628, rec=0.129, cos=0.003), tot_loss_proj:2.276 [t=0.17s]
prediction: ['[CLS] striking visually striking slick visually staged [SEP]']
[ 200/2000] tot_loss=2.031 (perp=9.628, rec=0.104, cos=0.002), tot_loss_proj:2.274 [t=0.17s]
prediction: ['[CLS] striking visually striking slick visually staged [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.877 (perp=8.946, rec=0.086, cos=0.002), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] slick striking and striking visually staged [SEP]']
[ 300/2000] tot_loss=2.093 (perp=10.018, rec=0.088, cos=0.001), tot_loss_proj:2.357 [t=0.17s]
prediction: ['[CLS] slick striking andly visually staged [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.718 (perp=8.223, rec=0.072, cos=0.001), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS] slickly visually striking and staged [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.539 (perp=7.328, rec=0.071, cos=0.001), tot_loss_proj:1.643 [t=0.21s]
prediction: ['[CLS] slick and visually strikingly staged [SEP]']
[ 450/2000] tot_loss=1.537 (perp=7.328, rec=0.070, cos=0.001), tot_loss_proj:1.652 [t=0.17s]
prediction: ['[CLS] slick and visually strikingly staged [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.394 (perp=6.580, rec=0.076, cos=0.001), tot_loss_proj:1.483 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.391 (perp=6.580, rec=0.074, cos=0.001), tot_loss_proj:1.487 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 600/2000] tot_loss=1.380 (perp=6.580, rec=0.063, cos=0.001), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.378 (perp=6.580, rec=0.060, cos=0.001), tot_loss_proj:1.486 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.385 (perp=6.580, rec=0.068, cos=0.001), tot_loss_proj:1.483 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 750/2000] tot_loss=1.382 (perp=6.580, rec=0.064, cos=0.001), tot_loss_proj:1.481 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.379 (perp=6.580, rec=0.061, cos=0.001), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.389 (perp=6.580, rec=0.072, cos=0.001), tot_loss_proj:1.490 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[ 900/2000] tot_loss=1.369 (perp=6.580, rec=0.052, cos=0.001), tot_loss_proj:1.490 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.387 (perp=6.580, rec=0.070, cos=0.001), tot_loss_proj:1.481 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1000/2000] tot_loss=1.388 (perp=6.580, rec=0.070, cos=0.001), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1050/2000] tot_loss=1.381 (perp=6.580, rec=0.064, cos=0.001), tot_loss_proj:1.480 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1100/2000] tot_loss=1.374 (perp=6.580, rec=0.057, cos=0.001), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.378 (perp=6.580, rec=0.060, cos=0.001), tot_loss_proj:1.507 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1200/2000] tot_loss=1.386 (perp=6.580, rec=0.069, cos=0.001), tot_loss_proj:1.497 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1250/2000] tot_loss=1.389 (perp=6.580, rec=0.071, cos=0.001), tot_loss_proj:1.489 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1300/2000] tot_loss=1.381 (perp=6.580, rec=0.063, cos=0.001), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1350/2000] tot_loss=1.391 (perp=6.580, rec=0.074, cos=0.001), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1400/2000] tot_loss=1.378 (perp=6.580, rec=0.060, cos=0.001), tot_loss_proj:1.492 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1450/2000] tot_loss=1.387 (perp=6.580, rec=0.069, cos=0.001), tot_loss_proj:1.486 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1500/2000] tot_loss=1.383 (perp=6.580, rec=0.066, cos=0.001), tot_loss_proj:1.487 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1550/2000] tot_loss=1.378 (perp=6.580, rec=0.060, cos=0.001), tot_loss_proj:1.493 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1600/2000] tot_loss=1.390 (perp=6.580, rec=0.073, cos=0.001), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1650/2000] tot_loss=1.386 (perp=6.580, rec=0.069, cos=0.001), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.389 (perp=6.580, rec=0.072, cos=0.001), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1750/2000] tot_loss=1.374 (perp=6.580, rec=0.057, cos=0.001), tot_loss_proj:1.488 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1800/2000] tot_loss=1.396 (perp=6.580, rec=0.079, cos=0.001), tot_loss_proj:1.483 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1850/2000] tot_loss=1.379 (perp=6.580, rec=0.062, cos=0.001), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.378 (perp=6.580, rec=0.060, cos=0.001), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
[1950/2000] tot_loss=1.380 (perp=6.580, rec=0.063, cos=0.001), tot_loss_proj:1.492 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Attempt swap
[2000/2000] tot_loss=1.377 (perp=6.580, rec=0.060, cos=0.001), tot_loss_proj:1.481 [t=0.17s]
prediction: ['[CLS] slickly staged and visually striking [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] slickly staged and visually striking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 91.804 | p: 91.353 | r: 92.367
rouge2     | fm: 61.990 | p: 61.682 | r: 62.285
rougeL     | fm: 78.622 | p: 78.329 | r: 79.007
rougeLsum  | fm: 78.583 | p: 78.253 | r: 78.998
r1fm+r2fm = 153.794

input #46 time: 0:07:37 | total time: 6:21:40


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9992059059142622
highest_index [0]
highest [0.9992059059142622]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.6953830718994141 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6925281286239624 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6903731226921082 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6853982210159302 for ['[CLS] purse divine rush [SEP]']
[Init] best rec loss: 0.6800500154495239 for ['[CLS] network biceps truth [SEP]']
[Init] best rec loss: 0.6800178289413452 for ['[CLS] circles hand school [SEP]']
[Init] best rec loss: 0.67453533411026 for ['[CLS] sky next sailed [SEP]']
[Init] best rec loss: 0.6720250844955444 for ['[CLS] salt reality poles [SEP]']
[Init] best perm rec loss: 0.668911337852478 for ['[CLS] poles salt reality [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.737 (perp=11.373, rec=0.342, cos=0.121), tot_loss_proj:3.390 [t=0.17s]
prediction: ['[CLS] transparent transparent commando [SEP]']
[ 100/2000] tot_loss=2.771 (perp=12.775, rec=0.188, cos=0.028), tot_loss_proj:3.557 [t=0.17s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 150/2000] tot_loss=2.728 (perp=12.775, rec=0.126, cos=0.047), tot_loss_proj:3.557 [t=0.17s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 200/2000] tot_loss=2.741 (perp=12.775, rec=0.117, cos=0.068), tot_loss_proj:3.569 [t=0.17s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.672 (perp=12.775, rec=0.099, cos=0.018), tot_loss_proj:3.566 [t=0.17s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 300/2000] tot_loss=2.687 (perp=12.775, rec=0.102, cos=0.030), tot_loss_proj:3.558 [t=0.17s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.679 (perp=12.775, rec=0.106, cos=0.018), tot_loss_proj:3.568 [t=0.17s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.851 (perp=8.803, rec=0.081, cos=0.009), tot_loss_proj:1.827 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.857 (perp=8.803, rec=0.086, cos=0.011), tot_loss_proj:1.832 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.827 (perp=8.803, rec=0.063, cos=0.003), tot_loss_proj:1.839 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.843 (perp=8.803, rec=0.075, cos=0.007), tot_loss_proj:1.828 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.866 (perp=8.803, rec=0.068, cos=0.037), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.820 (perp=8.803, rec=0.056, cos=0.004), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.825 (perp=8.803, rec=0.062, cos=0.003), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.825 (perp=8.803, rec=0.060, cos=0.004), tot_loss_proj:1.839 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.840 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.834 (perp=8.803, rec=0.070, cos=0.003), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.841 (perp=8.803, rec=0.066, cos=0.014), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.853 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.826 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.834 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.835 (perp=8.803, rec=0.073, cos=0.002), tot_loss_proj:1.840 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.817 (perp=8.803, rec=0.055, cos=0.002), tot_loss_proj:1.845 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.823 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.846 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.845 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.816 (perp=8.803, rec=0.054, cos=0.002), tot_loss_proj:1.852 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.815 (perp=8.803, rec=0.053, cos=0.002), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.832 (perp=8.803, rec=0.070, cos=0.002), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.827 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.846 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.814 (perp=8.803, rec=0.052, cos=0.002), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.810 (perp=8.803, rec=0.048, cos=0.002), tot_loss_proj:1.832 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.824 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.834 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.829 (perp=8.803, rec=0.067, cos=0.002), tot_loss_proj:1.845 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.837 (perp=8.803, rec=0.075, cos=0.002), tot_loss_proj:1.830 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.823 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.853 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.821 (perp=8.803, rec=0.059, cos=0.002), tot_loss_proj:1.839 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.981 | p: 91.605 | r: 92.489
rouge2     | fm: 62.613 | p: 62.352 | r: 62.853
rougeL     | fm: 79.176 | p: 78.882 | r: 79.591
rougeLsum  | fm: 78.970 | p: 78.678 | r: 79.390
r1fm+r2fm = 154.593

input #47 time: 0:07:22 | total time: 6:29:03


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9993046234064709
highest_index [0]
highest [0.9993046234064709]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.9481353759765625 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.9344632625579834 for ['[CLS] general deathstle air [SEP]']
[Init] best rec loss: 0.9107456207275391 for ['[CLS] indians * progress elevator [SEP]']
[Init] best rec loss: 0.893878161907196 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 0.8840940594673157 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 0.8556822538375854 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8369787931442261 for ['[CLS]lu natural horizontal work [SEP]']
[Init] best rec loss: 0.796784520149231 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7961894869804382 for ['[CLS] runsdinetute graveyard [SEP]']
[Init] best perm rec loss: 0.7949187159538269 for ['[CLS]tutedine runs graveyard [SEP]']
[Init] best perm rec loss: 0.7926889657974243 for ['[CLS] graveyard runstutedine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.607 (perp=12.047, rec=0.192, cos=0.006), tot_loss_proj:2.843 [t=0.17s]
prediction: ['[CLS] rotting rotting under rotting [SEP]']
[ 100/2000] tot_loss=2.527 (perp=12.071, rec=0.111, cos=0.002), tot_loss_proj:2.701 [t=0.17s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 150/2000] tot_loss=2.680 (perp=12.949, rec=0.089, cos=0.002), tot_loss_proj:2.936 [t=0.17s]
prediction: ['[CLS] rotting under underbell [SEP]']
[ 200/2000] tot_loss=2.677 (perp=12.949, rec=0.085, cos=0.002), tot_loss_proj:2.933 [t=0.17s]
prediction: ['[CLS] rotting under underbell [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.309 (perp=10.623, rec=0.179, cos=0.006), tot_loss_proj:2.542 [t=0.17s]
prediction: ['[CLS]y underbell rotting [SEP]']
[ 300/2000] tot_loss=2.233 (perp=10.623, rec=0.107, cos=0.001), tot_loss_proj:2.563 [t=0.17s]
prediction: ['[CLS]y underbell rotting [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.497 (perp=7.028, rec=0.090, cos=0.001), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.462 (perp=7.028, rec=0.055, cos=0.001), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.731 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.463 (perp=7.028, rec=0.056, cos=0.001), tot_loss_proj:1.734 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.484 (perp=7.028, rec=0.077, cos=0.001), tot_loss_proj:1.727 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.464 (perp=7.028, rec=0.057, cos=0.001), tot_loss_proj:1.734 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.479 (perp=7.028, rec=0.072, cos=0.001), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.461 (perp=7.028, rec=0.054, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.484 (perp=7.028, rec=0.077, cos=0.001), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.457 (perp=7.028, rec=0.050, cos=0.001), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.478 (perp=7.028, rec=0.071, cos=0.001), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.724 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.482 (perp=7.028, rec=0.075, cos=0.001), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.727 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.726 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.734 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.463 (perp=7.028, rec=0.056, cos=0.001), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.457 (perp=7.028, rec=0.050, cos=0.001), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.731 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.461 (perp=7.028, rec=0.054, cos=0.001), tot_loss_proj:1.727 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.465 (perp=7.028, rec=0.058, cos=0.001), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.098 | p: 91.750 | r: 92.569
rouge2     | fm: 61.050 | p: 60.808 | r: 61.420
rougeL     | fm: 79.106 | p: 78.806 | r: 79.469
rougeLsum  | fm: 78.980 | p: 78.666 | r: 79.376
r1fm+r2fm = 153.149

input #48 time: 0:07:25 | total time: 6:36:28


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9992285770800434
highest_index [0]
highest [0.9992285770800434]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8349988460540771 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.7890780568122864 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.7884876728057861 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 0.7864314913749695 for ['[CLS] saline rang market aspects senate brothersona situation trafficking health follows tel [SEP]']
[Init] best rec loss: 0.7806379795074463 for ['[CLS] painted exactly tips haunt unknown going wrong matches until tamillaw ambulance [SEP]']
[Init] best rec loss: 0.7647554874420166 for ['[CLS] where perrin sheepuous he tried things majoranial accompanied ourtani [SEP]']
[Init] best rec loss: 0.7542374730110168 for ['[CLS] trick jose college legs jockey baby tongue processiza during gmina patrick [SEP]']
[Init] best perm rec loss: 0.7533898949623108 for ['[CLS] legs jose trick tongue gmina collegeiza during jockey patrick process baby [SEP]']
[Init] best perm rec loss: 0.7522913813591003 for ['[CLS] tongue during process gmina patrick baby legsiza jose trick college jockey [SEP]']
[Init] best perm rec loss: 0.7503772377967834 for ['[CLS]iza process gmina jose college tongue baby patrick jockey during trick legs [SEP]']
[Init] best perm rec loss: 0.7501202821731567 for ['[CLS] legs college patrick gmina jockey trick baby during jose processiza tongue [SEP]']
[Init] best perm rec loss: 0.74857497215271 for ['[CLS] tongue jose trick jockey legs gmina patrick college babyiza during process [SEP]']
[Init] best perm rec loss: 0.7482708692550659 for ['[CLS] college process legs during trick patrick jockeyiza jose tongue gmina baby [SEP]']
[Init] best perm rec loss: 0.7479612827301025 for ['[CLS] jose baby legs during patrick tongue college process gmina trickiza jockey [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.501 (perp=10.703, rec=0.303, cos=0.058), tot_loss_proj:3.233 [t=0.19s]
prediction: ['[CLS] culture thick should. females population women than of contempt least possibly [SEP]']
[ 100/2000] tot_loss=2.139 (perp=9.666, rec=0.185, cos=0.021), tot_loss_proj:2.936 [t=0.17s]
prediction: ['[CLS] population heat less. single contempt female than of contemptuous could [SEP]']
[ 150/2000] tot_loss=2.270 (perp=10.585, rec=0.142, cos=0.011), tot_loss_proj:2.955 [t=0.17s]
prediction: ['[CLS] population heat could. singleuous female coulduous contempt more possibly [SEP]']
[ 200/2000] tot_loss=2.167 (perp=10.213, rec=0.116, cos=0.009), tot_loss_proj:3.066 [t=0.17s]
prediction: ['[CLS] population record could. singleuous female possibly of contempt more possibly [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.126 (perp=9.970, rec=0.123, cos=0.009), tot_loss_proj:2.976 [t=0.17s]
prediction: ['[CLS] population possibly be. singleuous female already of possibly more contempt [SEP]']
[ 300/2000] tot_loss=2.014 (perp=9.521, rec=0.103, cos=0.007), tot_loss_proj:2.901 [t=0.17s]
prediction: ['[CLS] population possibly be. singleuous female possibly of possibly more contempt [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.123 (perp=10.050, rec=0.107, cos=0.006), tot_loss_proj:2.984 [t=0.17s]
prediction: ['[CLS] population possibly be. singleuous female possibly more could of contempt [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.958 (perp=9.254, rec=0.100, cos=0.006), tot_loss_proj:2.779 [t=0.17s]
prediction: ['[CLS] population possibly be. singleuous female possibly could more of contempt [SEP]']
[ 450/2000] tot_loss=1.947 (perp=9.254, rec=0.091, cos=0.006), tot_loss_proj:2.778 [t=0.17s]
prediction: ['[CLS] population possibly be. singleuous female possibly could more of contempt [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.937 (perp=9.254, rec=0.081, cos=0.005), tot_loss_proj:2.781 [t=0.19s]
prediction: ['[CLS] population possibly be. singleuous female possibly could more of contempt [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.944 (perp=9.254, rec=0.088, cos=0.005), tot_loss_proj:2.775 [t=0.19s]
prediction: ['[CLS] population possibly be. singleuous female possibly could more of contempt [SEP]']
[ 600/2000] tot_loss=1.938 (perp=9.254, rec=0.081, cos=0.006), tot_loss_proj:2.776 [t=0.19s]
prediction: ['[CLS] population possibly be. singleuous female possibly could more of contempt [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.879 (perp=8.881, rec=0.094, cos=0.008), tot_loss_proj:2.846 [t=0.17s]
prediction: ['[CLS] population lex more. singleuous female possibly could be of contempt [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.792 (perp=8.450, rec=0.095, cos=0.008), tot_loss_proj:2.693 [t=0.19s]
prediction: ['[CLS] population more lex. singleuous female possibly could be of contempt [SEP]']
[ 750/2000] tot_loss=1.789 (perp=8.450, rec=0.092, cos=0.007), tot_loss_proj:2.689 [t=0.19s]
prediction: ['[CLS] population more lex. singleuous female possibly could be of contempt [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.787 (perp=8.450, rec=0.090, cos=0.007), tot_loss_proj:2.691 [t=0.17s]
prediction: ['[CLS] population more lex. singleuous female possibly could be of contempt [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.794 (perp=8.450, rec=0.097, cos=0.007), tot_loss_proj:2.686 [t=0.17s]
prediction: ['[CLS] population more lex. singleuous female possibly could be of contempt [SEP]']
[ 900/2000] tot_loss=1.781 (perp=8.450, rec=0.084, cos=0.006), tot_loss_proj:2.690 [t=0.17s]
prediction: ['[CLS] population more lex. singleuous female possibly could be of contempt [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.894 (perp=9.031, rec=0.082, cos=0.006), tot_loss_proj:2.804 [t=0.17s]
prediction: ['[CLS] population morendon. singleuous female possibly could be of contempt [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.778 (perp=8.403, rec=0.092, cos=0.006), tot_loss_proj:2.757 [t=0.17s]
prediction: ['[CLS] population often more. singleuous female possibly could be of contempt [SEP]']
[1050/2000] tot_loss=1.896 (perp=8.991, rec=0.092, cos=0.005), tot_loss_proj:2.826 [t=0.17s]
prediction: ['[CLS] populationndon more. singleuous female possibly could be of contempt [SEP]']
Attempt swap
[1100/2000] tot_loss=1.883 (perp=8.991, rec=0.080, cos=0.005), tot_loss_proj:2.822 [t=0.17s]
prediction: ['[CLS] populationndon more. singleuous female possibly could be of contempt [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.899 (perp=9.031, rec=0.088, cos=0.005), tot_loss_proj:2.800 [t=0.17s]
prediction: ['[CLS] population morendon. singleuous female possibly could be of contempt [SEP]']
[1200/2000] tot_loss=1.900 (perp=9.031, rec=0.089, cos=0.005), tot_loss_proj:2.802 [t=0.17s]
prediction: ['[CLS] population morendon. singleuous female possibly could be of contempt [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.880 (perp=8.991, rec=0.077, cos=0.005), tot_loss_proj:2.825 [t=0.17s]
prediction: ['[CLS] populationndon more. singleuous female possibly could be of contempt [SEP]']
Attempt swap
[1300/2000] tot_loss=1.883 (perp=8.991, rec=0.081, cos=0.004), tot_loss_proj:2.823 [t=0.17s]
prediction: ['[CLS] populationndon more. singleuous female possibly could be of contempt [SEP]']
[1350/2000] tot_loss=1.876 (perp=8.991, rec=0.074, cos=0.004), tot_loss_proj:2.818 [t=0.17s]
prediction: ['[CLS] populationndon more. singleuous female possibly could be of contempt [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.824 (perp=8.691, rec=0.081, cos=0.005), tot_loss_proj:2.797 [t=0.17s]
prediction: ['[CLS] population more. singlendonuous female possibly could be of contempt [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.731 (perp=8.218, rec=0.081, cos=0.006), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
[1500/2000] tot_loss=1.721 (perp=8.218, rec=0.073, cos=0.004), tot_loss_proj:2.571 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
Attempt swap
[1550/2000] tot_loss=1.731 (perp=8.218, rec=0.083, cos=0.004), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
Attempt swap
[1600/2000] tot_loss=1.726 (perp=8.218, rec=0.078, cos=0.004), tot_loss_proj:2.570 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
[1650/2000] tot_loss=1.729 (perp=8.218, rec=0.081, cos=0.004), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
Attempt swap
[1700/2000] tot_loss=1.719 (perp=8.218, rec=0.071, cos=0.004), tot_loss_proj:2.572 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
Attempt swap
[1750/2000] tot_loss=1.732 (perp=8.218, rec=0.084, cos=0.004), tot_loss_proj:2.575 [t=0.18s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
[1800/2000] tot_loss=1.728 (perp=8.218, rec=0.081, cos=0.004), tot_loss_proj:2.572 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
Attempt swap
[1850/2000] tot_loss=1.713 (perp=8.218, rec=0.065, cos=0.004), tot_loss_proj:2.569 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
Attempt swap
[1900/2000] tot_loss=1.722 (perp=8.218, rec=0.074, cos=0.004), tot_loss_proj:2.573 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
[1950/2000] tot_loss=1.721 (perp=8.218, rec=0.074, cos=0.004), tot_loss_proj:2.572 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
Attempt swap
[2000/2000] tot_loss=1.725 (perp=8.218, rec=0.078, cos=0.004), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] possibly more. singlendonuous female population could be of contempt [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] possibly more. singlendonuous female population could be of contempt [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 81.818 | r: 75.000
rouge2     | fm: 9.524 | p: 10.000 | r: 9.091
rougeL     | fm: 52.174 | p: 54.545 | r: 50.000
rougeLsum  | fm: 52.174 | p: 54.545 | r: 50.000
r1fm+r2fm = 87.785

[Aggregate metrics]:
rouge1     | fm: 91.838 | p: 91.540 | r: 92.294
rouge2     | fm: 60.390 | p: 60.231 | r: 60.628
rougeL     | fm: 78.507 | p: 78.222 | r: 78.841
rougeLsum  | fm: 78.383 | p: 78.105 | r: 78.733
r1fm+r2fm = 152.229

input #49 time: 0:07:58 | total time: 6:44:27


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9992840964591766
highest_index [0]
highest [0.9992840964591766]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.9206792116165161 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8376301527023315 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.7573332786560059 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7526006698608398 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best perm rec loss: 0.7520577311515808 for ['[CLS]ieving night byhamlent bridget accordance red crisis [SEP]']
[Init] best perm rec loss: 0.7493540644645691 for ['[CLS]lent accordance bridgethamieving by night crisis red [SEP]']
[Init] best perm rec loss: 0.7488336563110352 for ['[CLS]lent accordance redieving crisis night by bridgetham [SEP]']
[Init] best perm rec loss: 0.7483512163162231 for ['[CLS]hamievinglent accordance by red night bridget crisis [SEP]']
[Init] best perm rec loss: 0.7482115030288696 for ['[CLS] red accordance bridgetlent nightham byieving crisis [SEP]']
[Init] best perm rec loss: 0.7472875714302063 for ['[CLS]lentham accordance bridgetieving by night red crisis [SEP]']
[Init] best perm rec loss: 0.7451678514480591 for ['[CLS]lent crisis red by accordanceham nightieving bridget [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.821 (perp=11.847, rec=0.370, cos=0.081), tot_loss_proj:3.864 [t=0.16s]
prediction: ['[CLS] once bad clever thereby often pardon unknown genius handicap [SEP]']
[ 100/2000] tot_loss=2.621 (perp=11.383, rec=0.297, cos=0.047), tot_loss_proj:3.617 [t=0.18s]
prediction: ['[CLS] english what clever ` what called grand catherine half [SEP]']
[ 150/2000] tot_loss=2.632 (perp=11.589, rec=0.279, cos=0.036), tot_loss_proj:3.429 [t=0.17s]
prediction: ['[CLS] english what clever ` what call by catherine half [SEP]']
[ 200/2000] tot_loss=2.411 (perp=10.826, rec=0.220, cos=0.025), tot_loss_proj:3.314 [t=0.17s]
prediction: ['[CLS] english what clever ` english call by catherine half [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.254 (perp=10.367, rec=0.157, cos=0.024), tot_loss_proj:3.456 [t=0.18s]
prediction: ['[CLS] what english clever ` english call by calendar half [SEP]']
[ 300/2000] tot_loss=2.219 (perp=10.367, rec=0.133, cos=0.013), tot_loss_proj:3.459 [t=0.17s]
prediction: ['[CLS] what english clever ` english call by calendar half [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.081 (perp=9.768, rec=0.118, cos=0.009), tot_loss_proj:3.360 [t=0.17s]
prediction: ['[CLS] what english clever ` english call calendar by half [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.048 (perp=9.593, rec=0.121, cos=0.009), tot_loss_proj:2.910 [t=0.17s]
prediction: ['[CLS] what english ` english call christians clever by half [SEP]']
[ 450/2000] tot_loss=2.087 (perp=9.845, rec=0.112, cos=0.006), tot_loss_proj:2.507 [t=0.17s]
prediction: ['[CLS] what english ` english call unfortunately clever by half [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.878 (perp=8.851, rec=0.101, cos=0.008), tot_loss_proj:2.438 [t=0.17s]
prediction: ['[CLS] what radicals ` english call english clever by half [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.899 (perp=9.009, rec=0.092, cos=0.006), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] what unfortunately ` english call english clever by half [SEP]']
[ 600/2000] tot_loss=1.907 (perp=9.009, rec=0.101, cos=0.004), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] what unfortunately ` english call english clever by half [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.927 (perp=9.125, rec=0.098, cos=0.004), tot_loss_proj:2.587 [t=0.17s]
prediction: ['[CLS] what too ` english call english clever by half [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.912 (perp=9.125, rec=0.084, cos=0.003), tot_loss_proj:2.589 [t=0.20s]
prediction: ['[CLS] what too ` english call english clever by half [SEP]']
[ 750/2000] tot_loss=2.049 (perp=9.797, rec=0.087, cos=0.003), tot_loss_proj:2.968 [t=0.17s]
prediction: ['[CLS] what too ` the call english clever by half [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.874 (perp=8.962, rec=0.079, cos=0.003), tot_loss_proj:2.487 [t=0.19s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.865 (perp=8.962, rec=0.070, cos=0.002), tot_loss_proj:2.485 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
[ 900/2000] tot_loss=1.870 (perp=8.962, rec=0.076, cos=0.002), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.858 (perp=8.962, rec=0.064, cos=0.002), tot_loss_proj:2.483 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1000/2000] tot_loss=1.863 (perp=8.962, rec=0.069, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
[1050/2000] tot_loss=1.858 (perp=8.962, rec=0.064, cos=0.002), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1100/2000] tot_loss=1.856 (perp=8.962, rec=0.062, cos=0.002), tot_loss_proj:2.492 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1150/2000] tot_loss=1.855 (perp=8.962, rec=0.061, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
[1200/2000] tot_loss=1.857 (perp=8.962, rec=0.063, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1250/2000] tot_loss=1.858 (perp=8.962, rec=0.064, cos=0.002), tot_loss_proj:2.487 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1300/2000] tot_loss=1.862 (perp=8.962, rec=0.068, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
[1350/2000] tot_loss=1.860 (perp=8.962, rec=0.066, cos=0.002), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1400/2000] tot_loss=1.861 (perp=8.962, rec=0.067, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1450/2000] tot_loss=1.856 (perp=8.962, rec=0.062, cos=0.002), tot_loss_proj:2.487 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
[1500/2000] tot_loss=1.860 (perp=8.962, rec=0.066, cos=0.002), tot_loss_proj:2.492 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1550/2000] tot_loss=1.852 (perp=8.962, rec=0.059, cos=0.002), tot_loss_proj:2.486 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1600/2000] tot_loss=1.861 (perp=8.962, rec=0.067, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
[1650/2000] tot_loss=1.861 (perp=8.962, rec=0.067, cos=0.002), tot_loss_proj:2.495 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1700/2000] tot_loss=1.860 (perp=8.962, rec=0.066, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1750/2000] tot_loss=1.859 (perp=8.962, rec=0.065, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
[1800/2000] tot_loss=1.861 (perp=8.962, rec=0.067, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1850/2000] tot_loss=1.868 (perp=8.962, rec=0.074, cos=0.002), tot_loss_proj:2.491 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[1900/2000] tot_loss=1.858 (perp=8.962, rec=0.064, cos=0.002), tot_loss_proj:2.494 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
[1950/2000] tot_loss=1.856 (perp=8.962, rec=0.062, cos=0.002), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Attempt swap
[2000/2000] tot_loss=1.858 (perp=8.962, rec=0.064, cos=0.002), tot_loss_proj:2.494 [t=0.17s]
prediction: ['[CLS] what too ` call the english clever by half [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what too ` call the english clever by half [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 55.556 | p: 55.556 | r: 55.556
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 155.556

[Aggregate metrics]:
rouge1     | fm: 91.985 | p: 91.634 | r: 92.417
rouge2     | fm: 60.103 | p: 59.941 | r: 60.392
rougeL     | fm: 78.527 | p: 78.284 | r: 78.852
rougeLsum  | fm: 78.534 | p: 78.239 | r: 78.892
r1fm+r2fm = 152.088

input #50 time: 0:08:14 | total time: 6:52:42


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9992548315433463
highest_index [0]
highest [0.9992548315433463]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.826704740524292 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7897737622261047 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7381834387779236 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7270974516868591 for ['[CLS] join paying nonsense thought secret mine sans fields sara stench [SEP]']
[Init] best rec loss: 0.7253291010856628 for ['[CLS] lying acceptance [MASK] longer fence hotel rocking view knocked iaaf [SEP]']
[Init] best rec loss: 0.7200135588645935 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 0.7114751935005188 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 0.7108536958694458 for ['[CLS] symbol blanc australian civil front compact foundation doubt 2018 fitness [SEP]']
[Init] best rec loss: 0.7055902481079102 for ['[CLS] disappointed market in toured literary watching once renamedrak medium [SEP]']
[Init] best perm rec loss: 0.7039530873298645 for ['[CLS] in toured once renamed medium watching market disappointed literaryrak [SEP]']
[Init] best perm rec loss: 0.7036332488059998 for ['[CLS]rak once watching literary renamed medium toured disappointed in market [SEP]']
[Init] best perm rec loss: 0.7021721601486206 for ['[CLS] disappointed toured renamed mediumrak once in watching market literary [SEP]']
[Init] best perm rec loss: 0.7017951011657715 for ['[CLS] toured disappointed in once medium renamed market literary watchingrak [SEP]']
[Init] best perm rec loss: 0.7002806663513184 for ['[CLS] medium market watching toured disappointedrak renamed in once literary [SEP]']
[Init] best perm rec loss: 0.7000938057899475 for ['[CLS] literary renamed toured watching disappointed medium market inrak once [SEP]']
[Init] best perm rec loss: 0.6998263597488403 for ['[CLS] medium toured disappointed once watching renamed marketrak literary in [SEP]']
[Init] best perm rec loss: 0.6994193196296692 for ['[CLS] medium in market watchingrak literary renamed toured disappointed once [SEP]']
[Init] best perm rec loss: 0.6993638277053833 for ['[CLS]rak renamed once watching medium toured disappointed in market literary [SEP]']
[Init] best perm rec loss: 0.6992019414901733 for ['[CLS] watching medium disappointed renamed marketrak in literary once toured [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.723 (perp=11.587, rec=0.330, cos=0.076), tot_loss_proj:3.207 [t=0.17s]
prediction: ['[CLS] sucks should figured into but funny moment sometime exit sucks [SEP]']
[ 100/2000] tot_loss=2.249 (perp=9.863, rec=0.235, cos=0.041), tot_loss_proj:2.869 [t=0.17s]
prediction: ['[CLS] sucks has funny and. funny moment but funny sucks [SEP]']
[ 150/2000] tot_loss=1.687 (perp=7.689, rec=0.137, cos=0.012), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] or has funny, a funny moment but funny sucks [SEP]']
[ 200/2000] tot_loss=1.639 (perp=7.689, rec=0.095, cos=0.007), tot_loss_proj:2.524 [t=0.17s]
prediction: ['[CLS] or has funny, a funny moment but funny sucks [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.574 (perp=7.369, rec=0.093, cos=0.007), tot_loss_proj:2.489 [t=0.18s]
prediction: ['[CLS] or, funny has a funny moment but two sucks [SEP]']
[ 300/2000] tot_loss=1.556 (perp=7.369, rec=0.077, cos=0.005), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] or, funny has a funny moment but two sucks [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.697 (perp=7.548, rec=0.167, cos=0.021), tot_loss_proj:2.259 [t=0.17s]
prediction: ['[CLS] but. [SEP] has a funny moment or two sucks [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.355 (perp=6.214, rec=0.103, cos=0.009), tot_loss_proj:1.658 [t=0.17s]
prediction: ['[CLS] but sucks [SEP] has a funny moment or two. [SEP]']
[ 450/2000] tot_loss=1.340 (perp=6.214, rec=0.090, cos=0.007), tot_loss_proj:1.653 [t=0.17s]
prediction: ['[CLS] but sucks [SEP] has a funny moment or two. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.279 (perp=5.907, rec=0.091, cos=0.007), tot_loss_proj:1.411 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.273 (perp=5.907, rec=0.085, cos=0.007), tot_loss_proj:1.402 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[ 600/2000] tot_loss=1.267 (perp=5.907, rec=0.079, cos=0.006), tot_loss_proj:1.408 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.268 (perp=5.907, rec=0.081, cos=0.006), tot_loss_proj:1.409 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.271 (perp=5.907, rec=0.084, cos=0.006), tot_loss_proj:1.411 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[ 750/2000] tot_loss=1.270 (perp=5.907, rec=0.082, cos=0.006), tot_loss_proj:1.404 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.270 (perp=5.907, rec=0.083, cos=0.006), tot_loss_proj:1.413 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.265 (perp=5.907, rec=0.077, cos=0.006), tot_loss_proj:1.404 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[ 900/2000] tot_loss=1.259 (perp=5.907, rec=0.071, cos=0.006), tot_loss_proj:1.406 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.265 (perp=5.907, rec=0.078, cos=0.006), tot_loss_proj:1.409 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.267 (perp=5.907, rec=0.080, cos=0.006), tot_loss_proj:1.400 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1050/2000] tot_loss=1.267 (perp=5.907, rec=0.079, cos=0.006), tot_loss_proj:1.396 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.269 (perp=5.907, rec=0.081, cos=0.006), tot_loss_proj:1.399 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.268 (perp=5.907, rec=0.081, cos=0.006), tot_loss_proj:1.407 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1200/2000] tot_loss=1.262 (perp=5.907, rec=0.075, cos=0.006), tot_loss_proj:1.400 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.269 (perp=5.907, rec=0.082, cos=0.006), tot_loss_proj:1.398 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.268 (perp=5.907, rec=0.081, cos=0.006), tot_loss_proj:1.395 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1350/2000] tot_loss=1.262 (perp=5.907, rec=0.075, cos=0.006), tot_loss_proj:1.397 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.261 (perp=5.907, rec=0.074, cos=0.006), tot_loss_proj:1.410 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.263 (perp=5.907, rec=0.076, cos=0.006), tot_loss_proj:1.407 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1500/2000] tot_loss=1.264 (perp=5.907, rec=0.077, cos=0.006), tot_loss_proj:1.404 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.264 (perp=5.907, rec=0.077, cos=0.006), tot_loss_proj:1.399 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.262 (perp=5.907, rec=0.075, cos=0.006), tot_loss_proj:1.402 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1650/2000] tot_loss=1.266 (perp=5.907, rec=0.079, cos=0.006), tot_loss_proj:1.402 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.258 (perp=5.907, rec=0.071, cos=0.006), tot_loss_proj:1.400 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.261 (perp=5.907, rec=0.074, cos=0.006), tot_loss_proj:1.397 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1800/2000] tot_loss=1.264 (perp=5.907, rec=0.077, cos=0.006), tot_loss_proj:1.399 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.269 (perp=5.907, rec=0.082, cos=0.006), tot_loss_proj:1.407 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.265 (perp=5.907, rec=0.078, cos=0.006), tot_loss_proj:1.393 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
[1950/2000] tot_loss=1.260 (perp=5.907, rec=0.073, cos=0.006), tot_loss_proj:1.396 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.265 (perp=5.907, rec=0.078, cos=0.006), tot_loss_proj:1.402 [t=0.17s]
prediction: ['[CLS] [SEP] sucks but has a funny moment or two. [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] [SEP] sucks but has a funny moment or two. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 84.211 | p: 80.000 | r: 88.889
rougeL     | fm: 95.238 | p: 90.909 | r: 100.000
rougeLsum  | fm: 95.238 | p: 90.909 | r: 100.000
r1fm+r2fm = 179.449

[Aggregate metrics]:
rouge1     | fm: 92.090 | p: 91.699 | r: 92.566
rouge2     | fm: 60.807 | p: 60.491 | r: 61.190
rougeL     | fm: 78.689 | p: 78.365 | r: 79.138
rougeLsum  | fm: 78.884 | p: 78.577 | r: 79.300
r1fm+r2fm = 152.898

input #51 time: 0:08:24 | total time: 7:01:06


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9992769471396806
highest_index [0]
highest [0.9992769471396806]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9633553624153137 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9276461005210876 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8949947357177734 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 0.8681666254997253 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 0.7894576191902161 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7760429382324219 for ['[CLS] confession commentator die [SEP]']
[Init] best rec loss: 0.7046040296554565 for ['[CLS] vocabulary football expected [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.291 (perp=10.655, rec=0.155, cos=0.005), tot_loss_proj:2.458 [t=0.18s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 100/2000] tot_loss=2.231 (perp=10.655, rec=0.097, cos=0.003), tot_loss_proj:2.466 [t=0.22s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 150/2000] tot_loss=2.219 (perp=10.655, rec=0.086, cos=0.002), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 200/2000] tot_loss=2.176 (perp=10.528, rec=0.068, cos=0.002), tot_loss_proj:2.207 [t=0.17s]
prediction: ['[CLS] trailer - trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.832 (perp=8.482, rec=0.130, cos=0.005), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 300/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.002), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.140 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.754 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.772 (perp=8.482, rec=0.074, cos=0.001), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.759 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.138 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.770 (perp=8.482, rec=0.072, cos=0.001), tot_loss_proj:2.123 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.752 (perp=8.482, rec=0.055, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.766 (perp=8.482, rec=0.068, cos=0.001), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.752 (perp=8.482, rec=0.054, cos=0.001), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.754 (perp=8.482, rec=0.057, cos=0.001), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.757 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.754 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.765 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.767 (perp=8.482, rec=0.069, cos=0.001), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.137 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.768 (perp=8.482, rec=0.070, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.765 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.774 (perp=8.482, rec=0.076, cos=0.001), tot_loss_proj:2.130 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.750 (perp=8.482, rec=0.052, cos=0.001), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.747 (perp=8.482, rec=0.049, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.748 (perp=8.482, rec=0.050, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.128 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.770 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.756 (perp=8.482, rec=0.058, cos=0.001), tot_loss_proj:2.129 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.131 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.770 (perp=8.482, rec=0.072, cos=0.001), tot_loss_proj:2.121 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.134 [t=0.17s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.229 | p: 91.851 | r: 92.694
rouge2     | fm: 59.553 | p: 59.292 | r: 59.888
rougeL     | fm: 78.740 | p: 78.405 | r: 79.191
rougeLsum  | fm: 78.770 | p: 78.460 | r: 79.158
r1fm+r2fm = 151.782

input #52 time: 0:08:14 | total time: 7:09:20


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9993462296030828
highest_index [0]
highest [0.9993462296030828]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.9457181096076965 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.862006664276123 for ['[CLS] chain oliver [SEP]']
[Init] best rec loss: 0.8316056728363037 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 0.7958467602729797 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 0.7199336886405945 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.6997024416923523 for ['[CLS] lake highlands [SEP]']
[Init] best rec loss: 0.6986270546913147 for ['[CLS] towerbal [SEP]']
[Init] best rec loss: 0.6915310621261597 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6842321157455444 for ['[CLS] nick design [SEP]']
[Init] best rec loss: 0.6748745441436768 for ['[CLS] el peace [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.787 (perp=12.492, rec=0.231, cos=0.057), tot_loss_proj:3.329 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=2.664 (perp=12.492, rec=0.145, cos=0.020), tot_loss_proj:3.340 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.638 (perp=12.492, rec=0.124, cos=0.016), tot_loss_proj:3.333 [t=0.17s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=1.695 (perp=8.090, rec=0.075, cos=0.002), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.675 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.670 (perp=8.090, rec=0.050, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.662 (perp=8.090, rec=0.042, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.665 (perp=8.090, rec=0.045, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.668 (perp=8.090, rec=0.048, cos=0.001), tot_loss_proj:1.685 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.694 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.690 (perp=8.090, rec=0.071, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.668 (perp=8.090, rec=0.049, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.686 (perp=8.090, rec=0.066, cos=0.001), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.677 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.673 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.690 (perp=8.090, rec=0.070, cos=0.001), tot_loss_proj:1.691 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.685 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.680 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.685 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.684 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.676 (perp=8.090, rec=0.056, cos=0.001), tot_loss_proj:1.687 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.678 (perp=8.090, rec=0.058, cos=0.001), tot_loss_proj:1.709 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.379 | p: 92.012 | r: 92.867
rouge2     | fm: 60.058 | p: 59.750 | r: 60.407
rougeL     | fm: 79.106 | p: 78.787 | r: 79.506
rougeLsum  | fm: 79.221 | p: 78.852 | r: 79.542
r1fm+r2fm = 152.436

input #53 time: 0:08:12 | total time: 7:17:32


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9991885466091153
highest_index [0]
highest [0.9991885466091153]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.9532368183135986 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.8024941086769104 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7537968754768372 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.7135902047157288 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.7061654329299927 for ['[CLS] deployment bro [SEP]']
[Init] best perm rec loss: 0.7006915807723999 for ['[CLS] bro deployment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.287 (perp=9.351, rec=0.354, cos=0.062), tot_loss_proj:2.861 [t=0.17s]
prediction: ['[CLS] topics great [SEP]']
[ 100/2000] tot_loss=2.459 (perp=11.553, rec=0.141, cos=0.008), tot_loss_proj:2.875 [t=0.17s]
prediction: ['[CLS] topics hot [SEP]']
[ 150/2000] tot_loss=2.417 (perp=11.553, rec=0.102, cos=0.004), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] topics hot [SEP]']
[ 200/2000] tot_loss=2.407 (perp=11.553, rec=0.093, cos=0.003), tot_loss_proj:2.874 [t=0.17s]
prediction: ['[CLS] topics hot [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.733 (perp=8.198, rec=0.087, cos=0.006), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.709 (perp=8.198, rec=0.067, cos=0.003), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.713 (perp=8.198, rec=0.071, cos=0.002), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.716 (perp=8.198, rec=0.073, cos=0.004), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.720 (perp=8.198, rec=0.078, cos=0.002), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.702 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.756 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.698 (perp=8.198, rec=0.057, cos=0.002), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.711 (perp=8.198, rec=0.070, cos=0.002), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.700 (perp=8.198, rec=0.059, cos=0.002), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.738 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.708 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.693 (perp=8.198, rec=0.052, cos=0.002), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.694 (perp=8.198, rec=0.053, cos=0.002), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.693 (perp=8.198, rec=0.052, cos=0.002), tot_loss_proj:1.744 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.705 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.693 (perp=8.198, rec=0.052, cos=0.002), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.696 (perp=8.198, rec=0.054, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.755 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.690 (perp=8.198, rec=0.049, cos=0.002), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.715 (perp=8.198, rec=0.073, cos=0.002), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.715 (perp=8.198, rec=0.074, cos=0.002), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.708 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.754 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.697 (perp=8.198, rec=0.056, cos=0.002), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.691 (perp=8.198, rec=0.050, cos=0.002), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.484 | p: 92.113 | r: 92.940
rouge2     | fm: 61.261 | p: 60.929 | r: 61.581
rougeL     | fm: 79.474 | p: 79.135 | r: 79.884
rougeLsum  | fm: 79.551 | p: 79.222 | r: 79.969
r1fm+r2fm = 153.745

input #54 time: 0:08:02 | total time: 7:25:35


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9991205863745829
highest_index [0]
highest [0.9991205863745829]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.9149343371391296 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.8663113713264465 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.7905805706977844 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 0.7703065872192383 for ['[CLS]z firm fl [SEP]']
[Init] best rec loss: 0.7634938359260559 for ['[CLS] kirk door regional [SEP]']
[Init] best rec loss: 0.7582106590270996 for ['[CLS] single argentine patent [SEP]']
[Init] best rec loss: 0.7517237663269043 for ['[CLS] plantesthesia pr [SEP]']
[Init] best rec loss: 0.712469220161438 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.703285276889801 for ['[CLS] stride holly post [SEP]']
[Init] best perm rec loss: 0.7019903659820557 for ['[CLS] post holly stride [SEP]']
[Init] best perm rec loss: 0.7008416652679443 for ['[CLS] stride post holly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.651 (perp=10.646, rec=0.389, cos=0.133), tot_loss_proj:3.871 [t=0.16s]
prediction: ['[CLS] civilization settle easily [SEP]']
[ 100/2000] tot_loss=2.174 (perp=9.583, rec=0.209, cos=0.048), tot_loss_proj:2.336 [t=0.17s]
prediction: ['[CLS] too settles easily [SEP]']
[ 150/2000] tot_loss=1.993 (perp=9.583, rec=0.072, cos=0.004), tot_loss_proj:2.325 [t=0.17s]
prediction: ['[CLS] too settles easily [SEP]']
[ 200/2000] tot_loss=1.987 (perp=9.583, rec=0.068, cos=0.002), tot_loss_proj:2.325 [t=0.17s]
prediction: ['[CLS] too settles easily [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.795 (perp=8.671, rec=0.057, cos=0.004), tot_loss_proj:1.815 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.804 (perp=8.671, rec=0.068, cos=0.002), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.804 (perp=8.671, rec=0.068, cos=0.002), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.807 (perp=8.671, rec=0.071, cos=0.002), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.805 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.800 (perp=8.671, rec=0.064, cos=0.002), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.803 (perp=8.671, rec=0.067, cos=0.002), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.801 (perp=8.671, rec=0.065, cos=0.002), tot_loss_proj:1.811 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.805 (perp=8.671, rec=0.069, cos=0.002), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.805 (perp=8.671, rec=0.069, cos=0.002), tot_loss_proj:1.813 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.002), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.790 (perp=8.671, rec=0.054, cos=0.002), tot_loss_proj:1.803 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.801 (perp=8.671, rec=0.065, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.810 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.792 (perp=8.671, rec=0.056, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.002), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.792 (perp=8.671, rec=0.056, cos=0.002), tot_loss_proj:1.809 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.788 (perp=8.671, rec=0.052, cos=0.002), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.784 (perp=8.671, rec=0.048, cos=0.002), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.795 (perp=8.671, rec=0.059, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.781 (perp=8.671, rec=0.045, cos=0.002), tot_loss_proj:1.813 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.804 (perp=8.671, rec=0.068, cos=0.002), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.803 (perp=8.671, rec=0.067, cos=0.002), tot_loss_proj:1.815 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.810 (perp=8.671, rec=0.074, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.783 (perp=8.671, rec=0.047, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.800 (perp=8.671, rec=0.064, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.802 (perp=8.671, rec=0.066, cos=0.002), tot_loss_proj:1.806 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.803 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.002), tot_loss_proj:1.797 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.798 (perp=8.671, rec=0.062, cos=0.002), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.795 (perp=8.671, rec=0.059, cos=0.002), tot_loss_proj:1.804 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.800 (perp=8.671, rec=0.064, cos=0.002), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.791 (perp=8.671, rec=0.055, cos=0.002), tot_loss_proj:1.794 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.799 (perp=8.671, rec=0.063, cos=0.002), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.791 (perp=8.671, rec=0.055, cos=0.002), tot_loss_proj:1.801 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.657 | p: 92.306 | r: 93.126
rouge2     | fm: 61.944 | p: 61.654 | r: 62.291
rougeL     | fm: 79.849 | p: 79.538 | r: 80.276
rougeLsum  | fm: 79.924 | p: 79.538 | r: 80.354
r1fm+r2fm = 154.601

input #55 time: 0:08:10 | total time: 7:33:45


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.9992743912224646
highest_index [0]
highest [0.9992743912224646]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.932321310043335 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.9175447821617126 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.9035267233848572 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 0.8958414793014526 for ['[CLS] sergeant atlanticrted further enough face za sincedah had bringing experience claus stereo tour novelmler trails worn korean armed [SEP]']
[Init] best rec loss: 0.8944609761238098 for ['[CLS] direction casual pl constitution orange storm beardction norris polo reaches accmity bladetlingus mayer hatch novels chinese ore [SEP]']
[Init] best rec loss: 0.8827247619628906 for ['[CLS] handed almost with leadership emotional obsidian wall households consolation potential spectroscopy defeated been existing organization variables up acquainted cas dive realm [SEP]']
[Init] best perm rec loss: 0.8799951076507568 for ['[CLS] almost wall up emotional defeated leadership acquainted variables spectroscopy dive realm with consolation households cas potential obsidian handed existing been organization [SEP]']
[Init] best perm rec loss: 0.8781517744064331 for ['[CLS] organization almost been emotional consolation defeated existing obsidian households acquainted with spectroscopy dive wall leadership up cas handed potential realm variables [SEP]']
[Init] best perm rec loss: 0.8778687119483948 for ['[CLS] cas variables wall emotional potential dive spectroscopy leadership organization obsidian existing consolation with almost defeated realm handed up been acquainted households [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.411 (perp=10.767, rec=0.247, cos=0.010), tot_loss_proj:3.021 [t=0.17s]
prediction: ['[CLS] full damagees painful cause films destroyed movie damage any costly damageeries at repairter damage that films problem damage [SEP]']
[ 100/2000] tot_loss=2.381 (perp=11.011, rec=0.173, cos=0.006), tot_loss_proj:3.066 [t=0.17s]
prediction: ['[CLS] which causesre which cause films damage loads damage that costly fix almost of costly of analysis which films fix damage [SEP]']
[ 150/2000] tot_loss=2.441 (perp=11.529, rec=0.132, cos=0.004), tot_loss_proj:2.989 [t=0.17s]
prediction: ['[CLS] which causesre painful will films damage loads damage that costly fix years of never of analysis could films fix damage [SEP]']
[ 200/2000] tot_loss=2.274 (perp=10.857, rec=0.100, cos=0.002), tot_loss_proj:3.086 [t=0.17s]
prediction: ['[CLS] whichparare which will films cause loads damage that costly fix years and never of analysis could filmsble damage [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.285 (perp=10.968, rec=0.089, cos=0.002), tot_loss_proj:3.455 [t=0.17s]
prediction: ['[CLS] whichparare of will films cause loads fix years that costly years and never of analysis could filmsble damage [SEP]']
[ 300/2000] tot_loss=2.269 (perp=10.968, rec=0.074, cos=0.002), tot_loss_proj:3.455 [t=0.17s]
prediction: ['[CLS] whichparare of will films cause loads fix years that costly years and never of analysis could filmsble damage [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.068 (perp=9.937, rec=0.079, cos=0.002), tot_loss_proj:2.883 [t=0.17s]
prediction: ['[CLS] whichparable costly will films cause loads fix years that of years and never of analysis could filmsble damage [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.004 (perp=9.553, rec=0.092, cos=0.002), tot_loss_proj:2.841 [t=0.19s]
prediction: ['[CLS] whichparable costly will films cause loads fix years that of years and never of analysis could damageble films [SEP]']
[ 450/2000] tot_loss=1.986 (perp=9.553, rec=0.074, cos=0.002), tot_loss_proj:2.840 [t=0.19s]
prediction: ['[CLS] whichparable costly will films cause loads fix years that of years and never of analysis could damageble films [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.919 (perp=9.187, rec=0.080, cos=0.002), tot_loss_proj:2.819 [t=0.23s]
prediction: ['[CLS] whichparable costly films will cause loads fix years that of years and never of analysis could damageble films [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.869 (perp=8.937, rec=0.079, cos=0.002), tot_loss_proj:2.708 [t=0.19s]
prediction: ['[CLS] whichparable costly films will cause loads of years that fix years and never of analysis could damageble films [SEP]']
[ 600/2000] tot_loss=1.865 (perp=8.937, rec=0.076, cos=0.002), tot_loss_proj:2.706 [t=0.19s]
prediction: ['[CLS] whichparable costly films will cause loads of years that fix years and never of analysis could damageble films [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.796 (perp=8.558, rec=0.083, cos=0.002), tot_loss_proj:3.566 [t=0.19s]
prediction: ['[CLS] whichparable films will cause loads of years that fix years and never of costly analysis could damageble films [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.741 (perp=8.345, rec=0.071, cos=0.002), tot_loss_proj:3.208 [t=0.19s]
prediction: ['[CLS] whichparable films will cause loads of years that fix and years never of costly analysis could damageble films [SEP]']
[ 750/2000] tot_loss=1.745 (perp=8.345, rec=0.074, cos=0.002), tot_loss_proj:3.209 [t=0.19s]
prediction: ['[CLS] whichparable films will cause loads of years that fix and years never of costly analysis could damageble films [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.688 (perp=8.086, rec=0.070, cos=0.002), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] whichparable films will cause loads of years that fix and never years of costly analysis could damageble films [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.691 (perp=8.071, rec=0.076, cos=0.002), tot_loss_proj:3.107 [t=0.19s]
prediction: ['[CLS] whichparable films will cause loads of years that fix and never years of costly analysisble could damage films [SEP]']
[ 900/2000] tot_loss=1.864 (perp=8.971, rec=0.068, cos=0.002), tot_loss_proj:3.384 [t=0.19s]
prediction: ['[CLS] whichpara ir films will cause loads of years that fix and never years of costly analysisble could damage films [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.689 (perp=8.093, rec=0.069, cos=0.001), tot_loss_proj:3.284 [t=0.19s]
prediction: ['[CLS] whichparable ir films will cause loads of years that fix and never years of costly analysis could damage films [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.628 (perp=7.734, rec=0.080, cos=0.001), tot_loss_proj:3.167 [t=0.17s]
prediction: ['[CLS] ir whichparable films will cause loads of years that fix and never years of costly analysis could damage films [SEP]']
[1050/2000] tot_loss=1.620 (perp=7.734, rec=0.072, cos=0.001), tot_loss_proj:3.167 [t=0.17s]
prediction: ['[CLS] ir whichparable films will cause loads of years that fix and never years of costly analysis could damage films [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.545 (perp=7.364, rec=0.071, cos=0.002), tot_loss_proj:3.013 [t=0.17s]
prediction: ['[CLS] which irparable films will cause loads of years that fix and never years of costly analysis could damage films [SEP]']
Attempt swap
[1150/2000] tot_loss=1.534 (perp=7.364, rec=0.060, cos=0.002), tot_loss_proj:3.017 [t=0.17s]
prediction: ['[CLS] which irparable films will cause loads of years that fix and never years of costly analysis could damage films [SEP]']
[1200/2000] tot_loss=1.538 (perp=7.364, rec=0.064, cos=0.002), tot_loss_proj:3.008 [t=0.17s]
prediction: ['[CLS] which irparable films will cause loads of years that fix and never years of costly analysis could damage films [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.502 (perp=7.160, rec=0.068, cos=0.001), tot_loss_proj:2.858 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that fix and never years of costly analysis could damage films [SEP]']
Attempt swap
[1300/2000] tot_loss=1.502 (perp=7.160, rec=0.069, cos=0.001), tot_loss_proj:2.854 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that fix and never years of costly analysis could damage films [SEP]']
[1350/2000] tot_loss=1.501 (perp=7.160, rec=0.067, cos=0.001), tot_loss_proj:2.848 [t=0.18s]
prediction: ['[CLS] which loads of irparable films will cause years that fix and never years of costly analysis could damage films [SEP]']
Attempt swap
[1400/2000] tot_loss=1.501 (perp=7.160, rec=0.067, cos=0.001), tot_loss_proj:2.856 [t=0.20s]
prediction: ['[CLS] which loads of irparable films will cause years that fix and never years of costly analysis could damage films [SEP]']
Attempt swap
[1450/2000] tot_loss=1.497 (perp=7.160, rec=0.064, cos=0.001), tot_loss_proj:2.849 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that fix and never years of costly analysis could damage films [SEP]']
[1500/2000] tot_loss=1.492 (perp=7.160, rec=0.059, cos=0.002), tot_loss_proj:2.849 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that fix and never years of costly analysis could damage films [SEP]']
Attempt swap
[1550/2000] tot_loss=1.515 (perp=7.160, rec=0.081, cos=0.001), tot_loss_proj:2.848 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that fix and never years of costly analysis could damage films [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.478 (perp=7.046, rec=0.067, cos=0.001), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that never fix and years of costly analysis could damage films [SEP]']
[1650/2000] tot_loss=1.476 (perp=7.046, rec=0.065, cos=0.001), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that never fix and years of costly analysis could damage films [SEP]']
Attempt swap
[1700/2000] tot_loss=1.481 (perp=7.046, rec=0.070, cos=0.001), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that never fix and years of costly analysis could damage films [SEP]']
Attempt swap
[1750/2000] tot_loss=1.477 (perp=7.046, rec=0.066, cos=0.001), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that never fix and years of costly analysis could damage films [SEP]']
[1800/2000] tot_loss=1.480 (perp=7.046, rec=0.070, cos=0.001), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that never fix and years of costly analysis could damage films [SEP]']
Attempt swap
[1850/2000] tot_loss=1.478 (perp=7.046, rec=0.067, cos=0.001), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that never fix and years of costly analysis could damage films [SEP]']
Attempt swap
[1900/2000] tot_loss=1.482 (perp=7.046, rec=0.071, cos=0.001), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that never fix and years of costly analysis could damage films [SEP]']
[1950/2000] tot_loss=1.465 (perp=7.046, rec=0.054, cos=0.001), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that never fix and years of costly analysis could damage films [SEP]']
Attempt swap
[2000/2000] tot_loss=1.479 (perp=7.046, rec=0.068, cos=0.001), tot_loss_proj:1.884 [t=0.17s]
prediction: ['[CLS] which loads of irparable films will cause years that never fix and years of costly analysis could damage films [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] which loads of irparable films will cause years that fix and never years of costly analysis could damage films [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.683 | p: 90.476 | r: 95.000
rouge2     | fm: 30.769 | p: 30.000 | r: 31.579
rougeL     | fm: 58.537 | p: 57.143 | r: 60.000
rougeLsum  | fm: 58.537 | p: 57.143 | r: 60.000
r1fm+r2fm = 123.452

[Aggregate metrics]:
rouge1     | fm: 92.677 | p: 92.294 | r: 93.142
rouge2     | fm: 61.170 | p: 60.892 | r: 61.470
rougeL     | fm: 79.585 | p: 79.298 | r: 79.984
rougeLsum  | fm: 79.396 | p: 79.058 | r: 79.845
r1fm+r2fm = 153.847

input #56 time: 0:09:10 | total time: 7:42:55


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9993815950585874
highest_index [0]
highest [0.9993815950585874]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.8631657361984253 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.7994511723518372 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.705524206161499 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6581541299819946 for ['[CLS] expressed [SEP]']
[Init] best rec loss: 0.643149733543396 for ['[CLS] decision [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.711 (perp=12.282, rec=0.194, cos=0.060), tot_loss_proj:2.530 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.533 (perp=12.282, rec=0.074, cos=0.003), tot_loss_proj:2.507 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.529 (perp=12.282, rec=0.071, cos=0.002), tot_loss_proj:2.528 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.511 (perp=12.282, rec=0.053, cos=0.001), tot_loss_proj:2.533 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.511 (perp=12.282, rec=0.051, cos=0.003), tot_loss_proj:2.519 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.518 (perp=12.282, rec=0.060, cos=0.002), tot_loss_proj:2.521 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.515 (perp=12.282, rec=0.056, cos=0.002), tot_loss_proj:2.515 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.505 (perp=12.282, rec=0.048, cos=0.001), tot_loss_proj:2.506 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.528 (perp=12.282, rec=0.071, cos=0.001), tot_loss_proj:2.510 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.521 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.512 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.521 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.511 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.515 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.515 (perp=12.282, rec=0.057, cos=0.001), tot_loss_proj:2.520 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.527 (perp=12.282, rec=0.069, cos=0.001), tot_loss_proj:2.528 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.515 (perp=12.282, rec=0.057, cos=0.001), tot_loss_proj:2.505 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.522 (perp=12.282, rec=0.065, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.527 (perp=12.282, rec=0.070, cos=0.001), tot_loss_proj:2.516 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.518 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.522 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.514 (perp=12.282, rec=0.056, cos=0.001), tot_loss_proj:2.527 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.507 (perp=12.282, rec=0.050, cos=0.001), tot_loss_proj:2.509 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.507 (perp=12.282, rec=0.049, cos=0.001), tot_loss_proj:2.523 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.516 (perp=12.282, rec=0.059, cos=0.001), tot_loss_proj:2.530 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.511 (perp=12.282, rec=0.053, cos=0.001), tot_loss_proj:2.509 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.509 (perp=12.282, rec=0.051, cos=0.001), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.505 (perp=12.282, rec=0.048, cos=0.001), tot_loss_proj:2.512 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.524 (perp=12.282, rec=0.066, cos=0.001), tot_loss_proj:2.528 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.507 (perp=12.282, rec=0.049, cos=0.001), tot_loss_proj:2.509 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.511 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.518 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.530 (perp=12.282, rec=0.073, cos=0.001), tot_loss_proj:2.521 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.522 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.513 (perp=12.282, rec=0.056, cos=0.001), tot_loss_proj:2.512 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.508 (perp=12.282, rec=0.050, cos=0.001), tot_loss_proj:2.521 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.526 (perp=12.282, rec=0.068, cos=0.001), tot_loss_proj:2.518 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.507 (perp=12.282, rec=0.050, cos=0.001), tot_loss_proj:2.529 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.517 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.520 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.515 (perp=12.282, rec=0.057, cos=0.001), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.517 (perp=12.282, rec=0.059, cos=0.001), tot_loss_proj:2.517 [t=0.16s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.527 (perp=12.282, rec=0.069, cos=0.001), tot_loss_proj:2.516 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.838 | p: 92.427 | r: 93.288
rouge2     | fm: 62.006 | p: 61.746 | r: 62.351
rougeL     | fm: 79.941 | p: 79.581 | r: 80.359
rougeLsum  | fm: 79.800 | p: 79.450 | r: 80.233
r1fm+r2fm = 154.844

input #57 time: 0:08:02 | total time: 7:50:58


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9992685151622416
highest_index [0]
highest [0.9992685151622416]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 0.9649522304534912 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9525012969970703 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9179250597953796 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9173662066459656 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 0.9167462587356567 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.8904667496681213 for ['[CLS] when bread conceptual likely mason rolesulouslysight beyond [MASK] idol bel and contemporary initially [CLS] [SEP]']
[Init] best rec loss: 0.8734395503997803 for ['[CLS] marcuslam brothers closet archives damnvation med park nothing length engineered census lap brooks memorial [SEP]']
[Init] best rec loss: 0.872577428817749 for ['[CLS] down trade zack serious verde thighsager finishedtyle chiefuration apart beautyitical est herself [SEP]']
[Init] best perm rec loss: 0.872272789478302 for ['[CLS] verde finishedager thighs beauty estitical trade zack herselfuration apart chieftyle down serious [SEP]']
[Init] best perm rec loss: 0.8679993748664856 for ['[CLS] down herselfitical verde zack finished apart serious chiefuration thighs tradetyle beauty estager [SEP]']
[Init] best perm rec loss: 0.8665047287940979 for ['[CLS]itical est trade zack serioustyle herself down thighs finished beauty apart chiefageruration verde [SEP]']
[Init] best perm rec loss: 0.8653094172477722 for ['[CLS] beauty aparturation thighs trade verde zack down chief finished herself serioustyle estiticalager [SEP]']
[Init] best perm rec loss: 0.8635257482528687 for ['[CLS] est chief beauty down zack serious tradetyle verde thighsurationitical apartager herself finished [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.669 (perp=11.959, rec=0.269, cos=0.008), tot_loss_proj:4.247 [t=0.17s]
prediction: ['[CLS]less country sexual excellent academic relationship throughout clever entertainment good compulsion relationship goodbye song financial was [SEP]']
[ 100/2000] tot_loss=2.351 (perp=10.729, rec=0.201, cos=0.003), tot_loss_proj:2.929 [t=0.18s]
prediction: ['[CLS], heart economic inspirational childhood story throughout inspirational fitness personal inspirational relationship love story inspirational a [SEP]']
[ 150/2000] tot_loss=2.096 (perp=9.767, rec=0.141, cos=0.002), tot_loss_proj:2.876 [t=0.19s]
prediction: ['[CLS] is - sexual inspirational first story throughout capturing fitness personal, relationship love story inspirational a [SEP]']
[ 200/2000] tot_loss=2.211 (perp=10.499, rec=0.109, cos=0.002), tot_loss_proj:2.907 [t=0.17s]
prediction: ['[CLS] is - sexual inspirational first encounter throughout capturing innocence capturing,ache love story inspirational an [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.047 (perp=9.770, rec=0.091, cos=0.002), tot_loss_proj:2.705 [t=0.22s]
prediction: ['[CLS] is - sexual inspirational first encounter throughout capturing innocence ideal innocence, love story inspirational an [SEP]']
[ 300/2000] tot_loss=2.042 (perp=9.708, rec=0.099, cos=0.002), tot_loss_proj:2.635 [t=0.17s]
prediction: ['[CLS] is - uses inspirational first encounter throughout capturing innocence ideal innocence, love story inspirational an [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.914 (perp=9.087, rec=0.095, cos=0.002), tot_loss_proj:2.606 [t=0.19s]
prediction: ['[CLS] is sense uses inspirational first encounter - capturing innocence ideal innocence, love story inspirational an [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.787 (perp=8.500, rec=0.085, cos=0.002), tot_loss_proj:2.201 [t=0.20s]
prediction: ['[CLS] is sense an inspirational first encounter - capturing innocence ideal innocence, love story inspirational different [SEP]']
[ 450/2000] tot_loss=1.705 (perp=8.095, rec=0.084, cos=0.002), tot_loss_proj:2.086 [t=0.19s]
prediction: ['[CLS] is sense an inspirational first encounter - capturing innocence theism, love story inspirational uses [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.692 (perp=8.053, rec=0.080, cos=0.001), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] is sense an inspirational first encounter - capturing innocence the of, love story inspirational of [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.596 (perp=7.558, rec=0.082, cos=0.002), tot_loss_proj:1.866 [t=0.17s]
prediction: ['[CLS] is sense an inspirational first encounter - capturing innocence of the, love story inspirational of [SEP]']
[ 600/2000] tot_loss=1.594 (perp=7.558, rec=0.081, cos=0.002), tot_loss_proj:1.880 [t=0.17s]
prediction: ['[CLS] is sense an inspirational first encounter - capturing innocence of the, love story inspirational of [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.615 (perp=7.694, rec=0.074, cos=0.002), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] is sense an ideal first encounter - capturing innocence of the, love story of inspirational [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.535 (perp=7.226, rec=0.088, cos=0.002), tot_loss_proj:1.872 [t=0.17s]
prediction: ['[CLS] is sense an ideal first encounter - capturing innocence of the love, story of inspirational [SEP]']
[ 750/2000] tot_loss=1.519 (perp=7.226, rec=0.072, cos=0.002), tot_loss_proj:1.867 [t=0.17s]
prediction: ['[CLS] is sense an ideal first encounter - capturing innocence of the love, story of inspirational [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.494 (perp=7.062, rec=0.080, cos=0.002), tot_loss_proj:1.821 [t=0.22s]
prediction: ['[CLS] is sense an ideal first encounter - capturing innocence of inspirational love, story of the [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.471 (perp=6.935, rec=0.082, cos=0.002), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] is sense an ideal first encounter - capturing innocence of love, inspirational story of the [SEP]']
[ 900/2000] tot_loss=1.458 (perp=6.935, rec=0.070, cos=0.002), tot_loss_proj:1.782 [t=0.17s]
prediction: ['[CLS] is sense an ideal first encounter - capturing innocence of love, inspirational story of the [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.429 (perp=6.707, rec=0.086, cos=0.002), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] is inspirational sense an ideal first encounter - capturing innocence of love, story of the [SEP]']
Attempt swap
[1000/2000] tot_loss=1.419 (perp=6.707, rec=0.076, cos=0.002), tot_loss_proj:1.720 [t=0.17s]
prediction: ['[CLS] is inspirational sense an ideal first encounter - capturing innocence of love, story of the [SEP]']
[1050/2000] tot_loss=1.426 (perp=6.707, rec=0.083, cos=0.002), tot_loss_proj:1.725 [t=0.17s]
prediction: ['[CLS] is inspirational sense an ideal first encounter - capturing innocence of love, story of the [SEP]']
Attempt swap
[1100/2000] tot_loss=1.423 (perp=6.707, rec=0.080, cos=0.002), tot_loss_proj:1.727 [t=0.17s]
prediction: ['[CLS] is inspirational sense an ideal first encounter - capturing innocence of love, story of the [SEP]']
Attempt swap
[1150/2000] tot_loss=1.428 (perp=6.707, rec=0.085, cos=0.002), tot_loss_proj:1.719 [t=0.17s]
prediction: ['[CLS] is inspirational sense an ideal first encounter - capturing innocence of love, story of the [SEP]']
[1200/2000] tot_loss=1.417 (perp=6.707, rec=0.074, cos=0.002), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] is inspirational sense an ideal first encounter - capturing innocence of love, story of the [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.400 (perp=6.632, rec=0.072, cos=0.002), tot_loss_proj:1.720 [t=0.17s]
prediction: ['[CLS] is inspirational sense an ideal first encounter, capturing innocence of love - story of the [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.383 (perp=6.575, rec=0.067, cos=0.002), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter sense capturing innocence and love - story of the [SEP]']
[1350/2000] tot_loss=1.395 (perp=6.575, rec=0.078, cos=0.002), tot_loss_proj:1.630 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter sense capturing innocence and love - story of the [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.346 (perp=6.340, rec=0.077, cos=0.002), tot_loss_proj:1.592 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing innocence of love - sense of the [SEP]']
Attempt swap
[1450/2000] tot_loss=1.344 (perp=6.340, rec=0.075, cos=0.002), tot_loss_proj:1.590 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing innocence of love - sense of the [SEP]']
[1500/2000] tot_loss=1.348 (perp=6.340, rec=0.078, cos=0.002), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing innocence of love - sense of the [SEP]']
Attempt swap
[1550/2000] tot_loss=1.339 (perp=6.328, rec=0.072, cos=0.002), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing innocence and love - sense of the [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.284 (perp=6.015, rec=0.079, cos=0.002), tot_loss_proj:1.500 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing the innocence of love - sense of [SEP]']
[1650/2000] tot_loss=1.283 (perp=6.015, rec=0.078, cos=0.002), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing the innocence of love - sense of [SEP]']
Attempt swap
[1700/2000] tot_loss=1.280 (perp=6.015, rec=0.075, cos=0.002), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing the innocence of love - sense of [SEP]']
Attempt swap
[1750/2000] tot_loss=1.282 (perp=6.015, rec=0.077, cos=0.002), tot_loss_proj:1.495 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing the innocence of love - sense of [SEP]']
[1800/2000] tot_loss=1.226 (perp=5.733, rec=0.078, cos=0.002), tot_loss_proj:1.439 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing the innocence of love and sense of [SEP]']
Attempt swap
[1850/2000] tot_loss=1.228 (perp=5.733, rec=0.080, cos=0.002), tot_loss_proj:1.444 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing the innocence of love and sense of [SEP]']
Attempt swap
[1900/2000] tot_loss=1.225 (perp=5.733, rec=0.077, cos=0.002), tot_loss_proj:1.444 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing the innocence of love and sense of [SEP]']
[1950/2000] tot_loss=1.226 (perp=5.733, rec=0.078, cos=0.002), tot_loss_proj:1.443 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing the innocence of love and sense of [SEP]']
Attempt swap
[2000/2000] tot_loss=1.223 (perp=5.733, rec=0.074, cos=0.002), tot_loss_proj:1.440 [t=0.17s]
prediction: ['[CLS] is inspirational, an ideal first encounter story capturing the innocence of love and sense of [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] is inspirational, an ideal first encounter story capturing innocence of love - sense of the [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.250 | p: 81.250 | r: 81.250
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 101.250

[Aggregate metrics]:
rouge1     | fm: 92.561 | p: 92.176 | r: 93.043
rouge2     | fm: 61.383 | p: 61.118 | r: 61.748
rougeL     | fm: 79.381 | p: 79.011 | r: 79.704
rougeLsum  | fm: 79.266 | p: 78.965 | r: 79.651
r1fm+r2fm = 153.944

input #58 time: 0:09:09 | total time: 8:00:08


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9992224669689527
highest_index [0]
highest [0.9992224669689527]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.9151541590690613 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.9016127586364746 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 0.8955602645874023 for ['[CLS] clutch sports meridian placed weekly dixonwords up⁄ faerie rugby been towards resist programming infantry [SEP]']
[Init] best rec loss: 0.865580677986145 for ['[CLS] professor dexter lime rolling parliament music australiancoat revised sts mexican wr mixed consort racer harm [SEP]']
[Init] best rec loss: 0.857191801071167 for ['[CLS]ition wandering wearing right wore kent hemisphere purple strict we gas dark deserve tonnes did letterman [SEP]']
[Init] best rec loss: 0.8294965028762817 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best perm rec loss: 0.8291977643966675 for ['[CLS] wasby temperament awhile noah information bologna 1993 fleet thus pump bobo races tunnel stuffak [SEP]']
[Init] best perm rec loss: 0.8291869163513184 for ['[CLS] awhile pump bobo tunnel fleet thus was temperamentak races stuff noah 1993by bologna information [SEP]']
[Init] best perm rec loss: 0.8275994658470154 for ['[CLS] thus information pump temperament awhile bobo races stuff fleetby was 1993 noah tunnelak bologna [SEP]']
[Init] best perm rec loss: 0.8272705078125 for ['[CLS] fleet temperament pumpak information noah bologna races tunnelby awhile thus stuff bobo 1993 was [SEP]']
[Init] best perm rec loss: 0.8271450400352478 for ['[CLS] bologna tunnel pump thus noah races information bobo stuff fleet 1993 temperament wasakby awhile [SEP]']
[Init] best perm rec loss: 0.8269852995872498 for ['[CLS] bologna pump 1993 information awhile stuffbyak bobo fleet races temperament thus was noah tunnel [SEP]']
[Init] best perm rec loss: 0.8267932534217834 for ['[CLS] thus 1993 bologna stuff pump temperament fleet tunnel was awhile noahakby races bobo information [SEP]']
[Init] best perm rec loss: 0.8258228898048401 for ['[CLS] bobo stuff temperamentby tunnel 1993 informationak thus races awhile noah bologna pump was fleet [SEP]']
[Init] best perm rec loss: 0.8244286775588989 for ['[CLS]by fleet thus information bologna tunnel temperament races awhile stuff pump noah bobo was 1993ak [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.975 (perp=13.104, rec=0.339, cos=0.015), tot_loss_proj:4.006 [t=0.17s]
prediction: ['[CLS] nature suppliesographic the spots youngcy event classical womando brillianttails runner the coffee [SEP]']
[ 100/2000] tot_loss=2.610 (perp=11.739, rec=0.257, cos=0.005), tot_loss_proj:3.918 [t=0.17s]
prediction: ['[CLS] nature hasstic hasism young of event ms woman styled looking char woman the screen [SEP]']
[ 150/2000] tot_loss=2.333 (perp=10.742, rec=0.182, cos=0.003), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] nature hasstic hasism young of screen of woman knowing how char screen the screen [SEP]']
[ 200/2000] tot_loss=2.345 (perp=10.978, rec=0.145, cos=0.004), tot_loss_proj:3.628 [t=0.17s]
prediction: ['[CLS] nature has char hasism young of screen of woman who how char screen the screen [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.330 (perp=10.817, rec=0.164, cos=0.003), tot_loss_proj:3.718 [t=0.17s]
prediction: ['[CLS] has compositionityicism young of screen a woman who how how hold the [SEP] [SEP]']
[ 300/2000] tot_loss=2.377 (perp=11.293, rec=0.116, cos=0.002), tot_loss_proj:2.957 [t=0.17s]
prediction: ['[CLS] has char char ofism young of screen a woman who knows how hold the [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.075 (perp=9.800, rec=0.113, cos=0.002), tot_loss_proj:2.704 [t=0.17s]
prediction: ['[CLS] has char of charism young of screen a woman who knows how hold the [SEP] [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.159 (perp=10.226, rec=0.111, cos=0.002), tot_loss_proj:2.924 [t=0.19s]
prediction: ['[CLS] char has char ofism young of screen a woman who knows how hold the [SEP] [SEP]']
[ 450/2000] tot_loss=2.143 (perp=10.226, rec=0.096, cos=0.002), tot_loss_proj:2.921 [t=0.19s]
prediction: ['[CLS] char has char ofism young of screen a woman who knows how hold the [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.128 (perp=10.180, rec=0.090, cos=0.002), tot_loss_proj:2.781 [t=0.20s]
prediction: ['[CLS]ism has char ofism young of screen a woman who knows how hold the [SEP] [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.992 (perp=9.553, rec=0.079, cos=0.002), tot_loss_proj:2.620 [t=0.17s]
prediction: ['[CLS]ism has charism of young of screen a woman who knows how hold the [SEP] [SEP]']
[ 600/2000] tot_loss=1.994 (perp=9.553, rec=0.082, cos=0.002), tot_loss_proj:2.614 [t=0.17s]
prediction: ['[CLS]ism has charism of young of screen a woman who knows how hold the [SEP] [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.831 (perp=8.697, rec=0.090, cos=0.002), tot_loss_proj:2.318 [t=0.17s]
prediction: ['[CLS]ism has charism the young of screen a woman who knows how hold the [SEP] [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.743 (perp=8.253, rec=0.090, cos=0.002), tot_loss_proj:2.159 [t=0.17s]
prediction: ['[CLS]ism has charism the young of a woman who knows how hold the screen [SEP] [SEP]']
[ 750/2000] tot_loss=1.735 (perp=8.253, rec=0.082, cos=0.002), tot_loss_proj:2.153 [t=0.17s]
prediction: ['[CLS]ism has charism the young of a woman who knows how hold the screen [SEP] [SEP]']
Attempt swap
Put prefix at the end
[ 800/2000] tot_loss=1.646 (perp=7.768, rec=0.090, cos=0.002), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] [SEP]ism has charism the young of a woman who knows how hold the screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.647 (perp=7.768, rec=0.092, cos=0.002), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] [SEP]ism has charism the young of a woman who knows how hold the screen [SEP]']
[ 900/2000] tot_loss=1.632 (perp=7.768, rec=0.076, cos=0.002), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] [SEP]ism has charism the young of a woman who knows how hold the screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.634 (perp=7.768, rec=0.079, cos=0.002), tot_loss_proj:2.111 [t=0.17s]
prediction: ['[CLS] [SEP]ism has charism the young of a woman who knows how hold the screen [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.623 (perp=7.658, rec=0.089, cos=0.002), tot_loss_proj:2.191 [t=0.17s]
prediction: ['[CLS] [SEP]ism charism has the young of a woman who knows how hold the screen [SEP]']
[1050/2000] tot_loss=1.617 (perp=7.658, rec=0.084, cos=0.002), tot_loss_proj:2.187 [t=0.17s]
prediction: ['[CLS] [SEP]ism charism has the young of a woman who knows how hold the screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.621 (perp=7.658, rec=0.087, cos=0.002), tot_loss_proj:2.180 [t=0.17s]
prediction: ['[CLS] [SEP]ism charism has the young of a woman who knows how hold the screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.612 (perp=7.658, rec=0.079, cos=0.002), tot_loss_proj:2.191 [t=0.17s]
prediction: ['[CLS] [SEP]ism charism has the young of a woman who knows how hold the screen [SEP]']
[1200/2000] tot_loss=1.610 (perp=7.658, rec=0.077, cos=0.002), tot_loss_proj:2.192 [t=0.17s]
prediction: ['[CLS] [SEP]ism charism has the young of a woman who knows how hold the screen [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.585 (perp=7.493, rec=0.084, cos=0.002), tot_loss_proj:2.065 [t=0.17s]
prediction: ['[CLS] [SEP]ism char young has theism of a woman who knows how hold the screen [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.550 (perp=7.316, rec=0.084, cos=0.002), tot_loss_proj:1.930 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
[1350/2000] tot_loss=1.550 (perp=7.316, rec=0.085, cos=0.002), tot_loss_proj:1.941 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.543 (perp=7.316, rec=0.078, cos=0.002), tot_loss_proj:1.937 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.547 (perp=7.316, rec=0.082, cos=0.002), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
[1500/2000] tot_loss=1.550 (perp=7.316, rec=0.084, cos=0.002), tot_loss_proj:1.939 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.544 (perp=7.316, rec=0.079, cos=0.002), tot_loss_proj:1.934 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.541 (perp=7.316, rec=0.076, cos=0.002), tot_loss_proj:1.934 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
[1650/2000] tot_loss=1.535 (perp=7.316, rec=0.070, cos=0.002), tot_loss_proj:1.946 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.538 (perp=7.316, rec=0.073, cos=0.002), tot_loss_proj:1.940 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.539 (perp=7.316, rec=0.074, cos=0.002), tot_loss_proj:1.938 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
[1800/2000] tot_loss=1.543 (perp=7.316, rec=0.078, cos=0.002), tot_loss_proj:1.941 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.540 (perp=7.316, rec=0.075, cos=0.002), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.540 (perp=7.316, rec=0.074, cos=0.002), tot_loss_proj:1.947 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
[1950/2000] tot_loss=1.551 (perp=7.316, rec=0.086, cos=0.002), tot_loss_proj:1.944 [t=0.20s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.550 (perp=7.316, rec=0.085, cos=0.002), tot_loss_proj:1.944 [t=0.17s]
prediction: ['[CLS] [SEP]ism char has theism of a young woman who knows how hold the screen [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] [SEP]ism charism has the young of a woman who knows how hold the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.848 | p: 82.353 | r: 87.500
rouge2     | fm: 51.613 | p: 50.000 | r: 53.333
rougeL     | fm: 78.788 | p: 76.471 | r: 81.250
rougeLsum  | fm: 78.788 | p: 76.471 | r: 81.250
r1fm+r2fm = 136.461

[Aggregate metrics]:
rouge1     | fm: 92.449 | p: 92.032 | r: 92.979
rouge2     | fm: 61.085 | p: 60.793 | r: 61.471
rougeL     | fm: 79.394 | p: 79.055 | r: 79.897
rougeLsum  | fm: 79.408 | p: 78.975 | r: 79.895
r1fm+r2fm = 153.534

input #59 time: 0:08:50 | total time: 8:08:58


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.999371813039142
highest_index [0]
highest [0.999371813039142]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9299472570419312 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9130843281745911 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8701856732368469 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8695709109306335 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8544469475746155 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 0.842263400554657 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 0.8397374749183655 for ['[CLS] constitutionitude upsetshaw coverlby strungouring majority plenty / through [SEP]']
[Init] best perm rec loss: 0.8392449617385864 for ['[CLS] majorityitudelby upsetouring plentyshaw constitution cover strung through / [SEP]']
[Init] best perm rec loss: 0.8391808867454529 for ['[CLS]itude coverouring majoritylbyshaw through / plenty upset strung constitution [SEP]']
[Init] best perm rec loss: 0.8388378024101257 for ['[CLS]lby / upsetouring constitutionshaw cover strung majorityitude through plenty [SEP]']
[Init] best perm rec loss: 0.838720440864563 for ['[CLS] throughlby / majority upset strungitude constitutionshaw plentyouring cover [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.621 (perp=11.741, rec=0.264, cos=0.009), tot_loss_proj:2.902 [t=0.18s]
prediction: ['[CLS] is awkwardly paced gossip - story awkwardly soap awkwardly film circuit awkwardly [SEP]']
[ 100/2000] tot_loss=2.530 (perp=11.785, rec=0.170, cos=0.004), tot_loss_proj:2.887 [t=0.17s]
prediction: ['[CLS] is awkwardly paced gossip opera is awkwardly soap awkwardly story circuit awkwardly [SEP]']
[ 150/2000] tot_loss=1.771 (perp=8.279, rec=0.112, cos=0.003), tot_loss_proj:2.430 [t=0.17s]
prediction: ['[CLS] is the paced soap opera is awkwardly soap bubble story circuit. [SEP]']
[ 200/2000] tot_loss=2.041 (perp=9.724, rec=0.094, cos=0.003), tot_loss_proj:2.437 [t=0.17s]
prediction: ['[CLS] is the pacedh opera - awkwardly soaph story circuit. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.948 (perp=9.228, rec=0.100, cos=0.003), tot_loss_proj:2.271 [t=0.17s]
prediction: ['[CLS] is awkwardly pacedh opera - the soaph story circuit. [SEP]']
[ 300/2000] tot_loss=1.926 (perp=9.228, rec=0.078, cos=0.002), tot_loss_proj:2.276 [t=0.17s]
prediction: ['[CLS] is awkwardly pacedh opera - the soaph story circuit. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.718 (perp=8.159, rec=0.084, cos=0.002), tot_loss_proj:2.074 [t=0.17s]
prediction: ['[CLS] is awkwardly pacedh soap opera - theh story circuit. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.909 (perp=8.903, rec=0.124, cos=0.004), tot_loss_proj:2.167 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the mis story circuit / [SEP]']
[ 450/2000] tot_loss=1.774 (perp=8.373, rec=0.097, cos=0.002), tot_loss_proj:2.057 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the is story circuit ; [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.455 (perp=6.834, rec=0.086, cos=0.002), tot_loss_proj:1.938 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera is story circuit. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.441 (perp=6.834, rec=0.071, cos=0.002), tot_loss_proj:1.949 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera is story circuit. [SEP]']
[ 600/2000] tot_loss=1.446 (perp=6.834, rec=0.077, cos=0.002), tot_loss_proj:1.950 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera is story circuit. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.446 (perp=6.834, rec=0.077, cos=0.002), tot_loss_proj:1.950 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera is story circuit. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.441 (perp=6.834, rec=0.072, cos=0.002), tot_loss_proj:1.942 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera is story circuit. [SEP]']
[ 750/2000] tot_loss=1.441 (perp=6.834, rec=0.072, cos=0.002), tot_loss_proj:1.944 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera is story circuit. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.439 (perp=6.834, rec=0.070, cos=0.002), tot_loss_proj:1.951 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera is story circuit. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.422 (perp=6.744, rec=0.072, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
[ 900/2000] tot_loss=1.415 (perp=6.744, rec=0.065, cos=0.001), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.415 (perp=6.744, rec=0.065, cos=0.001), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.418 (perp=6.744, rec=0.068, cos=0.001), tot_loss_proj:1.984 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
[1050/2000] tot_loss=1.416 (perp=6.744, rec=0.066, cos=0.001), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.408 (perp=6.744, rec=0.058, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.425 (perp=6.744, rec=0.075, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
[1200/2000] tot_loss=1.416 (perp=6.744, rec=0.066, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.406 (perp=6.744, rec=0.056, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.408 (perp=6.744, rec=0.058, cos=0.001), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
[1350/2000] tot_loss=1.415 (perp=6.744, rec=0.065, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.415 (perp=6.744, rec=0.065, cos=0.001), tot_loss_proj:1.984 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.414 (perp=6.744, rec=0.064, cos=0.001), tot_loss_proj:1.985 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
[1500/2000] tot_loss=1.417 (perp=6.744, rec=0.067, cos=0.001), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.422 (perp=6.744, rec=0.072, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.419 (perp=6.744, rec=0.069, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
[1650/2000] tot_loss=1.427 (perp=6.744, rec=0.077, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.406 (perp=6.744, rec=0.056, cos=0.001), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.420 (perp=6.744, rec=0.070, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
[1800/2000] tot_loss=1.414 (perp=6.744, rec=0.064, cos=0.001), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.414 (perp=6.744, rec=0.064, cos=0.001), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.405 (perp=6.744, rec=0.055, cos=0.001), tot_loss_proj:1.985 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
[1950/2000] tot_loss=1.407 (perp=6.744, rec=0.057, cos=0.001), tot_loss_proj:1.992 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.421 (perp=6.744, rec=0.071, cos=0.001), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS]h is awkwardly paced - the soap opera circuit is story. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 38.095 | p: 36.364 | r: 40.000
rougeL     | fm: 69.565 | p: 66.667 | r: 72.727
rougeLsum  | fm: 69.565 | p: 66.667 | r: 72.727
r1fm+r2fm = 125.052

[Aggregate metrics]:
rouge1     | fm: 92.390 | p: 91.934 | r: 92.971
rouge2     | fm: 60.758 | p: 60.497 | r: 61.094
rougeL     | fm: 79.131 | p: 78.787 | r: 79.602
rougeLsum  | fm: 79.240 | p: 78.780 | r: 79.690
r1fm+r2fm = 153.148

input #60 time: 0:07:47 | total time: 8:16:46


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.999284746941759
highest_index [0]
highest [0.999284746941759]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9795893430709839 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9741564989089966 for ['[CLS] lighterloh heartbeat [SEP]']
[Init] best rec loss: 0.9512136578559875 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9470409154891968 for ['[CLS] paths whose bar [SEP]']
[Init] best rec loss: 0.9432965517044067 for ['[CLS] conscious baptizedness [SEP]']
[Init] best rec loss: 0.9347224831581116 for ['[CLS] crested tend prize [SEP]']
[Init] best rec loss: 0.9169871807098389 for ['[CLS] bologna nails steps [SEP]']
[Init] best rec loss: 0.9168724417686462 for ['[CLS] joint flamingual [SEP]']
[Init] best rec loss: 0.9121196269989014 for ['[CLS] you wedding velvet [SEP]']
[Init] best rec loss: 0.9106317162513733 for ['[CLS] installed equipped unlike [SEP]']
[Init] best rec loss: 0.8808217644691467 for ['[CLS] respect thrill butterfly [SEP]']
[Init] best rec loss: 0.8280910849571228 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 0.8269730806350708 for ['[CLS] lets mini request [SEP]']
[Init] best perm rec loss: 0.8244650959968567 for ['[CLS] mini request lets [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.148 (perp=9.683, rec=0.200, cos=0.011), tot_loss_proj:2.381 [t=0.16s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 100/2000] tot_loss=2.096 (perp=9.683, rec=0.151, cos=0.008), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 150/2000] tot_loss=2.075 (perp=9.683, rec=0.131, cos=0.007), tot_loss_proj:2.394 [t=0.17s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
[ 200/2000] tot_loss=2.075 (perp=9.683, rec=0.132, cos=0.006), tot_loss_proj:2.393 [t=0.17s]
prediction: ['[CLS] scene beautiful beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.681 (perp=8.032, rec=0.073, cos=0.002), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS], beautiful scene [SEP]']
[ 300/2000] tot_loss=1.667 (perp=8.032, rec=0.059, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS], beautiful scene [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.489 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.621 [t=0.20s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.481 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.499 (perp=7.101, rec=0.077, cos=0.001), tot_loss_proj:1.620 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.490 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.628 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.494 (perp=7.101, rec=0.073, cos=0.001), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.483 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.497 (perp=7.101, rec=0.075, cos=0.001), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.478 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.484 (perp=7.101, rec=0.062, cos=0.001), tot_loss_proj:1.629 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.476 (perp=7.101, rec=0.054, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.489 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.478 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.495 (perp=7.101, rec=0.073, cos=0.001), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.481 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.610 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.484 (perp=7.101, rec=0.062, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.482 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.631 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.491 (perp=7.101, rec=0.070, cos=0.001), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.494 (perp=7.101, rec=0.072, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.480 (perp=7.101, rec=0.058, cos=0.001), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.485 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.482 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.466 | p: 91.986 | r: 93.035
rouge2     | fm: 61.154 | p: 60.897 | r: 61.594
rougeL     | fm: 79.569 | p: 79.191 | r: 80.063
rougeLsum  | fm: 79.490 | p: 79.085 | r: 79.992
r1fm+r2fm = 153.620

input #61 time: 0:07:29 | total time: 8:24:16


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.999255650346929
highest_index [0]
highest [0.999255650346929]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9540637731552124 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9288767576217651 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.927240788936615 for ['[CLS] gem longer congregationiq commemorate members police later pm drawing [MASK]ly onwards drops team senator access head wrath miss shane [SEP]']
[Init] best rec loss: 0.9213613867759705 for ['[CLS] percentage trap danzinghur shapeee sacred persianlon record theater freestylegold cards dance sacks pits dreadmund existed [SEP]']
[Init] best rec loss: 0.9167788624763489 for ['[CLS] girl plain followedion recalls間 by spread fight sioux 2002 test origins humanitarian peck reed forumnce tooth closely mccarthy [SEP]']
[Init] best perm rec loss: 0.9164981842041016 for ['[CLS]nce followed mccarthy sioux by forum fight closely origins peckion humanitarian 2002 recalls reed spread tooth plain test girl間 [SEP]']
[Init] best perm rec loss: 0.914860188961029 for ['[CLS] girl by tooth forum followednce test reed sioux plain fight 2002 origins spread recalls closely humanitarian mccarthy間 peckion [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.680 (perp=11.565, rec=0.355, cos=0.013), tot_loss_proj:4.166 [t=0.17s]
prediction: ['[CLS] / by congregation grace opera street best connor organizational a good miniseries hopecy avoided being single encodedable basis occasion [SEP]']
[ 100/2000] tot_loss=2.272 (perp=9.995, rec=0.265, cos=0.007), tot_loss_proj:3.808 [t=0.17s]
prediction: ['[CLS] / to for grace movies ) best grace prevention making good than hope grace prevention being war moviesly one usual [SEP]']
[ 150/2000] tot_loss=2.283 (perp=10.394, rec=0.200, cos=0.004), tot_loss_proj:3.704 [t=0.17s]
prediction: ['[CLS] / to to grace movies among best grace prevention making best than grace grace prevention the war moviesly one ever [SEP]']
[ 200/2000] tot_loss=2.376 (perp=11.042, rec=0.165, cos=0.003), tot_loss_proj:3.972 [t=0.19s]
prediction: ['[CLS] call to to grace movies among best grace prevention making one than grace grace prevention the war moviesly one ever [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.112 (perp=9.832, rec=0.143, cos=0.002), tot_loss_proj:3.770 [t=0.19s]
prediction: ['[CLS] call to to grace movies the best grace prevention making one than grace call rather among war movies suddenly one ever [SEP]']
[ 300/2000] tot_loss=2.033 (perp=9.547, rec=0.121, cos=0.002), tot_loss_proj:3.843 [t=0.17s]
prediction: ['[CLS] call to call grace movies to best grace prevention making one its grace call rather of war movies suddenly one ever [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.990 (perp=9.454, rec=0.097, cos=0.002), tot_loss_proj:3.849 [t=0.17s]
prediction: ['[CLS] call to call grace movies for except grace prevention making one it best call rather of war movies suddenly one ever [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.924 (perp=9.091, rec=0.104, cos=0.002), tot_loss_proj:3.690 [t=0.17s]
prediction: ['[CLS] call to call grace movies for grace prevention prevention making one it best call rather the war made, one ever [SEP]']
[ 450/2000] tot_loss=1.984 (perp=9.394, rec=0.103, cos=0.002), tot_loss_proj:3.649 [t=0.17s]
prediction: ['[CLS] call to call grace movies for grace prevention prevention making one it best place rather the war made over one ever [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.888 (perp=8.953, rec=0.096, cos=0.002), tot_loss_proj:3.575 [t=0.17s]
prediction: ['[CLS] call to call grace movies for grace prevention prevention making it best one place rather the war made over one ever [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.945 (perp=9.246, rec=0.094, cos=0.002), tot_loss_proj:3.738 [t=0.17s]
prediction: ['[CLS] call to call grace movies for grace prevention prevention making it best one place responsible rather the war made one ever [SEP]']
[ 600/2000] tot_loss=1.879 (perp=8.954, rec=0.087, cos=0.002), tot_loss_proj:3.487 [t=0.17s]
prediction: ['[CLS] call to call blame movies for grace prevention prevention making it best one place blame rather the war made one ever [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.768 (perp=8.375, rec=0.091, cos=0.002), tot_loss_proj:3.377 [t=0.17s]
prediction: ['[CLS] place to call blame movies for grace prevention blame making it best of call blame rather the war made one ever [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.715 (perp=8.114, rec=0.090, cos=0.002), tot_loss_proj:3.336 [t=0.17s]
prediction: ['[CLS] place to call blame movies for grace prevention blame making it best of call blame rather the war one ever made [SEP]']
[ 750/2000] tot_loss=1.699 (perp=8.114, rec=0.075, cos=0.002), tot_loss_proj:3.335 [t=0.17s]
prediction: ['[CLS] place to call blame movies for grace prevention blame making it best of call blame rather the war one ever made [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.664 (perp=7.902, rec=0.081, cos=0.002), tot_loss_proj:3.229 [t=0.17s]
prediction: ['[CLS] place to call blame movies for grace prevention blame of making it best call blame rather the war one ever made [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.704 (perp=8.081, rec=0.086, cos=0.002), tot_loss_proj:3.296 [t=0.17s]
prediction: ['[CLS] place to make blame for movies grace prevention blame of making it best call blame rather the war one ever made [SEP]']
[ 900/2000] tot_loss=1.705 (perp=8.081, rec=0.087, cos=0.002), tot_loss_proj:3.291 [t=0.17s]
prediction: ['[CLS] place to make blame for movies grace prevention blame of making it best call blame rather the war one ever made [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.674 (perp=7.909, rec=0.091, cos=0.002), tot_loss_proj:3.337 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention blame of making it best call blame rather the war one ever made [SEP]']
Attempt swap
[1000/2000] tot_loss=1.665 (perp=7.909, rec=0.081, cos=0.002), tot_loss_proj:3.331 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention blame of making it best call blame rather the war one ever made [SEP]']
[1050/2000] tot_loss=1.661 (perp=7.909, rec=0.078, cos=0.002), tot_loss_proj:3.327 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention blame of making it best call blame rather the war one ever made [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.606 (perp=7.607, rec=0.083, cos=0.002), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention blame of making it call blame rather the best war one ever made [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.586 (perp=7.422, rec=0.100, cos=0.002), tot_loss_proj:3.403 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention blame of making it one blame rather the best war call ever made [SEP]']
[1200/2000] tot_loss=1.577 (perp=7.422, rec=0.091, cos=0.002), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention blame of making it one blame rather the best war call ever made [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.569 (perp=7.398, rec=0.088, cos=0.002), tot_loss_proj:3.174 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making it one blame rather the best war call ever made [SEP]']
Attempt swap
[1300/2000] tot_loss=1.563 (perp=7.398, rec=0.082, cos=0.002), tot_loss_proj:3.170 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making it one blame rather the best war call ever made [SEP]']
[1350/2000] tot_loss=1.565 (perp=7.398, rec=0.084, cos=0.002), tot_loss_proj:3.175 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making it one blame rather the best war call ever made [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.545 (perp=7.313, rec=0.081, cos=0.002), tot_loss_proj:2.965 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
Attempt swap
[1450/2000] tot_loss=1.546 (perp=7.313, rec=0.082, cos=0.002), tot_loss_proj:2.957 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
[1500/2000] tot_loss=1.548 (perp=7.313, rec=0.083, cos=0.002), tot_loss_proj:2.965 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
Attempt swap
[1550/2000] tot_loss=1.546 (perp=7.313, rec=0.082, cos=0.002), tot_loss_proj:2.959 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
Attempt swap
[1600/2000] tot_loss=1.535 (perp=7.313, rec=0.071, cos=0.002), tot_loss_proj:2.957 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
[1650/2000] tot_loss=1.554 (perp=7.313, rec=0.090, cos=0.002), tot_loss_proj:2.964 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
Attempt swap
[1700/2000] tot_loss=1.545 (perp=7.313, rec=0.081, cos=0.002), tot_loss_proj:2.958 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
Attempt swap
[1750/2000] tot_loss=1.547 (perp=7.313, rec=0.083, cos=0.002), tot_loss_proj:2.962 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
[1800/2000] tot_loss=1.541 (perp=7.313, rec=0.077, cos=0.002), tot_loss_proj:2.959 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
Attempt swap
[1850/2000] tot_loss=1.545 (perp=7.313, rec=0.081, cos=0.002), tot_loss_proj:2.964 [t=0.17s]
prediction: ['[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.513 (perp=7.125, rec=0.086, cos=0.002), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS] place to make blame for grace call prevention of blame making blame it one rather the best war movies ever made [SEP]']
[1950/2000] tot_loss=1.510 (perp=7.125, rec=0.083, cos=0.002), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS] place to make blame for grace call prevention of blame making blame it one rather the best war movies ever made [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.409 (perp=6.673, rec=0.073, cos=0.002), tot_loss_proj:2.457 [t=0.17s]
prediction: ['[CLS] place to make blame for grace call prevention rather blame making blame it one of the best war movies ever made [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] place to make blame for grace movies prevention of blame making blame it one rather the best war call ever made [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 86.957 | r: 90.909
rouge2     | fm: 27.907 | p: 27.273 | r: 28.571
rougeL     | fm: 62.222 | p: 60.870 | r: 63.636
rougeLsum  | fm: 62.222 | p: 60.870 | r: 63.636
r1fm+r2fm = 116.796

[Aggregate metrics]:
rouge1     | fm: 92.452 | p: 91.926 | r: 93.020
rouge2     | fm: 60.592 | p: 60.278 | r: 61.008
rougeL     | fm: 79.251 | p: 78.833 | r: 79.752
rougeLsum  | fm: 79.187 | p: 78.780 | r: 79.660
r1fm+r2fm = 153.044

input #62 time: 0:08:04 | total time: 8:32:21


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9992646432214791
highest_index [0]
highest [0.9992646432214791]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.9565043449401855 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.9048953652381897 for ['[CLS] touch alternative glacier bentry [SEP]']
[Init] best rec loss: 0.7484632730484009 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.7433376908302307 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 0.739037811756134 for ['[CLS] diploma catalogue honors knee skirt [SEP]']
[Init] best rec loss: 0.7285273671150208 for ['[CLS] forces solutions... offense civil [SEP]']
[Init] best perm rec loss: 0.7276551127433777 for ['[CLS] solutions forces offense... civil [SEP]']
[Init] best perm rec loss: 0.7259407639503479 for ['[CLS] solutions civil forces... offense [SEP]']
[Init] best perm rec loss: 0.7244595885276794 for ['[CLS] forces... offense solutions civil [SEP]']
[Init] best perm rec loss: 0.7240341901779175 for ['[CLS] forces solutions... civil offense [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.525 (perp=10.331, rec=0.376, cos=0.083), tot_loss_proj:3.264 [t=0.18s]
prediction: ['[CLS] limited rejected off ticket ticket [SEP]']
[ 100/2000] tot_loss=2.212 (perp=10.156, rec=0.171, cos=0.010), tot_loss_proj:3.101 [t=0.18s]
prediction: ['[CLS] return looking off ticket ticket [SEP]']
[ 150/2000] tot_loss=1.831 (perp=8.565, rec=0.113, cos=0.005), tot_loss_proj:2.640 [t=0.18s]
prediction: ['[CLS] return looking for ticket return [SEP]']
[ 200/2000] tot_loss=1.804 (perp=8.565, rec=0.087, cos=0.004), tot_loss_proj:2.641 [t=0.18s]
prediction: ['[CLS] return looking for ticket return [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.798 (perp=8.565, rec=0.081, cos=0.004), tot_loss_proj:2.643 [t=0.19s]
prediction: ['[CLS] return looking for ticket return [SEP]']
[ 300/2000] tot_loss=1.795 (perp=8.565, rec=0.079, cos=0.004), tot_loss_proj:2.651 [t=0.19s]
prediction: ['[CLS] return looking for ticket return [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.792 (perp=8.565, rec=0.075, cos=0.004), tot_loss_proj:2.648 [t=0.22s]
prediction: ['[CLS] return looking for ticket return [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.795 (perp=8.565, rec=0.079, cos=0.004), tot_loss_proj:2.646 [t=0.17s]
prediction: ['[CLS] return looking for ticket return [SEP]']
[ 450/2000] tot_loss=1.796 (perp=8.565, rec=0.079, cos=0.004), tot_loss_proj:2.654 [t=0.17s]
prediction: ['[CLS] return looking for ticket return [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.806 (perp=8.687, rec=0.065, cos=0.003), tot_loss_proj:2.416 [t=0.17s]
prediction: ['[CLS] a looking for ticket return [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.256 (perp=5.941, rec=0.064, cos=0.004), tot_loss_proj:1.465 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 600/2000] tot_loss=1.267 (perp=5.941, rec=0.075, cos=0.003), tot_loss_proj:1.458 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.260 (perp=5.941, rec=0.069, cos=0.003), tot_loss_proj:1.464 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.264 (perp=5.941, rec=0.073, cos=0.003), tot_loss_proj:1.460 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 750/2000] tot_loss=1.262 (perp=5.941, rec=0.071, cos=0.003), tot_loss_proj:1.460 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.269 (perp=5.941, rec=0.078, cos=0.003), tot_loss_proj:1.461 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.258 (perp=5.941, rec=0.067, cos=0.002), tot_loss_proj:1.468 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[ 900/2000] tot_loss=1.260 (perp=5.941, rec=0.070, cos=0.002), tot_loss_proj:1.462 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.259 (perp=5.941, rec=0.069, cos=0.002), tot_loss_proj:1.468 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1000/2000] tot_loss=1.260 (perp=5.941, rec=0.071, cos=0.002), tot_loss_proj:1.461 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1050/2000] tot_loss=1.256 (perp=5.941, rec=0.067, cos=0.002), tot_loss_proj:1.476 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1100/2000] tot_loss=1.259 (perp=5.941, rec=0.070, cos=0.002), tot_loss_proj:1.472 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1150/2000] tot_loss=1.257 (perp=5.941, rec=0.068, cos=0.001), tot_loss_proj:1.463 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1200/2000] tot_loss=1.259 (perp=5.941, rec=0.069, cos=0.001), tot_loss_proj:1.473 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1250/2000] tot_loss=1.259 (perp=5.941, rec=0.069, cos=0.001), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1300/2000] tot_loss=1.259 (perp=5.941, rec=0.070, cos=0.001), tot_loss_proj:1.458 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1350/2000] tot_loss=1.244 (perp=5.941, rec=0.054, cos=0.001), tot_loss_proj:1.456 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1400/2000] tot_loss=1.251 (perp=5.941, rec=0.061, cos=0.001), tot_loss_proj:1.471 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1450/2000] tot_loss=1.254 (perp=5.941, rec=0.064, cos=0.001), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1500/2000] tot_loss=1.247 (perp=5.941, rec=0.057, cos=0.001), tot_loss_proj:1.470 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1550/2000] tot_loss=1.264 (perp=5.941, rec=0.075, cos=0.001), tot_loss_proj:1.460 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1600/2000] tot_loss=1.261 (perp=5.941, rec=0.071, cos=0.001), tot_loss_proj:1.456 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1650/2000] tot_loss=1.260 (perp=5.941, rec=0.070, cos=0.001), tot_loss_proj:1.466 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1700/2000] tot_loss=1.254 (perp=5.941, rec=0.065, cos=0.001), tot_loss_proj:1.463 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1750/2000] tot_loss=1.260 (perp=5.941, rec=0.070, cos=0.001), tot_loss_proj:1.466 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1800/2000] tot_loss=1.250 (perp=5.941, rec=0.060, cos=0.001), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1850/2000] tot_loss=1.251 (perp=5.941, rec=0.062, cos=0.001), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[1900/2000] tot_loss=1.254 (perp=5.941, rec=0.064, cos=0.001), tot_loss_proj:1.462 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
[1950/2000] tot_loss=1.264 (perp=5.941, rec=0.074, cos=0.001), tot_loss_proj:1.459 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Attempt swap
[2000/2000] tot_loss=1.247 (perp=5.941, rec=0.058, cos=0.001), tot_loss_proj:1.465 [t=0.17s]
prediction: ['[CLS] looking for a ticket return [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a ticket return [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 92.552 | p: 92.100 | r: 93.117
rouge2     | fm: 60.539 | p: 60.266 | r: 60.891
rougeL     | fm: 79.323 | p: 78.901 | r: 79.742
rougeLsum  | fm: 79.303 | p: 78.884 | r: 79.733
r1fm+r2fm = 153.092

input #63 time: 0:08:22 | total time: 8:40:43


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.999160846219472
highest_index [0]
highest [0.999160846219472]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8796932697296143 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8693087697029114 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 0.728920042514801 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.675671398639679 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 0.6740126609802246 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 0.6711879372596741 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.966 (perp=8.653, rec=0.200, cos=0.036), tot_loss_proj:2.062 [t=0.17s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.900 (perp=8.653, rec=0.150, cos=0.019), tot_loss_proj:2.050 [t=0.17s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.904 (perp=8.653, rec=0.145, cos=0.029), tot_loss_proj:2.051 [t=0.17s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=2.077 (perp=9.634, rec=0.135, cos=0.016), tot_loss_proj:2.558 [t=0.17s]
prediction: ['[CLS] strange horror strange [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.976 (perp=9.190, rec=0.127, cos=0.012), tot_loss_proj:2.202 [t=0.17s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 300/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.714 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.684 (perp=8.065, rec=0.069, cos=0.002), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.672 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.713 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.667 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.714 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.706 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.717 [t=0.20s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.716 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.715 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.713 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.673 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.687 (perp=8.065, rec=0.072, cos=0.002), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.671 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.716 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.712 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.667 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.675 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.688 (perp=8.065, rec=0.073, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.680 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.646 | p: 92.169 | r: 93.200
rouge2     | fm: 61.454 | p: 61.134 | r: 61.711
rougeL     | fm: 79.753 | p: 79.327 | r: 80.278
rougeLsum  | fm: 79.763 | p: 79.336 | r: 80.234
r1fm+r2fm = 154.100

input #64 time: 0:08:11 | total time: 8:48:54


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9992260466615117
highest_index [0]
highest [0.9992260466615117]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.0258606672286987 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9586822390556335 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.9518215656280518 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.9477682113647461 for ['[CLS]blpf bce med stride plot skip honest what [SEP]']
[Init] best rec loss: 0.8876939415931702 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.8789583444595337 for ['[CLS] news evenmament pu overs someday general funhoff [SEP]']
[Init] best perm rec loss: 0.8788501620292664 for ['[CLS] evenhoff overs pu newsmament general fun someday [SEP]']
[Init] best perm rec loss: 0.875924289226532 for ['[CLS]hoff someday general even pumament news fun overs [SEP]']
[Init] best perm rec loss: 0.8755142688751221 for ['[CLS] general news evenmament puhoff overs fun someday [SEP]']
[Init] best perm rec loss: 0.8745706081390381 for ['[CLS] even general news pumament somedayhoff fun overs [SEP]']
[Init] best perm rec loss: 0.8732827305793762 for ['[CLS] somedaymamenthoff general overs pu news even fun [SEP]']
[Init] best perm rec loss: 0.8718383312225342 for ['[CLS]mament news general even pu overs fun somedayhoff [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.120 (perp=9.064, rec=0.299, cos=0.009), tot_loss_proj:2.338 [t=0.21s]
prediction: ['[CLS] joyous joy look. florida joy - joy [SEP]']
[ 100/2000] tot_loss=1.807 (perp=8.124, rec=0.178, cos=0.004), tot_loss_proj:2.117 [t=0.17s]
prediction: ['[CLS] joyous joyous, film of - joy [SEP]']
[ 150/2000] tot_loss=2.505 (perp=11.837, rec=0.135, cos=0.002), tot_loss_proj:3.059 [t=0.17s]
prediction: ['[CLS] romousousous, film of. joy [SEP]']
[ 200/2000] tot_loss=2.468 (perp=11.837, rec=0.099, cos=0.002), tot_loss_proj:3.062 [t=0.17s]
prediction: ['[CLS] romousousous, film of. joy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.825 (perp=8.700, rec=0.082, cos=0.002), tot_loss_proj:2.339 [t=0.17s]
prediction: ['[CLS] rompousous, film of joy. [SEP]']
[ 300/2000] tot_loss=1.819 (perp=8.700, rec=0.077, cos=0.002), tot_loss_proj:2.342 [t=0.17s]
prediction: ['[CLS] rompousous, film of joy. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.690 (perp=8.013, rec=0.085, cos=0.002), tot_loss_proj:2.265 [t=0.17s]
prediction: ['[CLS] romp,ousous film of joy. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.414 (perp=6.643, rec=0.083, cos=0.002), tot_loss_proj:2.053 [t=0.17s]
prediction: ['[CLS] romp,ous of joyous film. [SEP]']
[ 450/2000] tot_loss=1.480 (perp=6.937, rec=0.091, cos=0.002), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS] romp,ous of joy of film. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.410 (perp=6.643, rec=0.079, cos=0.002), tot_loss_proj:2.078 [t=0.17s]
prediction: ['[CLS] romp,ous of joyous film. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.403 (perp=6.643, rec=0.072, cos=0.002), tot_loss_proj:2.077 [t=0.17s]
prediction: ['[CLS] romp,ous of joyous film. [SEP]']
[ 600/2000] tot_loss=1.412 (perp=6.643, rec=0.082, cos=0.002), tot_loss_proj:2.077 [t=0.17s]
prediction: ['[CLS] romp,ous of joyous film. [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.258 (perp=5.877, rec=0.081, cos=0.002), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.250 (perp=5.877, rec=0.073, cos=0.002), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
[ 750/2000] tot_loss=1.254 (perp=5.877, rec=0.076, cos=0.002), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.260 (perp=5.877, rec=0.083, cos=0.002), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.251 (perp=5.877, rec=0.074, cos=0.002), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
[ 900/2000] tot_loss=1.253 (perp=5.877, rec=0.076, cos=0.002), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.254 (perp=5.877, rec=0.077, cos=0.002), tot_loss_proj:1.629 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.251 (perp=5.877, rec=0.074, cos=0.002), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
[1050/2000] tot_loss=1.255 (perp=5.877, rec=0.078, cos=0.002), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.250 (perp=5.877, rec=0.073, cos=0.002), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.246 (perp=5.877, rec=0.068, cos=0.002), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
[1200/2000] tot_loss=1.257 (perp=5.877, rec=0.080, cos=0.002), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.246 (perp=5.877, rec=0.068, cos=0.002), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.251 (perp=5.877, rec=0.073, cos=0.002), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
[1350/2000] tot_loss=1.249 (perp=5.877, rec=0.072, cos=0.002), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.258 (perp=5.877, rec=0.081, cos=0.002), tot_loss_proj:1.615 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.243 (perp=5.877, rec=0.066, cos=0.002), tot_loss_proj:1.618 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
[1500/2000] tot_loss=1.249 (perp=5.877, rec=0.072, cos=0.002), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.244 (perp=5.877, rec=0.066, cos=0.002), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.248 (perp=5.877, rec=0.071, cos=0.002), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
[1650/2000] tot_loss=1.253 (perp=5.877, rec=0.076, cos=0.002), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.244 (perp=5.877, rec=0.067, cos=0.002), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.250 (perp=5.877, rec=0.073, cos=0.002), tot_loss_proj:1.608 [t=0.22s]
prediction: ['[CLS] joyous romp, of of film. [SEP]']
[1800/2000] tot_loss=1.096 (perp=5.096, rec=0.075, cos=0.002), tot_loss_proj:1.306 [t=0.17s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.102 (perp=5.096, rec=0.081, cos=0.002), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.087 (perp=5.096, rec=0.066, cos=0.002), tot_loss_proj:1.313 [t=0.17s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
[1950/2000] tot_loss=1.086 (perp=5.096, rec=0.065, cos=0.002), tot_loss_proj:1.309 [t=0.17s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.081 (perp=5.096, rec=0.061, cos=0.002), tot_loss_proj:1.312 [t=0.17s]
prediction: ['[CLS] joyous romp, of a film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] joyous romp, of a film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.800 | p: 92.313 | r: 93.322
rouge2     | fm: 61.805 | p: 61.459 | r: 62.166
rougeL     | fm: 79.969 | p: 79.592 | r: 80.395
rougeLsum  | fm: 79.970 | p: 79.565 | r: 80.433
r1fm+r2fm = 154.605

input #65 time: 0:07:40 | total time: 8:56:35


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9992330092949469
highest_index [0]
highest [0.9992330092949469]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.973792552947998 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.9307570457458496 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.9160336256027222 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8862890601158142 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 0.8742782473564148 for ['[CLS]beersa bryce two [SEP]']
[Init] best perm rec loss: 0.8719822764396667 for ['[CLS]beersa two bryce [SEP]']
[Init] best perm rec loss: 0.8696925640106201 for ['[CLS]rsa two brycebee [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.867 (perp=8.308, rec=0.196, cos=0.009), tot_loss_proj:1.952 [t=0.17s]
prediction: ['[CLS] longtime professional tolkien fan [SEP]']
[ 100/2000] tot_loss=1.608 (perp=7.673, rec=0.071, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 150/2000] tot_loss=1.593 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 200/2000] tot_loss=1.590 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.599 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.593 (perp=7.673, rec=0.057, cos=0.002), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.609 (perp=7.673, rec=0.073, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.588 (perp=7.673, rec=0.052, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.002), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.612 (perp=7.673, rec=0.076, cos=0.002), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.607 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.585 (perp=7.673, rec=0.049, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.595 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.605 (perp=7.673, rec=0.069, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.591 (perp=7.673, rec=0.055, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.597 (perp=7.673, rec=0.061, cos=0.002), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.591 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.605 (perp=7.673, rec=0.069, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.594 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.597 [t=0.18s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.983 | p: 92.510 | r: 93.507
rouge2     | fm: 62.336 | p: 62.025 | r: 62.735
rougeL     | fm: 80.371 | p: 79.890 | r: 80.812
rougeLsum  | fm: 80.267 | p: 79.864 | r: 80.721
r1fm+r2fm = 155.319

input #66 time: 0:07:22 | total time: 9:03:58


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.999292690019056
highest_index [0]
highest [0.999292690019056]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.005807638168335 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9567444324493408 for ['[CLS] clear winnie cloudsc ling commercialiny royal classic [UNK] [SEP]']
[Init] best rec loss: 0.9554714560508728 for ['[CLS] repeat well rv strikes combined leaned written itself welsh bunch [SEP]']
[Init] best rec loss: 0.9473316669464111 for ['[CLS] position citationliga carriage demands source administered leancode pope [SEP]']
[Init] best rec loss: 0.9436708688735962 for ['[CLS] contributions. cars tied sir if - stalk alexis hilton [SEP]']
[Init] best rec loss: 0.9336733222007751 for ['[CLS] investment parker mostly radical national snow nearly baltimore contact are [SEP]']
[Init] best rec loss: 0.9325234889984131 for ['[CLS]ible ultimately season mainly swifthood abby source price need [SEP]']
[Init] best rec loss: 0.9268360137939453 for ['[CLS] wild tribes upon cone home enough promotion mural courtney ） [SEP]']
[Init] best perm rec loss: 0.9241943955421448 for ['[CLS] ） cone home mural courtney promotion upon enough wild tribes [SEP]']
[Init] best perm rec loss: 0.9226720929145813 for ['[CLS] promotion tribes home cone enough ） wild courtney upon mural [SEP]']
[Init] best perm rec loss: 0.9221352934837341 for ['[CLS] upon home tribes courtney cone mural ） wild promotion enough [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.259 (perp=14.631, rec=0.322, cos=0.011), tot_loss_proj:4.274 [t=0.17s]
prediction: ['[CLS]rdialwar celestial 2018 altitude absorbed ; energygoing kind [SEP]']
[ 100/2000] tot_loss=2.700 (perp=12.548, rec=0.186, cos=0.004), tot_loss_proj:4.011 [t=0.17s]
prediction: ['[CLS] nonwar angelental heart non,mingental kind [SEP]']
[ 150/2000] tot_loss=2.701 (perp=12.609, rec=0.176, cos=0.003), tot_loss_proj:3.768 [t=0.17s]
prediction: ['[CLS] nonwar creatureental heart heart,mingental kind [SEP]']
[ 200/2000] tot_loss=2.476 (perp=11.766, rec=0.121, cos=0.002), tot_loss_proj:3.401 [t=0.17s]
prediction: ['[CLS] nonwargmental heart heart,mingental kind [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.283 (perp=10.874, rec=0.106, cos=0.002), tot_loss_proj:3.055 [t=0.17s]
prediction: ['[CLS] nonwargmental, heart heartmingental kind [SEP]']
[ 300/2000] tot_loss=2.271 (perp=10.874, rec=0.094, cos=0.002), tot_loss_proj:3.052 [t=0.17s]
prediction: ['[CLS] nonwargmental, heart heartmingental kind [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.219 (perp=10.610, rec=0.095, cos=0.002), tot_loss_proj:2.921 [t=0.17s]
prediction: ['[CLS] nonwargmental, heartming heartental kind [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.798 (perp=12.989, rec=0.196, cos=0.004), tot_loss_proj:3.698 [t=0.17s]
prediction: ['[CLS] nongmgm,mingwarming heartental kind [SEP]']
[ 450/2000] tot_loss=2.730 (perp=12.989, rec=0.130, cos=0.002), tot_loss_proj:3.656 [t=0.17s]
prediction: ['[CLS] nongmgm,mingwarming heartental kind [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.240 (perp=10.531, rec=0.132, cos=0.002), tot_loss_proj:3.051 [t=0.17s]
prediction: ['[CLS] nongmgmental,mingwarming heart kind [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.987 (perp=9.412, rec=0.102, cos=0.002), tot_loss_proj:2.336 [t=0.17s]
prediction: ['[CLS] nongmjuental, heartwarmingming kind [SEP]']
[ 600/2000] tot_loss=1.983 (perp=9.412, rec=0.099, cos=0.002), tot_loss_proj:2.326 [t=0.17s]
prediction: ['[CLS] nongmjuental, heartwarmingming kind [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.830 (perp=8.659, rec=0.097, cos=0.002), tot_loss_proj:2.094 [t=0.17s]
prediction: ['[CLS]ming nongmjuental, heartwarming kind [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.692 (perp=7.977, rec=0.095, cos=0.002), tot_loss_proj:1.898 [t=0.17s]
prediction: ['[CLS]ming nonjugmental, heartwarming kind [SEP]']
[ 750/2000] tot_loss=1.675 (perp=7.977, rec=0.078, cos=0.002), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS]ming nonjugmental, heartwarming kind [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.827 (perp=8.727, rec=0.080, cos=0.002), tot_loss_proj:2.155 [t=0.17s]
prediction: ['[CLS] noningjugmental, heartwarming kind [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.671 (perp=7.910, rec=0.087, cos=0.002), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
[ 900/2000] tot_loss=1.664 (perp=7.910, rec=0.080, cos=0.001), tot_loss_proj:1.851 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.665 (perp=7.910, rec=0.082, cos=0.001), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1000/2000] tot_loss=1.656 (perp=7.910, rec=0.072, cos=0.001), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
[1050/2000] tot_loss=1.662 (perp=7.910, rec=0.078, cos=0.001), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1100/2000] tot_loss=1.657 (perp=7.910, rec=0.073, cos=0.001), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1150/2000] tot_loss=1.653 (perp=7.910, rec=0.069, cos=0.001), tot_loss_proj:1.832 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
[1200/2000] tot_loss=1.660 (perp=7.910, rec=0.076, cos=0.001), tot_loss_proj:1.852 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1250/2000] tot_loss=1.663 (perp=7.910, rec=0.080, cos=0.001), tot_loss_proj:1.850 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1300/2000] tot_loss=1.667 (perp=7.910, rec=0.083, cos=0.001), tot_loss_proj:1.855 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
[1350/2000] tot_loss=1.659 (perp=7.910, rec=0.076, cos=0.001), tot_loss_proj:1.845 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1400/2000] tot_loss=1.657 (perp=7.910, rec=0.074, cos=0.001), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1450/2000] tot_loss=1.659 (perp=7.910, rec=0.076, cos=0.001), tot_loss_proj:1.846 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
[1500/2000] tot_loss=1.661 (perp=7.910, rec=0.078, cos=0.001), tot_loss_proj:1.838 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1550/2000] tot_loss=1.660 (perp=7.910, rec=0.077, cos=0.001), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1600/2000] tot_loss=1.659 (perp=7.910, rec=0.076, cos=0.001), tot_loss_proj:1.844 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
[1650/2000] tot_loss=1.654 (perp=7.910, rec=0.071, cos=0.001), tot_loss_proj:1.840 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1700/2000] tot_loss=1.660 (perp=7.910, rec=0.077, cos=0.001), tot_loss_proj:1.845 [t=0.18s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1750/2000] tot_loss=1.661 (perp=7.910, rec=0.078, cos=0.001), tot_loss_proj:1.838 [t=0.18s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
[1800/2000] tot_loss=1.665 (perp=7.910, rec=0.081, cos=0.001), tot_loss_proj:1.838 [t=0.18s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1850/2000] tot_loss=1.656 (perp=7.910, rec=0.073, cos=0.001), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[1900/2000] tot_loss=1.655 (perp=7.910, rec=0.072, cos=0.001), tot_loss_proj:1.832 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
[1950/2000] tot_loss=1.656 (perp=7.910, rec=0.073, cos=0.001), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Attempt swap
[2000/2000] tot_loss=1.659 (perp=7.910, rec=0.076, cos=0.001), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] nonjuinggmental, heartwarming kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] nonjuinggmental, heartwarming kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 92.664 | p: 92.211 | r: 93.218
rouge2     | fm: 61.937 | p: 61.650 | r: 62.240
rougeL     | fm: 80.293 | p: 79.903 | r: 80.689
rougeLsum  | fm: 80.195 | p: 79.836 | r: 80.674
r1fm+r2fm = 154.601

input #67 time: 0:07:30 | total time: 9:11:28


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9992789242841313
highest_index [0]
highest [0.9992789242841313]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.989619255065918 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.9645585417747498 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 0.9424722194671631 for ['[CLS] raise describedwehrwork witch rom can bray fictional elton here sex pilots [SEP]']
[Init] best rec loss: 0.9253563284873962 for ['[CLS] neutron acrosswas 2005 security tip fa— identity david entitled readers letters [SEP]']
[Init] best rec loss: 0.8706526756286621 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.8648829460144043 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.8608188629150391 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 0.8541148900985718 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 0.8531020283699036 for ['[CLS]iferous comfortyn form medal died floor. beth possibly riding view councils [SEP]']
[Init] best perm rec loss: 0.8519254326820374 for ['[CLS] possibly councils comfortiferousyn floor died form view beth. medal riding [SEP]']
[Init] best perm rec loss: 0.8488271236419678 for ['[CLS]iferous flooryn form possibly medal riding view beth councils. died comfort [SEP]']
[Init] best perm rec loss: 0.8450530767440796 for ['[CLS] beth comfortyn died form riding councils possibly medal floor. viewiferous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.288 (perp=10.528, rec=0.176, cos=0.006), tot_loss_proj:2.604 [t=0.17s]
prediction: ['[CLS] east iansible,iblecho absurd, absurd vicious and absurd un [SEP]']
[ 100/2000] tot_loss=1.634 (perp=7.620, rec=0.107, cos=0.003), tot_loss_proj:1.854 [t=0.17s]
prediction: ['[CLS] uncouth,siblecouth, absurd vicious and absurd un [SEP]']
[ 150/2000] tot_loss=1.722 (perp=8.194, rec=0.082, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] uncouth,sibleomputh, absurd vicious and absurd un [SEP]']
[ 200/2000] tot_loss=1.938 (perp=9.269, rec=0.083, cos=0.002), tot_loss_proj:2.295 [t=0.17s]
prediction: ['[CLS]ompcouth,sibleomputh, absurd vicious and absurd un [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.894 (perp=9.029, rec=0.086, cos=0.002), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS]ompcouth,sible unhenuth, absurd vicious and absurd [SEP]']
[ 300/2000] tot_loss=2.015 (perp=9.663, rec=0.081, cos=0.002), tot_loss_proj:2.237 [t=0.17s]
prediction: ['[CLS]ompcouth,sible unhenre, absurd vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.710 (perp=8.190, rec=0.071, cos=0.002), tot_loss_proj:1.945 [t=0.17s]
prediction: ['[CLS] uncouth,sibleomphenre, inc vicious and absurd [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.424 (perp=6.765, rec=0.069, cos=0.002), tot_loss_proj:1.668 [t=0.17s]
prediction: ['[CLS] uncouth,sibleomprehen, inc vicious and absurd [SEP]']
[ 450/2000] tot_loss=1.419 (perp=6.765, rec=0.065, cos=0.001), tot_loss_proj:1.659 [t=0.17s]
prediction: ['[CLS] uncouth,sibleomprehen, inc vicious and absurd [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.412 (perp=6.765, rec=0.057, cos=0.001), tot_loss_proj:1.666 [t=0.17s]
prediction: ['[CLS] uncouth,sibleomprehen, inc vicious and absurd [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.349 (perp=6.418, rec=0.064, cos=0.002), tot_loss_proj:1.469 [t=0.17s]
prediction: ['[CLS] uncouth,sible incomprehen, vicious and absurd [SEP]']
[ 600/2000] tot_loss=1.343 (perp=6.418, rec=0.057, cos=0.001), tot_loss_proj:1.471 [t=0.17s]
prediction: ['[CLS] uncouth,sible incomprehen, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.205 (perp=5.690, rec=0.066, cos=0.002), tot_loss_proj:1.306 [t=0.17s]
prediction: ['[CLS] uncouth,, incomprehensible vicious and absurd [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=0.995 (perp=4.494, rec=0.094, cos=0.002), tot_loss_proj:0.973 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[ 750/2000] tot_loss=0.972 (perp=4.494, rec=0.072, cos=0.002), tot_loss_proj:0.966 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.967 (perp=4.494, rec=0.066, cos=0.001), tot_loss_proj:0.970 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.973 (perp=4.494, rec=0.072, cos=0.001), tot_loss_proj:0.984 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[ 900/2000] tot_loss=0.975 (perp=4.494, rec=0.074, cos=0.001), tot_loss_proj:0.979 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.968 (perp=4.494, rec=0.068, cos=0.001), tot_loss_proj:0.980 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1000/2000] tot_loss=0.963 (perp=4.494, rec=0.063, cos=0.001), tot_loss_proj:0.975 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1050/2000] tot_loss=0.962 (perp=4.494, rec=0.061, cos=0.001), tot_loss_proj:0.982 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1100/2000] tot_loss=0.973 (perp=4.494, rec=0.072, cos=0.001), tot_loss_proj:0.978 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1150/2000] tot_loss=0.971 (perp=4.494, rec=0.071, cos=0.001), tot_loss_proj:0.978 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1200/2000] tot_loss=0.961 (perp=4.494, rec=0.061, cos=0.001), tot_loss_proj:0.975 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=0.961 (perp=4.494, rec=0.061, cos=0.001), tot_loss_proj:0.979 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1300/2000] tot_loss=0.970 (perp=4.494, rec=0.070, cos=0.001), tot_loss_proj:0.971 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1350/2000] tot_loss=0.959 (perp=4.494, rec=0.059, cos=0.001), tot_loss_proj:0.974 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=0.967 (perp=4.494, rec=0.067, cos=0.001), tot_loss_proj:0.979 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=0.961 (perp=4.494, rec=0.061, cos=0.001), tot_loss_proj:0.976 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1500/2000] tot_loss=0.961 (perp=4.494, rec=0.061, cos=0.001), tot_loss_proj:0.970 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=0.968 (perp=4.494, rec=0.068, cos=0.001), tot_loss_proj:0.976 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1600/2000] tot_loss=0.967 (perp=4.494, rec=0.067, cos=0.001), tot_loss_proj:0.969 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1650/2000] tot_loss=0.956 (perp=4.494, rec=0.056, cos=0.001), tot_loss_proj:0.982 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=0.963 (perp=4.494, rec=0.063, cos=0.001), tot_loss_proj:0.977 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=0.971 (perp=4.494, rec=0.071, cos=0.001), tot_loss_proj:0.977 [t=0.19s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1800/2000] tot_loss=0.963 (perp=4.494, rec=0.063, cos=0.001), tot_loss_proj:0.971 [t=0.18s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=0.957 (perp=4.494, rec=0.057, cos=0.001), tot_loss_proj:0.974 [t=0.19s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=0.970 (perp=4.494, rec=0.069, cos=0.001), tot_loss_proj:0.977 [t=0.19s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[1950/2000] tot_loss=0.955 (perp=4.494, rec=0.055, cos=0.001), tot_loss_proj:0.977 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=0.966 (perp=4.494, rec=0.066, cos=0.001), tot_loss_proj:0.968 [t=0.17s]
prediction: ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.855 | p: 92.394 | r: 93.394
rouge2     | fm: 62.439 | p: 62.117 | r: 62.814
rougeL     | fm: 80.491 | p: 80.116 | r: 80.982
rougeLsum  | fm: 80.433 | p: 80.116 | r: 80.936
r1fm+r2fm = 155.295

input #68 time: 0:07:46 | total time: 9:19:15


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9992908222867736
highest_index [0]
highest [0.9992908222867736]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.086551547050476 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9466122388839722 for ['[CLS] cade atoms especially suddenly schneider commanded noble retirement causescap meant grin immortals fai act paternal [SEP]']
[Init] best rec loss: 0.925304114818573 for ['[CLS] meetings bells mountain bloody technical script⁄ sarah rebound fare they br hospital christmas value turkmenistan [SEP]']
[Init] best rec loss: 0.9242345690727234 for ['[CLS] et roughly christian cinema angela zoo commanded determinedpine treatcraft said being amountigo ; [SEP]']
[Init] best rec loss: 0.9170600771903992 for ['[CLS] operation tactics toes collective valley stitches drop criticism insteadivequitable francis surnamezer san zone [SEP]']
[Init] best rec loss: 0.9078761339187622 for ['[CLS] mans border mormon vocational be doubt recordseft outcomes same humor spring chi ears other ling [SEP]']
[Init] best rec loss: 0.8832088112831116 for ['[CLS] tract havinggated libraries himself odd magna courtney jonah tempted miller stunning spit opened french now [SEP]']
[Init] best rec loss: 0.8760436773300171 for ['[CLS]mission down unopposedacio tray adelaide african platform burnham ferrisest port case [MASK] gross main [SEP]']
[Init] best perm rec loss: 0.8714134693145752 for ['[CLS] ferris main case african gross tray adelaide burnham port unopposedest [MASK] platformmission downacio [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.105 (perp=13.730, rec=0.349, cos=0.010), tot_loss_proj:4.377 [t=0.17s]
prediction: ['[CLS] epic risk sox clockwise livear grammy natural miles ever fm border polished labrador championpowering [SEP]']
[ 100/2000] tot_loss=2.727 (perp=12.243, rec=0.273, cos=0.005), tot_loss_proj:4.385 [t=0.17s]
prediction: ['[CLS] realand miserable pinyin livear grammy smart - a " : polished\'road innovative [SEP]']
[ 150/2000] tot_loss=2.216 (perp=9.875, rec=0.238, cos=0.003), tot_loss_proj:2.806 [t=0.17s]
prediction: ["[CLS] real, wins winner strong subtle winner smart - - two - byzantine'road wise [SEP]"]
[ 200/2000] tot_loss=2.142 (perp=9.660, rec=0.207, cos=0.003), tot_loss_proj:2.968 [t=0.17s]
prediction: ['[CLS] real, wins winner resident subtle winner funny - - " - ─\'road funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.913 (perp=8.476, rec=0.215, cos=0.003), tot_loss_proj:2.461 [t=0.17s]
prediction: ['[CLS] real, winner a subtle winner funny - - win " - blossom\'champion funny [SEP]']
[ 300/2000] tot_loss=1.986 (perp=8.931, rec=0.198, cos=0.002), tot_loss_proj:3.267 [t=0.17s]
prediction: ['[CLS] real,, a subtle winner real - subtle defeated " - blossom\'champion funny [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.662 (perp=7.320, rec=0.196, cos=0.003), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] real, funny, a subtle winner real - subtle defeated " - -\'champion [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.673 (perp=7.460, rec=0.179, cos=0.002), tot_loss_proj:2.812 [t=0.17s]
prediction: ['[CLS] real, funny, a real winner subtle - subtle defeated " - - ᵍ champion [SEP]']
[ 450/2000] tot_loss=1.592 (perp=7.103, rec=0.169, cos=0.002), tot_loss_proj:2.093 [t=0.17s]
prediction: ["[CLS] real, funny, a real winner subtle - subtle ', - - ᵍ, [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.854 (perp=7.369, rec=0.369, cos=0.011), tot_loss_proj:1.984 [t=0.17s]
prediction: ['[CLS] real, funny, a real winner subtle. devi and - - - superior champion [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.935 (perp=7.894, rec=0.347, cos=0.009), tot_loss_proj:2.201 [t=0.17s]
prediction: ['[CLS] active, funny, a real winner subtle. and - - - superior federal devi [SEP]']
[ 600/2000] tot_loss=2.006 (perp=8.392, rec=0.319, cos=0.008), tot_loss_proj:2.233 [t=0.17s]
prediction: ['[CLS] active, funny, a real winner subtle. and - - - superior federalna [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.888 (perp=7.861, rec=0.308, cos=0.008), tot_loss_proj:2.089 [t=0.17s]
prediction: ['[CLS] active, funny, a real winner subtle. and superior - - - federalna [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.785 (perp=7.371, rec=0.303, cos=0.007), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] active, funny, a real winner. subtle and superior - - - federalna [SEP]']
[ 750/2000] tot_loss=1.688 (perp=6.977, rec=0.286, cos=0.007), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] active, funny, a real winner. subtle and superior - - - federalviere [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.683 (perp=6.977, rec=0.281, cos=0.006), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] active, funny, a real winner. subtle and superior - - - federalviere [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.676 (perp=6.977, rec=0.275, cos=0.006), tot_loss_proj:1.892 [t=0.17s]
prediction: ['[CLS] active, funny, a real winner. subtle and superior - - - federalviere [SEP]']
[ 900/2000] tot_loss=1.684 (perp=6.977, rec=0.283, cos=0.006), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] active, funny, a real winner. subtle and superior - - - federalviere [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.644 (perp=6.779, rec=0.282, cos=0.006), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle superior - - - federalviere [SEP]']
Attempt swap
[1000/2000] tot_loss=1.622 (perp=6.779, rec=0.260, cos=0.006), tot_loss_proj:1.893 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle superior - - - federalviere [SEP]']
[1050/2000] tot_loss=1.629 (perp=6.779, rec=0.268, cos=0.006), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle superior - - - federalviere [SEP]']
Attempt swap
[1100/2000] tot_loss=1.625 (perp=6.779, rec=0.264, cos=0.005), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle superior - - - federalviere [SEP]']
Attempt swap
[1150/2000] tot_loss=1.633 (perp=6.826, rec=0.263, cos=0.005), tot_loss_proj:1.924 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle springs - - - federalviere [SEP]']
[1200/2000] tot_loss=1.593 (perp=6.631, rec=0.262, cos=0.005), tot_loss_proj:1.872 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle springs - - - interstateviere [SEP]']
Attempt swap
[1250/2000] tot_loss=1.601 (perp=6.631, rec=0.269, cos=0.005), tot_loss_proj:1.875 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle springs - - - interstateviere [SEP]']
Attempt swap
[1300/2000] tot_loss=1.627 (perp=6.776, rec=0.267, cos=0.005), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle springs - - - heroviere [SEP]']
[1350/2000] tot_loss=1.615 (perp=6.776, rec=0.255, cos=0.005), tot_loss_proj:1.860 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle springs - - - heroviere [SEP]']
Attempt swap
[1400/2000] tot_loss=1.620 (perp=6.776, rec=0.260, cos=0.005), tot_loss_proj:1.860 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle springs - - - heroviere [SEP]']
Attempt swap
[1450/2000] tot_loss=1.614 (perp=6.776, rec=0.255, cos=0.005), tot_loss_proj:1.859 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle springs - - - heroviere [SEP]']
[1500/2000] tot_loss=1.616 (perp=6.776, rec=0.257, cos=0.005), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle springs - - - heroviere [SEP]']
Attempt swap
[1550/2000] tot_loss=1.622 (perp=6.776, rec=0.262, cos=0.005), tot_loss_proj:1.858 [t=0.17s]
prediction: ['[CLS] active, funny, and a real winner. subtle springs - - - heroviere [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.759 (perp=7.442, rec=0.266, cos=0.005), tot_loss_proj:2.160 [t=0.17s]
prediction: ['[CLS] active, funny, and a real interstate. subtle springs - - - winnerviere [SEP]']
[1650/2000] tot_loss=1.754 (perp=7.447, rec=0.260, cos=0.005), tot_loss_proj:2.186 [t=0.17s]
prediction: ['[CLS]ive, funny, and a real interstate. subtle springs - - - winnerviere [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.729 (perp=7.388, rec=0.247, cos=0.005), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS]ive, funny, and a real interstate. subtle winner - - - springsviere [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.654 (perp=6.950, rec=0.259, cos=0.005), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS]ive, funny, and a real winner. subtle interstate - - - springsviere [SEP]']
[1800/2000] tot_loss=1.647 (perp=6.950, rec=0.252, cos=0.005), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS]ive, funny, and a real winner. subtle interstate - - - springsviere [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.656 (perp=6.983, rec=0.254, cos=0.005), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS]ive, funny, and a real winner. - hero subtle - - springsviere [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.638 (perp=6.923, rec=0.249, cos=0.005), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS]ive, funny, and a real winner. - - subtle hero - springsviere [SEP]']
[1950/2000] tot_loss=1.733 (perp=7.358, rec=0.256, cos=0.005), tot_loss_proj:2.135 [t=0.17s]
prediction: ['[CLS]ive, funny, and a real winner. - - subtle interstate - springsviere [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.604 (perp=6.719, rec=0.255, cos=0.005), tot_loss_proj:1.952 [t=0.17s]
prediction: ['[CLS]ive, funny, and a real winner. - - interstate subtle - springsviere [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] real, funny, a real winner subtle - subtle ', - - ᵍ, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 77.778 | r: 70.000
rouge2     | fm: 23.529 | p: 25.000 | r: 22.222
rougeL     | fm: 63.158 | p: 66.667 | r: 60.000
rougeLsum  | fm: 63.158 | p: 66.667 | r: 60.000
r1fm+r2fm = 97.214

[Aggregate metrics]:
rouge1     | fm: 92.558 | p: 92.174 | r: 92.999
rouge2     | fm: 61.803 | p: 61.471 | r: 62.173
rougeL     | fm: 80.376 | p: 80.062 | r: 80.729
rougeLsum  | fm: 80.286 | p: 79.953 | r: 80.642
r1fm+r2fm = 154.361

input #69 time: 0:07:43 | total time: 9:26:59


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9993748902467187
highest_index [0]
highest [0.9993748902467187]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8451830148696899 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.81871098279953 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7903928160667419 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7371676564216614 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best perm rec loss: 0.7334622144699097 for ['[CLS] detention technological sharma herself blood mark effects [SEP]']
[Init] best perm rec loss: 0.7315616607666016 for ['[CLS] blood sharma herself effects mark detention technological [SEP]']
[Init] best perm rec loss: 0.7313181161880493 for ['[CLS] detention sharma effects mark herself blood technological [SEP]']
[Init] best perm rec loss: 0.7305154204368591 for ['[CLS] sharma blood herself detention technological effects mark [SEP]']
[Init] best perm rec loss: 0.730158805847168 for ['[CLS] mark blood herself effects technological detention sharma [SEP]']
[Init] best perm rec loss: 0.7293766736984253 for ['[CLS] detention blood effects sharma herself technological mark [SEP]']
[Init] best perm rec loss: 0.7282413840293884 for ['[CLS] detention herself mark sharma technological effects blood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.590 (perp=11.031, rec=0.325, cos=0.059), tot_loss_proj:3.768 [t=0.17s]
prediction: ['[CLS] clyunk goes onunk screen [SEP]']
[ 100/2000] tot_loss=2.418 (perp=11.133, rec=0.178, cos=0.014), tot_loss_proj:3.026 [t=0.17s]
prediction: ['[CLS] clyunk gets clunk screen [SEP]']
[ 150/2000] tot_loss=2.342 (perp=11.097, rec=0.115, cos=0.008), tot_loss_proj:4.036 [t=0.17s]
prediction: ['[CLS] clyunk gets onunk screen [SEP]']
[ 200/2000] tot_loss=2.314 (perp=11.097, rec=0.089, cos=0.005), tot_loss_proj:4.023 [t=0.17s]
prediction: ['[CLS] clyunk gets onunk screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.939 (perp=9.041, rec=0.119, cos=0.011), tot_loss_proj:2.606 [t=0.17s]
prediction: ['[CLS] clunky gets onunk screen [SEP]']
[ 300/2000] tot_loss=1.893 (perp=9.041, rec=0.082, cos=0.003), tot_loss_proj:2.596 [t=0.17s]
prediction: ['[CLS] clunky gets onunk screen [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.644 (perp=7.851, rec=0.071, cos=0.003), tot_loss_proj:2.439 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.636 (perp=7.851, rec=0.063, cos=0.003), tot_loss_proj:2.453 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 450/2000] tot_loss=1.648 (perp=7.851, rec=0.075, cos=0.003), tot_loss_proj:2.447 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.647 (perp=7.851, rec=0.074, cos=0.002), tot_loss_proj:2.450 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.647 (perp=7.851, rec=0.074, cos=0.003), tot_loss_proj:2.445 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 600/2000] tot_loss=1.642 (perp=7.851, rec=0.069, cos=0.002), tot_loss_proj:2.453 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.638 (perp=7.851, rec=0.065, cos=0.002), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.647 (perp=7.851, rec=0.075, cos=0.002), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 750/2000] tot_loss=1.642 (perp=7.851, rec=0.069, cos=0.002), tot_loss_proj:2.458 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.647 (perp=7.851, rec=0.074, cos=0.002), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.655 (perp=7.851, rec=0.082, cos=0.002), tot_loss_proj:2.447 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[ 900/2000] tot_loss=1.647 (perp=7.851, rec=0.074, cos=0.002), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.635 (perp=7.851, rec=0.063, cos=0.002), tot_loss_proj:2.460 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.646 (perp=7.851, rec=0.073, cos=0.002), tot_loss_proj:2.459 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1050/2000] tot_loss=1.635 (perp=7.851, rec=0.063, cos=0.002), tot_loss_proj:2.456 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.641 (perp=7.851, rec=0.069, cos=0.002), tot_loss_proj:2.461 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.648 (perp=7.851, rec=0.076, cos=0.002), tot_loss_proj:2.469 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1200/2000] tot_loss=1.651 (perp=7.851, rec=0.078, cos=0.002), tot_loss_proj:2.463 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.641 (perp=7.851, rec=0.068, cos=0.002), tot_loss_proj:2.468 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.634 (perp=7.851, rec=0.062, cos=0.002), tot_loss_proj:2.458 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1350/2000] tot_loss=1.646 (perp=7.851, rec=0.073, cos=0.002), tot_loss_proj:2.460 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.644 (perp=7.851, rec=0.072, cos=0.002), tot_loss_proj:2.462 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.646 (perp=7.851, rec=0.073, cos=0.002), tot_loss_proj:2.535 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1500/2000] tot_loss=1.634 (perp=7.851, rec=0.061, cos=0.002), tot_loss_proj:2.535 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.638 (perp=7.851, rec=0.066, cos=0.002), tot_loss_proj:2.465 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.638 (perp=7.851, rec=0.065, cos=0.002), tot_loss_proj:2.466 [t=0.19s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1650/2000] tot_loss=1.638 (perp=7.851, rec=0.066, cos=0.002), tot_loss_proj:2.468 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.640 (perp=7.851, rec=0.067, cos=0.002), tot_loss_proj:2.464 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.645 (perp=7.851, rec=0.072, cos=0.002), tot_loss_proj:2.546 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1800/2000] tot_loss=1.634 (perp=7.851, rec=0.061, cos=0.002), tot_loss_proj:2.540 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.643 (perp=7.851, rec=0.071, cos=0.002), tot_loss_proj:2.539 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.635 (perp=7.851, rec=0.063, cos=0.002), tot_loss_proj:2.538 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
[1950/2000] tot_loss=1.645 (perp=7.851, rec=0.073, cos=0.002), tot_loss_proj:2.540 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.641 (perp=7.851, rec=0.069, cos=0.002), tot_loss_proj:2.539 [t=0.17s]
prediction: ['[CLS] clunkunky gets on screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] clunkunky gets on screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 83.333 | r: 71.429
rouge2     | fm: 18.182 | p: 20.000 | r: 16.667
rougeL     | fm: 76.923 | p: 83.333 | r: 71.429
rougeLsum  | fm: 76.923 | p: 83.333 | r: 71.429
r1fm+r2fm = 95.105

[Aggregate metrics]:
rouge1     | fm: 92.365 | p: 92.071 | r: 92.711
rouge2     | fm: 61.181 | p: 60.931 | r: 61.530
rougeL     | fm: 80.272 | p: 80.058 | r: 80.655
rougeLsum  | fm: 80.226 | p: 80.015 | r: 80.507
r1fm+r2fm = 153.546

input #70 time: 0:07:41 | total time: 9:34:41


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9993403548184047
highest_index [0]
highest [0.9993403548184047]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.8840630650520325 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.847382128238678 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8406677842140198 for ['[CLS] fed to radar county sun gunshot parchment waiting regional wallacewo dia [CLS] smiles fantasy [SEP]']
[Init] best rec loss: 0.8305583596229553 for ['[CLS] shoulders protocol powerfulfication sash jonas obligatory definition box thorough whole except visit flanked dated [SEP]']
[Init] best rec loss: 0.8247600197792053 for ['[CLS] cidloubridge living blues republicfl projections transition rally mere torpedo spellingcio espn [SEP]']
[Init] best rec loss: 0.8176411986351013 for ['[CLS] mutual internal travel grief with album careful item serious european either warp spoil waived every [SEP]']
[Init] best rec loss: 0.813213050365448 for ['[CLS] knock lily combinedzh times soundfinger assist chains kylie most asha? industryico [SEP]']
[Init] best rec loss: 0.8101482391357422 for ['[CLS]. coursearth acids south gogh beyond stage reservoir until little tombathlontered wright [SEP]']
[Init] best perm rec loss: 0.8090407252311707 for ['[CLS] tomb gogharth acids course beyond littletered wright until south. reservoir stageathlon [SEP]']
[Init] best perm rec loss: 0.8082916736602783 for ['[CLS] beyond gogh southarth wright stage course acidstered. little until tombathlon reservoir [SEP]']
[Init] best perm rec loss: 0.8073354363441467 for ['[CLS] reservoir beyond.athlon little acids tombarth wright south course stage until goghtered [SEP]']
[Init] best perm rec loss: 0.8070156574249268 for ['[CLS]. reservoir wright beyondathlon tombarth stage acids south gogh course littletered until [SEP]']
[Init] best perm rec loss: 0.8070120215415955 for ['[CLS]athlon. reservoir southarth stagetered tomb beyond wright until little gogh acids course [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.290 (perp=9.820, rec=0.283, cos=0.043), tot_loss_proj:3.352 [t=0.17s]
prediction: ['[CLS] around. species not single single jump jump moment constructed - seat v moment and [SEP]']
[ 100/2000] tot_loss=1.924 (perp=8.835, rec=0.141, cos=0.016), tot_loss_proj:2.651 [t=0.17s]
prediction: ["[CLS] position'system not a single jump seat moment jumping - seat yours moment and [SEP]"]
[ 150/2000] tot_loss=1.811 (perp=8.398, rec=0.121, cos=0.011), tot_loss_proj:2.390 [t=0.17s]
prediction: ["[CLS] -'bunch not a single jump seat moment s - seat your moment and [SEP]"]
[ 200/2000] tot_loss=1.576 (perp=7.417, rec=0.087, cos=0.006), tot_loss_proj:2.191 [t=0.17s]
prediction: ['[CLS] - s there not a single jump seat moment in - seat your moment and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.533 (perp=7.180, rec=0.093, cos=0.004), tot_loss_proj:2.044 [t=0.17s]
prediction: ['[CLS] there - s not a single jump seat moment in - your your moment and [SEP]']
[ 300/2000] tot_loss=1.515 (perp=7.180, rec=0.077, cos=0.002), tot_loss_proj:2.032 [t=0.17s]
prediction: ['[CLS] there - s not a single jump seat moment in - your your moment and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.445 (perp=6.812, rec=0.081, cos=0.002), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] there your s not a single jump seat moment in - - your moment and [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.227 (perp=5.704, rec=0.084, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ["[CLS] there's not a single jump seat in moment - - your moment and [SEP]"]
[ 450/2000] tot_loss=1.208 (perp=5.704, rec=0.066, cos=0.002), tot_loss_proj:1.613 [t=0.17s]
prediction: ["[CLS] there's not a single jump seat in moment - - your moment and [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.205 (perp=5.704, rec=0.062, cos=0.002), tot_loss_proj:1.609 [t=0.17s]
prediction: ["[CLS] there's not a single jump seat in moment - - your moment and [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.198 (perp=5.704, rec=0.056, cos=0.001), tot_loss_proj:1.604 [t=0.17s]
prediction: ["[CLS] there's not a single jump seat in moment - - your moment and [SEP]"]
[ 600/2000] tot_loss=1.137 (perp=5.370, rec=0.061, cos=0.001), tot_loss_proj:1.858 [t=0.17s]
prediction: ["[CLS] there's not a single jump seat in - - - your moment and [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.144 (perp=5.370, rec=0.068, cos=0.001), tot_loss_proj:1.853 [t=0.17s]
prediction: ["[CLS] there's not a single jump seat in - - - your moment and [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.130 (perp=5.370, rec=0.054, cos=0.001), tot_loss_proj:1.861 [t=0.17s]
prediction: ["[CLS] there's not a single jump seat in - - - your moment and [SEP]"]
[ 750/2000] tot_loss=1.139 (perp=5.370, rec=0.063, cos=0.001), tot_loss_proj:1.864 [t=0.17s]
prediction: ["[CLS] there's not a single jump seat in - - - your moment and [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.097 (perp=5.087, rec=0.079, cos=0.001), tot_loss_proj:2.081 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.082 (perp=5.087, rec=0.063, cos=0.001), tot_loss_proj:2.079 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
[ 900/2000] tot_loss=1.079 (perp=5.087, rec=0.061, cos=0.001), tot_loss_proj:2.082 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.094 (perp=5.087, rec=0.075, cos=0.001), tot_loss_proj:2.087 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.085 (perp=5.087, rec=0.066, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
[1050/2000] tot_loss=1.072 (perp=5.087, rec=0.053, cos=0.001), tot_loss_proj:1.981 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.086 (perp=5.087, rec=0.067, cos=0.001), tot_loss_proj:1.982 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.083 (perp=5.087, rec=0.065, cos=0.001), tot_loss_proj:1.992 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
[1200/2000] tot_loss=1.090 (perp=5.087, rec=0.072, cos=0.001), tot_loss_proj:1.992 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.091 (perp=5.087, rec=0.072, cos=0.001), tot_loss_proj:1.994 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.076 (perp=5.087, rec=0.058, cos=0.001), tot_loss_proj:1.986 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
[1350/2000] tot_loss=1.085 (perp=5.087, rec=0.066, cos=0.001), tot_loss_proj:1.991 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.095 (perp=5.087, rec=0.077, cos=0.001), tot_loss_proj:1.993 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.081 (perp=5.087, rec=0.063, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
[1500/2000] tot_loss=1.078 (perp=5.087, rec=0.059, cos=0.001), tot_loss_proj:1.994 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.083 (perp=5.087, rec=0.064, cos=0.001), tot_loss_proj:1.999 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.076 (perp=5.087, rec=0.057, cos=0.001), tot_loss_proj:1.990 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
[1650/2000] tot_loss=1.086 (perp=5.087, rec=0.067, cos=0.001), tot_loss_proj:2.000 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.082 (perp=5.087, rec=0.063, cos=0.001), tot_loss_proj:1.996 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.091 (perp=5.087, rec=0.072, cos=0.001), tot_loss_proj:2.005 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
[1800/2000] tot_loss=1.085 (perp=5.087, rec=0.067, cos=0.001), tot_loss_proj:2.001 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.079 (perp=5.087, rec=0.060, cos=0.001), tot_loss_proj:1.997 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.085 (perp=5.087, rec=0.066, cos=0.001), tot_loss_proj:1.999 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
[1950/2000] tot_loss=1.088 (perp=5.087, rec=0.069, cos=0.001), tot_loss_proj:1.994 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.085 (perp=5.087, rec=0.066, cos=0.001), tot_loss_proj:2.006 [t=0.17s]
prediction: ["[CLS] there's not a single seat in jump - - - your moment and [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] there's not a single seat in jump - - - your moment and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 58.333 | p: 58.333 | r: 58.333
rougeL     | fm: 84.615 | p: 84.615 | r: 84.615
rougeLsum  | fm: 84.615 | p: 84.615 | r: 84.615
r1fm+r2fm = 158.333

[Aggregate metrics]:
rouge1     | fm: 92.466 | p: 92.176 | r: 92.846
rouge2     | fm: 61.253 | p: 60.982 | r: 61.477
rougeL     | fm: 80.383 | p: 80.166 | r: 80.648
rougeLsum  | fm: 80.360 | p: 80.115 | r: 80.648
r1fm+r2fm = 153.719

input #71 time: 0:07:44 | total time: 9:42:25


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9992329827199963
highest_index [0]
highest [0.9992329827199963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7871954441070557 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.756220817565918 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7524415254592896 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7376322150230408 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.736792266368866 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7195456624031067 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best perm rec loss: 0.7185581922531128 for ['[CLS] pork accidentally reserve support ta orbital! except nonetheless lifeboat dna van walking zoneungen [SEP]']
[Init] best perm rec loss: 0.7164209485054016 for ['[CLS] except orbitalungen lifeboat dna walking nonetheless support van! pork zone ta reserve accidentally [SEP]']
[Init] best perm rec loss: 0.713283896446228 for ['[CLS] except pork zone! lifeboat nonetheless accidentally ta orbital support walking dnaungen reserve van [SEP]']
[Init] best perm rec loss: 0.7122484445571899 for ['[CLS] porkungen lifeboat support accidentally nonetheless except walking dna reserve ta! zone orbital van [SEP]']
[Init] best perm rec loss: 0.7111414074897766 for ['[CLS] orbital except pork lifeboat! accidentally support reserve walkingungen ta van dna zone nonetheless [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.012 (perp=13.231, rec=0.333, cos=0.033), tot_loss_proj:4.445 [t=0.17s]
prediction: ['[CLS] something tough blood tough card voterser laude punk paramount an ] flesh your builds [SEP]']
[ 100/2000] tot_loss=2.433 (perp=10.942, rec=0.229, cos=0.015), tot_loss_proj:3.843 [t=0.17s]
prediction: ['[CLS] has balancing tough tough time time its laude thing balancing an - violence philosophy an [SEP]']
[ 150/2000] tot_loss=2.388 (perp=11.156, rec=0.151, cos=0.006), tot_loss_proj:3.675 [t=0.17s]
prediction: ['[CLS] has balancing tough tough time time its assassination violenceoumer a violence philosophy a [SEP]']
[ 200/2000] tot_loss=2.013 (perp=9.495, rec=0.109, cos=0.004), tot_loss_proj:3.298 [t=0.20s]
prediction: ['[CLS] has balancing its tough time time its inspired violence compareder with violence philosophy a [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.953 (perp=9.324, rec=0.086, cos=0.003), tot_loss_proj:3.405 [t=0.17s]
prediction: ['[CLS] has balancing its tough time timeerfk inspired violence compared with violence philosophy a [SEP]']
[ 300/2000] tot_loss=1.955 (perp=9.324, rec=0.088, cos=0.002), tot_loss_proj:3.410 [t=0.19s]
prediction: ['[CLS] has balancing its tough time timeerfk inspired violence compared with violence philosophy a [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.866 (perp=8.969, rec=0.070, cos=0.002), tot_loss_proj:2.699 [t=0.17s]
prediction: ['[CLS] haser its tough time time balancingfk inspired violence compared with violence philosophy a [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.781 (perp=8.519, rec=0.075, cos=0.002), tot_loss_proj:2.625 [t=0.17s]
prediction: ['[CLS] haser its tough time balancing timefk inspired violence compared with violence philosophy a [SEP]']
[ 450/2000] tot_loss=1.768 (perp=8.519, rec=0.062, cos=0.002), tot_loss_proj:2.628 [t=0.17s]
prediction: ['[CLS] haser its tough time balancing timefk inspired violence compared with violence philosophy a [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.730 (perp=8.258, rec=0.076, cos=0.002), tot_loss_proj:2.578 [t=0.17s]
prediction: ['[CLS]er has its tough time balancing timefk inspired violence compared with violence philosophy a [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.909 (perp=9.186, rec=0.069, cos=0.002), tot_loss_proj:2.845 [t=0.17s]
prediction: ['[CLS]er has its tough time balancing timefk inspired violence with violence intervene philosophy a [SEP]']
[ 600/2000] tot_loss=2.000 (perp=9.619, rec=0.075, cos=0.002), tot_loss_proj:2.886 [t=0.17s]
prediction: ['[CLS]er has its tough time balancing timefk inspired - with violence intervene philosophy a [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.881 (perp=8.998, rec=0.080, cos=0.002), tot_loss_proj:2.739 [t=0.17s]
prediction: ['[CLS]er has its tough time balancing timefk inspired - with a violence intervene philosophy [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.828 (perp=8.813, rec=0.064, cos=0.002), tot_loss_proj:2.614 [t=0.17s]
prediction: ['[CLS]er has its tough time balancing timefk inspired intervene with a violence - philosophy [SEP]']
[ 750/2000] tot_loss=1.857 (perp=8.942, rec=0.067, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ['[CLS]er has its tough time balancing timefk inspiredou with a violence - philosophy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.776 (perp=8.519, rec=0.071, cos=0.002), tot_loss_proj:2.932 [t=0.17s]
prediction: ['[CLS]er has its tough time balancing time inspiredfkou with a violence - philosophy [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.598 (perp=7.632, rec=0.069, cos=0.002), tot_loss_proj:2.141 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time inspiredfkou with its violence - philosophy [SEP]']
[ 900/2000] tot_loss=1.612 (perp=7.632, rec=0.084, cos=0.002), tot_loss_proj:2.138 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time inspiredfkou with its violence - philosophy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.600 (perp=7.632, rec=0.072, cos=0.002), tot_loss_proj:2.130 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time inspiredfkou with its violence - philosophy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.596 (perp=7.632, rec=0.068, cos=0.002), tot_loss_proj:2.124 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time inspiredfkou with its violence - philosophy [SEP]']
[1050/2000] tot_loss=1.603 (perp=7.632, rec=0.075, cos=0.001), tot_loss_proj:2.133 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time inspiredfkou with its violence - philosophy [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.464 (perp=6.950, rec=0.073, cos=0.002), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing timefk compared with its violence - inspired philosophy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.463 (perp=6.950, rec=0.072, cos=0.002), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing timefk compared with its violence - inspired philosophy [SEP]']
[1200/2000] tot_loss=1.531 (perp=7.309, rec=0.068, cos=0.002), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing timefker with its violence - inspired philosophy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.524 (perp=7.309, rec=0.060, cos=0.002), tot_loss_proj:2.021 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing timefker with its violence - inspired philosophy [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.495 (perp=7.131, rec=0.067, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence -fker inspired philosophy [SEP]']
[1350/2000] tot_loss=1.508 (perp=7.131, rec=0.080, cos=0.002), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence -fker inspired philosophy [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.495 (perp=7.112, rec=0.071, cos=0.002), tot_loss_proj:1.988 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspiredfker philosophy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.485 (perp=7.112, rec=0.060, cos=0.002), tot_loss_proj:1.992 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspiredfker philosophy [SEP]']
[1500/2000] tot_loss=1.485 (perp=7.112, rec=0.061, cos=0.002), tot_loss_proj:1.984 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspiredfker philosophy [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.469 (perp=7.004, rec=0.067, cos=0.002), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
Attempt swap
[1600/2000] tot_loss=1.474 (perp=7.004, rec=0.072, cos=0.002), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
[1650/2000] tot_loss=1.476 (perp=7.004, rec=0.074, cos=0.002), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
Attempt swap
[1700/2000] tot_loss=1.468 (perp=7.004, rec=0.066, cos=0.002), tot_loss_proj:1.981 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
Attempt swap
[1750/2000] tot_loss=1.466 (perp=7.004, rec=0.064, cos=0.002), tot_loss_proj:1.986 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
[1800/2000] tot_loss=1.478 (perp=7.004, rec=0.075, cos=0.002), tot_loss_proj:1.988 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
Attempt swap
[1850/2000] tot_loss=1.475 (perp=7.004, rec=0.072, cos=0.002), tot_loss_proj:1.986 [t=0.19s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
Attempt swap
[1900/2000] tot_loss=1.463 (perp=7.004, rec=0.060, cos=0.002), tot_loss_proj:1.982 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
[1950/2000] tot_loss=1.480 (perp=7.004, rec=0.077, cos=0.002), tot_loss_proj:1.986 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
Attempt swap
[2000/2000] tot_loss=1.461 (perp=7.004, rec=0.059, cos=0.002), tot_loss_proj:1.979 [t=0.17s]
prediction: ['[CLS]er has a tough time balancing time with its violence - inspired philosophyfker [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS]er has its tough time balancing timefk inspired - with a violence intervene philosophy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 73.333 | r: 84.615
rouge2     | fm: 15.385 | p: 14.286 | r: 16.667
rougeL     | fm: 50.000 | p: 46.667 | r: 53.846
rougeLsum  | fm: 50.000 | p: 46.667 | r: 53.846
r1fm+r2fm = 93.956

[Aggregate metrics]:
rouge1     | fm: 92.247 | p: 91.883 | r: 92.723
rouge2     | fm: 60.497 | p: 60.278 | r: 60.781
rougeL     | fm: 80.037 | p: 79.780 | r: 80.402
rougeLsum  | fm: 79.960 | p: 79.679 | r: 80.298
r1fm+r2fm = 152.744

input #72 time: 0:07:49 | total time: 9:50:14


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9991746597716884
highest_index [0]
highest [0.9991746597716884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9928975701332092 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9657580256462097 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9560467600822449 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9083574414253235 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.8474614024162292 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 0.8438819646835327 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.134 (perp=9.723, rec=0.181, cos=0.009), tot_loss_proj:2.019 [t=0.20s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.016 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.000 [t=0.20s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.003 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.006 [t=0.20s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.011 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.004 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.001 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=1.998 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.011 [t=0.20s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.001 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.003 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.011 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.016 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.002 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.004 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=1.998 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.023 (perp=9.723, rec=0.076, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.994 (perp=9.723, rec=0.047, cos=0.002), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=1.998 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.022 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.008 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.016 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.012 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:1.997 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.998 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.002 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.014 (perp=9.723, rec=0.068, cos=0.002), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.001 (perp=9.723, rec=0.054, cos=0.002), tot_loss_proj:2.005 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.344 | p: 91.986 | r: 92.796
rouge2     | fm: 60.998 | p: 60.777 | r: 61.329
rougeL     | fm: 80.243 | p: 79.962 | r: 80.578
rougeLsum  | fm: 80.131 | p: 79.873 | r: 80.498
r1fm+r2fm = 153.342

input #73 time: 0:07:42 | total time: 9:57:57


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9992591939462341
highest_index [0]
highest [0.9992591939462341]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.0006722211837769 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6869400143623352 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6835439205169678 for ['[CLS] answering [SEP]']
[Init] best rec loss: 0.6572129726409912 for ['[CLS] birth [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.899 (perp=8.178, rec=0.232, cos=0.031), tot_loss_proj:2.025 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.706 (perp=8.178, rec=0.068, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.702 (perp=8.178, rec=0.064, cos=0.002), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.712 (perp=8.178, rec=0.074, cos=0.003), tot_loss_proj:1.791 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.002), tot_loss_proj:1.738 [t=0.20s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.687 (perp=8.178, rec=0.050, cos=0.002), tot_loss_proj:1.727 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.691 (perp=8.178, rec=0.054, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.705 (perp=8.178, rec=0.068, cos=0.002), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.002), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.002), tot_loss_proj:1.723 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.685 (perp=8.178, rec=0.048, cos=0.001), tot_loss_proj:1.729 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.726 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.681 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.729 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.729 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.725 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.716 (perp=8.178, rec=0.079, cos=0.001), tot_loss_proj:1.729 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.701 (perp=8.178, rec=0.064, cos=0.001), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.725 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.694 (perp=8.178, rec=0.057, cos=0.001), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.728 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.720 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.681 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.731 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.001), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.714 (perp=8.178, rec=0.077, cos=0.001), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.727 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.675 (perp=8.178, rec=0.037, cos=0.001), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.690 (perp=8.178, rec=0.053, cos=0.001), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.686 (perp=8.178, rec=0.049, cos=0.001), tot_loss_proj:1.740 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.723 [t=0.16s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.713 (perp=8.178, rec=0.076, cos=0.001), tot_loss_proj:1.729 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.744 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.720 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.709 (perp=8.178, rec=0.072, cos=0.001), tot_loss_proj:1.741 [t=0.20s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.514 | p: 92.135 | r: 92.922
rouge2     | fm: 61.702 | p: 61.425 | r: 61.960
rougeL     | fm: 80.526 | p: 80.312 | r: 80.869
rougeLsum  | fm: 80.490 | p: 80.254 | r: 80.819
r1fm+r2fm = 154.216

input #74 time: 0:07:36 | total time: 10:05:34


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9993458403755586
highest_index [0]
highest [0.9993458403755586]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.9583500623703003 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.9476472735404968 for ['[CLS] changed door covert obviously tone sinclair final hard eventdrome apps nick tempo nations diveiii willem nodded rolled [SEP]']
[Init] best rec loss: 0.9449086785316467 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.904586672782898 for ['[CLS] years public during cup months du sources community ind baseman viz together clinton est frog gum firing points prick [SEP]']
[Init] best rec loss: 0.8991710543632507 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 0.8988634347915649 for ['[CLS] gas harbour jobs primarily indy starts smile colorado spirit mach [MASK] academy breakingmetonic ling readerimum millennium [SEP]']
[Init] best rec loss: 0.8913002014160156 for ['[CLS]orin rearview bore nicky yang dynasty confidence hockey preaching mangrove meanllet ventureix resistance constitution sun nicholas piece [SEP]']
[Init] best rec loss: 0.8875274658203125 for ['[CLS] stir will case bills blocked hand miniseries electricchen words tha batting shed az happen women known gen tourist [SEP]']
[Init] best rec loss: 0.8863378167152405 for ['[CLS]thermal howbara single free better coats younger which against goddess portion 2018 octopus managed hu honoraryom compares [SEP]']
[Init] best rec loss: 0.8637418150901794 for ['[CLS]ception resultedrate left fact crown skill apollo auxiliary regardedcl magic to eachmmel viewed stood loop royalties [SEP]']
[Init] best perm rec loss: 0.8630682826042175 for ['[CLS] magic eachrate apollo stood royalties resultedmmel loopcl skill crown fact viewed auxiliary left regardedception to [SEP]']
[Init] best perm rec loss: 0.8622175455093384 for ['[CLS] stood loop crownrate auxiliarymmel left apollo each royalties to magic viewedcl skillception resulted fact regarded [SEP]']
[Init] best perm rec loss: 0.8622075319290161 for ['[CLS]mmel loop royalties regarded fact magic to left apollo stoodcl skill resultedception viewedrate each crown auxiliary [SEP]']
[Init] best perm rec loss: 0.8609483242034912 for ['[CLS]ceptionmmel auxiliary stood fact apollo regarded viewed eachclrate royalties skill magic crown resulted loop to left [SEP]']
[Init] best perm rec loss: 0.8605997562408447 for ['[CLS] resulted skill apollocl to crown stood auxiliary fact each regardedmmelception loop magic royalties viewed leftrate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.027 (perp=13.027, rec=0.387, cos=0.034), tot_loss_proj:4.356 [t=0.17s]
prediction: ['[CLS] wasn society bates mission the d wrote moments.peration avery hardly campeonato unknownclass relaxed renamed losing island [SEP]']
[ 100/2000] tot_loss=2.383 (perp=10.474, rec=0.267, cos=0.021), tot_loss_proj:4.034 [t=0.19s]
prediction: ['[CLS] got himself easily mission the d wrote denied.peration forgotten never obtained unknown not easily renamed forgotten forgotten [SEP]']
[ 150/2000] tot_loss=2.227 (perp=10.033, rec=0.209, cos=0.011), tot_loss_proj:3.894 [t=0.19s]
prediction: ['[CLS] swap sides easily excursion the d lateral instability. easily forgotten instability is isn not easily renamed or forgotten [SEP]']
[ 200/2000] tot_loss=2.239 (perp=10.295, rec=0.173, cos=0.007), tot_loss_proj:3.173 [t=0.19s]
prediction: ['[CLS] having frankly easily excursion the. lateral instabilityratingdlowenter instability is is not easily renamed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.246 (perp=10.248, rec=0.188, cos=0.008), tot_loss_proj:3.939 [t=0.17s]
prediction: ['[CLS] this is easily excursion into largest of instabilitypromisingness mental mental hyper instability not easily renamed or forgotten [SEP]']
[ 300/2000] tot_loss=2.127 (perp=9.948, rec=0.133, cos=0.004), tot_loss_proj:3.373 [t=0.17s]
prediction: ['[CLS] this isnson excursion into. of instabilityenterness mental mental over instability not easily dismissed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.191 (perp=10.296, rec=0.128, cos=0.003), tot_loss_proj:3.275 [t=0.17s]
prediction: ['[CLS] this is mental excursion into. of instabilityenter rely mentalnent hyper instability not easily dismissed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.020 (perp=9.525, rec=0.112, cos=0.003), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS] this is mental excursion into. ofnententer rely mental instability hyper instability not easily dismissed or forgotten [SEP]']
[ 450/2000] tot_loss=2.002 (perp=9.525, rec=0.094, cos=0.003), tot_loss_proj:3.200 [t=0.17s]
prediction: ['[CLS] this is mental excursion into. ofnententer rely mental instability hyper instability not easily dismissed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.894 (perp=8.959, rec=0.099, cos=0.003), tot_loss_proj:3.102 [t=0.17s]
prediction: ['[CLS] this is mental excursion into. relynententer of mental instability hyper instability not easily dismissed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.828 (perp=8.603, rec=0.105, cos=0.003), tot_loss_proj:2.973 [t=0.17s]
prediction: ['[CLS] this is. excursion into mental relynententer of mental instability stuff instability not easily dismissed or forgotten [SEP]']
[ 600/2000] tot_loss=1.816 (perp=8.603, rec=0.093, cos=0.003), tot_loss_proj:2.979 [t=0.17s]
prediction: ['[CLS] this is. excursion into mental relynententer of mental instability stuff instability not easily dismissed or forgotten [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.846 (perp=8.743, rec=0.095, cos=0.003), tot_loss_proj:2.793 [t=0.17s]
prediction: ['[CLS] this is. excursion into mental instability relynententer of mental instability hyper not easily dismissed or forgotten [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.807 (perp=8.539, rec=0.097, cos=0.003), tot_loss_proj:2.744 [t=0.17s]
prediction: ['[CLS] this is. excursion into relynententer of mental instability hyper mental instability not easily dismissed or forgotten [SEP]']
[ 750/2000] tot_loss=1.794 (perp=8.530, rec=0.085, cos=0.003), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] this is. excursion into rely ofenter of mental instability hyper mental instability not easily dismissed or forgotten [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.792 (perp=8.522, rec=0.085, cos=0.003), tot_loss_proj:2.888 [t=0.17s]
prediction: ['[CLS] this is. excursion into relyenter of mental instabilitynent hyper mental instability not easily dismissed or forgotten [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.673 (perp=7.872, rec=0.095, cos=0.004), tot_loss_proj:2.053 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instability considered hyper mental instability is not easily dismissed or forgotten [SEP]']
[ 900/2000] tot_loss=1.663 (perp=7.872, rec=0.086, cos=0.003), tot_loss_proj:2.041 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instability considered hyper mental instability is not easily dismissed or forgotten [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.662 (perp=7.855, rec=0.088, cos=0.003), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instability hyper considered mental instability is not easily dismissed or forgotten [SEP]']
Attempt swap
[1000/2000] tot_loss=1.655 (perp=7.855, rec=0.082, cos=0.003), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instability hyper considered mental instability is not easily dismissed or forgotten [SEP]']
[1050/2000] tot_loss=1.664 (perp=7.855, rec=0.091, cos=0.002), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instability hyper considered mental instability is not easily dismissed or forgotten [SEP]']
Attempt swap
[1100/2000] tot_loss=1.705 (perp=8.046, rec=0.093, cos=0.002), tot_loss_proj:2.065 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instabilitycola considered mental instability is not easily dismissed or forgotten [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.655 (perp=7.853, rec=0.082, cos=0.002), tot_loss_proj:2.074 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instabilitycola considered mental instability is not easily forgotten or dismissed [SEP]']
[1200/2000] tot_loss=1.658 (perp=7.853, rec=0.085, cos=0.002), tot_loss_proj:2.070 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instabilitycola considered mental instability is not easily forgotten or dismissed [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.588 (perp=7.490, rec=0.088, cos=0.002), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instabilitycola mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
[1300/2000] tot_loss=1.598 (perp=7.490, rec=0.098, cos=0.002), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instabilitycola mental instability is not considered easily forgotten or dismissed [SEP]']
[1350/2000] tot_loss=1.594 (perp=7.490, rec=0.093, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] this epic excursion into relyenter of mental instabilitycola mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
[1400/2000] tot_loss=1.587 (perp=7.490, rec=0.087, cos=0.002), tot_loss_proj:2.012 [t=0.19s]
prediction: ['[CLS] this epic excursion into relyenter of mental instabilitycola mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.555 (perp=7.320, rec=0.089, cos=0.003), tot_loss_proj:2.042 [t=0.17s]
prediction: ['[CLS] thisignant excursion into epicenter of mental instabilitycola mental instability is not considered easily forgotten or dismissed [SEP]']
[1500/2000] tot_loss=1.557 (perp=7.320, rec=0.091, cos=0.002), tot_loss_proj:2.046 [t=0.17s]
prediction: ['[CLS] thisignant excursion into epicenter of mental instabilitycola mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.510 (perp=7.121, rec=0.083, cos=0.003), tot_loss_proj:2.025 [t=0.17s]
prediction: ['[CLS] thisignant excursion into epicentercola mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
[1600/2000] tot_loss=1.514 (perp=7.121, rec=0.087, cos=0.003), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS] thisignant excursion into epicentercola mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
[1650/2000] tot_loss=1.515 (perp=7.121, rec=0.088, cos=0.002), tot_loss_proj:2.023 [t=0.17s]
prediction: ['[CLS] thisignant excursion into epicentercola mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
[1700/2000] tot_loss=1.512 (perp=7.121, rec=0.085, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] thisignant excursion into epicentercola mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
[1750/2000] tot_loss=1.566 (perp=7.429, rec=0.078, cos=0.002), tot_loss_proj:2.226 [t=0.17s]
prediction: ['[CLS] thisdale excursion into epicentercola mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
[1800/2000] tot_loss=1.563 (perp=7.429, rec=0.075, cos=0.002), tot_loss_proj:2.234 [t=0.19s]
prediction: ['[CLS] thisdale excursion into epicentercola mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.532 (perp=7.253, rec=0.078, cos=0.003), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] thiscola excursion into epicenterdale mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
[1900/2000] tot_loss=1.544 (perp=7.253, rec=0.091, cos=0.003), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] thiscola excursion into epicenterdale mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
[1950/2000] tot_loss=1.527 (perp=7.253, rec=0.074, cos=0.002), tot_loss_proj:2.100 [t=0.17s]
prediction: ['[CLS] thiscola excursion into epicenterdale mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.537 (perp=7.253, rec=0.084, cos=0.003), tot_loss_proj:2.103 [t=0.17s]
prediction: ['[CLS] thiscola excursion into epicenterdale mental instability of mental instability is not considered easily forgotten or dismissed [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] thiscola excursion into epicenterdale mental instability of mental instability is not considered easily forgotten or dismissed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.286 | p: 72.222 | r: 76.471
rouge2     | fm: 24.242 | p: 23.529 | r: 25.000
rougeL     | fm: 62.857 | p: 61.111 | r: 64.706
rougeLsum  | fm: 62.857 | p: 61.111 | r: 64.706
r1fm+r2fm = 98.528

[Aggregate metrics]:
rouge1     | fm: 92.241 | p: 91.882 | r: 92.701
rouge2     | fm: 61.129 | p: 60.854 | r: 61.460
rougeL     | fm: 80.176 | p: 79.925 | r: 80.543
rougeLsum  | fm: 80.113 | p: 79.829 | r: 80.451
r1fm+r2fm = 153.370

input #75 time: 0:08:46 | total time: 10:14:20


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9991386602126575
highest_index [0]
highest [0.9991386602126575]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9212543964385986 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.9036272764205933 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 0.8987579345703125 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 0.892052412033081 for ['[CLS] carrie word 38 saying subject window rican disc anatomy awardscles cf past resisted [SEP]']
[Init] best rec loss: 0.8654380440711975 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 0.8489521741867065 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 0.8485825657844543 for ['[CLS] surreal onwardsoning hard ab tauthaw mangoˣ purse left ( pushed backward [SEP]']
[Init] best perm rec loss: 0.8479114174842834 for ['[CLS] purse left hard abˣ backward mango ( surreal tautoning pushed onwardshaw [SEP]']
[Init] best perm rec loss: 0.8466055393218994 for ['[CLS] left mango onwards ( ab hard surreal taut backwardoning purse pushedˣhaw [SEP]']
[Init] best perm rec loss: 0.8464253544807434 for ['[CLS] (haw surreal purse onwards backward hardˣ taut pushedoning mango ab left [SEP]']
[Init] best perm rec loss: 0.846075177192688 for ['[CLS]oning onwards purse left ( taut pushedhaw hard mango backward abˣ surreal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.317 (perp=10.154, rec=0.266, cos=0.020), tot_loss_proj:3.642 [t=0.17s]
prediction: ['[CLS], than. although himself. bennett like stopped. not stopped challenging stopped [SEP]']
[ 100/2000] tot_loss=1.994 (perp=9.106, rec=0.165, cos=0.007), tot_loss_proj:3.105 [t=0.17s]
prediction: ['[CLS] is allen. although himself,cks as stopped, has stopped challenging stopped [SEP]']
[ 150/2000] tot_loss=2.064 (perp=9.622, rec=0.134, cos=0.006), tot_loss_proj:2.824 [t=0.17s]
prediction: ['[CLS] as allen. 66 himself,cks as stopped, has stopped challenging stopped [SEP]']
[ 200/2000] tot_loss=2.112 (perp=9.957, rec=0.116, cos=0.005), tot_loss_proj:3.049 [t=0.17s]
prediction: ["[CLS]. allen. 66 himself at'as stopped, has stopped challenging sl [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.209 (perp=9.282, rec=0.320, cos=0.033), tot_loss_proj:3.087 [t=0.17s]
prediction: ['[CLS] is. allen 66 himself at, as (, has stopped challengingperation [SEP]']
[ 300/2000] tot_loss=2.106 (perp=9.654, rec=0.171, cos=0.005), tot_loss_proj:3.129 [t=0.17s]
prediction: ['[CLS] is. allen 66 himself at as as (, has stopped challenging if [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.125 (perp=9.729, rec=0.174, cos=0.005), tot_loss_proj:3.024 [t=0.17s]
prediction: ['[CLS] s - allen 66 himself at. as (, has stopped challengingperation [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.915 (perp=8.791, rec=0.153, cos=0.004), tot_loss_proj:2.816 [t=0.17s]
prediction: ['[CLS] s - ( 66 himself at. as allen, has stopped challengingperation [SEP]']
[ 450/2000] tot_loss=1.846 (perp=8.502, rec=0.142, cos=0.004), tot_loss_proj:2.873 [t=0.17s]
prediction: ['[CLS] s - ( 66 himself at. as allen, has stopped challenging 2 [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.796 (perp=8.351, rec=0.123, cos=0.003), tot_loss_proj:2.842 [t=0.17s]
prediction: ['[CLS] s - ( allen himself at. as 66, has stopped challenging 2 [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.748 (perp=8.066, rec=0.131, cos=0.003), tot_loss_proj:2.587 [t=0.17s]
prediction: ['[CLS] s dick. allen himself at. as 66, has stopped challenging ( [SEP]']
[ 600/2000] tot_loss=1.745 (perp=8.066, rec=0.129, cos=0.003), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] s dick. allen himself at. as 66, has stopped challenging ( [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.696 (perp=7.921, rec=0.109, cos=0.003), tot_loss_proj:2.652 [t=0.17s]
prediction: ['[CLS] s dick. allen himself at ( as 66, has stopped challenging. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.706 (perp=7.921, rec=0.119, cos=0.003), tot_loss_proj:2.651 [t=0.17s]
prediction: ['[CLS] s dick. allen himself at ( as 66, has stopped challenging. [SEP]']
[ 750/2000] tot_loss=1.728 (perp=8.070, rec=0.111, cos=0.003), tot_loss_proj:2.745 [t=0.17s]
prediction: ['[CLS] s dick. allen himself at in as 66, has stopped challenging. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.676 (perp=7.820, rec=0.109, cos=0.003), tot_loss_proj:2.620 [t=0.17s]
prediction: ['[CLS] stz. allen himself at 66 as in, has stopped challenging. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.749 (perp=8.186, rec=0.109, cos=0.003), tot_loss_proj:2.886 [t=0.17s]
prediction: ['[CLS] s.tz allen himself at 66 as in, has stopped challenging. [SEP]']
[ 900/2000] tot_loss=1.745 (perp=8.186, rec=0.105, cos=0.003), tot_loss_proj:2.890 [t=0.17s]
prediction: ['[CLS] s.tz allen himself at 66 as in, has stopped challenging. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.587 (perp=7.325, rec=0.119, cos=0.003), tot_loss_proj:2.537 [t=0.17s]
prediction: ['[CLS] s. in allen himself at 66 astz, has stopped challenging. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.527 (perp=7.104, rec=0.103, cos=0.003), tot_loss_proj:2.475 [t=0.17s]
prediction: ['[CLS] s. allen in himself at 66 as ponytail, has stopped challenging. [SEP]']
[1050/2000] tot_loss=1.530 (perp=7.104, rec=0.107, cos=0.003), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] s. allen in himself at 66 as ponytail, has stopped challenging. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.644 (perp=7.645, rec=0.112, cos=0.003), tot_loss_proj:2.676 [t=0.17s]
prediction: ['[CLS] s, allen in himself at 66 as ponytail, has stopped challenging. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.551 (perp=7.162, rec=0.116, cos=0.003), tot_loss_proj:2.559 [t=0.17s]
prediction: ['[CLS] s allen, in himself at 66 as ponytail, has stopped challenging. [SEP]']
[1200/2000] tot_loss=1.542 (perp=7.162, rec=0.107, cos=0.003), tot_loss_proj:2.561 [t=0.17s]
prediction: ['[CLS] s allen, in himself at 66 as ponytail, has stopped challenging. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.541 (perp=7.162, rec=0.106, cos=0.003), tot_loss_proj:2.563 [t=0.17s]
prediction: ['[CLS] s allen, in himself at 66 as ponytail, has stopped challenging. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.622 (perp=7.556, rec=0.107, cos=0.004), tot_loss_proj:2.572 [t=0.17s]
prediction: ['[CLS] s allen. in ponytail at 66 as himself, has stopped challenging. [SEP]']
[1350/2000] tot_loss=1.513 (perp=6.997, rec=0.111, cos=0.003), tot_loss_proj:2.470 [t=0.17s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.504 (perp=6.997, rec=0.102, cos=0.003), tot_loss_proj:2.469 [t=0.17s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.509 (perp=6.997, rec=0.106, cos=0.003), tot_loss_proj:2.479 [t=0.19s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
[1500/2000] tot_loss=1.510 (perp=6.997, rec=0.108, cos=0.003), tot_loss_proj:2.479 [t=0.19s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.508 (perp=6.997, rec=0.106, cos=0.003), tot_loss_proj:2.476 [t=0.17s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.499 (perp=6.997, rec=0.097, cos=0.003), tot_loss_proj:2.475 [t=0.19s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
[1650/2000] tot_loss=1.511 (perp=6.997, rec=0.109, cos=0.003), tot_loss_proj:2.480 [t=0.17s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.501 (perp=6.997, rec=0.098, cos=0.003), tot_loss_proj:2.472 [t=0.17s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.506 (perp=6.997, rec=0.104, cos=0.003), tot_loss_proj:2.476 [t=0.18s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
[1800/2000] tot_loss=1.503 (perp=6.997, rec=0.101, cos=0.003), tot_loss_proj:2.480 [t=0.19s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.496 (perp=6.997, rec=0.094, cos=0.003), tot_loss_proj:2.472 [t=0.18s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.505 (perp=6.997, rec=0.102, cos=0.003), tot_loss_proj:2.481 [t=0.19s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
[1950/2000] tot_loss=1.504 (perp=6.997, rec=0.102, cos=0.003), tot_loss_proj:2.478 [t=0.17s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.500 (perp=6.997, rec=0.098, cos=0.003), tot_loss_proj:2.479 [t=0.17s]
prediction: ['[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s allen, in ponytail at 66 as himself, has stopped challenging. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 34.783 | p: 33.333 | r: 36.364
rougeL     | fm: 72.000 | p: 69.231 | r: 75.000
rougeLsum  | fm: 72.000 | p: 69.231 | r: 75.000
r1fm+r2fm = 122.783

[Aggregate metrics]:
rouge1     | fm: 92.129 | p: 91.709 | r: 92.641
rouge2     | fm: 60.715 | p: 60.473 | r: 61.017
rougeL     | fm: 80.221 | p: 79.860 | r: 80.634
rougeLsum  | fm: 80.095 | p: 79.775 | r: 80.485
r1fm+r2fm = 152.844

input #76 time: 0:07:24 | total time: 10:21:44


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9992013460879874
highest_index [0]
highest [0.9992013460879874]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.9127402305603027 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.8795410990715027 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.8759706020355225 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best rec loss: 0.8712755441665649 for ['[CLS]yana daylight matthewlson blacksmithdrop county endless rural tel gallery pencil poet something yugoslav [SEP]']
[Init] best perm rec loss: 0.8703407049179077 for ['[CLS] ruraldrop endless yugoslavlson countyyana pencil tel poet something daylight gallery blacksmith matthew [SEP]']
[Init] best perm rec loss: 0.8697276711463928 for ['[CLS] county somethingdropyana gallery rural daylight tellson matthew blacksmith pencil yugoslav endless poet [SEP]']
[Init] best perm rec loss: 0.8681926727294922 for ['[CLS] gallerydrop endless tel matthewyana countylson blacksmith yugoslav rural poet something daylight pencil [SEP]']
[Init] best perm rec loss: 0.8674351572990417 for ['[CLS] pencildrop yugoslav endless something matthew gallery tel ruralyanalson daylight county blacksmith poet [SEP]']
[Init] best perm rec loss: 0.8671553730964661 for ['[CLS] blacksmith countyyana daylight endless yugoslav gallerydrop matthew pencil rural poetlson tel something [SEP]']
[Init] best perm rec loss: 0.8659143447875977 for ['[CLS] poet yugoslav county daylight matthewyanadrop something pencil gallery tel blacksmith endlesslson rural [SEP]']
[Init] best perm rec loss: 0.8652167916297913 for ['[CLS]lson gallery matthewdrop pencil something daylight yugoslav county endless tel rural blacksmith poetyana [SEP]']
[Init] best perm rec loss: 0.8632962107658386 for ['[CLS]yana poet county something matthew blacksmithdrop endless rural pencil tel daylightlson gallery yugoslav [SEP]']
[Init] best perm rec loss: 0.863000750541687 for ['[CLS] poet daylightdrop county something gallery blacksmithlson rural pencil tel yugoslav matthewyana endless [SEP]']
[Init] best perm rec loss: 0.862393856048584 for ['[CLS] poet matthewdrop yugoslav endless galleryyana something countylson tel blacksmith rural pencil daylight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.552 (perp=11.091, rec=0.312, cos=0.022), tot_loss_proj:4.048 [t=0.17s]
prediction: ['[CLS] trickp above reformation ourora has growing last acceptance substanceed of years lay [SEP]']
[ 100/2000] tot_loss=2.376 (perp=10.620, rec=0.243, cos=0.009), tot_loss_proj:3.046 [t=0.17s]
prediction: ['[CLS] soor above life its believe ultimately above being promise materialurable of believe is [SEP]']
[ 150/2000] tot_loss=1.979 (perp=8.942, rec=0.185, cos=0.006), tot_loss_proj:2.712 [t=0.17s]
prediction: ['[CLS] so promise above life its make believe above life promise materialر that believe is [SEP]']
[ 200/2000] tot_loss=1.896 (perp=8.577, rec=0.174, cos=0.006), tot_loss_proj:2.590 [t=0.17s]
prediction: ['[CLS] so promise above life its make believe above life promise materialed that believe is [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.966 (perp=8.917, rec=0.177, cos=0.005), tot_loss_proj:2.571 [t=0.17s]
prediction: ['[CLS] runs promise that believe above world its make believe above life promise materialed is [SEP]']
[ 300/2000] tot_loss=2.195 (perp=10.025, rec=0.180, cos=0.010), tot_loss_proj:2.974 [t=0.17s]
prediction: ['[CLS]ars promise that make above realm its make believe above life promise material of is [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.004 (perp=9.345, rec=0.132, cos=0.003), tot_loss_proj:2.904 [t=0.17s]
prediction: ['[CLS]ars promise that believe of realm life make believe above its promise material of is [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.926 (perp=9.011, rec=0.121, cos=0.003), tot_loss_proj:2.866 [t=0.17s]
prediction: ['[CLS]ars promise that believe life of realm make believe above its promise material of is [SEP]']
[ 450/2000] tot_loss=1.912 (perp=9.011, rec=0.108, cos=0.002), tot_loss_proj:2.861 [t=0.17s]
prediction: ['[CLS]ars promise that believe life of realm make believe above its promise material of is [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.813 (perp=8.505, rec=0.110, cos=0.002), tot_loss_proj:2.735 [t=0.17s]
prediction: ['[CLS]ars promise that believe life of realm make believe above its promise of material is [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.764 (perp=8.200, rec=0.121, cos=0.003), tot_loss_proj:2.706 [t=0.17s]
prediction: ['[CLS]arsar that believe life of make believe above its promise of realm material is [SEP]']
[ 600/2000] tot_loss=1.701 (perp=8.005, rec=0.098, cos=0.002), tot_loss_proj:2.655 [t=0.17s]
prediction: ['[CLS]arsars that believe life of make believe above its promise of realm material is [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.638 (perp=7.642, rec=0.107, cos=0.002), tot_loss_proj:2.588 [t=0.17s]
prediction: ['[CLS]arsars that believe life of make believe above its promise of material realm is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.638 (perp=7.642, rec=0.108, cos=0.002), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS]arsars that believe life of make believe above its promise of material realm is [SEP]']
[ 750/2000] tot_loss=1.615 (perp=7.642, rec=0.084, cos=0.002), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS]arsars that believe life of make believe above its promise of material realm is [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.544 (perp=7.270, rec=0.088, cos=0.002), tot_loss_proj:2.518 [t=0.17s]
prediction: ['[CLS]arsars believe that life the make believe above its promise of material realm is [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.527 (perp=7.174, rec=0.090, cos=0.002), tot_loss_proj:2.452 [t=0.17s]
prediction: ['[CLS]arsars believe that life above the make believe its promise of material realm is [SEP]']
[ 900/2000] tot_loss=1.535 (perp=7.174, rec=0.098, cos=0.002), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS]arsars believe that life above the make believe its promise of material realm is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.531 (perp=7.174, rec=0.094, cos=0.002), tot_loss_proj:2.450 [t=0.17s]
prediction: ['[CLS]arsars believe that life above the make believe its promise of material realm is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.525 (perp=7.174, rec=0.088, cos=0.002), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS]arsars believe that life above the make believe its promise of material realm is [SEP]']
[1050/2000] tot_loss=1.520 (perp=7.174, rec=0.083, cos=0.002), tot_loss_proj:2.447 [t=0.17s]
prediction: ['[CLS]arsars believe that life above the make believe its promise of material realm is [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.504 (perp=7.015, rec=0.099, cos=0.002), tot_loss_proj:2.413 [t=0.17s]
prediction: ['[CLS]arsars believe that life above make believe its promise of the material realm is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.498 (perp=7.015, rec=0.094, cos=0.002), tot_loss_proj:2.414 [t=0.17s]
prediction: ['[CLS]arsars believe that life above make believe its promise of the material realm is [SEP]']
[1200/2000] tot_loss=1.485 (perp=7.015, rec=0.080, cos=0.002), tot_loss_proj:2.405 [t=0.17s]
prediction: ['[CLS]arsars believe that life above make believe its promise of the material realm is [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.418 (perp=6.639, rec=0.088, cos=0.002), tot_loss_proj:2.265 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe its promise of life above the material realm is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.416 (perp=6.639, rec=0.087, cos=0.002), tot_loss_proj:2.261 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe its promise of life above the material realm is [SEP]']
[1350/2000] tot_loss=1.410 (perp=6.639, rec=0.080, cos=0.002), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe its promise of life above the material realm is [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.367 (perp=6.375, rec=0.090, cos=0.002), tot_loss_proj:1.993 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
Attempt swap
[1450/2000] tot_loss=1.370 (perp=6.375, rec=0.093, cos=0.002), tot_loss_proj:1.996 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
[1500/2000] tot_loss=1.364 (perp=6.375, rec=0.087, cos=0.002), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
Attempt swap
[1550/2000] tot_loss=1.359 (perp=6.375, rec=0.082, cos=0.002), tot_loss_proj:1.999 [t=0.18s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
Attempt swap
[1600/2000] tot_loss=1.359 (perp=6.375, rec=0.082, cos=0.002), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
[1650/2000] tot_loss=1.355 (perp=6.375, rec=0.079, cos=0.002), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
Attempt swap
[1700/2000] tot_loss=1.357 (perp=6.375, rec=0.080, cos=0.002), tot_loss_proj:1.999 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
Attempt swap
[1750/2000] tot_loss=1.365 (perp=6.375, rec=0.088, cos=0.002), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
[1800/2000] tot_loss=1.356 (perp=6.375, rec=0.079, cos=0.002), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
Attempt swap
[1850/2000] tot_loss=1.361 (perp=6.375, rec=0.084, cos=0.002), tot_loss_proj:2.004 [t=0.17s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
Attempt swap
[1900/2000] tot_loss=1.366 (perp=6.375, rec=0.089, cos=0.002), tot_loss_proj:1.992 [t=0.19s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
[1950/2000] tot_loss=1.354 (perp=6.375, rec=0.078, cos=0.002), tot_loss_proj:1.998 [t=0.19s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
Attempt swap
[2000/2000] tot_loss=1.363 (perp=6.375, rec=0.087, cos=0.002), tot_loss_proj:1.997 [t=0.20s]
prediction: ['[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS]arsars believe that make believe is its promise of life above the material realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.323 | p: 87.500 | r: 93.333
rouge2     | fm: 55.172 | p: 53.333 | r: 57.143
rougeL     | fm: 70.968 | p: 68.750 | r: 73.333
rougeLsum  | fm: 70.968 | p: 68.750 | r: 73.333
r1fm+r2fm = 145.495

[Aggregate metrics]:
rouge1     | fm: 92.163 | p: 91.682 | r: 92.713
rouge2     | fm: 60.624 | p: 60.356 | r: 60.923
rougeL     | fm: 80.040 | p: 79.728 | r: 80.453
rougeLsum  | fm: 79.935 | p: 79.542 | r: 80.427
r1fm+r2fm = 152.787

input #77 time: 0:07:59 | total time: 10:29:44


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9992696483604169
highest_index [0]
highest [0.9992696483604169]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9868218302726746 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9798540472984314 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8532800674438477 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.8239110112190247 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 0.8230682015419006 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.981 (perp=8.972, rec=0.177, cos=0.010), tot_loss_proj:2.709 [t=0.21s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 100/2000] tot_loss=1.907 (perp=8.972, rec=0.109, cos=0.004), tot_loss_proj:2.712 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 150/2000] tot_loss=1.893 (perp=8.972, rec=0.094, cos=0.005), tot_loss_proj:2.719 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 200/2000] tot_loss=1.887 (perp=8.972, rec=0.088, cos=0.004), tot_loss_proj:2.726 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.886 (perp=8.972, rec=0.087, cos=0.004), tot_loss_proj:2.727 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 300/2000] tot_loss=2.224 (perp=10.782, rec=0.066, cos=0.002), tot_loss_proj:2.997 [t=0.17s]
prediction: ['[CLS] exit theater the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.676 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.677 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.667 (perp=7.958, rec=0.074, cos=0.001), tot_loss_proj:1.671 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.673 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.692 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.679 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.665 (perp=7.958, rec=0.072, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.679 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.640 (perp=7.958, rec=0.047, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.677 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.658 (perp=7.958, rec=0.065, cos=0.001), tot_loss_proj:1.672 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.644 (perp=7.958, rec=0.051, cos=0.001), tot_loss_proj:1.668 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.639 (perp=7.958, rec=0.046, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.667 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.642 (perp=7.958, rec=0.049, cos=0.001), tot_loss_proj:1.673 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.636 (perp=7.958, rec=0.043, cos=0.001), tot_loss_proj:1.680 [t=0.19s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.676 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.207 | p: 91.762 | r: 92.735
rouge2     | fm: 61.041 | p: 60.760 | r: 61.381
rougeL     | fm: 80.242 | p: 79.924 | r: 80.656
rougeLsum  | fm: 80.288 | p: 79.965 | r: 80.712
r1fm+r2fm = 153.249

input #78 time: 0:08:50 | total time: 10:38:35


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.9993343381444821
highest_index [0]
highest [0.9993343381444821]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.97676020860672 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.8503931164741516 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.8493977189064026 for ['[CLS]rna into [SEP]']
[Init] best rec loss: 0.8459595441818237 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.8386962413787842 for ['[CLS] funslow [SEP]']
[Init] best rec loss: 0.8356737494468689 for ['[CLS] gray should [SEP]']
[Init] best rec loss: 0.8324992060661316 for ['[CLS] comte sculptor [SEP]']
[Init] best perm rec loss: 0.8268929123878479 for ['[CLS] sculptor comte [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.497 (perp=11.428, rec=0.207, cos=0.005), tot_loss_proj:2.639 [t=0.17s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 100/2000] tot_loss=2.449 (perp=11.428, rec=0.159, cos=0.004), tot_loss_proj:2.626 [t=0.17s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 150/2000] tot_loss=2.431 (perp=11.428, rec=0.142, cos=0.003), tot_loss_proj:2.623 [t=0.17s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=1.967 (perp=9.381, rec=0.089, cos=0.001), tot_loss_proj:1.954 [t=0.17s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.942 (perp=9.381, rec=0.064, cos=0.001), tot_loss_proj:1.947 [t=0.17s]
prediction: ['[CLS] is fascinating [SEP]']
[ 300/2000] tot_loss=1.945 (perp=9.381, rec=0.067, cos=0.001), tot_loss_proj:1.944 [t=0.17s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.940 (perp=9.381, rec=0.063, cos=0.001), tot_loss_proj:1.948 [t=0.17s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.822 (perp=8.695, rec=0.082, cos=0.002), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.809 (perp=8.695, rec=0.068, cos=0.001), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.818 (perp=8.695, rec=0.077, cos=0.001), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.960 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.810 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.955 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.815 (perp=8.695, rec=0.075, cos=0.001), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.800 (perp=8.695, rec=0.060, cos=0.001), tot_loss_proj:1.960 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.801 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.797 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.961 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.961 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.804 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.817 (perp=8.695, rec=0.077, cos=0.001), tot_loss_proj:1.961 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.954 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.966 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.788 (perp=8.695, rec=0.048, cos=0.001), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.795 (perp=8.695, rec=0.055, cos=0.001), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.957 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.959 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.799 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.971 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.800 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.955 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.817 (perp=8.695, rec=0.076, cos=0.001), tot_loss_proj:1.954 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.791 (perp=8.695, rec=0.050, cos=0.001), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.812 (perp=8.695, rec=0.072, cos=0.001), tot_loss_proj:1.958 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.814 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.963 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.799 (perp=8.695, rec=0.059, cos=0.001), tot_loss_proj:1.961 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.344 | p: 91.903 | r: 92.864
rouge2     | fm: 60.360 | p: 60.060 | r: 60.703
rougeL     | fm: 80.275 | p: 79.971 | r: 80.705
rougeLsum  | fm: 80.077 | p: 79.737 | r: 80.516
r1fm+r2fm = 152.704

input #79 time: 0:07:43 | total time: 10:46:18


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9992812106805644
highest_index [0]
highest [0.9992812106805644]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9617707133293152 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9375922083854675 for ['[CLS] team joined target * results [SEP]']
[Init] best rec loss: 0.9287824034690857 for ['[CLS]down frasercake court beta [SEP]']
[Init] best rec loss: 0.9259979724884033 for ['[CLS] western area whilepres took [SEP]']
[Init] best rec loss: 0.9242680668830872 for ['[CLS] close blonde form parks pussy [SEP]']
[Init] best rec loss: 0.9182730913162231 for ["[CLS]'incense kraft it jubilee [SEP]"]
[Init] best perm rec loss: 0.9177989959716797 for ["[CLS] jubilee incense'kraft it [SEP]"]
[Init] best perm rec loss: 0.9138138294219971 for ["[CLS] jubilee'kraft it incense [SEP]"]
[Init] best perm rec loss: 0.913648784160614 for ["[CLS] incense it'jubilee kraft [SEP]"]
[Init] best perm rec loss: 0.9132492542266846 for ["[CLS] kraft jubilee it incense'[SEP]"]
[Init] best perm rec loss: 0.9125822186470032 for ["[CLS] it incense kraft jubilee'[SEP]"]
[Init] best perm rec loss: 0.9123266935348511 for ["[CLS] kraft it'incense jubilee [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.604 (perp=11.746, rec=0.250, cos=0.005), tot_loss_proj:3.299 [t=0.17s]
prediction: ['[CLS] versa wise watersted wise [SEP]']
[ 100/2000] tot_loss=2.470 (perp=11.464, rec=0.174, cos=0.003), tot_loss_proj:2.960 [t=0.17s]
prediction: ['[CLS]zen wise ;zen wise [SEP]']
[ 150/2000] tot_loss=2.384 (perp=11.158, rec=0.150, cos=0.003), tot_loss_proj:2.873 [t=0.17s]
prediction: ['[CLS]zen wise,zen wise [SEP]']
[ 200/2000] tot_loss=2.775 (perp=13.152, rec=0.141, cos=0.003), tot_loss_proj:3.544 [t=0.17s]
prediction: ['[CLS]zen wisebellazen wise [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.622 (perp=7.418, rec=0.136, cos=0.003), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] wise wizened wise [SEP]']
[ 300/2000] tot_loss=1.879 (perp=8.909, rec=0.095, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] wi wizened wise [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.751 (perp=8.250, rec=0.099, cos=0.002), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.745 (perp=8.250, rec=0.093, cos=0.002), tot_loss_proj:2.015 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
[ 450/2000] tot_loss=1.740 (perp=8.250, rec=0.088, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.743 (perp=8.250, rec=0.091, cos=0.002), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.737 (perp=8.250, rec=0.085, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
[ 600/2000] tot_loss=1.750 (perp=8.250, rec=0.098, cos=0.002), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.750 (perp=8.250, rec=0.098, cos=0.002), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.739 (perp=8.250, rec=0.087, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
[ 750/2000] tot_loss=1.736 (perp=8.250, rec=0.084, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.726 (perp=8.250, rec=0.074, cos=0.002), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.722 (perp=8.250, rec=0.070, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
[ 900/2000] tot_loss=1.731 (perp=8.250, rec=0.079, cos=0.001), tot_loss_proj:2.029 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.720 (perp=8.250, rec=0.068, cos=0.001), tot_loss_proj:2.027 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[1000/2000] tot_loss=1.707 (perp=8.250, rec=0.056, cos=0.001), tot_loss_proj:2.023 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
[1050/2000] tot_loss=1.723 (perp=8.250, rec=0.071, cos=0.001), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] wizened wi wise [SEP]']
Attempt swap
[1100/2000] tot_loss=2.345 (perp=11.326, rec=0.078, cos=0.001), tot_loss_proj:2.840 [t=0.17s]
prediction: ['[CLS],zened wi wise [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.444 (perp=6.853, rec=0.072, cos=0.002), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS], wizened wise [SEP]']
[1200/2000] tot_loss=1.433 (perp=6.853, rec=0.062, cos=0.001), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS], wizened wise [SEP]']
Attempt swap
[1250/2000] tot_loss=1.449 (perp=6.853, rec=0.077, cos=0.001), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS], wizened wise [SEP]']
Attempt swap
Put prefix at the end
[1300/2000] tot_loss=1.369 (perp=6.464, rec=0.075, cos=0.001), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
[1350/2000] tot_loss=1.353 (perp=6.464, rec=0.059, cos=0.001), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.359 (perp=6.464, rec=0.064, cos=0.001), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.362 (perp=6.464, rec=0.068, cos=0.001), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
[1500/2000] tot_loss=1.355 (perp=6.464, rec=0.061, cos=0.001), tot_loss_proj:1.525 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.359 (perp=6.464, rec=0.065, cos=0.001), tot_loss_proj:1.522 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.354 (perp=6.464, rec=0.059, cos=0.001), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
[1650/2000] tot_loss=1.354 (perp=6.464, rec=0.059, cos=0.001), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.370 (perp=6.464, rec=0.076, cos=0.001), tot_loss_proj:1.525 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.366 (perp=6.464, rec=0.072, cos=0.001), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
[1800/2000] tot_loss=1.360 (perp=6.464, rec=0.066, cos=0.001), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.362 (perp=6.464, rec=0.068, cos=0.001), tot_loss_proj:1.520 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.361 (perp=6.464, rec=0.067, cos=0.001), tot_loss_proj:1.524 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
[1950/2000] tot_loss=1.362 (perp=6.464, rec=0.068, cos=0.001), tot_loss_proj:1.523 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.361 (perp=6.464, rec=0.067, cos=0.001), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] wizened wise, [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wizened wise, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 92.414 | p: 91.974 | r: 92.949
rouge2     | fm: 59.709 | p: 59.399 | r: 59.994
rougeL     | fm: 80.178 | p: 79.818 | r: 80.579
rougeLsum  | fm: 80.081 | p: 79.767 | r: 80.484
r1fm+r2fm = 152.123

input #80 time: 0:08:00 | total time: 10:54:19


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9992879299948307
highest_index [0]
highest [0.9992879299948307]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9063941836357117 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.85554039478302 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8432484865188599 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.8243643641471863 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.8131975531578064 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.8085715174674988 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 0.794321596622467 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 0.790020227432251 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 0.7895707488059998 for ['[CLS] ivy proceededplate donaldsondownvik [SEP]']
[Init] best perm rec loss: 0.7880122065544128 for ['[CLS]down ivyvik proceeded donaldsonplate [SEP]']
[Init] best perm rec loss: 0.786943256855011 for ['[CLS] ivy donaldson proceededvikplatedown [SEP]']
[Init] best perm rec loss: 0.7865198850631714 for ['[CLS]vik ivy donaldsondown proceededplate [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.020 (perp=12.788, rec=0.390, cos=0.072), tot_loss_proj:3.700 [t=0.24s]
prediction: ['[CLS] established growing poor impressive most not [SEP]']
[ 100/2000] tot_loss=2.163 (perp=9.568, rec=0.232, cos=0.017), tot_loss_proj:3.238 [t=0.17s]
prediction: ['[CLS] majority is not player most not [SEP]']
[ 150/2000] tot_loss=2.034 (perp=9.274, rec=0.167, cos=0.012), tot_loss_proj:3.612 [t=0.17s]
prediction: ['[CLS] impressive is not player most player [SEP]']
[ 200/2000] tot_loss=1.974 (perp=9.274, rec=0.114, cos=0.006), tot_loss_proj:3.610 [t=0.17s]
prediction: ['[CLS] impressive is not player most player [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.708 (perp=7.966, rec=0.108, cos=0.006), tot_loss_proj:3.003 [t=0.17s]
prediction: ['[CLS] player is not player most impressive [SEP]']
[ 300/2000] tot_loss=1.693 (perp=7.966, rec=0.095, cos=0.005), tot_loss_proj:3.023 [t=0.17s]
prediction: ['[CLS] player is not player most impressive [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.622 (perp=7.545, rec=0.108, cos=0.005), tot_loss_proj:2.328 [t=0.17s]
prediction: ['[CLS] player is player not most impressive [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.524 (perp=7.037, rec=0.109, cos=0.007), tot_loss_proj:3.227 [t=0.19s]
prediction: ['[CLS] player not player is most impressive [SEP]']
[ 450/2000] tot_loss=1.513 (perp=7.037, rec=0.100, cos=0.005), tot_loss_proj:3.228 [t=0.19s]
prediction: ['[CLS] player not player is most impressive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.509 (perp=7.037, rec=0.097, cos=0.005), tot_loss_proj:3.228 [t=0.19s]
prediction: ['[CLS] player not player is most impressive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.499 (perp=7.037, rec=0.087, cos=0.005), tot_loss_proj:3.226 [t=0.19s]
prediction: ['[CLS] player not player is most impressive [SEP]']
[ 600/2000] tot_loss=1.513 (perp=7.037, rec=0.101, cos=0.005), tot_loss_proj:3.226 [t=0.18s]
prediction: ['[CLS] player not player is most impressive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.510 (perp=7.037, rec=0.098, cos=0.005), tot_loss_proj:3.230 [t=0.18s]
prediction: ['[CLS] player not player is most impressive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.498 (perp=7.037, rec=0.086, cos=0.005), tot_loss_proj:3.228 [t=0.17s]
prediction: ['[CLS] player not player is most impressive [SEP]']
[ 750/2000] tot_loss=1.499 (perp=7.037, rec=0.088, cos=0.004), tot_loss_proj:3.227 [t=0.17s]
prediction: ['[CLS] player not player is most impressive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.502 (perp=7.037, rec=0.090, cos=0.004), tot_loss_proj:3.229 [t=0.17s]
prediction: ['[CLS] player not player is most impressive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.508 (perp=7.037, rec=0.096, cos=0.004), tot_loss_proj:3.228 [t=0.16s]
prediction: ['[CLS] player not player is most impressive [SEP]']
[ 900/2000] tot_loss=1.501 (perp=7.037, rec=0.089, cos=0.004), tot_loss_proj:3.225 [t=0.17s]
prediction: ['[CLS] player not player is most impressive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.460 (perp=6.890, rec=0.080, cos=0.003), tot_loss_proj:3.146 [t=0.17s]
prediction: ['[CLS] the not player is most impressive [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.371 (perp=6.481, rec=0.073, cos=0.002), tot_loss_proj:2.165 [t=0.17s]
prediction: ['[CLS] not the player is most impressive [SEP]']
[1050/2000] tot_loss=1.382 (perp=6.481, rec=0.084, cos=0.002), tot_loss_proj:2.161 [t=0.17s]
prediction: ['[CLS] not the player is most impressive [SEP]']
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.274 (perp=5.946, rec=0.082, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.266 (perp=5.946, rec=0.075, cos=0.002), tot_loss_proj:1.656 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1200/2000] tot_loss=1.265 (perp=5.946, rec=0.074, cos=0.002), tot_loss_proj:1.643 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.260 (perp=5.946, rec=0.069, cos=0.002), tot_loss_proj:1.636 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.247 (perp=5.946, rec=0.056, cos=0.002), tot_loss_proj:1.639 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1350/2000] tot_loss=1.275 (perp=5.946, rec=0.084, cos=0.002), tot_loss_proj:1.648 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.254 (perp=5.946, rec=0.063, cos=0.002), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.259 (perp=5.946, rec=0.068, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1500/2000] tot_loss=1.263 (perp=5.946, rec=0.072, cos=0.002), tot_loss_proj:1.641 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.261 (perp=5.946, rec=0.070, cos=0.002), tot_loss_proj:1.640 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.253 (perp=5.946, rec=0.062, cos=0.002), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1650/2000] tot_loss=1.264 (perp=5.946, rec=0.073, cos=0.002), tot_loss_proj:1.642 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.258 (perp=5.946, rec=0.067, cos=0.002), tot_loss_proj:1.640 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.269 (perp=5.946, rec=0.078, cos=0.002), tot_loss_proj:1.651 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1800/2000] tot_loss=1.258 (perp=5.946, rec=0.067, cos=0.002), tot_loss_proj:1.639 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.264 (perp=5.946, rec=0.073, cos=0.002), tot_loss_proj:1.637 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.270 (perp=5.946, rec=0.080, cos=0.002), tot_loss_proj:1.645 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
[1950/2000] tot_loss=1.260 (perp=5.946, rec=0.070, cos=0.002), tot_loss_proj:1.637 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.261 (perp=5.946, rec=0.070, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] player is not the most impressive [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] player is not the most impressive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 92.525 | p: 92.085 | r: 93.084
rouge2     | fm: 59.578 | p: 59.342 | r: 59.908
rougeL     | fm: 80.273 | p: 79.953 | r: 80.704
rougeLsum  | fm: 80.158 | p: 79.845 | r: 80.586
r1fm+r2fm = 152.103

input #81 time: 0:07:36 | total time: 11:01:55


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.9992801011451229
highest_index [0]
highest [0.9992801011451229]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.98771733045578 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9761659502983093 for ['[CLS] vicky drewris towardpheus clue engineering arts [SEP]']
[Init] best rec loss: 0.9474851489067078 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.9335925579071045 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9326500296592712 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 0.8672366738319397 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.8271898627281189 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8216337561607361 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8212171196937561 for ['[CLS]basket plumage whoeverach respective role recordfur [SEP]']
[Init] best perm rec loss: 0.8198072910308838 for ['[CLS] respectivebasket record plumagefurach role whoever [SEP]']
[Init] best perm rec loss: 0.819161593914032 for ['[CLS] respectiveach whoeverfur role record plumagebasket [SEP]']
[Init] best perm rec loss: 0.81831294298172 for ['[CLS]fur respective rolebasketach plumage whoever record [SEP]']
[Init] best perm rec loss: 0.8175076842308044 for ['[CLS] whoeverbasket role respective plumagefurach record [SEP]']
[Init] best perm rec loss: 0.8163747787475586 for ['[CLS]furbasket respective roleach plumage record whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.668 (perp=12.195, rec=0.223, cos=0.006), tot_loss_proj:3.216 [t=0.17s]
prediction: ['[CLS] sloppy undone aryhus undone script a [SEP]']
[ 100/2000] tot_loss=2.142 (perp=10.264, rec=0.087, cos=0.003), tot_loss_proj:2.423 [t=0.17s]
prediction: ['[CLS] sloppy undone s by a sloppy script it [SEP]']
[ 150/2000] tot_loss=2.130 (perp=10.264, rec=0.075, cos=0.002), tot_loss_proj:2.425 [t=0.17s]
prediction: ['[CLS] sloppy undone s by a sloppy script it [SEP]']
[ 200/2000] tot_loss=2.125 (perp=10.264, rec=0.069, cos=0.003), tot_loss_proj:2.418 [t=0.17s]
prediction: ['[CLS] sloppy undone s by a sloppy script it [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.880 (perp=9.029, rec=0.072, cos=0.002), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] sloppy s undone by a sloppy script it [SEP]']
[ 300/2000] tot_loss=1.884 (perp=9.029, rec=0.077, cos=0.002), tot_loss_proj:2.131 [t=0.18s]
prediction: ['[CLS] sloppy s undone by a sloppy script it [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.626 (perp=7.783, rec=0.067, cos=0.002), tot_loss_proj:1.827 [t=0.17s]
prediction: ['[CLS] it sloppy s undone by a sloppy script [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.565 (perp=7.465, rec=0.070, cos=0.002), tot_loss_proj:1.637 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 450/2000] tot_loss=1.565 (perp=7.465, rec=0.070, cos=0.002), tot_loss_proj:1.639 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.002), tot_loss_proj:1.632 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.553 (perp=7.465, rec=0.058, cos=0.002), tot_loss_proj:1.639 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 600/2000] tot_loss=1.563 (perp=7.465, rec=0.069, cos=0.002), tot_loss_proj:1.637 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.556 (perp=7.465, rec=0.061, cos=0.002), tot_loss_proj:1.633 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.565 (perp=7.465, rec=0.071, cos=0.002), tot_loss_proj:1.635 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 750/2000] tot_loss=1.557 (perp=7.465, rec=0.062, cos=0.002), tot_loss_proj:1.637 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.558 (perp=7.465, rec=0.063, cos=0.002), tot_loss_proj:1.636 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.560 (perp=7.465, rec=0.065, cos=0.002), tot_loss_proj:1.632 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[ 900/2000] tot_loss=1.557 (perp=7.465, rec=0.062, cos=0.002), tot_loss_proj:1.640 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.552 (perp=7.465, rec=0.057, cos=0.002), tot_loss_proj:1.641 [t=0.19s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1000/2000] tot_loss=1.567 (perp=7.465, rec=0.072, cos=0.002), tot_loss_proj:1.649 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1050/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.002), tot_loss_proj:1.640 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1100/2000] tot_loss=1.559 (perp=7.465, rec=0.065, cos=0.002), tot_loss_proj:1.643 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1150/2000] tot_loss=1.550 (perp=7.465, rec=0.055, cos=0.002), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1200/2000] tot_loss=1.554 (perp=7.465, rec=0.059, cos=0.002), tot_loss_proj:1.641 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1250/2000] tot_loss=1.562 (perp=7.465, rec=0.067, cos=0.002), tot_loss_proj:1.639 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1300/2000] tot_loss=1.564 (perp=7.465, rec=0.070, cos=0.002), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1350/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.002), tot_loss_proj:1.648 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1400/2000] tot_loss=1.565 (perp=7.465, rec=0.071, cos=0.002), tot_loss_proj:1.647 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1450/2000] tot_loss=1.561 (perp=7.465, rec=0.066, cos=0.002), tot_loss_proj:1.638 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1500/2000] tot_loss=1.554 (perp=7.465, rec=0.059, cos=0.002), tot_loss_proj:1.645 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1550/2000] tot_loss=1.564 (perp=7.465, rec=0.069, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1600/2000] tot_loss=1.553 (perp=7.465, rec=0.058, cos=0.002), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1650/2000] tot_loss=1.559 (perp=7.465, rec=0.064, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1700/2000] tot_loss=1.562 (perp=7.465, rec=0.068, cos=0.002), tot_loss_proj:1.649 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1750/2000] tot_loss=1.557 (perp=7.465, rec=0.062, cos=0.002), tot_loss_proj:1.643 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1800/2000] tot_loss=1.563 (perp=7.465, rec=0.068, cos=0.002), tot_loss_proj:1.642 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1850/2000] tot_loss=1.566 (perp=7.465, rec=0.072, cos=0.002), tot_loss_proj:1.642 [t=0.19s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[1900/2000] tot_loss=1.554 (perp=7.465, rec=0.060, cos=0.002), tot_loss_proj:1.642 [t=0.19s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
[1950/2000] tot_loss=1.564 (perp=7.465, rec=0.070, cos=0.002), tot_loss_proj:1.644 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Attempt swap
[2000/2000] tot_loss=1.560 (perp=7.465, rec=0.065, cos=0.002), tot_loss_proj:1.645 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy sloppy script [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s undone by a sloppy sloppy script [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 94.118 | p: 88.889 | r: 100.000
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 188.854

[Aggregate metrics]:
rouge1     | fm: 92.577 | p: 92.065 | r: 93.109
rouge2     | fm: 60.102 | p: 59.750 | r: 60.466
rougeL     | fm: 80.421 | p: 80.090 | r: 80.888
rougeLsum  | fm: 80.364 | p: 79.995 | r: 80.794
r1fm+r2fm = 152.680

input #82 time: 0:07:55 | total time: 11:09:51


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9992427003793516
highest_index [0]
highest [0.9992427003793516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.9601501822471619 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.9566210508346558 for ['[CLS] consisting hartley lives champions forgotten johnson account integeronal merge [SEP]']
[Init] best rec loss: 0.9550451636314392 for ['[CLS] ben tawork position naked map because sort been season [SEP]']
[Init] best rec loss: 0.9463936686515808 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.887312650680542 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 0.8696892261505127 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8692896366119385 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 0.8648756146430969 for ['[CLS] original review giggled field floor arid read beckett cecil i [SEP]']
[Init] best rec loss: 0.8604941964149475 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.8593842387199402 for ['[CLS] ut sighed another tex predicted hooper alsoов toes personally [SEP]']
[Init] best rec loss: 0.8368008732795715 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best rec loss: 0.8151112198829651 for ['[CLS] stew follows residence vice boys pitch neck envelope comprehensive nearly [SEP]']
[Init] best perm rec loss: 0.8039038181304932 for ['[CLS] nearly pitch residence vice stew follows comprehensive neck boys envelope [SEP]']
[Init] best perm rec loss: 0.8021044135093689 for ['[CLS] vice neck pitch comprehensive stew follows boys nearly residence envelope [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.848 (perp=12.579, rec=0.303, cos=0.030), tot_loss_proj:3.400 [t=0.17s]
prediction: ['[CLS] know raise growing it culture become when lily study tomorrow [SEP]']
[ 100/2000] tot_loss=2.143 (perp=9.656, rec=0.202, cos=0.009), tot_loss_proj:2.719 [t=0.17s]
prediction: ['[CLS] know be what it culture become when it study kim [SEP]']
[ 150/2000] tot_loss=2.237 (perp=10.405, rec=0.152, cos=0.005), tot_loss_proj:2.858 [t=0.17s]
prediction: ['[CLS] know be what it when grows when up find ray [SEP]']
[ 200/2000] tot_loss=2.111 (perp=9.950, rec=0.117, cos=0.004), tot_loss_proj:2.915 [t=0.17s]
prediction: ['[CLS] know be wants it when grows when up getting it [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.215 (perp=9.984, rec=0.210, cos=0.009), tot_loss_proj:3.233 [t=0.17s]
prediction: ['[CLS] know be wants it logo grows up when getting it [SEP]']
[ 300/2000] tot_loss=2.207 (perp=10.425, rec=0.120, cos=0.002), tot_loss_proj:3.219 [t=0.17s]
prediction: ['[CLS] know be wants ittium grows up when what it [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.859 (perp=8.806, rec=0.096, cos=0.002), tot_loss_proj:2.590 [t=0.17s]
prediction: ['[CLS] know be wants what it life grows up when it [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.656 (perp=7.797, rec=0.095, cos=0.002), tot_loss_proj:2.236 [t=0.17s]
prediction: ['[CLS] know be world what it wants grows up when it [SEP]']
[ 450/2000] tot_loss=1.643 (perp=7.797, rec=0.081, cos=0.002), tot_loss_proj:2.240 [t=0.17s]
prediction: ['[CLS] know be world what it wants grows up when it [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.459 (perp=6.906, rec=0.077, cos=0.002), tot_loss_proj:1.913 [t=0.17s]
prediction: ['[CLS] know what it wants be world grows up when it [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.430 (perp=6.701, rec=0.088, cos=0.002), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS] know what it wants be world it grows up when [SEP]']
[ 600/2000] tot_loss=1.416 (perp=6.701, rec=0.074, cos=0.002), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] know what it wants be world it grows up when [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.357 (perp=6.366, rec=0.082, cos=0.002), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] know what it wants be when it grows up world [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.264 (perp=5.957, rec=0.071, cos=0.002), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
[ 750/2000] tot_loss=1.266 (perp=5.957, rec=0.073, cos=0.002), tot_loss_proj:1.628 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.261 (perp=5.957, rec=0.068, cos=0.002), tot_loss_proj:1.631 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.268 (perp=5.957, rec=0.075, cos=0.002), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
[ 900/2000] tot_loss=1.264 (perp=5.957, rec=0.071, cos=0.002), tot_loss_proj:1.635 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.264 (perp=5.957, rec=0.071, cos=0.002), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.261 (perp=5.957, rec=0.068, cos=0.002), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
[1050/2000] tot_loss=1.259 (perp=5.957, rec=0.066, cos=0.002), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.261 (perp=5.957, rec=0.068, cos=0.002), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.260 (perp=5.957, rec=0.067, cos=0.002), tot_loss_proj:1.630 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
[1200/2000] tot_loss=1.259 (perp=5.957, rec=0.066, cos=0.002), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.266 (perp=5.957, rec=0.073, cos=0.002), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.256 (perp=5.957, rec=0.063, cos=0.002), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
[1350/2000] tot_loss=1.261 (perp=5.957, rec=0.068, cos=0.002), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.263 (perp=5.957, rec=0.070, cos=0.002), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.266 (perp=5.957, rec=0.073, cos=0.002), tot_loss_proj:1.629 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
[1500/2000] tot_loss=1.269 (perp=5.957, rec=0.076, cos=0.002), tot_loss_proj:1.628 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.263 (perp=5.957, rec=0.070, cos=0.002), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.258 (perp=5.957, rec=0.065, cos=0.002), tot_loss_proj:1.622 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
[1650/2000] tot_loss=1.270 (perp=5.957, rec=0.077, cos=0.002), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.261 (perp=5.957, rec=0.068, cos=0.002), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.258 (perp=5.957, rec=0.065, cos=0.002), tot_loss_proj:1.627 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
[1800/2000] tot_loss=1.259 (perp=5.957, rec=0.066, cos=0.002), tot_loss_proj:1.624 [t=0.18s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.267 (perp=5.957, rec=0.074, cos=0.002), tot_loss_proj:1.621 [t=0.18s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.252 (perp=5.957, rec=0.059, cos=0.002), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
[1950/2000] tot_loss=1.262 (perp=5.957, rec=0.069, cos=0.002), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.263 (perp=5.957, rec=0.070, cos=0.002), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] know what it wants be world when it grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] know what it wants be world when it grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 92.520 | p: 92.053 | r: 93.082
rouge2     | fm: 60.032 | p: 59.738 | r: 60.398
rougeL     | fm: 80.530 | p: 80.164 | r: 80.981
rougeLsum  | fm: 80.565 | p: 80.172 | r: 80.967
r1fm+r2fm = 152.552

input #83 time: 0:08:08 | total time: 11:17:59


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9991125724774641
highest_index [0]
highest [0.9991125724774641]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9286046624183655 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.9211990833282471 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 0.8995694518089294 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.8926138281822205 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 0.8923629522323608 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8866891264915466 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 0.8839888572692871 for ['[CLS]oglaise catholicur prototype issues cheered [SEP]']
[Init] best rec loss: 0.8611317276954651 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best perm rec loss: 0.8604739904403687 for ['[CLS] sar block is whetherness project dark [SEP]']
[Init] best perm rec loss: 0.8604679703712463 for ['[CLS] block dark sar whether isness project [SEP]']
[Init] best perm rec loss: 0.85843825340271 for ['[CLS] whether sar project block is darkness [SEP]']
[Init] best perm rec loss: 0.8576532006263733 for ['[CLS] whether is block projectness dark sar [SEP]']
[Init] best perm rec loss: 0.8570180535316467 for ['[CLS] sar block project dark is whetherness [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.578 (perp=11.655, rec=0.236, cos=0.011), tot_loss_proj:3.036 [t=0.17s]
prediction: ['[CLS] they lost unable ability think larry people [SEP]']
[ 100/2000] tot_loss=2.174 (perp=10.255, rec=0.119, cos=0.004), tot_loss_proj:2.630 [t=0.17s]
prediction: ['[CLS] have lost people ability thinking people [SEP]']
[ 150/2000] tot_loss=1.522 (perp=7.139, rec=0.091, cos=0.003), tot_loss_proj:1.905 [t=0.17s]
prediction: ['[CLS] have lost the ability think to people [SEP]']
[ 200/2000] tot_loss=1.493 (perp=7.139, rec=0.063, cos=0.002), tot_loss_proj:1.910 [t=0.17s]
prediction: ['[CLS] have lost the ability think to people [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.193 (perp=5.494, rec=0.092, cos=0.003), tot_loss_proj:1.493 [t=0.17s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
[ 300/2000] tot_loss=1.171 (perp=5.494, rec=0.071, cos=0.002), tot_loss_proj:1.485 [t=0.17s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.168 (perp=5.494, rec=0.068, cos=0.002), tot_loss_proj:1.493 [t=0.17s]
prediction: ['[CLS] have lost the ability to people think [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.037 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 450/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.032 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 500/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.035 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.032 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 600/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.038 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.008 (perp=4.681, rec=0.070, cos=0.002), tot_loss_proj:1.036 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.028 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 750/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.031 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.033 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.996 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.041 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[ 900/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.036 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.043 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1000/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.031 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1050/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.026 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1100/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.034 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1150/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.042 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1200/2000] tot_loss=0.994 (perp=4.681, rec=0.056, cos=0.002), tot_loss_proj:1.033 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1250/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.043 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=0.989 (perp=4.681, rec=0.051, cos=0.002), tot_loss_proj:1.029 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=0.996 (perp=4.681, rec=0.058, cos=0.002), tot_loss_proj:1.039 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.039 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.030 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.032 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=0.992 (perp=4.681, rec=0.054, cos=0.002), tot_loss_proj:1.036 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.032 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=0.996 (perp=4.681, rec=0.058, cos=0.002), tot_loss_proj:1.034 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.039 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.027 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.038 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.033 [t=0.21s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=0.990 (perp=4.681, rec=0.052, cos=0.002), tot_loss_proj:1.037 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.028 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=1.007 (perp=4.681, rec=0.069, cos=0.002), tot_loss_proj:1.047 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.615 | p: 92.184 | r: 93.179
rouge2     | fm: 60.731 | p: 60.403 | r: 61.107
rougeL     | fm: 80.760 | p: 80.399 | r: 81.196
rougeLsum  | fm: 80.700 | p: 80.324 | r: 81.134
r1fm+r2fm = 153.347

input #84 time: 0:07:58 | total time: 11:25:58


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9992374406339235
highest_index [0]
highest [0.9992374406339235]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9699996709823608 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.9557927250862122 for ['[CLS] tau rock vacancy revision topical literature down classification drive3 [SEP]']
[Init] best rec loss: 0.933201789855957 for ['[CLS] creek i instrumental bottomifnotes kensington military kowalski smoky [SEP]']
[Init] best rec loss: 0.8898030519485474 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8735714554786682 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best perm rec loss: 0.8669417500495911 for ['[CLS] indies backgroundleinthing road laps indianrman fallen defender [SEP]']
[Init] best perm rec loss: 0.8647000193595886 for ['[CLS]lein laps roadrman indian background indiesthing defender fallen [SEP]']
[Init] best perm rec loss: 0.8642165064811707 for ['[CLS]rmanlein indies lapsthing fallen defender background road indian [SEP]']
[Init] best perm rec loss: 0.8628117442131042 for ['[CLS] indiesleinthing lapsrman indian defender background fallen road [SEP]']
[Init] best perm rec loss: 0.8601159453392029 for ['[CLS] indieslein fallen road background laps indianthing defenderrman [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.990 (perp=8.481, rec=0.278, cos=0.016), tot_loss_proj:2.866 [t=0.17s]
prediction: ['[CLS] unfortunately very unfortunately good not also good good. unfortunately [SEP]']
[ 100/2000] tot_loss=1.731 (perp=7.818, rec=0.162, cos=0.006), tot_loss_proj:2.302 [t=0.17s]
prediction: ['[CLS] unfortunately still unfortunately not not also good good good. [SEP]']
[ 150/2000] tot_loss=1.884 (perp=8.794, rec=0.121, cos=0.005), tot_loss_proj:2.657 [t=0.17s]
prediction: ['[CLS] unfortunately s unfortunately not not also very good good usually [SEP]']
[ 200/2000] tot_loss=1.890 (perp=8.978, rec=0.090, cos=0.004), tot_loss_proj:3.064 [t=0.17s]
prediction: ['[CLS] unfortunately s unfortunately not not also very. good perhaps [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.481 (perp=6.866, rec=0.104, cos=0.004), tot_loss_proj:2.195 [t=0.17s]
prediction: ['[CLS], s unfortunately not not also very good. perhaps [SEP]']
[ 300/2000] tot_loss=1.515 (perp=7.098, rec=0.091, cos=0.004), tot_loss_proj:3.315 [t=0.17s]
prediction: ['[CLS], s unfortunately not s also very good. perhaps [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.471 (perp=6.882, rec=0.092, cos=0.003), tot_loss_proj:3.132 [t=0.17s]
prediction: ['[CLS] s, unfortunately not s also very good? perhaps [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.241 (perp=5.750, rec=0.089, cos=0.003), tot_loss_proj:2.963 [t=0.17s]
prediction: ['[CLS] unfortunately, it not s also very good. perhaps [SEP]']
[ 450/2000] tot_loss=1.218 (perp=5.750, rec=0.065, cos=0.002), tot_loss_proj:2.953 [t=0.17s]
prediction: ['[CLS] unfortunately, it not s also very good. perhaps [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.113 (perp=5.194, rec=0.072, cos=0.002), tot_loss_proj:1.569 [t=0.17s]
prediction: ['[CLS] unfortunately, it s not also very good. perhaps [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.200 (perp=5.585, rec=0.080, cos=0.003), tot_loss_proj:1.638 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s not very good? perhaps [SEP]']
[ 600/2000] tot_loss=1.045 (perp=4.864, rec=0.070, cos=0.002), tot_loss_proj:1.255 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s not very good. perhaps [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.029 (perp=4.756, rec=0.075, cos=0.002), tot_loss_proj:1.249 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s not very good perhaps. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.024 (perp=4.756, rec=0.071, cos=0.002), tot_loss_proj:1.258 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s not very good perhaps. [SEP]']
[ 750/2000] tot_loss=1.027 (perp=4.756, rec=0.073, cos=0.002), tot_loss_proj:1.261 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s not very good perhaps. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.001 (perp=4.622, rec=0.074, cos=0.003), tot_loss_proj:1.201 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[ 850/2000] tot_loss=0.998 (perp=4.622, rec=0.071, cos=0.003), tot_loss_proj:1.204 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
[ 900/2000] tot_loss=0.994 (perp=4.622, rec=0.067, cos=0.003), tot_loss_proj:1.201 [t=0.22s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.993 (perp=4.622, rec=0.066, cos=0.003), tot_loss_proj:1.206 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.001 (perp=4.622, rec=0.074, cos=0.003), tot_loss_proj:1.203 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
[1050/2000] tot_loss=0.988 (perp=4.622, rec=0.061, cos=0.003), tot_loss_proj:1.203 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1100/2000] tot_loss=0.989 (perp=4.622, rec=0.062, cos=0.003), tot_loss_proj:1.217 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1150/2000] tot_loss=0.989 (perp=4.622, rec=0.062, cos=0.003), tot_loss_proj:1.208 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
[1200/2000] tot_loss=0.996 (perp=4.622, rec=0.069, cos=0.003), tot_loss_proj:1.203 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1250/2000] tot_loss=0.984 (perp=4.622, rec=0.057, cos=0.003), tot_loss_proj:1.205 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.001 (perp=4.622, rec=0.074, cos=0.003), tot_loss_proj:1.207 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
[1350/2000] tot_loss=0.990 (perp=4.622, rec=0.062, cos=0.003), tot_loss_proj:1.204 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1400/2000] tot_loss=0.996 (perp=4.622, rec=0.069, cos=0.003), tot_loss_proj:1.205 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1450/2000] tot_loss=0.995 (perp=4.622, rec=0.068, cos=0.003), tot_loss_proj:1.208 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
[1500/2000] tot_loss=0.991 (perp=4.622, rec=0.064, cos=0.003), tot_loss_proj:1.214 [t=0.18s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1550/2000] tot_loss=0.995 (perp=4.622, rec=0.068, cos=0.003), tot_loss_proj:1.204 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.003 (perp=4.622, rec=0.076, cos=0.003), tot_loss_proj:1.208 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
[1650/2000] tot_loss=0.999 (perp=4.622, rec=0.071, cos=0.003), tot_loss_proj:1.204 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1700/2000] tot_loss=0.989 (perp=4.622, rec=0.062, cos=0.003), tot_loss_proj:1.204 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1750/2000] tot_loss=0.998 (perp=4.622, rec=0.071, cos=0.003), tot_loss_proj:1.207 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
[1800/2000] tot_loss=0.993 (perp=4.622, rec=0.066, cos=0.003), tot_loss_proj:1.208 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
[1850/2000] tot_loss=0.991 (perp=4.622, rec=0.064, cos=0.003), tot_loss_proj:1.209 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s perhaps not very good. [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=0.983 (perp=4.541, rec=0.072, cos=0.003), tot_loss_proj:1.239 [t=0.17s]
prediction: ['[CLS] unfortunately, perhaps it also s not very good. [SEP]']
[1950/2000] tot_loss=0.985 (perp=4.541, rec=0.074, cos=0.003), tot_loss_proj:1.238 [t=0.17s]
prediction: ['[CLS] unfortunately, perhaps it also s not very good. [SEP]']
Attempt swap
[2000/2000] tot_loss=0.969 (perp=4.541, rec=0.058, cos=0.003), tot_loss_proj:1.244 [t=0.17s]
prediction: ['[CLS] unfortunately, perhaps it also s not very good. [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, it also s perhaps not very good. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 58.824 | p: 55.556 | r: 62.500
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 153.560

[Aggregate metrics]:
rouge1     | fm: 92.675 | p: 92.159 | r: 93.276
rouge2     | fm: 60.487 | p: 60.129 | r: 60.897
rougeL     | fm: 80.758 | p: 80.359 | r: 81.270
rougeLsum  | fm: 80.791 | p: 80.428 | r: 81.363
r1fm+r2fm = 153.162

input #85 time: 0:09:02 | total time: 11:35:01


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9993327117168653
highest_index [0]
highest [0.9993327117168653]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9209051132202148 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9168149828910828 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 0.8586238026618958 for ['[CLS] len tin signals [SEP]']
[Init] best rec loss: 0.7911268472671509 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.7695991396903992 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.7565065622329712 for ['[CLS] liberated round alright [SEP]']
[Init] best perm rec loss: 0.7532469630241394 for ['[CLS] alright round liberated [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.626 (perp=11.170, rec=0.379, cos=0.013), tot_loss_proj:3.436 [t=0.17s]
prediction: ['[CLS] clarity [SEP] dinah [SEP]']
[ 100/2000] tot_loss=1.939 (perp=8.317, rec=0.268, cos=0.007), tot_loss_proj:1.757 [t=0.17s]
prediction: ['[CLS] clarity and emotional [SEP]']
[ 150/2000] tot_loss=2.261 (perp=10.257, rec=0.204, cos=0.006), tot_loss_proj:2.427 [t=0.17s]
prediction: ['[CLS] clarity emotional emotional [SEP]']
[ 200/2000] tot_loss=2.598 (perp=12.012, rec=0.191, cos=0.005), tot_loss_proj:3.206 [t=0.17s]
prediction: ['[CLS] clarity [SEP] emotional [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.138 (perp=9.365, rec=0.256, cos=0.009), tot_loss_proj:2.479 [t=0.18s]
prediction: ['[CLS] [SEP] emotional clarity [SEP]']
[ 300/2000] tot_loss=1.791 (perp=8.211, rec=0.143, cos=0.005), tot_loss_proj:1.877 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.773 (perp=8.211, rec=0.127, cos=0.004), tot_loss_proj:1.867 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.765 (perp=8.211, rec=0.119, cos=0.004), tot_loss_proj:1.876 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 450/2000] tot_loss=1.765 (perp=8.211, rec=0.119, cos=0.004), tot_loss_proj:1.868 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.744 (perp=8.211, rec=0.098, cos=0.004), tot_loss_proj:1.873 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.748 (perp=8.211, rec=0.101, cos=0.004), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 600/2000] tot_loss=1.741 (perp=8.211, rec=0.095, cos=0.004), tot_loss_proj:1.865 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.750 (perp=8.211, rec=0.103, cos=0.004), tot_loss_proj:1.872 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.744 (perp=8.211, rec=0.097, cos=0.004), tot_loss_proj:1.872 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=1.742 (perp=8.211, rec=0.096, cos=0.004), tot_loss_proj:1.875 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.744 (perp=8.211, rec=0.098, cos=0.004), tot_loss_proj:1.882 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.740 (perp=8.211, rec=0.094, cos=0.004), tot_loss_proj:1.874 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=1.753 (perp=8.211, rec=0.107, cos=0.004), tot_loss_proj:1.869 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.729 (perp=8.211, rec=0.083, cos=0.004), tot_loss_proj:1.868 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.751 (perp=8.211, rec=0.105, cos=0.004), tot_loss_proj:1.877 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=1.729 (perp=8.211, rec=0.083, cos=0.004), tot_loss_proj:1.873 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.748 (perp=8.211, rec=0.102, cos=0.004), tot_loss_proj:1.881 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.739 (perp=8.211, rec=0.093, cos=0.004), tot_loss_proj:1.876 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=1.749 (perp=8.211, rec=0.103, cos=0.004), tot_loss_proj:1.871 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.747 (perp=8.211, rec=0.101, cos=0.004), tot_loss_proj:1.868 [t=0.20s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.735 (perp=8.211, rec=0.088, cos=0.004), tot_loss_proj:1.875 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=1.745 (perp=8.211, rec=0.099, cos=0.004), tot_loss_proj:1.870 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.737 (perp=8.211, rec=0.090, cos=0.004), tot_loss_proj:1.866 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.753 (perp=8.211, rec=0.107, cos=0.004), tot_loss_proj:1.871 [t=0.21s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=1.750 (perp=8.211, rec=0.104, cos=0.004), tot_loss_proj:1.869 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.752 (perp=8.211, rec=0.106, cos=0.004), tot_loss_proj:1.877 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.743 (perp=8.211, rec=0.097, cos=0.004), tot_loss_proj:1.876 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=1.749 (perp=8.211, rec=0.103, cos=0.004), tot_loss_proj:1.870 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.738 (perp=8.211, rec=0.091, cos=0.004), tot_loss_proj:1.877 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.739 (perp=8.211, rec=0.093, cos=0.004), tot_loss_proj:1.878 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=1.727 (perp=8.211, rec=0.081, cos=0.004), tot_loss_proj:1.880 [t=0.19s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.742 (perp=8.211, rec=0.096, cos=0.004), tot_loss_proj:1.870 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.734 (perp=8.211, rec=0.087, cos=0.004), tot_loss_proj:1.879 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=1.732 (perp=8.211, rec=0.085, cos=0.004), tot_loss_proj:1.873 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.743 (perp=8.211, rec=0.097, cos=0.004), tot_loss_proj:1.872 [t=0.18s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.747 | p: 92.245 | r: 93.352
rouge2     | fm: 60.262 | p: 59.901 | r: 60.702
rougeL     | fm: 80.740 | p: 80.338 | r: 81.224
rougeLsum  | fm: 80.775 | p: 80.366 | r: 81.254
r1fm+r2fm = 153.008

input #86 time: 0:09:19 | total time: 11:44:20


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9992553760665845
highest_index [0]
highest [0.9992553760665845]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.8846666812896729 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.7553390860557556 for ['[CLS]minate force [SEP]']
[Init] best rec loss: 0.7130892872810364 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.7034943103790283 for ['[CLS] officer yorker [SEP]']
[Init] best rec loss: 0.6935102939605713 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.6770039796829224 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6745697855949402 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.888 (perp=12.535, rec=0.343, cos=0.038), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=1.628 (perp=7.258, rec=0.170, cos=0.007), tot_loss_proj:1.517 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.568 (perp=7.258, rec=0.113, cos=0.003), tot_loss_proj:1.513 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.526 (perp=7.258, rec=0.072, cos=0.002), tot_loss_proj:1.537 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.618 (perp=7.258, rec=0.154, cos=0.013), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.530 (perp=7.258, rec=0.077, cos=0.002), tot_loss_proj:1.532 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.002), tot_loss_proj:1.538 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.002), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.505 (perp=7.258, rec=0.052, cos=0.001), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.535 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.495 (perp=7.258, rec=0.042, cos=0.002), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.509 (perp=7.258, rec=0.056, cos=0.001), tot_loss_proj:1.533 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.523 (perp=7.258, rec=0.070, cos=0.002), tot_loss_proj:1.544 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.513 (perp=7.258, rec=0.060, cos=0.001), tot_loss_proj:1.522 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.520 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.503 (perp=7.258, rec=0.050, cos=0.001), tot_loss_proj:1.549 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.529 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.493 (perp=7.258, rec=0.040, cos=0.001), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.502 (perp=7.258, rec=0.049, cos=0.001), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.521 (perp=7.258, rec=0.068, cos=0.001), tot_loss_proj:1.532 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.530 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.537 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.545 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.499 (perp=7.258, rec=0.046, cos=0.001), tot_loss_proj:1.528 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.505 (perp=7.258, rec=0.052, cos=0.001), tot_loss_proj:1.539 [t=0.19s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.550 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.524 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.500 (perp=7.258, rec=0.047, cos=0.001), tot_loss_proj:1.543 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.531 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.504 (perp=7.258, rec=0.051, cos=0.001), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.548 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.531 (perp=7.258, rec=0.078, cos=0.001), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.522 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.798 | p: 92.286 | r: 93.411
rouge2     | fm: 60.670 | p: 60.301 | r: 61.049
rougeL     | fm: 81.022 | p: 80.617 | r: 81.512
rougeLsum  | fm: 80.950 | p: 80.541 | r: 81.492
r1fm+r2fm = 153.469

input #87 time: 0:09:02 | total time: 11:53:23


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9992358071326222
highest_index [0]
highest [0.9992358071326222]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9809058904647827 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.944068431854248 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 0.9212347269058228 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.917607307434082 for ['[CLS] signing architectural miss of? tension popbreaker covered versus planning bean single field advanced a lipstickingdon tab shorter dos down luther ki t directors wounded drink people ps animals administrativeari tone geologic international above 18 free dam way software clay [SEP]']
[Init] best rec loss: 0.9161702394485474 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.9086971879005432 for ['[CLS] assistants isbag mighty ll shortagekou subject central printian contract separated eight tick twenties ball how orange victor help fund council key morris lace weight vacancy hungick equipment her goran dvd business gould sidou rector us g moment freud [SEP]']
[Init] best rec loss: 0.9049574136734009 for ['[CLS] towards scene too tram beetle vice updated being west grips above.olaignment golden gloss hot boundaries slave satellite warm reasons meant chord antagonist now trick migration part pennsylvania julius following embraced center rebound miss together hero bail museum days four rash [SEP]']
[Init] best rec loss: 0.9017528891563416 for ["[CLS]⁺'ship socialist knightlines trapped golden vital rail soil or accepted seasonal behind mall tickets american fallon https word appearedminated break people familiar bornllie serious once wealth are ll protector caterizedest trade masspina berlin flavortine [SEP]"]
[Init] best rec loss: 0.8954169154167175 for ['[CLS] designated engine never pondered harmon programs? mandarin according employees legitimate exchanged as elevated piston exodus won machine aunt hadnbbed insanity allowed home landing [UNK] starting ki! signed close today force immortality nets where reform baronet ) network demi observation spanning [SEP]']
[Init] best perm rec loss: 0.8942180275917053 for ['[CLS] pondered allowed where! aunt never designated starting demi as programs home hadn piston spanning legitimate engine exodusbbed? insanity machine immortality [UNK] reform harmon network elevated nets today according baronet ki exchanged ) signed employees mandarin force close won landing observation [SEP]']
[Init] best perm rec loss: 0.8933555483818054 for ['[CLS] landing signed? ki legitimate network harmon starting demi observation! exchanged where aunt programs exodus insanity ) never today nets pistonbbed mandarin allowed baronet close won [UNK] reform force pondered employees home engine designated as spanning according elevated machine hadn immortality [SEP]']
[Init] best perm rec loss: 0.8925676345825195 for ['[CLS] machine? never immortality exodus landing exchanged! harmon force spanning according as reform [UNK] won where programs auntbbed home employees pondered insanity observation piston today network allowed close ) starting hadn mandarin nets demi elevated legitimate signed engine baronet designated ki [SEP]']
[Init] best perm rec loss: 0.8924002051353455 for ['[CLS] harmon today piston? [UNK] won legitimate machine designated where landing starting allowed demibbed close engine elevated baronet nets ) hadn aunt exchanged never! according employees spanning mandarin insanity exodus immortality signed reform observation as force pondered programs network ki home [SEP]']
[Init] best perm rec loss: 0.8921587467193604 for ['[CLS] allowed hadn legitimate signed piston mandarin exodus reform pondered as observation ) ki engine never network insanitybbed aunt? immortality force demi starting today! where nets machine landing [UNK] home close spanning exchanged designated won employees baronet programs elevated according harmon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.578 (perp=11.381, rec=0.296, cos=0.006), tot_loss_proj:4.170 [t=0.19s]
prediction: ['[CLS] youth henry william henry henry and which love. almost productionsless pictures davidstone francis gentle agency ann ) lovent michiganal. and which lankan christian understanding chennai editor. : evening elise loved cross comes beauty lacked reversed understands [SEP]']
[ 100/2000] tot_loss=2.540 (perp=11.040, rec=0.324, cos=0.007), tot_loss_proj:4.149 [t=0.17s]
prediction: ['[CLS] youth henry as. henryiously a s.... ˈ & romance stepness william measures series ann and a 京 thomas who the. winner morning [SEP] understands romance bowen,drik. smashwords grandness. love lacked inter understands [SEP]']
[ 150/2000] tot_loss=2.494 (perp=11.004, rec=0.289, cos=0.005), tot_loss_proj:3.741 [t=0.17s]
prediction: ['[CLS] clay daniel re. nothing♯ t o. t grew, romance.field rachel minute. playhouse andwhile pleasure peace finn was does "in [SEP] understands romance melanie, ‿ upon ← greatness they love pleasure inter understood [SEP]']
[ 200/2000] tot_loss=2.488 (perp=10.935, rec=0.293, cos=0.008), tot_loss_proj:3.897 [t=0.17s]
prediction: ['[CLS] love daniel.. would a p l. p as romancenessfield elizabeth grand into madame and theoretical potential : akin. w that banjo our understands ⇄ melanie frames. fictional ª grand love merely love calm uncomfortable understands [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.202 (perp=9.596, rec=0.278, cos=0.005), tot_loss_proj:3.438 [t=0.17s]
prediction: ['[CLS] calm daniel.. the a t un. john anderson or romancegoodum elizabeth grand and the the¹ pleasure alien a. e civilization i [SEP] understands ள joy, stress chapter ª great love cannot love love anderson understands [SEP]']
[ 300/2000] tot_loss=2.277 (perp=10.110, rec=0.252, cos=0.003), tot_loss_proj:3.922 [t=0.17s]
prediction: ['[CLS] calm p.. the of t un. henry 場 techniques romance. ; elizabeth grand and the and¹ pleasure 車 ). is ] losing we understands spirits t,neas lives ª grand love cannot love love anderson understands [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.193 (perp=9.769, rec=0.236, cos=0.003), tot_loss_proj:3.596 [t=0.17s]
prediction: ['[CLS] calm p. t. the *.. p 場 hours romancered idle jessie grand that the and ; pleasureneas a. is ]ic [SEP] understands imagination t,. lives ª grand love cannot love love anderson understands [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.282 (perp=10.241, rec=0.231, cos=0.003), tot_loss_proj:3.800 [t=0.17s]
prediction: ['[CLS] calm p. t. the№.. p ェkeeping romanceredf katherine grand that the andaneous effort alien t.} ] permanent our understands atmosphere bride understands. we ª grand love cannot love love anderson russell [SEP]']
[ 450/2000] tot_loss=2.340 (perp=10.417, rec=0.251, cos=0.005), tot_loss_proj:3.669 [t=0.17s]
prediction: ['[CLS] calm p. t. the §.. p ェability romance.f romance grand how the andaneous effort players t.} civilization flows our understands atmosphere joy understands. we ª grand love cannot love love anderson russell [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.220 (perp=10.014, rec=0.214, cos=0.003), tot_loss_proj:3.590 [t=0.17s]
prediction: ['[CLS] calm p. t t our § of. t ェ of romance and and melanie grand how ourf ; joyity anderson.） ள flows our understands atmosphere ⇌ understands. we. grand love cannot love love anderson anderson [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.006 (perp=8.999, rec=0.203, cos=0.003), tot_loss_proj:3.268 [t=0.17s]
prediction: ['[CLS] calm p. t. our - of. t ェ of romance and and melanie grand how ourf ; joy assault anderson.} ள flows our understands atmosphere joy understands. we cannot love love anderson. grand love anderson [SEP]']
[ 600/2000] tot_loss=2.028 (perp=9.169, rec=0.191, cos=0.002), tot_loss_proj:3.273 [t=0.17s]
prediction: ['[CLS] calm p. t. our § of. t ェ of romance and and melanie grand how ourf ; joy throttle anderson.} ள flows our understandsness joy understands. our cannot love love anderson. grand realm anderson [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.945 (perp=8.791, rec=0.185, cos=0.003), tot_loss_proj:3.353 [t=0.17s]
prediction: ['[CLS] calm p. t. our - contemporary. t ェ of romance and and romance grand how ourr ; joy throttle anderson.} ள of our understandsness joy understands. our cannot love love anderson. grand realm anderson [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.948 (perp=8.823, rec=0.181, cos=0.002), tot_loss_proj:3.359 [t=0.17s]
prediction: ['[CLS] calm p. t. our - past. t ェ of romance and and romance grand how ourr ; joy throttle anderson.} ] of our understandsness joy understands. our realm cannot love love anderson. grand anderson [SEP]']
[ 750/2000] tot_loss=2.091 (perp=9.405, rec=0.207, cos=0.003), tot_loss_proj:3.386 [t=0.17s]
prediction: ['[CLS] calm p. t. focuses of past. t 場 how romance of and⁺ grand how wer ; joyious anderson. ― ள of our understandsness joy understands. we realm cannot love love anderson. grand anderson [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.120 (perp=9.660, rec=0.185, cos=0.002), tot_loss_proj:3.502 [t=0.19s]
prediction: ['[CLS] calm p. t. focuses my past. t ェ of romance of and⁺ grand how wer ; joy violence anderson. ― ள and our understandsness joy understands. our realm love cannot love anderson. grand anderson [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.030 (perp=9.213, rec=0.185, cos=0.002), tot_loss_proj:3.273 [t=0.17s]
prediction: ['[CLS] calm p. t. and my past. t ェ of romance of focuses⁺ grand how wer ; joy villain anderson. ― ள and our understandsness joy understands. our realm love cannot love anderson. grand miracle [SEP]']
[ 900/2000] tot_loss=2.006 (perp=9.156, rec=0.173, cos=0.002), tot_loss_proj:3.018 [t=0.17s]
prediction: ['[CLS] calm p. t. and my past. t ェ of romance of focuses⁺ grand how we believes joy villain anderson. ― ள of our understandsness joy understands. our realm love seems love anderson. grand miracle [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.998 (perp=9.097, rec=0.176, cos=0.002), tot_loss_proj:2.937 [t=0.17s]
prediction: ['[CLS] calm p. t. and my past. t ェ of romance of focuses⁺ anderson how we believes joy hearts anderson. ― ள of our understandsness joy can. our realm love seems love grand. grand miracle [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.910 (perp=8.696, rec=0.169, cos=0.002), tot_loss_proj:2.860 [t=0.17s]
prediction: ['[CLS] calm p. t. and my past. t ェ of romance of focuses⁺ ― how we believes joy hearts anderson. anderson ள of our understandsness joy can. our realm love seems love grand. grand the [SEP]']
[1050/2000] tot_loss=1.957 (perp=8.924, rec=0.171, cos=0.002), tot_loss_proj:3.097 [t=0.17s]
prediction: ['[CLS] calm p. t. and my past. t ェ of romance of focuses⁺ ― how we ills joy hearts anderson. anderson ள of our understandsness joy can. our realm love easier love grand. grand the [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.969 (perp=8.970, rec=0.173, cos=0.002), tot_loss_proj:3.152 [t=0.20s]
prediction: ['[CLS] calm p. t. and my past. t ェ of romance of focuses marcus ― how joy ills joy hearts anderson. anderson ள of our understandsness is can. our realm love easier love grand. grand the [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.914 (perp=8.749, rec=0.163, cos=0.002), tot_loss_proj:3.059 [t=0.17s]
prediction: ['[CLS] calm p. t. and my past. t ェ of romance of focuses⁺ ― how joy ills joy hearts anderson. anderson ள of our understandsness love can. our realm love easier is grand. grand the [SEP]']
[1200/2000] tot_loss=1.949 (perp=8.894, rec=0.168, cos=0.002), tot_loss_proj:3.213 [t=0.17s]
prediction: ['[CLS] calm p. t. and my past. t ェ of romance of focuses⁺ ― how joy ills joy civil anderson. anderson ள of our understandsness love can. our realm love easier is grand. grand the [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.892 (perp=8.632, rec=0.164, cos=0.002), tot_loss_proj:3.184 [t=0.19s]
prediction: ['[CLS] calm p. t. and my past. t ェ of romance of the⁺ ― how joy ills joy civil anderson. anderson ள of our understandsness love can. our realm love easier is grand. grand focuses [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.825 (perp=8.308, rec=0.162, cos=0.002), tot_loss_proj:3.162 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ェ of romance of the⁺ ― how joy ills my civil anderson. anderson ள of our understandsness love can. our realm love easier is grand. grand focuses [SEP]']
[1350/2000] tot_loss=1.827 (perp=8.308, rec=0.163, cos=0.002), tot_loss_proj:3.159 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ェ of romance of the⁺ ― how joy ills my civil anderson. anderson ள of our understandsness love can. our realm love easier is grand. grand focuses [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.817 (perp=8.263, rec=0.162, cos=0.002), tot_loss_proj:2.999 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ェ of romance of the⁺ ― how love ills my civil anderson. anderson ள of our understandsness joy can. our ill love easier is grand. grand focuses [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.804 (perp=8.201, rec=0.162, cos=0.002), tot_loss_proj:3.038 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ェ of romance of the⁺ ― how love ills my civil anderson. anderson ள of our understandsness joy can love our ill. easier is grand. grand focuses [SEP]']
[1500/2000] tot_loss=1.806 (perp=8.201, rec=0.164, cos=0.002), tot_loss_proj:3.041 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ェ of romance of the⁺ ― how love ills my civil anderson. anderson ள of our understandsness joy can love our ill. easier is grand. grand focuses [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.774 (perp=8.083, rec=0.155, cos=0.002), tot_loss_proj:3.047 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the⁺ ― how love ills my civil anderson. anderson ள of our understandsness ill can love our joy. easier is grand. grand focuses [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.789 (perp=8.152, rec=0.157, cos=0.002), tot_loss_proj:3.204 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the⁺ ― how love ills myious anderson. anderson ள of our understandsness ill can love our grand. easier is grand. joy focuses [SEP]']
[1650/2000] tot_loss=1.792 (perp=8.152, rec=0.160, cos=0.002), tot_loss_proj:3.205 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the⁺ ― how love ills myious anderson. anderson ள of our understandsness ill can love our grand. easier is grand. joy focuses [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.748 (perp=7.946, rec=0.157, cos=0.002), tot_loss_proj:3.053 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the⁺ focuses how love ills myious anderson. anderson ள of our understandsness ill can love our grand. our is grand. joy/ [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.741 (perp=7.845, rec=0.170, cos=0.002), tot_loss_proj:3.004 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the/ focuses how love ills myious anderson. anderson ள of our understandsness ill can love our grand. our is grand. joy⁺ [SEP]']
[1800/2000] tot_loss=1.731 (perp=7.845, rec=0.160, cos=0.002), tot_loss_proj:3.004 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the/ focuses how love ills myious anderson. anderson ள of our understandsness ill can love our grand. our is grand. joy⁺ [SEP]']
Attempt swap
[1850/2000] tot_loss=1.732 (perp=7.856, rec=0.158, cos=0.002), tot_loss_proj:3.013 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the/ focuses how love ills myious anderson. anderson ள of our understandsness ill can love our grand. our is grand and joy⁺ [SEP]']
Attempt swap
[1900/2000] tot_loss=1.727 (perp=7.830, rec=0.160, cos=0.002), tot_loss_proj:3.059 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the/ focuses how love ills my verdict anderson. anderson ள of our understandsness ill can love our grand. our is grand and joy⁺ [SEP]']
[1950/2000] tot_loss=1.723 (perp=7.830, rec=0.155, cos=0.002), tot_loss_proj:3.057 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the/ focuses how love ills my verdict anderson. anderson ள of our understandsness ill can love our grand. our is grand and joy⁺ [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.688 (perp=7.672, rec=0.152, cos=0.002), tot_loss_proj:3.035 [t=0.19s]
prediction: ['[CLS] calm p. t. and joy past. t ᴺ of romance of the/ focuses how love ills our intellectual anderson. anderson ள of our understandsness ill can love my grand. our is grand and joy⁺ [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] calm p. t. and joy past. t ᴺ of romance of the/ focuses how love ills myious anderson. anderson ள of our understandsness ill can love our grand. our is grand. joy⁺ [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 51.429 | p: 56.250 | r: 47.368
rouge2     | fm: 11.765 | p: 12.903 | r: 10.811
rougeL     | fm: 31.429 | p: 34.375 | r: 28.947
rougeLsum  | fm: 31.429 | p: 34.375 | r: 28.947
r1fm+r2fm = 63.193

[Aggregate metrics]:
rouge1     | fm: 92.391 | p: 91.933 | r: 92.921
rouge2     | fm: 60.183 | p: 59.884 | r: 60.555
rougeL     | fm: 80.529 | p: 80.159 | r: 80.946
rougeLsum  | fm: 80.492 | p: 80.128 | r: 80.929
r1fm+r2fm = 152.574

input #88 time: 0:09:14 | total time: 12:02:37


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9993426143386362
highest_index [0]
highest [0.9993426143386362]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9663888216018677 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9524359107017517 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.9456372857093811 for ['[CLS] lucraction ditch vin vehicle nights filing wholeierusion above myself capacity easter just bowlpath silver campaign urging draw huntersky operation himself plant bolt gin won ours only object [SEP]']
[Init] best rec loss: 0.9341058135032654 for ['[CLS] watt trustingats promisepate weight eight blood happened photograph deaths credited jp wish practicing boysfulfootuded donttemedia broken atomic muttereduating gps leon relatively atari document cutler [SEP]']
[Init] best perm rec loss: 0.933344841003418 for ['[CLS] trusting weight blood boysmediafultte donfoot muttered happenedats atari document practicing photograph eight leon watt cutler gps jp brokenuded credited wish relatively promisepateuating deaths atomic [SEP]']
[Init] best perm rec loss: 0.9307798743247986 for ['[CLS] happenedtte atari promiseats gps leon relatively blood broken weight deathsfootmedia jp wish atomic cutleruating eight watt boys practicing muttereduded document creditedpate donful photograph trusting [SEP]']
[Init] best perm rec loss: 0.9285004734992981 for ['[CLS]ats jp practicing blood trustingmediauating donfulpate promise boysfoot broken happened document relatively weight muttered atomic wish deaths credited photographtte atariuded leon cutler gps watt eight [SEP]']
[Init] best perm rec loss: 0.9245237708091736 for ['[CLS]pate watt weight gpsats eight boys document cutler jptte deathsuating blood trusting atari atomic credited wish donuded mutteredfoot happenedful photograph broken practicingmedia promise relatively leon [SEP]']
[Init] best perm rec loss: 0.9240761399269104 for ['[CLS]foot credited blooduded document atomic promise cutler boysats relatively photographmedia ataripate broken watt gps jp deathsful trustinguating weight don happenedtte practicing eight wish leon muttered [SEP]']
[Init] best perm rec loss: 0.9212810397148132 for ['[CLS] eight documentpateuating deaths blood boys muttered donuded photographfoot relatively broken cutler atomic practicing atari watt jpats happened trusting wish weight credited gpsmedia leonfultte promise [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.574 (perp=11.375, rec=0.289, cos=0.010), tot_loss_proj:2.967 [t=0.17s]
prediction: ['[CLS] assembly shirt tacticity of typical. military - st cover the its worsehe - worse for tactic any excuse officials tactic by since proved none fbies contributing worse technology [SEP]']
[ 100/2000] tot_loss=1.934 (perp=8.536, rec=0.221, cos=0.006), tot_loss_proj:2.541 [t=0.17s]
prediction: ['[CLS] yet faint tactic fact of tactic, conceptual - none cover up fact worsea - worse for tactic - worse pictures tactic - since yet worse - yet come worse ideas [SEP]']
[ 150/2000] tot_loss=2.006 (perp=9.034, rec=0.194, cos=0.005), tot_loss_proj:2.735 [t=0.18s]
prediction: ['[CLS] - me tactic fact the to - conceptual concept none cover up fact worse or to worse to tactic - worse picture tactic - picture yet worse - yet come worse ideas [SEP]']
[ 200/2000] tot_loss=2.032 (perp=9.354, rec=0.158, cos=0.004), tot_loss_proj:2.789 [t=0.18s]
prediction: ['[CLS] -is tactic fact of to is picture - none cover up fact worse or -im to tactic - worse yet tactic - picture none worse yet - core worse ideas [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.997 (perp=9.283, rec=0.138, cos=0.003), tot_loss_proj:3.104 [t=0.17s]
prediction: ['[CLS] -is tactic fact of core is picture to none cover up fact worse or -im - tactic - worse the tactic is picture none worse yet - core - ideas [SEP]']
[ 300/2000] tot_loss=1.957 (perp=9.152, rec=0.124, cos=0.002), tot_loss_proj:3.121 [t=0.17s]
prediction: ['[CLS] - fl tactic fact of core is built to none cover up fact worse or aimsy tactic - around the tactic is picturexi worse yet - core - ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.857 (perp=8.728, rec=0.109, cos=0.002), tot_loss_proj:2.859 [t=0.17s]
prediction: ['[CLS] a fl tactic fact of core that built to none cover up fact worse or -imsy tactic - around the tactic is picturexi worse yet - around - ideas [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.848 (perp=8.721, rec=0.101, cos=0.002), tot_loss_proj:2.915 [t=0.17s]
prediction: ['[CLS] a fl tactic fact of core that constructed to none cover up worse or fact -imsy tactic - around the tactic is picturexi worse yet - around - ideas [SEP]']
[ 450/2000] tot_loss=1.845 (perp=8.721, rec=0.099, cos=0.002), tot_loss_proj:2.908 [t=0.17s]
prediction: ['[CLS] a fl tactic fact of core that constructed to none cover up worse or fact -imsy tactic - around the tactic is picturexi worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.728 (perp=8.131, rec=0.099, cos=0.002), tot_loss_proj:2.366 [t=0.17s]
prediction: ['[CLS] a fl tactic fact of core that constructed to none cover up picture or fact -imsy tactic - - the tactic is worsexi worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.599 (perp=7.494, rec=0.098, cos=0.002), tot_loss_proj:2.177 [t=0.17s]
prediction: ['[CLS] a fl tactic fact fl core that constructed to worse cover up picture or fact flimsy tactic - - the tactic is nonexi worse yet - around - ideas [SEP]']
[ 600/2000] tot_loss=1.633 (perp=7.696, rec=0.092, cos=0.002), tot_loss_proj:2.146 [t=0.17s]
prediction: ['[CLS] a fl tactic fact fl core that constructed to worse cover up picture or fact flimsy tactic - ( the tactic is nonexi worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.633 (perp=7.701, rec=0.091, cos=0.002), tot_loss_proj:2.152 [t=0.17s]
prediction: ['[CLS] a fl tactic fact or core that constructed to worse cover up picture of fact flimsy tactic - ( the tactic is nonexi worse yet - around - ideas [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.573 (perp=7.422, rec=0.087, cos=0.002), tot_loss_proj:2.485 [t=0.17s]
prediction: ['[CLS] a fl tactic fact or core that worse constructed to cover up picture of fact flimsy tactic -, the tactic is nonexi worse yet - around - ideas [SEP]']
[ 750/2000] tot_loss=1.571 (perp=7.422, rec=0.084, cos=0.002), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] a fl tactic fact or core that worse constructed to cover up picture of fact flimsy tactic -, the tactic is nonexi worse yet - around - ideas [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.529 (perp=7.233, rec=0.081, cos=0.002), tot_loss_proj:2.580 [t=0.17s]
prediction: ['[CLS] a fl tactic fact or core that worse constructed to cover up picture of fact flimsy tactic - - the tactic is nonexi worse yet - around, ideas [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.681 (perp=7.924, rec=0.094, cos=0.002), tot_loss_proj:2.652 [t=0.17s]
prediction: ['[CLS] a fl tactic picture or core that worse constructed to cover up fact of fact flimsy tactic -sten the tactic is nonexi worse yet - around, ideas [SEP]']
[ 900/2000] tot_loss=1.659 (perp=7.885, rec=0.081, cos=0.002), tot_loss_proj:2.632 [t=0.17s]
prediction: ['[CLS] a fl tactic picture or core that worse constructed to cover up fact of fact flimsy tactic -sten the picture is nonexi worse yet - around, ideas [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.641 (perp=7.746, rec=0.090, cos=0.002), tot_loss_proj:2.379 [t=0.17s]
prediction: ['[CLS] a fl tactic picture or, that worse constructed to cover up fact of fact flimsy tactic -sten the picture is nonexi worse yet - around core ideas [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.608 (perp=7.602, rec=0.085, cos=0.002), tot_loss_proj:2.592 [t=0.17s]
prediction: ['[CLS] a fl tactic picture or, that worse constructed to cover up fact of fact flimsy tactic - around the tactic is nonexi worse yet -sten core ideas [SEP]']
[1050/2000] tot_loss=1.598 (perp=7.602, rec=0.076, cos=0.002), tot_loss_proj:2.589 [t=0.17s]
prediction: ['[CLS] a fl tactic picture or, that worse constructed to cover up fact of fact flimsy tactic - around the tactic is nonexi worse yet -sten core ideas [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.575 (perp=7.485, rec=0.077, cos=0.002), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] a fl tactic picture, or that worse constructed to cover up fact of fact flimsy tactic - around the tactic is nonexi worse yet -sten core ideas [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.511 (perp=7.159, rec=0.077, cos=0.002), tot_loss_proj:2.369 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - around the tactic is nonexi, yet -sten core ideas [SEP]']
[1200/2000] tot_loss=1.520 (perp=7.159, rec=0.087, cos=0.002), tot_loss_proj:2.363 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - around the tactic is nonexi, yet -sten core ideas [SEP]']
Attempt swap
[1250/2000] tot_loss=1.517 (perp=7.159, rec=0.084, cos=0.001), tot_loss_proj:2.362 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - around the tactic is nonexi, yet -sten core ideas [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.497 (perp=7.096, rec=0.077, cos=0.002), tot_loss_proj:2.203 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexi, yet -sten core ideas [SEP]']
[1350/2000] tot_loss=1.499 (perp=7.096, rec=0.078, cos=0.002), tot_loss_proj:2.208 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexi, yet -sten core ideas [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.460 (perp=6.884, rec=0.082, cos=0.002), tot_loss_proj:2.376 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the picture around nonexisten yet -, core ideas [SEP]']
Attempt swap
[1450/2000] tot_loss=1.451 (perp=6.877, rec=0.074, cos=0.001), tot_loss_proj:2.334 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet -, core ideas [SEP]']
[1500/2000] tot_loss=1.454 (perp=6.877, rec=0.077, cos=0.001), tot_loss_proj:2.329 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet -, core ideas [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.428 (perp=6.771, rec=0.072, cos=0.001), tot_loss_proj:2.235 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet, - core ideas [SEP]']
Attempt swap
[1600/2000] tot_loss=1.431 (perp=6.771, rec=0.075, cos=0.001), tot_loss_proj:2.237 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet, - core ideas [SEP]']
[1650/2000] tot_loss=1.433 (perp=6.771, rec=0.077, cos=0.001), tot_loss_proj:2.231 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet, - core ideas [SEP]']
Attempt swap
[1700/2000] tot_loss=1.436 (perp=6.771, rec=0.080, cos=0.001), tot_loss_proj:2.235 [t=0.17s]
prediction: ['[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet, - core ideas [SEP]']
Attempt swap
[1750/2000] tot_loss=1.467 (perp=6.926, rec=0.081, cos=0.001), tot_loss_proj:2.344 [t=0.17s]
prediction: ['[CLS] a of tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet, - core ideas [SEP]']
[1800/2000] tot_loss=1.461 (perp=6.926, rec=0.074, cos=0.001), tot_loss_proj:2.343 [t=0.17s]
prediction: ['[CLS] a of tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet, - core ideas [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.409 (perp=6.647, rec=0.078, cos=0.001), tot_loss_proj:2.239 [t=0.17s]
prediction: ['[CLS] of a tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet, - core ideas [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.384 (perp=6.520, rec=0.078, cos=0.002), tot_loss_proj:2.912 [t=0.17s]
prediction: ['[CLS] of a tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - - the tactic around nonexisten yet, is core ideas [SEP]']
[1950/2000] tot_loss=1.384 (perp=6.520, rec=0.078, cos=0.001), tot_loss_proj:2.913 [t=0.17s]
prediction: ['[CLS] of a tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - - the tactic around nonexisten yet, is core ideas [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.367 (perp=6.421, rec=0.081, cos=0.001), tot_loss_proj:2.359 [t=0.17s]
prediction: ['[CLS] of a tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - - the tactic is around nonexisten yet, core ideas [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] a fl tactic or picture, that worse constructed to cover up fact of fact flimsy tactic - is the tactic around nonexisten yet, - core ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 80.769 | r: 91.304
rouge2     | fm: 12.766 | p: 12.000 | r: 13.636
rougeL     | fm: 44.898 | p: 42.308 | r: 47.826
rougeLsum  | fm: 44.898 | p: 42.308 | r: 47.826
r1fm+r2fm = 98.480

[Aggregate metrics]:
rouge1     | fm: 92.315 | p: 91.809 | r: 92.914
rouge2     | fm: 59.700 | p: 59.375 | r: 60.053
rougeL     | fm: 80.124 | p: 79.726 | r: 80.538
rougeLsum  | fm: 80.084 | p: 79.675 | r: 80.597
r1fm+r2fm = 152.015

input #89 time: 0:08:49 | total time: 12:11:26


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9993650968600143
highest_index [0]
highest [0.9993650968600143]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.9487876892089844 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.9457016587257385 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.9307820200920105 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 0.9131976962089539 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8914667963981628 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.8844628930091858 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.874426543712616 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.8734989166259766 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.8714959025382996 for ['[CLS] when entourage spirited male released cannot [SEP]']
[Init] best perm rec loss: 0.8705925345420837 for ['[CLS] cannot male spirited entourage released when [SEP]']
[Init] best perm rec loss: 0.8705049157142639 for ['[CLS] cannot entourage spirited male released when [SEP]']
[Init] best perm rec loss: 0.8698896765708923 for ['[CLS] male cannot when spirited released entourage [SEP]']
[Init] best perm rec loss: 0.8698087334632874 for ['[CLS] entourage released spirited male cannot when [SEP]']
[Init] best perm rec loss: 0.8679990172386169 for ['[CLS] cannot released male spirited when entourage [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.325 (perp=10.178, rec=0.272, cos=0.018), tot_loss_proj:2.881 [t=0.17s]
prediction: ['[CLS] highly ridiculous ; legislative money how [SEP]']
[ 100/2000] tot_loss=2.299 (perp=10.783, rec=0.139, cos=0.004), tot_loss_proj:2.852 [t=0.17s]
prediction: ['[CLS] ridiculous ridiculous and oriented money how [SEP]']
[ 150/2000] tot_loss=2.260 (perp=10.783, rec=0.100, cos=0.003), tot_loss_proj:2.842 [t=0.17s]
prediction: ['[CLS] ridiculous ridiculous and oriented money how [SEP]']
[ 200/2000] tot_loss=2.513 (perp=12.167, rec=0.077, cos=0.002), tot_loss_proj:3.397 [t=0.20s]
prediction: ['[CLS] insane ridiculous and oriented money how [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.795 (perp=8.441, rec=0.102, cos=0.005), tot_loss_proj:2.308 [t=0.19s]
prediction: ['[CLS] how ridiculous and oriented money - [SEP]']
[ 300/2000] tot_loss=1.754 (perp=8.441, rec=0.064, cos=0.002), tot_loss_proj:2.312 [t=0.19s]
prediction: ['[CLS] how ridiculous and oriented money - [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.452 (perp=6.870, rec=0.077, cos=0.002), tot_loss_proj:1.704 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.445 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.443 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.433 (perp=6.870, rec=0.058, cos=0.001), tot_loss_proj:1.715 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.453 (perp=6.870, rec=0.077, cos=0.001), tot_loss_proj:1.712 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.711 [t=0.20s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.707 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.717 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.715 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.434 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.446 (perp=6.870, rec=0.071, cos=0.001), tot_loss_proj:1.715 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.715 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.435 (perp=6.870, rec=0.059, cos=0.001), tot_loss_proj:1.717 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.432 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.724 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.428 (perp=6.870, rec=0.053, cos=0.001), tot_loss_proj:1.719 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.720 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.432 (perp=6.870, rec=0.057, cos=0.001), tot_loss_proj:1.716 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.428 (perp=6.870, rec=0.053, cos=0.001), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.430 (perp=6.870, rec=0.055, cos=0.001), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.429 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.405 | p: 91.902 | r: 92.990
rouge2     | fm: 60.060 | p: 59.723 | r: 60.503
rougeL     | fm: 80.241 | p: 79.840 | r: 80.721
rougeLsum  | fm: 80.334 | p: 79.969 | r: 80.798
r1fm+r2fm = 152.465

input #90 time: 0:08:15 | total time: 12:19:42


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9993538374859834
highest_index [0]
highest [0.9993538374859834]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.9367198944091797 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.8268771767616272 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.8143160343170166 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.77603679895401 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.7621927261352539 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.7398632168769836 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 0.7303189039230347 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 0.7301856279373169 for ['[CLS]dern pony revolutionpment unknownlip hard shelter [SEP]']
[Init] best perm rec loss: 0.7299460172653198 for ['[CLS]lippment hard unknown pony shelterdern revolution [SEP]']
[Init] best perm rec loss: 0.7278955578804016 for ['[CLS] hard unknown revolutiondernlip shelter ponypment [SEP]']
[Init] best perm rec loss: 0.7267093658447266 for ['[CLS] pony hard shelterpmentlip unknowndern revolution [SEP]']
[Init] best perm rec loss: 0.7247644662857056 for ['[CLS] hard unknown revolutionpmentlipdern shelter pony [SEP]']
[Init] best perm rec loss: 0.7247127890586853 for ['[CLS] hard shelterpmentlip revolution unknowndern pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.381 (perp=10.234, rec=0.305, cos=0.029), tot_loss_proj:2.977 [t=0.17s]
prediction: ['[CLS] yellow crazy loco more ridiculous more wave ridiculous [SEP]']
[ 100/2000] tot_loss=2.406 (perp=10.921, rec=0.206, cos=0.015), tot_loss_proj:2.989 [t=0.17s]
prediction: ['[CLS]y loco loco more ridiculous more mu ridiculous [SEP]']
[ 150/2000] tot_loss=2.315 (perp=10.277, rec=0.193, cos=0.066), tot_loss_proj:2.600 [t=0.17s]
prediction: ['[CLS] but loco loco no ridiculous more mu ridiculous [SEP]']
[ 200/2000] tot_loss=2.008 (perp=9.515, rec=0.101, cos=0.004), tot_loss_proj:2.443 [t=0.17s]
prediction: ['[CLS] but locoy no ridiculous more mu ridiculous [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.982 (perp=9.285, rec=0.115, cos=0.010), tot_loss_proj:2.334 [t=0.17s]
prediction: ['[CLS] but locoy no more ridiculous mu ridiculous [SEP]']
[ 300/2000] tot_loss=1.948 (perp=9.285, rec=0.088, cos=0.003), tot_loss_proj:2.331 [t=0.17s]
prediction: ['[CLS] but locoy no more ridiculous mu ridiculous [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.932 (perp=9.285, rec=0.071, cos=0.003), tot_loss_proj:2.326 [t=0.17s]
prediction: ['[CLS] but locoy no more ridiculous mu ridiculous [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.894 (perp=8.995, rec=0.091, cos=0.004), tot_loss_proj:2.824 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
[ 450/2000] tot_loss=1.877 (perp=8.995, rec=0.075, cos=0.003), tot_loss_proj:2.826 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.875 (perp=8.995, rec=0.073, cos=0.003), tot_loss_proj:2.820 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.879 (perp=8.995, rec=0.078, cos=0.003), tot_loss_proj:2.821 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
[ 600/2000] tot_loss=1.877 (perp=8.995, rec=0.075, cos=0.003), tot_loss_proj:2.811 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.867 (perp=8.995, rec=0.066, cos=0.003), tot_loss_proj:2.814 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.885 (perp=8.995, rec=0.084, cos=0.003), tot_loss_proj:2.807 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
[ 750/2000] tot_loss=1.868 (perp=8.995, rec=0.067, cos=0.003), tot_loss_proj:2.803 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.878 (perp=8.995, rec=0.076, cos=0.003), tot_loss_proj:2.801 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.872 (perp=8.995, rec=0.070, cos=0.003), tot_loss_proj:2.803 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
[ 900/2000] tot_loss=1.881 (perp=8.995, rec=0.079, cos=0.003), tot_loss_proj:2.801 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.874 (perp=8.995, rec=0.073, cos=0.003), tot_loss_proj:2.798 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
Attempt swap
[1000/2000] tot_loss=1.879 (perp=8.995, rec=0.077, cos=0.003), tot_loss_proj:2.798 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu ridiculous [SEP]']
[1050/2000] tot_loss=2.018 (perp=9.739, rec=0.068, cos=0.002), tot_loss_proj:2.720 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu joyah [SEP]']
Attempt swap
[1100/2000] tot_loss=2.032 (perp=9.739, rec=0.082, cos=0.003), tot_loss_proj:2.731 [t=0.17s]
prediction: ['[CLS] ridiculous locoy no more but mu joyah [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.992 (perp=9.542, rec=0.080, cos=0.004), tot_loss_proj:2.822 [t=0.20s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
[1200/2000] tot_loss=1.984 (perp=9.542, rec=0.073, cos=0.003), tot_loss_proj:2.828 [t=0.19s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1250/2000] tot_loss=1.988 (perp=9.542, rec=0.077, cos=0.002), tot_loss_proj:2.830 [t=0.18s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1300/2000] tot_loss=1.975 (perp=9.542, rec=0.064, cos=0.002), tot_loss_proj:2.831 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
[1350/2000] tot_loss=1.988 (perp=9.542, rec=0.077, cos=0.002), tot_loss_proj:2.827 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1400/2000] tot_loss=1.991 (perp=9.542, rec=0.080, cos=0.002), tot_loss_proj:2.827 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1450/2000] tot_loss=1.984 (perp=9.542, rec=0.073, cos=0.002), tot_loss_proj:2.833 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
[1500/2000] tot_loss=1.977 (perp=9.542, rec=0.066, cos=0.002), tot_loss_proj:2.829 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1550/2000] tot_loss=1.979 (perp=9.542, rec=0.069, cos=0.002), tot_loss_proj:2.831 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1600/2000] tot_loss=1.989 (perp=9.542, rec=0.078, cos=0.002), tot_loss_proj:2.830 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
[1650/2000] tot_loss=1.983 (perp=9.542, rec=0.073, cos=0.002), tot_loss_proj:2.826 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1700/2000] tot_loss=1.977 (perp=9.542, rec=0.067, cos=0.002), tot_loss_proj:2.839 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1750/2000] tot_loss=1.985 (perp=9.542, rec=0.074, cos=0.002), tot_loss_proj:2.838 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
[1800/2000] tot_loss=1.983 (perp=9.542, rec=0.072, cos=0.002), tot_loss_proj:2.824 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1850/2000] tot_loss=1.990 (perp=9.542, rec=0.079, cos=0.002), tot_loss_proj:2.835 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[1900/2000] tot_loss=1.980 (perp=9.542, rec=0.070, cos=0.002), tot_loss_proj:2.834 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
[1950/2000] tot_loss=1.978 (perp=9.542, rec=0.067, cos=0.002), tot_loss_proj:2.833 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butperation [SEP]']
Attempt swap
[2000/2000] tot_loss=1.995 (perp=9.623, rec=0.068, cos=0.002), tot_loss_proj:3.114 [t=0.17s]
prediction: ['[CLS] ridiculous loco muy no more butgingly [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] ridiculous loco muy no more butgingly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 101.786

[Aggregate metrics]:
rouge1     | fm: 92.317 | p: 91.861 | r: 92.935
rouge2     | fm: 59.533 | p: 59.214 | r: 59.900
rougeL     | fm: 80.209 | p: 79.844 | r: 80.639
rougeLsum  | fm: 80.099 | p: 79.710 | r: 80.593
r1fm+r2fm = 151.850

input #91 time: 0:07:59 | total time: 12:27:41


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9993137310302476
highest_index [0]
highest [0.9993137310302476]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.8797468543052673 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8783625364303589 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8693297505378723 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.8594153523445129 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 0.8578515648841858 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.8554595112800598 for ['[CLS] edge island [SEP]']
[Init] best rec loss: 0.7936431765556335 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 0.7916328310966492 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.630 (perp=12.265, rec=0.171, cos=0.006), tot_loss_proj:3.210 [t=0.21s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.592 (perp=7.646, rec=0.061, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.592 (perp=7.646, rec=0.061, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.580 (perp=7.646, rec=0.049, cos=0.002), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.586 (perp=7.646, rec=0.055, cos=0.002), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.599 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.605 (perp=7.646, rec=0.074, cos=0.001), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.605 (perp=7.646, rec=0.075, cos=0.001), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.596 (perp=7.646, rec=0.066, cos=0.001), tot_loss_proj:1.590 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.594 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.601 (perp=7.646, rec=0.071, cos=0.001), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.584 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.603 [t=0.16s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.594 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.595 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.576 (perp=7.646, rec=0.046, cos=0.001), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.582 (perp=7.646, rec=0.051, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.591 (perp=7.646, rec=0.061, cos=0.001), tot_loss_proj:1.578 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.606 (perp=7.646, rec=0.076, cos=0.001), tot_loss_proj:1.610 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.604 (perp=7.646, rec=0.073, cos=0.001), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.586 (perp=7.646, rec=0.055, cos=0.001), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.570 (perp=7.646, rec=0.040, cos=0.001), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.594 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.583 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.581 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.586 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.580 (perp=7.646, rec=0.049, cos=0.001), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.601 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.592 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.593 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.588 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.594 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.587 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.413 | p: 91.936 | r: 93.003
rouge2     | fm: 59.981 | p: 59.657 | r: 60.387
rougeL     | fm: 80.238 | p: 79.909 | r: 80.736
rougeLsum  | fm: 80.271 | p: 79.941 | r: 80.742
r1fm+r2fm = 152.393

input #92 time: 0:09:05 | total time: 12:36:47


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9993323263895038
highest_index [0]
highest [0.9993323263895038]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.0078084468841553 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.8302108645439148 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.8220402598381042 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 0.8074820637702942 for ['[CLS] solo specificball shrinking lad 1970s judicial [SEP]']
[Init] best perm rec loss: 0.8070929646492004 for ['[CLS]ball lad specific shrinking judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.807031512260437 for ['[CLS] lad specific shrinkingball judicial 1970s solo [SEP]']
[Init] best perm rec loss: 0.806305468082428 for ['[CLS] lad shrinkingball solo 1970s judicial specific [SEP]']
[Init] best perm rec loss: 0.8061965107917786 for ['[CLS] solo 1970s shrinkingball lad judicial specific [SEP]']
[Init] best perm rec loss: 0.8059419989585876 for ['[CLS] 1970s specificball shrinking judicial lad solo [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.984 (perp=13.254, rec=0.320, cos=0.012), tot_loss_proj:3.705 [t=0.17s]
prediction: ['[CLS] functionip - funny understanding she aid [SEP]']
[ 100/2000] tot_loss=2.485 (perp=11.275, rec=0.224, cos=0.006), tot_loss_proj:3.674 [t=0.17s]
prediction: ['[CLS] functionley in funny understanding maybe understanding [SEP]']
[ 150/2000] tot_loss=2.184 (perp=9.965, rec=0.187, cos=0.004), tot_loss_proj:2.505 [t=0.17s]
prediction: ['[CLS] functionley in funny understanding, understanding [SEP]']
[ 200/2000] tot_loss=2.500 (perp=11.697, rec=0.157, cos=0.003), tot_loss_proj:2.802 [t=0.17s]
prediction: ['[CLS] function often in funny funny often understanding [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.128 (perp=9.784, rec=0.168, cos=0.003), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] disease often in funny funny way often [SEP]']
[ 300/2000] tot_loss=2.035 (perp=9.446, rec=0.142, cos=0.003), tot_loss_proj:2.257 [t=0.17s]
prediction: ['[CLS] developed often in funny funny way often [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.107 (perp=9.845, rec=0.135, cos=0.003), tot_loss_proj:2.443 [t=0.17s]
prediction: ['[CLS] developed in hey funny funny way often [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.980 (perp=9.166, rec=0.144, cos=0.003), tot_loss_proj:2.245 [t=0.17s]
prediction: ['[CLS] ; developed in funny funny way often [SEP]']
[ 450/2000] tot_loss=2.085 (perp=9.810, rec=0.121, cos=0.003), tot_loss_proj:2.352 [t=0.17s]
prediction: ['[CLS] ; developed in understanding funny way often [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.069 (perp=9.688, rec=0.129, cos=0.002), tot_loss_proj:2.424 [t=0.17s]
prediction: ['[CLS] at understanding developed in funny way often [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.940 (perp=9.058, rec=0.125, cos=0.003), tot_loss_proj:2.195 [t=0.17s]
prediction: ['[CLS] at understanding developed in often funny way [SEP]']
[ 600/2000] tot_loss=1.924 (perp=9.058, rec=0.110, cos=0.003), tot_loss_proj:2.190 [t=0.17s]
prediction: ['[CLS] at understanding developed in often funny way [SEP]']
Attempt swap
Put prefix at the end
[ 650/2000] tot_loss=1.795 (perp=8.385, rec=0.115, cos=0.002), tot_loss_proj:2.084 [t=0.17s]
prediction: ['[CLS] understanding developed in often funny way at [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.786 (perp=8.385, rec=0.107, cos=0.002), tot_loss_proj:2.087 [t=0.17s]
prediction: ['[CLS] understanding developed in often funny way at [SEP]']
[ 750/2000] tot_loss=1.791 (perp=8.385, rec=0.112, cos=0.002), tot_loss_proj:2.090 [t=0.17s]
prediction: ['[CLS] understanding developed in often funny way at [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.786 (perp=8.385, rec=0.107, cos=0.002), tot_loss_proj:2.090 [t=0.17s]
prediction: ['[CLS] understanding developed in often funny way at [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.788 (perp=8.385, rec=0.108, cos=0.002), tot_loss_proj:2.090 [t=0.17s]
prediction: ['[CLS] understanding developed in often funny way at [SEP]']
[ 900/2000] tot_loss=1.797 (perp=8.385, rec=0.117, cos=0.002), tot_loss_proj:2.087 [t=0.17s]
prediction: ['[CLS] understanding developed in often funny way at [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.780 (perp=8.385, rec=0.100, cos=0.002), tot_loss_proj:2.085 [t=0.17s]
prediction: ['[CLS] understanding developed in often funny way at [SEP]']
Attempt swap
[1000/2000] tot_loss=1.887 (perp=8.897, rec=0.105, cos=0.002), tot_loss_proj:2.255 [t=0.17s]
prediction: ['[CLS] understanding its in often funny way at [SEP]']
[1050/2000] tot_loss=1.693 (perp=7.936, rec=0.103, cos=0.002), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] understanding its in often funny way, [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.451 (perp=6.704, rec=0.108, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.445 (perp=6.704, rec=0.102, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1200/2000] tot_loss=1.446 (perp=6.704, rec=0.103, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.442 (perp=6.704, rec=0.099, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.441 (perp=6.704, rec=0.098, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1350/2000] tot_loss=1.441 (perp=6.704, rec=0.098, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.440 (perp=6.704, rec=0.096, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.436 (perp=6.704, rec=0.093, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1500/2000] tot_loss=1.435 (perp=6.704, rec=0.092, cos=0.002), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.429 (perp=6.704, rec=0.087, cos=0.002), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.424 (perp=6.704, rec=0.081, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1650/2000] tot_loss=1.418 (perp=6.704, rec=0.076, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.421 (perp=6.704, rec=0.079, cos=0.002), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.423 (perp=6.704, rec=0.080, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1800/2000] tot_loss=1.415 (perp=6.704, rec=0.073, cos=0.002), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.416 (perp=6.704, rec=0.074, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.414 (perp=6.704, rec=0.072, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
[1950/2000] tot_loss=1.414 (perp=6.704, rec=0.071, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.420 (perp=6.704, rec=0.077, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] understanding in its often funny way, [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding in its often funny way, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 92.518 | p: 92.037 | r: 93.137
rouge2     | fm: 59.822 | p: 59.541 | r: 60.243
rougeL     | fm: 80.488 | p: 80.088 | r: 80.937
rougeLsum  | fm: 80.427 | p: 80.015 | r: 80.916
r1fm+r2fm = 152.340

input #93 time: 0:08:00 | total time: 12:44:48


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9993168061064917
highest_index [0]
highest [0.9993168061064917]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9727807641029358 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9545496106147766 for ['[CLS] bears participating president flipping mines outstanding carr ultimateon crossingle [SEP]']
[Init] best rec loss: 0.9148076176643372 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.9085803627967834 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 0.8869084715843201 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8795130848884583 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 0.879210889339447 for ['[CLS] internal plum rockwell expedition crushed flowering shocks territorialventing chronic centre [SEP]']
[Init] best perm rec loss: 0.8783528804779053 for ['[CLS] internalventing territorial shocks expedition centre crushed plum flowering chronic rockwell [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=12.852, rec=0.324, cos=0.016), tot_loss_proj:3.328 [t=0.17s]
prediction: ['[CLS] missing killing outbreak aywood surrounding transport neitherting neither funny [SEP]']
[ 100/2000] tot_loss=2.205 (perp=9.886, rec=0.221, cos=0.007), tot_loss_proj:2.582 [t=0.17s]
prediction: ['[CLS] or who serials a caper s neither terribly neither funny [SEP]']
[ 150/2000] tot_loss=1.831 (perp=8.375, rec=0.152, cos=0.004), tot_loss_proj:2.317 [t=0.17s]
prediction: ['[CLS] not who a a caper s neither original nor funny [SEP]']
[ 200/2000] tot_loss=1.951 (perp=9.190, rec=0.110, cos=0.003), tot_loss_proj:2.413 [t=0.17s]
prediction: ['[CLS] s cape a a caper s neither original nor funny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.695 (perp=7.877, rec=0.117, cos=0.003), tot_loss_proj:2.061 [t=0.17s]
prediction: ['[CLS] s a terribly a caper s neither original nor funny [SEP]']
[ 300/2000] tot_loss=1.663 (perp=7.877, rec=0.086, cos=0.002), tot_loss_proj:2.070 [t=0.17s]
prediction: ['[CLS] s a terribly a caper s neither original nor funny [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.667 (perp=7.877, rec=0.090, cos=0.002), tot_loss_proj:2.062 [t=0.17s]
prediction: ['[CLS] s a terribly a caper s neither original nor funny [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.598 (perp=7.646, rec=0.067, cos=0.001), tot_loss_proj:2.113 [t=0.17s]
prediction: ['[CLS] s a terribly that a caper neither original nor funny [SEP]']
[ 450/2000] tot_loss=1.602 (perp=7.646, rec=0.072, cos=0.001), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] s a terribly that a caper neither original nor funny [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.439 (perp=6.858, rec=0.066, cos=0.001), tot_loss_proj:1.802 [t=0.17s]
prediction: ['[CLS] s that a caper neither a terribly original nor funny [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.430 (perp=6.800, rec=0.068, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] that s a caper neither a terribly original nor funny [SEP]']
[ 600/2000] tot_loss=1.438 (perp=6.800, rec=0.077, cos=0.001), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS] that s a caper neither a terribly original nor funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.422 (perp=6.800, rec=0.061, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] that s a caper neither a terribly original nor funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.433 (perp=6.800, rec=0.071, cos=0.001), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] that s a caper neither a terribly original nor funny [SEP]']
[ 750/2000] tot_loss=1.437 (perp=6.800, rec=0.075, cos=0.001), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] that s a caper neither a terribly original nor funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.435 (perp=6.800, rec=0.074, cos=0.001), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS] that s a caper neither a terribly original nor funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.429 (perp=6.800, rec=0.068, cos=0.001), tot_loss_proj:1.745 [t=0.17s]
prediction: ['[CLS] that s a caper neither a terribly original nor funny [SEP]']
[ 900/2000] tot_loss=1.432 (perp=6.800, rec=0.071, cos=0.001), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] that s a caper neither a terribly original nor funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.487 (perp=7.127, rec=0.060, cos=0.001), tot_loss_proj:1.857 [t=0.17s]
prediction: ["[CLS] that s a caper neither'terribly original nor funny [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.345 (perp=6.377, rec=0.068, cos=0.002), tot_loss_proj:1.600 [t=0.19s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
[1050/2000] tot_loss=1.344 (perp=6.377, rec=0.067, cos=0.001), tot_loss_proj:1.607 [t=0.17s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.349 (perp=6.377, rec=0.072, cos=0.001), tot_loss_proj:1.599 [t=0.19s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.337 (perp=6.377, rec=0.061, cos=0.001), tot_loss_proj:1.611 [t=0.17s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
[1200/2000] tot_loss=1.344 (perp=6.377, rec=0.067, cos=0.001), tot_loss_proj:1.610 [t=0.17s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.345 (perp=6.377, rec=0.069, cos=0.001), tot_loss_proj:1.608 [t=0.17s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.348 (perp=6.377, rec=0.071, cos=0.001), tot_loss_proj:1.612 [t=0.17s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
[1350/2000] tot_loss=1.341 (perp=6.377, rec=0.064, cos=0.001), tot_loss_proj:1.610 [t=0.17s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.337 (perp=6.377, rec=0.061, cos=0.001), tot_loss_proj:1.620 [t=0.17s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.343 (perp=6.377, rec=0.067, cos=0.001), tot_loss_proj:1.611 [t=0.21s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
[1500/2000] tot_loss=1.344 (perp=6.377, rec=0.068, cos=0.001), tot_loss_proj:1.609 [t=0.17s]
prediction: ["[CLS]'s a caper neither that terribly original nor funny [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.164 (perp=5.517, rec=0.059, cos=0.001), tot_loss_proj:1.398 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.166 (perp=5.517, rec=0.061, cos=0.001), tot_loss_proj:1.406 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1650/2000] tot_loss=1.171 (perp=5.517, rec=0.066, cos=0.001), tot_loss_proj:1.403 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.168 (perp=5.517, rec=0.064, cos=0.001), tot_loss_proj:1.404 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.179 (perp=5.517, rec=0.074, cos=0.001), tot_loss_proj:1.411 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1800/2000] tot_loss=1.178 (perp=5.517, rec=0.073, cos=0.001), tot_loss_proj:1.401 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.175 (perp=5.517, rec=0.070, cos=0.001), tot_loss_proj:1.410 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.165 (perp=5.517, rec=0.060, cos=0.001), tot_loss_proj:1.405 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
[1950/2000] tot_loss=1.167 (perp=5.517, rec=0.062, cos=0.001), tot_loss_proj:1.405 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.161 (perp=5.517, rec=0.057, cos=0.001), tot_loss_proj:1.404 [t=0.17s]
prediction: ["[CLS] that's a caper neither terribly original nor funny [SEP]"]
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] that's a caper neither terribly original nor funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 72.727 | p: 72.727 | r: 72.727
rougeLsum  | fm: 72.727 | p: 72.727 | r: 72.727
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 92.583 | p: 92.125 | r: 93.139
rouge2     | fm: 59.555 | p: 59.233 | r: 59.929
rougeL     | fm: 80.320 | p: 79.961 | r: 80.802
rougeLsum  | fm: 80.355 | p: 79.980 | r: 80.812
r1fm+r2fm = 152.138

input #94 time: 0:09:43 | total time: 12:54:32


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9991574288984811
highest_index [0]
highest [0.9991574288984811]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9695915579795837 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9447000622749329 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 0.9425680041313171 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.9293648600578308 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 0.9289979338645935 for ['[CLS] oval foster welfarecu range turk partly support turret familiesumatic helping inclinedsteredling [SEP]']
[Init] best rec loss: 0.9244387745857239 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 0.8965775966644287 for ['[CLS] plenty heroes kit operating aim ouby fa physics pinco victim playing cisco feeling [SEP]']
[Init] best rec loss: 0.8573101758956909 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8477544188499451 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 0.8469237089157104 for ['[CLS] cut pressure ]ے wire complete sister block monty hanging damp tech trailer privatenne [SEP]']
[Init] best perm rec loss: 0.8467367887496948 for ['[CLS] wireے pressure ] damp trailer cut private block sister complete hanging tech montynne [SEP]']
[Init] best perm rec loss: 0.8459979295730591 for ['[CLS] complete trailer pressure private damp sister hanging wire block monty cutnneے ] tech [SEP]']
[Init] best perm rec loss: 0.8446309566497803 for ['[CLS] sister damp trailer cut private monty complete pressure tech wire hangingے ] blocknne [SEP]']
[Init] best perm rec loss: 0.8437495231628418 for ['[CLS]ے ] wire tech private pressure trailer monty completenne cut block damp sister hanging [SEP]']
[Init] best perm rec loss: 0.8430407643318176 for ['[CLS] trailer sister wire monty blockے hanging private cut complete pressure damp ] technne [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.600 (perp=11.868, rec=0.220, cos=0.006), tot_loss_proj:2.860 [t=0.17s]
prediction: ['[CLS] the brick protein hopeless story becomes hopeless vested mud become an hopeless hopelessdam hopeless [SEP]']
[ 100/2000] tot_loss=2.454 (perp=11.530, rec=0.144, cos=0.004), tot_loss_proj:2.827 [t=0.17s]
prediction: ['[CLS] ( mud atmosphere hopeless story becomes hopeless externaldle becomes,fying hopeless,sat [SEP]']
[ 150/2000] tot_loss=1.966 (perp=9.241, rec=0.115, cos=0.003), tot_loss_proj:2.292 [t=0.17s]
prediction: ['[CLS] ( mud ) hopeless story becomes a muddle become,fying hopeless,sat [SEP]']
[ 200/2000] tot_loss=2.023 (perp=9.578, rec=0.105, cos=0.003), tot_loss_proj:2.338 [t=0.17s]
prediction: ['[CLS] ( mud ) un story becomes a muddle (,fying hopelessissat [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.270 (perp=10.393, rec=0.187, cos=0.005), tot_loss_proj:2.536 [t=0.17s]
prediction: ["[CLS]'mudsat arrangements story becomes a adle un,fying hopelessis ) [SEP]"]
[ 300/2000] tot_loss=2.305 (perp=10.905, rec=0.121, cos=0.003), tot_loss_proj:2.694 [t=0.17s]
prediction: ["[CLS]'mudsat un story becomesislaus adle un,fying hopelessis ) [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.005 (perp=9.459, rec=0.111, cos=0.003), tot_loss_proj:2.412 [t=0.17s]
prediction: ["[CLS]'mudsat un story becomes, adle un denisfying hopelessis ) [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=1.950 (perp=9.192, rec=0.109, cos=0.002), tot_loss_proj:2.344 [t=0.21s]
prediction: ["[CLS]'mudsat un story becomes, adle un denisisfying hopeless ) [SEP]"]
[ 450/2000] tot_loss=1.938 (perp=9.192, rec=0.097, cos=0.002), tot_loss_proj:2.343 [t=0.19s]
prediction: ["[CLS]'mudsat un story becomes, adle un denisisfying hopeless ) [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.824 (perp=8.640, rec=0.093, cos=0.002), tot_loss_proj:2.263 [t=0.17s]
prediction: ["[CLS]'mud denis un story becomes, adle unsatisfying hopeless ) [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.707 (perp=8.093, rec=0.086, cos=0.002), tot_loss_proj:2.149 [t=0.17s]
prediction: ["[CLS]'mud story un denis becomes, adle unsatisfying hopeless ) [SEP]"]
[ 600/2000] tot_loss=1.703 (perp=8.093, rec=0.082, cos=0.002), tot_loss_proj:2.148 [t=0.17s]
prediction: ["[CLS]'mud story un denis becomes, adle unsatisfying hopeless ) [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.645 (perp=7.786, rec=0.086, cos=0.002), tot_loss_proj:2.037 [t=0.17s]
prediction: ["[CLS]'mud story, un denis becomes adle unsatisfying hopeless ) [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.517 (perp=7.057, rec=0.103, cos=0.002), tot_loss_proj:1.859 [t=0.17s]
prediction: ["[CLS]'story, un denis becomes a muddle unsatisfying hopeless ) [SEP]"]
[ 750/2000] tot_loss=1.496 (perp=7.057, rec=0.083, cos=0.002), tot_loss_proj:1.851 [t=0.17s]
prediction: ["[CLS]'story, un denis becomes a muddle unsatisfying hopeless ) [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.461 (perp=6.865, rec=0.086, cos=0.002), tot_loss_proj:1.826 [t=0.17s]
prediction: ["[CLS] denis story, un'becomes a muddle unsatisfying hopeless ) [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.429 (perp=6.730, rec=0.080, cos=0.002), tot_loss_proj:1.812 [t=0.18s]
prediction: ["[CLS] denis story,'un becomes a muddle unsatisfying hopeless ) [SEP]"]
[ 900/2000] tot_loss=1.422 (perp=6.730, rec=0.073, cos=0.002), tot_loss_proj:1.812 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a muddle unsatisfying hopeless ) [SEP]"]
Attempt swap
Moved token
[ 950/2000] tot_loss=1.334 (perp=6.271, rec=0.078, cos=0.002), tot_loss_proj:1.809 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.333 (perp=6.271, rec=0.077, cos=0.002), tot_loss_proj:1.810 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
[1050/2000] tot_loss=1.330 (perp=6.271, rec=0.074, cos=0.002), tot_loss_proj:1.812 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.335 (perp=6.271, rec=0.079, cos=0.002), tot_loss_proj:1.809 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.326 (perp=6.271, rec=0.070, cos=0.002), tot_loss_proj:1.803 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
[1200/2000] tot_loss=1.337 (perp=6.271, rec=0.081, cos=0.002), tot_loss_proj:1.811 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.341 (perp=6.271, rec=0.084, cos=0.002), tot_loss_proj:1.807 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.331 (perp=6.271, rec=0.075, cos=0.002), tot_loss_proj:1.814 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
[1350/2000] tot_loss=1.335 (perp=6.271, rec=0.078, cos=0.002), tot_loss_proj:1.807 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.335 (perp=6.271, rec=0.078, cos=0.002), tot_loss_proj:1.815 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.334 (perp=6.271, rec=0.078, cos=0.002), tot_loss_proj:1.812 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
[1500/2000] tot_loss=1.336 (perp=6.271, rec=0.080, cos=0.002), tot_loss_proj:1.812 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.335 (perp=6.271, rec=0.079, cos=0.002), tot_loss_proj:1.809 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.329 (perp=6.271, rec=0.072, cos=0.002), tot_loss_proj:1.814 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
[1650/2000] tot_loss=1.330 (perp=6.271, rec=0.074, cos=0.002), tot_loss_proj:1.813 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.331 (perp=6.271, rec=0.075, cos=0.002), tot_loss_proj:1.813 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.330 (perp=6.271, rec=0.073, cos=0.002), tot_loss_proj:1.816 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
[1800/2000] tot_loss=1.337 (perp=6.271, rec=0.080, cos=0.002), tot_loss_proj:1.817 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.333 (perp=6.271, rec=0.077, cos=0.002), tot_loss_proj:1.811 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.335 (perp=6.271, rec=0.079, cos=0.002), tot_loss_proj:1.818 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
[1950/2000] tot_loss=1.334 (perp=6.271, rec=0.077, cos=0.002), tot_loss_proj:1.815 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.336 (perp=6.271, rec=0.080, cos=0.002), tot_loss_proj:1.810 [t=0.17s]
prediction: ["[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] denis story,'un becomes a hopeless muddle unsatisfying ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 47.059 | p: 44.444 | r: 50.000
rougeL     | fm: 84.211 | p: 80.000 | r: 88.889
rougeLsum  | fm: 84.211 | p: 80.000 | r: 88.889
r1fm+r2fm = 141.796

[Aggregate metrics]:
rouge1     | fm: 92.598 | p: 92.072 | r: 93.249
rouge2     | fm: 59.450 | p: 59.169 | r: 59.790
rougeL     | fm: 80.373 | p: 79.945 | r: 80.868
rougeLsum  | fm: 80.326 | p: 79.937 | r: 80.786
r1fm+r2fm = 152.047

input #95 time: 0:10:53 | total time: 13:05:25


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9992866562400882
highest_index [0]
highest [0.9992866562400882]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.8909018635749817 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.8791100382804871 for ['[CLS] regrets emotionsoit purpose superior loop released given higher careini speechply springs assist [SEP]']
[Init] best rec loss: 0.8585579991340637 for ['[CLS] all nova resolution which assault domestic look mandy headquarteredtated thanlus completion stillboards [SEP]']
[Init] best rec loss: 0.8257309794425964 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 0.8243802189826965 for ['[CLS] lighter dunbar y itself phantom gen pickflowerled record margaret failed living giles stake [SEP]']
[Init] best rec loss: 0.8242563605308533 for ['[CLS] flex thought considerationlin kylie ste in gasped somewherese top close christian raised us [SEP]']
[Init] best rec loss: 0.8184889554977417 for ['[CLS] lea corps cellrily smashed unconscious garcia broke intensity baseball urban who reins brigade β [SEP]']
[Init] best rec loss: 0.8130791187286377 for ['[CLS]culus teacher robson colonies now world over enables who obsidianrlerving peacehwa contract [SEP]']
[Init] best rec loss: 0.7910962700843811 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best perm rec loss: 0.7895482182502747 for ['[CLS] wig memoir pondered save august typical smashwords statue sounding projectile spent era livinggn time [SEP]']
[Init] best perm rec loss: 0.7892841100692749 for ['[CLS] living statue sounding eragn pondered smashwords typical projectile time spent save august memoir wig [SEP]']
[Init] best perm rec loss: 0.7874389290809631 for ['[CLS] typical living save sounding wig smashwords august statue time spent projectile era ponderedgn memoir [SEP]']
[Init] best perm rec loss: 0.7851721048355103 for ['[CLS] typical era spent statue smashwords memoir wig sounding august timegn save living pondered projectile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.700 (perp=11.702, rec=0.316, cos=0.044), tot_loss_proj:3.451 [t=0.20s]
prediction: ['[CLS] force into leaders primarily nobody ( hemingway and everyday curriculum mickey passion people force staff [SEP]']
[ 100/2000] tot_loss=2.375 (perp=10.387, rec=0.272, cos=0.026), tot_loss_proj:3.369 [t=0.19s]
prediction: ['[CLS] himself into force ( situations (ian and lesser principle twice romance people force into [SEP]']
[ 150/2000] tot_loss=2.389 (perp=10.784, rec=0.218, cos=0.014), tot_loss_proj:3.466 [t=0.19s]
prediction: ['[CLS] himself into standing here situations (ville and lesser sphere lesser himself people force men [SEP]']
[ 200/2000] tot_loss=2.349 (perp=10.740, rec=0.187, cos=0.013), tot_loss_proj:3.358 [t=0.19s]
prediction: ['[CLS] himself into standing here situations ( on and lesser sphere lesser himself people force men [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.034 (perp=9.226, rec=0.179, cos=0.010), tot_loss_proj:2.866 [t=0.19s]
prediction: ['[CLS] himself on people and situations ( to that lesser situations lesser himself standing force men [SEP]']
[ 300/2000] tot_loss=2.017 (perp=9.243, rec=0.159, cos=0.010), tot_loss_proj:2.958 [t=0.17s]
prediction: ['[CLS] himself on people and situations from to that lessernessy lesser himself for force men [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.096 (perp=9.739, rec=0.139, cos=0.009), tot_loss_proj:3.150 [t=0.19s]
prediction: ['[CLS] himself on people and situations apply brothers would lesser to lesser himself cover force men [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.948 (perp=8.971, rec=0.147, cos=0.007), tot_loss_proj:2.898 [t=0.17s]
prediction: ['[CLS] himself on people and situations apply brothers would force to lesser himself cover lesser men [SEP]']
[ 450/2000] tot_loss=1.812 (perp=8.485, rec=0.110, cos=0.005), tot_loss_proj:3.057 [t=0.17s]
prediction: ['[CLS] himself on people and situations apply to would force to lesser himself cover lesser men [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.872 (perp=8.765, rec=0.115, cos=0.005), tot_loss_proj:3.125 [t=0.17s]
prediction: ['[CLS] apply on himself on people and situations would force far lesser himself cover lesser men [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.785 (perp=8.330, rec=0.114, cos=0.005), tot_loss_proj:2.919 [t=0.17s]
prediction: ['[CLS] apply on himself on people and situations would force himself lesser far cover into men [SEP]']
[ 600/2000] tot_loss=1.759 (perp=8.199, rec=0.115, cos=0.004), tot_loss_proj:2.869 [t=0.17s]
prediction: ['[CLS] circumstances on himself on people and situations would force himself lesser far run into men [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.795 (perp=8.382, rec=0.114, cos=0.005), tot_loss_proj:3.219 [t=0.18s]
prediction: ['[CLS] circumstances on himself on people and situations would force himself lesser men far run cover [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.901 (perp=8.938, rec=0.108, cos=0.005), tot_loss_proj:3.446 [t=0.17s]
prediction: ['[CLS] circumstances on himselfheart people and situations would force himself lesser men far run cover [SEP]']
[ 750/2000] tot_loss=1.747 (perp=8.183, rec=0.106, cos=0.004), tot_loss_proj:3.154 [t=0.17s]
prediction: ['[CLS] circumstances on himself that people and situations would force himself lesser men far run cover [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.765 (perp=8.250, rec=0.110, cos=0.004), tot_loss_proj:3.152 [t=0.17s]
prediction: ['[CLS] circumstances on cover that people and situations would force himself and lesser men run cover [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.659 (perp=7.742, rec=0.106, cos=0.004), tot_loss_proj:2.946 [t=0.17s]
prediction: ['[CLS] circumstances and cover that people and situations would force himself on lesser men run cover [SEP]']
[ 900/2000] tot_loss=1.721 (perp=8.057, rec=0.106, cos=0.004), tot_loss_proj:3.109 [t=0.17s]
prediction: ['[CLS] circumstances for cover that people and situations would force himself on lesser men run cover [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.659 (perp=7.766, rec=0.102, cos=0.004), tot_loss_proj:2.994 [t=0.17s]
prediction: ['[CLS] circumstances for that cover people and situations would force himself on lesser men run cover [SEP]']
Attempt swap
[1000/2000] tot_loss=1.649 (perp=7.766, rec=0.092, cos=0.004), tot_loss_proj:2.992 [t=0.17s]
prediction: ['[CLS] circumstances for that cover people and situations would force himself on lesser men run cover [SEP]']
[1050/2000] tot_loss=1.655 (perp=7.766, rec=0.098, cos=0.004), tot_loss_proj:2.997 [t=0.17s]
prediction: ['[CLS] circumstances for that cover people and situations would force himself on lesser men run cover [SEP]']
Attempt swap
[1100/2000] tot_loss=1.659 (perp=7.766, rec=0.102, cos=0.004), tot_loss_proj:2.999 [t=0.19s]
prediction: ['[CLS] circumstances for that cover people and situations would force himself on lesser men run cover [SEP]']
Attempt swap
[1150/2000] tot_loss=1.655 (perp=7.766, rec=0.098, cos=0.004), tot_loss_proj:2.996 [t=0.19s]
prediction: ['[CLS] circumstances for that cover people and situations would force himself on lesser men run cover [SEP]']
[1200/2000] tot_loss=1.651 (perp=7.766, rec=0.095, cos=0.004), tot_loss_proj:2.996 [t=0.19s]
prediction: ['[CLS] circumstances for that cover people and situations would force himself on lesser men run cover [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.644 (perp=7.745, rec=0.092, cos=0.003), tot_loss_proj:2.958 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run cover [SEP]']
Attempt swap
[1300/2000] tot_loss=1.561 (perp=7.289, rec=0.100, cos=0.004), tot_loss_proj:2.785 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
[1350/2000] tot_loss=1.561 (perp=7.289, rec=0.100, cos=0.003), tot_loss_proj:2.786 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Attempt swap
[1400/2000] tot_loss=1.563 (perp=7.289, rec=0.102, cos=0.003), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Attempt swap
[1450/2000] tot_loss=1.559 (perp=7.289, rec=0.097, cos=0.003), tot_loss_proj:2.785 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
[1500/2000] tot_loss=1.557 (perp=7.289, rec=0.096, cos=0.003), tot_loss_proj:2.789 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Attempt swap
[1550/2000] tot_loss=1.553 (perp=7.289, rec=0.092, cos=0.003), tot_loss_proj:2.785 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Attempt swap
[1600/2000] tot_loss=1.562 (perp=7.289, rec=0.100, cos=0.003), tot_loss_proj:2.788 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
[1650/2000] tot_loss=1.556 (perp=7.289, rec=0.095, cos=0.003), tot_loss_proj:2.784 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Attempt swap
[1700/2000] tot_loss=1.548 (perp=7.289, rec=0.086, cos=0.003), tot_loss_proj:2.783 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Attempt swap
[1750/2000] tot_loss=1.556 (perp=7.289, rec=0.094, cos=0.003), tot_loss_proj:2.780 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
[1800/2000] tot_loss=1.549 (perp=7.289, rec=0.088, cos=0.003), tot_loss_proj:2.787 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Attempt swap
[1850/2000] tot_loss=1.554 (perp=7.289, rec=0.092, cos=0.003), tot_loss_proj:2.789 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Attempt swap
[1900/2000] tot_loss=1.554 (perp=7.289, rec=0.092, cos=0.003), tot_loss_proj:2.789 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
[1950/2000] tot_loss=1.543 (perp=7.289, rec=0.082, cos=0.003), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Attempt swap
[2000/2000] tot_loss=1.548 (perp=7.289, rec=0.087, cos=0.003), tot_loss_proj:2.783 [t=0.17s]
prediction: ['[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] circumstances that cover for people and situations would force himself on lesser men run into [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 31.250 | p: 31.250 | r: 31.250
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 125.368

[Aggregate metrics]:
rouge1     | fm: 92.556 | p: 92.065 | r: 93.182
rouge2     | fm: 59.285 | p: 58.968 | r: 59.722
rougeL     | fm: 80.079 | p: 79.654 | r: 80.556
rougeLsum  | fm: 80.072 | p: 79.710 | r: 80.549
r1fm+r2fm = 151.841

input #96 time: 0:10:59 | total time: 13:16:25


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9991660915875735
highest_index [0]
highest [0.9991660915875735]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.8396337628364563 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.8173046708106995 for ['[CLS] [SEP] crates margarita trip decisionsylus [SEP]']
[Init] best rec loss: 0.8006014823913574 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.7802342772483826 for ['[CLS] jealous glennm his = empire [SEP]']
[Init] best rec loss: 0.7502726316452026 for ['[CLS] perfect channel cam working 140et [SEP]']
[Init] best perm rec loss: 0.7448185682296753 for ['[CLS] working perfectet 140 cam channel [SEP]']
[Init] best perm rec loss: 0.7447396516799927 for ['[CLS] channel cam perfect working 140et [SEP]']
[Init] best perm rec loss: 0.7446287870407104 for ['[CLS] cam channel perfect workinget 140 [SEP]']
[Init] best perm rec loss: 0.7441828846931458 for ['[CLS] cam perfect working 140et channel [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.899 (perp=12.638, rec=0.348, cos=0.023), tot_loss_proj:4.130 [t=0.17s]
prediction: ['[CLS] une impactget series goddess fantastic [SEP]']
[ 100/2000] tot_loss=2.554 (perp=11.600, rec=0.225, cos=0.009), tot_loss_proj:4.119 [t=0.17s]
prediction: ['[CLS]fortableget characterstable category [SEP]']
[ 150/2000] tot_loss=2.599 (perp=12.135, rec=0.163, cos=0.009), tot_loss_proj:4.282 [t=0.19s]
prediction: ['[CLS]fortableget characterstabletable [SEP]']
[ 200/2000] tot_loss=2.568 (perp=12.135, rec=0.135, cos=0.005), tot_loss_proj:4.264 [t=0.17s]
prediction: ['[CLS]fortableget characterstabletable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.122 (perp=9.972, rec=0.126, cos=0.002), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS]forgettable characterstabletable [SEP]']
[ 300/2000] tot_loss=1.958 (perp=9.237, rec=0.108, cos=0.002), tot_loss_proj:2.321 [t=0.17s]
prediction: ['[CLS]forgettable characters andtable [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.198 (perp=5.520, rec=0.092, cos=0.002), tot_loss_proj:1.284 [t=0.17s]
prediction: ['[CLS] unforgettable characters and [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.191 (perp=5.514, rec=0.087, cos=0.002), tot_loss_proj:1.375 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 450/2000] tot_loss=1.177 (perp=5.514, rec=0.073, cos=0.002), tot_loss_proj:1.382 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.175 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.382 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.180 (perp=5.514, rec=0.076, cos=0.002), tot_loss_proj:1.385 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 600/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.373 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.171 (perp=5.514, rec=0.067, cos=0.002), tot_loss_proj:1.382 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.157 (perp=5.514, rec=0.052, cos=0.002), tot_loss_proj:1.374 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 750/2000] tot_loss=1.179 (perp=5.514, rec=0.075, cos=0.002), tot_loss_proj:1.373 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.165 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.368 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.175 (perp=5.514, rec=0.071, cos=0.002), tot_loss_proj:1.371 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[ 900/2000] tot_loss=1.163 (perp=5.514, rec=0.059, cos=0.002), tot_loss_proj:1.388 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.173 (perp=5.514, rec=0.069, cos=0.002), tot_loss_proj:1.375 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.177 (perp=5.514, rec=0.073, cos=0.002), tot_loss_proj:1.376 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1050/2000] tot_loss=1.172 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.378 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.168 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.374 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.158 (perp=5.514, rec=0.054, cos=0.002), tot_loss_proj:1.375 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1200/2000] tot_loss=1.157 (perp=5.514, rec=0.053, cos=0.002), tot_loss_proj:1.365 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.167 (perp=5.514, rec=0.062, cos=0.002), tot_loss_proj:1.375 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.171 (perp=5.514, rec=0.066, cos=0.002), tot_loss_proj:1.375 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1350/2000] tot_loss=1.162 (perp=5.514, rec=0.058, cos=0.002), tot_loss_proj:1.375 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.173 (perp=5.514, rec=0.068, cos=0.002), tot_loss_proj:1.369 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.177 (perp=5.514, rec=0.073, cos=0.002), tot_loss_proj:1.371 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1500/2000] tot_loss=1.170 (perp=5.514, rec=0.065, cos=0.002), tot_loss_proj:1.371 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.167 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.374 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.163 (perp=5.514, rec=0.058, cos=0.002), tot_loss_proj:1.367 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1650/2000] tot_loss=1.174 (perp=5.514, rec=0.070, cos=0.002), tot_loss_proj:1.376 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.167 (perp=5.514, rec=0.063, cos=0.002), tot_loss_proj:1.374 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.165 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.365 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1800/2000] tot_loss=1.169 (perp=5.514, rec=0.064, cos=0.002), tot_loss_proj:1.358 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.157 (perp=5.514, rec=0.053, cos=0.002), tot_loss_proj:1.374 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.167 (perp=5.514, rec=0.062, cos=0.002), tot_loss_proj:1.377 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
[1950/2000] tot_loss=1.166 (perp=5.514, rec=0.061, cos=0.002), tot_loss_proj:1.381 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.162 (perp=5.514, rec=0.058, cos=0.002), tot_loss_proj:1.373 [t=0.17s]
prediction: ['[CLS] unforgettable and characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] unforgettable and characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 92.698 | p: 92.162 | r: 93.336
rouge2     | fm: 58.979 | p: 58.606 | r: 59.416
rougeL     | fm: 80.038 | p: 79.660 | r: 80.471
rougeLsum  | fm: 80.113 | p: 79.732 | r: 80.630
r1fm+r2fm = 151.677

input #97 time: 0:09:19 | total time: 13:25:45


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9991916976323436
highest_index [0]
highest [0.9991916976323436]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.7122125029563904 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.7120754718780518 for ['[CLS] jed nos prohibited ada [SEP]']
[Init] best perm rec loss: 0.709286630153656 for ['[CLS] jed ada nos prohibited [SEP]']
[Init] best perm rec loss: 0.7076743245124817 for ['[CLS] prohibited nos ada jed [SEP]']
[Init] best perm rec loss: 0.7051839828491211 for ['[CLS] nos ada jed prohibited [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.643 (perp=11.864, rec=0.252, cos=0.019), tot_loss_proj:3.154 [t=0.17s]
prediction: ['[CLS] unfulful maintenance [SEP]']
[ 100/2000] tot_loss=2.708 (perp=12.917, rec=0.119, cos=0.006), tot_loss_proj:3.198 [t=0.17s]
prediction: ['[CLS] unfulllingfi [SEP]']
[ 150/2000] tot_loss=2.682 (perp=12.917, rec=0.095, cos=0.004), tot_loss_proj:3.196 [t=0.17s]
prediction: ['[CLS] unfulllingfi [SEP]']
[ 200/2000] tot_loss=2.652 (perp=12.917, rec=0.066, cos=0.002), tot_loss_proj:3.197 [t=0.17s]
prediction: ['[CLS] unfulllingfi [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.055 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.061 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.077 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.044 (perp=4.948, rec=0.052, cos=0.002), tot_loss_proj:1.073 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.059 (perp=4.948, rec=0.068, cos=0.002), tot_loss_proj:1.054 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.056 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.074 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.051 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.061 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.057 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.044 (perp=4.948, rec=0.053, cos=0.002), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.053 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.062 (perp=4.948, rec=0.070, cos=0.002), tot_loss_proj:1.053 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.060 (perp=4.948, rec=0.069, cos=0.002), tot_loss_proj:1.068 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.053 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.060 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.065 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.055 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.054 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.072 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.060 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.063 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.042 (perp=4.948, rec=0.051, cos=0.002), tot_loss_proj:1.059 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.056 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.044 (perp=4.948, rec=0.053, cos=0.002), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.046 (perp=4.948, rec=0.055, cos=0.002), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.041 (perp=4.948, rec=0.050, cos=0.002), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.053 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.052 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.062 (perp=4.948, rec=0.071, cos=0.002), tot_loss_proj:1.057 [t=0.20s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.053 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.061 [t=0.20s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 92.750 | p: 92.265 | r: 93.376
rouge2     | fm: 59.368 | p: 59.007 | r: 59.796
rougeL     | fm: 80.311 | p: 79.911 | r: 80.774
rougeLsum  | fm: 80.259 | p: 79.866 | r: 80.736
r1fm+r2fm = 152.119

input #98 time: 0:09:46 | total time: 13:35:31


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9993095816453154
highest_index [0]
highest [0.9993095816453154]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8722755908966064 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8668547868728638 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.8600996136665344 for ['[CLS] cabinet crash strike championᵍ commencedpheus true place developing muttered result champion chewing likely cared watch toward tank paintome patrick bout personality state defense base ban rescue campaign harvey deputy onlycheagofying [SEP]']
[Init] best rec loss: 0.8582916855812073 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.8477660417556763 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 0.8349575400352478 for ['[CLS] sealed−1 bearing anticipated laps advanced champion priest unit ottoman match party fluidprint cord eric boom twice raf chain [ key bank growing 2009 south reaching words completely sin asked read tehranzziness [CLS] bottles [SEP]']
[Init] best rec loss: 0.8292847275733948 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 0.823960542678833 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.8212921023368835 for ['[CLS] orient te [MASK] barbie still claire taste forced temps services knowledge bet screens himself bearing garcia earliestaging thunderˈ harper right distance dental re actually slight ratingsts currently opposed ferns when cushion synonymte [SEP]']
[Init] best perm rec loss: 0.820878267288208 for ['[CLS]ˈ ferns opposedaging actually orient taste earliest claire slight thunder ratings currently temps bet te distance whente cushion services bearing re barbie knowledgets garcia synonym harper still screens [MASK] dental forced himself right [SEP]']
[Init] best perm rec loss: 0.8208308815956116 for ['[CLS] knowledge ratings re synonym slight currently taste ferns claire actuallyˈ forced garcia bet opposed screens right when orient himself thunder services temps earliest dental cushionts te still harperagingte distance barbie [MASK] bearing [SEP]']
[Init] best perm rec loss: 0.8205059766769409 for ['[CLS] cushionts garcia opposed distance ratings synonym thunder slight bearing ferns when services knowledge taste harper orient clairete forced bet [MASK] temps te currently actually re himself screensˈ rightaging still earliest barbie dental [SEP]']
[Init] best perm rec loss: 0.8195905089378357 for ['[CLS] distance cushion knowledge right services re screens still claire orient dentalaging [MASK] garcia thunder harper synonym taste fernsˈte forced barbie ratings tempsts bet actually when te bearing slight earliest opposed currently himself [SEP]']
[Init] best perm rec loss: 0.818151593208313 for ['[CLS] temps taste re fernsaging forced ratings dentalˈ cushion right claire te garcia slight earliest thunder knowledge actually services himself harper bet screens still orient when [MASK] opposed synonym currently barbiete distance bearingts [SEP]']
[Init] best perm rec loss: 0.8180760741233826 for ['[CLS] ratingsˈ claire thunder betts taste ferns temps garcia still re [MASK] himself slight cushion opposed actuallyte currently screensaging bearing te harper dental right orient services barbie forced distance earliest knowledge when synonym [SEP]']
[Init] best perm rec loss: 0.8174036741256714 for ['[CLS] opposed screens forcedagingts synonym earliest [MASK] garcia claire dental actually barbie orient currently harper thunder ferns slight bearing rete still right temps ratings when cushion te taste distance knowledge himself bet servicesˈ [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.473 (perp=10.556, rec=0.335, cos=0.027), tot_loss_proj:3.020 [t=0.17s]
prediction: ["[CLS] non stupidudes'term or off. horrible baby phraseoid cursed just what bad else,'afford course. littleches renamedssingcr writing film - this [SEP]ditional insurance results adventures [SEP]"]
[ 100/2000] tot_loss=2.205 (perp=9.801, rec=0.234, cos=0.011), tot_loss_proj:3.431 [t=0.20s]
prediction: ["[CLS] non stupid found'they choir stupid'di di phrase `ssing but put bads,'afford enjoymentssing little'interferessing'making film - that'walked film fun fun [SEP]"]
[ 150/2000] tot_loss=2.277 (perp=10.344, rec=0.198, cos=0.010), tot_loss_proj:2.933 [t=0.17s]
prediction: ["[CLS] non stupid walked `ally yelling stupid'di dikled `ssing but got horrible ','bills funssing little'interferessing di have film i that the walked film ticket fun [SEP]"]
[ 200/2000] tot_loss=2.131 (perp=9.842, rec=0.158, cos=0.004), tot_loss_proj:3.000 [t=0.17s]
prediction: ["[CLS] non incredibly walked out out muttering terribly'di diur `ssing but put horrible ','mind dissing'' helpssing di had film that this the walked ticket ticket fun [SEP]"]
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.078 (perp=9.620, rec=0.149, cos=0.005), tot_loss_proj:2.708 [t=0.19s]
prediction: ["[CLS] non so walked out out muttering outstanding'dissing but ` di words ` horrible ','mind dissing them'villainssing di had film that they the walked ticket ticket fun [SEP]"]
[ 300/2000] tot_loss=2.188 (perp=10.225, rec=0.139, cos=0.004), tot_loss_proj:2.812 [t=0.19s]
prediction: ["[CLS] non so walked out out muttering faced ` likessing but'di words ` horrible ','mind dissing them'villainssing di had film that they the walked ticket ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.013 (perp=9.438, rec=0.120, cos=0.006), tot_loss_proj:2.593 [t=0.19s]
prediction: ["[CLS] non they walked out out muttering not ` likessing but'di'` horrible words.'mind dissing'' villainssing di had film that they did walked ticket ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.109 (perp=9.825, rec=0.140, cos=0.004), tot_loss_proj:2.797 [t=0.21s]
prediction: ["[CLS] non so walked out out muttering t''ssing but'di'` horrible terminology'' mind di. middle like enzymessing so had film that they did walked ticket ticket fun [SEP]"]
[ 450/2000] tot_loss=2.134 (perp=10.063, rec=0.118, cos=0.003), tot_loss_proj:2.931 [t=0.17s]
prediction: ["[CLS] non so walked out out muttering t''ssing but'di, ` terrible terminology'' mind diing middle like enzymessing so had film that they did walked the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.025 (perp=9.577, rec=0.106, cos=0.004), tot_loss_proj:2.806 [t=0.17s]
prediction: ["[CLS] non so walked out out muttering t `'ssing but'di,'terrible words `'mind diing middle like enzymessing so had film that they did walked the ticket fun [SEP]"]
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.982 (perp=9.338, rec=0.111, cos=0.003), tot_loss_proj:2.831 [t=0.17s]
prediction: ["[CLS] so walked out out muttering t non `'ssing but'di,'terrible words `'mind diing middle like enzymessing so had film that they did walked the ticket fun [SEP]"]
[ 600/2000] tot_loss=1.971 (perp=9.338, rec=0.101, cos=0.003), tot_loss_proj:2.838 [t=0.17s]
prediction: ["[CLS] so walked out out muttering t non `'ssing but'di,'terrible words `'mind diing middle like enzymessing so had film that they did walked the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.942 (perp=9.201, rec=0.099, cos=0.003), tot_loss_proj:2.835 [t=0.17s]
prediction: ["[CLS] so walked out out muttering t non `'ssing but'di,'terrible words `'mind di like middleing enzymessing so had film that they did walked the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.896 (perp=8.973, rec=0.099, cos=0.003), tot_loss_proj:2.504 [t=0.17s]
prediction: ["[CLS] so walked out out muttering t non `'ssing but'di,'terrible words `'mind di like middle walked enzymessing so had film that they diding the ticket fun [SEP]"]
[ 750/2000] tot_loss=1.893 (perp=8.973, rec=0.096, cos=0.003), tot_loss_proj:2.507 [t=0.19s]
prediction: ["[CLS] so walked out out muttering t non `'ssing but'di,'terrible words `'mind di like middle walked enzymessing so had film that they diding the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.875 (perp=8.903, rec=0.092, cos=0.003), tot_loss_proj:2.463 [t=0.17s]
prediction: ["[CLS] we walked out out muttering t ` non'ssing but'di,'terrible words `'mind di like middle walked enzymessing so had film that they diding the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.774 (perp=8.427, rec=0.086, cos=0.003), tot_loss_proj:2.299 [t=0.17s]
prediction: ["[CLS] we walked out out muttering t ` non'ssing but'di,'terrible words `'di mind like your walked nssing so had film that they diding the ticket fun [SEP]"]
[ 900/2000] tot_loss=1.805 (perp=8.593, rec=0.084, cos=0.002), tot_loss_proj:2.342 [t=0.17s]
prediction: ["[CLS] we walked out out muttering t ` non `ssing but'di,'terrible words `'di mind like your walked nssing so had film that they diding the ticket fun [SEP]"]
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.791 (perp=8.482, rec=0.092, cos=0.002), tot_loss_proj:2.317 [t=0.17s]
prediction: ["[CLS] we walked out out muttering ` t ` nonssing but'di,'terrible words `'di mind like your walked nssing so had film that they diding the ticket fun [SEP]"]
Attempt swap
Moved token
[1000/2000] tot_loss=1.777 (perp=8.392, rec=0.096, cos=0.003), tot_loss_proj:2.339 [t=0.22s]
prediction: ["[CLS] we walked out out muttering ` t ` nonssing but'di,'terrible words ` like'di mind your walked nssing so had film that they diding the ticket fun [SEP]"]
[1050/2000] tot_loss=1.791 (perp=8.513, rec=0.086, cos=0.003), tot_loss_proj:2.353 [t=0.19s]
prediction: ["[CLS] we walked out out muttering ` t ` nonssing but'di,'terrible words ` like'di mind your walked hierarchyssing so had film that they diding the ticket fun [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.828 (perp=8.695, rec=0.087, cos=0.002), tot_loss_proj:2.457 [t=0.19s]
prediction: ["[CLS] we walked out the muttering ` t ` nonssing but'di,'terrible words ` like'di mind middle walked hierarchyssing so had film that they diding out ticket fun [SEP]"]
Attempt swap
Moved token
[1150/2000] tot_loss=1.785 (perp=8.466, rec=0.090, cos=0.003), tot_loss_proj:2.392 [t=0.17s]
prediction: ["[CLS] we walked out the muttering ` t ` nonssing but'di middle,'terrible words ` like'di mind walked hierarchyssing so had film that they diding out ticket fun [SEP]"]
[1200/2000] tot_loss=1.778 (perp=8.466, rec=0.083, cos=0.002), tot_loss_proj:2.394 [t=0.17s]
prediction: ["[CLS] we walked out the muttering ` t ` nonssing but'di middle,'terrible words ` like'di mind walked hierarchyssing so had film that they diding out ticket fun [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.780 (perp=8.457, rec=0.086, cos=0.002), tot_loss_proj:2.423 [t=0.17s]
prediction: ["[CLS] we walked out the muttering ` ` t nonssing but'di middle,'terrible words ` like'di mind walked hierarchyssing so had film that they diding out ticket fun [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.770 (perp=8.448, rec=0.078, cos=0.002), tot_loss_proj:2.348 [t=0.17s]
prediction: ["[CLS] we walked out the muttering ` ` t nonssing but'di middle,'terrible words ` like'di hierarchy walked mindssing so had film that they diding out ticket fun [SEP]"]
[1350/2000] tot_loss=1.777 (perp=8.448, rec=0.085, cos=0.002), tot_loss_proj:2.350 [t=0.17s]
prediction: ["[CLS] we walked out the muttering ` ` t nonssing but'di middle,'terrible words ` like'di hierarchy walked mindssing so had film that they diding out ticket fun [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.765 (perp=8.390, rec=0.085, cos=0.002), tot_loss_proj:2.392 [t=0.17s]
prediction: ["[CLS] we walked out the muttering ` `'t nonssing but'di your, terrible words ` like'di hierarchy walked mindssing so had film that they diding out ticket fun [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.714 (perp=8.056, rec=0.100, cos=0.003), tot_loss_proj:2.275 [t=0.17s]
prediction: ["[CLS] we walked out the muttering ` `'t nonssing but'di, terrible words ` like'di hierarchy walked mindssing so had your film that they diding out ticket fun [SEP]"]
[1500/2000] tot_loss=1.708 (perp=8.056, rec=0.094, cos=0.003), tot_loss_proj:2.277 [t=0.17s]
prediction: ["[CLS] we walked out the muttering ` `'t nonssing but'di, terrible words ` like'di hierarchy walked mindssing so had your film that they diding out ticket fun [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.669 (perp=7.856, rec=0.095, cos=0.002), tot_loss_proj:2.256 [t=0.17s]
prediction: ["[CLS] we walked out the muttering ` `'t nonssing but'di `, terrible words like'di hierarchy walked mindssing so had your film that they diding out ticket fun [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.695 (perp=8.007, rec=0.091, cos=0.003), tot_loss_proj:2.254 [t=0.17s]
prediction: ["[CLS] n walked out the muttering ` `'t nonssing but'di `, terrible words like'mind hierarchy walked dissing so had my film that they diding out ticket fun [SEP]"]
[1650/2000] tot_loss=1.688 (perp=8.007, rec=0.085, cos=0.002), tot_loss_proj:2.252 [t=0.17s]
prediction: ["[CLS] n walked out the muttering ` `'t nonssing but'di `, terrible words like'mind hierarchy walked dissing so had my film that they diding out ticket fun [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.665 (perp=7.869, rec=0.089, cos=0.002), tot_loss_proj:2.222 [t=0.19s]
prediction: ["[CLS] di walked out the muttering ` `'t nonssing but'n `, terrible words like'mind hierarchy walked dissing so had my film that they diding out ticket fun [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.637 (perp=7.698, rec=0.095, cos=0.002), tot_loss_proj:2.246 [t=0.19s]
prediction: ["[CLS] di walked out the muttering ` `'t nonssing but'n `, terrible words like'mind hierarchy walked dissing so had my film ticket that they diding out fun [SEP]"]
[1800/2000] tot_loss=1.634 (perp=7.698, rec=0.092, cos=0.002), tot_loss_proj:2.248 [t=0.19s]
prediction: ["[CLS] di walked out the muttering ` `'t nonssing but'n `, terrible words like'mind hierarchy walked dissing so had my film ticket that they diding out fun [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.635 (perp=7.698, rec=0.093, cos=0.002), tot_loss_proj:2.248 [t=0.17s]
prediction: ["[CLS] di walked out the muttering ` `'t nonssing but'n `, terrible words like'mind hierarchy walked dissing so had my film ticket that they diding out fun [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.629 (perp=7.698, rec=0.087, cos=0.002), tot_loss_proj:2.244 [t=0.17s]
prediction: ["[CLS] di walked out the muttering ` `'t nonssing but'n `, terrible words like'mind hierarchy walked dissing so had my film ticket that they diding out fun [SEP]"]
[1950/2000] tot_loss=1.630 (perp=7.698, rec=0.088, cos=0.002), tot_loss_proj:2.247 [t=0.17s]
prediction: ["[CLS] di walked out the muttering ` `'t nonssing but'n `, terrible words like'mind hierarchy walked dissing so had my film ticket that they diding out fun [SEP]"]
Attempt swap
Moved token
[2000/2000] tot_loss=1.605 (perp=7.552, rec=0.092, cos=0.002), tot_loss_proj:2.217 [t=0.17s]
prediction: ["[CLS] di walked out the muttering ` `'t nonssing but'n `, walked terrible words like'mind hierarchy dissing so had my film ticket that they diding out fun [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] we walked out out muttering ` t ` nonssing but'di,'terrible words ` like'di mind your walked hierarchyssing so had film that they diding the ticket fun [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.370 | p: 67.857 | r: 73.077
rouge2     | fm: 23.077 | p: 22.222 | r: 24.000
rougeL     | fm: 48.148 | p: 46.429 | r: 50.000
rougeLsum  | fm: 48.148 | p: 46.429 | r: 50.000
r1fm+r2fm = 93.447

[Aggregate metrics]:
rouge1     | fm: 92.569 | p: 92.036 | r: 93.216
rouge2     | fm: 58.951 | p: 58.621 | r: 59.362
rougeL     | fm: 79.975 | p: 79.558 | r: 80.460
rougeLsum  | fm: 79.991 | p: 79.580 | r: 80.444
r1fm+r2fm = 151.520

input #99 time: 0:11:12 | total time: 13:46:44


Average Cosine Similarity: 0.9992812683158312
Done with all.
