


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.01 --coeff_pooler_match_margin 0.0 --pooler_match_for_init no --pooler_match_for_optimization yes --pooler_match_for_swap no 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 48.64it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9986283114393419
highest_index [0]
highest [0.9986283114393419]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 0.9625368118286133 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 0.8679832816123962 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 0.855973482131958 for ['[CLS]ify board [SEP]']
[Init] best rec loss: 0.8426324129104614 for ['[CLS] tolerance receiving [SEP]']
[Init] best rec loss: 0.8288277387619019 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.149 (perp=10.251, rec=0.095, cos=0.004), tot_loss_proj:2.122 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 100/2000] tot_loss=2.114 (perp=10.251, rec=0.061, cos=0.003), tot_loss_proj:2.110 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.113 (perp=10.251, rec=0.060, cos=0.003), tot_loss_proj:2.127 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.119 (perp=10.251, rec=0.066, cos=0.003), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.109 (perp=10.251, rec=0.056, cos=0.003), tot_loss_proj:2.110 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.117 (perp=10.251, rec=0.064, cos=0.003), tot_loss_proj:2.119 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.119 (perp=10.251, rec=0.066, cos=0.003), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.117 (perp=10.251, rec=0.064, cos=0.003), tot_loss_proj:2.118 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.003), tot_loss_proj:2.121 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.120 (perp=10.251, rec=0.067, cos=0.003), tot_loss_proj:2.136 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.111 (perp=10.251, rec=0.058, cos=0.003), tot_loss_proj:2.129 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.105 (perp=10.251, rec=0.052, cos=0.003), tot_loss_proj:2.121 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.114 (perp=10.251, rec=0.061, cos=0.003), tot_loss_proj:2.129 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.121 (perp=10.251, rec=0.068, cos=0.003), tot_loss_proj:2.120 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.112 (perp=10.251, rec=0.059, cos=0.003), tot_loss_proj:2.114 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.113 (perp=10.251, rec=0.060, cos=0.003), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.003), tot_loss_proj:2.129 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.100 (perp=10.251, rec=0.047, cos=0.003), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.107 (perp=10.251, rec=0.054, cos=0.003), tot_loss_proj:2.128 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.109 (perp=10.251, rec=0.056, cos=0.003), tot_loss_proj:2.125 [t=0.20s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.102 (perp=10.251, rec=0.049, cos=0.003), tot_loss_proj:2.127 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.114 (perp=10.251, rec=0.061, cos=0.003), tot_loss_proj:2.120 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.106 (perp=10.251, rec=0.053, cos=0.003), tot_loss_proj:2.121 [t=0.29s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.117 (perp=10.251, rec=0.064, cos=0.003), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.109 (perp=10.251, rec=0.056, cos=0.003), tot_loss_proj:2.122 [t=0.17s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.112 (perp=10.251, rec=0.059, cos=0.003), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.112 (perp=10.251, rec=0.059, cos=0.003), tot_loss_proj:2.123 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.121 (perp=10.251, rec=0.068, cos=0.003), tot_loss_proj:2.115 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.121 (perp=10.251, rec=0.068, cos=0.003), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.106 (perp=10.251, rec=0.053, cos=0.003), tot_loss_proj:2.104 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.101 (perp=10.251, rec=0.048, cos=0.003), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.114 (perp=10.251, rec=0.061, cos=0.003), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.110 (perp=10.251, rec=0.057, cos=0.003), tot_loss_proj:2.128 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.104 (perp=10.251, rec=0.051, cos=0.003), tot_loss_proj:2.111 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.122 (perp=10.251, rec=0.069, cos=0.003), tot_loss_proj:2.125 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.120 (perp=10.251, rec=0.067, cos=0.003), tot_loss_proj:2.121 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.114 (perp=10.251, rec=0.061, cos=0.003), tot_loss_proj:2.120 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.119 (perp=10.251, rec=0.066, cos=0.003), tot_loss_proj:2.114 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.111 (perp=10.251, rec=0.058, cos=0.003), tot_loss_proj:2.115 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.116 (perp=10.251, rec=0.063, cos=0.003), tot_loss_proj:2.118 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:08:04 | total time: 0:08:04


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.998903138098826
highest_index [0]
highest [0.998903138098826]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 0.9862967729568481 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 0.9697775840759277 for ['[CLS] scheme sera [SEP]']
[Init] best rec loss: 0.9063156843185425 for ['[CLS] football package [SEP]']
[Init] best rec loss: 0.8695228099822998 for ['[CLS] martialmoral [SEP]']
[Init] best rec loss: 0.8666290044784546 for ['[CLS] course characters [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.276 (perp=10.543, rec=0.164, cos=0.003), tot_loss_proj:2.397 [t=0.24s]
prediction: ['[CLS] splendid splendid [SEP]']
[ 100/2000] tot_loss=2.163 (perp=10.288, rec=0.103, cos=0.002), tot_loss_proj:2.296 [t=0.17s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.130 (perp=10.288, rec=0.070, cos=0.002), tot_loss_proj:2.296 [t=0.28s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.130 (perp=10.288, rec=0.070, cos=0.002), tot_loss_proj:2.305 [t=0.25s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.908 (perp=9.171, rec=0.072, cos=0.002), tot_loss_proj:1.896 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.888 (perp=9.171, rec=0.051, cos=0.002), tot_loss_proj:1.908 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.901 (perp=9.171, rec=0.064, cos=0.002), tot_loss_proj:1.901 [t=0.21s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.002), tot_loss_proj:1.900 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.891 (perp=9.171, rec=0.054, cos=0.002), tot_loss_proj:1.893 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.902 (perp=9.171, rec=0.065, cos=0.002), tot_loss_proj:1.895 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.002), tot_loss_proj:1.898 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.896 (perp=9.171, rec=0.060, cos=0.002), tot_loss_proj:1.902 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.002), tot_loss_proj:1.898 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.894 (perp=9.171, rec=0.057, cos=0.002), tot_loss_proj:1.900 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.002), tot_loss_proj:1.898 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.894 (perp=9.171, rec=0.057, cos=0.002), tot_loss_proj:1.899 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.002), tot_loss_proj:1.905 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.902 (perp=9.171, rec=0.066, cos=0.002), tot_loss_proj:1.892 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.898 (perp=9.171, rec=0.062, cos=0.002), tot_loss_proj:1.913 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.904 (perp=9.171, rec=0.068, cos=0.002), tot_loss_proj:1.894 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.904 (perp=9.171, rec=0.068, cos=0.002), tot_loss_proj:1.906 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.894 (perp=9.171, rec=0.057, cos=0.002), tot_loss_proj:1.898 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.902 (perp=9.171, rec=0.066, cos=0.002), tot_loss_proj:1.903 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.905 (perp=9.171, rec=0.069, cos=0.002), tot_loss_proj:1.905 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.894 (perp=9.171, rec=0.057, cos=0.002), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.893 (perp=9.171, rec=0.056, cos=0.002), tot_loss_proj:1.900 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.002), tot_loss_proj:1.905 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.899 (perp=9.171, rec=0.062, cos=0.002), tot_loss_proj:1.899 [t=0.21s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.002), tot_loss_proj:1.904 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.892 (perp=9.171, rec=0.055, cos=0.002), tot_loss_proj:1.890 [t=0.21s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.895 (perp=9.171, rec=0.058, cos=0.002), tot_loss_proj:1.887 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.891 (perp=9.171, rec=0.054, cos=0.002), tot_loss_proj:1.899 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.896 (perp=9.171, rec=0.060, cos=0.002), tot_loss_proj:1.897 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.915 (perp=9.171, rec=0.078, cos=0.002), tot_loss_proj:1.896 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.002), tot_loss_proj:1.888 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.892 (perp=9.171, rec=0.055, cos=0.002), tot_loss_proj:1.910 [t=0.23s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.002), tot_loss_proj:1.909 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.905 (perp=9.171, rec=0.069, cos=0.002), tot_loss_proj:1.902 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.896 (perp=9.171, rec=0.060, cos=0.002), tot_loss_proj:1.892 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.002), tot_loss_proj:1.891 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:08:27 | total time: 0:16:31


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9986829534302224
highest_index [0]
highest [0.9986829534302224]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 0.7639372944831848 for ['[CLS] wash〜 at [SEP]']
[Init] best perm rec loss: 0.7628830075263977 for ['[CLS]〜 at wash [SEP]']
[Init] best perm rec loss: 0.7605738043785095 for ['[CLS] at〜 wash [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.011 (perp=11.891, rec=0.477, cos=0.156), tot_loss_proj:3.145 [t=0.18s]
prediction: ['[CLS] incline winning momentum [SEP]']
[ 100/2000] tot_loss=2.513 (perp=10.390, rec=0.310, cos=0.125), tot_loss_proj:2.867 [t=0.25s]
prediction: ['[CLS] bounce gaining momentum [SEP]']
[ 150/2000] tot_loss=2.165 (perp=8.750, rec=0.314, cos=0.101), tot_loss_proj:2.159 [t=0.24s]
prediction: ['[CLS] momentum gaining momentum [SEP]']
[ 200/2000] tot_loss=2.115 (perp=8.750, rec=0.245, cos=0.120), tot_loss_proj:2.169 [t=0.18s]
prediction: ['[CLS] momentum gaining momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.505 (perp=10.705, rec=0.219, cos=0.145), tot_loss_proj:2.918 [t=0.18s]
prediction: ['[CLS] ins gaining momentum [SEP]']
[ 300/2000] tot_loss=2.117 (perp=8.522, rec=0.221, cos=0.191), tot_loss_proj:2.193 [t=0.18s]
prediction: ['[CLS] sensation gaining momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.362 (perp=9.856, rec=0.206, cos=0.184), tot_loss_proj:2.941 [t=0.21s]
prediction: ['[CLS] bone gaining momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.374 (perp=9.918, rec=0.192, cos=0.199), tot_loss_proj:2.654 [t=0.18s]
prediction: ['[CLS] getting gaining momentum [SEP]']
[ 450/2000] tot_loss=2.368 (perp=9.856, rec=0.195, cos=0.202), tot_loss_proj:2.947 [t=0.18s]
prediction: ['[CLS] bone gaining momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.415 (perp=10.115, rec=0.187, cos=0.205), tot_loss_proj:2.779 [t=0.18s]
prediction: ['[CLS] gets gaining momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.413 (perp=10.115, rec=0.191, cos=0.198), tot_loss_proj:2.780 [t=0.23s]
prediction: ['[CLS] gets gaining momentum [SEP]']
[ 600/2000] tot_loss=2.442 (perp=10.342, rec=0.194, cos=0.180), tot_loss_proj:3.147 [t=0.24s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.456 (perp=10.342, rec=0.185, cos=0.202), tot_loss_proj:3.145 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.447 (perp=10.342, rec=0.194, cos=0.184), tot_loss_proj:3.140 [t=0.21s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
[ 750/2000] tot_loss=2.443 (perp=10.342, rec=0.189, cos=0.186), tot_loss_proj:3.148 [t=0.27s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.434 (perp=10.342, rec=0.189, cos=0.176), tot_loss_proj:3.143 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.436 (perp=10.342, rec=0.187, cos=0.180), tot_loss_proj:3.145 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
[ 900/2000] tot_loss=2.431 (perp=10.342, rec=0.187, cos=0.175), tot_loss_proj:3.144 [t=0.17s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.449 (perp=10.342, rec=0.198, cos=0.183), tot_loss_proj:3.151 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=2.436 (perp=10.342, rec=0.189, cos=0.178), tot_loss_proj:3.146 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
[1050/2000] tot_loss=2.443 (perp=10.342, rec=0.193, cos=0.182), tot_loss_proj:3.141 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=2.439 (perp=10.342, rec=0.184, cos=0.186), tot_loss_proj:3.145 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=2.438 (perp=10.342, rec=0.185, cos=0.185), tot_loss_proj:3.145 [t=0.23s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
[1200/2000] tot_loss=2.441 (perp=10.342, rec=0.189, cos=0.183), tot_loss_proj:3.143 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=2.436 (perp=10.342, rec=0.186, cos=0.181), tot_loss_proj:3.144 [t=0.23s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=2.441 (perp=10.342, rec=0.191, cos=0.182), tot_loss_proj:3.148 [t=0.20s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
[1350/2000] tot_loss=2.439 (perp=10.342, rec=0.189, cos=0.182), tot_loss_proj:3.141 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=2.427 (perp=10.342, rec=0.174, cos=0.185), tot_loss_proj:3.153 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=2.430 (perp=10.342, rec=0.177, cos=0.184), tot_loss_proj:3.137 [t=0.24s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
[1500/2000] tot_loss=2.444 (perp=10.342, rec=0.195, cos=0.180), tot_loss_proj:3.148 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=2.444 (perp=10.342, rec=0.193, cos=0.182), tot_loss_proj:3.134 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=2.441 (perp=10.342, rec=0.192, cos=0.180), tot_loss_proj:3.147 [t=0.20s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
[1650/2000] tot_loss=2.444 (perp=10.342, rec=0.192, cos=0.183), tot_loss_proj:3.134 [t=0.30s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=2.435 (perp=10.342, rec=0.186, cos=0.181), tot_loss_proj:3.142 [t=0.19s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=2.437 (perp=10.342, rec=0.185, cos=0.183), tot_loss_proj:3.146 [t=0.23s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
[1800/2000] tot_loss=2.439 (perp=10.342, rec=0.189, cos=0.182), tot_loss_proj:3.131 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=2.429 (perp=10.342, rec=0.178, cos=0.183), tot_loss_proj:3.132 [t=0.22s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=2.427 (perp=10.342, rec=0.178, cos=0.181), tot_loss_proj:3.141 [t=0.23s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
[1950/2000] tot_loss=2.442 (perp=10.342, rec=0.192, cos=0.182), tot_loss_proj:3.143 [t=0.18s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=2.432 (perp=10.342, rec=0.183, cos=0.181), tot_loss_proj:3.143 [t=0.19s]
prediction: ['[CLS] subtle gaining momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] subtle gaining momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 105.000

[Aggregate metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 93.333 | p: 93.333 | r: 93.333
rougeLsum  | fm: 93.333 | p: 93.333 | r: 93.333
r1fm+r2fm = 168.333

input #2 time: 0:08:05 | total time: 0:24:36


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9987692391351461
highest_index [0]
highest [0.9987692391351461]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 0.9880272746086121 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 0.9356280565261841 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 0.9205706715583801 for ['[CLS] caused please [SEP]']
[Init] best rec loss: 0.8775091171264648 for ['[CLS] rarerled [SEP]']
[Init] best rec loss: 0.8466953039169312 for ['[CLS] end depart [SEP]']
[Init] best rec loss: 0.8466756939888 for ['[CLS] hidden doesn [SEP]']
[Init] best rec loss: 0.8349443078041077 for ['[CLS] early force [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.535 (perp=11.528, rec=0.619, cos=0.610), tot_loss_proj:4.250 [t=0.20s]
prediction: ['[CLS]clusive round [SEP]']
[ 100/2000] tot_loss=1.845 (perp=8.385, rec=0.162, cos=0.006), tot_loss_proj:1.797 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/2000] tot_loss=1.755 (perp=8.385, rec=0.075, cos=0.003), tot_loss_proj:1.775 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[ 200/2000] tot_loss=1.751 (perp=8.385, rec=0.072, cos=0.002), tot_loss_proj:1.773 [t=0.28s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.732 (perp=8.385, rec=0.052, cos=0.002), tot_loss_proj:1.790 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.741 (perp=8.385, rec=0.062, cos=0.002), tot_loss_proj:1.771 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.002), tot_loss_proj:1.778 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.718 (perp=8.385, rec=0.039, cos=0.002), tot_loss_proj:1.773 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.741 (perp=8.385, rec=0.062, cos=0.002), tot_loss_proj:1.766 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.738 (perp=8.385, rec=0.058, cos=0.002), tot_loss_proj:1.774 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.734 (perp=8.385, rec=0.055, cos=0.002), tot_loss_proj:1.778 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.736 (perp=8.385, rec=0.056, cos=0.002), tot_loss_proj:1.756 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.747 (perp=8.385, rec=0.067, cos=0.002), tot_loss_proj:1.761 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.725 (perp=8.385, rec=0.046, cos=0.002), tot_loss_proj:1.768 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.731 (perp=8.385, rec=0.052, cos=0.002), tot_loss_proj:1.767 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.754 (perp=8.385, rec=0.075, cos=0.002), tot_loss_proj:1.766 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.744 (perp=8.385, rec=0.064, cos=0.002), tot_loss_proj:1.762 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.740 (perp=8.385, rec=0.061, cos=0.002), tot_loss_proj:1.782 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.725 (perp=8.385, rec=0.046, cos=0.002), tot_loss_proj:1.773 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.735 (perp=8.385, rec=0.055, cos=0.002), tot_loss_proj:1.769 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.736 (perp=8.385, rec=0.057, cos=0.002), tot_loss_proj:1.783 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.739 (perp=8.385, rec=0.060, cos=0.002), tot_loss_proj:1.773 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.729 (perp=8.385, rec=0.050, cos=0.002), tot_loss_proj:1.781 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.747 (perp=8.385, rec=0.068, cos=0.002), tot_loss_proj:1.757 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.748 (perp=8.385, rec=0.068, cos=0.002), tot_loss_proj:1.782 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.729 (perp=8.385, rec=0.050, cos=0.002), tot_loss_proj:1.777 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.733 (perp=8.385, rec=0.054, cos=0.002), tot_loss_proj:1.759 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.742 (perp=8.385, rec=0.062, cos=0.002), tot_loss_proj:1.763 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.744 (perp=8.385, rec=0.065, cos=0.002), tot_loss_proj:1.773 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.732 (perp=8.385, rec=0.053, cos=0.002), tot_loss_proj:1.783 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.742 (perp=8.385, rec=0.063, cos=0.002), tot_loss_proj:1.761 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.750 (perp=8.385, rec=0.070, cos=0.002), tot_loss_proj:1.782 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.742 (perp=8.385, rec=0.063, cos=0.002), tot_loss_proj:1.769 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.002), tot_loss_proj:1.762 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.727 (perp=8.385, rec=0.047, cos=0.002), tot_loss_proj:1.767 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.735 (perp=8.385, rec=0.056, cos=0.002), tot_loss_proj:1.776 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.751 (perp=8.385, rec=0.071, cos=0.002), tot_loss_proj:1.766 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.742 (perp=8.385, rec=0.063, cos=0.002), tot_loss_proj:1.769 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.738 (perp=8.385, rec=0.058, cos=0.002), tot_loss_proj:1.762 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.740 (perp=8.385, rec=0.061, cos=0.002), tot_loss_proj:1.772 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 95.000 | p: 95.000 | r: 95.000
rouge2     | fm: 81.250 | p: 81.250 | r: 81.250
rougeL     | fm: 95.000 | p: 95.000 | r: 95.000
rougeLsum  | fm: 95.000 | p: 95.000 | r: 95.000
r1fm+r2fm = 176.250

input #3 time: 0:08:20 | total time: 0:32:56


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.9986257111912629
highest_index [0]
highest [0.9986257111912629]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 0.97457355260849 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 0.9598498344421387 for ['[CLS]chel gulf chloe [SEP]']
[Init] best rec loss: 0.9540842771530151 for ['[CLS] together tracks print [SEP]']
[Init] best rec loss: 0.9450376629829407 for ['[CLS] activities sw eight [SEP]']
[Init] best rec loss: 0.9423826336860657 for ['[CLS]urized bait bae [SEP]']
[Init] best rec loss: 0.9423542022705078 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 0.9144652485847473 for ['[CLS] concern love black [SEP]']
[Init] best rec loss: 0.8900902271270752 for ['[CLS] fatedss jack [SEP]']
[Init] best perm rec loss: 0.8888614177703857 for ['[CLS]ss fated jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.643 (perp=7.516, rec=0.134, cos=0.006), tot_loss_proj:1.653 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[ 100/2000] tot_loss=1.582 (perp=7.516, rec=0.074, cos=0.005), tot_loss_proj:1.651 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.584 (perp=7.516, rec=0.077, cos=0.004), tot_loss_proj:1.672 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.570 (perp=7.516, rec=0.064, cos=0.003), tot_loss_proj:1.667 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.573 (perp=7.516, rec=0.068, cos=0.003), tot_loss_proj:1.665 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.566 (perp=7.516, rec=0.060, cos=0.003), tot_loss_proj:1.667 [t=0.31s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.557 (perp=7.516, rec=0.051, cos=0.003), tot_loss_proj:1.646 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.556 (perp=7.516, rec=0.050, cos=0.003), tot_loss_proj:1.651 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.569 (perp=7.516, rec=0.063, cos=0.003), tot_loss_proj:1.663 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.558 (perp=7.516, rec=0.052, cos=0.003), tot_loss_proj:1.669 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.581 (perp=7.516, rec=0.075, cos=0.003), tot_loss_proj:1.659 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.554 (perp=7.516, rec=0.048, cos=0.003), tot_loss_proj:1.660 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.567 (perp=7.516, rec=0.061, cos=0.003), tot_loss_proj:1.661 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.569 (perp=7.516, rec=0.063, cos=0.003), tot_loss_proj:1.663 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.575 (perp=7.516, rec=0.069, cos=0.003), tot_loss_proj:1.653 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.565 (perp=7.516, rec=0.059, cos=0.003), tot_loss_proj:1.657 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.570 (perp=7.516, rec=0.064, cos=0.003), tot_loss_proj:1.658 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.559 (perp=7.516, rec=0.053, cos=0.003), tot_loss_proj:1.629 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.564 (perp=7.516, rec=0.058, cos=0.003), tot_loss_proj:1.625 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.559 (perp=7.516, rec=0.053, cos=0.003), tot_loss_proj:1.617 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.552 (perp=7.516, rec=0.047, cos=0.003), tot_loss_proj:1.617 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.566 (perp=7.516, rec=0.060, cos=0.003), tot_loss_proj:1.615 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.570 (perp=7.516, rec=0.064, cos=0.003), tot_loss_proj:1.624 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.568 (perp=7.516, rec=0.062, cos=0.003), tot_loss_proj:1.609 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.578 (perp=7.516, rec=0.072, cos=0.003), tot_loss_proj:1.618 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.564 (perp=7.516, rec=0.058, cos=0.003), tot_loss_proj:1.616 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.562 (perp=7.516, rec=0.056, cos=0.003), tot_loss_proj:1.621 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.562 (perp=7.516, rec=0.056, cos=0.003), tot_loss_proj:1.615 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.564 (perp=7.516, rec=0.058, cos=0.003), tot_loss_proj:1.608 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.566 (perp=7.516, rec=0.060, cos=0.003), tot_loss_proj:1.627 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.562 (perp=7.516, rec=0.056, cos=0.003), tot_loss_proj:1.607 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.573 (perp=7.516, rec=0.067, cos=0.003), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.567 (perp=7.516, rec=0.061, cos=0.003), tot_loss_proj:1.614 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.573 (perp=7.516, rec=0.067, cos=0.003), tot_loss_proj:1.615 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.003), tot_loss_proj:1.615 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.003), tot_loss_proj:1.620 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.572 (perp=7.516, rec=0.066, cos=0.003), tot_loss_proj:1.606 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.574 (perp=7.516, rec=0.068, cos=0.003), tot_loss_proj:1.617 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.560 (perp=7.516, rec=0.054, cos=0.003), tot_loss_proj:1.630 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.572 (perp=7.516, rec=0.066, cos=0.003), tot_loss_proj:1.617 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 96.000 | p: 96.000 | r: 96.000
rouge2     | fm: 85.000 | p: 85.000 | r: 85.000
rougeL     | fm: 96.000 | p: 96.000 | r: 96.000
rougeLsum  | fm: 96.000 | p: 96.000 | r: 96.000
r1fm+r2fm = 181.000

input #4 time: 0:08:23 | total time: 0:41:20


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9988021591605685
highest_index [0]
highest [0.9988021591605685]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 0.9576162695884705 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 0.9557139873504639 for ['[CLS] short renaissance [SEP]']
[Init] best rec loss: 0.949370801448822 for ['[CLS] preservation notre [SEP]']
[Init] best rec loss: 0.9488649368286133 for ['[CLS] institution wanting [SEP]']
[Init] best rec loss: 0.9270480871200562 for ['[CLS] eye central [SEP]']
[Init] best rec loss: 0.919043242931366 for ['[CLS] quiet. [SEP]']
[Init] best perm rec loss: 0.9174767136573792 for ['[CLS]. quiet [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.682 (perp=12.125, rec=0.686, cos=0.571), tot_loss_proj:4.142 [t=0.18s]
prediction: ['[CLS] hurt perhaps [SEP]']
[ 100/2000] tot_loss=3.068 (perp=9.230, rec=0.634, cos=0.588), tot_loss_proj:3.599 [t=0.24s]
prediction: ['[CLS] ease jurisdiction [SEP]']
[ 150/2000] tot_loss=3.752 (perp=12.554, rec=0.636, cos=0.606), tot_loss_proj:4.304 [t=0.27s]
prediction: ['[CLS] doubt bribes [SEP]']
[ 200/2000] tot_loss=3.429 (perp=11.298, rec=0.559, cos=0.610), tot_loss_proj:4.213 [t=0.23s]
prediction: ['[CLS] ease bribes [SEP]']
Attempt swap
[ 250/2000] tot_loss=3.816 (perp=13.175, rec=0.590, cos=0.591), tot_loss_proj:4.605 [t=0.24s]
prediction: ['[CLS] easeislaus [SEP]']
[ 300/2000] tot_loss=3.656 (perp=12.524, rec=0.525, cos=0.626), tot_loss_proj:3.039 [t=0.18s]
prediction: ['[CLS] ease excelled [SEP]']
Attempt swap
[ 350/2000] tot_loss=3.649 (perp=12.524, rec=0.521, cos=0.623), tot_loss_proj:3.043 [t=0.18s]
prediction: ['[CLS] ease excelled [SEP]']
Attempt swap
[ 400/2000] tot_loss=3.421 (perp=11.370, rec=0.523, cos=0.624), tot_loss_proj:3.679 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
[ 450/2000] tot_loss=3.688 (perp=12.098, rec=0.612, cos=0.656), tot_loss_proj:3.704 [t=0.19s]
prediction: ['[CLS] ease carpathian [SEP]']
Attempt swap
[ 500/2000] tot_loss=3.603 (perp=12.098, rec=0.530, cos=0.654), tot_loss_proj:3.723 [t=0.24s]
prediction: ['[CLS] ease carpathian [SEP]']
Attempt swap
[ 550/2000] tot_loss=3.258 (perp=10.429, rec=0.521, cos=0.652), tot_loss_proj:2.985 [t=0.18s]
prediction: ['[CLS] ease » [SEP]']
[ 600/2000] tot_loss=3.241 (perp=10.429, rec=0.497, cos=0.658), tot_loss_proj:2.992 [t=0.26s]
prediction: ['[CLS] ease » [SEP]']
Attempt swap
[ 650/2000] tot_loss=3.421 (perp=11.370, rec=0.501, cos=0.646), tot_loss_proj:3.685 [t=0.26s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 700/2000] tot_loss=3.385 (perp=11.370, rec=0.487, cos=0.624), tot_loss_proj:3.678 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
[ 750/2000] tot_loss=3.415 (perp=11.370, rec=0.510, cos=0.631), tot_loss_proj:3.676 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 800/2000] tot_loss=3.436 (perp=11.370, rec=0.500, cos=0.662), tot_loss_proj:3.682 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 850/2000] tot_loss=3.398 (perp=11.370, rec=0.492, cos=0.632), tot_loss_proj:3.684 [t=0.19s]
prediction: ['[CLS] ease ease [SEP]']
[ 900/2000] tot_loss=3.414 (perp=11.370, rec=0.484, cos=0.656), tot_loss_proj:3.682 [t=0.21s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[ 950/2000] tot_loss=3.406 (perp=11.370, rec=0.485, cos=0.648), tot_loss_proj:3.683 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1000/2000] tot_loss=3.390 (perp=11.370, rec=0.467, cos=0.649), tot_loss_proj:3.681 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
[1050/2000] tot_loss=3.405 (perp=11.370, rec=0.485, cos=0.646), tot_loss_proj:3.680 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1100/2000] tot_loss=3.422 (perp=11.370, rec=0.486, cos=0.663), tot_loss_proj:3.677 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1150/2000] tot_loss=3.387 (perp=11.370, rec=0.472, cos=0.640), tot_loss_proj:3.680 [t=0.21s]
prediction: ['[CLS] ease ease [SEP]']
[1200/2000] tot_loss=3.388 (perp=11.370, rec=0.476, cos=0.638), tot_loss_proj:3.676 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1250/2000] tot_loss=3.414 (perp=11.370, rec=0.483, cos=0.657), tot_loss_proj:3.678 [t=0.24s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1300/2000] tot_loss=3.405 (perp=11.370, rec=0.478, cos=0.654), tot_loss_proj:3.677 [t=0.20s]
prediction: ['[CLS] ease ease [SEP]']
[1350/2000] tot_loss=3.419 (perp=11.370, rec=0.478, cos=0.667), tot_loss_proj:3.680 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1400/2000] tot_loss=3.397 (perp=11.370, rec=0.476, cos=0.647), tot_loss_proj:3.681 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1450/2000] tot_loss=3.420 (perp=11.370, rec=0.481, cos=0.665), tot_loss_proj:3.675 [t=0.19s]
prediction: ['[CLS] ease ease [SEP]']
[1500/2000] tot_loss=3.422 (perp=11.370, rec=0.475, cos=0.672), tot_loss_proj:3.683 [t=0.29s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1550/2000] tot_loss=3.415 (perp=11.370, rec=0.481, cos=0.660), tot_loss_proj:3.683 [t=0.25s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1600/2000] tot_loss=3.410 (perp=11.370, rec=0.475, cos=0.661), tot_loss_proj:3.688 [t=0.19s]
prediction: ['[CLS] ease ease [SEP]']
[1650/2000] tot_loss=3.412 (perp=11.370, rec=0.473, cos=0.665), tot_loss_proj:3.683 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1700/2000] tot_loss=3.414 (perp=11.370, rec=0.466, cos=0.674), tot_loss_proj:3.680 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1750/2000] tot_loss=3.414 (perp=11.370, rec=0.478, cos=0.662), tot_loss_proj:3.679 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
[1800/2000] tot_loss=3.418 (perp=11.370, rec=0.475, cos=0.669), tot_loss_proj:3.686 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1850/2000] tot_loss=3.408 (perp=11.370, rec=0.468, cos=0.666), tot_loss_proj:3.679 [t=0.19s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[1900/2000] tot_loss=3.422 (perp=11.370, rec=0.471, cos=0.677), tot_loss_proj:3.682 [t=0.18s]
prediction: ['[CLS] ease ease [SEP]']
[1950/2000] tot_loss=3.413 (perp=11.370, rec=0.478, cos=0.660), tot_loss_proj:3.678 [t=0.21s]
prediction: ['[CLS] ease ease [SEP]']
Attempt swap
[2000/2000] tot_loss=3.406 (perp=11.370, rec=0.473, cos=0.659), tot_loss_proj:3.677 [t=0.22s]
prediction: ['[CLS] ease ease [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease ease [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 75.000 | p: 75.000 | r: 75.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 108.333

[Aggregate metrics]:
rouge1     | fm: 92.500 | p: 92.500 | r: 92.500
rouge2     | fm: 76.389 | p: 76.389 | r: 76.389
rougeL     | fm: 92.500 | p: 92.500 | r: 92.500
rougeLsum  | fm: 92.500 | p: 92.500 | r: 92.500
r1fm+r2fm = 168.889

input #5 time: 0:08:17 | total time: 0:49:38


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.9987767753178913
highest_index [0]
highest [0.9987767753178913]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 0.9421886801719666 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 0.8477110862731934 for ['[CLS]ius ) [SEP]']
[Init] best rec loss: 0.8184031248092651 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 0.803709864616394 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 0.7538610100746155 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 0.7160127758979797 for ['[CLS] air little [SEP]']
[Init] best rec loss: 0.6948166489601135 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 0.6765562891960144 for ['[CLS] double deep [SEP]']
[Init] best perm rec loss: 0.6708187460899353 for ['[CLS] deep double [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.265 (perp=10.460, rec=0.166, cos=0.008), tot_loss_proj:2.507 [t=0.22s]
prediction: ['[CLS]ish gray [SEP]']
[ 100/2000] tot_loss=2.159 (perp=10.460, rec=0.064, cos=0.004), tot_loss_proj:2.512 [t=0.26s]
prediction: ['[CLS]ish gray [SEP]']
[ 150/2000] tot_loss=2.156 (perp=10.460, rec=0.061, cos=0.003), tot_loss_proj:2.516 [t=0.23s]
prediction: ['[CLS]ish gray [SEP]']
[ 200/2000] tot_loss=2.168 (perp=10.460, rec=0.073, cos=0.003), tot_loss_proj:2.503 [t=0.25s]
prediction: ['[CLS]ish gray [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.692 (perp=8.089, rec=0.071, cos=0.003), tot_loss_proj:1.704 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.684 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.690 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.688 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.682 (perp=8.089, rec=0.062, cos=0.002), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.679 (perp=8.089, rec=0.059, cos=0.002), tot_loss_proj:1.687 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.676 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.675 (perp=8.089, rec=0.055, cos=0.002), tot_loss_proj:1.694 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.681 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.690 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.684 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.687 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.685 (perp=8.089, rec=0.065, cos=0.002), tot_loss_proj:1.688 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.668 (perp=8.089, rec=0.048, cos=0.002), tot_loss_proj:1.690 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.002), tot_loss_proj:1.701 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.685 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.678 (perp=8.089, rec=0.057, cos=0.002), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.685 (perp=8.089, rec=0.065, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.677 (perp=8.089, rec=0.057, cos=0.002), tot_loss_proj:1.686 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.664 (perp=8.089, rec=0.044, cos=0.002), tot_loss_proj:1.681 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.698 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.683 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.700 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.681 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.674 (perp=8.089, rec=0.054, cos=0.002), tot_loss_proj:1.681 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.686 (perp=8.089, rec=0.066, cos=0.002), tot_loss_proj:1.699 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.673 (perp=8.089, rec=0.053, cos=0.002), tot_loss_proj:1.696 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.686 (perp=8.089, rec=0.066, cos=0.002), tot_loss_proj:1.696 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.672 (perp=8.089, rec=0.052, cos=0.002), tot_loss_proj:1.700 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.666 (perp=8.089, rec=0.045, cos=0.002), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.687 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.695 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.679 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.667 (perp=8.089, rec=0.047, cos=0.002), tot_loss_proj:1.697 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.682 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.696 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.002), tot_loss_proj:1.691 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.679 (perp=8.089, rec=0.059, cos=0.002), tot_loss_proj:1.687 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.697 (perp=8.089, rec=0.077, cos=0.002), tot_loss_proj:1.692 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.677 (perp=8.089, rec=0.057, cos=0.002), tot_loss_proj:1.681 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 93.571 | p: 93.571 | r: 93.571
rouge2     | fm: 79.762 | p: 79.762 | r: 79.762
rougeL     | fm: 93.571 | p: 93.571 | r: 93.571
rougeLsum  | fm: 93.571 | p: 93.571 | r: 93.571
r1fm+r2fm = 173.333

input #6 time: 0:08:03 | total time: 0:57:41


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9983450939516059
highest_index [0]
highest [0.9983450939516059]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 0.9030833840370178 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 0.8309371471405029 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 0.8219938278198242 for ['[CLS] flat forewingsys mick separation ) oh yorkening las sat an consecutive charity qaeda clinicroud ill column rustling marathon rom viper dinner chuck ( [SEP]']
[Init] best rec loss: 0.819702684879303 for ['[CLS] few ready candidates nateim were lassolo located nice basis hon hepburn bailey hull visa professional wen taller zip™ venue burkina sits now hydraulic [SEP]']
[Init] best rec loss: 0.809517502784729 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best rec loss: 0.8014093041419983 for ['[CLS] ni maintained micro aces echo all behind legal somethingelli stanley park d conspiracy medicine childbation jobtative hop rule fighting early twins sykes line [SEP]']
[Init] best rec loss: 0.8002603650093079 for ['[CLS] cod dock # openר sat both grande flow hs most purpose baby beings comppia jenny infants part end pay exactly conference moths median [SEP]']
[Init] best perm rec loss: 0.7996097207069397 for ['[CLS]p beings sat # baby conference both most median dock end flowר hs pay part infants moths grande exactlypia jenny purpose cod com open [SEP]']
[Init] best perm rec loss: 0.799469530582428 for ['[CLS] median exactly hs infants com conference most # both grandeppia beings end moths cod sat open part flowר purpose pay baby dock jenny [SEP]']
[Init] best perm rec loss: 0.7991330027580261 for ['[CLS] sat dockp end grande both flow jenny babypia most com cod moths beings conference # hs exactly open median infants purpose partר pay [SEP]']
[Init] best perm rec loss: 0.7984753847122192 for ['[CLS] infants exactly #p purpose dock flowר com end moths cod paypia hs most part baby beings open median conference both jenny grande sat [SEP]']
[Init] best perm rec loss: 0.7970612645149231 for ['[CLS] mostpia moths beings flow end purpose open dock part pay jenny cod both median # conference baby hs infants com sat exactlyר grandep [SEP]']
[Init] best perm rec loss: 0.7970491647720337 for ['[CLS] exactly part baby com cod hs sat most grande open beings dock bothpia pay conference end flow purpose jenny mothsרp median # infants [SEP]']
[Init] best perm rec loss: 0.7953745722770691 for ['[CLS] beings end moths dock jenny com both open most flowר purpose part sat cod hs exactly conference median baby pay grande infants #ppia [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.822 (perp=10.995, rec=0.505, cos=0.118), tot_loss_proj:3.194 [t=0.24s]
prediction: ["[CLS] no seems and finland for is except hit from problem usually incident the truck mexican cr my a his video cheap was smell him organisation'[SEP]"]
[ 100/2000] tot_loss=2.380 (perp=9.850, rec=0.356, cos=0.054), tot_loss_proj:2.869 [t=0.19s]
prediction: ['[CLS] no character and tamil and [CLS] no exist during problem or seat the mca the problem is a rub video [SEP] were speed him organisation. [SEP]']
[ 150/2000] tot_loss=2.355 (perp=10.226, rec=0.281, cos=0.029), tot_loss_proj:3.009 [t=0.28s]
prediction: ['[CLS] no character anderated and work no exists sexuality problem or ordinary the mca any problem is a rub video [SEP] were speed him organisation. [SEP]']
[ 200/2000] tot_loss=2.230 (perp=9.834, rec=0.245, cos=0.018), tot_loss_proj:2.826 [t=0.19s]
prediction: ['[CLS] no character anderated and he no existsrained problem or ordinary the mca thereof problem is a ship variety down were speed him organisation. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.191 (perp=9.623, rec=0.248, cos=0.019), tot_loss_proj:2.870 [t=0.28s]
prediction: ['[CLS] no character iserated and he no exists acquired problem or ordinary the mca vile problem is a ship variety organisation were rate him [SEP]. [SEP]']
[ 300/2000] tot_loss=2.226 (perp=9.997, rec=0.214, cos=0.013), tot_loss_proj:3.120 [t=0.22s]
prediction: ['[CLS] no character isnator and he no batted lgbt problem or ordinary the mca vile problem is a ship variety boiler were risk him [SEP]. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.195 (perp=9.762, rec=0.229, cos=0.014), tot_loss_proj:3.258 [t=0.19s]
prediction: ['[CLS] no character is - and he no fun abbreviated problem or for the mca here problem romantic a involves cause boiler were risk him [SEP]. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.071 (perp=9.206, rec=0.217, cos=0.012), tot_loss_proj:3.078 [t=0.18s]
prediction: ['[CLS] no character is fighting and he no cute affection problem or for the rot cause problem is a involves vile clubs were risk him [SEP]. [SEP]']
[ 450/2000] tot_loss=1.953 (perp=8.646, rec=0.210, cos=0.014), tot_loss_proj:2.536 [t=0.19s]
prediction: ['[CLS] no character has or and he no fun ; problem, should the rot cause problem love a exists vile clubs were risk treatment [SEP]. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.863 (perp=8.213, rec=0.207, cos=0.013), tot_loss_proj:2.545 [t=0.24s]
prediction: ['[CLS] no character has or and he not fun ; problem, for the rot cause a was problem is vile clubs were problem treatment [SEP]. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.866 (perp=8.260, rec=0.202, cos=0.012), tot_loss_proj:2.762 [t=0.23s]
prediction: ['[CLS] no character has or and he not rot existent problem ; not the fun cause a love problem is vile boiler were problem treatment [SEP]. [SEP]']
[ 600/2000] tot_loss=1.798 (perp=7.967, rec=0.194, cos=0.011), tot_loss_proj:2.703 [t=0.24s]
prediction: ['[CLS] no character has, and he not rot carolyn problem ; not the interesting cause a love problem is removed boiler were problem treatment [SEP]. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.658 (perp=7.363, rec=0.174, cos=0.011), tot_loss_proj:2.542 [t=0.18s]
prediction: ['[CLS] no character has, and he not rot carolyn problem ; not the interesting cause a love problem is were removed label problem. [SEP]. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.711 (perp=7.582, rec=0.184, cos=0.011), tot_loss_proj:2.805 [t=0.20s]
prediction: ['[CLS] no character has, and he not rot carolyn problem ; not the interesting fancy or love problem is were deity problem. [SEP] label. [SEP]']
[ 750/2000] tot_loss=1.692 (perp=7.520, rec=0.177, cos=0.010), tot_loss_proj:3.183 [t=0.19s]
prediction: ['[CLS] no character has, and he not rot disneyland problem ; not the cute fancy or love problem is were deity problem. [SEP] label. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.650 (perp=7.367, rec=0.167, cos=0.010), tot_loss_proj:3.185 [t=0.18s]
prediction: ['[CLS] no character has, and he not rot disneyland problem ; not the cute problem or love problem is were deity problem. [SEP] label. [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.630 (perp=7.263, rec=0.167, cos=0.010), tot_loss_proj:3.204 [t=0.23s]
prediction: ['[CLS] no character has, and he not rot disneyland problem ; not the cute problem or love problem is deity problem were. [SEP] label. [SEP]']
[ 900/2000] tot_loss=1.651 (perp=7.357, rec=0.171, cos=0.009), tot_loss_proj:3.064 [t=0.19s]
prediction: ['[CLS] no character has, and he not rot disneyland problem ; not the cute mind or love problem is deity problem were. [SEP] label. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.706 (perp=7.629, rec=0.171, cos=0.009), tot_loss_proj:2.810 [t=0.20s]
prediction: ['[CLS] no character has he, and not rotivision problem ; not the cute mind or love problem is deity problem were. [SEP] label. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.730 (perp=7.787, rec=0.164, cos=0.009), tot_loss_proj:2.814 [t=0.19s]
prediction: ['[CLS] no character has he, for not rotivision problem ; not the cute mind or love problem is deity problem were. [SEP] label. [SEP]']
[1050/2000] tot_loss=1.844 (perp=8.335, rec=0.168, cos=0.009), tot_loss_proj:3.094 [t=0.25s]
prediction: ['[CLS] no character has here for not rotivision problem ; not the cute mind or love problem is deity problem were. [SEP] label. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.766 (perp=7.973, rec=0.163, cos=0.009), tot_loss_proj:3.178 [t=0.18s]
prediction: ['[CLS] no character has here and not rotivision problem ; not the cute mind or deity problem is love problem were. [SEP] label. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.797 (perp=8.113, rec=0.166, cos=0.009), tot_loss_proj:3.186 [t=0.18s]
prediction: ['[CLS] no character has heor and not rotivision problem ; not the cute mind or deity problem is love problem were. [SEP] label. [SEP]']
[1200/2000] tot_loss=1.788 (perp=8.113, rec=0.157, cos=0.009), tot_loss_proj:3.183 [t=0.32s]
prediction: ['[CLS] no character has heor and not rotivision problem ; not the cute mind or deity problem is love problem were. [SEP] label. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.790 (perp=8.113, rec=0.159, cos=0.009), tot_loss_proj:3.186 [t=0.19s]
prediction: ['[CLS] no character has heor and not rotivision problem ; not the cute mind or deity problem is love problem were. [SEP] label. [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.785 (perp=8.114, rec=0.153, cos=0.009), tot_loss_proj:3.046 [t=0.18s]
prediction: ['[CLS] no character heor has and not rotivision problem ; not the cute mind or deity problem is love problem were. [SEP] label. [SEP]']
[1350/2000] tot_loss=1.781 (perp=8.062, rec=0.159, cos=0.009), tot_loss_proj:2.593 [t=0.25s]
prediction: ['[CLS] no character heor has. not rotivision problem ; not the cute mind or deity problem is love problem were. [SEP] label. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.773 (perp=8.062, rec=0.152, cos=0.009), tot_loss_proj:2.591 [t=0.29s]
prediction: ['[CLS] no character heor has. not rotivision problem ; not the cute mind or deity problem is love problem were. [SEP] label. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.855 (perp=8.449, rec=0.157, cos=0.009), tot_loss_proj:2.916 [t=0.19s]
prediction: ['[CLS] no character heor has. not rotivision problem ; previously the cute mind or deity problem is love problem were. [SEP] label. [SEP]']
[1500/2000] tot_loss=1.853 (perp=8.449, rec=0.154, cos=0.008), tot_loss_proj:2.917 [t=0.19s]
prediction: ['[CLS] no character heor has. not rotivision problem ; previously the cute mind or deity problem is love problem were. [SEP] label. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.765 (perp=7.993, rec=0.157, cos=0.009), tot_loss_proj:2.623 [t=0.22s]
prediction: ['[CLS] no character heor has. not rotivision problem ; not the cute mind or deity problem is love problem. [SEP] label were. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.758 (perp=7.993, rec=0.151, cos=0.009), tot_loss_proj:2.623 [t=0.18s]
prediction: ['[CLS] no character heor has. not rotivision problem ; not the cute mind or deity problem is love problem. [SEP] label were. [SEP]']
[1650/2000] tot_loss=1.830 (perp=8.298, rec=0.161, cos=0.009), tot_loss_proj:2.915 [t=0.19s]
prediction: ['[CLS] no character heor has. not rotivision problem ; previously the cute mind or deity problem is love problem. [SEP] label were. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.818 (perp=8.298, rec=0.150, cos=0.009), tot_loss_proj:2.913 [t=0.19s]
prediction: ['[CLS] no character heor has. not rotivision problem ; previously the cute mind or deity problem is love problem. [SEP] label were. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.825 (perp=8.298, rec=0.157, cos=0.009), tot_loss_proj:2.913 [t=0.18s]
prediction: ['[CLS] no character heor has. not rotivision problem ; previously the cute mind or deity problem is love problem. [SEP] label were. [SEP]']
[1800/2000] tot_loss=1.815 (perp=8.241, rec=0.158, cos=0.009), tot_loss_proj:2.988 [t=0.24s]
prediction: ['[CLS] no character heor has. not rotivision problem ; previously the cute mind or deity problem is love problem. [SEP] shareholder were. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.800 (perp=8.206, rec=0.150, cos=0.008), tot_loss_proj:3.018 [t=0.19s]
prediction: ['[CLS] no character heable has. not rotivision problem ; previously the cute mind or deity problem is love problem. [SEP] were shareholder. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.799 (perp=8.206, rec=0.150, cos=0.008), tot_loss_proj:3.018 [t=0.18s]
prediction: ['[CLS] no character heable has. not rotivision problem ; previously the cute mind or deity problem is love problem. [SEP] were shareholder. [SEP]']
[1950/2000] tot_loss=1.754 (perp=7.947, rec=0.156, cos=0.009), tot_loss_proj:2.946 [t=0.22s]
prediction: ['[CLS] no character heable has. not rotivision problem ; previously the cute mind or deity problem is love problem.. were shareholder. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.742 (perp=7.947, rec=0.145, cos=0.008), tot_loss_proj:2.950 [t=0.19s]
prediction: ['[CLS] no character heable has. not rotivision problem ; previously the cute mind or deity problem is love problem.. were shareholder. [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] no character heable has. not rotivision problem ; previously the cute mind or deity problem is love problem.. were shareholder. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 57.143 | p: 57.143 | r: 57.143
rouge2     | fm: 15.000 | p: 15.000 | r: 15.000
rougeL     | fm: 33.333 | p: 33.333 | r: 33.333
rougeLsum  | fm: 33.333 | p: 33.333 | r: 33.333
r1fm+r2fm = 72.143

[Aggregate metrics]:
rouge1     | fm: 89.018 | p: 89.018 | r: 89.018
rouge2     | fm: 71.667 | p: 71.667 | r: 71.667
rougeL     | fm: 86.042 | p: 86.042 | r: 86.042
rougeLsum  | fm: 86.042 | p: 86.042 | r: 86.042
r1fm+r2fm = 160.685

input #7 time: 0:08:35 | total time: 1:06:17


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.998959762311237
highest_index [0]
highest [0.998959762311237]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 0.6597844362258911 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 0.655926525592804 for ['[CLS] breed app king jude rome am regal roman grown levi mine fitting peninsula cappella age bulldogs component founder macarthur unionist overturegible raysstock [SEP]']
[Init] best rec loss: 0.6527599692344666 for ['[CLS] vin figure blowgger note mission [CLS] planet outside xi awardhe collections work money... unsuccessful canon ob brainally street wheat shortly [SEP]']
[Init] best rec loss: 0.6519345045089722 for ['[CLS] rebounds representatives subject deal statistical punchfieduro warner timelessflow fromventing how kylie electric sox activity huh roth make tax anglia seventeenth [SEP]']
[Init] best rec loss: 0.6440722346305847 for ['[CLS] andhra basque richards surrounding rockwell gloss rodeo series balanced waived word line plan styx responsible wish procession than attentionrave retention past doe tv [SEP]']
[Init] best perm rec loss: 0.6438997387886047 for ['[CLS] doe waived attention rodeo rockwell wish richards basque procession planrave balanced than tv surrounding gloss styx past series line andhra retention responsible word [SEP]']
[Init] best perm rec loss: 0.6407497525215149 for ['[CLS] plan wish attention than procession word responsible basquerave balanced gloss surrounding series doe rockwell rodeo andhra richards retention waived tv line past styx [SEP]']
[Init] best perm rec loss: 0.6402841806411743 for ['[CLS] tv plan doe than responsible rockwell line surrounding procession basque balancedrave andhra styx waived word attention retention past series rodeo wish richards gloss [SEP]']
[Init] best perm rec loss: 0.63776034116745 for ['[CLS] attention richards basque word pastrave than rodeo tv rockwell styx line surrounding andhra balanced procession retention responsible wish gloss plan waived series doe [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.972 (perp=13.099, rec=0.282, cos=0.070), tot_loss_proj:4.151 [t=0.35s]
prediction: ['[CLS] an vanity pays vanity department? vanity pay vanity movie vanity films film offvable pays paid lawrence pay vanity what whose indeed vanity [SEP]']
[ 100/2000] tot_loss=2.744 (perp=12.176, rec=0.226, cos=0.083), tot_loss_proj:4.105 [t=0.18s]
prediction: ['[CLS] an vanity pays vanity debt doubt vanity merely hell film vanity debt film off vanity pays debtmax debt vanity what what what doubt [SEP]']
[ 150/2000] tot_loss=2.611 (perp=12.101, rec=0.165, cos=0.026), tot_loss_proj:3.762 [t=0.26s]
prediction: ['[CLS] aful pays fright debt doubt vanity merely no that vanity debt film off vanity pays offmax debt vanityvar whose what doubt [SEP]']
[ 200/2000] tot_loss=2.304 (perp=10.571, rec=0.134, cos=0.056), tot_loss_proj:3.492 [t=0.24s]
prediction: ['[CLS] aful pays fright debt, vanity merely no that vanity off film benign vanity pays offmax debt vanity what they what doubt [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.235 (perp=10.578, rec=0.107, cos=0.012), tot_loss_proj:3.273 [t=0.19s]
prediction: ['[CLS] frightful pays a debt, vanity merely no that vanity off film benignevsky pays offmax owed vanity benign they what doubt [SEP]']
[ 300/2000] tot_loss=2.217 (perp=10.607, rec=0.088, cos=0.008), tot_loss_proj:3.384 [t=0.22s]
prediction: ['[CLS] frightful pays a debt, vanity merely no that vanity off film benignfish pays offmax owed vanity benign they what doubt [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.293 (perp=10.842, rec=0.108, cos=0.017), tot_loss_proj:3.544 [t=0.19s]
prediction: ['[CLS] frightful a s debt, vanitylowe no that vanity off film benigni pays off owed vanity benignmax felt what doubt [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.160 (perp=10.299, rec=0.094, cos=0.006), tot_loss_proj:3.365 [t=0.18s]
prediction: ['[CLS] frightful owed s debt, vanitylowe no that vanity off film benigni pays off a vanity benignmax felt what doubt [SEP]']
[ 450/2000] tot_loss=2.157 (perp=10.299, rec=0.094, cos=0.004), tot_loss_proj:3.362 [t=0.23s]
prediction: ['[CLS] frightful owed s debt, vanitylowe no that vanity off film benigni pays off a vanity benignmax felt what doubt [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.048 (perp=9.788, rec=0.086, cos=0.004), tot_loss_proj:3.367 [t=0.18s]
prediction: ['[CLS] s frightful owed debt, vanity immediately no that vanity off film benigni pays off a vanity benignmax felt what doubt [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.957 (perp=9.326, rec=0.088, cos=0.004), tot_loss_proj:2.977 [t=0.18s]
prediction: ['[CLS] s frightful owed debt, that immediately no vanity vanity off film benigni pays off a vanity benignmax felt what doubt [SEP]']
[ 600/2000] tot_loss=1.908 (perp=9.121, rec=0.080, cos=0.004), tot_loss_proj:2.862 [t=0.18s]
prediction: ['[CLS] s frightful owed debt, that immediately no vanity vanity off film benigni pays off a vanity theymax felt what doubt [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.860 (perp=8.873, rec=0.079, cos=0.006), tot_loss_proj:2.928 [t=0.23s]
prediction: ['[CLS] s frightful owed debt, thatmax no vanity vanity off film benigni pays off a vanity they immediately felt what doubt [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.785 (perp=8.509, rec=0.078, cos=0.005), tot_loss_proj:2.825 [t=0.25s]
prediction: ['[CLS] s frightful owedmax debt, that no vanity vanity off film benigni pays off a vanity they immediately felt what doubt [SEP]']
[ 750/2000] tot_loss=1.783 (perp=8.509, rec=0.078, cos=0.004), tot_loss_proj:2.830 [t=0.20s]
prediction: ['[CLS] s frightful owedmax debt, that no vanity vanity off film benigni pays off a vanity they immediately felt what doubt [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.882 (perp=8.998, rec=0.079, cos=0.003), tot_loss_proj:2.853 [t=0.18s]
prediction: ['[CLS] s frightful owedmax debt, that no vanity vanity off film benigni pays off a vanity they ‖ felt what doubt [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.881 (perp=8.998, rec=0.078, cos=0.003), tot_loss_proj:2.849 [t=0.19s]
prediction: ['[CLS] s frightful owedmax debt, that no vanity vanity off film benigni pays off a vanity they ‖ felt what doubt [SEP]']
[ 900/2000] tot_loss=1.877 (perp=8.998, rec=0.074, cos=0.003), tot_loss_proj:2.844 [t=0.18s]
prediction: ['[CLS] s frightful owedmax debt, that no vanity vanity off film benigni pays off a vanity they ‖ felt what doubt [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.844 (perp=8.840, rec=0.072, cos=0.003), tot_loss_proj:2.803 [t=0.19s]
prediction: ['[CLS] s frightfulmax owed debt, that no vanity vanity off film benigni pays off a vanity they ‖ felt what doubt [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.847 (perp=8.792, rec=0.083, cos=0.006), tot_loss_proj:2.815 [t=0.19s]
prediction: ['[CLS] s frightfulmax owed debt, that no vanity off vanity film benigni pays off a vanity they ‖ felt what doubt [SEP]']
[1050/2000] tot_loss=1.838 (perp=8.792, rec=0.077, cos=0.003), tot_loss_proj:2.815 [t=0.23s]
prediction: ['[CLS] s frightfulmax owed debt, that no vanity off vanity film benigni pays off a vanity they ‖ felt what doubt [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.829 (perp=8.779, rec=0.070, cos=0.003), tot_loss_proj:2.799 [t=0.23s]
prediction: ['[CLS] s frightful debt owedmax, that no vanity off vanity film benigni pays off a vanity they ‖ felt what doubt [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.833 (perp=8.695, rec=0.089, cos=0.005), tot_loss_proj:2.767 [t=0.18s]
prediction: ['[CLS] s frightful debt owedmax, that no vanity off vanity film benigni pays off a vanity they felt ‖ what doubt [SEP]']
[1200/2000] tot_loss=1.812 (perp=8.695, rec=0.070, cos=0.003), tot_loss_proj:2.773 [t=0.21s]
prediction: ['[CLS] s frightful debt owedmax, that no vanity off vanity film benigni pays off a vanity they felt ‖ what doubt [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.811 (perp=8.649, rec=0.078, cos=0.003), tot_loss_proj:2.775 [t=0.18s]
prediction: ['[CLS] s frightful debtmax owed, that no vanity off vanity film benigni pays off a vanity they felt ‖ what doubt [SEP]']
Attempt swap
[1300/2000] tot_loss=1.813 (perp=8.649, rec=0.080, cos=0.003), tot_loss_proj:2.776 [t=0.18s]
prediction: ['[CLS] s frightful debtmax owed, that no vanity off vanity film benigni pays off a vanity they felt ‖ what doubt [SEP]']
[1350/2000] tot_loss=1.805 (perp=8.649, rec=0.072, cos=0.003), tot_loss_proj:2.775 [t=0.21s]
prediction: ['[CLS] s frightful debtmax owed, that no vanity off vanity film benigni pays off a vanity they felt ‖ what doubt [SEP]']
Attempt swap
[1400/2000] tot_loss=1.802 (perp=8.649, rec=0.069, cos=0.003), tot_loss_proj:2.775 [t=0.18s]
prediction: ['[CLS] s frightful debtmax owed, that no vanity off vanity film benigni pays off a vanity they felt ‖ what doubt [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.795 (perp=8.556, rec=0.081, cos=0.003), tot_loss_proj:2.650 [t=0.18s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off a vanity they felt∘ what doubt [SEP]']
[1500/2000] tot_loss=1.777 (perp=8.473, rec=0.079, cos=0.003), tot_loss_proj:2.639 [t=0.21s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off a vanity they feltₗ what doubt [SEP]']
Attempt swap
[1550/2000] tot_loss=1.772 (perp=8.473, rec=0.074, cos=0.003), tot_loss_proj:2.641 [t=0.22s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off a vanity they feltₗ what doubt [SEP]']
Attempt swap
[1600/2000] tot_loss=1.769 (perp=8.473, rec=0.071, cos=0.003), tot_loss_proj:2.647 [t=0.23s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off a vanity they feltₗ what doubt [SEP]']
[1650/2000] tot_loss=1.768 (perp=8.473, rec=0.070, cos=0.003), tot_loss_proj:2.641 [t=0.26s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off a vanity they feltₗ what doubt [SEP]']
Attempt swap
[1700/2000] tot_loss=1.777 (perp=8.473, rec=0.080, cos=0.003), tot_loss_proj:2.643 [t=0.19s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off a vanity they feltₗ what doubt [SEP]']
Attempt swap
[1750/2000] tot_loss=1.694 (perp=8.054, rec=0.080, cos=0.003), tot_loss_proj:2.532 [t=0.24s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off a vanity they felt to what doubt [SEP]']
[1800/2000] tot_loss=1.684 (perp=8.054, rec=0.070, cos=0.003), tot_loss_proj:2.539 [t=0.18s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off a vanity they felt to what doubt [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.651 (perp=7.876, rec=0.072, cos=0.004), tot_loss_proj:2.517 [t=0.18s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off what a vanity they felt to doubt [SEP]']
Attempt swap
[1900/2000] tot_loss=1.649 (perp=7.876, rec=0.070, cos=0.003), tot_loss_proj:2.516 [t=0.23s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off what a vanity they felt to doubt [SEP]']
[1950/2000] tot_loss=1.658 (perp=7.876, rec=0.079, cos=0.003), tot_loss_proj:2.514 [t=0.22s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off what a vanity they felt to doubt [SEP]']
Attempt swap
[2000/2000] tot_loss=1.654 (perp=7.876, rec=0.076, cos=0.003), tot_loss_proj:2.515 [t=0.18s]
prediction: ['[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off what a vanity they felt to doubt [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] s frightfulmax debt owed, that no vanity off vanity film benigni pays off a vanity they felt to what doubt [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 81.818 | r: 90.000
rouge2     | fm: 20.000 | p: 19.048 | r: 21.053
rougeL     | fm: 42.857 | p: 40.909 | r: 45.000
rougeLsum  | fm: 42.857 | p: 40.909 | r: 45.000
r1fm+r2fm = 105.714

[Aggregate metrics]:
rouge1     | fm: 88.651 | p: 88.218 | r: 89.127
rouge2     | fm: 65.926 | p: 65.608 | r: 66.043
rougeL     | fm: 81.243 | p: 81.027 | r: 81.481
rougeLsum  | fm: 81.746 | p: 81.313 | r: 82.037
r1fm+r2fm = 154.577

input #8 time: 0:08:22 | total time: 1:14:40


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.998825983748425
highest_index [0]
highest [0.998825983748425]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 0.7783852219581604 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 0.6857913136482239 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 0.6582470536231995 for ['[CLS] ham ice command across see beatty anal tan [SEP]']
[Init] best perm rec loss: 0.6571835279464722 for ['[CLS] ice ham command across see anal tan beatty [SEP]']
[Init] best perm rec loss: 0.6571743488311768 for ['[CLS] command across see ice anal beatty ham tan [SEP]']
[Init] best perm rec loss: 0.6564609408378601 for ['[CLS] ham beatty anal see tan ice across command [SEP]']
[Init] best perm rec loss: 0.656074047088623 for ['[CLS] see ice command tan ham anal beatty across [SEP]']
[Init] best perm rec loss: 0.6552069783210754 for ['[CLS] ice ham command across beatty see tan anal [SEP]']
[Init] best perm rec loss: 0.6550137400627136 for ['[CLS] command beatty ham ice tan across see anal [SEP]']
[Init] best perm rec loss: 0.6549914479255676 for ['[CLS] see beatty tan across command ham anal ice [SEP]']
[Init] best perm rec loss: 0.6547313332557678 for ['[CLS] command beatty ham across see tan ice anal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.528 (perp=10.887, rec=0.246, cos=0.105), tot_loss_proj:3.610 [t=0.18s]
prediction: ['[CLS] soft metaphysicalhead clap clap clap soft brain [SEP]']
[ 100/2000] tot_loss=2.725 (perp=12.689, rec=0.161, cos=0.027), tot_loss_proj:3.501 [t=0.19s]
prediction: ['[CLS] soft metaphysicalheadhead clap claptratra [SEP]']
[ 150/2000] tot_loss=2.588 (perp=12.267, rec=0.123, cos=0.011), tot_loss_proj:3.542 [t=0.19s]
prediction: ['[CLS] soft metaphysicalheadp clap claptra of [SEP]']
[ 200/2000] tot_loss=2.574 (perp=12.441, rec=0.082, cos=0.003), tot_loss_proj:3.458 [t=0.24s]
prediction: ['[CLS] soft metaphysicalheadped claptra of [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.858 (perp=8.932, rec=0.067, cos=0.004), tot_loss_proj:2.567 [t=0.18s]
prediction: ['[CLS] soft metaphysicalheaded claptrap of [SEP]']
[ 300/2000] tot_loss=1.864 (perp=8.932, rec=0.075, cos=0.002), tot_loss_proj:2.579 [t=0.18s]
prediction: ['[CLS] soft metaphysicalheaded claptrap of [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.713 (perp=8.240, rec=0.063, cos=0.002), tot_loss_proj:2.063 [t=0.18s]
prediction: ['[CLS] metaphysical softheaded claptrap of [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.538 (perp=7.384, rec=0.058, cos=0.004), tot_loss_proj:1.637 [t=0.20s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 450/2000] tot_loss=1.545 (perp=7.384, rec=0.066, cos=0.002), tot_loss_proj:1.635 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.538 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.636 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.538 (perp=7.384, rec=0.059, cos=0.002), tot_loss_proj:1.645 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 600/2000] tot_loss=1.545 (perp=7.384, rec=0.066, cos=0.002), tot_loss_proj:1.638 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.538 (perp=7.384, rec=0.059, cos=0.002), tot_loss_proj:1.633 [t=0.20s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.540 (perp=7.384, rec=0.061, cos=0.002), tot_loss_proj:1.648 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 750/2000] tot_loss=1.547 (perp=7.384, rec=0.068, cos=0.002), tot_loss_proj:1.623 [t=0.21s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.544 (perp=7.384, rec=0.065, cos=0.002), tot_loss_proj:1.634 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.545 (perp=7.384, rec=0.066, cos=0.002), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[ 900/2000] tot_loss=1.536 (perp=7.384, rec=0.057, cos=0.002), tot_loss_proj:1.646 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.537 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.636 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1000/2000] tot_loss=1.540 (perp=7.384, rec=0.061, cos=0.002), tot_loss_proj:1.635 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1050/2000] tot_loss=1.548 (perp=7.384, rec=0.068, cos=0.002), tot_loss_proj:1.645 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1100/2000] tot_loss=1.539 (perp=7.384, rec=0.060, cos=0.002), tot_loss_proj:1.643 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1150/2000] tot_loss=1.546 (perp=7.384, rec=0.066, cos=0.002), tot_loss_proj:1.628 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1200/2000] tot_loss=1.547 (perp=7.384, rec=0.067, cos=0.002), tot_loss_proj:1.650 [t=0.26s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1250/2000] tot_loss=1.530 (perp=7.384, rec=0.051, cos=0.002), tot_loss_proj:1.622 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1300/2000] tot_loss=1.541 (perp=7.384, rec=0.062, cos=0.002), tot_loss_proj:1.643 [t=0.22s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1350/2000] tot_loss=1.546 (perp=7.384, rec=0.067, cos=0.002), tot_loss_proj:1.643 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1400/2000] tot_loss=1.547 (perp=7.384, rec=0.068, cos=0.002), tot_loss_proj:1.646 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1450/2000] tot_loss=1.551 (perp=7.384, rec=0.072, cos=0.002), tot_loss_proj:1.630 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1500/2000] tot_loss=1.545 (perp=7.384, rec=0.066, cos=0.002), tot_loss_proj:1.627 [t=0.21s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1550/2000] tot_loss=1.534 (perp=7.384, rec=0.055, cos=0.002), tot_loss_proj:1.634 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1600/2000] tot_loss=1.539 (perp=7.384, rec=0.060, cos=0.002), tot_loss_proj:1.640 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1650/2000] tot_loss=1.547 (perp=7.384, rec=0.068, cos=0.002), tot_loss_proj:1.635 [t=0.27s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1700/2000] tot_loss=1.544 (perp=7.384, rec=0.065, cos=0.002), tot_loss_proj:1.641 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1750/2000] tot_loss=1.537 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.629 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1800/2000] tot_loss=1.540 (perp=7.384, rec=0.061, cos=0.002), tot_loss_proj:1.633 [t=0.23s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1850/2000] tot_loss=1.545 (perp=7.384, rec=0.066, cos=0.002), tot_loss_proj:1.618 [t=0.18s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[1900/2000] tot_loss=1.537 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.628 [t=0.25s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
[1950/2000] tot_loss=1.537 (perp=7.384, rec=0.058, cos=0.002), tot_loss_proj:1.628 [t=0.24s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Attempt swap
[2000/2000] tot_loss=1.540 (perp=7.384, rec=0.060, cos=0.002), tot_loss_proj:1.641 [t=0.19s]
prediction: ['[CLS] of metaphysical softheaded claptrap [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS] of metaphysical softheaded claptrap [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 90.000 | p: 89.578 | r: 90.500
rouge2     | fm: 63.333 | p: 63.238 | r: 63.439
rougeL     | fm: 81.452 | p: 81.258 | r: 81.667
rougeLsum  | fm: 81.952 | p: 81.758 | r: 82.167
r1fm+r2fm = 153.333

input #9 time: 0:08:10 | total time: 1:22:50


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9989484440257819
highest_index [0]
highest [0.9989484440257819]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 0.796733558177948 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 0.7741899490356445 for ['[CLS] university mitaonaefa never existing gym backed ribs realmsund odd [SEP]']
[Init] best rec loss: 0.746838390827179 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 0.6623549461364746 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 0.6601974368095398 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 0.6590364575386047 for ['[CLS]blood common angeloric up sheep order blessed sound level totally places themes [SEP]']
[Init] best perm rec loss: 0.6576473712921143 for ['[CLS] places totally order leveloric themes up blessed common sound sheep angelblood [SEP]']
[Init] best perm rec loss: 0.6570503115653992 for ['[CLS] common up soundblood sheep totally blessed angel level places themesoric order [SEP]']
[Init] best perm rec loss: 0.6562265157699585 for ['[CLS] totally level blessed sheep up themes places angeloricblood common sound order [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.708 (perp=11.987, rec=0.286, cos=0.024), tot_loss_proj:3.382 [t=0.19s]
prediction: ['[CLS] and focuses and empirical lennox abablely indirectly ab sound balance balance [SEP]']
[ 100/2000] tot_loss=2.529 (perp=11.662, rec=0.186, cos=0.010), tot_loss_proj:3.105 [t=0.22s]
prediction: ['[CLS] and reveal real objective veteran ablyly directlyly rhythms balance balance [SEP]']
[ 150/2000] tot_loss=2.341 (perp=10.909, rec=0.151, cos=0.008), tot_loss_proj:2.796 [t=0.21s]
prediction: ['[CLS] and making realulsive veteran ablyly impulsely rhythms incident balance [SEP]']
[ 200/2000] tot_loss=2.522 (perp=11.902, rec=0.133, cos=0.008), tot_loss_proj:3.291 [t=0.20s]
prediction: ['[CLS] and prop realulsive owned ablyly impulsely rhythms incident balance [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.536 (perp=10.784, rec=0.339, cos=0.040), tot_loss_proj:2.858 [t=0.27s]
prediction: ['[CLS] prop prop incident balance realulsive veteran ablyly impulsely rhythms [SEP]']
[ 300/2000] tot_loss=2.509 (perp=11.321, rec=0.218, cos=0.027), tot_loss_proj:2.864 [t=0.19s]
prediction: ['[CLS] prop begin incident balance realulsive forefront ably withulsively rhythms [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.376 (perp=10.632, rec=0.211, cos=0.039), tot_loss_proj:2.760 [t=0.19s]
prediction: ["[CLS] theater incident balance realulsiveulsive ably with 'ulsively rhythms [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.186 (perp=9.801, rec=0.184, cos=0.042), tot_loss_proj:2.563 [t=0.19s]
prediction: ['[CLS]ulsive incident balance realulsive theater ably with everulsively rhythms [SEP]']
[ 450/2000] tot_loss=2.104 (perp=9.325, rec=0.187, cos=0.052), tot_loss_proj:2.417 [t=0.18s]
prediction: ["[CLS]ulsive incident balance real time theater ably with 'ulsively rhythms [SEP]"]
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.095 (perp=9.351, rec=0.169, cos=0.056), tot_loss_proj:3.024 [t=0.18s]
prediction: ["[CLS] incident balance real time blond abclusively with 'ulsively rhythms [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.035 (perp=9.053, rec=0.167, cos=0.058), tot_loss_proj:2.974 [t=0.23s]
prediction: ["[CLS] incident balance real time blond abclusively with rhythmsulsively'[SEP]"]
[ 600/2000] tot_loss=2.047 (perp=9.053, rec=0.179, cos=0.058), tot_loss_proj:2.987 [t=0.23s]
prediction: ["[CLS] incident balance real time blond abclusively with rhythmsulsively'[SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.147 (perp=9.567, rec=0.176, cos=0.058), tot_loss_proj:2.769 [t=0.20s]
prediction: ["[CLS] incident balance real time'ab basedly with rhythmsulsively sessions [SEP]"]
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.025 (perp=8.971, rec=0.169, cos=0.062), tot_loss_proj:2.783 [t=0.22s]
prediction: ["[CLS] incident balance real time'ably with rhythmsulsively systems sessions [SEP]"]
[ 750/2000] tot_loss=2.018 (perp=8.971, rec=0.168, cos=0.056), tot_loss_proj:2.791 [t=0.22s]
prediction: ["[CLS] incident balance real time'ably with rhythmsulsively systems sessions [SEP]"]
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.859 (perp=8.692, rec=0.113, cos=0.007), tot_loss_proj:2.520 [t=0.22s]
prediction: ["[CLS] incident systems shoulders balance real time'ably with rhythmsulsively [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=2.056 (perp=9.705, rec=0.108, cos=0.007), tot_loss_proj:2.713 [t=0.21s]
prediction: ['[CLS] incident shoulders balance real time prop ably with based rhythmsulsively [SEP]']
[ 900/2000] tot_loss=2.037 (perp=9.705, rec=0.089, cos=0.007), tot_loss_proj:2.712 [t=0.22s]
prediction: ['[CLS] incident shoulders balance real time prop ably with based rhythmsulsively [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.840 (perp=8.626, rec=0.108, cos=0.007), tot_loss_proj:2.208 [t=0.19s]
prediction: ['[CLS] incident fighters balance real time propulsively with based rhythms ably [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.730 (perp=8.114, rec=0.101, cos=0.007), tot_loss_proj:2.055 [t=0.18s]
prediction: ['[CLS] incident fighters balance real time with propulsively based rhythms ably [SEP]']
[1050/2000] tot_loss=1.728 (perp=8.114, rec=0.099, cos=0.007), tot_loss_proj:2.043 [t=0.18s]
prediction: ['[CLS] incident fighters balance real time with propulsively based rhythms ably [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.700 (perp=7.996, rec=0.095, cos=0.007), tot_loss_proj:2.145 [t=0.23s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1150/2000] tot_loss=1.704 (perp=7.996, rec=0.099, cos=0.006), tot_loss_proj:2.142 [t=0.18s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
[1200/2000] tot_loss=1.703 (perp=7.996, rec=0.097, cos=0.007), tot_loss_proj:2.144 [t=0.21s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1250/2000] tot_loss=1.707 (perp=7.996, rec=0.101, cos=0.007), tot_loss_proj:2.144 [t=0.21s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1300/2000] tot_loss=1.703 (perp=7.996, rec=0.097, cos=0.007), tot_loss_proj:2.148 [t=0.24s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
[1350/2000] tot_loss=1.700 (perp=7.996, rec=0.094, cos=0.007), tot_loss_proj:2.141 [t=0.20s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1400/2000] tot_loss=1.704 (perp=7.996, rec=0.099, cos=0.006), tot_loss_proj:2.145 [t=0.18s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1450/2000] tot_loss=1.702 (perp=7.996, rec=0.096, cos=0.007), tot_loss_proj:2.149 [t=0.20s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
[1500/2000] tot_loss=1.695 (perp=7.996, rec=0.089, cos=0.006), tot_loss_proj:2.140 [t=0.23s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1550/2000] tot_loss=1.710 (perp=7.996, rec=0.104, cos=0.006), tot_loss_proj:2.142 [t=0.26s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1600/2000] tot_loss=1.700 (perp=7.996, rec=0.095, cos=0.006), tot_loss_proj:2.141 [t=0.24s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
[1650/2000] tot_loss=1.698 (perp=7.996, rec=0.092, cos=0.006), tot_loss_proj:2.137 [t=0.26s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1700/2000] tot_loss=1.698 (perp=7.996, rec=0.092, cos=0.006), tot_loss_proj:2.138 [t=0.18s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1750/2000] tot_loss=1.701 (perp=7.996, rec=0.096, cos=0.006), tot_loss_proj:2.141 [t=0.22s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
[1800/2000] tot_loss=1.712 (perp=7.996, rec=0.107, cos=0.006), tot_loss_proj:2.140 [t=0.23s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1850/2000] tot_loss=1.698 (perp=7.996, rec=0.093, cos=0.006), tot_loss_proj:2.148 [t=0.18s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[1900/2000] tot_loss=1.697 (perp=7.996, rec=0.091, cos=0.006), tot_loss_proj:2.134 [t=0.24s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
[1950/2000] tot_loss=1.697 (perp=7.996, rec=0.091, cos=0.006), tot_loss_proj:2.140 [t=0.18s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Attempt swap
[2000/2000] tot_loss=1.700 (perp=7.996, rec=0.095, cos=0.006), tot_loss_proj:2.144 [t=0.18s]
prediction: ['[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] incident balance fighters real time with propulsively based rhythms ably [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 66.667 | r: 80.000
rouge2     | fm: 10.000 | p: 9.091 | r: 11.111
rougeL     | fm: 45.455 | p: 41.667 | r: 50.000
rougeLsum  | fm: 45.455 | p: 41.667 | r: 50.000
r1fm+r2fm = 82.727

[Aggregate metrics]:
rouge1     | fm: 88.471 | p: 87.525 | r: 89.545
rouge2     | fm: 58.485 | p: 58.316 | r: 58.626
rougeL     | fm: 78.416 | p: 77.858 | r: 78.939
rougeLsum  | fm: 78.971 | p: 78.416 | r: 79.545
r1fm+r2fm = 146.956

input #10 time: 0:08:20 | total time: 1:31:11


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9986028654506885
highest_index [0]
highest [0.9986028654506885]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 0.8807545900344849 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 0.8697853088378906 for ['[CLS] changelift tonig half moth bodo contractgmche [SEP]']
[Init] best rec loss: 0.8275038599967957 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 0.7575719952583313 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 0.7556154727935791 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 0.7508075833320618 for ['[CLS]ture inlandvd tal me platform drawngu mile familiar [SEP]']
[Init] best perm rec loss: 0.749920666217804 for ['[CLS] mile drawn inland familiar me platformguvd talture [SEP]']
[Init] best perm rec loss: 0.7474204301834106 for ['[CLS] megu drawnvd platform mile familiarture tal inland [SEP]']
[Init] best perm rec loss: 0.7468851804733276 for ['[CLS]ture me inland drawn mile platform talvdgu familiar [SEP]']
[Init] best perm rec loss: 0.7468094229698181 for ['[CLS] inlandgu me tal platformture mile familiar drawnvd [SEP]']
[Init] best perm rec loss: 0.7468055486679077 for ['[CLS] me talgu inland mileturevd drawn platform familiar [SEP]']
[Init] best perm rec loss: 0.746592104434967 for ['[CLS] inlandgu drawn me talvd familiarture mile platform [SEP]']
[Init] best perm rec loss: 0.7452490329742432 for ['[CLS] familiar me talgu mile platform drawnvdture inland [SEP]']
[Init] best perm rec loss: 0.7438916563987732 for ['[CLS] tal meturevd mile platform familiar drawngu inland [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.949 (perp=12.967, rec=0.323, cos=0.033), tot_loss_proj:3.871 [t=0.24s]
prediction: ['[CLS] refused attempted stubborned attempt her refused refused gel refused [SEP]']
[ 100/2000] tot_loss=2.763 (perp=12.664, rec=0.218, cos=0.012), tot_loss_proj:3.535 [t=0.20s]
prediction: ['[CLS] stubborn attempted stubbornly attempt stubborn refused refused gel refused [SEP]']
[ 150/2000] tot_loss=2.628 (perp=12.233, rec=0.170, cos=0.012), tot_loss_proj:3.318 [t=0.21s]
prediction: ['[CLS] stubborn attempted wasly attempt stubborn stubborn that gel refused [SEP]']
[ 200/2000] tot_loss=2.564 (perp=12.018, rec=0.146, cos=0.014), tot_loss_proj:3.365 [t=0.25s]
prediction: ['[CLS] stubborn attempted wasly here stubborn stubborn that gel refused [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.322 (perp=11.001, rec=0.114, cos=0.008), tot_loss_proj:3.157 [t=0.24s]
prediction: ['[CLS] stubborn attempted was stubbornly here stubborn that gel refused [SEP]']
[ 300/2000] tot_loss=2.295 (perp=10.899, rec=0.107, cos=0.008), tot_loss_proj:3.151 [t=0.22s]
prediction: ['[CLS] stubborn attempted was stubbornly here here that gel refused [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.952 (perp=9.179, rec=0.109, cos=0.007), tot_loss_proj:2.940 [t=0.18s]
prediction: ['[CLS] here attempted was stubbornly stubborn here that gel refused [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.851 (perp=8.670, rec=0.112, cos=0.005), tot_loss_proj:2.439 [t=0.18s]
prediction: ['[CLS] here attempted was stubbornly stubborn here that refused gel [SEP]']
[ 450/2000] tot_loss=1.912 (perp=9.039, rec=0.097, cos=0.007), tot_loss_proj:2.602 [t=0.23s]
prediction: ['[CLS] here attempted was stubbornly stubborn that that refused gel [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.772 (perp=8.380, rec=0.090, cos=0.005), tot_loss_proj:2.326 [t=0.18s]
prediction: ['[CLS] here was attempted stubbornly stubborn being that refused gel [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.762 (perp=8.322, rec=0.093, cos=0.005), tot_loss_proj:2.328 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
[ 600/2000] tot_loss=1.748 (perp=8.322, rec=0.077, cos=0.007), tot_loss_proj:2.329 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.749 (perp=8.322, rec=0.079, cos=0.005), tot_loss_proj:2.325 [t=0.20s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.777 (perp=8.322, rec=0.109, cos=0.005), tot_loss_proj:2.327 [t=0.20s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
[ 750/2000] tot_loss=1.748 (perp=8.322, rec=0.078, cos=0.007), tot_loss_proj:2.330 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.748 (perp=8.322, rec=0.079, cos=0.005), tot_loss_proj:2.323 [t=0.21s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.750 (perp=8.322, rec=0.080, cos=0.005), tot_loss_proj:2.331 [t=0.18s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
[ 900/2000] tot_loss=1.755 (perp=8.322, rec=0.086, cos=0.005), tot_loss_proj:2.321 [t=0.18s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.747 (perp=8.322, rec=0.077, cos=0.005), tot_loss_proj:2.329 [t=0.18s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.742 (perp=8.322, rec=0.073, cos=0.005), tot_loss_proj:2.323 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
[1050/2000] tot_loss=1.740 (perp=8.322, rec=0.070, cos=0.006), tot_loss_proj:2.323 [t=0.18s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.748 (perp=8.322, rec=0.079, cos=0.005), tot_loss_proj:2.320 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.739 (perp=8.322, rec=0.069, cos=0.006), tot_loss_proj:2.327 [t=0.18s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
[1200/2000] tot_loss=1.746 (perp=8.322, rec=0.077, cos=0.005), tot_loss_proj:2.325 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.754 (perp=8.322, rec=0.085, cos=0.005), tot_loss_proj:2.332 [t=0.20s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.746 (perp=8.322, rec=0.076, cos=0.005), tot_loss_proj:2.326 [t=0.21s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
[1350/2000] tot_loss=1.747 (perp=8.322, rec=0.077, cos=0.005), tot_loss_proj:2.319 [t=0.22s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.747 (perp=8.322, rec=0.078, cos=0.005), tot_loss_proj:2.326 [t=0.25s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.752 (perp=8.322, rec=0.083, cos=0.005), tot_loss_proj:2.329 [t=0.20s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
[1500/2000] tot_loss=1.750 (perp=8.322, rec=0.081, cos=0.005), tot_loss_proj:2.319 [t=0.23s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.738 (perp=8.322, rec=0.069, cos=0.005), tot_loss_proj:2.327 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.763 (perp=8.353, rec=0.088, cos=0.005), tot_loss_proj:2.382 [t=0.21s]
prediction: ['[CLS] here was attempted stubbornly stubborn that being refused gel [SEP]']
[1650/2000] tot_loss=1.751 (perp=8.353, rec=0.075, cos=0.005), tot_loss_proj:2.382 [t=0.18s]
prediction: ['[CLS] here was attempted stubbornly stubborn that being refused gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.757 (perp=8.353, rec=0.082, cos=0.005), tot_loss_proj:2.377 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly stubborn that being refused gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.748 (perp=8.353, rec=0.072, cos=0.005), tot_loss_proj:2.377 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly stubborn that being refused gel [SEP]']
[1800/2000] tot_loss=1.754 (perp=8.353, rec=0.078, cos=0.005), tot_loss_proj:2.380 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly stubborn that being refused gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.759 (perp=8.353, rec=0.083, cos=0.005), tot_loss_proj:2.376 [t=0.21s]
prediction: ['[CLS] here was attempted stubbornly stubborn that being refused gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.754 (perp=8.353, rec=0.078, cos=0.005), tot_loss_proj:2.373 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly stubborn that being refused gel [SEP]']
[1950/2000] tot_loss=1.747 (perp=8.353, rec=0.072, cos=0.005), tot_loss_proj:2.382 [t=0.19s]
prediction: ['[CLS] here was attempted stubbornly stubborn that being refused gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.750 (perp=8.353, rec=0.074, cos=0.005), tot_loss_proj:2.387 [t=0.18s]
prediction: ['[CLS] here was attempted stubbornly stubborn that being refused gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was attempted stubbornly being stubborn that refused gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 10.000 | p: 10.000 | r: 10.000
rougeL     | fm: 63.636 | p: 63.636 | r: 63.636
rougeLsum  | fm: 63.636 | p: 63.636 | r: 63.636
r1fm+r2fm = 100.909

[Aggregate metrics]:
rouge1     | fm: 88.609 | p: 87.704 | r: 89.629
rouge2     | fm: 54.375 | p: 54.258 | r: 54.514
rougeL     | fm: 76.760 | p: 76.383 | r: 77.386
rougeLsum  | fm: 77.214 | p: 76.705 | r: 77.803
r1fm+r2fm = 142.984

input #11 time: 0:08:12 | total time: 1:39:23


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.9988047785062888
highest_index [0]
highest [0.9988047785062888]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 0.8671844005584717 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 0.8568954467773438 for ['[CLS] systems simonway met armenia blockade tongue when unisonizes and present reeve representatives [SEP]']
[Init] best rec loss: 0.7856228947639465 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 0.7831497192382812 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 0.7755429744720459 for ['[CLS] wolf rex usualli plant live painfully sqlamtpemi wallace du sort [SEP]']
[Init] best rec loss: 0.7728604674339294 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 0.7630936503410339 for ['[CLS] hear protocol heidi race strokes safety association transactions snail most place buried terror documentary [SEP]']
[Init] best rec loss: 0.7584690451622009 for ['[CLS] alive expression semiuid wise friend investigationthed beloved [MASK] got richards didnbank [SEP]']
[Init] best rec loss: 0.756440281867981 for ['[CLS] ruins league release compoundled twinned major also after touch cora sunday wicked appoint [SEP]']
[Init] best perm rec loss: 0.7511959075927734 for ['[CLS] cora appointled compound twinned release wicked sunday touch ruins also league after major [SEP]']
[Init] best perm rec loss: 0.7502198815345764 for ['[CLS] league sunday twinned ruins wicked release touch cora appoint compound majorled also after [SEP]']
[Init] best perm rec loss: 0.7502052187919617 for ['[CLS] also release compound wicked touchled major after cora twinned ruins league appoint sunday [SEP]']
[Init] best perm rec loss: 0.7486573457717896 for ['[CLS] twinned after sundayled release touch also ruins compound league wicked cora major appoint [SEP]']
[Init] best perm rec loss: 0.74770587682724 for ['[CLS] major twinned sunday after ruins also compound wicked league cora appoint release touchled [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.637 (perp=11.326, rec=0.318, cos=0.053), tot_loss_proj:3.400 [t=0.21s]
prediction: ['[CLS] better advantage neck lower almost for cable barely cable on hazards cable claims better [SEP]']
[ 100/2000] tot_loss=2.508 (perp=11.394, rec=0.208, cos=0.021), tot_loss_proj:3.311 [t=0.22s]
prediction: ['[CLS] better advantage neck barely must to advantage barely cable, consider cable barely better [SEP]']
[ 150/2000] tot_loss=2.411 (perp=11.254, rec=0.151, cos=0.010), tot_loss_proj:3.202 [t=0.18s]
prediction: ['[CLS] better advantage attention barely must will advantage barely cable on on cable considering better [SEP]']
[ 200/2000] tot_loss=2.256 (perp=10.618, rec=0.124, cos=0.009), tot_loss_proj:3.069 [t=0.18s]
prediction: ['[CLS] better advantage injury its even will seen barely cable, on cable considering better [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.004 (perp=9.415, rec=0.113, cos=0.008), tot_loss_proj:3.354 [t=0.28s]
prediction: ['[CLS] that its attention advantage which will seen barely cable on on cable considering better [SEP]']
[ 300/2000] tot_loss=1.982 (perp=9.366, rec=0.103, cos=0.005), tot_loss_proj:2.632 [t=0.23s]
prediction: ['[CLS] that its getting advantage to will seen barely cable to on cable considering better [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.104 (perp=10.006, rec=0.097, cos=0.006), tot_loss_proj:3.056 [t=0.24s]
prediction: ['[CLS] that its cable advantage especially will seen barely facto to on cable considering better [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.018 (perp=9.570, rec=0.099, cos=0.005), tot_loss_proj:2.958 [t=0.21s]
prediction: ['[CLS] that its cable advantage especially will seen barely toons on cable considering better [SEP]']
[ 450/2000] tot_loss=2.003 (perp=9.570, rec=0.084, cos=0.005), tot_loss_proj:2.955 [t=0.18s]
prediction: ['[CLS] that its cable advantage especially will seen barely toons on cable considering better [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.941 (perp=9.287, rec=0.079, cos=0.005), tot_loss_proj:2.744 [t=0.20s]
prediction: ['[CLS] that its cable advantage especially will barely seen toons on cable considering better [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.912 (perp=9.155, rec=0.076, cos=0.005), tot_loss_proj:2.629 [t=0.19s]
prediction: ['[CLS] that its cable advantageons will barely seen to especially on cable considering better [SEP]']
[ 600/2000] tot_loss=1.906 (perp=9.155, rec=0.070, cos=0.005), tot_loss_proj:2.628 [t=0.19s]
prediction: ['[CLS] that its cable advantageons will barely seen to especially on cable considering better [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.837 (perp=8.757, rec=0.081, cos=0.005), tot_loss_proj:2.587 [t=0.18s]
prediction: ['[CLS] that its cable advantageons will barely seen especially on cable to considering better [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.828 (perp=8.757, rec=0.072, cos=0.005), tot_loss_proj:2.592 [t=0.18s]
prediction: ['[CLS] that its cable advantageons will barely seen especially on cable to considering better [SEP]']
[ 750/2000] tot_loss=1.831 (perp=8.757, rec=0.075, cos=0.004), tot_loss_proj:2.583 [t=0.18s]
prediction: ['[CLS] that its cable advantageons will barely seen especially on cable to considering better [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.829 (perp=8.757, rec=0.074, cos=0.004), tot_loss_proj:2.591 [t=0.18s]
prediction: ['[CLS] that its cable advantageons will barely seen especially on cable to considering better [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.864 (perp=8.942, rec=0.071, cos=0.004), tot_loss_proj:2.562 [t=0.22s]
prediction: ['[CLS] that its cable advantage to will barely seen especially on cableons considering better [SEP]']
[ 900/2000] tot_loss=1.709 (perp=8.122, rec=0.080, cos=0.004), tot_loss_proj:2.418 [t=0.18s]
prediction: ['[CLS] that its cable advantage to will barely seen especially on cable ; considering better [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.625 (perp=7.687, rec=0.083, cos=0.005), tot_loss_proj:2.505 [t=0.20s]
prediction: ['[CLS] better its cable advantage to will barely seen especially on cable ; considering that [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.565 (perp=7.368, rec=0.086, cos=0.005), tot_loss_proj:2.374 [t=0.27s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
[1050/2000] tot_loss=1.547 (perp=7.368, rec=0.069, cos=0.004), tot_loss_proj:2.374 [t=0.23s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
Attempt swap
[1100/2000] tot_loss=1.554 (perp=7.368, rec=0.076, cos=0.004), tot_loss_proj:2.378 [t=0.30s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
Attempt swap
[1150/2000] tot_loss=1.548 (perp=7.368, rec=0.070, cos=0.004), tot_loss_proj:2.377 [t=0.22s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
[1200/2000] tot_loss=1.554 (perp=7.368, rec=0.076, cos=0.004), tot_loss_proj:2.371 [t=0.18s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
Attempt swap
[1250/2000] tot_loss=1.547 (perp=7.368, rec=0.069, cos=0.004), tot_loss_proj:2.372 [t=0.19s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
Attempt swap
[1300/2000] tot_loss=1.550 (perp=7.368, rec=0.072, cos=0.004), tot_loss_proj:2.378 [t=0.19s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
[1350/2000] tot_loss=1.550 (perp=7.368, rec=0.072, cos=0.004), tot_loss_proj:2.378 [t=0.18s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
Attempt swap
[1400/2000] tot_loss=1.545 (perp=7.368, rec=0.068, cos=0.004), tot_loss_proj:2.376 [t=0.18s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
Attempt swap
[1450/2000] tot_loss=1.554 (perp=7.368, rec=0.076, cos=0.004), tot_loss_proj:2.370 [t=0.18s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
[1500/2000] tot_loss=1.547 (perp=7.368, rec=0.070, cos=0.004), tot_loss_proj:2.373 [t=0.24s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
Attempt swap
[1550/2000] tot_loss=1.544 (perp=7.368, rec=0.066, cos=0.004), tot_loss_proj:2.376 [t=0.23s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
Attempt swap
[1600/2000] tot_loss=1.556 (perp=7.368, rec=0.078, cos=0.004), tot_loss_proj:2.378 [t=0.18s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]']
[1650/2000] tot_loss=1.494 (perp=7.117, rec=0.067, cos=0.004), tot_loss_proj:2.299 [t=0.18s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable, considering that [SEP]']
Attempt swap
[1700/2000] tot_loss=1.505 (perp=7.117, rec=0.077, cos=0.004), tot_loss_proj:2.298 [t=0.19s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable, considering that [SEP]']
Attempt swap
[1750/2000] tot_loss=1.508 (perp=7.117, rec=0.080, cos=0.004), tot_loss_proj:2.296 [t=0.19s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable, considering that [SEP]']
[1800/2000] tot_loss=1.506 (perp=7.117, rec=0.078, cos=0.004), tot_loss_proj:2.297 [t=0.20s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable, considering that [SEP]']
Attempt swap
[1850/2000] tot_loss=1.498 (perp=7.117, rec=0.070, cos=0.004), tot_loss_proj:2.298 [t=0.19s]
prediction: ['[CLS] especially its cable advantage to will barely seen better on cable, considering that [SEP]']
Attempt swap
Moved sequence
[1900/2000] tot_loss=1.498 (perp=7.100, rec=0.074, cos=0.004), tot_loss_proj:2.360 [t=0.26s]
prediction: ['[CLS] especially its cable advantage to will barely better seen on cable, considering that [SEP]']
[1950/2000] tot_loss=1.492 (perp=7.100, rec=0.068, cos=0.004), tot_loss_proj:2.362 [t=0.19s]
prediction: ['[CLS] especially its cable advantage to will barely better seen on cable, considering that [SEP]']
Attempt swap
[2000/2000] tot_loss=1.499 (perp=7.100, rec=0.075, cos=0.004), tot_loss_proj:2.358 [t=0.33s]
prediction: ['[CLS] especially its cable advantage to will barely better seen on cable, considering that [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] especially its cable advantage to will barely seen better on cable ; considering that [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 7.143 | p: 7.143 | r: 7.143
rougeL     | fm: 53.333 | p: 53.333 | r: 53.333
rougeLsum  | fm: 53.333 | p: 53.333 | r: 53.333
r1fm+r2fm = 100.476

[Aggregate metrics]:
rouge1     | fm: 88.906 | p: 88.107 | r: 89.898
rouge2     | fm: 50.586 | p: 50.435 | r: 50.732
rougeL     | fm: 74.992 | p: 74.505 | r: 75.536
rougeLsum  | fm: 74.800 | p: 74.277 | r: 75.291
r1fm+r2fm = 139.492

input #12 time: 0:08:26 | total time: 1:47:50


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9987130703446319
highest_index [0]
highest [0.9987130703446319]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 0.7244099378585815 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 0.697172999382019 for ['[CLS] baccalaureate, black saunderstec armed much [SEP]']
[Init] best rec loss: 0.6967779397964478 for ['[CLS] armchairitic from arrived operation negative india [SEP]']
[Init] best perm rec loss: 0.6966491341590881 for ['[CLS] arrived india fromitic operation armchair negative [SEP]']
[Init] best perm rec loss: 0.6965093016624451 for ['[CLS]itic armchair from operation india negative arrived [SEP]']
[Init] best perm rec loss: 0.6959060430526733 for ['[CLS]itic india from armchair arrived negative operation [SEP]']
[Init] best perm rec loss: 0.6956750154495239 for ['[CLS] operation negative arriveditic armchair india from [SEP]']
[Init] best perm rec loss: 0.6952217221260071 for ['[CLS] arrived indiaitic armchair from negative operation [SEP]']
[Init] best perm rec loss: 0.6939332485198975 for ['[CLS]itic arrived from armchair operation india negative [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.591 (perp=11.190, rec=0.281, cos=0.072), tot_loss_proj:3.136 [t=0.21s]
prediction: ['[CLS] point point bullshit into flame into flame [SEP]']
[ 100/2000] tot_loss=2.351 (perp=11.133, rec=0.116, cos=0.008), tot_loss_proj:2.841 [t=0.20s]
prediction: ['[CLS] point at things into flame explode flame [SEP]']
[ 150/2000] tot_loss=2.320 (perp=11.133, rec=0.087, cos=0.006), tot_loss_proj:2.815 [t=0.24s]
prediction: ['[CLS] point at things into flame explode flame [SEP]']
[ 200/2000] tot_loss=2.328 (perp=11.133, rec=0.090, cos=0.011), tot_loss_proj:2.810 [t=0.19s]
prediction: ['[CLS] point at things into flame explode flame [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.823 (perp=8.657, rec=0.086, cos=0.005), tot_loss_proj:2.383 [t=0.19s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
[ 300/2000] tot_loss=1.825 (perp=8.657, rec=0.086, cos=0.007), tot_loss_proj:2.383 [t=0.24s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.821 (perp=8.657, rec=0.085, cos=0.004), tot_loss_proj:2.376 [t=0.25s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.816 (perp=8.657, rec=0.080, cos=0.004), tot_loss_proj:2.376 [t=0.18s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
[ 450/2000] tot_loss=1.808 (perp=8.657, rec=0.072, cos=0.004), tot_loss_proj:2.374 [t=0.18s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.820 (perp=8.657, rec=0.084, cos=0.004), tot_loss_proj:2.365 [t=0.23s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.818 (perp=8.657, rec=0.083, cos=0.004), tot_loss_proj:2.369 [t=0.25s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
[ 600/2000] tot_loss=1.817 (perp=8.657, rec=0.082, cos=0.004), tot_loss_proj:2.372 [t=0.18s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.813 (perp=8.657, rec=0.077, cos=0.004), tot_loss_proj:2.364 [t=0.21s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.815 (perp=8.657, rec=0.080, cos=0.003), tot_loss_proj:2.367 [t=0.18s]
prediction: ['[CLS] point at things flame explode into flame [SEP]']
[ 750/2000] tot_loss=1.878 (perp=9.034, rec=0.069, cos=0.003), tot_loss_proj:2.571 [t=0.18s]
prediction: ['[CLS] point at things flame explode into things [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.935 (perp=9.337, rec=0.065, cos=0.003), tot_loss_proj:2.928 [t=0.19s]
prediction: ['[CLS] point at that flame explode into things [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.722 (perp=8.227, rec=0.071, cos=0.006), tot_loss_proj:2.623 [t=0.18s]
prediction: ['[CLS] flame at that point explode into things [SEP]']
[ 900/2000] tot_loss=1.714 (perp=8.227, rec=0.066, cos=0.003), tot_loss_proj:2.624 [t=0.19s]
prediction: ['[CLS] flame at that point explode into things [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.378 (perp=6.527, rec=0.070, cos=0.003), tot_loss_proj:2.042 [t=0.18s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1000/2000] tot_loss=1.372 (perp=6.527, rec=0.064, cos=0.003), tot_loss_proj:2.046 [t=0.24s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
[1050/2000] tot_loss=1.378 (perp=6.527, rec=0.070, cos=0.003), tot_loss_proj:2.047 [t=0.25s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1100/2000] tot_loss=1.365 (perp=6.527, rec=0.057, cos=0.003), tot_loss_proj:2.047 [t=0.26s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1150/2000] tot_loss=1.371 (perp=6.527, rec=0.063, cos=0.003), tot_loss_proj:2.051 [t=0.18s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
[1200/2000] tot_loss=1.371 (perp=6.527, rec=0.064, cos=0.003), tot_loss_proj:2.044 [t=0.18s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1250/2000] tot_loss=1.370 (perp=6.527, rec=0.062, cos=0.003), tot_loss_proj:2.042 [t=0.18s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1300/2000] tot_loss=1.366 (perp=6.527, rec=0.058, cos=0.003), tot_loss_proj:2.050 [t=0.18s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
[1350/2000] tot_loss=1.383 (perp=6.527, rec=0.075, cos=0.003), tot_loss_proj:2.042 [t=0.19s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1400/2000] tot_loss=1.364 (perp=6.527, rec=0.056, cos=0.003), tot_loss_proj:2.040 [t=0.25s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1450/2000] tot_loss=1.371 (perp=6.527, rec=0.063, cos=0.003), tot_loss_proj:2.041 [t=0.23s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
[1500/2000] tot_loss=1.363 (perp=6.527, rec=0.055, cos=0.003), tot_loss_proj:2.049 [t=0.19s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1550/2000] tot_loss=1.377 (perp=6.527, rec=0.069, cos=0.003), tot_loss_proj:2.048 [t=0.19s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1600/2000] tot_loss=1.374 (perp=6.527, rec=0.066, cos=0.003), tot_loss_proj:2.044 [t=0.21s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
[1650/2000] tot_loss=1.372 (perp=6.527, rec=0.064, cos=0.003), tot_loss_proj:2.048 [t=0.18s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1700/2000] tot_loss=1.365 (perp=6.527, rec=0.057, cos=0.003), tot_loss_proj:2.043 [t=0.23s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1750/2000] tot_loss=1.370 (perp=6.527, rec=0.062, cos=0.003), tot_loss_proj:2.039 [t=0.18s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
[1800/2000] tot_loss=1.374 (perp=6.527, rec=0.066, cos=0.003), tot_loss_proj:2.045 [t=0.19s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1850/2000] tot_loss=1.370 (perp=6.527, rec=0.062, cos=0.003), tot_loss_proj:2.039 [t=0.28s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[1900/2000] tot_loss=1.374 (perp=6.527, rec=0.066, cos=0.003), tot_loss_proj:2.050 [t=0.25s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
[1950/2000] tot_loss=1.361 (perp=6.527, rec=0.053, cos=0.003), tot_loss_proj:2.045 [t=0.24s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Attempt swap
[2000/2000] tot_loss=1.366 (perp=6.527, rec=0.058, cos=0.003), tot_loss_proj:2.046 [t=0.23s]
prediction: ['[CLS] things at that point explode into flame [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] things at that point explode into flame [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 137.500

[Aggregate metrics]:
rouge1     | fm: 89.734 | p: 88.956 | r: 90.660
rouge2     | fm: 49.286 | p: 49.161 | r: 49.432
rougeL     | fm: 75.144 | p: 74.726 | r: 75.626
rougeLsum  | fm: 75.279 | p: 74.919 | r: 75.758
r1fm+r2fm = 139.020

input #13 time: 0:08:27 | total time: 1:56:17


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9986894364287884
highest_index [0]
highest [0.9986894364287884]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 0.9886805415153503 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 0.9870709776878357 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 0.9780771136283875 for ['[CLS] ocean relevantping list plum [SEP]']
[Init] best rec loss: 0.9737805724143982 for ['[CLS] appeared ins explosion deer stephen [SEP]']
[Init] best rec loss: 0.9679508209228516 for ['[CLS] female pants hard surely olympics [SEP]']
[Init] best rec loss: 0.965600848197937 for ['[CLS]rin eligibility grand haiti jay [SEP]']
[Init] best rec loss: 0.9632632732391357 for ['[CLS] math burning rangecino fritz [SEP]']
[Init] best rec loss: 0.9572461247444153 for ['[CLS] brooks mentioninianame nothing [SEP]']
[Init] best rec loss: 0.9523090720176697 for ['[CLS] tractor no massachusettsint vision [SEP]']
[Init] best rec loss: 0.9504384994506836 for ['[CLS] century delegates annie gun photography [SEP]']
[Init] best rec loss: 0.9486973285675049 for ['[CLS] diedecteration til share [SEP]']
[Init] best rec loss: 0.9423763751983643 for ['[CLS]wife bloodhun coach low [SEP]']
[Init] best rec loss: 0.9290497899055481 for ['[CLS] striker jade united ash siding [SEP]']
[Init] best perm rec loss: 0.9288198351860046 for ['[CLS] united jade ash siding striker [SEP]']
[Init] best perm rec loss: 0.928429365158081 for ['[CLS] united ash jade siding striker [SEP]']
[Init] best perm rec loss: 0.9283403754234314 for ['[CLS] siding jade ash striker united [SEP]']
[Init] best perm rec loss: 0.927172064781189 for ['[CLS] ash striker united siding jade [SEP]']
[Init] best perm rec loss: 0.9269252419471741 for ['[CLS] siding ash jade striker united [SEP]']
[Init] best perm rec loss: 0.9260293841362 for ['[CLS] united siding jade striker ash [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.303 (perp=13.468, rec=0.486, cos=0.123), tot_loss_proj:4.562 [t=0.20s]
prediction: ['[CLS] believed verity magnus prison thank [SEP]']
[ 100/2000] tot_loss=2.995 (perp=12.395, rec=0.369, cos=0.147), tot_loss_proj:3.446 [t=0.18s]
prediction: ['[CLS] intriguingᵏ tropicalneas intriguing [SEP]']
[ 150/2000] tot_loss=2.537 (perp=10.118, rec=0.340, cos=0.174), tot_loss_proj:2.688 [t=0.24s]
prediction: ['[CLS] intriguingeniablyusly intriguing [SEP]']
[ 200/2000] tot_loss=2.550 (perp=10.118, rec=0.309, cos=0.218), tot_loss_proj:2.695 [t=0.28s]
prediction: ['[CLS] intriguingeniablyusly intriguing [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.483 (perp=9.883, rec=0.296, cos=0.210), tot_loss_proj:2.383 [t=0.27s]
prediction: ['[CLS]eniably filmusly intriguing [SEP]']
[ 300/2000] tot_loss=2.470 (perp=9.883, rec=0.280, cos=0.214), tot_loss_proj:2.391 [t=0.19s]
prediction: ['[CLS]eniably filmusly intriguing [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.669 (perp=10.993, rec=0.260, cos=0.210), tot_loss_proj:3.355 [t=0.19s]
prediction: ['[CLS]eniably filmiating intriguing [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.663 (perp=10.685, rec=0.288, cos=0.238), tot_loss_proj:2.733 [t=0.18s]
prediction: ['[CLS]eniably intriguingusly film [SEP]']
[ 450/2000] tot_loss=2.607 (perp=10.685, rec=0.255, cos=0.215), tot_loss_proj:2.736 [t=0.17s]
prediction: ['[CLS]eniably intriguingusly film [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=3.024 (perp=12.703, rec=0.280, cos=0.204), tot_loss_proj:3.747 [t=0.21s]
prediction: ['[CLS]ignanteniaiful intriguing film [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.859 (perp=11.922, rec=0.266, cos=0.209), tot_loss_proj:3.413 [t=0.18s]
prediction: ['[CLS]eniaignantiful intriguing film [SEP]']
[ 600/2000] tot_loss=2.753 (perp=11.432, rec=0.259, cos=0.208), tot_loss_proj:2.558 [t=0.18s]
prediction: ['[CLS]eniaignantbly intriguing film [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.202 (perp=8.595, rec=0.272, cos=0.211), tot_loss_proj:2.014 [t=0.19s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.181 (perp=8.595, rec=0.234, cos=0.228), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
[ 750/2000] tot_loss=2.167 (perp=8.595, rec=0.219, cos=0.228), tot_loss_proj:2.012 [t=0.24s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.170 (perp=8.595, rec=0.223, cos=0.229), tot_loss_proj:2.021 [t=0.19s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.182 (perp=8.595, rec=0.228, cos=0.235), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
[ 900/2000] tot_loss=2.206 (perp=8.595, rec=0.258, cos=0.229), tot_loss_proj:2.013 [t=0.18s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.184 (perp=8.595, rec=0.226, cos=0.238), tot_loss_proj:2.011 [t=0.23s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=2.191 (perp=8.595, rec=0.237, cos=0.235), tot_loss_proj:2.008 [t=0.22s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
[1050/2000] tot_loss=2.177 (perp=8.595, rec=0.224, cos=0.234), tot_loss_proj:2.013 [t=0.18s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=2.178 (perp=8.595, rec=0.226, cos=0.233), tot_loss_proj:2.005 [t=0.22s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=2.177 (perp=8.595, rec=0.228, cos=0.230), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
[1200/2000] tot_loss=2.174 (perp=8.595, rec=0.222, cos=0.234), tot_loss_proj:2.025 [t=0.19s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=2.193 (perp=8.595, rec=0.238, cos=0.236), tot_loss_proj:2.008 [t=0.19s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=2.182 (perp=8.595, rec=0.226, cos=0.237), tot_loss_proj:2.007 [t=0.18s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
[1350/2000] tot_loss=2.167 (perp=8.595, rec=0.213, cos=0.234), tot_loss_proj:2.013 [t=0.19s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=2.181 (perp=8.595, rec=0.225, cos=0.237), tot_loss_proj:2.013 [t=0.18s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=2.181 (perp=8.595, rec=0.224, cos=0.238), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
[1500/2000] tot_loss=2.187 (perp=8.595, rec=0.234, cos=0.233), tot_loss_proj:2.018 [t=0.25s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=2.177 (perp=8.595, rec=0.223, cos=0.235), tot_loss_proj:2.009 [t=0.18s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=2.180 (perp=8.595, rec=0.228, cos=0.233), tot_loss_proj:2.014 [t=0.22s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
[1650/2000] tot_loss=2.175 (perp=8.595, rec=0.223, cos=0.232), tot_loss_proj:2.019 [t=0.20s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=2.181 (perp=8.595, rec=0.226, cos=0.236), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=2.180 (perp=8.595, rec=0.225, cos=0.236), tot_loss_proj:2.015 [t=0.23s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
[1800/2000] tot_loss=2.188 (perp=8.595, rec=0.234, cos=0.235), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=2.184 (perp=8.595, rec=0.231, cos=0.234), tot_loss_proj:2.017 [t=0.25s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=2.182 (perp=8.595, rec=0.230, cos=0.234), tot_loss_proj:2.009 [t=0.22s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
[1950/2000] tot_loss=2.179 (perp=8.595, rec=0.223, cos=0.237), tot_loss_proj:2.023 [t=0.27s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=2.178 (perp=8.595, rec=0.225, cos=0.234), tot_loss_proj:2.011 [t=0.30s]
prediction: ['[CLS]ignanteniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS]ignanteniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 88.965 | p: 88.284 | r: 89.759
rouge2     | fm: 49.278 | p: 49.146 | r: 49.352
rougeL     | fm: 75.515 | p: 75.145 | r: 75.880
rougeLsum  | fm: 75.739 | p: 75.372 | r: 76.214
r1fm+r2fm = 138.243

input #14 time: 0:08:22 | total time: 2:04:39


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9986809779093262
highest_index [0]
highest [0.9986809779093262]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 0.873100996017456 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 0.8654344081878662 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 0.8580591678619385 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 0.8505675196647644 for ['[CLS] universe honor becky romanized dc source bucks where [SEP]']
[Init] best rec loss: 0.8478925228118896 for ['[CLS] tower titans road photos trace oh board alone [SEP]']
[Init] best rec loss: 0.8443586826324463 for ['[CLS] attractive duncan belle believeiver shotgun hitch florida [SEP]']
[Init] best rec loss: 0.8378604054450989 for ['[CLS] [CLS] martha diner consumer much troopergly safe [SEP]']
[Init] best rec loss: 0.8309980630874634 for ['[CLS]ₑ scouts jeffital near mills reserveignment [SEP]']
[Init] best perm rec loss: 0.8298674821853638 for ['[CLS] near reserveital jeff millsₑ scoutsignment [SEP]']
[Init] best perm rec loss: 0.8297567367553711 for ['[CLS] mills reserve near jeffignment scoutsitalₑ [SEP]']
[Init] best perm rec loss: 0.829018235206604 for ['[CLS] reserveignmentₑ mills scoutsital jeff near [SEP]']
[Init] best perm rec loss: 0.8287711143493652 for ['[CLS] scoutsitalignment millsₑ jeff near reserve [SEP]']
[Init] best perm rec loss: 0.8276447653770447 for ['[CLS] reserveₑital mills scoutsignment jeff near [SEP]']
[Init] best perm rec loss: 0.8272281289100647 for ['[CLS] reserve nearₑ jeff millsignment scoutsital [SEP]']
[Init] best perm rec loss: 0.8271809220314026 for ['[CLS] jeff reserve millsitalₑ scouts nearignment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.502 (perp=11.311, rec=0.232, cos=0.008), tot_loss_proj:3.204 [t=0.18s]
prediction: ['[CLS] efficient efficientably anonymous efficient bodyguardable! [SEP]']
[ 100/2000] tot_loss=2.285 (perp=10.534, rec=0.174, cos=0.004), tot_loss_proj:2.913 [t=0.18s]
prediction: ['[CLS] efficient efficient suit chillably chill chill. [SEP]']
[ 150/2000] tot_loss=2.263 (perp=10.534, rec=0.151, cos=0.005), tot_loss_proj:2.906 [t=0.19s]
prediction: ['[CLS] efficient efficient suit chillably chill chill. [SEP]']
[ 200/2000] tot_loss=2.344 (perp=10.878, rec=0.162, cos=0.006), tot_loss_proj:3.349 [t=0.22s]
prediction: ['[CLS] anonymous efficient suit chillably chill chill. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.974 (perp=9.224, rec=0.126, cos=0.003), tot_loss_proj:2.863 [t=0.21s]
prediction: ['[CLS] anonymous efficient suitablyer chiller. [SEP]']
[ 300/2000] tot_loss=2.241 (perp=10.708, rec=0.097, cos=0.003), tot_loss_proj:3.571 [t=0.22s]
prediction: ['[CLS] anonymous efficient suitablyer chill anonymous. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.843 (perp=8.774, rec=0.084, cos=0.003), tot_loss_proj:2.666 [t=0.24s]
prediction: ['[CLS] anonymous efficient suitably anonymous chiller. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.719 (perp=8.014, rec=0.110, cos=0.006), tot_loss_proj:1.931 [t=0.18s]
prediction: ['[CLS] efficient suitably anonymous anonymous chiller. [SEP]']
[ 450/2000] tot_loss=1.703 (perp=8.014, rec=0.095, cos=0.006), tot_loss_proj:1.925 [t=0.18s]
prediction: ['[CLS] efficient suitably anonymous anonymous chiller. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.632 (perp=7.660, rec=0.094, cos=0.006), tot_loss_proj:1.806 [t=0.25s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.633 (perp=7.660, rec=0.095, cos=0.006), tot_loss_proj:1.799 [t=0.26s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
[ 600/2000] tot_loss=1.633 (perp=7.660, rec=0.095, cos=0.006), tot_loss_proj:1.805 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.634 (perp=7.660, rec=0.096, cos=0.006), tot_loss_proj:1.801 [t=0.23s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.623 (perp=7.660, rec=0.085, cos=0.006), tot_loss_proj:1.809 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
[ 750/2000] tot_loss=1.625 (perp=7.660, rec=0.088, cos=0.006), tot_loss_proj:1.799 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.623 (perp=7.660, rec=0.085, cos=0.006), tot_loss_proj:1.806 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.632 (perp=7.660, rec=0.094, cos=0.006), tot_loss_proj:1.799 [t=0.28s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
[ 900/2000] tot_loss=1.625 (perp=7.660, rec=0.087, cos=0.006), tot_loss_proj:1.795 [t=0.30s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.624 (perp=7.660, rec=0.086, cos=0.006), tot_loss_proj:1.799 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.623 (perp=7.660, rec=0.085, cos=0.006), tot_loss_proj:1.801 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
[1050/2000] tot_loss=1.627 (perp=7.660, rec=0.089, cos=0.006), tot_loss_proj:1.807 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.608 (perp=7.660, rec=0.071, cos=0.006), tot_loss_proj:1.802 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.619 (perp=7.660, rec=0.081, cos=0.006), tot_loss_proj:1.799 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
[1200/2000] tot_loss=1.619 (perp=7.660, rec=0.081, cos=0.006), tot_loss_proj:1.807 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.610 (perp=7.660, rec=0.072, cos=0.006), tot_loss_proj:1.796 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous anonymous chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.581 (perp=7.507, rec=0.074, cos=0.006), tot_loss_proj:1.800 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous, chiller. [SEP]']
[1350/2000] tot_loss=1.576 (perp=7.507, rec=0.069, cos=0.006), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous, chiller. [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.418 (perp=6.697, rec=0.073, cos=0.006), tot_loss_proj:1.523 [t=0.18s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.423 (perp=6.697, rec=0.078, cos=0.006), tot_loss_proj:1.513 [t=0.18s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1500/2000] tot_loss=1.421 (perp=6.697, rec=0.076, cos=0.006), tot_loss_proj:1.522 [t=0.24s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.414 (perp=6.697, rec=0.069, cos=0.006), tot_loss_proj:1.523 [t=0.18s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.410 (perp=6.697, rec=0.065, cos=0.006), tot_loss_proj:1.523 [t=0.18s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1650/2000] tot_loss=1.414 (perp=6.697, rec=0.069, cos=0.006), tot_loss_proj:1.530 [t=0.19s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.414 (perp=6.697, rec=0.069, cos=0.006), tot_loss_proj:1.517 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.416 (perp=6.697, rec=0.071, cos=0.006), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1800/2000] tot_loss=1.430 (perp=6.697, rec=0.085, cos=0.006), tot_loss_proj:1.522 [t=0.25s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.413 (perp=6.697, rec=0.068, cos=0.006), tot_loss_proj:1.522 [t=0.21s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.426 (perp=6.697, rec=0.081, cos=0.006), tot_loss_proj:1.524 [t=0.18s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
[1950/2000] tot_loss=1.423 (perp=6.697, rec=0.078, cos=0.006), tot_loss_proj:1.527 [t=0.19s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.420 (perp=6.697, rec=0.075, cos=0.006), tot_loss_proj:1.524 [t=0.22s]
prediction: ['[CLS] suitably efficient, anonymous chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient, anonymous chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 89.608 | p: 89.073 | r: 90.374
rouge2     | fm: 48.914 | p: 48.813 | r: 49.126
rougeL     | fm: 76.003 | p: 75.636 | r: 76.443
rougeLsum  | fm: 75.980 | p: 75.628 | r: 76.424
r1fm+r2fm = 138.521

input #15 time: 0:08:17 | total time: 2:12:57


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9987599238674777
highest_index [0]
highest [0.9987599238674777]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 0.8345687389373779 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 0.7980451583862305 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 0.7602971196174622 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 0.7549031376838684 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 0.7360859513282776 for ['[CLS] bountyign appropriate tongue himself serie [SEP]']
[Init] best rec loss: 0.7314200401306152 for ['[CLS] hermic clement glass dig mount [SEP]']
[Init] best rec loss: 0.7112704515457153 for ['[CLS] influence device lighthouse whatever user employee [SEP]']
[Init] best rec loss: 0.7081174254417419 for ['[CLS] dynamic logicsivenessy fast square [SEP]']
[Init] best perm rec loss: 0.7054397463798523 for ['[CLS] dynamic logic squaresive fastnessy [SEP]']
[Init] best perm rec loss: 0.705224335193634 for ['[CLS] square fast dynamic logicnessysive [SEP]']
[Init] best perm rec loss: 0.704889714717865 for ['[CLS]nessy fast logic squaresive dynamic [SEP]']
[Init] best perm rec loss: 0.704724133014679 for ['[CLS] fastnessy logic dynamic squaresive [SEP]']
[Init] best perm rec loss: 0.7042863965034485 for ['[CLS]nessy dynamic fastsive logic square [SEP]']
[Init] best perm rec loss: 0.7022446990013123 for ['[CLS] dynamic logic fastnessy squaresive [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.765 (perp=11.496, rec=0.369, cos=0.097), tot_loss_proj:3.652 [t=0.18s]
prediction: ['[CLS], these [SEP]la more almost [SEP]']
[ 100/2000] tot_loss=1.456 (perp=6.107, rec=0.207, cos=0.027), tot_loss_proj:1.830 [t=0.21s]
prediction: ['[CLS] all of and all more this [SEP]']
[ 150/2000] tot_loss=1.589 (perp=7.372, rec=0.107, cos=0.008), tot_loss_proj:1.947 [t=0.20s]
prediction: ['[CLS] all of and, more this [SEP]']
[ 200/2000] tot_loss=1.544 (perp=7.372, rec=0.067, cos=0.003), tot_loss_proj:1.947 [t=0.18s]
prediction: ['[CLS] all of and, more this [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.225 (perp=5.769, rec=0.068, cos=0.003), tot_loss_proj:1.592 [t=0.18s]
prediction: ['[CLS] all of this, more and [SEP]']
[ 300/2000] tot_loss=1.222 (perp=5.769, rec=0.065, cos=0.003), tot_loss_proj:1.583 [t=0.21s]
prediction: ['[CLS] all of this, more and [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.001 (perp=4.697, rec=0.060, cos=0.002), tot_loss_proj:1.095 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.013 (perp=4.697, rec=0.071, cos=0.002), tot_loss_proj:1.094 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 450/2000] tot_loss=1.004 (perp=4.697, rec=0.062, cos=0.002), tot_loss_proj:1.094 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.001 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.091 [t=0.28s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 550/2000] tot_loss=0.993 (perp=4.697, rec=0.051, cos=0.002), tot_loss_proj:1.089 [t=0.27s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 600/2000] tot_loss=1.006 (perp=4.697, rec=0.064, cos=0.002), tot_loss_proj:1.092 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.005 (perp=4.697, rec=0.063, cos=0.002), tot_loss_proj:1.101 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.005 (perp=4.697, rec=0.063, cos=0.002), tot_loss_proj:1.102 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 750/2000] tot_loss=1.006 (perp=4.697, rec=0.064, cos=0.002), tot_loss_proj:1.103 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 800/2000] tot_loss=0.995 (perp=4.697, rec=0.053, cos=0.002), tot_loss_proj:1.088 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.004 (perp=4.697, rec=0.063, cos=0.002), tot_loss_proj:1.093 [t=0.20s]
prediction: ['[CLS] all of this, and more [SEP]']
[ 900/2000] tot_loss=1.002 (perp=4.697, rec=0.060, cos=0.002), tot_loss_proj:1.089 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[ 950/2000] tot_loss=0.999 (perp=4.697, rec=0.057, cos=0.002), tot_loss_proj:1.097 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1000/2000] tot_loss=0.996 (perp=4.697, rec=0.055, cos=0.002), tot_loss_proj:1.100 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
[1050/2000] tot_loss=1.000 (perp=4.697, rec=0.058, cos=0.002), tot_loss_proj:1.096 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.000 (perp=4.697, rec=0.058, cos=0.002), tot_loss_proj:1.087 [t=0.20s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.003 (perp=4.697, rec=0.061, cos=0.002), tot_loss_proj:1.098 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
[1200/2000] tot_loss=1.004 (perp=4.697, rec=0.062, cos=0.002), tot_loss_proj:1.096 [t=0.21s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1250/2000] tot_loss=0.989 (perp=4.697, rec=0.047, cos=0.002), tot_loss_proj:1.091 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.009 (perp=4.697, rec=0.067, cos=0.002), tot_loss_proj:1.093 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
[1350/2000] tot_loss=1.009 (perp=4.697, rec=0.067, cos=0.002), tot_loss_proj:1.088 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.000 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.093 [t=0.22s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1450/2000] tot_loss=0.994 (perp=4.697, rec=0.052, cos=0.002), tot_loss_proj:1.100 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
[1500/2000] tot_loss=0.992 (perp=4.697, rec=0.050, cos=0.002), tot_loss_proj:1.099 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.006 (perp=4.697, rec=0.064, cos=0.002), tot_loss_proj:1.099 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1600/2000] tot_loss=0.999 (perp=4.697, rec=0.057, cos=0.002), tot_loss_proj:1.091 [t=0.24s]
prediction: ['[CLS] all of this, and more [SEP]']
[1650/2000] tot_loss=1.001 (perp=4.697, rec=0.059, cos=0.002), tot_loss_proj:1.091 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.003 (perp=4.697, rec=0.061, cos=0.002), tot_loss_proj:1.100 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.000 (perp=4.697, rec=0.058, cos=0.002), tot_loss_proj:1.094 [t=0.20s]
prediction: ['[CLS] all of this, and more [SEP]']
[1800/2000] tot_loss=0.995 (perp=4.697, rec=0.053, cos=0.002), tot_loss_proj:1.102 [t=0.24s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.014 (perp=4.697, rec=0.073, cos=0.002), tot_loss_proj:1.099 [t=0.19s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.003 (perp=4.697, rec=0.061, cos=0.002), tot_loss_proj:1.096 [t=0.23s]
prediction: ['[CLS] all of this, and more [SEP]']
[1950/2000] tot_loss=1.007 (perp=4.697, rec=0.065, cos=0.002), tot_loss_proj:1.095 [t=0.25s]
prediction: ['[CLS] all of this, and more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.004 (perp=4.697, rec=0.062, cos=0.002), tot_loss_proj:1.091 [t=0.18s]
prediction: ['[CLS] all of this, and more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] all of this, and more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.268 | p: 89.698 | r: 90.985
rouge2     | fm: 51.975 | p: 51.874 | r: 52.087
rougeL     | fm: 77.954 | p: 77.643 | r: 78.220
rougeLsum  | fm: 77.808 | p: 77.460 | r: 78.082
r1fm+r2fm = 142.243

input #16 time: 0:08:21 | total time: 2:21:19


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9987595923559641
highest_index [0]
highest [0.9987595923559641]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 0.8125812411308289 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 0.8113617300987244 for ['[CLS] sunk following jointenberg ten onwardsair sour bis andre minority [SEP]']
[Init] best rec loss: 0.801008939743042 for ['[CLS] training cloud engineering cedar shipping hill scratch dal saxophone luke mueller [SEP]']
[Init] best rec loss: 0.7948780655860901 for ['[CLS] qualifierian justwicz countersnes sousa otherwise started lessons careers [SEP]']
[Init] best rec loss: 0.7942177653312683 for ['[CLS] staretha jack nur stone lied pointsmori richie sienna foot [SEP]']
[Init] best rec loss: 0.7888410091400146 for ['[CLS] parts voltagecrow k look flying cl thus lc pharaoh league [SEP]']
[Init] best rec loss: 0.7887375354766846 for ['[CLS] clan monopoly monty downstairs cy disposal hail wreck knights eden eye [SEP]']
[Init] best rec loss: 0.7883778214454651 for ['[CLS] cuba vu hurt trend khan loves scenario ashton ice captured servicing [SEP]']
[Init] best rec loss: 0.7863129377365112 for ['[CLS]ult nursing jealous crush potential slim as course sole original vigor [SEP]']
[Init] best perm rec loss: 0.785481333732605 for ['[CLS] nursing jealous slim original potential course vigor as soleult crush [SEP]']
[Init] best perm rec loss: 0.7850344181060791 for ['[CLS] course original slim sole nursing potential crush vigor jealous asult [SEP]']
[Init] best perm rec loss: 0.7836190462112427 for ['[CLS] nursing course potential crush slim originalult as vigor jealous sole [SEP]']
[Init] best perm rec loss: 0.7824971675872803 for ['[CLS] sole as crush nursingult jealous vigor slim course potential original [SEP]']
[Init] best perm rec loss: 0.7822069525718689 for ['[CLS] crush sole course nursing potential vigorult original jealous slim as [SEP]']
[Init] best perm rec loss: 0.782164990901947 for ['[CLS] nursing slim crush course jealousult as original vigor sole potential [SEP]']
[Init] best perm rec loss: 0.7787516713142395 for ['[CLS] jealous vigor crush slim nursing original courseult sole as potential [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.196 (perp=9.648, rec=0.235, cos=0.032), tot_loss_proj:3.083 [t=0.17s]
prediction: ['[CLS] too think desperately think much about want too alcohol too damage [SEP]']
[ 100/2000] tot_loss=2.136 (perp=10.206, rec=0.088, cos=0.007), tot_loss_proj:3.183 [t=0.21s]
prediction: ['[CLS] too think want think about about want much goings going [SEP]']
[ 150/2000] tot_loss=1.734 (perp=8.305, rec=0.069, cos=0.003), tot_loss_proj:2.594 [t=0.19s]
prediction: ['[CLS] too think to think about what want much what s going [SEP]']
[ 200/2000] tot_loss=1.811 (perp=8.723, rec=0.063, cos=0.003), tot_loss_proj:2.686 [t=0.20s]
prediction: ['[CLS] too think to think about what want much s on going [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.504 (perp=7.116, rec=0.078, cos=0.003), tot_loss_proj:2.339 [t=0.25s]
prediction: ['[CLS] too much think to think about what want s on going [SEP]']
[ 300/2000] tot_loss=1.476 (perp=7.116, rec=0.050, cos=0.003), tot_loss_proj:2.340 [t=0.20s]
prediction: ['[CLS] too much think to think about what want s on going [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.283 (perp=6.066, rec=0.068, cos=0.003), tot_loss_proj:2.135 [t=0.27s]
prediction: ['[CLS] too much think to think about what want s going on [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.156 (perp=5.377, rec=0.077, cos=0.003), tot_loss_proj:1.703 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[ 450/2000] tot_loss=1.148 (perp=5.377, rec=0.070, cos=0.003), tot_loss_proj:1.714 [t=0.24s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.149 (perp=5.377, rec=0.071, cos=0.003), tot_loss_proj:1.719 [t=0.21s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.151 (perp=5.377, rec=0.073, cos=0.003), tot_loss_proj:1.718 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[ 600/2000] tot_loss=1.155 (perp=5.377, rec=0.077, cos=0.002), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.151 (perp=5.377, rec=0.073, cos=0.003), tot_loss_proj:1.737 [t=0.19s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.153 (perp=5.377, rec=0.076, cos=0.003), tot_loss_proj:1.741 [t=0.19s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[ 750/2000] tot_loss=1.139 (perp=5.377, rec=0.061, cos=0.002), tot_loss_proj:1.741 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.134 (perp=5.377, rec=0.056, cos=0.003), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.140 (perp=5.377, rec=0.063, cos=0.002), tot_loss_proj:1.744 [t=0.24s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[ 900/2000] tot_loss=1.142 (perp=5.377, rec=0.064, cos=0.002), tot_loss_proj:1.750 [t=0.26s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.140 (perp=5.377, rec=0.062, cos=0.002), tot_loss_proj:1.751 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1000/2000] tot_loss=1.143 (perp=5.377, rec=0.065, cos=0.002), tot_loss_proj:1.759 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[1050/2000] tot_loss=1.144 (perp=5.377, rec=0.066, cos=0.002), tot_loss_proj:1.758 [t=0.22s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.144 (perp=5.377, rec=0.067, cos=0.002), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.143 (perp=5.377, rec=0.065, cos=0.002), tot_loss_proj:1.770 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[1200/2000] tot_loss=1.157 (perp=5.377, rec=0.080, cos=0.002), tot_loss_proj:1.767 [t=0.22s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1250/2000] tot_loss=1.144 (perp=5.377, rec=0.066, cos=0.002), tot_loss_proj:1.770 [t=0.24s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1300/2000] tot_loss=1.141 (perp=5.377, rec=0.063, cos=0.002), tot_loss_proj:1.771 [t=0.22s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[1350/2000] tot_loss=1.141 (perp=5.377, rec=0.064, cos=0.002), tot_loss_proj:1.771 [t=0.24s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.144 (perp=5.377, rec=0.066, cos=0.002), tot_loss_proj:1.768 [t=0.23s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.144 (perp=5.377, rec=0.066, cos=0.003), tot_loss_proj:1.775 [t=0.24s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[1500/2000] tot_loss=1.141 (perp=5.377, rec=0.063, cos=0.002), tot_loss_proj:1.782 [t=0.19s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1550/2000] tot_loss=1.133 (perp=5.377, rec=0.055, cos=0.002), tot_loss_proj:1.780 [t=0.19s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1600/2000] tot_loss=1.131 (perp=5.377, rec=0.053, cos=0.002), tot_loss_proj:1.774 [t=0.19s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[1650/2000] tot_loss=1.136 (perp=5.377, rec=0.058, cos=0.002), tot_loss_proj:1.779 [t=0.25s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1700/2000] tot_loss=1.133 (perp=5.377, rec=0.055, cos=0.002), tot_loss_proj:1.783 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1750/2000] tot_loss=1.128 (perp=5.377, rec=0.050, cos=0.002), tot_loss_proj:1.778 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[1800/2000] tot_loss=1.137 (perp=5.377, rec=0.060, cos=0.002), tot_loss_proj:1.783 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1850/2000] tot_loss=1.146 (perp=5.377, rec=0.068, cos=0.002), tot_loss_proj:1.771 [t=0.21s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[1900/2000] tot_loss=1.147 (perp=5.377, rec=0.069, cos=0.002), tot_loss_proj:1.781 [t=0.18s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
[1950/2000] tot_loss=1.147 (perp=5.377, rec=0.070, cos=0.002), tot_loss_proj:1.778 [t=0.24s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Attempt swap
[2000/2000] tot_loss=1.139 (perp=5.377, rec=0.061, cos=0.002), tot_loss_proj:1.780 [t=0.19s]
prediction: ['[CLS] too much think want to think about what s going on [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] too much think want to think about what s going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 69.565 | p: 66.667 | r: 72.727
rougeL     | fm: 80.000 | p: 76.923 | r: 83.333
rougeLsum  | fm: 80.000 | p: 76.923 | r: 83.333
r1fm+r2fm = 165.565

[Aggregate metrics]:
rouge1     | fm: 90.588 | p: 89.776 | r: 91.508
rouge2     | fm: 53.336 | p: 53.065 | r: 53.616
rougeL     | fm: 77.942 | p: 77.433 | r: 78.488
rougeLsum  | fm: 77.796 | p: 77.298 | r: 78.350
r1fm+r2fm = 143.924

input #17 time: 0:08:21 | total time: 2:29:40


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9987217710701053
highest_index [0]
highest [0.9987217710701053]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 1.0071908235549927 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 0.9391602873802185 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 0.9118751287460327 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 0.9055460691452026 for ['[CLS] openly died clockwise degree [SEP]']
[Init] best rec loss: 0.9050319194793701 for ['[CLS] master asteroidnagar fungi [SEP]']
[Init] best rec loss: 0.9033723473548889 for ['[CLS] clubs tallerptive magnetic [SEP]']
[Init] best rec loss: 0.9020410776138306 for ['[CLS]fire suffrage magdalene narrowly [SEP]']
[Init] best rec loss: 0.8888553380966187 for ['[CLS] independent battle old dried [SEP]']
[Init] best rec loss: 0.8888416886329651 for ['[CLS] zenor harmony after [SEP]']
[Init] best rec loss: 0.8852969408035278 for ['[CLS] statue difficult harta made [SEP]']
[Init] best rec loss: 0.8825945854187012 for ['[CLS] insteaduber nebula rancho [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.965 (perp=12.685, rec=0.396, cos=0.031), tot_loss_proj:3.728 [t=0.26s]
prediction: ['[CLS] remindingvigorstatic [SEP]']
[ 100/2000] tot_loss=2.395 (perp=10.264, rec=0.302, cos=0.040), tot_loss_proj:2.891 [t=0.18s]
prediction: ['[CLS] susannahvigorating [SEP]']
[ 150/2000] tot_loss=2.343 (perp=10.264, rec=0.254, cos=0.037), tot_loss_proj:2.888 [t=0.20s]
prediction: ['[CLS] susannahvigorating [SEP]']
[ 200/2000] tot_loss=2.321 (perp=10.264, rec=0.238, cos=0.030), tot_loss_proj:2.889 [t=0.19s]
prediction: ['[CLS] susannahvigorating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.384 (perp=5.588, rec=0.220, cos=0.047), tot_loss_proj:1.198 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.360 (perp=5.588, rec=0.216, cos=0.026), tot_loss_proj:1.192 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.364 (perp=5.588, rec=0.210, cos=0.036), tot_loss_proj:1.194 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.361 (perp=5.588, rec=0.204, cos=0.039), tot_loss_proj:1.189 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.375 (perp=5.588, rec=0.218, cos=0.040), tot_loss_proj:1.194 [t=0.21s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.357 (perp=5.588, rec=0.196, cos=0.043), tot_loss_proj:1.181 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.362 (perp=5.588, rec=0.200, cos=0.043), tot_loss_proj:1.181 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.344 (perp=5.588, rec=0.186, cos=0.040), tot_loss_proj:1.175 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.336 (perp=5.588, rec=0.182, cos=0.037), tot_loss_proj:1.198 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.344 (perp=5.588, rec=0.186, cos=0.041), tot_loss_proj:1.192 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.346 (perp=5.588, rec=0.185, cos=0.044), tot_loss_proj:1.182 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.342 (perp=5.588, rec=0.185, cos=0.040), tot_loss_proj:1.190 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.338 (perp=5.588, rec=0.177, cos=0.043), tot_loss_proj:1.190 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.342 (perp=5.588, rec=0.181, cos=0.044), tot_loss_proj:1.188 [t=0.29s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.334 (perp=5.588, rec=0.175, cos=0.041), tot_loss_proj:1.190 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.346 (perp=5.588, rec=0.182, cos=0.046), tot_loss_proj:1.188 [t=0.31s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.334 (perp=5.588, rec=0.170, cos=0.046), tot_loss_proj:1.195 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.334 (perp=5.588, rec=0.171, cos=0.045), tot_loss_proj:1.184 [t=0.21s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.331 (perp=5.588, rec=0.165, cos=0.048), tot_loss_proj:1.191 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.318 (perp=5.588, rec=0.153, cos=0.047), tot_loss_proj:1.187 [t=0.28s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.333 (perp=5.588, rec=0.167, cos=0.048), tot_loss_proj:1.187 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.344 (perp=5.588, rec=0.180, cos=0.046), tot_loss_proj:1.187 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.335 (perp=5.588, rec=0.171, cos=0.046), tot_loss_proj:1.197 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.342 (perp=5.588, rec=0.178, cos=0.046), tot_loss_proj:1.190 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.345 (perp=5.588, rec=0.176, cos=0.052), tot_loss_proj:1.166 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.338 (perp=5.588, rec=0.173, cos=0.047), tot_loss_proj:1.185 [t=0.17s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.327 (perp=5.588, rec=0.164, cos=0.045), tot_loss_proj:1.190 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.340 (perp=5.588, rec=0.177, cos=0.045), tot_loss_proj:1.178 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.351 (perp=5.588, rec=0.189, cos=0.044), tot_loss_proj:1.190 [t=0.21s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.337 (perp=5.588, rec=0.175, cos=0.044), tot_loss_proj:1.179 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.341 (perp=5.588, rec=0.178, cos=0.046), tot_loss_proj:1.186 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.342 (perp=5.588, rec=0.175, cos=0.049), tot_loss_proj:1.193 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.343 (perp=5.588, rec=0.177, cos=0.049), tot_loss_proj:1.182 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.319 (perp=5.588, rec=0.152, cos=0.049), tot_loss_proj:1.198 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.342 (perp=5.588, rec=0.175, cos=0.049), tot_loss_proj:1.203 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.332 (perp=5.588, rec=0.165, cos=0.049), tot_loss_proj:1.190 [t=0.21s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.107 | p: 90.399 | r: 91.871
rouge2     | fm: 55.624 | p: 55.427 | r: 56.029
rougeL     | fm: 79.013 | p: 78.622 | r: 79.532
rougeLsum  | fm: 78.949 | p: 78.466 | r: 79.417
r1fm+r2fm = 146.730

input #18 time: 0:08:19 | total time: 2:38:00


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9988014446812904
highest_index [0]
highest [0.9988014446812904]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 0.7222892642021179 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 0.722188413143158 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 0.7017906904220581 for ['[CLS] breedingies several lieutenant [SEP]']
[Init] best rec loss: 0.6938217282295227 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 0.6909639835357666 for ['[CLS] that muth file [SEP]']
[Init] best rec loss: 0.6896130442619324 for ['[CLS] griffin dressing man arched [SEP]']
[Init] best rec loss: 0.6883799433708191 for ['[CLS] voice material spots acre [SEP]']
[Init] best rec loss: 0.6818927526473999 for ['[CLS]yna reaching pin order [SEP]']
[Init] best perm rec loss: 0.6775478720664978 for ['[CLS] reaching pin orderyna [SEP]']
[Init] best perm rec loss: 0.6771998405456543 for ['[CLS] reaching orderyna pin [SEP]']
[Init] best perm rec loss: 0.676864504814148 for ['[CLS] reachingyna order pin [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.363 (perp=15.121, rec=0.285, cos=0.054), tot_loss_proj:4.181 [t=0.22s]
prediction: ['[CLS] infafafa [SEP]']
[ 100/2000] tot_loss=2.435 (perp=11.468, rec=0.132, cos=0.010), tot_loss_proj:3.447 [t=0.19s]
prediction: ['[CLS] tomyfamy [SEP]']
[ 150/2000] tot_loss=2.201 (perp=10.446, rec=0.105, cos=0.007), tot_loss_proj:3.057 [t=0.26s]
prediction: ['[CLS] inmyfamy [SEP]']
[ 200/2000] tot_loss=2.194 (perp=10.446, rec=0.097, cos=0.008), tot_loss_proj:3.059 [t=0.24s]
prediction: ['[CLS] inmyfamy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.075 (perp=9.749, rec=0.114, cos=0.011), tot_loss_proj:3.036 [t=0.24s]
prediction: ['[CLS] tofamymy [SEP]']
[ 300/2000] tot_loss=1.732 (perp=8.119, rec=0.103, cos=0.005), tot_loss_proj:2.240 [t=0.18s]
prediction: ['[CLS] infamymy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.720 (perp=8.119, rec=0.091, cos=0.005), tot_loss_proj:2.233 [t=0.18s]
prediction: ['[CLS] infamymy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.723 (perp=8.119, rec=0.095, cos=0.004), tot_loss_proj:2.243 [t=0.18s]
prediction: ['[CLS] infamymy [SEP]']
[ 450/2000] tot_loss=1.717 (perp=8.119, rec=0.089, cos=0.004), tot_loss_proj:2.231 [t=0.20s]
prediction: ['[CLS] infamymy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.724 (perp=8.119, rec=0.094, cos=0.006), tot_loss_proj:2.232 [t=0.18s]
prediction: ['[CLS] infamymy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.712 (perp=8.119, rec=0.084, cos=0.004), tot_loss_proj:2.232 [t=0.18s]
prediction: ['[CLS] infamymy [SEP]']
[ 600/2000] tot_loss=1.708 (perp=8.119, rec=0.081, cos=0.003), tot_loss_proj:2.231 [t=0.18s]
prediction: ['[CLS] infamymy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.707 (perp=8.119, rec=0.080, cos=0.003), tot_loss_proj:2.233 [t=0.19s]
prediction: ['[CLS] infamymy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.711 (perp=8.119, rec=0.084, cos=0.003), tot_loss_proj:2.220 [t=0.18s]
prediction: ['[CLS] infamymy [SEP]']
[ 750/2000] tot_loss=1.563 (perp=7.434, rec=0.073, cos=0.003), tot_loss_proj:1.973 [t=0.18s]
prediction: ['[CLS] infamy in [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.377 (perp=6.548, rec=0.065, cos=0.003), tot_loss_proj:1.723 [t=0.18s]
prediction: ['[CLS] in infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.384 (perp=6.548, rec=0.072, cos=0.003), tot_loss_proj:1.718 [t=0.23s]
prediction: ['[CLS] in infamy [SEP]']
[ 900/2000] tot_loss=1.382 (perp=6.548, rec=0.070, cos=0.003), tot_loss_proj:1.730 [t=0.20s]
prediction: ['[CLS] in infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.385 (perp=6.548, rec=0.073, cos=0.002), tot_loss_proj:1.722 [t=0.25s]
prediction: ['[CLS] in infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.373 (perp=6.548, rec=0.061, cos=0.002), tot_loss_proj:1.733 [t=0.25s]
prediction: ['[CLS] in infamy [SEP]']
[1050/2000] tot_loss=1.291 (perp=6.110, rec=0.067, cos=0.002), tot_loss_proj:1.303 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.278 (perp=6.110, rec=0.054, cos=0.002), tot_loss_proj:1.294 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.294 (perp=6.110, rec=0.069, cos=0.002), tot_loss_proj:1.293 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.279 (perp=6.110, rec=0.054, cos=0.002), tot_loss_proj:1.295 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.282 (perp=6.110, rec=0.057, cos=0.002), tot_loss_proj:1.286 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.283 (perp=6.110, rec=0.059, cos=0.002), tot_loss_proj:1.299 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.291 (perp=6.110, rec=0.067, cos=0.002), tot_loss_proj:1.311 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.285 (perp=6.110, rec=0.060, cos=0.002), tot_loss_proj:1.282 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.278 (perp=6.110, rec=0.054, cos=0.002), tot_loss_proj:1.307 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.295 (perp=6.110, rec=0.070, cos=0.002), tot_loss_proj:1.297 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.288 (perp=6.110, rec=0.063, cos=0.002), tot_loss_proj:1.275 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.291 (perp=6.110, rec=0.066, cos=0.002), tot_loss_proj:1.310 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.280 (perp=6.110, rec=0.056, cos=0.002), tot_loss_proj:1.306 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.288 (perp=6.110, rec=0.064, cos=0.002), tot_loss_proj:1.292 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.295 (perp=6.110, rec=0.071, cos=0.002), tot_loss_proj:1.293 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.294 (perp=6.110, rec=0.070, cos=0.002), tot_loss_proj:1.301 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.279 (perp=6.110, rec=0.055, cos=0.002), tot_loss_proj:1.294 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.285 (perp=6.110, rec=0.061, cos=0.002), tot_loss_proj:1.304 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.285 (perp=6.110, rec=0.060, cos=0.002), tot_loss_proj:1.286 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.273 (perp=6.110, rec=0.049, cos=0.002), tot_loss_proj:1.296 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 91.711 | p: 90.915 | r: 92.508
rouge2     | fm: 57.682 | p: 57.436 | r: 57.921
rougeL     | fm: 80.374 | p: 79.941 | r: 80.821
rougeLsum  | fm: 80.128 | p: 79.667 | r: 80.722
r1fm+r2fm = 149.393

input #19 time: 0:08:11 | total time: 2:46:11


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9988696440501421
highest_index [0]
highest [0.9988696440501421]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 0.8397797346115112 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 0.8261665105819702 for ['[CLS] map your included adventure [SEP]']
[Init] best rec loss: 0.8172202706336975 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 0.8095159530639648 for ['[CLS]±iae younger paranormal [SEP]']
[Init] best rec loss: 0.800568699836731 for ['[CLS] paper and indicationjah [SEP]']
[Init] best rec loss: 0.7951342463493347 for ['[CLS]vers extraction winode [SEP]']
[Init] best rec loss: 0.7832277417182922 for ['[CLS] historically hiroshima stand wing [SEP]']
[Init] best rec loss: 0.782712459564209 for ['[CLS] high kurtpass our [SEP]']
[Init] best rec loss: 0.776943564414978 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 0.7707585692405701 for ['[CLS]ness storylinexi [CLS] [SEP]']
[Init] best perm rec loss: 0.7689293026924133 for ['[CLS] storylinexiness [CLS] [SEP]']
[Init] best perm rec loss: 0.7688274383544922 for ['[CLS] storyline [CLS]nessxi [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.355 (perp=10.581, rec=0.203, cos=0.036), tot_loss_proj:3.048 [t=0.18s]
prediction: ['[CLS]verse pleasure mostverse [SEP]']
[ 100/2000] tot_loss=2.018 (perp=9.469, rec=0.109, cos=0.015), tot_loss_proj:2.765 [t=0.24s]
prediction: ['[CLS]verse pleasure perverse [SEP]']
[ 150/2000] tot_loss=1.899 (perp=9.139, rec=0.068, cos=0.003), tot_loss_proj:2.426 [t=0.19s]
prediction: ['[CLS] per pleasure perverse [SEP]']
[ 200/2000] tot_loss=2.044 (perp=9.870, rec=0.066, cos=0.004), tot_loss_proj:2.618 [t=0.18s]
prediction: ['[CLS] per pleasure theverse [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.676 (perp=7.535, rec=0.152, cos=0.016), tot_loss_proj:1.988 [t=0.27s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 300/2000] tot_loss=1.599 (perp=7.535, rec=0.089, cos=0.003), tot_loss_proj:2.015 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.581 (perp=7.535, rec=0.072, cos=0.002), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.576 (perp=7.535, rec=0.067, cos=0.002), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 450/2000] tot_loss=1.570 (perp=7.535, rec=0.061, cos=0.002), tot_loss_proj:2.007 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.581 (perp=7.535, rec=0.071, cos=0.002), tot_loss_proj:2.016 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.588 (perp=7.535, rec=0.079, cos=0.002), tot_loss_proj:2.013 [t=0.26s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 600/2000] tot_loss=1.562 (perp=7.535, rec=0.053, cos=0.002), tot_loss_proj:2.000 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.585 (perp=7.535, rec=0.075, cos=0.002), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.583 (perp=7.535, rec=0.074, cos=0.002), tot_loss_proj:2.009 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 750/2000] tot_loss=1.562 (perp=7.535, rec=0.053, cos=0.002), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.576 (perp=7.535, rec=0.067, cos=0.002), tot_loss_proj:2.011 [t=0.25s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.584 (perp=7.535, rec=0.074, cos=0.002), tot_loss_proj:2.018 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[ 900/2000] tot_loss=1.571 (perp=7.535, rec=0.062, cos=0.002), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.578 (perp=7.535, rec=0.069, cos=0.002), tot_loss_proj:2.007 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1000/2000] tot_loss=1.585 (perp=7.535, rec=0.076, cos=0.002), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1050/2000] tot_loss=1.570 (perp=7.535, rec=0.060, cos=0.002), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1100/2000] tot_loss=1.574 (perp=7.535, rec=0.064, cos=0.002), tot_loss_proj:2.018 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1150/2000] tot_loss=1.569 (perp=7.535, rec=0.060, cos=0.002), tot_loss_proj:2.018 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1200/2000] tot_loss=1.564 (perp=7.535, rec=0.055, cos=0.002), tot_loss_proj:2.008 [t=0.25s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1250/2000] tot_loss=1.591 (perp=7.535, rec=0.082, cos=0.002), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1300/2000] tot_loss=1.576 (perp=7.535, rec=0.066, cos=0.002), tot_loss_proj:2.018 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1350/2000] tot_loss=1.575 (perp=7.535, rec=0.066, cos=0.002), tot_loss_proj:2.005 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1400/2000] tot_loss=1.571 (perp=7.535, rec=0.062, cos=0.002), tot_loss_proj:2.011 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1450/2000] tot_loss=1.581 (perp=7.535, rec=0.072, cos=0.002), tot_loss_proj:2.015 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1500/2000] tot_loss=1.580 (perp=7.535, rec=0.070, cos=0.002), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1550/2000] tot_loss=1.569 (perp=7.535, rec=0.060, cos=0.002), tot_loss_proj:2.008 [t=0.26s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1600/2000] tot_loss=1.568 (perp=7.535, rec=0.059, cos=0.002), tot_loss_proj:2.014 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1650/2000] tot_loss=1.572 (perp=7.535, rec=0.063, cos=0.002), tot_loss_proj:2.009 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1700/2000] tot_loss=1.573 (perp=7.535, rec=0.064, cos=0.002), tot_loss_proj:2.016 [t=0.21s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1750/2000] tot_loss=1.575 (perp=7.535, rec=0.065, cos=0.002), tot_loss_proj:2.013 [t=0.20s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1800/2000] tot_loss=1.574 (perp=7.535, rec=0.064, cos=0.002), tot_loss_proj:2.020 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1850/2000] tot_loss=1.565 (perp=7.535, rec=0.056, cos=0.002), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[1900/2000] tot_loss=1.572 (perp=7.535, rec=0.063, cos=0.002), tot_loss_proj:2.004 [t=0.19s]
prediction: ['[CLS] pleasure the perverse [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.535, rec=0.056, cos=0.002), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Attempt swap
[2000/2000] tot_loss=1.574 (perp=7.535, rec=0.064, cos=0.002), tot_loss_proj:2.018 [t=0.22s]
prediction: ['[CLS] pleasure the perverse [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] pleasure the perverse [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 91.967 | p: 91.276 | r: 92.698
rouge2     | fm: 56.243 | p: 56.067 | r: 56.489
rougeL     | fm: 80.300 | p: 79.903 | r: 80.715
rougeLsum  | fm: 80.021 | p: 79.626 | r: 80.485
r1fm+r2fm = 148.211

input #20 time: 0:08:15 | total time: 2:54:27


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.9986347105985566
highest_index [0]
highest [0.9986347105985566]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 0.8674206137657166 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 0.8430505394935608 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 0.8231990337371826 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 0.804859459400177 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 0.7957730889320374 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 0.7757977247238159 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 0.7718383073806763 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 0.7716163992881775 for ['[CLS]back stony golden rights size side loan she dee vii connecticut item situations benttaking according general there [UNK] pose baby fauna, especially labor [SEP]']
[Init] best perm rec loss: 0.771418035030365 for ['[CLS] dee fauna general loan poseback vii stony connecticut she baby golden item bent according sidetaking [UNK], size rights situations labor especially there [SEP]']
[Init] best perm rec loss: 0.7686938047409058 for ['[CLS] stony according especially dee side, connecticut golden general vii pose situations fauna rightstaking babyback size labor she bent [UNK] loan there item [SEP]']
[Init] best perm rec loss: 0.768121063709259 for ['[CLS] especially stony fauna item side sheback connecticut [UNK] bent rights pose general baby size there according loan vii dee situations goldentaking, labor [SEP]']
[Init] best perm rec loss: 0.7674907445907593 for ['[CLS] bent especially golden [UNK]taking sheback baby connecticut there rights item, according situations pose stony loan labor general size dee fauna vii side [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.028 (perp=13.077, rec=0.371, cos=0.042), tot_loss_proj:3.703 [t=0.19s]
prediction: ['[CLS] graphics all old pgaolo are guitargraphsground every locks officials obviously recently leaders ignoring no have treatment players women out a food airplay [SEP]']
[ 100/2000] tot_loss=2.617 (perp=11.546, rec=0.287, cos=0.021), tot_loss_proj:4.041 [t=0.19s]
prediction: ['[CLS]ds way this spectators means out guitar works make loop serious athletes if recently workers despite of serious women athletes women the among athletes curriculum [SEP]']
[ 150/2000] tot_loss=1.919 (perp=8.488, rec=0.206, cos=0.016), tot_loss_proj:2.655 [t=0.19s]
prediction: ['[CLS] that way this way works out ticket works makes instead serious athletes more like caretaker instead of serious way athletes women the serious athletes students [SEP]']
[ 200/2000] tot_loss=1.926 (perp=8.872, rec=0.144, cos=0.008), tot_loss_proj:2.646 [t=0.18s]
prediction: ['[CLS] that way this the works out look works makes stereo serioustypical more like caretaker instead of serious women athletes women the. athletes out [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.696 (perp=7.738, rec=0.134, cos=0.014), tot_loss_proj:2.328 [t=0.18s]
prediction: ['[CLS] that way this all works out look works makes stereotypical look like serious caretaker instead of serious women athletes women the. athletes out [SEP]']
[ 300/2000] tot_loss=1.662 (perp=7.732, rec=0.108, cos=0.007), tot_loss_proj:2.484 [t=0.19s]
prediction: ['[CLS] the way all all works out look works makes stereotypical look like moral caretaker instead of serious women athletes women the. athletes out [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.623 (perp=7.582, rec=0.101, cos=0.006), tot_loss_proj:2.233 [t=0.19s]
prediction: ['[CLS] the way all all works outtypical works makes stereotypical look like moral caretaker instead of serious of. athletes women the athletes out [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.636 (perp=7.590, rec=0.110, cos=0.008), tot_loss_proj:2.785 [t=0.18s]
prediction: ['[CLS] the way all all works outtypical those makes stereotypical look like moral caretaker instead of serious of. athletes the women athletes out [SEP]']
[ 450/2000] tot_loss=1.580 (perp=7.405, rec=0.094, cos=0.005), tot_loss_proj:2.129 [t=0.19s]
prediction: ['[CLS] the way this all works out look more makes stereotypical look like moral caretaker instead of serious of. athletes the women athletes out [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.519 (perp=7.154, rec=0.084, cos=0.004), tot_loss_proj:1.845 [t=0.25s]
prediction: ['[CLS] the way this all works out makes stereotypical look like moral caretaker instead of serious of,typical more athletes the women athletes out [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.410 (perp=6.627, rec=0.081, cos=0.004), tot_loss_proj:1.783 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical look like moral caretaker instead of serious of, and more athletes the women athletes out [SEP]']
[ 600/2000] tot_loss=1.400 (perp=6.562, rec=0.083, cos=0.004), tot_loss_proj:1.761 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical look like moral caretaker instead of seriouss, and more athletes the women athletes out [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.336 (perp=6.268, rec=0.078, cos=0.004), tot_loss_proj:1.689 [t=0.19s]
prediction: ['[CLS] the way this all works out makes stereotypical look like moral caretakers instead of serious, and more athletes the women athletes out [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.286 (perp=6.064, rec=0.068, cos=0.005), tot_loss_proj:1.604 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical look like moral caretakers instead of serious women, and more athletes the athletes out [SEP]']
[ 750/2000] tot_loss=1.298 (perp=6.064, rec=0.081, cos=0.004), tot_loss_proj:1.596 [t=0.20s]
prediction: ['[CLS] the way this all works out makes stereotypical look like moral caretakers instead of serious women, and more athletes the athletes out [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.264 (perp=5.935, rec=0.072, cos=0.004), tot_loss_proj:1.611 [t=0.33s]
prediction: ['[CLS] the way this all works out makes stereotypical look like moral caretakers instead of more serious women, and athletes the athletes out [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.258 (perp=5.935, rec=0.067, cos=0.004), tot_loss_proj:1.598 [t=0.28s]
prediction: ['[CLS] the way this all works out makes stereotypical look like moral caretakers instead of more serious women, and athletes the athletes out [SEP]']
[ 900/2000] tot_loss=1.268 (perp=5.935, rec=0.076, cos=0.004), tot_loss_proj:1.611 [t=0.30s]
prediction: ['[CLS] the way this all works out makes stereotypical look like moral caretakers instead of more serious women, and athletes the athletes out [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.176 (perp=5.461, rec=0.078, cos=0.005), tot_loss_proj:1.572 [t=0.23s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1000/2000] tot_loss=1.174 (perp=5.461, rec=0.078, cos=0.004), tot_loss_proj:1.579 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
[1050/2000] tot_loss=1.165 (perp=5.461, rec=0.068, cos=0.005), tot_loss_proj:1.578 [t=0.20s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1100/2000] tot_loss=1.164 (perp=5.461, rec=0.068, cos=0.004), tot_loss_proj:1.573 [t=0.23s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1150/2000] tot_loss=1.173 (perp=5.461, rec=0.077, cos=0.004), tot_loss_proj:1.574 [t=0.20s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
[1200/2000] tot_loss=1.176 (perp=5.461, rec=0.079, cos=0.004), tot_loss_proj:1.564 [t=0.27s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1250/2000] tot_loss=1.160 (perp=5.461, rec=0.063, cos=0.005), tot_loss_proj:1.575 [t=0.19s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1300/2000] tot_loss=1.164 (perp=5.461, rec=0.067, cos=0.005), tot_loss_proj:1.574 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
[1350/2000] tot_loss=1.172 (perp=5.461, rec=0.075, cos=0.004), tot_loss_proj:1.577 [t=0.21s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1400/2000] tot_loss=1.174 (perp=5.461, rec=0.077, cos=0.004), tot_loss_proj:1.576 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1450/2000] tot_loss=1.175 (perp=5.461, rec=0.079, cos=0.004), tot_loss_proj:1.567 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
[1500/2000] tot_loss=1.161 (perp=5.461, rec=0.064, cos=0.004), tot_loss_proj:1.575 [t=0.20s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1550/2000] tot_loss=1.178 (perp=5.461, rec=0.081, cos=0.004), tot_loss_proj:1.569 [t=0.23s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1600/2000] tot_loss=1.159 (perp=5.461, rec=0.062, cos=0.004), tot_loss_proj:1.574 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
[1650/2000] tot_loss=1.166 (perp=5.461, rec=0.069, cos=0.004), tot_loss_proj:1.574 [t=0.19s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1700/2000] tot_loss=1.163 (perp=5.461, rec=0.066, cos=0.004), tot_loss_proj:1.573 [t=0.26s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1750/2000] tot_loss=1.170 (perp=5.461, rec=0.073, cos=0.004), tot_loss_proj:1.568 [t=0.23s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
[1800/2000] tot_loss=1.161 (perp=5.461, rec=0.064, cos=0.004), tot_loss_proj:1.577 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1850/2000] tot_loss=1.172 (perp=5.461, rec=0.075, cos=0.004), tot_loss_proj:1.577 [t=0.23s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[1900/2000] tot_loss=1.161 (perp=5.461, rec=0.065, cos=0.004), tot_loss_proj:1.576 [t=0.19s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
[1950/2000] tot_loss=1.164 (perp=5.461, rec=0.068, cos=0.004), tot_loss_proj:1.579 [t=0.23s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Attempt swap
[2000/2000] tot_loss=1.158 (perp=5.461, rec=0.062, cos=0.004), tot_loss_proj:1.574 [t=0.18s]
prediction: ['[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] the way this all works out makes stereotypical athletes look like moral caretakers instead of more serious women, and the athletes out [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.617 | p: 91.667 | r: 95.652
rouge2     | fm: 35.556 | p: 34.783 | r: 36.364
rougeL     | fm: 68.085 | p: 66.667 | r: 69.565
rougeLsum  | fm: 68.085 | p: 66.667 | r: 69.565
r1fm+r2fm = 129.173

[Aggregate metrics]:
rouge1     | fm: 92.084 | p: 91.314 | r: 92.938
rouge2     | fm: 55.492 | p: 55.180 | r: 55.765
rougeL     | fm: 79.542 | p: 79.121 | r: 79.994
rougeLsum  | fm: 79.565 | p: 79.140 | r: 80.040
r1fm+r2fm = 147.575

input #21 time: 0:08:28 | total time: 3:02:55


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9988005080812612
highest_index [0]
highest [0.9988005080812612]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 0.9889786839485168 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 0.9732847213745117 for ['[CLS] mast landlord rockome crusaders enjoyed denise fire dock almost vera [SEP]']
[Init] best rec loss: 0.964691162109375 for ['[CLS] 2008 were change nixon lighting range francois fate near reservoir medal [SEP]']
[Init] best perm rec loss: 0.9643498659133911 for ['[CLS] change fate range medal 2008 near were nixon lighting reservoir francois [SEP]']
[Init] best perm rec loss: 0.964210569858551 for ['[CLS] medal range were fate change lighting francois 2008 nixon reservoir near [SEP]']
[Init] best perm rec loss: 0.9638873338699341 for ['[CLS] fate lighting 2008 medal were reservoir change range nixon francois near [SEP]']
[Init] best perm rec loss: 0.9633219838142395 for ['[CLS] change fate near reservoir 2008 lighting nixon francois medal were range [SEP]']
[Init] best perm rec loss: 0.9627426862716675 for ['[CLS] fate change 2008 near lighting medal were reservoir nixon francois range [SEP]']
[Init] best perm rec loss: 0.9617449641227722 for ['[CLS] fate medal lighting reservoir nixon 2008 francois near were range change [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.727 (perp=12.742, rec=0.589, cos=0.590), tot_loss_proj:4.431 [t=0.23s]
prediction: ['[CLS] recommended ruins mm adaptation gifts a adaptation until adaptation because revival [SEP]']
[ 100/2000] tot_loss=3.187 (perp=12.740, rec=0.453, cos=0.186), tot_loss_proj:4.372 [t=0.19s]
prediction: ['[CLS] successful bad digital adaptationlster a adaptation until mom because nowhere [SEP]']
[ 150/2000] tot_loss=3.277 (perp=13.231, rec=0.385, cos=0.245), tot_loss_proj:4.712 [t=0.24s]
prediction: ['[CLS] successful bad racecourse adaptationlster an adaptation until mom sounding adaptation [SEP]']
[ 200/2000] tot_loss=3.326 (perp=13.620, rec=0.365, cos=0.237), tot_loss_proj:4.577 [t=0.24s]
prediction: ['[CLS] successful broke vuelta adaptation eagle an adaptation until pastor sounding christians [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=3.166 (perp=12.945, rec=0.327, cos=0.250), tot_loss_proj:4.548 [t=0.19s]
prediction: ['[CLS] successful vuelta adaptation thornton broke an adaptation until mom film christians [SEP]']
[ 300/2000] tot_loss=3.066 (perp=12.539, rec=0.293, cos=0.265), tot_loss_proj:3.785 [t=0.18s]
prediction: ['[CLS] enjoyable bmw adaptation abc impressive an adaptation until sequel film christians [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.072 (perp=12.621, rec=0.279, cos=0.268), tot_loss_proj:3.608 [t=0.18s]
prediction: ['[CLS] enjoyable films adaptation mama impressive unchanged a adaptation lover film christians [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.780 (perp=11.188, rec=0.272, cos=0.270), tot_loss_proj:3.280 [t=0.22s]
prediction: ['[CLS] enjoyable films adaptation adaptation impressive unchanged a mama lover film christians [SEP]']
[ 450/2000] tot_loss=2.690 (perp=10.734, rec=0.275, cos=0.268), tot_loss_proj:2.837 [t=0.23s]
prediction: ['[CLS] enjoyable films adaptation film fragile unchanged a considerable lover film definitely [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.975 (perp=12.211, rec=0.256, cos=0.277), tot_loss_proj:3.193 [t=0.24s]
prediction: ['[CLS] enjoyable film adaptation werewolf fragile volleyball an considerable patton film christians [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.786 (perp=11.214, rec=0.255, cos=0.288), tot_loss_proj:2.974 [t=0.18s]
prediction: ['[CLS] enjoyable film adaptation werewolf fragile volleyball anumber patton film definitely [SEP]']
[ 600/2000] tot_loss=2.830 (perp=11.455, rec=0.242, cos=0.298), tot_loss_proj:3.007 [t=0.20s]
prediction: ['[CLS] enjoyable film adaptation werewolf fragile volleyball anumber lover film definitely [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.715 (perp=10.883, rec=0.262, cos=0.276), tot_loss_proj:2.928 [t=0.26s]
prediction: ['[CLS] enjoyable film adaptation sincere tragedy volleyball anumber films its definitely [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.681 (perp=10.697, rec=0.282, cos=0.260), tot_loss_proj:2.920 [t=0.21s]
prediction: ['[CLS] enjoyable film adaptationaround tragedy films anumber volleyball its definitely [SEP]']
[ 750/2000] tot_loss=2.759 (perp=11.199, rec=0.253, cos=0.266), tot_loss_proj:3.634 [t=0.19s]
prediction: ['[CLS] enjoyable film adaptation patton tragedy films anumber volleyball itsructured [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.974 (perp=12.305, rec=0.244, cos=0.270), tot_loss_proj:3.256 [t=0.19s]
prediction: ['[CLS] enjoyable film adaptation patton tragedy films an behalf volleyball definitely its [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.731 (perp=11.014, rec=0.243, cos=0.286), tot_loss_proj:2.929 [t=0.23s]
prediction: ['[CLS] enjoyable film adaptation behalf fragile films anchev volleyball definitely its [SEP]']
[ 900/2000] tot_loss=2.713 (perp=11.014, rec=0.235, cos=0.275), tot_loss_proj:2.939 [t=0.21s]
prediction: ['[CLS] enjoyable film adaptation behalf fragile films anchev volleyball definitely its [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.622 (perp=10.541, rec=0.234, cos=0.280), tot_loss_proj:2.813 [t=0.23s]
prediction: ['[CLS] enjoyable film adaptation behalf fragile films anchev volleyball its definitely [SEP]']
Attempt swap
[1000/2000] tot_loss=2.782 (perp=11.287, rec=0.240, cos=0.284), tot_loss_proj:3.430 [t=0.26s]
prediction: ['[CLS] enjoyable film adaptation behalf award films anchev volleyball itsructured [SEP]']
[1050/2000] tot_loss=2.750 (perp=11.200, rec=0.230, cos=0.280), tot_loss_proj:2.954 [t=0.19s]
prediction: ['[CLS] enjoyable film adaptation behalf award films anchev volleyball its definitely [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.679 (perp=10.825, rec=0.238, cos=0.276), tot_loss_proj:3.214 [t=0.18s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an award volleyball itsructured [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.483 (perp=9.853, rec=0.237, cos=0.276), tot_loss_proj:2.851 [t=0.21s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an award its behalfructured [SEP]']
[1200/2000] tot_loss=2.491 (perp=9.853, rec=0.242, cos=0.278), tot_loss_proj:2.851 [t=0.18s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an award its behalfructured [SEP]']
Attempt swap
[1250/2000] tot_loss=2.725 (perp=11.086, rec=0.234, cos=0.273), tot_loss_proj:3.231 [t=0.20s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an fragile its behalf file [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.788 (perp=11.371, rec=0.236, cos=0.278), tot_loss_proj:3.643 [t=0.19s]
prediction: ['[CLS] enjoyable film adaptation behalfchev unsuccessful films an its behalf file [SEP]']
[1350/2000] tot_loss=2.804 (perp=11.436, rec=0.242, cos=0.275), tot_loss_proj:3.152 [t=0.19s]
prediction: ['[CLS] enjoyable film adaptation behalfchev urgent films an its behalf file [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.588 (perp=10.377, rec=0.234, cos=0.279), tot_loss_proj:2.867 [t=0.27s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf urgent file [SEP]']
Attempt swap
[1450/2000] tot_loss=2.576 (perp=10.377, rec=0.225, cos=0.276), tot_loss_proj:2.873 [t=0.24s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf urgent file [SEP]']
[1500/2000] tot_loss=2.601 (perp=10.423, rec=0.241, cos=0.275), tot_loss_proj:3.155 [t=0.29s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
Attempt swap
[1550/2000] tot_loss=2.595 (perp=10.423, rec=0.234, cos=0.276), tot_loss_proj:3.145 [t=0.19s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
Attempt swap
[1600/2000] tot_loss=2.604 (perp=10.423, rec=0.246, cos=0.273), tot_loss_proj:3.148 [t=0.22s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
[1650/2000] tot_loss=2.590 (perp=10.423, rec=0.233, cos=0.272), tot_loss_proj:3.149 [t=0.20s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
Attempt swap
[1700/2000] tot_loss=2.586 (perp=10.423, rec=0.227, cos=0.275), tot_loss_proj:3.151 [t=0.20s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
Attempt swap
[1750/2000] tot_loss=2.592 (perp=10.423, rec=0.231, cos=0.276), tot_loss_proj:3.150 [t=0.25s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
[1800/2000] tot_loss=2.600 (perp=10.423, rec=0.238, cos=0.278), tot_loss_proj:3.143 [t=0.19s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
Attempt swap
[1850/2000] tot_loss=2.579 (perp=10.423, rec=0.222, cos=0.272), tot_loss_proj:3.154 [t=0.18s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
Attempt swap
[1900/2000] tot_loss=2.599 (perp=10.423, rec=0.238, cos=0.277), tot_loss_proj:3.147 [t=0.18s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
[1950/2000] tot_loss=2.589 (perp=10.423, rec=0.231, cos=0.274), tot_loss_proj:3.148 [t=0.19s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
Attempt swap
[2000/2000] tot_loss=2.583 (perp=10.423, rec=0.224, cos=0.275), tot_loss_proj:3.150 [t=0.19s]
prediction: ['[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] enjoyable film adaptation behalfchev films an its behalf demanding file [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.000 | p: 58.333 | r: 53.846
rouge2     | fm: 8.696 | p: 9.091 | r: 8.333
rougeL     | fm: 40.000 | p: 41.667 | r: 38.462
rougeLsum  | fm: 40.000 | p: 41.667 | r: 38.462
r1fm+r2fm = 64.696

[Aggregate metrics]:
rouge1     | fm: 90.616 | p: 89.930 | r: 91.299
rouge2     | fm: 53.380 | p: 53.165 | r: 53.601
rougeL     | fm: 77.975 | p: 77.568 | r: 78.417
rougeLsum  | fm: 77.759 | p: 77.354 | r: 78.241
r1fm+r2fm = 143.997

input #22 time: 0:08:36 | total time: 3:11:32


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.9987073327192254
highest_index [0]
highest [0.9987073327192254]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 0.6936860680580139 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 0.6900186538696289 for ["[CLS] terrible dvd lives race philharmonic event andover scholars scaling tesla semi du both relatingories change towelrogated mohawk interview clear rat accession once ripping vol motorsports stove country somewhere 1999 ground employed each about murders'deadwer even cargo clickhopper prophet storesarderos state [SEP]"]
[Init] best rec loss: 0.6899714469909668 for ['[CLS] experiment de forecast expo adventure emergingship no cost epic e investmenttya separate componentvision crowned nazi balthazar alliancered predecessor consensuslis unrest coverage( kick par cnn 7 pas hugh powerful hospitalian postedmussen examinerback con while office print returntaffaterricular [SEP]']
[Init] best rec loss: 0.6891133189201355 for ['[CLS] duty coach request relief minister novel awayrin sections stores techcape circa stage subboard previous concession mediamate lab gas saddleurbed voted je miles dove軍 parliament jennie demon assessment motors t case troopples slate depending need similar renamed ant young overlooking tanner solar [SEP]']
[Init] best perm rec loss: 0.6888461709022522 for ['[CLS] assessment away case turbed coach circa media relief novel troop sub saddleples ant minister young request sections tanner voted depending stage previous軍cape concession gas parliament jennie overlooking renamed need similar duty motors doverin lab slate storesboard solar demonmate tech je miles [SEP]']
[Init] best perm rec loss: 0.6885929107666016 for ['[CLS] needples similar previous jennie circamate tech sections stage assessment t dove media coach concession case troop gas miles lab slate solar stores軍 request young motors saddle parliament awayurbedboard voted tanner relief minister je duty demon novel dependingrin overlooking ant renamedcape sub [SEP]']
[Init] best perm rec loss: 0.688476026058197 for ['[CLS] parliament request similar young renamed concession demon needboard gas slate tanner dove je軍 troop motors solarcape media away miles sectionsmate duty ministerples depending previous novel saddle coach circa case overlooking jennie suburbed trin assessment stores tech voted ant stage relief lab [SEP]']
[Init] best perm rec loss: 0.6881545782089233 for ['[CLS] coach novel renamed case relief circa je parliament media gas solar assessment ministerurbed sectionsboard demon overlooking young sub jennie similar depending stage dutyrin t slate need labmate away ant motors concession request techcapeples miles dove tanner saddle voted troop previous軍 stores [SEP]']
[Init] best perm rec loss: 0.6880853772163391 for ['[CLS] assessment previous sections jennie dove votedurbed ant parliament軍 saddle lab case minister coach gas depending stores circa relief novel renamed solar tanner requestrincape need away stage dutyboard tech demon similarples jemate t miles slate motors concession young sub troop media overlooking [SEP]']
[Init] best perm rec loss: 0.6875452995300293 for ['[CLS] novel slate overlooking stores ministerples dove awayurbed tanner depending sub reliefboard young miles jerin demon case request jennie stage assessmentcape circa tech renamed sections solar previous concession need coach parliament saddle mediamate troop gas voted軍 t duty motors ant similar lab [SEP]']
[Init] best perm rec loss: 0.6873003244400024 for ['[CLS] similar gas milesrin reliefcapeples voted tanner overlooking t renamed assessmenturbed concession duty troop lab ant request previous parliament minister stagemate media young depending jennie case軍 need tech slate stores dove away saddle novel demon motors solarboard coach je sub circa sections [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.564 (perp=11.239, rec=0.263, cos=0.053), tot_loss_proj:3.291 [t=0.20s]
prediction: ['[CLS]c and objective soldiers german soldiers war, rah tone cardlizerraphic project theted nazi strategic havilland [CLS] objective walkl dexter in security its : its primarily strategic strategic campaign objective the obtain decades studies settlement until paramilitary. / take attack strategic objective [SEP]']
[ 100/2000] tot_loss=2.137 (perp=9.555, rec=0.199, cos=0.027), tot_loss_proj:2.787 [t=0.22s]
prediction: ['[CLS]c and objective soldiers vietnam soldiers fight, rah tone cedar soldiersh idea the objective discussion a its similar objective generation soldiers achieve earned strategic its : main main strategic strategic strategic objective the achieve decades dramazing until intensity. eventually the initial objective objective [SEP]']
[ 150/2000] tot_loss=2.205 (perp=10.074, rec=0.171, cos=0.018), tot_loss_proj:3.092 [t=0.18s]
prediction: ['[CLS]ly and objective soldiers vietnam soldiers conflict, rah tone cedar patriotic a idea drama objective very patriotic its similar tone generation soldiers achieve earned patriotic its : main main strategic strategic strategic objective the achieve which dramazing into intensity. ultimately achieve grip objective objective [SEP]']
[ 200/2000] tot_loss=2.272 (perp=10.223, rec=0.200, cos=0.027), tot_loss_proj:2.943 [t=0.19s]
prediction: ['[CLS] could and objective true vietnam soldiers suffering are rah tone shillings patriotic a idea the. question historical its although picture generation soldiers define legislature soldiers its : main main strategic strategic strategic objective the achieve change dramazing through lucan, eventually the initial objective colonization [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.316 (perp=10.351, rec=0.217, cos=0.029), tot_loss_proj:3.044 [t=0.19s]
prediction: ['[CLS] could the elements national true vietnam soldiers sufferingh rah tone, patriotic a idea drama the " is while tone generation initially eventually generation strategic its : main main strategic tactical strategic objective the achieve changed dramazing what [SEP], eventually the level objective celebration [SEP]']
[ 300/2000] tot_loss=2.242 (perp=10.310, rec=0.169, cos=0.011), tot_loss_proj:2.998 [t=0.21s]
prediction: ['[CLS] could the the his true vietnam soldiers conflicth rah tonedents patriotic a idea drama the " is while tone generation initially eventually generation military its : main main strategic tactical strategic objective the achieve that dramazing what [SEP], ultimately the climbing objective define [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.265 (perp=10.544, rec=0.147, cos=0.009), tot_loss_proj:3.158 [t=0.19s]
prediction: ['[CLS] could the drama an opposition vietnam soldiers conflict, rah tone accent patriotic a idea drama ‖ " is while tone generation initially define generation conflict its : main main strategic ultimately strategic objective the achieve that conflictzing what [SEP], ultimately is climbing objective cost [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.226 (perp=10.356, rec=0.144, cos=0.010), tot_loss_proj:2.979 [t=0.27s]
prediction: ['[CLS] will the drama a object vietnam soldiers battle, rah tone accent is patriotic a idea drama to " while tone generation initially define generation conflict its : main main strategic ultimately strategic objective the achieve that conflictzing what [SEP], ultimately of climbing objective cost [SEP]']
[ 450/2000] tot_loss=2.151 (perp=9.962, rec=0.146, cos=0.013), tot_loss_proj:2.904 [t=0.18s]
prediction: ['[CLS] will, drama a object vietnam soldiers battle, rah toneicles is patriotic a idea drama ள " while tone generation military define generation conflict its : main main strategic tactical strategic objective the achieve that conflictzing what [SEP], ultimately the criminal objective cost [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=2.078 (perp=9.724, rec=0.125, cos=0.008), tot_loss_proj:2.956 [t=0.19s]
prediction: ['[CLS] will, drama object vietnam soldiers battle, a rah tone such is patriotic a idea drama ள " while tone generation initially define generation conflict its : main main strategic tactical strategic objective the achieve that conflictzing the [SEP], ultimately the criminal objective cost [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.988 (perp=9.303, rec=0.121, cos=0.006), tot_loss_proj:2.796 [t=0.28s]
prediction: ['[CLS] will, drama object vietnam soldiers battle, a rah tone suchs patriotic a idea drama ள " while tone generation military define its conflict generation : main main strategic tactical strategic objective the achieve that conflictzing the [SEP], ultimately the criminal objective cost [SEP]']
[ 600/2000] tot_loss=2.021 (perp=9.467, rec=0.121, cos=0.007), tot_loss_proj:2.773 [t=0.19s]
prediction: ['[CLS] will and drama object vietnam soldiers battle, a rah tone suchs patriotic a idea drama ள " while picture generation military define its conflict generation : main main strategic tactical strategic objective the achieve that conflictzing the [SEP], ultimately the criminal objective cost [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.981 (perp=9.307, rec=0.113, cos=0.007), tot_loss_proj:2.765 [t=0.24s]
prediction: ['[CLS] will. drama object vietnam soldiers battle, a rah patriotic suchs tone a idea drama ள " while picture generation military define its conflict generation : main main strategic tactical strategic objective the achieve that conflictzing the [SEP], ultimatelys criminal objective cost [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.955 (perp=9.221, rec=0.106, cos=0.005), tot_loss_proj:2.986 [t=0.22s]
prediction: ['[CLS] will. drama object vietnam soldiers battle, a rah patriotic suchs tone a idea drama ள " while picture generation military define its conflict generation : main main strategic tactical strategic objective the achieve climbing conflictzing the [SEP], ultimatelys that objective cost [SEP]']
[ 750/2000] tot_loss=1.942 (perp=9.159, rec=0.104, cos=0.006), tot_loss_proj:2.955 [t=0.21s]
prediction: ['[CLS] will. drama object vietnam soldiers battle, a rah patriotic suchs tone a idea drama ள " while picture generation military define its conflict generation : main main strategic tactical strategic objective the achieve criminal conflictzing the [SEP], ultimatelys that objective cost [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.919 (perp=9.019, rec=0.109, cos=0.006), tot_loss_proj:2.893 [t=0.21s]
prediction: ['[CLS] will - drama object vietnam soldiers battle, a rah patriotic suchs tone a idea drama architectural " while picture generation military define its conflict generation : the main main strategic tactical strategic objective the achieve criminal conflictzing [SEP], ultimatelys that objective cost [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.869 (perp=8.796, rec=0.104, cos=0.005), tot_loss_proj:2.702 [t=0.28s]
prediction: ['[CLS] will - drama object vietnam soldiers battle, a rah patriotic suchs tone a idea drama architectural " while military picture generation define its conflict generation : the main main strategic tactical strategic objective the achieve criminal conflictzing the, ultimatelys that objective cost [SEP]']
[ 900/2000] tot_loss=1.863 (perp=8.796, rec=0.099, cos=0.005), tot_loss_proj:2.702 [t=0.20s]
prediction: ['[CLS] will - drama object vietnam soldiers battle, a rah patriotic suchs tone a idea drama architectural " while military picture generation define its conflict generation : the main main strategic tactical strategic objective the achieve criminal conflictzing the, ultimatelys that objective cost [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.835 (perp=8.641, rec=0.101, cos=0.006), tot_loss_proj:2.649 [t=0.19s]
prediction: ['[CLS] will - drama object conflict soldiers battle, a rah patriotic suchs tone a idea drama architectural " while military picture generation define its conflict generation : the main main strategic tactical strategic objective the achieve criminal vietnamzing the, ultimatelys that objective cost [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.814 (perp=8.553, rec=0.098, cos=0.005), tot_loss_proj:2.648 [t=0.28s]
prediction: ['[CLS] will - drama object conflict soldiers battle, a rah patriotic suchs tone a idea drama architectural " while military picture generation define its conflict generation : the main strategic tactical main strategic objective the achieve criminal vietnamzing the, ultimatelys that objective cost [SEP]']
[1050/2000] tot_loss=1.813 (perp=8.553, rec=0.097, cos=0.005), tot_loss_proj:2.646 [t=0.19s]
prediction: ['[CLS] will - drama object conflict soldiers battle, a rah patriotic suchs tone a idea drama architectural " while military picture generation define its conflict generation : the main strategic tactical main strategic objective the achieve criminal vietnamzing the, ultimatelys that objective cost [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.781 (perp=8.405, rec=0.094, cos=0.005), tot_loss_proj:2.608 [t=0.19s]
prediction: ['[CLS] will - drama object conflict soldiers battle, a rah patriotic suchs tone a idea architectural drama " while military picture generation define its conflict generation : the main strategic tactical main strategic objective the achieve criminal vietnamzing the, ultimatelys that objective cost [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.756 (perp=8.263, rec=0.099, cos=0.005), tot_loss_proj:2.961 [t=0.21s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea architectural drama " while military picture generation define its conflict generation : the main strategic tactical main strategic objective the achieve criminal vietnamzing -, ultimatelys that objective cost [SEP]']
[1200/2000] tot_loss=1.771 (perp=8.353, rec=0.095, cos=0.005), tot_loss_proj:3.041 [t=0.18s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea ि drama " while military picture generation define its conflict generation : the main strategic tactical main strategic objective the achieve criminal vietnamzing -, ultimatelys that objective cost [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.772 (perp=8.361, rec=0.095, cos=0.005), tot_loss_proj:2.832 [t=0.22s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea 主 drama " while military picture generation define its conflict generation : the main strategic tactical main strategic objective the achieve climbing vietnams -, ultimatelyzing that objective cost [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.750 (perp=8.252, rec=0.095, cos=0.005), tot_loss_proj:2.757 [t=0.23s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea 主 drama " while military picture generation define the conflict generation : its main strategic tactical main strategic objective the achieve climbing vietnams -, ultimatelyzing that objective cost [SEP]']
[1350/2000] tot_loss=1.749 (perp=8.252, rec=0.094, cos=0.004), tot_loss_proj:2.759 [t=0.24s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea 主 drama " while military picture generation define the conflict generation : its main strategic tactical main strategic objective the achieve climbing vietnams -, ultimatelyzing that objective cost [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.734 (perp=8.179, rec=0.094, cos=0.004), tot_loss_proj:2.594 [t=0.18s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea 主 drama " while military picture generation define the conflict generation : its main tactical main strategic objective the achieve climbing vietnams - strategic, ultimatelyzing that objective cost [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.726 (perp=8.120, rec=0.097, cos=0.004), tot_loss_proj:2.569 [t=0.24s]
prediction: ['[CLS] will the generation object conflict soldiers battle, a rah patriotic suchs tone a idea 主 drama " while military picture drama define the conflict generation : its main tactical main strategic objective the achieve climbing vietnams - strategic, ultimatelyzing that objective cost [SEP]']
[1500/2000] tot_loss=1.728 (perp=8.150, rec=0.094, cos=0.005), tot_loss_proj:2.577 [t=0.26s]
prediction: ['[CLS] will the generation object conflict soldiers battle, a rah patriotic suchs tone a idea 主 drama and while military picture drama define the conflict generation : its main tactical main strategic objective the achieve climbing vietnams - strategic, ultimatelyzing that objective cost [SEP]']
Attempt swap
[1550/2000] tot_loss=1.726 (perp=8.150, rec=0.091, cos=0.004), tot_loss_proj:2.578 [t=0.23s]
prediction: ['[CLS] will the generation object conflict soldiers battle, a rah patriotic suchs tone a idea 主 drama and while military picture drama define the conflict generation : its main tactical main strategic objective the achieve climbing vietnams - strategic, ultimatelyzing that objective cost [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.705 (perp=8.035, rec=0.093, cos=0.005), tot_loss_proj:2.553 [t=0.19s]
prediction: ['[CLS] will the generation object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 while military picture drama define the conflict generation : its main tactical main strategic objective the achieve conflict vietnams - strategic, ultimatelyzing that objective cost [SEP]']
[1650/2000] tot_loss=1.706 (perp=8.035, rec=0.094, cos=0.005), tot_loss_proj:2.551 [t=0.19s]
prediction: ['[CLS] will the generation object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 while military picture drama define the conflict generation : its main tactical main strategic objective the achieve conflict vietnams - strategic, ultimatelyzing that objective cost [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.689 (perp=7.941, rec=0.096, cos=0.004), tot_loss_proj:2.521 [t=0.19s]
prediction: ['[CLS] will the generation object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 while military picture drama define the conflict generation : its main tactical main strategic objective the achieves conflict vietnam - strategic, ultimatelyzing that objective cost [SEP]']
Attempt swap
[1750/2000] tot_loss=1.688 (perp=7.941, rec=0.095, cos=0.004), tot_loss_proj:2.520 [t=0.19s]
prediction: ['[CLS] will the generation object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 while military picture drama define the conflict generation : its main tactical main strategic objective the achieves conflict vietnam - strategic, ultimatelyzing that objective cost [SEP]']
[1800/2000] tot_loss=1.683 (perp=7.941, rec=0.090, cos=0.004), tot_loss_proj:2.520 [t=0.19s]
prediction: ['[CLS] will the generation object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 while military picture drama define the conflict generation : its main tactical main strategic objective the achieves conflict vietnam - strategic, ultimatelyzing that objective cost [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.722 (perp=8.119, rec=0.094, cos=0.004), tot_loss_proj:2.527 [t=0.22s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 while military picture generation define the conflict generation : its main ultimately main strategic objective the achieves conflict vietnam - strategic, ultimatelyzing that objective cost [SEP]']
Attempt swap
[1900/2000] tot_loss=1.720 (perp=8.119, rec=0.092, cos=0.004), tot_loss_proj:2.525 [t=0.22s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 while military picture generation define the conflict generation : its main ultimately main strategic objective the achieves conflict vietnam - strategic, ultimatelyzing that objective cost [SEP]']
[1950/2000] tot_loss=1.722 (perp=8.119, rec=0.094, cos=0.004), tot_loss_proj:2.525 [t=0.18s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 while military picture generation define the conflict generation : its main ultimately main strategic objective the achieves conflict vietnam - strategic, ultimatelyzing that objective cost [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.717 (perp=8.103, rec=0.092, cos=0.004), tot_loss_proj:2.570 [t=0.19s]
prediction: ['[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 strategic military picture generation define the conflict generation : its main ultimately main strategic objective the achieves conflict vietnam - while, ultimatelyzing that objective cost [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] will the drama object conflict soldiers battle, a rah patriotic suchs tone a idea and drama 主 while military picture generation define the conflict generation : its main ultimately main strategic objective the achieves conflict vietnam - strategic, ultimatelyzing that objective cost [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.136 | p: 68.293 | r: 70.000
rouge2     | fm: 15.190 | p: 15.000 | r: 15.385
rougeL     | fm: 37.037 | p: 36.585 | r: 37.500
rougeLsum  | fm: 37.037 | p: 36.585 | r: 37.500
r1fm+r2fm = 84.326

[Aggregate metrics]:
rouge1     | fm: 89.609 | p: 88.982 | r: 90.359
rouge2     | fm: 51.593 | p: 51.422 | r: 51.843
rougeL     | fm: 75.987 | p: 75.603 | r: 76.522
rougeLsum  | fm: 75.919 | p: 75.593 | r: 76.431
r1fm+r2fm = 141.203

input #23 time: 0:08:33 | total time: 3:20:05


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9987315771274169
highest_index [0]
highest [0.9987315771274169]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 0.8880969285964966 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 0.8363981246948242 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 0.8155826926231384 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 0.8116405010223389 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 0.7847121357917786 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 0.7629534602165222 for ['[CLS] numb clear post mirror leg closet died fond sometimes distributor bonus « piecegence nerve rush authority direction turnsxie [SEP]']
[Init] best rec loss: 0.7315658926963806 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 0.7306642532348633 for ['[CLS] port happy nowyl arms em ryu damnedaneous mid village bush bond suffer younger attack unless snow play county [SEP]']
[Init] best perm rec loss: 0.7306028008460999 for ['[CLS] arms mid damned sufferaneous happy ryu village attack port unless no em play snow younger bond countywyl bush [SEP]']
[Init] best perm rec loss: 0.7272691130638123 for ['[CLS] armsaneous county em suffer mid bondwyl village snow port bush ryu younger no attack damned unless happy play [SEP]']
[Init] best perm rec loss: 0.7269560098648071 for ['[CLS] no port bond arms younger attack damnedwyl bush unless play em ryu suffer happy snow county mid villageaneous [SEP]']
[Init] best perm rec loss: 0.726635754108429 for ['[CLS] em attack no happy snow arms village suffer younger port play bush county mid ryuaneouswyl damned unless bond [SEP]']
[Init] best perm rec loss: 0.7266090512275696 for ['[CLS] sufferwyl bond damned no happy younger mid snow village ryu em attack county port play bushaneous arms unless [SEP]']
[Init] best perm rec loss: 0.7254465222358704 for ['[CLS] ryu arms no village attack county port play snow em unless damned happy bond sufferaneous bushwyl mid younger [SEP]']
[Init] best perm rec loss: 0.7218968272209167 for ['[CLS] bond no suffer mid happy attack snow damned county port emwyl play ryu youngeraneous bush village unless arms [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.452 (perp=10.547, rec=0.293, cos=0.050), tot_loss_proj:3.095 [t=0.20s]
prediction: ['[CLS] terrorism less climate regarding context evil former caused terrorist hurt 2012 different not! take evil see more evil ) [SEP]']
[ 100/2000] tot_loss=2.125 (perp=9.631, rec=0.187, cos=0.012), tot_loss_proj:2.681 [t=0.19s]
prediction: ['[CLS] terrorists outside context taken context terrorists political political terrorists opposed 2012 ( than!azi evil see more evil ) [SEP]']
[ 150/2000] tot_loss=1.977 (perp=9.053, rec=0.159, cos=0.008), tot_loss_proj:2.519 [t=0.19s]
prediction: ['[CLS] terrorists outside context taken context terrorists political of terrorists : ) ( than! ) evil see more evil ) [SEP]']
[ 200/2000] tot_loss=1.897 (perp=8.801, rec=0.130, cos=0.007), tot_loss_proj:2.488 [t=0.19s]
prediction: ['[CLS] political outside context taken climate terrorists political climate terrorists : any ( than! ) evil see more evil ) [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.837 (perp=8.488, rec=0.134, cos=0.005), tot_loss_proj:2.487 [t=0.19s]
prediction: ['[CLS]! outside context taken climate terrorists political climate terrorists : ever ( than political ) evil see more evil ) [SEP]']
[ 300/2000] tot_loss=1.818 (perp=8.488, rec=0.116, cos=0.004), tot_loss_proj:2.485 [t=0.22s]
prediction: ['[CLS]! outside context taken climate terrorists political climate terrorists : ever ( than political ) evil see more evil ) [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.654 (perp=7.625, rec=0.124, cos=0.005), tot_loss_proj:2.429 [t=0.19s]
prediction: ['[CLS] ever! outside context taken climate terrorists political climate terrorists : ( than political ) ( see more evil ) [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.694 (perp=7.950, rec=0.100, cos=0.004), tot_loss_proj:2.496 [t=0.18s]
prediction: ['[CLS] ever! outside context taken climate terrorists political climate terrorists : ( than political ( see more evil are ) [SEP]']
[ 450/2000] tot_loss=1.768 (perp=8.323, rec=0.098, cos=0.004), tot_loss_proj:2.633 [t=0.18s]
prediction: ['[CLS] ever! outside context taken current terrorists political climate terrorists : ( than political ( see more evil are ) [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.732 (perp=8.203, rec=0.088, cos=0.004), tot_loss_proj:2.374 [t=0.19s]
prediction: ['[CLS] ever taken outside context! current terrorists political climate terrorists : ( than current ( see more evil are ) [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.596 (perp=7.469, rec=0.096, cos=0.006), tot_loss_proj:2.312 [t=0.23s]
prediction: ['[CLS] ever taken outside context! current political climate terrorists : ( than current ( see more evil are terrorists ) [SEP]']
[ 600/2000] tot_loss=1.588 (perp=7.469, rec=0.090, cos=0.004), tot_loss_proj:2.305 [t=0.24s]
prediction: ['[CLS] ever taken outside context! current political climate terrorists : ( than current ( see more evil are terrorists ) [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.542 (perp=7.241, rec=0.089, cos=0.005), tot_loss_proj:2.456 [t=0.25s]
prediction: ['[CLS] ever taken outside context! current political climate : ( than current ( see more evil terrorists are terrorists ) [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.480 (perp=6.816, rec=0.105, cos=0.012), tot_loss_proj:2.175 [t=0.19s]
prediction: ['[CLS] ever taken outside context! the political climate ( than current ( see more evil : terrorists are terrorists ) [SEP]']
[ 750/2000] tot_loss=1.457 (perp=6.816, rec=0.089, cos=0.005), tot_loss_proj:2.171 [t=0.20s]
prediction: ['[CLS] ever taken outside context! the political climate ( than current ( see more evil : terrorists are terrorists ) [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.403 (perp=6.567, rec=0.086, cos=0.004), tot_loss_proj:2.029 [t=0.19s]
prediction: ['[CLS] ever taken outside context the political climate ( than current ( see more evil : terrorists are terrorists! ) [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.399 (perp=6.567, rec=0.081, cos=0.004), tot_loss_proj:2.030 [t=0.19s]
prediction: ['[CLS] ever taken outside context the political climate ( than current ( see more evil : terrorists are terrorists! ) [SEP]']
[ 900/2000] tot_loss=1.513 (perp=7.103, rec=0.089, cos=0.004), tot_loss_proj:2.225 [t=0.18s]
prediction: ['[CLS] ever taken outside context the political climate ( than current the see more evil : terrorists are terrorists! ) [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.417 (perp=6.664, rec=0.080, cos=0.004), tot_loss_proj:2.221 [t=0.19s]
prediction: ['[CLS] ever taken outside context the political climate current than ( the see more evil : terrorists are terrorists! ) [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.380 (perp=6.473, rec=0.080, cos=0.004), tot_loss_proj:2.089 [t=0.19s]
prediction: ['[CLS] ever taken outside context the political climate than ( the current see more evil : terrorists are terrorists! ) [SEP]']
[1050/2000] tot_loss=1.382 (perp=6.473, rec=0.083, cos=0.004), tot_loss_proj:2.089 [t=0.18s]
prediction: ['[CLS] ever taken outside context the political climate than ( the current see more evil : terrorists are terrorists! ) [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.372 (perp=6.387, rec=0.090, cos=0.004), tot_loss_proj:2.130 [t=0.26s]
prediction: ['[CLS] ever taken outside context the political climate than ( current see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.281 (perp=5.982, rec=0.080, cos=0.005), tot_loss_proj:2.009 [t=0.20s]
prediction: ['[CLS] ever taken outside context the political climate than current ( see more evil : the terrorists are terrorists! ) [SEP]']
[1200/2000] tot_loss=1.279 (perp=5.982, rec=0.079, cos=0.004), tot_loss_proj:2.009 [t=0.25s]
prediction: ['[CLS] ever taken outside context the political climate than current ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
[1250/2000] tot_loss=1.278 (perp=5.982, rec=0.078, cos=0.004), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] ever taken outside context the political climate than current ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.266 (perp=5.848, rec=0.092, cos=0.004), tot_loss_proj:1.957 [t=0.20s]
prediction: ['[CLS] ever taken outside context the current political climate than ( see more evil : the terrorists are terrorists! ) [SEP]']
[1350/2000] tot_loss=1.250 (perp=5.848, rec=0.076, cos=0.004), tot_loss_proj:1.954 [t=0.18s]
prediction: ['[CLS] ever taken outside context the current political climate than ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.171 (perp=5.410, rec=0.085, cos=0.004), tot_loss_proj:1.822 [t=0.20s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
[1450/2000] tot_loss=1.156 (perp=5.410, rec=0.070, cos=0.004), tot_loss_proj:1.827 [t=0.19s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
[1500/2000] tot_loss=1.170 (perp=5.410, rec=0.084, cos=0.004), tot_loss_proj:1.821 [t=0.19s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
[1550/2000] tot_loss=1.169 (perp=5.410, rec=0.082, cos=0.004), tot_loss_proj:1.830 [t=0.19s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
[1600/2000] tot_loss=1.163 (perp=5.410, rec=0.077, cos=0.004), tot_loss_proj:1.823 [t=0.19s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
[1650/2000] tot_loss=1.149 (perp=5.410, rec=0.063, cos=0.004), tot_loss_proj:1.829 [t=0.19s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
[1700/2000] tot_loss=1.159 (perp=5.410, rec=0.073, cos=0.004), tot_loss_proj:1.824 [t=0.22s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
[1750/2000] tot_loss=1.162 (perp=5.410, rec=0.076, cos=0.004), tot_loss_proj:1.824 [t=0.19s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
[1800/2000] tot_loss=1.168 (perp=5.410, rec=0.082, cos=0.004), tot_loss_proj:1.827 [t=0.19s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
[1850/2000] tot_loss=1.167 (perp=5.410, rec=0.081, cos=0.004), tot_loss_proj:1.824 [t=0.24s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.167 (perp=5.410, rec=0.081, cos=0.004), tot_loss_proj:1.822 [t=0.18s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
[1950/2000] tot_loss=1.165 (perp=5.410, rec=0.078, cos=0.004), tot_loss_proj:1.825 [t=0.19s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
Attempt swap
[2000/2000] tot_loss=1.169 (perp=5.410, rec=0.083, cos=0.004), tot_loss_proj:1.827 [t=0.19s]
prediction: ['[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] ever taken outside context than the current political climate ( see more evil : the terrorists are terrorists! ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.444 | p: 94.444 | r: 94.444
rouge2     | fm: 41.176 | p: 41.176 | r: 41.176
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 135.621

[Aggregate metrics]:
rouge1     | fm: 89.945 | p: 89.292 | r: 90.683
rouge2     | fm: 51.196 | p: 50.930 | r: 51.496
rougeL     | fm: 75.745 | p: 75.441 | r: 76.238
rougeLsum  | fm: 75.582 | p: 75.236 | r: 75.991
r1fm+r2fm = 141.141

input #24 time: 0:08:25 | total time: 3:28:31


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9986868569377239
highest_index [0]
highest [0.9986868569377239]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 0.9572980403900146 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 0.9497916102409363 for ['[CLS] past banking son davies [SEP]']
[Init] best rec loss: 0.9472327828407288 for ['[CLS] weakness blue fast @ [SEP]']
[Init] best rec loss: 0.9431636333465576 for ['[CLS] stepped senate centuryfish [SEP]']
[Init] best rec loss: 0.9416790008544922 for ['[CLS] lady howin sum [SEP]']
[Init] best rec loss: 0.926240086555481 for ['[CLS]bla mozart orleans [SEP] [SEP]']
[Init] best rec loss: 0.9207825064659119 for ['[CLS] visionmetric dozennica [SEP]']
[Init] best rec loss: 0.918075680732727 for ['[CLS] manner from bathing small [SEP]']
[Init] best perm rec loss: 0.9170811176300049 for ['[CLS] from manner small bathing [SEP]']
[Init] best perm rec loss: 0.9168403148651123 for ['[CLS] from bathing manner small [SEP]']
[Init] best perm rec loss: 0.915385365486145 for ['[CLS] small manner bathing from [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.134 (perp=13.105, rec=0.446, cos=0.068), tot_loss_proj:3.298 [t=0.18s]
prediction: ['[CLS] wonderfullore currently big [SEP]']
[ 100/2000] tot_loss=2.148 (perp=8.974, rec=0.301, cos=0.052), tot_loss_proj:2.316 [t=0.22s]
prediction: ['[CLS] beautiful strange film strange [SEP]']
[ 150/2000] tot_loss=2.176 (perp=8.974, rec=0.318, cos=0.064), tot_loss_proj:2.312 [t=0.28s]
prediction: ['[CLS] beautiful strange film strange [SEP]']
[ 200/2000] tot_loss=2.127 (perp=8.974, rec=0.282, cos=0.051), tot_loss_proj:2.331 [t=0.18s]
prediction: ['[CLS] beautiful strange film strange [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.988 (perp=7.944, rec=0.270, cos=0.129), tot_loss_proj:2.052 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[ 300/2000] tot_loss=1.985 (perp=7.944, rec=0.251, cos=0.145), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.964 (perp=7.944, rec=0.239, cos=0.136), tot_loss_proj:2.049 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.950 (perp=7.944, rec=0.233, cos=0.129), tot_loss_proj:2.044 [t=0.27s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[ 450/2000] tot_loss=1.958 (perp=7.944, rec=0.227, cos=0.142), tot_loss_proj:2.046 [t=0.26s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.947 (perp=7.944, rec=0.218, cos=0.140), tot_loss_proj:2.048 [t=0.24s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.955 (perp=7.944, rec=0.222, cos=0.144), tot_loss_proj:2.065 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[ 600/2000] tot_loss=1.964 (perp=7.944, rec=0.228, cos=0.148), tot_loss_proj:2.060 [t=0.28s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.949 (perp=7.944, rec=0.228, cos=0.131), tot_loss_proj:2.063 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.939 (perp=7.944, rec=0.211, cos=0.139), tot_loss_proj:2.069 [t=0.20s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[ 750/2000] tot_loss=1.937 (perp=7.944, rec=0.215, cos=0.133), tot_loss_proj:2.068 [t=0.24s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.922 (perp=7.944, rec=0.198, cos=0.135), tot_loss_proj:2.064 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.933 (perp=7.944, rec=0.204, cos=0.139), tot_loss_proj:2.069 [t=0.30s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[ 900/2000] tot_loss=1.928 (perp=7.944, rec=0.206, cos=0.133), tot_loss_proj:2.069 [t=0.28s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.927 (perp=7.944, rec=0.203, cos=0.135), tot_loss_proj:2.071 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.927 (perp=7.944, rec=0.199, cos=0.140), tot_loss_proj:2.068 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1050/2000] tot_loss=1.922 (perp=7.944, rec=0.198, cos=0.136), tot_loss_proj:2.072 [t=0.22s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.933 (perp=7.944, rec=0.202, cos=0.142), tot_loss_proj:2.076 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.920 (perp=7.944, rec=0.196, cos=0.136), tot_loss_proj:2.071 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1200/2000] tot_loss=1.922 (perp=7.944, rec=0.197, cos=0.136), tot_loss_proj:2.062 [t=0.19s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.920 (perp=7.944, rec=0.197, cos=0.135), tot_loss_proj:2.076 [t=0.19s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.922 (perp=7.944, rec=0.198, cos=0.135), tot_loss_proj:2.068 [t=0.25s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1350/2000] tot_loss=1.924 (perp=7.944, rec=0.202, cos=0.134), tot_loss_proj:2.072 [t=0.21s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.915 (perp=7.944, rec=0.193, cos=0.133), tot_loss_proj:2.066 [t=0.19s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.927 (perp=7.944, rec=0.205, cos=0.133), tot_loss_proj:2.070 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1500/2000] tot_loss=1.922 (perp=7.944, rec=0.198, cos=0.135), tot_loss_proj:2.070 [t=0.24s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.912 (perp=7.944, rec=0.190, cos=0.133), tot_loss_proj:2.081 [t=0.19s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.921 (perp=7.944, rec=0.198, cos=0.134), tot_loss_proj:2.069 [t=0.25s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1650/2000] tot_loss=1.916 (perp=7.944, rec=0.193, cos=0.135), tot_loss_proj:2.082 [t=0.21s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.921 (perp=7.944, rec=0.198, cos=0.135), tot_loss_proj:2.077 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.918 (perp=7.944, rec=0.197, cos=0.133), tot_loss_proj:2.077 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1800/2000] tot_loss=1.916 (perp=7.944, rec=0.193, cos=0.134), tot_loss_proj:2.074 [t=0.22s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.932 (perp=7.944, rec=0.209, cos=0.135), tot_loss_proj:2.074 [t=0.18s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.930 (perp=7.944, rec=0.206, cos=0.135), tot_loss_proj:2.073 [t=0.23s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
[1950/2000] tot_loss=1.922 (perp=7.944, rec=0.200, cos=0.133), tot_loss_proj:2.078 [t=0.25s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.930 (perp=7.944, rec=0.207, cos=0.134), tot_loss_proj:2.080 [t=0.25s]
prediction: ['[CLS] beautiful strange strange film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] beautiful strange strange film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 103.333

[Aggregate metrics]:
rouge1     | fm: 89.506 | p: 88.956 | r: 90.234
rouge2     | fm: 49.946 | p: 49.829 | r: 50.218
rougeL     | fm: 75.492 | p: 75.217 | r: 75.872
rougeLsum  | fm: 75.087 | p: 74.819 | r: 75.493
r1fm+r2fm = 139.453

input #25 time: 0:08:25 | total time: 3:36:56


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9984618772582364
highest_index [0]
highest [0.9984618772582364]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 0.8840718865394592 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 0.8437322974205017 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 0.8408775329589844 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 0.8364135026931763 for ['[CLS] thisress duck rock torture rubber point latitude nice apart politics al rational lip what asian len field feud winner venues right as [SEP]']
[Init] best rec loss: 0.8206825852394104 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 0.817653477191925 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 0.8099510073661804 for ['[CLS] door colonial shot isotead discipline merelyᆼkan list more arrow four souls polish death fourth theoretical usually constituencies octave s officers [SEP]']
[Init] best perm rec loss: 0.8092045187950134 for ['[CLS] fourth iso soulstead octave shot four door death polish more list disciplineᆼkan usually s officers arrow constituencies merely colonial theoretical [SEP]']
[Init] best perm rec loss: 0.8066638708114624 for ['[CLS] door shot isokan souls colonial fourthtead usually constituencies list merely arrow death officers more s discipline polishᆼ octave theoretical four [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.575 (perp=11.394, rec=0.270, cos=0.026), tot_loss_proj:2.904 [t=0.22s]
prediction: ['[CLS] or, downco very pounds consequently tax pointless pointless pointless, french roof importato pointless - french younger import pointless import [SEP]']
[ 100/2000] tot_loss=2.307 (perp=10.495, rec=0.196, cos=0.013), tot_loss_proj:2.737 [t=0.30s]
prediction: ['[CLS] ) import -ut so and download. pointless pointless pointless french french import import from pointless - french writer import pointless import [SEP]']
[ 150/2000] tot_loss=2.166 (perp=9.997, rec=0.157, cos=0.009), tot_loss_proj:2.587 [t=0.32s]
prediction: ['[CLS] )der - tha coming and coming. import pointless pointless and french from import from pointless - french director import pointless import [SEP]']
[ 200/2000] tot_loss=2.297 (perp=10.693, rec=0.149, cos=0.009), tot_loss_proj:2.730 [t=0.26s]
prediction: ['[CLS] )der - age coming - cominging import pointless pointless and french from import - mean - anne director sophie pointless import [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.069 (perp=9.704, rec=0.122, cos=0.006), tot_loss_proj:2.555 [t=0.31s]
prediction: ['[CLS] )der - age coming - coming -ing from pointless pointless and french import - mean - anne director sophie pointless import [SEP]']
[ 300/2000] tot_loss=2.094 (perp=9.878, rec=0.112, cos=0.006), tot_loss_proj:2.527 [t=0.29s]
prediction: ['[CLS] )der - age coming - coming -ing from pointless mean and french import - mean - anne director sophie pointless this [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.979 (perp=9.328, rec=0.107, cos=0.006), tot_loss_proj:2.462 [t=0.31s]
prediction: ['[CLS] )der - age coming - coming meaning from pointless mean and french import - - - anne director sophie pointless this [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.888 (perp=8.853, rec=0.109, cos=0.008), tot_loss_proj:2.313 [t=0.23s]
prediction: ['[CLS] )der - age coming - coming meaning from pointless french and mean import - - - anne director sophie pointless this [SEP]']
[ 450/2000] tot_loss=1.866 (perp=8.853, rec=0.090, cos=0.005), tot_loss_proj:2.311 [t=0.26s]
prediction: ['[CLS] )der - age coming - coming meaning from pointless french and mean import - - - anne director sophie pointless this [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.950 (perp=8.944, rec=0.153, cos=0.008), tot_loss_proj:2.311 [t=0.19s]
prediction: ['[CLS] ) - age coming - coming meandering from pointless french and mean import -ed - anne director sophie pointless this [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.863 (perp=8.661, rec=0.125, cos=0.006), tot_loss_proj:2.275 [t=0.19s]
prediction: ['[CLS] ) - - coming - coming meandering from pointless french and mean import agecies - anne director sophierot this [SEP]']
[ 600/2000] tot_loss=1.794 (perp=8.444, rec=0.100, cos=0.005), tot_loss_proj:2.173 [t=0.22s]
prediction: ['[CLS] ) - - coming - coming meandering from pointless french and mean import age of - anne director sophierot this [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.837 (perp=8.634, rec=0.105, cos=0.005), tot_loss_proj:2.238 [t=0.18s]
prediction: ['[CLS] ) - - coming - jewish meandering from pointless french and mean import age of - director anne sophierot this [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.681 (perp=7.834, rec=0.109, cos=0.005), tot_loss_proj:2.064 [t=0.18s]
prediction: ['[CLS] ) - - coming - coming meandering from pointless french and mean import of age - director anne sophierot this [SEP]']
[ 750/2000] tot_loss=1.688 (perp=7.944, rec=0.095, cos=0.005), tot_loss_proj:2.192 [t=0.26s]
prediction: ['[CLS] ) - - coming of coming meandering from pointless french and mean import of age - director anne sophierot this [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.803 (perp=8.531, rec=0.092, cos=0.005), tot_loss_proj:2.284 [t=0.27s]
prediction: ['[CLS] ) - - coming of upcoming meandering from pointless french and mean import of age - director anne sophierot this [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.806 (perp=8.398, rec=0.120, cos=0.006), tot_loss_proj:2.282 [t=0.21s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french andupt import of age - director anne sophierot this [SEP]']
[ 900/2000] tot_loss=1.776 (perp=8.398, rec=0.092, cos=0.005), tot_loss_proj:2.296 [t=0.28s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french andupt import of age - director anne sophierot this [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.733 (perp=8.163, rec=0.095, cos=0.005), tot_loss_proj:2.319 [t=0.24s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french import melodic and of age - director anne sophierot this [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.685 (perp=7.860, rec=0.107, cos=0.005), tot_loss_proj:2.432 [t=0.19s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french import melodic and of this age - director anne sophierot [SEP]']
[1050/2000] tot_loss=1.612 (perp=7.568, rec=0.094, cos=0.005), tot_loss_proj:2.415 [t=0.19s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french import online and of this age - director anne sophierot [SEP]']
Attempt swap
[1100/2000] tot_loss=1.615 (perp=7.568, rec=0.097, cos=0.005), tot_loss_proj:2.416 [t=0.25s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french import online and of this age - director anne sophierot [SEP]']
Attempt swap
[1150/2000] tot_loss=1.601 (perp=7.568, rec=0.083, cos=0.005), tot_loss_proj:2.415 [t=0.26s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french import online and of this age - director anne sophierot [SEP]']
[1200/2000] tot_loss=1.611 (perp=7.568, rec=0.093, cos=0.004), tot_loss_proj:2.419 [t=0.25s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french import online and of this age - director anne sophierot [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.584 (perp=7.471, rec=0.086, cos=0.005), tot_loss_proj:2.377 [t=0.24s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
[1300/2000] tot_loss=1.582 (perp=7.471, rec=0.083, cos=0.004), tot_loss_proj:2.385 [t=0.19s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french online import and of this age - director anne sophierot [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.471, rec=0.087, cos=0.004), tot_loss_proj:2.377 [t=0.19s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
[1400/2000] tot_loss=1.585 (perp=7.471, rec=0.087, cos=0.004), tot_loss_proj:2.377 [t=0.25s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
[1450/2000] tot_loss=1.578 (perp=7.471, rec=0.080, cos=0.004), tot_loss_proj:2.377 [t=0.28s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french online import and of this age - director anne sophierot [SEP]']
[1500/2000] tot_loss=1.581 (perp=7.471, rec=0.083, cos=0.004), tot_loss_proj:2.379 [t=0.21s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
[1550/2000] tot_loss=1.582 (perp=7.471, rec=0.084, cos=0.004), tot_loss_proj:2.378 [t=0.19s]
prediction: ['[CLS] ) - - coming of mean meandering from pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.564 (perp=7.374, rec=0.085, cos=0.004), tot_loss_proj:2.375 [t=0.18s]
prediction: ['[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]']
[1650/2000] tot_loss=1.565 (perp=7.374, rec=0.086, cos=0.004), tot_loss_proj:2.374 [t=0.18s]
prediction: ['[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
[1700/2000] tot_loss=1.565 (perp=7.374, rec=0.086, cos=0.004), tot_loss_proj:2.374 [t=0.30s]
prediction: ['[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
[1750/2000] tot_loss=1.559 (perp=7.374, rec=0.080, cos=0.004), tot_loss_proj:2.376 [t=0.29s]
prediction: ['[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]']
[1800/2000] tot_loss=1.567 (perp=7.374, rec=0.088, cos=0.004), tot_loss_proj:2.372 [t=0.24s]
prediction: ['[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
[1850/2000] tot_loss=1.563 (perp=7.374, rec=0.084, cos=0.004), tot_loss_proj:2.374 [t=0.19s]
prediction: ['[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
[1900/2000] tot_loss=1.566 (perp=7.374, rec=0.087, cos=0.004), tot_loss_proj:2.376 [t=0.23s]
prediction: ['[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]']
[1950/2000] tot_loss=1.556 (perp=7.374, rec=0.077, cos=0.004), tot_loss_proj:2.376 [t=0.21s]
prediction: ['[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]']
Attempt swap
[2000/2000] tot_loss=1.558 (perp=7.374, rec=0.079, cos=0.004), tot_loss_proj:2.376 [t=0.19s]
prediction: ['[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] ) - - coming of mean from meandering pointless french online import and of this age - director anne sophierot [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 77.778 | r: 82.353
rouge2     | fm: 18.182 | p: 17.647 | r: 18.750
rougeL     | fm: 51.429 | p: 50.000 | r: 52.941
rougeLsum  | fm: 51.429 | p: 50.000 | r: 52.941
r1fm+r2fm = 98.182

[Aggregate metrics]:
rouge1     | fm: 89.255 | p: 88.624 | r: 90.023
rouge2     | fm: 48.725 | p: 48.484 | r: 48.940
rougeL     | fm: 74.605 | p: 74.239 | r: 74.991
rougeLsum  | fm: 74.363 | p: 74.018 | r: 74.766
r1fm+r2fm = 137.980

input #26 time: 0:08:57 | total time: 3:45:54


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.9986363483086472
highest_index [0]
highest [0.9986363483086472]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 0.9939648509025574 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 0.9559319019317627 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 0.9536970853805542 for ['[CLS]stiitate classified [SEP]']
[Init] best rec loss: 0.9305417537689209 for ['[CLS] banvan tap [SEP]']
[Init] best rec loss: 0.926738440990448 for ['[CLS] how turned basic [SEP]']
[Init] best rec loss: 0.919778048992157 for ['[CLS] op framework ran [SEP]']
[Init] best rec loss: 0.9119898676872253 for ['[CLS] givenwine transit [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.088 (perp=9.509, rec=0.172, cos=0.015), tot_loss_proj:2.336 [t=0.18s]
prediction: ['[CLS] are generic generic [SEP]']
[ 100/2000] tot_loss=2.065 (perp=9.509, rec=0.151, cos=0.013), tot_loss_proj:2.344 [t=0.19s]
prediction: ['[CLS] are generic generic [SEP]']
[ 150/2000] tot_loss=2.031 (perp=9.509, rec=0.122, cos=0.007), tot_loss_proj:2.337 [t=0.18s]
prediction: ['[CLS] are generic generic [SEP]']
[ 200/2000] tot_loss=1.882 (perp=8.980, rec=0.081, cos=0.004), tot_loss_proj:2.304 [t=0.18s]
prediction: ['[CLS] are generic so [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.736 (perp=8.320, rec=0.069, cos=0.003), tot_loss_proj:1.782 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[ 300/2000] tot_loss=1.728 (perp=8.320, rec=0.061, cos=0.003), tot_loss_proj:1.780 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.735 (perp=8.320, rec=0.067, cos=0.003), tot_loss_proj:1.778 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.736 (perp=8.320, rec=0.069, cos=0.003), tot_loss_proj:1.791 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[ 450/2000] tot_loss=1.736 (perp=8.320, rec=0.069, cos=0.003), tot_loss_proj:1.783 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.732 (perp=8.320, rec=0.065, cos=0.003), tot_loss_proj:1.778 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.747 (perp=8.320, rec=0.080, cos=0.003), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[ 600/2000] tot_loss=1.734 (perp=8.320, rec=0.067, cos=0.003), tot_loss_proj:1.781 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.735 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.782 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.737 (perp=8.320, rec=0.071, cos=0.003), tot_loss_proj:1.796 [t=0.20s]
prediction: ['[CLS] are so generic [SEP]']
[ 750/2000] tot_loss=1.721 (perp=8.320, rec=0.054, cos=0.003), tot_loss_proj:1.790 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.732 (perp=8.320, rec=0.066, cos=0.003), tot_loss_proj:1.776 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.727 (perp=8.320, rec=0.060, cos=0.003), tot_loss_proj:1.792 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.724 (perp=8.320, rec=0.057, cos=0.003), tot_loss_proj:1.796 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.723 (perp=8.320, rec=0.056, cos=0.003), tot_loss_proj:1.788 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.735 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.733 (perp=8.320, rec=0.066, cos=0.003), tot_loss_proj:1.794 [t=0.28s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.727 (perp=8.320, rec=0.060, cos=0.003), tot_loss_proj:1.798 [t=0.30s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.724 (perp=8.320, rec=0.057, cos=0.003), tot_loss_proj:1.785 [t=0.20s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.727 (perp=8.320, rec=0.060, cos=0.003), tot_loss_proj:1.794 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.733 (perp=8.320, rec=0.066, cos=0.003), tot_loss_proj:1.773 [t=0.26s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.735 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.788 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.722 (perp=8.320, rec=0.056, cos=0.003), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.737 (perp=8.320, rec=0.071, cos=0.003), tot_loss_proj:1.781 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.723 (perp=8.320, rec=0.056, cos=0.003), tot_loss_proj:1.785 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.721 (perp=8.320, rec=0.054, cos=0.003), tot_loss_proj:1.787 [t=0.20s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.730 (perp=8.320, rec=0.063, cos=0.003), tot_loss_proj:1.783 [t=0.20s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.735 (perp=8.320, rec=0.069, cos=0.003), tot_loss_proj:1.797 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.739 (perp=8.320, rec=0.072, cos=0.003), tot_loss_proj:1.789 [t=0.29s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.741 (perp=8.320, rec=0.074, cos=0.003), tot_loss_proj:1.773 [t=0.20s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.719 (perp=8.320, rec=0.052, cos=0.003), tot_loss_proj:1.789 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.732 (perp=8.320, rec=0.065, cos=0.003), tot_loss_proj:1.787 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.734 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.783 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.735 (perp=8.320, rec=0.068, cos=0.003), tot_loss_proj:1.792 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.720 (perp=8.320, rec=0.053, cos=0.003), tot_loss_proj:1.789 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.725 (perp=8.320, rec=0.058, cos=0.003), tot_loss_proj:1.764 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.672 | p: 89.044 | r: 90.361
rouge2     | fm: 50.489 | p: 50.212 | r: 50.661
rougeL     | fm: 75.444 | p: 75.091 | r: 75.839
rougeLsum  | fm: 75.364 | p: 74.980 | r: 75.756
r1fm+r2fm = 140.160

input #27 time: 0:08:39 | total time: 3:54:34


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9990122006866433
highest_index [0]
highest [0.9990122006866433]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 0.8570931553840637 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 0.8098179697990417 for ['[CLS] want set aperture jersey [SEP]']
[Init] best rec loss: 0.8051662445068359 for ['[CLS]the ; fought 2018 [SEP]']
[Init] best rec loss: 0.7967579364776611 for ['[CLS] w dean re thanks [SEP]']
[Init] best rec loss: 0.7908192276954651 for ['[CLS] pol maneuver lex bar [SEP]']
[Init] best rec loss: 0.7862107753753662 for ['[CLS] larvae heights jeremy roses [SEP]']
[Init] best perm rec loss: 0.7857854962348938 for ['[CLS] larvae heights roses jeremy [SEP]']
[Init] best perm rec loss: 0.7855483293533325 for ['[CLS] jeremy heights roses larvae [SEP]']
[Init] best perm rec loss: 0.7845249772071838 for ['[CLS] heights roses jeremy larvae [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.811 (perp=7.843, rec=0.218, cos=0.025), tot_loss_proj:2.365 [t=0.25s]
prediction: ['[CLS] for minutes only minutes [SEP]']
[ 100/2000] tot_loss=1.918 (perp=9.124, rec=0.088, cos=0.005), tot_loss_proj:2.254 [t=0.23s]
prediction: ['[CLS] for 71 only minutes [SEP]']
[ 150/2000] tot_loss=1.892 (perp=9.124, rec=0.065, cos=0.002), tot_loss_proj:2.249 [t=0.19s]
prediction: ['[CLS] for 71 only minutes [SEP]']
[ 200/2000] tot_loss=1.888 (perp=9.124, rec=0.061, cos=0.002), tot_loss_proj:2.258 [t=0.18s]
prediction: ['[CLS] for 71 only minutes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.570 (perp=7.445, rec=0.077, cos=0.004), tot_loss_proj:1.837 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 300/2000] tot_loss=1.563 (perp=7.445, rec=0.072, cos=0.002), tot_loss_proj:1.853 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.549 (perp=7.445, rec=0.058, cos=0.002), tot_loss_proj:1.853 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.549 (perp=7.445, rec=0.057, cos=0.002), tot_loss_proj:1.844 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 450/2000] tot_loss=1.562 (perp=7.445, rec=0.071, cos=0.002), tot_loss_proj:1.855 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.560 (perp=7.445, rec=0.069, cos=0.002), tot_loss_proj:1.840 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.551 (perp=7.445, rec=0.060, cos=0.002), tot_loss_proj:1.848 [t=0.21s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 600/2000] tot_loss=1.558 (perp=7.445, rec=0.067, cos=0.002), tot_loss_proj:1.850 [t=0.27s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.559 (perp=7.445, rec=0.068, cos=0.002), tot_loss_proj:1.853 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.002), tot_loss_proj:1.849 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 750/2000] tot_loss=1.557 (perp=7.445, rec=0.065, cos=0.002), tot_loss_proj:1.853 [t=0.27s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.551 (perp=7.445, rec=0.060, cos=0.002), tot_loss_proj:1.842 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.550 (perp=7.445, rec=0.059, cos=0.002), tot_loss_proj:1.859 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[ 900/2000] tot_loss=1.556 (perp=7.445, rec=0.065, cos=0.002), tot_loss_proj:1.849 [t=0.21s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.563 (perp=7.445, rec=0.072, cos=0.002), tot_loss_proj:1.850 [t=0.21s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1000/2000] tot_loss=1.548 (perp=7.445, rec=0.057, cos=0.002), tot_loss_proj:1.845 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1050/2000] tot_loss=1.547 (perp=7.445, rec=0.056, cos=0.002), tot_loss_proj:1.849 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1100/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.002), tot_loss_proj:1.847 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1150/2000] tot_loss=1.556 (perp=7.445, rec=0.065, cos=0.002), tot_loss_proj:1.850 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1200/2000] tot_loss=1.546 (perp=7.445, rec=0.055, cos=0.002), tot_loss_proj:1.843 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1250/2000] tot_loss=1.560 (perp=7.445, rec=0.069, cos=0.002), tot_loss_proj:1.846 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1300/2000] tot_loss=1.545 (perp=7.445, rec=0.054, cos=0.002), tot_loss_proj:1.856 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1350/2000] tot_loss=1.556 (perp=7.445, rec=0.065, cos=0.002), tot_loss_proj:1.848 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1400/2000] tot_loss=1.553 (perp=7.445, rec=0.062, cos=0.002), tot_loss_proj:1.849 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1450/2000] tot_loss=1.547 (perp=7.445, rec=0.056, cos=0.002), tot_loss_proj:1.842 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1500/2000] tot_loss=1.552 (perp=7.445, rec=0.061, cos=0.002), tot_loss_proj:1.852 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1550/2000] tot_loss=1.565 (perp=7.445, rec=0.074, cos=0.002), tot_loss_proj:1.848 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1600/2000] tot_loss=1.562 (perp=7.445, rec=0.071, cos=0.002), tot_loss_proj:1.852 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1650/2000] tot_loss=1.561 (perp=7.445, rec=0.070, cos=0.002), tot_loss_proj:1.850 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1700/2000] tot_loss=1.564 (perp=7.445, rec=0.073, cos=0.002), tot_loss_proj:1.849 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1750/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.002), tot_loss_proj:1.861 [t=0.25s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1800/2000] tot_loss=1.561 (perp=7.445, rec=0.070, cos=0.002), tot_loss_proj:1.852 [t=0.19s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1850/2000] tot_loss=1.550 (perp=7.445, rec=0.059, cos=0.002), tot_loss_proj:1.854 [t=0.23s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[1900/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.002), tot_loss_proj:1.849 [t=0.18s]
prediction: ['[CLS] for 71 minutes only [SEP]']
[1950/2000] tot_loss=1.555 (perp=7.445, rec=0.064, cos=0.002), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Attempt swap
[2000/2000] tot_loss=1.543 (perp=7.445, rec=0.052, cos=0.002), tot_loss_proj:1.849 [t=0.21s]
prediction: ['[CLS] for 71 minutes only [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for 71 minutes only [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 140.000

[Aggregate metrics]:
rouge1     | fm: 89.951 | p: 89.336 | r: 90.616
rouge2     | fm: 50.181 | p: 50.028 | r: 50.314
rougeL     | fm: 75.741 | p: 75.393 | r: 76.161
rougeLsum  | fm: 75.519 | p: 75.181 | r: 75.976
r1fm+r2fm = 140.133

input #28 time: 0:08:27 | total time: 4:03:02


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9987298958474827
highest_index [0]
highest [0.9987298958474827]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 0.9034144282341003 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 0.8640676140785217 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 0.847736120223999 for ['[CLS] label which £ anyway shoes mediamont campbell her cullen [SEP]']
[Init] best rec loss: 0.8320944309234619 for ['[CLS] once reason superior when kitty fear recorded constructed dwarfs id [SEP]']
[Init] best rec loss: 0.8071332573890686 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 0.7887157797813416 for ['[CLS] consuming after intern coach acres surf class speed tongues period [SEP]']
[Init] best rec loss: 0.7803555727005005 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best perm rec loss: 0.7788046002388 for ['[CLS] cells u transmit bu mostlyfounded veto meters f axle [SEP]']
[Init] best perm rec loss: 0.7772613167762756 for ['[CLS] meters u f bu cellsfounded transmit mostly veto axle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.940 (perp=8.290, rec=0.253, cos=0.030), tot_loss_proj:2.439 [t=0.18s]
prediction: ['[CLS] i believe that rebels that blind persecution panther is not [SEP]']
[ 100/2000] tot_loss=1.750 (perp=8.011, rec=0.137, cos=0.011), tot_loss_proj:2.830 [t=0.18s]
prediction: ['[CLS] i believe that also that for evil resident it not [SEP]']
[ 150/2000] tot_loss=1.809 (perp=8.397, rec=0.122, cos=0.008), tot_loss_proj:2.835 [t=0.21s]
prediction: ['[CLS] i believe also evil that is resident resident it not [SEP]']
[ 200/2000] tot_loss=1.550 (perp=7.245, rec=0.094, cos=0.007), tot_loss_proj:2.685 [t=0.24s]
prediction: ['[CLS] i believe also evil that is resident evil it not [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.583 (perp=7.484, rec=0.079, cos=0.007), tot_loss_proj:2.779 [t=0.19s]
prediction: ['[CLS] i believe that also not is resident evil it not [SEP]']
[ 300/2000] tot_loss=1.578 (perp=7.484, rec=0.074, cos=0.007), tot_loss_proj:2.777 [t=0.19s]
prediction: ['[CLS] i believe that also not is resident evil it not [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.376 (perp=6.434, rec=0.082, cos=0.007), tot_loss_proj:2.800 [t=0.19s]
prediction: ['[CLS] i believe that also is not resident evil it not [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.238 (perp=5.806, rec=0.069, cos=0.008), tot_loss_proj:2.544 [t=0.18s]
prediction: ['[CLS] i believe that also resident evil is not it not [SEP]']
[ 450/2000] tot_loss=1.239 (perp=5.806, rec=0.071, cos=0.007), tot_loss_proj:2.535 [t=0.18s]
prediction: ['[CLS] i believe that also resident evil is not it not [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.192 (perp=5.557, rec=0.074, cos=0.007), tot_loss_proj:2.607 [t=0.19s]
prediction: ['[CLS] i believe that also resident evil - is it not [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.177 (perp=5.456, rec=0.079, cos=0.007), tot_loss_proj:2.506 [t=0.20s]
prediction: ['[CLS] i also believe that resident evil - is it not [SEP]']
[ 600/2000] tot_loss=1.145 (perp=5.331, rec=0.072, cos=0.007), tot_loss_proj:2.636 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. is it not [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.055 (perp=4.884, rec=0.071, cos=0.007), tot_loss_proj:2.128 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.048 (perp=4.884, rec=0.065, cos=0.007), tot_loss_proj:2.133 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[ 750/2000] tot_loss=1.063 (perp=4.884, rec=0.079, cos=0.006), tot_loss_proj:2.129 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.056 (perp=4.884, rec=0.073, cos=0.006), tot_loss_proj:2.132 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.058 (perp=4.884, rec=0.075, cos=0.006), tot_loss_proj:2.128 [t=0.21s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[ 900/2000] tot_loss=1.059 (perp=4.884, rec=0.076, cos=0.006), tot_loss_proj:2.130 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.057 (perp=4.884, rec=0.074, cos=0.006), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1000/2000] tot_loss=1.053 (perp=4.884, rec=0.070, cos=0.006), tot_loss_proj:2.129 [t=0.29s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1050/2000] tot_loss=1.050 (perp=4.884, rec=0.067, cos=0.006), tot_loss_proj:2.123 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1100/2000] tot_loss=1.057 (perp=4.884, rec=0.074, cos=0.006), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1150/2000] tot_loss=1.049 (perp=4.884, rec=0.067, cos=0.006), tot_loss_proj:2.127 [t=0.30s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1200/2000] tot_loss=1.057 (perp=4.884, rec=0.074, cos=0.006), tot_loss_proj:2.115 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1250/2000] tot_loss=1.057 (perp=4.884, rec=0.074, cos=0.006), tot_loss_proj:2.124 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1300/2000] tot_loss=1.057 (perp=4.884, rec=0.074, cos=0.006), tot_loss_proj:2.116 [t=0.24s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1350/2000] tot_loss=1.052 (perp=4.884, rec=0.070, cos=0.006), tot_loss_proj:2.116 [t=0.28s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1400/2000] tot_loss=1.053 (perp=4.884, rec=0.070, cos=0.006), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1450/2000] tot_loss=1.052 (perp=4.884, rec=0.070, cos=0.006), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1500/2000] tot_loss=1.055 (perp=4.884, rec=0.072, cos=0.006), tot_loss_proj:2.107 [t=0.25s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1550/2000] tot_loss=1.052 (perp=4.884, rec=0.070, cos=0.005), tot_loss_proj:2.111 [t=0.21s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1600/2000] tot_loss=1.049 (perp=4.884, rec=0.067, cos=0.005), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1650/2000] tot_loss=1.049 (perp=4.884, rec=0.067, cos=0.005), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1700/2000] tot_loss=1.052 (perp=4.884, rec=0.070, cos=0.005), tot_loss_proj:2.102 [t=0.27s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1750/2000] tot_loss=1.058 (perp=4.884, rec=0.076, cos=0.005), tot_loss_proj:2.104 [t=0.30s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1800/2000] tot_loss=1.053 (perp=4.884, rec=0.071, cos=0.005), tot_loss_proj:2.099 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1850/2000] tot_loss=1.052 (perp=4.884, rec=0.070, cos=0.005), tot_loss_proj:2.103 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[1900/2000] tot_loss=1.059 (perp=4.884, rec=0.077, cos=0.005), tot_loss_proj:2.103 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
[1950/2000] tot_loss=1.053 (perp=4.884, rec=0.072, cos=0.005), tot_loss_proj:2.103 [t=0.18s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Attempt swap
[2000/2000] tot_loss=1.053 (perp=4.884, rec=0.072, cos=0.005), tot_loss_proj:2.102 [t=0.23s]
prediction: ['[CLS] i also believe that resident evil. it is not [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i also believe that resident evil. it is not [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 90.322 | p: 89.760 | r: 90.965
rouge2     | fm: 50.949 | p: 50.708 | r: 51.193
rougeL     | fm: 76.138 | p: 75.856 | r: 76.511
rougeLsum  | fm: 76.172 | p: 75.832 | r: 76.558
r1fm+r2fm = 141.271

input #29 time: 0:08:44 | total time: 4:11:46


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.9986139396485172
highest_index [0]
highest [0.9986139396485172]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 0.8545634150505066 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 0.7191709876060486 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 0.7144846320152283 for ['[CLS] shell albeittai [SEP]']
[Init] best rec loss: 0.7010146379470825 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 0.6648808717727661 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 0.6602421402931213 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 0.6538780331611633 for ['[CLS] mom who spent [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.108 (perp=9.540, rec=0.191, cos=0.009), tot_loss_proj:1.993 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 100/2000] tot_loss=1.993 (perp=9.540, rec=0.080, cos=0.005), tot_loss_proj:1.981 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=1.984 (perp=9.540, rec=0.073, cos=0.003), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=1.973 (perp=9.540, rec=0.061, cos=0.003), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.983 (perp=9.540, rec=0.070, cos=0.005), tot_loss_proj:1.977 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.968 (perp=9.540, rec=0.056, cos=0.004), tot_loss_proj:1.973 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.966 (perp=9.540, rec=0.055, cos=0.003), tot_loss_proj:1.971 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.976 (perp=9.540, rec=0.065, cos=0.003), tot_loss_proj:1.965 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.971 (perp=9.540, rec=0.061, cos=0.003), tot_loss_proj:1.981 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.974 (perp=9.540, rec=0.063, cos=0.003), tot_loss_proj:1.968 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.988 (perp=9.540, rec=0.077, cos=0.003), tot_loss_proj:1.981 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.975 (perp=9.540, rec=0.064, cos=0.003), tot_loss_proj:1.981 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.966 (perp=9.540, rec=0.055, cos=0.003), tot_loss_proj:1.974 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.970 (perp=9.540, rec=0.059, cos=0.003), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.962 (perp=9.540, rec=0.051, cos=0.003), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.981 (perp=9.540, rec=0.071, cos=0.003), tot_loss_proj:1.983 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.979 (perp=9.540, rec=0.069, cos=0.003), tot_loss_proj:1.980 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.964 (perp=9.540, rec=0.054, cos=0.003), tot_loss_proj:1.981 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.964 (perp=9.540, rec=0.054, cos=0.003), tot_loss_proj:1.985 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.971 (perp=9.540, rec=0.060, cos=0.003), tot_loss_proj:1.985 [t=0.28s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.971 (perp=9.540, rec=0.060, cos=0.003), tot_loss_proj:1.987 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.961 (perp=9.540, rec=0.050, cos=0.003), tot_loss_proj:1.988 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.979 (perp=9.540, rec=0.068, cos=0.003), tot_loss_proj:1.962 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.978 (perp=9.540, rec=0.067, cos=0.003), tot_loss_proj:1.969 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.977 (perp=9.540, rec=0.066, cos=0.003), tot_loss_proj:1.972 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.973 (perp=9.540, rec=0.062, cos=0.003), tot_loss_proj:1.969 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.967 (perp=9.540, rec=0.057, cos=0.003), tot_loss_proj:1.985 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.976 (perp=9.540, rec=0.066, cos=0.003), tot_loss_proj:1.971 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.962 (perp=9.540, rec=0.052, cos=0.003), tot_loss_proj:1.978 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.970 (perp=9.540, rec=0.060, cos=0.003), tot_loss_proj:1.966 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.971 (perp=9.540, rec=0.060, cos=0.003), tot_loss_proj:1.964 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.967 (perp=9.540, rec=0.057, cos=0.003), tot_loss_proj:1.979 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.960 (perp=9.540, rec=0.049, cos=0.003), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.982 (perp=9.540, rec=0.071, cos=0.003), tot_loss_proj:1.977 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.972 (perp=9.540, rec=0.062, cos=0.003), tot_loss_proj:1.982 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.967 (perp=9.540, rec=0.057, cos=0.003), tot_loss_proj:1.970 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.977 (perp=9.540, rec=0.066, cos=0.003), tot_loss_proj:1.971 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.966 (perp=9.540, rec=0.055, cos=0.003), tot_loss_proj:1.982 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.961 (perp=9.540, rec=0.050, cos=0.003), tot_loss_proj:1.976 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.966 (perp=9.540, rec=0.056, cos=0.003), tot_loss_proj:1.986 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.650 | p: 90.073 | r: 91.290
rouge2     | fm: 52.520 | p: 52.296 | r: 52.737
rougeL     | fm: 77.058 | p: 76.669 | r: 77.469
rougeLsum  | fm: 76.848 | p: 76.469 | r: 77.262
r1fm+r2fm = 143.170

input #30 time: 0:08:20 | total time: 4:20:07


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.9988469173737708
highest_index [0]
highest [0.9988469173737708]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 0.8436846733093262 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 0.8223318457603455 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 0.8141117095947266 for ['[CLS] jing critical hurts [SEP]']
[Init] best rec loss: 0.8050447106361389 for ['[CLS] fraternity translit reign [SEP]']
[Init] best rec loss: 0.7530651092529297 for ['[CLS] running artwork robin [SEP]']
[Init] best rec loss: 0.7484457492828369 for ['[CLS] lighthouse peace case [SEP]']
[Init] best rec loss: 0.7395322918891907 for ['[CLS] quarter joined less [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.154 (perp=9.604, rec=0.210, cos=0.023), tot_loss_proj:2.412 [t=0.22s]
prediction: ['[CLS] better better vehicle [SEP]']
[ 100/2000] tot_loss=1.839 (perp=8.742, rec=0.086, cos=0.005), tot_loss_proj:3.139 [t=0.18s]
prediction: ['[CLS] better a vehicle [SEP]']
[ 150/2000] tot_loss=1.820 (perp=8.742, rec=0.069, cos=0.003), tot_loss_proj:3.140 [t=0.19s]
prediction: ['[CLS] better a vehicle [SEP]']
[ 200/2000] tot_loss=1.819 (perp=8.742, rec=0.068, cos=0.003), tot_loss_proj:3.150 [t=0.20s]
prediction: ['[CLS] better a vehicle [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.583 (perp=7.603, rec=0.060, cos=0.002), tot_loss_proj:1.636 [t=0.30s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.584 (perp=7.603, rec=0.061, cos=0.002), tot_loss_proj:1.638 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.590 (perp=7.603, rec=0.067, cos=0.002), tot_loss_proj:1.631 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.002), tot_loss_proj:1.644 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.002), tot_loss_proj:1.641 [t=0.24s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.585 (perp=7.603, rec=0.062, cos=0.002), tot_loss_proj:1.635 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.581 (perp=7.603, rec=0.058, cos=0.002), tot_loss_proj:1.650 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.571 (perp=7.603, rec=0.048, cos=0.002), tot_loss_proj:1.648 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.581 (perp=7.603, rec=0.058, cos=0.002), tot_loss_proj:1.634 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.587 (perp=7.603, rec=0.064, cos=0.002), tot_loss_proj:1.649 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.002), tot_loss_proj:1.641 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.572 (perp=7.603, rec=0.049, cos=0.002), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.588 (perp=7.603, rec=0.065, cos=0.002), tot_loss_proj:1.640 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.593 (perp=7.603, rec=0.070, cos=0.002), tot_loss_proj:1.633 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.592 (perp=7.603, rec=0.069, cos=0.002), tot_loss_proj:1.623 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.581 (perp=7.603, rec=0.058, cos=0.002), tot_loss_proj:1.635 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.590 (perp=7.603, rec=0.067, cos=0.002), tot_loss_proj:1.641 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.576 (perp=7.603, rec=0.053, cos=0.002), tot_loss_proj:1.639 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.588 (perp=7.603, rec=0.065, cos=0.002), tot_loss_proj:1.650 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.576 (perp=7.603, rec=0.053, cos=0.002), tot_loss_proj:1.633 [t=0.28s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.587 (perp=7.603, rec=0.064, cos=0.002), tot_loss_proj:1.642 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.580 (perp=7.603, rec=0.057, cos=0.002), tot_loss_proj:1.630 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.586 (perp=7.603, rec=0.063, cos=0.002), tot_loss_proj:1.635 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.580 (perp=7.603, rec=0.057, cos=0.002), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.580 (perp=7.603, rec=0.057, cos=0.002), tot_loss_proj:1.651 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.592 (perp=7.603, rec=0.069, cos=0.002), tot_loss_proj:1.645 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.593 (perp=7.603, rec=0.070, cos=0.002), tot_loss_proj:1.654 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.586 (perp=7.603, rec=0.063, cos=0.002), tot_loss_proj:1.644 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.584 (perp=7.603, rec=0.061, cos=0.002), tot_loss_proj:1.641 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.002), tot_loss_proj:1.630 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.002), tot_loss_proj:1.642 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.573 (perp=7.603, rec=0.050, cos=0.002), tot_loss_proj:1.637 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.002), tot_loss_proj:1.626 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.584 (perp=7.603, rec=0.061, cos=0.002), tot_loss_proj:1.641 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.584 (perp=7.603, rec=0.061, cos=0.002), tot_loss_proj:1.643 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.574 (perp=7.603, rec=0.051, cos=0.002), tot_loss_proj:1.639 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.913 | p: 90.365 | r: 91.517
rouge2     | fm: 54.186 | p: 54.064 | r: 54.308
rougeL     | fm: 77.798 | p: 77.480 | r: 78.157
rougeLsum  | fm: 77.704 | p: 77.408 | r: 78.011
r1fm+r2fm = 145.100

input #31 time: 0:08:17 | total time: 4:28:24


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9987659185029547
highest_index [0]
highest [0.9987659185029547]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 0.9367122650146484 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 0.9286137223243713 for ['[CLS] huey while kill stuck doc urgent lakeside integration food trailers with a [SEP]']
[Init] best rec loss: 0.9281815886497498 for ['[CLS] youth old made particular lostgraph matchyna suicide kara global guess [SEP]']
[Init] best rec loss: 0.9231370091438293 for ['[CLS] call blood din else howard * omaha squat languagesna supermarkets ki [SEP]']
[Init] best rec loss: 0.9141356945037842 for ['[CLS] shield issues composer gallery calling passey line introduction beacon rob foot [SEP]']
[Init] best rec loss: 0.8987351655960083 for ['[CLS] palaceshire athletic th funds lilith bio circlecting thomas cake natalie [SEP]']
[Init] best perm rec loss: 0.896979033946991 for ['[CLS] natalieshire athletic th circle funds lilith thomas palacecting cake bio [SEP]']
[Init] best perm rec loss: 0.8961718678474426 for ['[CLS]shire th lilithcting natalie thomas palace bio cake funds circle athletic [SEP]']
[Init] best perm rec loss: 0.8953947424888611 for ['[CLS] lilithshirecting funds th palace circle bio thomas natalie cake athletic [SEP]']
[Init] best perm rec loss: 0.8925923109054565 for ['[CLS] fundscting natalie cake athleticshire palace bio circle lilith th thomas [SEP]']
[Init] best perm rec loss: 0.8922427296638489 for ['[CLS] athletic circle th bio thomascting palace natalie lilith fundsshire cake [SEP]']
[Init] best perm rec loss: 0.8908516764640808 for ['[CLS] cake thomas lilith athletic natalie circlecting palace funds bioshire th [SEP]']
[Init] best perm rec loss: 0.889938473701477 for ['[CLS]cting lilith circle bio cakeshire palace thomas th athletic natalie funds [SEP]']
[Init] best perm rec loss: 0.888489305973053 for ['[CLS]cting athletic bio natalieshire thomas palace circle cake lilith th funds [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.136 (perp=12.774, rec=0.447, cos=0.134), tot_loss_proj:4.335 [t=0.18s]
prediction: ['[CLS] werewolf eyes logic portrayed pierce records saw novak noah into from genuine [SEP]']
[ 100/2000] tot_loss=3.030 (perp=12.818, rec=0.325, cos=0.141), tot_loss_proj:4.026 [t=0.19s]
prediction: ['[CLS] storyline across logic portrayed res records barcelona bending cares into wideonate [SEP]']
[ 150/2000] tot_loss=3.112 (perp=13.012, rec=0.300, cos=0.210), tot_loss_proj:4.340 [t=0.22s]
prediction: ['[CLS] storyline together logic stories resundhsions caring bedroom wideonate [SEP]']
[ 200/2000] tot_loss=3.476 (perp=14.953, rec=0.282, cos=0.204), tot_loss_proj:4.904 [t=0.30s]
prediction: ['[CLS] storyline pull couldn stories resonatehonate pulls bedroomosomalonate [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=3.417 (perp=14.832, rec=0.258, cos=0.193), tot_loss_proj:4.634 [t=0.26s]
prediction: ['[CLS]onate pull couldn stories resonate riders storyline pulls paganosomalonate [SEP]']
[ 300/2000] tot_loss=3.089 (perp=13.123, rec=0.260, cos=0.204), tot_loss_proj:4.031 [t=0.22s]
prediction: ['[CLS]onate pull easily stories resonate bennett leviᅡ pagan accessibleonate [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=3.266 (perp=14.022, rec=0.242, cos=0.219), tot_loss_proj:4.104 [t=0.25s]
prediction: ['[CLS]tify pull easily averaging stories resonate riders storylineos dimensionalonate [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=3.072 (perp=13.105, rec=0.245, cos=0.206), tot_loss_proj:4.580 [t=0.18s]
prediction: ['[CLS]tify pull easily 《 werewolf stories resonateuranceos notonate [SEP]']
[ 450/2000] tot_loss=3.057 (perp=13.112, rec=0.225, cos=0.210), tot_loss_proj:4.578 [t=0.25s]
prediction: ['[CLS]tify pull easily 《 simone stories resonate driver immediately notonate [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.748 (perp=11.497, rec=0.241, cos=0.207), tot_loss_proj:4.228 [t=0.28s]
prediction: ['[CLS] pull easily 《plify werewolf stories resonate driver with notonate [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.967 (perp=12.624, rec=0.245, cos=0.197), tot_loss_proj:4.221 [t=0.22s]
prediction: ['[CLS] pull easily 《tify driver levi stories resonate specifically issuedonate [SEP]']
[ 600/2000] tot_loss=3.065 (perp=13.107, rec=0.223, cos=0.221), tot_loss_proj:4.131 [t=0.19s]
prediction: ['[CLS] pull easily 《onate driver lancashire stories resonate specifically disconate [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=3.164 (perp=13.595, rec=0.230, cos=0.215), tot_loss_proj:4.147 [t=0.18s]
prediction: ['[CLS] pull easily 《tify driver lancashire stories abbyonate specifically resonate [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.895 (perp=12.276, rec=0.227, cos=0.214), tot_loss_proj:3.780 [t=0.18s]
prediction: ['[CLS] pull easily 《tifyurance lancashire stories specificallyonate abby resonate [SEP]']
[ 750/2000] tot_loss=2.888 (perp=12.276, rec=0.215, cos=0.218), tot_loss_proj:3.779 [t=0.19s]
prediction: ['[CLS] pull easily 《tifyurance lancashire stories specificallyonate abby resonate [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.870 (perp=12.188, rec=0.221, cos=0.211), tot_loss_proj:3.782 [t=0.21s]
prediction: ['[CLS] pull easily 《tifyurance stories specificallyruffonate abby resonate [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.856 (perp=12.107, rec=0.225, cos=0.209), tot_loss_proj:3.695 [t=0.23s]
prediction: ['[CLS] pull easily 《tifyurance stories specificallyruffound abby resonate [SEP]']
[ 900/2000] tot_loss=2.879 (perp=12.107, rec=0.222, cos=0.236), tot_loss_proj:3.690 [t=0.18s]
prediction: ['[CLS] pull easily 《tifyurance stories specificallyruffound abby resonate [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.646 (perp=11.113, rec=0.209, cos=0.214), tot_loss_proj:3.716 [t=0.20s]
prediction: ['[CLS] pull easily 《 easilyurance stories specifically resound abbyruffonate [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.768 (perp=11.673, rec=0.211, cos=0.223), tot_loss_proj:3.734 [t=0.20s]
prediction: ['[CLS] pull easily 《 easilyurance stories specificallyruffund abby resonate [SEP]']
[1050/2000] tot_loss=2.768 (perp=11.673, rec=0.208, cos=0.226), tot_loss_proj:3.731 [t=0.24s]
prediction: ['[CLS] pull easily 《 easilyurance stories specificallyruffund abby resonate [SEP]']
Attempt swap
[1100/2000] tot_loss=2.760 (perp=11.673, rec=0.213, cos=0.213), tot_loss_proj:3.737 [t=0.18s]
prediction: ['[CLS] pull easily 《 easilyurance stories specificallyruffund abby resonate [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.877 (perp=12.000, rec=0.264, cos=0.212), tot_loss_proj:3.780 [t=0.19s]
prediction: ['[CLS]ruff easily 《tifyurance stories specifically pullounded abby resonate [SEP]']
[1200/2000] tot_loss=2.647 (perp=11.038, rec=0.228, cos=0.211), tot_loss_proj:3.716 [t=0.20s]
prediction: ['[CLS]ruff easily 《 easilyurance stories specifically pullund abby resonate [SEP]']
Attempt swap
[1250/2000] tot_loss=2.636 (perp=11.038, rec=0.214, cos=0.215), tot_loss_proj:3.715 [t=0.18s]
prediction: ['[CLS]ruff easily 《 easilyurance stories specifically pullund abby resonate [SEP]']
Attempt swap
[1300/2000] tot_loss=2.635 (perp=11.038, rec=0.213, cos=0.215), tot_loss_proj:3.714 [t=0.18s]
prediction: ['[CLS]ruff easily 《 easilyurance stories specifically pullund abby resonate [SEP]']
[1350/2000] tot_loss=2.623 (perp=11.038, rec=0.200, cos=0.215), tot_loss_proj:3.718 [t=0.26s]
prediction: ['[CLS]ruff easily 《 easilyurance stories specifically pullund abby resonate [SEP]']
Attempt swap
[1400/2000] tot_loss=2.722 (perp=11.536, rec=0.201, cos=0.214), tot_loss_proj:3.948 [t=0.24s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
Attempt swap
[1450/2000] tot_loss=2.729 (perp=11.536, rec=0.206, cos=0.215), tot_loss_proj:3.948 [t=0.18s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
[1500/2000] tot_loss=2.725 (perp=11.536, rec=0.201, cos=0.217), tot_loss_proj:3.946 [t=0.18s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
Attempt swap
[1550/2000] tot_loss=2.730 (perp=11.536, rec=0.205, cos=0.218), tot_loss_proj:3.951 [t=0.19s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
Attempt swap
[1600/2000] tot_loss=2.723 (perp=11.536, rec=0.197, cos=0.219), tot_loss_proj:3.949 [t=0.18s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
[1650/2000] tot_loss=2.739 (perp=11.536, rec=0.216, cos=0.215), tot_loss_proj:3.946 [t=0.19s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
Attempt swap
[1700/2000] tot_loss=2.728 (perp=11.536, rec=0.200, cos=0.220), tot_loss_proj:3.950 [t=0.19s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
Attempt swap
[1750/2000] tot_loss=2.731 (perp=11.536, rec=0.208, cos=0.216), tot_loss_proj:3.948 [t=0.20s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
[1800/2000] tot_loss=2.722 (perp=11.536, rec=0.197, cos=0.218), tot_loss_proj:3.946 [t=0.19s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
Attempt swap
[1850/2000] tot_loss=2.727 (perp=11.536, rec=0.201, cos=0.219), tot_loss_proj:3.948 [t=0.19s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
Attempt swap
[1900/2000] tot_loss=2.729 (perp=11.536, rec=0.204, cos=0.218), tot_loss_proj:3.950 [t=0.18s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
[1950/2000] tot_loss=2.726 (perp=11.536, rec=0.202, cos=0.217), tot_loss_proj:3.946 [t=0.17s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
Attempt swap
[2000/2000] tot_loss=2.728 (perp=11.536, rec=0.203, cos=0.218), tot_loss_proj:3.951 [t=0.18s]
prediction: ['[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS]ruff easily 《 easilyture stories specifically pullund abby resonate [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 47.619 | p: 50.000 | r: 45.455
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 47.619 | p: 50.000 | r: 45.455
rougeLsum  | fm: 47.619 | p: 50.000 | r: 45.455
r1fm+r2fm = 47.619

[Aggregate metrics]:
rouge1     | fm: 89.515 | p: 89.085 | r: 90.040
rouge2     | fm: 52.208 | p: 52.050 | r: 52.432
rougeL     | fm: 76.629 | p: 76.359 | r: 76.939
rougeLsum  | fm: 76.670 | p: 76.396 | r: 76.928
r1fm+r2fm = 141.723

input #32 time: 0:08:35 | total time: 4:36:59


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.998835123442205
highest_index [0]
highest [0.998835123442205]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 0.9772903919219971 for ['[CLS] riots [SEP]']
[Init] best rec loss: 0.8641786575317383 for ['[CLS] lord [SEP]']
[Init] best rec loss: 0.8592430949211121 for ['[CLS] bar [SEP]']
[Init] best rec loss: 0.8475261330604553 for ['[CLS] master [SEP]']
[Init] best rec loss: 0.8127543926239014 for ['[CLS] training [SEP]']
[Init] best rec loss: 0.7810152769088745 for ['[CLS] strip [SEP]']
[Init] best rec loss: 0.7769296169281006 for ['[CLS] effective [SEP]']
[Init] best rec loss: 0.7606217861175537 for ['[CLS] frame [SEP]']
[Init] best rec loss: 0.7279266119003296 for ['[CLS] railroad [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.829 (perp=11.231, rec=0.424, cos=0.159), tot_loss_proj:2.474 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.540 (perp=11.231, rec=0.211, cos=0.082), tot_loss_proj:2.431 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.512 (perp=11.231, rec=0.187, cos=0.078), tot_loss_proj:2.415 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.511 (perp=11.231, rec=0.179, cos=0.086), tot_loss_proj:2.373 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.505 (perp=11.231, rec=0.190, cos=0.069), tot_loss_proj:2.383 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.503 (perp=11.231, rec=0.164, cos=0.093), tot_loss_proj:2.406 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.499 (perp=11.231, rec=0.163, cos=0.091), tot_loss_proj:2.400 [t=0.20s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.515 (perp=11.231, rec=0.192, cos=0.076), tot_loss_proj:2.382 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.526 (perp=11.231, rec=0.206, cos=0.074), tot_loss_proj:2.376 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.501 (perp=11.231, rec=0.176, cos=0.079), tot_loss_proj:2.391 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.483 (perp=11.231, rec=0.156, cos=0.081), tot_loss_proj:2.390 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.497 (perp=11.231, rec=0.178, cos=0.073), tot_loss_proj:2.396 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.495 (perp=11.231, rec=0.158, cos=0.090), tot_loss_proj:2.382 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.500 (perp=11.231, rec=0.172, cos=0.082), tot_loss_proj:2.380 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.489 (perp=11.231, rec=0.158, cos=0.085), tot_loss_proj:2.377 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.506 (perp=11.231, rec=0.185, cos=0.075), tot_loss_proj:2.389 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.497 (perp=11.231, rec=0.169, cos=0.082), tot_loss_proj:2.392 [t=0.30s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.490 (perp=11.231, rec=0.163, cos=0.081), tot_loss_proj:2.401 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.489 (perp=11.231, rec=0.162, cos=0.080), tot_loss_proj:2.381 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.478 (perp=11.231, rec=0.151, cos=0.081), tot_loss_proj:2.386 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.473 (perp=11.231, rec=0.145, cos=0.081), tot_loss_proj:2.375 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.492 (perp=11.231, rec=0.165, cos=0.080), tot_loss_proj:2.385 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.493 (perp=11.231, rec=0.165, cos=0.081), tot_loss_proj:2.373 [t=0.20s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.498 (perp=11.231, rec=0.171, cos=0.080), tot_loss_proj:2.391 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.492 (perp=11.231, rec=0.165, cos=0.081), tot_loss_proj:2.387 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.491 (perp=11.231, rec=0.165, cos=0.080), tot_loss_proj:2.377 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.493 (perp=11.231, rec=0.166, cos=0.081), tot_loss_proj:2.369 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.498 (perp=11.231, rec=0.171, cos=0.081), tot_loss_proj:2.390 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.496 (perp=11.231, rec=0.169, cos=0.081), tot_loss_proj:2.393 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.483 (perp=11.231, rec=0.156, cos=0.081), tot_loss_proj:2.371 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.493 (perp=11.231, rec=0.166, cos=0.081), tot_loss_proj:2.387 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.486 (perp=11.231, rec=0.159, cos=0.081), tot_loss_proj:2.394 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.492 (perp=11.231, rec=0.165, cos=0.081), tot_loss_proj:2.395 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.495 (perp=11.231, rec=0.168, cos=0.081), tot_loss_proj:2.395 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.482 (perp=11.231, rec=0.155, cos=0.081), tot_loss_proj:2.384 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.490 (perp=11.231, rec=0.163, cos=0.081), tot_loss_proj:2.371 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.486 (perp=11.231, rec=0.159, cos=0.081), tot_loss_proj:2.392 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.492 (perp=11.231, rec=0.164, cos=0.082), tot_loss_proj:2.384 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.493 (perp=11.231, rec=0.165, cos=0.082), tot_loss_proj:2.379 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.491 (perp=11.231, rec=0.162, cos=0.083), tot_loss_proj:2.395 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.856 | p: 89.400 | r: 90.369
rouge2     | fm: 53.587 | p: 53.379 | r: 53.771
rougeL     | fm: 77.448 | p: 77.167 | r: 77.741
rougeLsum  | fm: 77.042 | p: 76.843 | r: 77.302
r1fm+r2fm = 143.442

input #33 time: 0:08:20 | total time: 4:45:20


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9987831619792424
highest_index [0]
highest [0.9987831619792424]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 0.8328803777694702 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 0.8154928684234619 for ['[CLS] bought savings rouge quincy [CLS] ex export shawn missions race san portpped [SEP]']
[Init] best rec loss: 0.8117577433586121 for ['[CLS]gut tam popular xml practice got maia accompanied gaulle dateize mc full [SEP]']
[Init] best rec loss: 0.7539072036743164 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 0.751044511795044 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 0.7420796751976013 for ['[CLS]truct way terminus week photos specifically dowager anime inducted valentin scotch watches watched [SEP]']
[Init] best rec loss: 0.712317943572998 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 0.7116584777832031 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 0.708612322807312 for ['[CLS]ibe lissa field worth founder along ship statue driversask slight who okay [SEP]']
[Init] best perm rec loss: 0.7070726752281189 for ['[CLS] slight worth drivers ship along okay founder field statueask whoibe lissa [SEP]']
[Init] best perm rec loss: 0.7068898677825928 for ['[CLS] statue slight worth lissa along driversibe okay shipask field who founder [SEP]']
[Init] best perm rec loss: 0.7057393193244934 for ['[CLS]ibe worth ship who along drivers statue field lissa okay founder slightask [SEP]']
[Init] best perm rec loss: 0.7040435671806335 for ['[CLS] drivers worthibe founder along who statue lissa ship okayask field slight [SEP]']
[Init] best perm rec loss: 0.7032349705696106 for ['[CLS] drivers shipask along statue founderibe slight who okay lissa worth field [SEP]']
[Init] best perm rec loss: 0.7021212577819824 for ['[CLS]ibe who founder drivers alongask field lissa statue okay ship worth slight [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.588 (perp=11.113, rec=0.266, cos=0.099), tot_loss_proj:3.692 [t=0.21s]
prediction: ['[CLS] extreme urgencyaraness felt urgency build re more, extreme urgency urgency [SEP]']
[ 100/2000] tot_loss=2.092 (perp=9.148, rec=0.181, cos=0.082), tot_loss_proj:2.896 [t=0.23s]
prediction: ['[CLS] extreme urgencysus. the build build and mind take extreme urgency urgency [SEP]']
[ 150/2000] tot_loss=1.815 (perp=8.173, rec=0.133, cos=0.047), tot_loss_proj:2.277 [t=0.28s]
prediction: ['[CLS] extreme urgency mind. the viewers build in and take extreme urgency urgency [SEP]']
[ 200/2000] tot_loss=1.848 (perp=8.239, rec=0.121, cos=0.080), tot_loss_proj:2.196 [t=0.25s]
prediction: ['[CLS] extreme urgency mind. the viewer build in and take extreme on urgency [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.953 (perp=9.013, rec=0.119, cos=0.032), tot_loss_proj:2.318 [t=0.25s]
prediction: ['[CLS] extreme urgency mind. in viewer build in and take extreme urgency on [SEP]']
[ 300/2000] tot_loss=1.857 (perp=8.501, rec=0.108, cos=0.048), tot_loss_proj:2.205 [t=0.23s]
prediction: ['[CLS] extreme urgency mind. the viewer build viewer and take extreme urgency on [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.910 (perp=8.790, rec=0.113, cos=0.039), tot_loss_proj:2.283 [t=0.18s]
prediction: ['[CLS] extreme urgency. in viewer build viewer and mind take extreme urgency on [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.825 (perp=8.155, rec=0.121, cos=0.073), tot_loss_proj:2.210 [t=0.18s]
prediction: ['[CLS] extreme urgency. viewer build viewer and mind take in extreme urgency on [SEP]']
[ 450/2000] tot_loss=1.802 (perp=8.155, rec=0.110, cos=0.061), tot_loss_proj:2.214 [t=0.21s]
prediction: ['[CLS] extreme urgency. viewer build viewer and mind take in extreme urgency on [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.810 (perp=8.130, rec=0.114, cos=0.071), tot_loss_proj:2.285 [t=0.18s]
prediction: ['[CLS] extreme urgency. viewer viewer build and mind take in extreme urgency on [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.790 (perp=8.130, rec=0.113, cos=0.051), tot_loss_proj:2.273 [t=0.29s]
prediction: ['[CLS] extreme urgency. viewer viewer build and mind take in extreme urgency on [SEP]']
[ 600/2000] tot_loss=1.811 (perp=8.130, rec=0.106, cos=0.079), tot_loss_proj:2.280 [t=0.24s]
prediction: ['[CLS] extreme urgency. viewer viewer build and mind take in extreme urgency on [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.707 (perp=7.694, rec=0.104, cos=0.064), tot_loss_proj:2.121 [t=0.19s]
prediction: ['[CLS] extreme urgency. viewer viewer build and mind take on in extreme urgency [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.697 (perp=7.694, rec=0.106, cos=0.052), tot_loss_proj:2.130 [t=0.24s]
prediction: ['[CLS] extreme urgency. viewer viewer build and mind take on in extreme urgency [SEP]']
[ 750/2000] tot_loss=1.693 (perp=7.694, rec=0.093, cos=0.061), tot_loss_proj:2.129 [t=0.20s]
prediction: ['[CLS] extreme urgency. viewer viewer build and mind take on in extreme urgency [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.968 (perp=7.728, rec=0.288, cos=0.134), tot_loss_proj:2.151 [t=0.19s]
prediction: ['[CLS] extreme urgency viewers viewer build and mind take on in extreme urgency. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.811 (perp=7.262, rec=0.238, cos=0.120), tot_loss_proj:1.993 [t=0.21s]
prediction: ['[CLS] extreme urgency viewer build and mind take viewers on in extreme urgency. [SEP]']
[ 900/2000] tot_loss=1.757 (perp=7.262, rec=0.201, cos=0.104), tot_loss_proj:1.993 [t=0.20s]
prediction: ['[CLS] extreme urgency viewer build and mind take viewers on in extreme urgency. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.670 (perp=7.019, rec=0.179, cos=0.088), tot_loss_proj:2.027 [t=0.18s]
prediction: ['[CLS] extreme urgency on viewer build and mind take viewers in extreme urgency. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.635 (perp=6.886, rec=0.178, cos=0.080), tot_loss_proj:1.963 [t=0.30s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
[1050/2000] tot_loss=1.625 (perp=6.886, rec=0.173, cos=0.075), tot_loss_proj:1.948 [t=0.18s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.611 (perp=6.886, rec=0.161, cos=0.073), tot_loss_proj:1.958 [t=0.18s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.608 (perp=6.886, rec=0.160, cos=0.070), tot_loss_proj:1.948 [t=0.18s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
[1200/2000] tot_loss=1.595 (perp=6.886, rec=0.148, cos=0.069), tot_loss_proj:1.956 [t=0.26s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.587 (perp=6.886, rec=0.141, cos=0.068), tot_loss_proj:1.951 [t=0.21s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.587 (perp=6.886, rec=0.140, cos=0.069), tot_loss_proj:1.952 [t=0.18s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
[1350/2000] tot_loss=1.587 (perp=6.886, rec=0.140, cos=0.070), tot_loss_proj:1.955 [t=0.27s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.583 (perp=6.886, rec=0.137, cos=0.069), tot_loss_proj:1.955 [t=0.18s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.590 (perp=6.886, rec=0.143, cos=0.069), tot_loss_proj:1.958 [t=0.18s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
[1500/2000] tot_loss=1.579 (perp=6.886, rec=0.133, cos=0.069), tot_loss_proj:1.958 [t=0.26s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.577 (perp=6.886, rec=0.131, cos=0.069), tot_loss_proj:1.960 [t=0.18s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.576 (perp=6.886, rec=0.130, cos=0.069), tot_loss_proj:1.957 [t=0.18s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
[1650/2000] tot_loss=1.574 (perp=6.886, rec=0.129, cos=0.068), tot_loss_proj:1.962 [t=0.18s]
prediction: ['[CLS] extreme urgency build on viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.585 (perp=6.889, rec=0.138, cos=0.070), tot_loss_proj:1.867 [t=0.20s]
prediction: ['[CLS] on extreme urgency build viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.584 (perp=6.889, rec=0.138, cos=0.069), tot_loss_proj:1.871 [t=0.18s]
prediction: ['[CLS] on extreme urgency build viewer and mind take viewers in extreme urgency. [SEP]']
[1800/2000] tot_loss=1.585 (perp=6.889, rec=0.140, cos=0.068), tot_loss_proj:1.865 [t=0.18s]
prediction: ['[CLS] on extreme urgency build viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.582 (perp=6.889, rec=0.136, cos=0.068), tot_loss_proj:1.874 [t=0.18s]
prediction: ['[CLS] on extreme urgency build viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.577 (perp=6.889, rec=0.131, cos=0.069), tot_loss_proj:1.866 [t=0.18s]
prediction: ['[CLS] on extreme urgency build viewer and mind take viewers in extreme urgency. [SEP]']
[1950/2000] tot_loss=1.581 (perp=6.889, rec=0.135, cos=0.068), tot_loss_proj:1.861 [t=0.18s]
prediction: ['[CLS] on extreme urgency build viewer and mind take viewers in extreme urgency. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.577 (perp=6.889, rec=0.131, cos=0.068), tot_loss_proj:1.861 [t=0.24s]
prediction: ['[CLS] on extreme urgency build viewer and mind take viewers in extreme urgency. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] extreme urgency. viewer viewer build and mind take on in extreme urgency [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.571 | p: 78.571 | r: 78.571
rouge2     | fm: 23.077 | p: 23.077 | r: 23.077
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 101.648

[Aggregate metrics]:
rouge1     | fm: 89.514 | p: 89.134 | r: 89.981
rouge2     | fm: 53.304 | p: 53.160 | r: 53.363
rougeL     | fm: 76.901 | p: 76.658 | r: 77.247
rougeLsum  | fm: 76.751 | p: 76.520 | r: 77.012
r1fm+r2fm = 142.817

input #34 time: 0:08:23 | total time: 4:53:43


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9987123447728568
highest_index [0]
highest [0.9987123447728568]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 0.9031211137771606 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 0.8874414563179016 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best perm rec loss: 0.8855950832366943 for ['[CLS] separately ari sheriff up popularizedtrip baptist red " two strait hunt sighted art [SEP] played torn responded qatar collapsed five budget eva actually grown april talmud example lendimated side everybody seat owned among in yives swallowed closer inspired? [SEP]']
[Init] best perm rec loss: 0.8846198320388794 for ['[CLS] inspired swallowed actually art side among played y eva seat? collapsed ari baptist " grownimated closer popularized red up budget everybody five sighted separately owned lend sheriff responded [SEP] exampletripives strait qatar two talmud april hunt in torn [SEP]']
[Init] best perm rec loss: 0.8836328983306885 for ['[CLS]ives collapsed responded " lend redtrip separately? budget talmud in torn grown ari swallowed hunt art actually eva everybody popularized y baptist sheriff five among [SEP] upimated side closer inspired owned seat strait qatar played example sighted two april [SEP]']
[Init] best perm rec loss: 0.8836079239845276 for ['[CLS] among ari example red art y seat eva torn hunt [SEP] qatar grown everybody owned collapsed popularized two separately swallowed up strait five baptistives "trip?imated sheriff closer played side april talmud responded actually in sighted lend inspired budget [SEP]']
[Init] best perm rec loss: 0.8834863305091858 for ['[CLS]imated lend inspired in everybody y actually grownives side eva [SEP] owned qatar " seat closer april strait popularized budget two played? five up ari sighted among separately example torn sheriff hunt swallowedtrip talmud red baptist art responded collapsed [SEP]']
[Init] best perm rec loss: 0.8834084868431091 for ['[CLS] grown budget torn seat closer everybody up baptist in red owned collapsed actually april separately? side example talmud y fiveives sightedimated popularized played among strait inspired swallowed " two sheriff eva qatartrip responded [SEP] lend art ari hunt [SEP]']
[Init] best perm rec loss: 0.8832829594612122 for ['[CLS] y closer [SEP] ari everybody five? lend " qatar among inspired up collapsed in actually eva example april hunt side owned talmudives budget played torn art seat baptist red sherifftrip swallowed popularized grownimated separately two sighted strait responded [SEP]']
[Init] best perm rec loss: 0.8819538950920105 for ['[CLS] owned popularized artives closer red seat baptistimated sherifftrip up collapsed ari " hunt swallowed responded april side five separately strait actually in everybody y among? [SEP] two inspired eva budget grown example played lend sighted qatar torn talmud [SEP]']
[Init] best perm rec loss: 0.881672739982605 for ['[CLS] actually played budget ari april strait two baptist " side swallowed hunt responded owned everybody inspired among example in y red separately qatar seat popularized up art closer collapsed grown sheriff torn five eva sighted? [SEP]tripives lendimated talmud [SEP]']
[Init] best perm rec loss: 0.8812024593353271 for ['[CLS] everybody swallowed sheriff? strait talmud sighted " responded art huntives budgetimated qatar actually in side owned example ari lend separately two inspired collapsed baptist red april y popularized eva closer grown up played torntrip among seat five [SEP] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.078 (perp=12.101, rec=0.471, cos=0.186), tot_loss_proj:4.321 [t=0.20s]
prediction: ["[CLS] [SEP] hello alexander. downss frank terms ashley bones polanddon [SEP] before while reliefung european populations law the chargek detachment passes this within, break'joint ellen entitypour─ become manythic marcus robin gen 2009 [SEP]"]
[ 100/2000] tot_loss=2.919 (perp=11.661, rec=0.409, cos=0.177), tot_loss_proj:4.211 [t=0.19s]
prediction: ["[CLS] [SEP] lieutenant alexander. downss alex s before degree excellentdon rugby before, relief processing last populations several the charge'questions alone this., where'famous her entity ; ⊕ become many gregory marcus robin vegetables 2009 [SEP]"]
[ 150/2000] tot_loss=2.532 (perp=10.168, rec=0.362, cos=0.136), tot_loss_proj:3.962 [t=0.22s]
prediction: ["[CLS] [SEP] exterior stuart. downnation we seen beforeerly excellent'secondly before, relief no last they several the passage from questions alone greatest viewing but where'care vault majesty care ever where the gregory =stormiface showed [SEP]"]
[ 200/2000] tot_loss=3.810 (perp=11.858, rec=0.884, cos=0.555), tot_loss_proj:4.291 [t=0.19s]
prediction: ['[CLS]nation [SEP] [SEP]. downnation we it before eliminated excellent awhile [SEP] sip, that trump [SEP] what uss the passage fromraße alone grab seen but ve us small elaine wheelbaseriization up the our vlad [SEP] [SEP] the [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=4.022 (perp=13.697, rec=0.830, cos=0.453), tot_loss_proj:4.631 [t=0.18s]
prediction: ["[CLS] greater bought [SEP] land'little traffic exit helping to [SEP] [SEP] tunnel shay funding [SEP] many and [SEP] repair bien [SEP] bronze folks [SEP] [SEP] [SEP] ceoescu [SEP] kind [SEP]straße cam downtown ) a simi [SEP] [SEP] [SEP] of [SEP]"]
[ 300/2000] tot_loss=4.322 (perp=12.399, rec=0.852, cos=0.991), tot_loss_proj:4.399 [t=0.28s]
prediction: ["[CLS] greater bought [SEP] was'extensive traffic exit helping to [SEP] [SEP] tunnel shay concept the historical and [SEP] effort junk [SEP] riding folks [SEP] [SEP] [SEP] electionescu [SEP] kind [SEP]straßeka hello ) the simi [SEP] [SEP] [SEP] of [SEP]"]
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=4.140 (perp=11.803, rec=0.809, cos=0.971), tot_loss_proj:4.267 [t=0.22s]
prediction: ["[CLS] hello ) the simi [SEP] [SEP] [SEP] of greater bought [SEP] designed'regional traffic exit helping to [SEP] [SEP] tunnel moment drowning the historical and [SEP] effort junk [SEP] fun folks [SEP] [SEP] [SEP] electionescu [SEP] kind [SEP]straßeka [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=4.220 (perp=12.463, rec=0.780, cos=0.947), tot_loss_proj:4.416 [t=0.19s]
prediction: ["[CLS] united ) a simi [SEP] greater [SEP] of [SEP] bought [SEP] built'regional traffic exit helping to [SEP] [SEP] tunnel moment polar the historical and [SEP] effort junk [SEP]point folks [SEP] [SEP] [SEP] electionescu [SEP] kind [SEP] m²ka [SEP]"]
[ 450/2000] tot_loss=4.156 (perp=12.407, rec=0.746, cos=0.929), tot_loss_proj:4.366 [t=0.24s]
prediction: ["[CLS] united places a simi [SEP] greater [SEP] of [SEP] bought [SEP] built'southeast traffic exit helping to [SEP] [SEP] tunnel moment polar the historical and [SEP] effort junk [SEP]point folks [SEP] [SEP] [SEP] electionescu [SEP] eighteen [SEP] m²ka [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=3.982 (perp=11.800, rec=0.711, cos=0.911), tot_loss_proj:4.280 [t=0.19s]
prediction: ["[CLS] hello places a simi [SEP] greater [SEP] of [SEP] good [SEP] built'southeast traffic exit helping to [SEP] [SEP] moment tunnel polar the historical and [SEP] effort junk [SEP]nction folks [SEP] [SEP] [SEP] electionescu [SEP] eighteen [SEP] loanedka [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=3.979 (perp=12.006, rec=0.693, cos=0.884), tot_loss_proj:4.320 [t=0.29s]
prediction: ["[CLS] hello places a simi [SEP] greater [SEP] of [SEP] good [SEP] park'stown traffic exit helping to [SEP] [SEP] aw tunnel polar the historical and [SEP] effort junk [SEP]nction folks [SEP] [SEP] electionescu [SEP] eighteen [SEP] loaned [SEP]ka [SEP]"]
[ 600/2000] tot_loss=3.990 (perp=12.254, rec=0.674, cos=0.864), tot_loss_proj:4.382 [t=0.24s]
prediction: ["[CLS] hello places a simi [SEP] greater [SEP] of [SEP] good [SEP] park'stown traffic exit helping to [SEP] [SEP] aw tunnel polar the historical and [SEP] poll junk [SEP] glacier folks [SEP] [SEP] electionescu [SEP] eighteen [SEP] loaned [SEP]ka [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=4.009 (perp=12.555, rec=0.656, cos=0.842), tot_loss_proj:4.438 [t=0.23s]
prediction: ["[CLS] hello places a simi [SEP] greater [SEP] of [SEP] good [SEP] park'[SEP] traffic voivodeship mountain tostown [SEP] bruise tunnelorough the historical and [SEP] poll junk [SEP]erina folks [SEP] [SEP] electionescu [SEP] parking [SEP] loaned [SEP]ka [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=3.846 (perp=11.996, rec=0.644, cos=0.803), tot_loss_proj:4.320 [t=0.26s]
prediction: ["[CLS] hello places a simi [SEP] greater [SEP] of [SEP] good [SEP] park'[SEP] traffic voivodeship mountain tostown [SEP] and tunnelorough the historical bruise [SEP] poll junk [SEP]erina folks [SEP] [SEP] every crack [SEP] parking [SEP] lanes [SEP]ka [SEP]"]
[ 750/2000] tot_loss=3.774 (perp=12.025, rec=0.628, cos=0.741), tot_loss_proj:4.332 [t=0.24s]
prediction: ["[CLS] hello places a simi [SEP] greater [SEP] of [SEP] good [SEP] park'[SEP] traffic voivodeship mountain tostown [SEP] and tunneledge the historical horrible [SEP] poll junk [SEP]erina folks [SEP] [SEP] every crack [SEP] parking [SEP] lanes [SEP]ka [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=3.647 (perp=11.737, rec=0.620, cos=0.680), tot_loss_proj:4.277 [t=0.22s]
prediction: ["[CLS] hello places a simi [SEP] greater [SEP] of [SEP] good [SEP] park'[SEP] traffic commendation mountain [SEP]stown [SEP] and tunneledge the historical fault [SEP] poll junk [SEP]erina folks [SEP] to every crack [SEP] parking [SEP] lanes [SEP]ka [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=3.607 (perp=11.734, rec=0.609, cos=0.651), tot_loss_proj:4.282 [t=0.19s]
prediction: ["[CLS] hello places a simi [SEP] greater [SEP] of [SEP] good [SEP] folks'[SEP] traffic commendation mountain [SEP]stown [SEP] and tunnel weigh the historical quarry [SEP] poll junk [SEP]erina park [SEP] to enough a [SEP] parking [SEP] lanes [SEP]ka [SEP]"]
[ 900/2000] tot_loss=3.529 (perp=11.715, rec=0.594, cos=0.591), tot_loss_proj:3.900 [t=0.19s]
prediction: ["[CLS] hello places a simi [SEP] greater [SEP] of [SEP] good [SEP] folks'[SEP] traffic commendation mountain [SEP]stown [SEP] and tunnel teddy the historical personality [SEP] poll % [SEP] joyah park [SEP] to enough a [SEP]une [SEP] lanes [SEP]ka [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=3.419 (perp=11.409, rec=0.589, cos=0.548), tot_loss_proj:3.854 [t=0.19s]
prediction: ["[CLS] hello places [SEP] simi [SEP] greater [SEP] of [SEP] good [SEP] folks'a traffic commendation than [SEP]stown [SEP] and tunnel teddy the historical personality [SEP] poll % [SEP]raphic park [SEP] to enough a [SEP]une [SEP] lanes [SEP]ka [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=3.447 (perp=11.734, rec=0.579, cos=0.522), tot_loss_proj:3.900 [t=0.24s]
prediction: ["[CLS] a places [SEP] simi [SEP] greater [SEP] of [SEP] good [SEP] folks'a traffic commendation than [SEP]stown [SEP] and tunnel teddy the historical needs [SEP] poll % [SEP]raphic park [SEP] to enough hello [SEP] regarding [SEP] lanes [SEP]ka [SEP]"]
[1050/2000] tot_loss=3.401 (perp=11.630, rec=0.570, cos=0.505), tot_loss_proj:3.857 [t=0.19s]
prediction: ["[CLS] a places [SEP] simi [SEP] greater [SEP] of [SEP] good [SEP] folks'a traffic commendation than [SEP]stown [SEP] and tunnel teddy the historical better [SEP] poll % [SEP]raphic park [SEP] to enough hello [SEP] regarding [SEP] lanes [SEP]ka [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=3.368 (perp=11.681, rec=0.557, cos=0.474), tot_loss_proj:4.015 [t=0.21s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] greater [SEP] of [SEP] good [SEP] folks'a traffic commendation than [SEP]stown [SEP] and tunnel teddy the historical needs [SEP] poll % [SEP] appear park [SEP] to enough hello [SEP] parking [SEP] lanes aka [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=3.331 (perp=10.821, rec=0.652, cos=0.515), tot_loss_proj:3.718 [t=0.18s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] greater [SEP] of [SEP] good [SEP] folks'a [SEP] commendation than [SEP]stown [SEP] their tunnel teddy the historical tonight [SEP] poll % [SEP]region park railroad to enough word [SEP] grandmother [SEP] twinned aka [SEP]"]
[1200/2000] tot_loss=3.238 (perp=10.931, rec=0.592, cos=0.459), tot_loss_proj:3.767 [t=0.29s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] great [SEP] of [SEP] good [SEP] folks'a [SEP] commendation than [SEP]stown [SEP] their tunnel weigh the historical okay [SEP] poll % [SEP]region park railroad to enough word [SEP] grandmother [SEP] twinned aka [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=3.134 (perp=10.593, rec=0.579, cos=0.436), tot_loss_proj:3.713 [t=0.23s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] great [SEP] % [SEP] good [SEP] folks'a [SEP] commendation than [SEP]stown [SEP] their tunnel weigh the historical okay [SEP] poll of [SEP]raphic park railroad to enough word [SEP] grandmother [SEP] twinned aka [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=3.177 (perp=10.880, rec=0.574, cos=0.427), tot_loss_proj:3.741 [t=0.24s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] great [SEP] % [SEP] good [SEP] folks'a [SEP] commendation than [SEP]stown [SEP] their tunnel analytics the historical okay [SEP] poll of [SEP]raphic began enough to railroad word [SEP]fixed [SEP] twinned aka [SEP]"]
[1350/2000] tot_loss=3.164 (perp=10.879, rec=0.569, cos=0.419), tot_loss_proj:3.688 [t=0.23s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] great [SEP] % [SEP] good [SEP] folks'a [SEP] commendation than [SEP]stown [SEP] their tunnel analytics the historical okay [SEP] poll of [SEP]raphic began enough to railroad word [SEP] grandmother [SEP] twinned aka [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=3.124 (perp=10.742, rec=0.559, cos=0.417), tot_loss_proj:3.645 [t=0.18s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] great [SEP] % [SEP] good [SEP] folks'a [SEP] commendation than [SEP]stown [SEP] their tunnelllation [SEP] historical okay [SEP] poll of theraphic began enough to railroad word [SEP] donnie [SEP] twinned aka [SEP]"]
Attempt swap
Moved sequence
[1450/2000] tot_loss=3.118 (perp=10.694, rec=0.559, cos=0.421), tot_loss_proj:3.650 [t=0.18s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]stown [SEP] their tunnelllation [SEP] historical okay [SEP] poll of theraphic began enough to railroad word [SEP] donnie [SEP] twinned aka [SEP]"]
[1500/2000] tot_loss=3.108 (perp=10.694, rec=0.554, cos=0.415), tot_loss_proj:3.649 [t=0.19s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]stown [SEP] their tunnelllation [SEP] historical okay [SEP] poll of theraphic began enough to railroad word [SEP] donnie [SEP] twinned aka [SEP]"]
Attempt swap
Swapped tokens
[1550/2000] tot_loss=3.080 (perp=10.585, rec=0.551, cos=0.412), tot_loss_proj:3.615 [t=0.26s]
prediction: ["[CLS] [SEP] places [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]ka [SEP] their tunnelllation [SEP] historical okay [SEP] poll of theraphic began enough to railroad word [SEP] donnie [SEP] twinned astown [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=3.073 (perp=10.555, rec=0.550, cos=0.412), tot_loss_proj:3.672 [t=0.21s]
prediction: ["[CLS] [SEP] tunnel [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]ka [SEP] their placesllation [SEP] historical okay [SEP] poll of theraphic began enough to railroad word [SEP] donnie [SEP] twinned astown [SEP]"]
[1650/2000] tot_loss=3.062 (perp=10.555, rec=0.548, cos=0.403), tot_loss_proj:3.671 [t=0.19s]
prediction: ["[CLS] [SEP] tunnel [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]ka [SEP] their placesllation [SEP] historical okay [SEP] poll of theraphic began enough to railroad word [SEP] donnie [SEP] twinned astown [SEP]"]
Attempt swap
[1700/2000] tot_loss=3.063 (perp=10.582, rec=0.545, cos=0.402), tot_loss_proj:3.755 [t=0.19s]
prediction: ["[CLS] [SEP] tunnel [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]ka [SEP] their placesllation [SEP] historical bout [SEP] poll of theraphic began enough to railroad word [SEP] donnie [SEP] twinned astown [SEP]"]
Attempt swap
[1750/2000] tot_loss=3.056 (perp=10.582, rec=0.540, cos=0.400), tot_loss_proj:3.748 [t=0.19s]
prediction: ["[CLS] [SEP] tunnel [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]ka [SEP] their placesllation [SEP] historical bout [SEP] poll of theraphic began enough to railroad word [SEP] donnie [SEP] twinned astown [SEP]"]
[1800/2000] tot_loss=3.057 (perp=10.576, rec=0.545, cos=0.396), tot_loss_proj:3.713 [t=0.22s]
prediction: ["[CLS] [SEP] tunnel [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]ka [SEP] their placesllation [SEP] historical bout [SEP] elevator of theraphic began enough to railroad word [SEP] donnie [SEP] twinned astown [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=3.053 (perp=10.576, rec=0.542, cos=0.395), tot_loss_proj:3.714 [t=0.24s]
prediction: ["[CLS] [SEP] tunnel [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]ka [SEP] their placesllation [SEP] historical bout [SEP] elevator of theraphic began enough to railroad word [SEP] donnie [SEP] twinned astown [SEP]"]
Attempt swap
[1900/2000] tot_loss=3.044 (perp=10.524, rec=0.539, cos=0.400), tot_loss_proj:3.721 [t=0.19s]
prediction: ["[CLS] [SEP] tunnel [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]ka [SEP] their placesllation [SEP] historical bout [SEP] elevator of the thou began enough to railroad named [SEP] donnie [SEP] twinned astown [SEP]"]
[1950/2000] tot_loss=3.040 (perp=10.524, rec=0.540, cos=0.395), tot_loss_proj:3.725 [t=0.26s]
prediction: ["[CLS] [SEP] tunnel [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP]ka [SEP] their placesllation [SEP] historical bout [SEP] elevator of the thou began enough to railroad named [SEP] donnie [SEP] twinned astown [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=2.984 (perp=10.241, rec=0.541, cos=0.395), tot_loss_proj:3.617 [t=0.19s]
prediction: ["[CLS] [SEP] tunnel [SEP] simi [SEP] great [SEP] % [SEP] folks good [SEP]'a [SEP] commendation than [SEP] twinned [SEP] their placesllation [SEP] historical bout [SEP] elevator of the thou land enough to railroad named [SEP] donnie 'ka astown [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] [SEP] exterior louis. downnation we seen beforeerly excellent'secondly before, relief no last they mural the'from questions alone this seen but where'care vault majesty care topic wherenation gregory ᵍstorm question - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 28.986 | p: 29.412 | r: 28.571
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 20.290 | p: 20.588 | r: 20.000
rougeLsum  | fm: 20.290 | p: 20.588 | r: 20.000
r1fm+r2fm = 28.986

[Aggregate metrics]:
rouge1     | fm: 87.848 | p: 87.435 | r: 88.350
rouge2     | fm: 51.489 | p: 51.352 | r: 51.648
rougeL     | fm: 75.317 | p: 75.067 | r: 75.514
rougeLsum  | fm: 75.089 | p: 74.820 | r: 75.408
r1fm+r2fm = 139.337

input #35 time: 0:08:29 | total time: 5:02:13


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.9986939333696003
highest_index [0]
highest [0.9986939333696003]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 0.9503858685493469 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 0.9464089870452881 for ['[CLS] drillan saintnction [SEP]']
[Init] best rec loss: 0.9075354337692261 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 0.8930901288986206 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 0.8865915536880493 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 0.8343518376350403 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 0.8343032002449036 for ['[CLS] cornelius bates harassment ramsey [SEP]']
[Init] best perm rec loss: 0.8333163261413574 for ['[CLS] bates ramsey cornelius harassment [SEP]']
[Init] best perm rec loss: 0.8295406699180603 for ['[CLS] cornelius ramsey bates harassment [SEP]']
[Init] best perm rec loss: 0.8287472128868103 for ['[CLS] harassment ramsey cornelius bates [SEP]']
[Init] best perm rec loss: 0.8271118998527527 for ['[CLS] cornelius harassment ramsey bates [SEP]']
[Init] best perm rec loss: 0.8253236413002014 for ['[CLS] bates cornelius ramsey harassment [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.211 (perp=10.398, rec=0.126, cos=0.005), tot_loss_proj:2.715 [t=0.18s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
[ 100/2000] tot_loss=2.171 (perp=10.398, rec=0.087, cos=0.004), tot_loss_proj:2.705 [t=0.18s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
[ 150/2000] tot_loss=2.154 (perp=10.398, rec=0.071, cos=0.003), tot_loss_proj:2.708 [t=0.18s]
prediction: ['[CLS] horribly wrong s wrong [SEP]']
[ 200/2000] tot_loss=1.811 (perp=8.511, rec=0.104, cos=0.006), tot_loss_proj:2.126 [t=0.18s]
prediction: ["[CLS] horribly's wrong [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.714 (perp=8.105, rec=0.088, cos=0.005), tot_loss_proj:2.023 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 300/2000] tot_loss=1.700 (perp=8.105, rec=0.075, cos=0.004), tot_loss_proj:2.010 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 350/2000] tot_loss=1.697 (perp=8.105, rec=0.072, cos=0.004), tot_loss_proj:2.012 [t=0.26s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 400/2000] tot_loss=1.693 (perp=8.105, rec=0.068, cos=0.004), tot_loss_proj:2.031 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 450/2000] tot_loss=1.689 (perp=8.105, rec=0.063, cos=0.004), tot_loss_proj:2.025 [t=0.21s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.692 (perp=8.105, rec=0.066, cos=0.005), tot_loss_proj:2.025 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.695 (perp=8.105, rec=0.070, cos=0.005), tot_loss_proj:2.023 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 600/2000] tot_loss=1.699 (perp=8.105, rec=0.073, cos=0.005), tot_loss_proj:2.016 [t=0.32s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.697 (perp=8.105, rec=0.071, cos=0.005), tot_loss_proj:2.014 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.703 (perp=8.105, rec=0.077, cos=0.005), tot_loss_proj:2.019 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 750/2000] tot_loss=1.696 (perp=8.105, rec=0.070, cos=0.005), tot_loss_proj:2.014 [t=0.20s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.705 (perp=8.105, rec=0.080, cos=0.005), tot_loss_proj:2.011 [t=0.17s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.706 (perp=8.105, rec=0.081, cos=0.005), tot_loss_proj:2.006 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[ 900/2000] tot_loss=1.703 (perp=8.105, rec=0.077, cos=0.005), tot_loss_proj:2.010 [t=0.20s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.701 (perp=8.105, rec=0.075, cos=0.005), tot_loss_proj:2.011 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.694 (perp=8.105, rec=0.068, cos=0.005), tot_loss_proj:2.006 [t=0.21s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1050/2000] tot_loss=1.699 (perp=8.105, rec=0.073, cos=0.005), tot_loss_proj:2.014 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.691 (perp=8.105, rec=0.065, cos=0.005), tot_loss_proj:2.014 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.692 (perp=8.105, rec=0.066, cos=0.005), tot_loss_proj:2.003 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1200/2000] tot_loss=1.694 (perp=8.105, rec=0.068, cos=0.005), tot_loss_proj:2.011 [t=0.21s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.702 (perp=8.105, rec=0.076, cos=0.005), tot_loss_proj:2.011 [t=0.24s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.702 (perp=8.105, rec=0.077, cos=0.005), tot_loss_proj:2.014 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1350/2000] tot_loss=1.687 (perp=8.105, rec=0.061, cos=0.005), tot_loss_proj:2.012 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.702 (perp=8.105, rec=0.076, cos=0.005), tot_loss_proj:2.007 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.689 (perp=8.105, rec=0.063, cos=0.005), tot_loss_proj:2.007 [t=0.23s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1500/2000] tot_loss=1.695 (perp=8.105, rec=0.069, cos=0.005), tot_loss_proj:2.016 [t=0.20s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.696 (perp=8.105, rec=0.070, cos=0.005), tot_loss_proj:2.010 [t=0.25s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.693 (perp=8.105, rec=0.067, cos=0.005), tot_loss_proj:2.013 [t=0.27s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1650/2000] tot_loss=1.691 (perp=8.105, rec=0.065, cos=0.005), tot_loss_proj:2.013 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.688 (perp=8.105, rec=0.062, cos=0.005), tot_loss_proj:2.009 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.695 (perp=8.105, rec=0.069, cos=0.005), tot_loss_proj:2.008 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1800/2000] tot_loss=1.699 (perp=8.105, rec=0.073, cos=0.005), tot_loss_proj:2.007 [t=0.19s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.701 (perp=8.105, rec=0.075, cos=0.005), tot_loss_proj:2.007 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.687 (perp=8.105, rec=0.061, cos=0.005), tot_loss_proj:2.016 [t=0.22s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
[1950/2000] tot_loss=1.688 (perp=8.105, rec=0.062, cos=0.005), tot_loss_proj:2.011 [t=0.18s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.695 (perp=8.105, rec=0.069, cos=0.005), tot_loss_proj:2.018 [t=0.21s]
prediction: ["[CLS] s'horribly wrong [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] s'horribly wrong [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.231 | p: 87.861 | r: 88.670
rouge2     | fm: 52.755 | p: 52.636 | r: 52.888
rougeL     | fm: 75.947 | p: 75.794 | r: 76.163
rougeLsum  | fm: 75.759 | p: 75.520 | r: 75.978
r1fm+r2fm = 140.986

input #36 time: 0:08:26 | total time: 5:10:39


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9989878233665475
highest_index [0]
highest [0.9989878233665475]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 0.7626432776451111 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 0.7576902508735657 for ['[CLS] value commune [SEP]']
[Init] best rec loss: 0.6896856427192688 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 0.6699984669685364 for ['[CLS] out example [SEP]']
[Init] best rec loss: 0.6448574662208557 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 0.6232651472091675 for ['[CLS] foundation duck [SEP]']
[Init] best rec loss: 0.6162562966346741 for ['[CLS] time speaker [SEP]']
[Init] best rec loss: 0.605371356010437 for ['[CLS] beer city [SEP]']
[Init] best rec loss: 0.6037830114364624 for ['[CLS] colorcards [SEP]']
[Init] best perm rec loss: 0.6028466820716858 for ['[CLS]cards color [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.379 (perp=10.822, rec=0.166, cos=0.050), tot_loss_proj:2.496 [t=0.23s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 100/2000] tot_loss=2.332 (perp=10.822, rec=0.124, cos=0.044), tot_loss_proj:2.494 [t=0.28s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=1.990 (perp=9.583, rec=0.070, cos=0.003), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
[ 200/2000] tot_loss=1.989 (perp=9.583, rec=0.071, cos=0.002), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] eccentric and [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.896 (perp=8.916, rec=0.100, cos=0.013), tot_loss_proj:2.047 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[ 300/2000] tot_loss=1.859 (perp=8.916, rec=0.074, cos=0.002), tot_loss_proj:2.054 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.845 (perp=8.916, rec=0.060, cos=0.002), tot_loss_proj:2.062 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.844 (perp=8.916, rec=0.059, cos=0.002), tot_loss_proj:2.053 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[ 450/2000] tot_loss=1.851 (perp=8.916, rec=0.066, cos=0.002), tot_loss_proj:2.048 [t=0.31s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.835 (perp=8.916, rec=0.050, cos=0.002), tot_loss_proj:2.067 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.863 (perp=8.916, rec=0.077, cos=0.002), tot_loss_proj:2.056 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
[ 600/2000] tot_loss=1.848 (perp=8.916, rec=0.062, cos=0.002), tot_loss_proj:2.057 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.844 (perp=8.916, rec=0.059, cos=0.002), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.859 (perp=8.916, rec=0.074, cos=0.002), tot_loss_proj:2.056 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=1.838 (perp=8.916, rec=0.052, cos=0.002), tot_loss_proj:2.059 [t=0.29s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.849 (perp=8.916, rec=0.064, cos=0.002), tot_loss_proj:2.063 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.847 (perp=8.916, rec=0.062, cos=0.002), tot_loss_proj:2.058 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=1.844 (perp=8.916, rec=0.059, cos=0.002), tot_loss_proj:2.058 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.848 (perp=8.916, rec=0.063, cos=0.002), tot_loss_proj:2.056 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=1.846 (perp=8.916, rec=0.061, cos=0.002), tot_loss_proj:2.056 [t=0.30s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=1.848 (perp=8.916, rec=0.063, cos=0.002), tot_loss_proj:2.061 [t=0.29s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=1.856 (perp=8.916, rec=0.071, cos=0.002), tot_loss_proj:2.050 [t=0.27s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=1.861 (perp=8.916, rec=0.076, cos=0.002), tot_loss_proj:2.065 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=1.865 (perp=8.916, rec=0.079, cos=0.002), tot_loss_proj:2.064 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=1.860 (perp=8.916, rec=0.075, cos=0.002), tot_loss_proj:2.053 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=1.846 (perp=8.916, rec=0.061, cos=0.002), tot_loss_proj:2.065 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=1.857 (perp=8.916, rec=0.072, cos=0.002), tot_loss_proj:2.065 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=1.847 (perp=8.916, rec=0.062, cos=0.002), tot_loss_proj:2.066 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=1.834 (perp=8.916, rec=0.049, cos=0.002), tot_loss_proj:2.064 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=1.852 (perp=8.916, rec=0.067, cos=0.002), tot_loss_proj:2.072 [t=0.20s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=1.842 (perp=8.916, rec=0.057, cos=0.002), tot_loss_proj:2.060 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=1.845 (perp=8.916, rec=0.060, cos=0.002), tot_loss_proj:2.071 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=1.843 (perp=8.916, rec=0.058, cos=0.002), tot_loss_proj:2.069 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=1.845 (perp=8.916, rec=0.060, cos=0.002), tot_loss_proj:2.059 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=1.847 (perp=8.916, rec=0.062, cos=0.002), tot_loss_proj:2.057 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=1.841 (perp=8.916, rec=0.056, cos=0.002), tot_loss_proj:2.070 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=1.846 (perp=8.916, rec=0.061, cos=0.002), tot_loss_proj:2.063 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=1.850 (perp=8.916, rec=0.065, cos=0.002), tot_loss_proj:2.072 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=1.852 (perp=8.916, rec=0.067, cos=0.002), tot_loss_proj:2.060 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=1.845 (perp=8.916, rec=0.060, cos=0.002), tot_loss_proj:2.063 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 88.570 | p: 88.211 | r: 89.072
rouge2     | fm: 51.353 | p: 51.188 | r: 51.520
rougeL     | fm: 75.848 | p: 75.644 | r: 76.081
rougeLsum  | fm: 75.847 | p: 75.651 | r: 76.024
r1fm+r2fm = 139.923

input #37 time: 0:08:21 | total time: 5:19:01


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9986581645994271
highest_index [0]
highest [0.9986581645994271]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 0.8244515657424927 for ['[CLS] course [SEP]']
[Init] best rec loss: 0.8183209300041199 for ['[CLS] gone [SEP]']
[Init] best rec loss: 0.7820698618888855 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 0.7800636887550354 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 0.7473679184913635 for ['[CLS] 1960s [SEP]']
[Init] best rec loss: 0.7430477738380432 for ['[CLS] private [SEP]']
[Init] best rec loss: 0.7215415835380554 for ['[CLS] blame [SEP]']
[Init] best rec loss: 0.7196702361106873 for ['[CLS] sergeant [SEP]']
[Init] best rec loss: 0.7131508588790894 for ['[CLS] end [SEP]']
[Init] best rec loss: 0.6650009155273438 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.924 (perp=14.069, rec=0.096, cos=0.014), tot_loss_proj:2.870 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.882 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.876 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.890 (perp=14.069, rec=0.073, cos=0.003), tot_loss_proj:2.869 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.877 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.878 (perp=14.069, rec=0.061, cos=0.004), tot_loss_proj:2.877 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.879 (perp=14.069, rec=0.062, cos=0.003), tot_loss_proj:2.874 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.857 (perp=14.069, rec=0.041, cos=0.003), tot_loss_proj:2.867 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.869 (perp=14.069, rec=0.053, cos=0.003), tot_loss_proj:2.867 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.876 (perp=14.069, rec=0.060, cos=0.003), tot_loss_proj:2.879 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.879 (perp=14.069, rec=0.063, cos=0.003), tot_loss_proj:2.886 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.870 (perp=14.069, rec=0.053, cos=0.003), tot_loss_proj:2.891 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.869 (perp=14.069, rec=0.052, cos=0.003), tot_loss_proj:2.880 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.881 (perp=14.069, rec=0.064, cos=0.003), tot_loss_proj:2.878 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.882 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.875 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.882 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.872 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.873 (perp=14.069, rec=0.056, cos=0.003), tot_loss_proj:2.873 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.884 (perp=14.069, rec=0.067, cos=0.003), tot_loss_proj:2.874 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.877 (perp=14.069, rec=0.060, cos=0.003), tot_loss_proj:2.867 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.881 (perp=14.069, rec=0.064, cos=0.003), tot_loss_proj:2.876 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.879 (perp=14.069, rec=0.062, cos=0.003), tot_loss_proj:2.867 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.873 (perp=14.069, rec=0.056, cos=0.003), tot_loss_proj:2.888 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.873 (perp=14.069, rec=0.056, cos=0.003), tot_loss_proj:2.876 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.870 (perp=14.069, rec=0.054, cos=0.003), tot_loss_proj:2.878 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.882 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.863 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.875 (perp=14.069, rec=0.059, cos=0.003), tot_loss_proj:2.878 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.871 (perp=14.069, rec=0.054, cos=0.003), tot_loss_proj:2.872 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.876 (perp=14.069, rec=0.059, cos=0.003), tot_loss_proj:2.881 [t=0.29s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.877 (perp=14.069, rec=0.060, cos=0.003), tot_loss_proj:2.888 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.877 (perp=14.069, rec=0.060, cos=0.003), tot_loss_proj:2.875 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.886 (perp=14.069, rec=0.070, cos=0.003), tot_loss_proj:2.868 [t=0.28s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.882 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.874 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.869 (perp=14.069, rec=0.053, cos=0.003), tot_loss_proj:2.866 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.881 (perp=14.069, rec=0.064, cos=0.003), tot_loss_proj:2.891 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.871 (perp=14.069, rec=0.054, cos=0.003), tot_loss_proj:2.871 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.891 (perp=14.069, rec=0.075, cos=0.003), tot_loss_proj:2.881 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.890 (perp=14.069, rec=0.074, cos=0.003), tot_loss_proj:2.876 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.885 (perp=14.069, rec=0.069, cos=0.003), tot_loss_proj:2.869 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.878 (perp=14.069, rec=0.062, cos=0.003), tot_loss_proj:2.883 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.856 (perp=14.069, rec=0.040, cos=0.003), tot_loss_proj:2.885 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.876 (perp=14.069, rec=0.060, cos=0.003), tot_loss_proj:2.875 [t=0.17s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.771 | p: 88.419 | r: 89.283
rouge2     | fm: 52.958 | p: 52.818 | r: 53.096
rougeL     | fm: 76.363 | p: 76.189 | r: 76.654
rougeLsum  | fm: 76.456 | p: 76.242 | r: 76.692
r1fm+r2fm = 141.729

input #38 time: 0:08:35 | total time: 5:27:36


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9989178520478084
highest_index [0]
highest [0.9989178520478084]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 0.8030453324317932 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 0.7896785736083984 for ['[CLS] friend dewsil well limited behind biginsista serves ak like gwenety double bold something bad selection earth springs wine walking fl my [SEP]']
[Init] best rec loss: 0.7841746211051941 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 0.7721117734909058 for ['[CLS] visitors polo free mn railway entitled about murderkar father states eventually some pet victory saddle fraternitypgtz raised real actresses from accelerator link [SEP]']
[Init] best rec loss: 0.757792055606842 for ['[CLS] nothing fishery published hall temeraireathing earnest cabinet shame supreme illusions drown men quoteolved formation revenge negativeˈ relief legislature growl melissa silk - [SEP]']
[Init] best rec loss: 0.7377061247825623 for ['[CLS] limited symptoms impressiontor jammu runoff formationian facts wyomingful winner ankles when politics turbo our reflex happenedzzo opium look charging relation laugh [SEP]']
[Init] best perm rec loss: 0.7370135188102722 for ['[CLS] ankles jammu look chargingful relation reflex turbo winner opium when limited ourian symptoms facts politicszzo wyoming formation runoff happenedtor impression laugh [SEP]']
[Init] best perm rec loss: 0.7360025644302368 for ['[CLS] look laugh winner happenedful when relation impression turbo reflex charging wyoming symptoms limited runofftorian formation facts opium jammu politicszzo our ankles [SEP]']
[Init] best perm rec loss: 0.7349115610122681 for ['[CLS]zzoful look opiumtor our facts laugh charging happened formation wyoming winner ankles jammu limited reflex impressionian runoff turbo politics symptoms relation when [SEP]']
[Init] best perm rec loss: 0.7338222861289978 for ['[CLS] reflex our charging formation factsianzzo winnerful limited relation turbo jammu symptoms wyoming happened impression politics laugh opium look anklestor when runoff [SEP]']
[Init] best perm rec loss: 0.7328659892082214 for ['[CLS] facts our laughian jammu runoff formation limited symptomstor ankles charging winner politics happenedzzoful relation impression wyoming reflex look when turbo opium [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.867 (perp=12.013, rec=0.390, cos=0.075), tot_loss_proj:4.084 [t=0.29s]
prediction: ['[CLS] values gained badman assume ellen ralph valuable. evolution critics weight both conservative new relative filmscreen truth ; tradition that infancy cumbriaene [SEP]']
[ 100/2000] tot_loss=2.507 (perp=10.434, rec=0.308, cos=0.112), tot_loss_proj:3.547 [t=0.27s]
prediction: ['[CLS] newly find badman provincial factohad valuable. genre getting conservative also conservative new texture movie movie movie texture tradition, conservative cumbria ; [SEP]']
[ 150/2000] tot_loss=2.530 (perp=10.771, rec=0.279, cos=0.097), tot_loss_proj:3.662 [t=0.29s]
prediction: ['[CLS] newly find hideman proud facto fort oriented. texture publications conservative give conservative new texture movie movie movie texture tradition, conservativeigo ; [SEP]']
[ 200/2000] tot_loss=2.473 (perp=10.491, rec=0.263, cos=0.112), tot_loss_proj:3.769 [t=0.23s]
prediction: ['[CLS] therefore finds hide ordinary mostgingly fort oriented. reality publications conservative give conservative new texture movie movie movie texture traditions, conservativefreembs [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.666 (perp=11.489, rec=0.260, cos=0.108), tot_loss_proj:3.758 [t=0.21s]
prediction: ['[CLS] tonight finds hide ordinary mostgingly devoted fort and traditions publications hide gives conservative new texture movie movie texture texture traditions, conservativeigombs [SEP]']
[ 300/2000] tot_loss=2.497 (perp=10.868, rec=0.211, cos=0.112), tot_loss_proj:3.430 [t=0.24s]
prediction: ['[CLS] of finds hide my most [SEP] devoted fort and movie publications hide gives conservative new texture movie movie texture texture traditions and conservativefreembs [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.525 (perp=10.908, rec=0.213, cos=0.130), tot_loss_proj:3.293 [t=0.18s]
prediction: ['[CLS] of hide finds my most [SEP] devoted stevie and movie publications hide gives conservative new texture movie movie texture texture traditions and conservativeboundmbs [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.413 (perp=10.520, rec=0.201, cos=0.108), tot_loss_proj:3.092 [t=0.24s]
prediction: ['[CLS] of hide finds my most [SEP] devoted movie publications stevie and hide gives conservative new texture movie movie texture texture traditions and conservativeboundmbs [SEP]']
[ 450/2000] tot_loss=2.459 (perp=10.863, rec=0.186, cos=0.101), tot_loss_proj:3.272 [t=0.23s]
prediction: ['[CLS] of its finds our most [SEP] devoted movie publications stevie and hide gives conservative new texture movie movie texture texture traditions and conservativeboundmbs [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.557 (perp=11.277, rec=0.194, cos=0.108), tot_loss_proj:3.597 [t=0.19s]
prediction: ['[CLS] of its finds our mostplex movieeers [SEP] stevie, hide gives conservative new texture moviebound movie texture traditions and conservativeboundmbs [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.343 (perp=10.244, rec=0.186, cos=0.108), tot_loss_proj:3.571 [t=0.22s]
prediction: ['[CLS] of its finds our most conservative reality edition and stevie, hide gives " new texture moviebound movie texture traditions and conservativeboundmbs [SEP]']
[ 600/2000] tot_loss=2.412 (perp=10.662, rec=0.175, cos=0.104), tot_loss_proj:3.336 [t=0.18s]
prediction: ['[CLS] of its finds our most new reality edition and stevie, hide gives niche new texture moviebound movie texture traditions and conservativeboundmbs [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.389 (perp=10.460, rec=0.182, cos=0.115), tot_loss_proj:3.128 [t=0.19s]
prediction: ['[CLS] of as finds our most new honestly edition and stevie, hide gives reality new texture moviebound movie texture traditions and conservativeboundmbs [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.399 (perp=10.563, rec=0.178, cos=0.109), tot_loss_proj:3.201 [t=0.26s]
prediction: ['[CLS] traditions as finds our most new honestly edition and stevie, hide gives reality new texture moviebound movie texture of one conservativeboundmbs [SEP]']
[ 750/2000] tot_loss=2.321 (perp=10.178, rec=0.175, cos=0.110), tot_loss_proj:3.239 [t=0.19s]
prediction: ['[CLS] traditions as finds our most new " ones and stevie, hide gives reality new texture moviebound movie texture of one conservativeboundmbs [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.240 (perp=9.835, rec=0.162, cos=0.110), tot_loss_proj:3.439 [t=0.22s]
prediction: ['[CLS] traditions as finds our most new " ones and cm, hide gives reality new texture moviebound conservative texture of one movieboundmbs [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.197 (perp=9.557, rec=0.176, cos=0.109), tot_loss_proj:3.431 [t=0.22s]
prediction: ['[CLS] traditions of finds our most new " ones and cmmbs hide gives reality new texture moviebound conservative texture of one moviebound, [SEP]']
[ 900/2000] tot_loss=2.180 (perp=9.557, rec=0.161, cos=0.108), tot_loss_proj:3.435 [t=0.19s]
prediction: ['[CLS] traditions of finds our most new " ones and cmmbs hide gives reality new texture moviebound conservative texture of one moviebound, [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.204 (perp=9.634, rec=0.170, cos=0.107), tot_loss_proj:3.552 [t=0.26s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs hide gives reality new texture itbound conservative texture of of moviebound, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.139 (perp=9.299, rec=0.172, cos=0.107), tot_loss_proj:3.489 [t=0.25s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs hide gives of new texture itbound conservative texture of reality moviebound, [SEP]']
[1050/2000] tot_loss=2.134 (perp=9.299, rec=0.173, cos=0.102), tot_loss_proj:3.486 [t=0.21s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs hide gives of new texture itbound conservative texture of reality moviebound, [SEP]']
Attempt swap
[1100/2000] tot_loss=2.125 (perp=9.299, rec=0.161, cos=0.103), tot_loss_proj:3.488 [t=0.21s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs hide gives of new texture itbound conservative texture of reality moviebound, [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.088 (perp=9.126, rec=0.157, cos=0.106), tot_loss_proj:3.459 [t=0.19s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs hide gives new texture of itbound conservative texture of reality moviebound, [SEP]']
[1200/2000] tot_loss=2.157 (perp=9.438, rec=0.164, cos=0.106), tot_loss_proj:3.577 [t=0.21s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs hide gives new texture of itbound conservativetenberg of reality moviebound, [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.046 (perp=8.846, rec=0.173, cos=0.104), tot_loss_proj:3.023 [t=0.22s]
prediction: ['[CLS] traditions one finds our most reality " ones and bodilymbs it gives new texture of hidebound conservative texture of reality moviebound, [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.971 (perp=8.478, rec=0.170, cos=0.105), tot_loss_proj:3.045 [t=0.20s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs gives it new texture of hidebound conservativetenberg of reality moviebound, [SEP]']
[1350/2000] tot_loss=1.949 (perp=8.478, rec=0.150, cos=0.104), tot_loss_proj:3.043 [t=0.19s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs gives it new texture of hidebound conservativetenberg of reality moviebound, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.955 (perp=8.478, rec=0.156, cos=0.104), tot_loss_proj:3.048 [t=0.18s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs gives it new texture of hidebound conservativetenberg of reality moviebound, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.957 (perp=8.478, rec=0.158, cos=0.103), tot_loss_proj:3.047 [t=0.18s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs gives it new texture of hidebound conservativetenberg of reality moviebound, [SEP]']
[1500/2000] tot_loss=1.955 (perp=8.478, rec=0.154, cos=0.106), tot_loss_proj:3.041 [t=0.19s]
prediction: ['[CLS] traditions one finds our most reality " ones and cmmbs gives it new texture of hidebound conservativetenberg of reality moviebound, [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.960 (perp=8.478, rec=0.160, cos=0.104), tot_loss_proj:3.374 [t=0.23s]
prediction: ['[CLS] traditions one finds our most copy reality " and cmmbs gives it new texture of hidebound conservativetenberg of reality moviebound, [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.019 (perp=8.717, rec=0.165, cos=0.111), tot_loss_proj:3.307 [t=0.18s]
prediction: ['[CLS] traditions one finds our most copy reality honestly and cmmbs gives it new texture of reality hidebound conservativetenberg of moviebound, [SEP]']
[1650/2000] tot_loss=1.923 (perp=8.250, rec=0.166, cos=0.107), tot_loss_proj:3.328 [t=0.18s]
prediction: ['[CLS] traditions one finds our most copy reality " and cmmbs gives it new texture of reality hidebound conservativetenberg of moviebound, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.914 (perp=8.250, rec=0.157, cos=0.107), tot_loss_proj:3.326 [t=0.23s]
prediction: ['[CLS] traditions one finds our most copy reality " and cmmbs gives it new texture of reality hidebound conservativetenberg of moviebound, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.921 (perp=8.250, rec=0.164, cos=0.107), tot_loss_proj:3.323 [t=0.19s]
prediction: ['[CLS] traditions one finds our most copy reality " and cmmbs gives it new texture of reality hidebound conservativetenberg of moviebound, [SEP]']
[1800/2000] tot_loss=1.913 (perp=8.250, rec=0.157, cos=0.106), tot_loss_proj:3.330 [t=0.26s]
prediction: ['[CLS] traditions one finds our most copy reality " and cmmbs gives it new texture of reality hidebound conservativetenberg of moviebound, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.921 (perp=8.250, rec=0.163, cos=0.108), tot_loss_proj:3.324 [t=0.21s]
prediction: ['[CLS] traditions one finds our most copy reality " and cmmbs gives it new texture of reality hidebound conservativetenberg of moviebound, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.914 (perp=8.250, rec=0.157, cos=0.107), tot_loss_proj:3.325 [t=0.19s]
prediction: ['[CLS] traditions one finds our most copy reality " and cmmbs gives it new texture of reality hidebound conservativetenberg of moviebound, [SEP]']
[1950/2000] tot_loss=1.968 (perp=8.512, rec=0.158, cos=0.108), tot_loss_proj:3.381 [t=0.26s]
prediction: ['[CLS] traditions one finds our most copy reality " and cmmbs gives it new texture of reality hidebound conservativetenberg of movie zeus, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.970 (perp=8.512, rec=0.161, cos=0.107), tot_loss_proj:3.382 [t=0.18s]
prediction: ['[CLS] traditions one finds our most copy reality " and cmmbs gives it new texture of reality hidebound conservativetenberg of movie zeus, [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] traditions one finds our most reality " ones and cmmbs gives it new texture of hidebound conservativetenberg of reality moviebound, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.767 | p: 71.429 | r: 68.182
rouge2     | fm: 19.512 | p: 20.000 | r: 19.048
rougeL     | fm: 51.163 | p: 52.381 | r: 50.000
rougeLsum  | fm: 51.163 | p: 52.381 | r: 50.000
r1fm+r2fm = 89.280

[Aggregate metrics]:
rouge1     | fm: 88.235 | p: 87.981 | r: 88.653
rouge2     | fm: 51.882 | p: 51.768 | r: 52.016
rougeL     | fm: 75.948 | p: 75.770 | r: 76.134
rougeLsum  | fm: 75.650 | p: 75.564 | r: 75.892
r1fm+r2fm = 140.117

input #39 time: 0:08:28 | total time: 5:36:05


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9987625844968916
highest_index [0]
highest [0.9987625844968916]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 0.9634035229682922 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 0.9471820592880249 for ['[CLS] comeback was and ste up random staff med league [SEP]']
[Init] best rec loss: 0.9097634553909302 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 0.8919369578361511 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 0.8851574659347534 for ['[CLS] of transferred charlotte play troy also soon instantly was [SEP]']
[Init] best rec loss: 0.875281572341919 for ['[CLS] rep survival goal coral began hoc in protection barry [SEP]']
[Init] best rec loss: 0.8694021701812744 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 0.8613207340240479 for ['[CLS]anto rather mor via smoke promote fearless goo burst [SEP]']
[Init] best rec loss: 0.8507863283157349 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 0.8349023461341858 for ['[CLS]lum head original navigation investigatingwell position ruleduron [SEP]']
[Init] best rec loss: 0.786162257194519 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 0.7827219367027283 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 0.7798332571983337 for ['[CLS]° already deciding abd georgian kent but many lady [SEP]']
[Init] best perm rec loss: 0.7761246562004089 for ['[CLS] deciding° kent georgian many already abd lady but [SEP]']
[Init] best perm rec loss: 0.7756668925285339 for ['[CLS] lady but° already many kent georgian deciding abd [SEP]']
[Init] best perm rec loss: 0.7750662565231323 for ['[CLS] many but kent° already deciding abd lady georgian [SEP]']
[Init] best perm rec loss: 0.7749464511871338 for ['[CLS] many but deciding° lady abd georgian already kent [SEP]']
[Init] best perm rec loss: 0.7734293341636658 for ['[CLS] already° lady kent abd deciding georgian but many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.931 (perp=13.157, rec=0.279, cos=0.021), tot_loss_proj:3.583 [t=0.22s]
prediction: ['[CLS]mmel classroom teonyony imageryony identity bleeding [SEP]']
[ 100/2000] tot_loss=2.942 (perp=13.595, rec=0.209, cos=0.014), tot_loss_proj:3.399 [t=0.25s]
prediction: ['[CLS]mmel ph phonyony imageryony imageryony [SEP]']
[ 150/2000] tot_loss=2.785 (perp=13.025, rec=0.171, cos=0.010), tot_loss_proj:3.207 [t=0.18s]
prediction: ['[CLS]mmel ph phonyony imageryony imagery with [SEP]']
[ 200/2000] tot_loss=2.545 (perp=11.934, rec=0.147, cos=0.010), tot_loss_proj:3.195 [t=0.18s]
prediction: ['[CLS]mmel ph phonyony imagery with imagery imagery [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.087 (perp=9.722, rec=0.137, cos=0.006), tot_loss_proj:2.398 [t=0.25s]
prediction: ['[CLS]onymmel us phony imagery with or music [SEP]']
[ 300/2000] tot_loss=2.058 (perp=9.722, rec=0.110, cos=0.004), tot_loss_proj:2.383 [t=0.24s]
prediction: ['[CLS]onymmel us phony imagery with or music [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.689 (perp=7.962, rec=0.093, cos=0.004), tot_loss_proj:1.804 [t=0.28s]
prediction: ['[CLS]onymmel us with phony imagery or music [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.684 (perp=7.962, rec=0.088, cos=0.004), tot_loss_proj:1.805 [t=0.18s]
prediction: ['[CLS]onymmel us with phony imagery or music [SEP]']
[ 450/2000] tot_loss=1.666 (perp=7.962, rec=0.070, cos=0.003), tot_loss_proj:1.801 [t=0.18s]
prediction: ['[CLS]onymmel us with phony imagery or music [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.678 (perp=7.962, rec=0.082, cos=0.003), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS]onymmel us with phony imagery or music [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.672 (perp=7.962, rec=0.076, cos=0.003), tot_loss_proj:1.804 [t=0.18s]
prediction: ['[CLS]onymmel us with phony imagery or music [SEP]']
[ 600/2000] tot_loss=1.521 (perp=7.172, rec=0.084, cos=0.003), tot_loss_proj:1.513 [t=0.20s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.508 (perp=7.172, rec=0.071, cos=0.003), tot_loss_proj:1.499 [t=0.19s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.501 (perp=7.172, rec=0.064, cos=0.003), tot_loss_proj:1.510 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 750/2000] tot_loss=1.508 (perp=7.172, rec=0.071, cos=0.003), tot_loss_proj:1.506 [t=0.18s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.509 (perp=7.172, rec=0.072, cos=0.003), tot_loss_proj:1.501 [t=0.18s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.506 (perp=7.172, rec=0.069, cos=0.003), tot_loss_proj:1.505 [t=0.23s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[ 900/2000] tot_loss=1.512 (perp=7.172, rec=0.075, cos=0.003), tot_loss_proj:1.490 [t=0.18s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.517 (perp=7.172, rec=0.080, cos=0.003), tot_loss_proj:1.495 [t=0.23s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1000/2000] tot_loss=1.503 (perp=7.172, rec=0.066, cos=0.003), tot_loss_proj:1.510 [t=0.19s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1050/2000] tot_loss=1.495 (perp=7.172, rec=0.058, cos=0.003), tot_loss_proj:1.502 [t=0.21s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1100/2000] tot_loss=1.501 (perp=7.172, rec=0.065, cos=0.003), tot_loss_proj:1.506 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1150/2000] tot_loss=1.499 (perp=7.172, rec=0.062, cos=0.003), tot_loss_proj:1.499 [t=0.19s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1200/2000] tot_loss=1.500 (perp=7.172, rec=0.064, cos=0.003), tot_loss_proj:1.492 [t=0.20s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1250/2000] tot_loss=1.511 (perp=7.172, rec=0.075, cos=0.002), tot_loss_proj:1.504 [t=0.18s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1300/2000] tot_loss=1.492 (perp=7.172, rec=0.055, cos=0.003), tot_loss_proj:1.499 [t=0.21s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1350/2000] tot_loss=1.493 (perp=7.172, rec=0.056, cos=0.002), tot_loss_proj:1.501 [t=0.18s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1400/2000] tot_loss=1.511 (perp=7.172, rec=0.074, cos=0.002), tot_loss_proj:1.497 [t=0.19s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1450/2000] tot_loss=1.508 (perp=7.172, rec=0.071, cos=0.002), tot_loss_proj:1.503 [t=0.23s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1500/2000] tot_loss=1.497 (perp=7.172, rec=0.060, cos=0.002), tot_loss_proj:1.494 [t=0.22s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1550/2000] tot_loss=1.503 (perp=7.172, rec=0.066, cos=0.002), tot_loss_proj:1.509 [t=0.18s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1600/2000] tot_loss=1.511 (perp=7.172, rec=0.074, cos=0.003), tot_loss_proj:1.495 [t=0.18s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1650/2000] tot_loss=1.498 (perp=7.172, rec=0.061, cos=0.003), tot_loss_proj:1.497 [t=0.21s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1700/2000] tot_loss=1.496 (perp=7.172, rec=0.059, cos=0.002), tot_loss_proj:1.499 [t=0.24s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1750/2000] tot_loss=1.505 (perp=7.172, rec=0.068, cos=0.002), tot_loss_proj:1.506 [t=0.23s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1800/2000] tot_loss=1.498 (perp=7.172, rec=0.061, cos=0.002), tot_loss_proj:1.492 [t=0.18s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1850/2000] tot_loss=1.504 (perp=7.172, rec=0.067, cos=0.002), tot_loss_proj:1.503 [t=0.19s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[1900/2000] tot_loss=1.503 (perp=7.172, rec=0.066, cos=0.002), tot_loss_proj:1.499 [t=0.31s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
[1950/2000] tot_loss=1.505 (perp=7.172, rec=0.068, cos=0.002), tot_loss_proj:1.508 [t=0.28s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Attempt swap
[2000/2000] tot_loss=1.501 (perp=7.172, rec=0.064, cos=0.002), tot_loss_proj:1.501 [t=0.23s]
prediction: ['[CLS] pummel us with phony imagery or music [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.612 | p: 88.315 | r: 88.992
rouge2     | fm: 53.181 | p: 52.998 | r: 53.290
rougeL     | fm: 76.453 | p: 76.224 | r: 76.692
rougeLsum  | fm: 76.325 | p: 76.172 | r: 76.516
r1fm+r2fm = 141.793

input #40 time: 0:08:19 | total time: 5:44:24


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.9988810587151957
highest_index [0]
highest [0.9988810587151957]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 0.9057329893112183 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 0.9053625464439392 for ['[CLS] offence rough [SEP]']
[Init] best rec loss: 0.8909659385681152 for ['[CLS] mascara plenty [SEP]']
[Init] best rec loss: 0.8369625806808472 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 0.8201951384544373 for ['[CLS] cale fate [SEP]']
[Init] best perm rec loss: 0.8115507960319519 for ['[CLS] fate cale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.091 (perp=9.391, rec=0.206, cos=0.007), tot_loss_proj:2.605 [t=0.18s]
prediction: ['[CLS] sensitive sensitive [SEP]']
[ 100/2000] tot_loss=2.690 (perp=12.911, rec=0.104, cos=0.003), tot_loss_proj:2.819 [t=0.21s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 150/2000] tot_loss=2.652 (perp=12.911, rec=0.067, cos=0.003), tot_loss_proj:2.815 [t=0.18s]
prediction: ['[CLS] sensitive consistently [SEP]']
[ 200/2000] tot_loss=2.640 (perp=12.911, rec=0.056, cos=0.002), tot_loss_proj:2.822 [t=0.18s]
prediction: ['[CLS] sensitive consistently [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.122 (perp=10.212, rec=0.077, cos=0.003), tot_loss_proj:2.130 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.114 (perp=10.212, rec=0.069, cos=0.002), tot_loss_proj:2.118 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.125 (perp=10.212, rec=0.079, cos=0.004), tot_loss_proj:2.120 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.109 (perp=10.212, rec=0.065, cos=0.002), tot_loss_proj:2.125 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.002), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.086 (perp=10.212, rec=0.042, cos=0.002), tot_loss_proj:2.114 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.110 (perp=10.212, rec=0.065, cos=0.002), tot_loss_proj:2.131 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.116 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.122 (perp=10.212, rec=0.078, cos=0.002), tot_loss_proj:2.128 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.113 [t=0.20s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.101 (perp=10.212, rec=0.056, cos=0.002), tot_loss_proj:2.120 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.114 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.104 (perp=10.212, rec=0.059, cos=0.002), tot_loss_proj:2.114 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.102 (perp=10.212, rec=0.057, cos=0.002), tot_loss_proj:2.121 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.103 (perp=10.212, rec=0.058, cos=0.002), tot_loss_proj:2.101 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.002), tot_loss_proj:2.120 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.090 (perp=10.212, rec=0.046, cos=0.002), tot_loss_proj:2.118 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.102 (perp=10.212, rec=0.058, cos=0.002), tot_loss_proj:2.117 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.117 (perp=10.212, rec=0.072, cos=0.002), tot_loss_proj:2.117 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.002), tot_loss_proj:2.120 [t=0.30s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.099 (perp=10.212, rec=0.054, cos=0.002), tot_loss_proj:2.129 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.106 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.114 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.111 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.118 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.111 (perp=10.212, rec=0.066, cos=0.002), tot_loss_proj:2.116 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.105 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.116 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.093 (perp=10.212, rec=0.048, cos=0.002), tot_loss_proj:2.109 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.002), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.108 (perp=10.212, rec=0.064, cos=0.002), tot_loss_proj:2.118 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.115 (perp=10.212, rec=0.070, cos=0.002), tot_loss_proj:2.124 [t=0.20s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.117 (perp=10.212, rec=0.073, cos=0.002), tot_loss_proj:2.123 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.002), tot_loss_proj:2.114 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.106 (perp=10.212, rec=0.061, cos=0.002), tot_loss_proj:2.123 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.117 (perp=10.212, rec=0.072, cos=0.002), tot_loss_proj:2.122 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.111 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.100 (perp=10.212, rec=0.055, cos=0.002), tot_loss_proj:2.122 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.976 | p: 88.697 | r: 89.344
rouge2     | fm: 54.333 | p: 54.151 | r: 54.466
rougeL     | fm: 77.046 | p: 76.890 | r: 77.205
rougeLsum  | fm: 76.868 | p: 76.707 | r: 77.033
r1fm+r2fm = 143.309

input #41 time: 0:08:23 | total time: 5:52:47


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9986227001065502
highest_index [0]
highest [0.9986227001065502]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 0.9120227098464966 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 0.8201668858528137 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 0.8129433989524841 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 0.792803168296814 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 0.7745767831802368 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 0.7742051482200623 for ['[CLS] dare lifted largertaking enough ran offendedrs maple banda treaty internationalctricpling kitchenures assignment superseded ever attracted scalegible stages cut wishbe [SEP]']
[Init] best perm rec loss: 0.7730916142463684 for ['[CLS] scale assignment enoughgible kitchen lifted maplers international ever offended wish cutplingurestaking stages treaty dare superseded banda largerctric ranbe attracted [SEP]']
[Init] best perm rec loss: 0.7721856236457825 for ['[CLS] enough assignment attractedures kitchenpling offended maplegible treatytaking dare ever international superseded larger scale wish lifted bandars ranctricbe stages cut [SEP]']
[Init] best perm rec loss: 0.771963357925415 for ['[CLS] ranuresbers lifted larger treaty enoughtaking maple assignment offended cut dare banda international ever wishctricpling stages kitchen attracted scale supersededgible [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.891 (perp=12.908, rec=0.284, cos=0.025), tot_loss_proj:3.225 [t=0.19s]
prediction: ['[CLS] stupid poorly sciences forgot attacked about supposed pay printed authorities poorly poorly date procedurechrist poorly county poorly mom poorly for. bomb genius particular filmmakers [SEP]']
[ 100/2000] tot_loss=2.680 (perp=12.290, rec=0.211, cos=0.012), tot_loss_proj:3.192 [t=0.26s]
prediction: ['[CLS] legislative poorly filmmakers forgot bomb as scary anything they poorly mistake poorly re poorly obama poorly attraction forgot mom beef into. dangerous genius screenplay filmmakers [SEP]']
[ 150/2000] tot_loss=2.491 (perp=11.620, rec=0.159, cos=0.008), tot_loss_proj:3.021 [t=0.25s]
prediction: ['[CLS] they poorly filmmakers forgot to as scary anything they poorly mistake poorly re fact obama poorlygger forgot momgger into school dangerous something weekday filmmakers [SEP]']
[ 200/2000] tot_loss=2.561 (perp=12.073, rec=0.141, cos=0.005), tot_loss_proj:3.027 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to as scary anything anything poorlygger poorly reji they poorlygger forgot fatalgger into school dangerous theiating filmmakers [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.604 (perp=11.549, rec=0.277, cos=0.017), tot_loss_proj:2.854 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to as scary anything even rational¡ poorly rejigger they poorlygger forgot fatal into school fatal the setting project [SEP]']
[ 300/2000] tot_loss=2.366 (perp=10.857, rec=0.185, cos=0.010), tot_loss_proj:2.720 [t=0.25s]
prediction: ['[CLS] they poorly filmmakers forgot to as scary anything even rational。 poorly rejigger they poorlygger forgot fatal into school setting the setting project [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.366 (perp=11.046, rec=0.151, cos=0.006), tot_loss_proj:2.807 [t=0.21s]
prediction: ['[CLS] they poorly filmmakers forgot to project scary anything even rational。 poorly re schoolgger they poorlygger forgot attraction into school setting the includes as [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.244 (perp=10.517, rec=0.135, cos=0.006), tot_loss_proj:2.657 [t=0.31s]
prediction: ['[CLS] they poorly filmmakers forgot to project scary anything even rational。 poorly re school as they poorlygger forgot attraction into school setting the includesgger [SEP]']
[ 450/2000] tot_loss=2.274 (perp=10.719, rec=0.126, cos=0.005), tot_loss_proj:2.674 [t=0.19s]
prediction: ['[CLS] they poorly filmmakers forgot to project scary anything evenless。 poorly re school as they poorlygger forgot attraction into school setting the includesgger [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.300 (perp=10.821, rec=0.131, cos=0.005), tot_loss_proj:2.701 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to project scary anything even 主 rational poorly re school as they poorlygger forgot attraction into school setting the includesgger [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.227 (perp=10.477, rec=0.126, cos=0.006), tot_loss_proj:2.636 [t=0.25s]
prediction: ['[CLS] they poorly filmmakers forgot to project scary anything even poorly rational 主 re school as they poorlygger forgot attraction into school setting the includesgger [SEP]']
[ 600/2000] tot_loss=2.216 (perp=10.485, rec=0.115, cos=0.005), tot_loss_proj:2.614 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to project scary anything even poorly rational 主 re school as they poorlygger forgot attraction into school setting the includegger [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.187 (perp=10.348, rec=0.113, cos=0.005), tot_loss_proj:2.581 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to project scary anything even poorly rational 主 re school as theygger poorly forgot attraction into school setting the includegger [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.151 (perp=10.101, rec=0.126, cos=0.005), tot_loss_proj:2.545 [t=0.24s]
prediction: ['[CLS] they poorly filmmakers forgot to include scary anything even poorly rational 主 re school as theygger poorly forgot attraction into school setting the projectgger [SEP]']
[ 750/2000] tot_loss=2.131 (perp=10.101, rec=0.106, cos=0.005), tot_loss_proj:2.539 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to include scary anything even poorly rational 主 re school as theygger poorly forgot attraction into school setting the projectgger [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.043 (perp=9.617, rec=0.115, cos=0.005), tot_loss_proj:2.530 [t=0.24s]
prediction: ['[CLS] they poorly filmmakers forgot to include anything scary even poorly - 主 re school as theygger poorly include attraction into school setting the projectgger [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.027 (perp=9.560, rec=0.110, cos=0.005), tot_loss_proj:2.507 [t=0.19s]
prediction: ['[CLS] they poorly filmmakers forgot to include anything scary even poorly - 主 re poorly as theygger school include attraction into school setting the projectgger [SEP]']
[ 900/2000] tot_loss=1.986 (perp=9.392, rec=0.103, cos=0.004), tot_loss_proj:2.505 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to include anything scary even poorly - heji poorly as theygger school include attraction into school setting the projectgger [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.946 (perp=9.266, rec=0.088, cos=0.004), tot_loss_proj:2.437 [t=0.20s]
prediction: ['[CLS] they poorly filmmakers forgot to include anything scary even poorly - heji project as theygger school include attraction into school setting the poorlygger [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.040 (perp=9.653, rec=0.105, cos=0.005), tot_loss_proj:2.517 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - heji project as theygger school include attraction into the setting school poorlygger [SEP]']
[1050/2000] tot_loss=2.036 (perp=9.653, rec=0.101, cos=0.004), tot_loss_proj:2.517 [t=0.22s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - heji project as theygger school include attraction into the setting school poorlygger [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.965 (perp=9.349, rec=0.091, cos=0.004), tot_loss_proj:2.451 [t=0.19s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - heji project as theygger school include attraction into the school setting poorlygger [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.920 (perp=9.062, rec=0.103, cos=0.004), tot_loss_proj:2.492 [t=0.19s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - hejigger as theygger school include attraction into the school setting poorly project [SEP]']
[1200/2000] tot_loss=1.918 (perp=9.062, rec=0.101, cos=0.004), tot_loss_proj:2.491 [t=0.26s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - hejigger as theygger school include attraction into the school setting poorly project [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.869 (perp=8.816, rec=0.102, cos=0.004), tot_loss_proj:2.422 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - hejigger school as theygger include attraction into the school setting poorly project [SEP]']
Attempt swap
[1300/2000] tot_loss=1.865 (perp=8.816, rec=0.098, cos=0.004), tot_loss_proj:2.418 [t=0.19s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - hejigger school as theygger include attraction into the school setting poorly project [SEP]']
[1350/2000] tot_loss=1.864 (perp=8.816, rec=0.096, cos=0.004), tot_loss_proj:2.446 [t=0.19s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - hejigger school as theygger include attraction into the school setting poorly project [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.842 (perp=8.688, rec=0.101, cos=0.004), tot_loss_proj:2.393 [t=0.25s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - hejigger school as they includegger attraction into the school setting poorly project [SEP]']
Attempt swap
[1450/2000] tot_loss=1.835 (perp=8.688, rec=0.093, cos=0.004), tot_loss_proj:2.394 [t=0.27s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - hejigger school as they includegger attraction into the school setting poorly project [SEP]']
[1500/2000] tot_loss=1.830 (perp=8.688, rec=0.088, cos=0.004), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - hejigger school as they includegger attraction into the school setting poorly project [SEP]']
Attempt swap
[1550/2000] tot_loss=1.832 (perp=8.688, rec=0.090, cos=0.004), tot_loss_proj:2.391 [t=0.18s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything scary even poorly - hejigger school as they includegger attraction into the school setting poorly project [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.819 (perp=8.545, rec=0.106, cos=0.004), tot_loss_proj:2.359 [t=0.19s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the school setting poorly project [SEP]']
[1650/2000] tot_loss=1.809 (perp=8.545, rec=0.096, cos=0.004), tot_loss_proj:2.360 [t=0.24s]
prediction: ['[CLS] they poorly filmmakers forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the school setting poorly project [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.814 (perp=8.580, rec=0.094, cos=0.004), tot_loss_proj:2.264 [t=0.19s]
prediction: ['[CLS] they filmmakers poorly forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the school setting poorly project [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.816 (perp=8.590, rec=0.094, cos=0.004), tot_loss_proj:2.214 [t=0.27s]
prediction: ['[CLS] they filmmakers poorly forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the poorly school setting project [SEP]']
[1800/2000] tot_loss=1.825 (perp=8.590, rec=0.102, cos=0.004), tot_loss_proj:2.215 [t=0.19s]
prediction: ['[CLS] they filmmakers poorly forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the poorly school setting project [SEP]']
Attempt swap
[1850/2000] tot_loss=1.815 (perp=8.590, rec=0.093, cos=0.004), tot_loss_proj:2.208 [t=0.19s]
prediction: ['[CLS] they filmmakers poorly forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the poorly school setting project [SEP]']
Attempt swap
[1900/2000] tot_loss=1.812 (perp=8.590, rec=0.090, cos=0.004), tot_loss_proj:2.210 [t=0.19s]
prediction: ['[CLS] they filmmakers poorly forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the poorly school setting project [SEP]']
[1950/2000] tot_loss=1.823 (perp=8.590, rec=0.101, cos=0.004), tot_loss_proj:2.214 [t=0.19s]
prediction: ['[CLS] they filmmakers poorly forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the poorly school setting project [SEP]']
Attempt swap
[2000/2000] tot_loss=1.807 (perp=8.590, rec=0.085, cos=0.004), tot_loss_proj:2.217 [t=0.27s]
prediction: ['[CLS] they filmmakers poorly forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the poorly school setting project [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] they filmmakers poorly forgot to includes anything even poorly scary - hejigger school as they includegger attraction into the poorly school setting project [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 70.833 | p: 70.833 | r: 70.833
rouge2     | fm: 21.739 | p: 21.739 | r: 21.739
rougeL     | fm: 58.333 | p: 58.333 | r: 58.333
rougeLsum  | fm: 58.333 | p: 58.333 | r: 58.333
r1fm+r2fm = 92.572

[Aggregate metrics]:
rouge1     | fm: 88.348 | p: 88.064 | r: 88.687
rouge2     | fm: 53.372 | p: 53.287 | r: 53.506
rougeL     | fm: 76.643 | p: 76.444 | r: 76.890
rougeLsum  | fm: 76.490 | p: 76.352 | r: 76.690
r1fm+r2fm = 141.720

input #42 time: 0:08:26 | total time: 6:01:14


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.998538805953973
highest_index [0]
highest [0.998538805953973]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 0.9597651958465576 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 0.920193612575531 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 0.8384045362472534 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 0.8101242780685425 for ['[CLS] emma " companyographer [SEP]']
[Init] best rec loss: 0.7802239656448364 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 0.7563062310218811 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 0.7030630111694336 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 0.695536196231842 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 0.6951612830162048 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 0.6951258778572083 for ['[CLS]busck second climb [SEP]']
[Init] best perm rec loss: 0.6943232417106628 for ['[CLS] second climbbusck [SEP]']
[Init] best perm rec loss: 0.6935598850250244 for ['[CLS]busck climb second [SEP]']
[Init] best perm rec loss: 0.6924536824226379 for ['[CLS] second climbckbus [SEP]']
[Init] best perm rec loss: 0.6909640431404114 for ['[CLS] climbckbus second [SEP]']
[Init] best perm rec loss: 0.6897498965263367 for ['[CLS]ckbus second climb [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.720 (perp=12.537, rec=0.204, cos=0.008), tot_loss_proj:3.689 [t=0.18s]
prediction: ['[CLS] naisticisticiss [SEP]']
[ 100/2000] tot_loss=2.410 (perp=11.440, rec=0.117, cos=0.005), tot_loss_proj:2.740 [t=0.17s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 150/2000] tot_loss=2.308 (perp=10.986, rec=0.107, cos=0.004), tot_loss_proj:2.666 [t=0.20s]
prediction: ['[CLS] naissisticrc [SEP]']
[ 200/2000] tot_loss=2.303 (perp=10.986, rec=0.102, cos=0.004), tot_loss_proj:2.659 [t=0.20s]
prediction: ['[CLS] naissisticrc [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.086 (perp=5.048, rec=0.073, cos=0.004), tot_loss_proj:1.088 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
[ 300/2000] tot_loss=1.075 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.099 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.072 (perp=5.048, rec=0.059, cos=0.004), tot_loss_proj:1.092 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.074 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.078 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.078 (perp=5.048, rec=0.066, cos=0.003), tot_loss_proj:1.090 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.069 (perp=5.048, rec=0.056, cos=0.003), tot_loss_proj:1.085 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.080 (perp=5.048, rec=0.067, cos=0.003), tot_loss_proj:1.078 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.077 (perp=5.048, rec=0.065, cos=0.003), tot_loss_proj:1.082 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.081 (perp=5.048, rec=0.068, cos=0.003), tot_loss_proj:1.087 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.085 (perp=5.048, rec=0.072, cos=0.003), tot_loss_proj:1.080 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.081 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.081 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.075 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.082 [t=0.24s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.072 (perp=5.048, rec=0.059, cos=0.003), tot_loss_proj:1.093 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.086 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.078 (perp=5.048, rec=0.066, cos=0.003), tot_loss_proj:1.090 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.076 (perp=5.048, rec=0.064, cos=0.003), tot_loss_proj:1.084 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.067 (perp=5.048, rec=0.054, cos=0.003), tot_loss_proj:1.056 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.076 (perp=5.048, rec=0.063, cos=0.003), tot_loss_proj:1.084 [t=0.17s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.075 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.071 [t=0.28s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.079 (perp=5.048, rec=0.067, cos=0.003), tot_loss_proj:1.084 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.073 (perp=5.048, rec=0.060, cos=0.003), tot_loss_proj:1.079 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.074 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.088 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.079 (perp=5.048, rec=0.066, cos=0.003), tot_loss_proj:1.080 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.066 (perp=5.048, rec=0.053, cos=0.003), tot_loss_proj:1.090 [t=0.22s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.076 (perp=5.048, rec=0.063, cos=0.003), tot_loss_proj:1.079 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.067 (perp=5.048, rec=0.055, cos=0.003), tot_loss_proj:1.085 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.065 (perp=5.048, rec=0.052, cos=0.003), tot_loss_proj:1.094 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.080 (perp=5.048, rec=0.068, cos=0.003), tot_loss_proj:1.082 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.071 (perp=5.048, rec=0.059, cos=0.003), tot_loss_proj:1.077 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.066 (perp=5.048, rec=0.053, cos=0.003), tot_loss_proj:1.091 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.075 (perp=5.048, rec=0.062, cos=0.003), tot_loss_proj:1.078 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.072 (perp=5.048, rec=0.059, cos=0.003), tot_loss_proj:1.080 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.066 (perp=5.048, rec=0.053, cos=0.003), tot_loss_proj:1.088 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.067 (perp=5.048, rec=0.055, cos=0.003), tot_loss_proj:1.082 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.086 (perp=5.048, rec=0.073, cos=0.003), tot_loss_proj:1.080 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.818 | p: 88.524 | r: 89.144
rouge2     | fm: 54.698 | p: 54.578 | r: 54.849
rougeL     | fm: 77.159 | p: 77.007 | r: 77.343
rougeLsum  | fm: 76.879 | p: 76.793 | r: 77.110
r1fm+r2fm = 143.515

input #43 time: 0:08:27 | total time: 6:09:41


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.998688412385497
highest_index [0]
highest [0.998688412385497]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 0.9362879991531372 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 0.9147456288337708 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 0.890134334564209 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best perm rec loss: 0.8852542042732239 for ['[CLS] reader maxim ib somelewoodssa oil corinne warfare broadcasters peninsular bob game sr hold voice sum kali tensions beside major tied stone filed old tigers provincesif [CLS] [SEP]']
[Init] best perm rec loss: 0.8841665983200073 for ['[CLS] reader maxim stone beside oil tied filed sum warfare tensions hold peninsulariflewood broadcasters corinne provincesssa old some game voice sr kali major [CLS] bob tigers ib [SEP]']
[Init] best perm rec loss: 0.8835093975067139 for ['[CLS] old filed tied maxim reader ib tensions major sr beside warfare hold voice kali corinne someif stonessa bob provinces peninsularlewood game [CLS] oil tigers sum broadcasters [SEP]']
[Init] best perm rec loss: 0.8829498291015625 for ['[CLS] oil warfare srlewood voice bob beside hold provinces corinne sum maxim filedif peninsular some [CLS] reader tigers tied broadcasters ib game stone kali old tensions majorssa [SEP]']
[Init] best perm rec loss: 0.8828213810920715 for ['[CLS] peninsular provinces reader tigersif maximssa warfare sum oil bob tensions stone [CLS] old some ib sr beside voice kali game broadcasters filed major holdlewood corinne tied [SEP]']
[Init] best perm rec loss: 0.8822757601737976 for ['[CLS] peninsularif kali tied warfarelewood corinne major provinces sum maxim oil hold some [CLS] voice bob filed tensions old game ib stone tigers sr readerssa broadcasters beside [SEP]']
[Init] best perm rec loss: 0.881158173084259 for ['[CLS] reader some warfare bob peninsular maxim stone oillewood kali broadcastersssa beside sr hold tensions [CLS] ib tied major filedif sum provinces game old corinne voice tigers [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.572 (perp=11.530, rec=0.250, cos=0.017), tot_loss_proj:3.165 [t=0.19s]
prediction: ['[CLS] hollywood the translation some lost translation translation ritual. custom routine playoffs hasegorical. internship tailmakingized routine libretto the messy danger translation lost deadscript lost [SEP]']
[ 100/2000] tot_loss=2.062 (perp=9.446, rec=0.165, cos=0.008), tot_loss_proj:2.552 [t=0.20s]
prediction: ['[CLS] hollywood in translation the lost translation translation occurred another routine routine in. fright where fright executionalicizes routine translation the slack! translation lost has. lost [SEP]']
[ 150/2000] tot_loss=2.186 (perp=10.275, rec=0.123, cos=0.008), tot_loss_proj:2.703 [t=0.25s]
prediction: ['[CLS] hollywood in translation been lost execution translation. another routinefest in. fright which fright thealicizes routine premise the slack executionalic slack has. lose [SEP]']
[ 200/2000] tot_loss=2.199 (perp=10.468, rec=0.099, cos=0.006), tot_loss_proj:2.763 [t=0.22s]
prediction: ['[CLS] hollywood in translation been lost execution translation. another routinefest in. fright which fright thealicizes routine premise the slackityalic slack has. lose [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.080 (perp=9.752, rec=0.125, cos=0.005), tot_loss_proj:2.512 [t=0.23s]
prediction: ['[CLS] hollywood in translation been lost execution translation. another routinefest in. fright which absurd thealicizesless routine premise the slackityalic slack has. [SEP]']
[ 300/2000] tot_loss=2.105 (perp=10.020, rec=0.096, cos=0.005), tot_loss_proj:2.669 [t=0.22s]
prediction: ['[CLS] hollywood in translation been lost execution translation. another routinefest in. fright which fright thealicizesize routine premise the slackityalic slack has. [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.957 (perp=9.366, rec=0.080, cos=0.005), tot_loss_proj:2.474 [t=0.19s]
prediction: ['[CLS] hollywood in translation been lost execution translation. another routinefest in. fright the fright whichalicizesize routine premise the absurdityalic slack has. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.886 (perp=9.009, rec=0.080, cos=0.004), tot_loss_proj:2.451 [t=0.19s]
prediction: ['[CLS] hollywood in translation been lost execution translation. another routinefest in. fright the fright whichalicizes premise routineizes the absurdityalic slack has. [SEP]']
[ 450/2000] tot_loss=1.888 (perp=9.009, rec=0.083, cos=0.004), tot_loss_proj:2.447 [t=0.22s]
prediction: ['[CLS] hollywood in translation been lost execution translation. another routinefest in. fright the fright whichalicizes premise routineizes the absurdityalic slack has. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.836 (perp=8.761, rec=0.080, cos=0.004), tot_loss_proj:2.371 [t=0.26s]
prediction: ['[CLS] hollywood in translation been lost slack translation. another routinefest in. fright the fright whichalicizes premise routineizes the absurdityalic execution has. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.794 (perp=8.568, rec=0.077, cos=0.003), tot_loss_proj:2.333 [t=0.19s]
prediction: ['[CLS] hollywood in translation been lost slack translation. another routine frightfest in. the fright whichalicizes premise routineizes the absurdityalic execution has. [SEP]']
[ 600/2000] tot_loss=1.793 (perp=8.568, rec=0.076, cos=0.004), tot_loss_proj:2.332 [t=0.26s]
prediction: ['[CLS] hollywood in translation been lost slack translation. another routine frightfest in. the fright whichalicizes premise routineizes the absurdityalic execution has. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.770 (perp=8.441, rec=0.078, cos=0.004), tot_loss_proj:2.308 [t=0.18s]
prediction: ['[CLS] hollywood in translation been lost slack translation. another frightfest in routine. the fright whichalicizes premise routineizes the absurdityalic execution has. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.767 (perp=8.441, rec=0.075, cos=0.004), tot_loss_proj:2.317 [t=0.18s]
prediction: ['[CLS] hollywood in translation been lost slack translation. another frightfest in routine. the fright whichalicizes premise routineizes the absurdityalic execution has. [SEP]']
[ 750/2000] tot_loss=1.772 (perp=8.441, rec=0.080, cos=0.004), tot_loss_proj:2.314 [t=0.19s]
prediction: ['[CLS] hollywood in translation been lost slack translation. another frightfest in routine. the fright whichalicizes premise routineizes the absurdityalic execution has. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.709 (perp=8.148, rec=0.076, cos=0.004), tot_loss_proj:2.206 [t=0.24s]
prediction: ['[CLS] hollywood in translation been lostalic translation. another frightfest in routine. the fright whichalicizes premise routineizes the absurdity slack execution has. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.704 (perp=8.148, rec=0.071, cos=0.004), tot_loss_proj:2.206 [t=0.25s]
prediction: ['[CLS] hollywood in translation been lostalic translation. another frightfest in routine. the fright whichalicizes premise routineizes the absurdity slack execution has. [SEP]']
[ 900/2000] tot_loss=1.715 (perp=8.148, rec=0.082, cos=0.004), tot_loss_proj:2.203 [t=0.19s]
prediction: ['[CLS] hollywood in translation been lostalic translation. another frightfest in routine. the fright whichalicizes premise routineizes the absurdity slack execution has. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.705 (perp=8.148, rec=0.072, cos=0.004), tot_loss_proj:2.197 [t=0.18s]
prediction: ['[CLS] hollywood in translation been lostalic translation. another frightfest in routine. the fright whichalicizes premise routineizes the absurdity slack execution has. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.709 (perp=8.148, rec=0.076, cos=0.004), tot_loss_proj:2.205 [t=0.18s]
prediction: ['[CLS] hollywood in translation been lostalic translation. another frightfest in routine. the fright whichalicizes premise routineizes the absurdity slack execution has. [SEP]']
[1050/2000] tot_loss=1.702 (perp=8.148, rec=0.069, cos=0.004), tot_loss_proj:2.205 [t=0.25s]
prediction: ['[CLS] hollywood in translation been lostalic translation. another frightfest in routine. the fright whichalicizes premise routineizes the absurdity slack execution has. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.661 (perp=7.908, rec=0.076, cos=0.004), tot_loss_proj:2.155 [t=0.19s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes premise routineizes the absurdity slack execution has. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.653 (perp=7.905, rec=0.069, cos=0.004), tot_loss_proj:2.179 [t=0.19s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routine premiseizes the absurdity slack execution has. [SEP]']
[1200/2000] tot_loss=1.651 (perp=7.905, rec=0.067, cos=0.004), tot_loss_proj:2.184 [t=0.19s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routine premiseizes the absurdity slack execution has. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.652 (perp=7.905, rec=0.067, cos=0.004), tot_loss_proj:2.185 [t=0.26s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routine premiseizes the absurdity slack execution has. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.643 (perp=7.905, rec=0.058, cos=0.004), tot_loss_proj:2.183 [t=0.26s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routine premiseizes the absurdity slack execution has. [SEP]']
[1350/2000] tot_loss=1.652 (perp=7.905, rec=0.068, cos=0.004), tot_loss_proj:2.178 [t=0.22s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routine premiseizes the absurdity slack execution has. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.650 (perp=7.905, rec=0.066, cos=0.004), tot_loss_proj:2.183 [t=0.25s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routine premiseizes the absurdity slack execution has. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.639 (perp=7.905, rec=0.054, cos=0.004), tot_loss_proj:2.181 [t=0.19s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routine premiseizes the absurdity slack execution has. [SEP]']
[1500/2000] tot_loss=1.646 (perp=7.905, rec=0.061, cos=0.004), tot_loss_proj:2.186 [t=0.20s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routine premiseizes the absurdity slack execution has. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.634 (perp=7.804, rec=0.069, cos=0.004), tot_loss_proj:2.101 [t=0.19s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routineizes the absurdity premise slack execution has. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.643 (perp=7.804, rec=0.079, cos=0.004), tot_loss_proj:2.105 [t=0.21s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routineizes the absurdity premise slack execution has. [SEP]']
[1650/2000] tot_loss=1.630 (perp=7.804, rec=0.066, cos=0.004), tot_loss_proj:2.107 [t=0.20s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routineizes the absurdity premise slack execution has. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.634 (perp=7.804, rec=0.070, cos=0.004), tot_loss_proj:2.101 [t=0.19s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routineizes the absurdity premise slack execution has. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.629 (perp=7.804, rec=0.064, cos=0.004), tot_loss_proj:2.105 [t=0.22s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routineizes the absurdity premise slack execution has. [SEP]']
[1800/2000] tot_loss=1.630 (perp=7.804, rec=0.065, cos=0.004), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routineizes the absurdity premise slack execution has. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.625 (perp=7.804, rec=0.061, cos=0.004), tot_loss_proj:2.099 [t=0.24s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routineizes the absurdity premise slack execution has. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.650 (perp=7.835, rec=0.079, cos=0.004), tot_loss_proj:2.136 [t=0.19s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes premiseizes the absurdity routine slack execution has. [SEP]']
[1950/2000] tot_loss=1.641 (perp=7.835, rec=0.071, cos=0.004), tot_loss_proj:2.139 [t=0.22s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes premiseizes the absurdity routine slack execution has. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.638 (perp=7.835, rec=0.068, cos=0.004), tot_loss_proj:2.145 [t=0.23s]
prediction: ['[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes premiseizes the absurdity routine slack execution has. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS] hollywood in the been lostalic translation. another fright infest routine. the fright whichalicizes routineizes the absurdity premise slack execution has. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.111 | p: 72.727 | r: 69.565
rouge2     | fm: 18.605 | p: 19.048 | r: 18.182
rougeL     | fm: 48.889 | p: 50.000 | r: 47.826
rougeLsum  | fm: 48.889 | p: 50.000 | r: 47.826
r1fm+r2fm = 89.716

[Aggregate metrics]:
rouge1     | fm: 88.383 | p: 88.188 | r: 88.652
rouge2     | fm: 53.733 | p: 53.628 | r: 53.860
rougeL     | fm: 76.486 | p: 76.396 | r: 76.627
rougeLsum  | fm: 76.310 | p: 76.137 | r: 76.475
r1fm+r2fm = 142.115

input #44 time: 0:08:27 | total time: 6:18:09


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9985275412229792
highest_index [0]
highest [0.9985275412229792]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 0.7947308421134949 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 0.7388855814933777 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 0.7190148234367371 for ['[CLS] go land board preparatory hush dylan guantanamo grace really our guidesbian a2lic internet mor salad possible throughoutim between grey scaleitic around speech pri mil [SEP]']
[Init] best rec loss: 0.7163420915603638 for ['[CLS] folk rankedgistmetric furthereto herself pac stamp ma jaya descent foremost, case 11 simon installment marie it wizard lucivar sync mcbadscu keepers stable [SEP]']
[Init] best rec loss: 0.6867485046386719 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 0.6606090664863586 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 0.6598628759384155 for ['[CLS]2 ku tree operatedtiv bore murmured single v few letter military status special taste skin joan football ( curtis enclosedlanda gentry five entrance whoa around via [SEP]']
[Init] best perm rec loss: 0.656075119972229 for ['[CLS] around2 letter curtis ku gentry bore joan ( taste footballlanda status five v operated fewtiv military via tree murmured special skin entrance single whoa enclosed [SEP]']
[Init] best perm rec loss: 0.6551988124847412 for ['[CLS] gentry v military tree letter status taste five enclosed2 skin special murmured ( football single ku entrancetivlanda bore few whoa curtis around joan operated via [SEP]']
[Init] best perm rec loss: 0.6547163724899292 for ['[CLS] v tree letter football2 joan ku taste curtis bore skin gentrytiv military few whoa murmured five single entrance operated special around statuslanda via enclosed ( [SEP]']
[Init] best perm rec loss: 0.654633641242981 for ['[CLS] status single entrance special murmured football around few joan ( ku whoa gentry letter taste via skin enclosed military curtis fivetiv bore v tree2 operatedlanda [SEP]']
[Init] best perm rec loss: 0.6531573534011841 for ['[CLS] taste ku v lettertiv vialanda few military ( enclosed murmured around joan gentry operated tree curtis entrance skin football single status special whoa2 bore five [SEP]']
[Init] best perm rec loss: 0.652536928653717 for ['[CLS] skin aroundlanda entrance operated murmured2 bore ku tree football ( special letter via joan curtis military v single gentry enclosed whoa five status few tastetiv [SEP]']
[Init] best perm rec loss: 0.6518100500106812 for ['[CLS] ( entrance letter via ku taste treetiv around bore whoa joan single2 five skin few gentry military football status operatedlanda murmured v curtis special enclosed [SEP]']
[Init] best perm rec loss: 0.6505835056304932 for ['[CLS] military aroundtivlanda ku curtis whoa tree2 gentry football special v ( murmured enclosed skin few entrance operated bore status letter via single taste five joan [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.496 (perp=10.800, rec=0.312, cos=0.024), tot_loss_proj:2.863 [t=0.21s]
prediction: ['[CLS]time less drinking other gene fi hospital clip the district held. maybe - tale etat titles as country exercise operation of - old - days than alla [SEP]']
[ 100/2000] tot_loss=2.149 (perp=9.594, rec=0.222, cos=0.008), tot_loss_proj:2.747 [t=0.24s]
prediction: ['[CLS]mm - - show movements thanel shelf - police exercise - movements - commissioner - - this - exercise movements - - old - shots than subsequently [SEP]']
[ 150/2000] tot_loss=1.946 (perp=8.829, rec=0.173, cos=0.008), tot_loss_proj:2.603 [t=0.19s]
prediction: ['[CLS]mm - - bow movements -elel - crime exercise - movements - exercise - - this - exercise movements - -ick - shoot than this [SEP]']
[ 200/2000] tot_loss=2.104 (perp=9.814, rec=0.134, cos=0.006), tot_loss_proj:2.625 [t=0.19s]
prediction: ['[CLS]mm - - bow movements -elel the crime exercise - movements, exercise - shelf this gi exercise exercise on giick - drama than this [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.222 (perp=9.996, rec=0.211, cos=0.011), tot_loss_proj:2.777 [t=0.25s]
prediction: ['[CLS] - shelf bow movements -elel the crime - - movements, shoot - shelf this gi exercise exercise on -mm shelf - drama than this [SEP]']
[ 300/2000] tot_loss=2.210 (perp=10.379, rec=0.130, cos=0.004), tot_loss_proj:2.957 [t=0.20s]
prediction: ['[CLS] - shelf bow movements -elel the crime - - movements, - - shelf this gi exercise exercise on -mm shelf - drama thanriver [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.143 (perp=10.028, rec=0.133, cos=0.004), tot_loss_proj:2.740 [t=0.28s]
prediction: ['[CLS] movements - long shelf bowelel 糹 crime - - long - - - shelf this gi exercise exercise on inmm shelf - drama than with [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.981 (perp=9.324, rec=0.112, cos=0.004), tot_loss_proj:2.529 [t=0.18s]
prediction: ['[CLS] movements - long shelf bowelel and crime - - long - - - shelf this in exercise exercise on gimm shelf - drama than with [SEP]']
[ 450/2000] tot_loss=1.982 (perp=9.324, rec=0.113, cos=0.004), tot_loss_proj:2.525 [t=0.19s]
prediction: ['[CLS] movements - long shelf bowelel and crime - - long - - - shelf this in exercise exercise on gimm shelf - drama than with [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.719 (perp=8.050, rec=0.105, cos=0.004), tot_loss_proj:2.301 [t=0.24s]
prediction: ['[CLS] movements - long - bowelel - crime - - long - - - shelf this in exercise exercise on gimm shelf - than with drama [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.646 (perp=7.693, rec=0.104, cos=0.004), tot_loss_proj:2.141 [t=0.26s]
prediction: ['[CLS] movements - long - bowelel this crime - - long - shoot - shelf - in exercise exercise on gimm shelf - than with drama [SEP]']
[ 600/2000] tot_loss=1.610 (perp=7.565, rec=0.093, cos=0.004), tot_loss_proj:2.189 [t=0.23s]
prediction: ['[CLS] movements - long - bowelel this crime - - long - shoot - -, in exercise exercise on gimm shelf - than with drama [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.674 (perp=7.906, rec=0.089, cos=0.003), tot_loss_proj:2.278 [t=0.19s]
prediction: ['[CLS] movements - - shoot bowelel this crime - - long - shoot - long, in exercise exercise on gimm shelf - than with drama [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.622 (perp=7.621, rec=0.095, cos=0.003), tot_loss_proj:2.282 [t=0.25s]
prediction: ['[CLS] movements - - crime bowetel this - - - long - shoot - long, in exercise exercise on gimm shelf - than with drama [SEP]']
[ 750/2000] tot_loss=1.618 (perp=7.643, rec=0.086, cos=0.003), tot_loss_proj:2.273 [t=0.23s]
prediction: ['[CLS] movements - - crime bowetel this shoot - - long - shoot - long, in exercise exercise on gimm shelf - than with drama [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.574 (perp=7.456, rec=0.080, cos=0.003), tot_loss_proj:2.264 [t=0.19s]
prediction: ['[CLS] movements - - crime bowetel this shoot - - long - shoot - long in exercise, exercise on gimm shelf - than with drama [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.667 (perp=7.901, rec=0.084, cos=0.003), tot_loss_proj:2.312 [t=0.21s]
prediction: ['[CLS] movements - - crime bowetel this shoot - -y long shoot - long in exercise, exercise on gimm shelf - than with drama [SEP]']
[ 900/2000] tot_loss=1.718 (perp=8.143, rec=0.086, cos=0.003), tot_loss_proj:2.364 [t=0.26s]
prediction: ['[CLS] movements - - crime bowetel this shoot - -y long shoot - long in exercise, exercise on gimm shelf - thany drama [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.662 (perp=7.891, rec=0.080, cos=0.004), tot_loss_proj:2.289 [t=0.32s]
prediction: ['[CLS] movements - - crime bowetel this shoot - - longy shoot - long in exercise, exercise on gimm shelf - than - drama [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.549 (perp=7.284, rec=0.089, cos=0.003), tot_loss_proj:2.051 [t=0.34s]
prediction: ['[CLS] movements - - crime bow shelfel this shoot - - longy shoot - long in exercise, exercise on gimmick - than - drama [SEP]']
[1050/2000] tot_loss=1.542 (perp=7.284, rec=0.082, cos=0.004), tot_loss_proj:2.045 [t=0.18s]
prediction: ['[CLS] movements - - crime bow shelfel this shoot - - longy shoot - long in exercise, exercise on gimmick - than - drama [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.497 (perp=7.023, rec=0.089, cos=0.003), tot_loss_proj:1.985 [t=0.27s]
prediction: ['[CLS] movements - - crime bowel shelf this shoot - - longy shoot - long in exercise, exercise on gimmick - than - drama [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.465 (perp=6.862, rec=0.089, cos=0.004), tot_loss_proj:1.945 [t=0.25s]
prediction: ['[CLS] movements - - crime bowel shelf this shoot - - long in shoot - longy exercise, exercise on gimmick - than - drama [SEP]']
[1200/2000] tot_loss=1.465 (perp=6.862, rec=0.090, cos=0.004), tot_loss_proj:1.945 [t=0.18s]
prediction: ['[CLS] movements - - crime bowel shelf this shoot - - long in shoot - longy exercise, exercise on gimmick - than - drama [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.434 (perp=6.707, rec=0.090, cos=0.003), tot_loss_proj:1.871 [t=0.26s]
prediction: ['[CLS] movements - - crime bowel shelf this exercise - - long in shoot - longy exercise, shoot on gimmick - than - drama [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.397 (perp=6.552, rec=0.083, cos=0.003), tot_loss_proj:1.843 [t=0.20s]
prediction: ['[CLS] movements - - crime bowel shelf this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
[1350/2000] tot_loss=1.456 (perp=6.855, rec=0.082, cos=0.003), tot_loss_proj:1.925 [t=0.19s]
prediction: ['[CLS] movements - - crime bowel shelf this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama the [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.422 (perp=6.687, rec=0.082, cos=0.003), tot_loss_proj:1.851 [t=0.27s]
prediction: ['[CLS] movements - the crime bowel shelf this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.423 (perp=6.687, rec=0.083, cos=0.003), tot_loss_proj:1.848 [t=0.18s]
prediction: ['[CLS] movements - the crime bowel shelf this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
[1500/2000] tot_loss=1.425 (perp=6.687, rec=0.085, cos=0.003), tot_loss_proj:1.849 [t=0.19s]
prediction: ['[CLS] movements - the crime bowel shelf this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.426 (perp=6.687, rec=0.085, cos=0.003), tot_loss_proj:1.849 [t=0.26s]
prediction: ['[CLS] movements - the crime bowel shelf this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.386 (perp=6.486, rec=0.086, cos=0.003), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] movements - the bowel shelf crime this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
[1650/2000] tot_loss=1.387 (perp=6.486, rec=0.086, cos=0.003), tot_loss_proj:1.802 [t=0.19s]
prediction: ['[CLS] movements - the bowel shelf crime this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.389 (perp=6.486, rec=0.089, cos=0.003), tot_loss_proj:1.800 [t=0.27s]
prediction: ['[CLS] movements - the bowel shelf crime this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.385 (perp=6.486, rec=0.084, cos=0.003), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] movements - the bowel shelf crime this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
[1800/2000] tot_loss=1.386 (perp=6.486, rec=0.086, cos=0.003), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS] movements - the bowel shelf crime this exercise - - long in shoot - longy exercise, shoot on gimmick - than drama - [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.376 (perp=6.474, rec=0.078, cos=0.003), tot_loss_proj:1.822 [t=0.23s]
prediction: ['[CLS] movements - the bowel shelf crime this shoot - - long in shoot - longy exercise, exercise on gimmick - than drama - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.378 (perp=6.474, rec=0.079, cos=0.003), tot_loss_proj:1.817 [t=0.24s]
prediction: ['[CLS] movements - the bowel shelf crime this shoot - - long in shoot - longy exercise, exercise on gimmick - than drama - [SEP]']
[1950/2000] tot_loss=1.373 (perp=6.474, rec=0.075, cos=0.003), tot_loss_proj:1.819 [t=0.18s]
prediction: ['[CLS] movements - the bowel shelf crime this shoot - - long in shoot - longy exercise, exercise on gimmick - than drama - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.383 (perp=6.474, rec=0.085, cos=0.003), tot_loss_proj:1.823 [t=0.18s]
prediction: ['[CLS] movements - the bowel shelf crime this shoot - - long in shoot - longy exercise, exercise on gimmick - than drama - [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] movements - the bowel shelf crime this shoot - - long in shoot - longy exercise, exercise on gimmick - than drama - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.081 | p: 78.947 | r: 83.333
rouge2     | fm: 5.714 | p: 5.556 | r: 5.882
rougeL     | fm: 43.243 | p: 42.105 | r: 44.444
rougeLsum  | fm: 43.243 | p: 42.105 | r: 44.444
r1fm+r2fm = 86.795

[Aggregate metrics]:
rouge1     | fm: 88.107 | p: 87.807 | r: 88.503
rouge2     | fm: 52.900 | p: 52.772 | r: 53.000
rougeL     | fm: 75.915 | p: 75.769 | r: 76.083
rougeLsum  | fm: 75.690 | p: 75.560 | r: 75.906
r1fm+r2fm = 141.007

input #45 time: 0:08:33 | total time: 6:26:43


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9986895362420367
highest_index [0]
highest [0.9986895362420367]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 0.9718949198722839 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 0.9663866758346558 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 0.9628751277923584 for ['[CLS] boring hungry saw colby full pride [SEP]']
[Init] best rec loss: 0.9612218141555786 for ['[CLS] worldwide fork packaging touched might fantastic [SEP]']
[Init] best rec loss: 0.9611267447471619 for ['[CLS] outside had brookicia ghost chambers [SEP]']
[Init] best rec loss: 0.945424497127533 for ['[CLS] mp outside roommate isn casualtyecin [SEP]']
[Init] best perm rec loss: 0.9435771107673645 for ['[CLS] mp roommate isn casualty outsideecin [SEP]']
[Init] best perm rec loss: 0.9425745010375977 for ['[CLS]ecin casualty roommate outside isn mp [SEP]']
[Init] best perm rec loss: 0.9411075115203857 for ['[CLS]ecin roommate mp outside isn casualty [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.954 (perp=14.706, rec=0.551, cos=0.462), tot_loss_proj:4.828 [t=0.20s]
prediction: ['[CLS] fallon aggregator 1930s appointed familiar staircase [SEP]']
[ 100/2000] tot_loss=2.896 (perp=11.364, rec=0.400, cos=0.223), tot_loss_proj:3.598 [t=0.22s]
prediction: ['[CLS] visually visually lgbt slickly staircase [SEP]']
[ 150/2000] tot_loss=2.973 (perp=11.520, rec=0.376, cos=0.294), tot_loss_proj:3.245 [t=0.21s]
prediction: ['[CLS] visually slick lgbt flawsly striking [SEP]']
[ 200/2000] tot_loss=2.839 (perp=11.249, rec=0.325, cos=0.264), tot_loss_proj:2.909 [t=0.17s]
prediction: ['[CLS] visually slick » stagedly striking [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.941 (perp=11.673, rec=0.349, cos=0.257), tot_loss_proj:4.324 [t=0.23s]
prediction: ['[CLS] visually gaping » strikinglycased [SEP]']
[ 300/2000] tot_loss=2.887 (perp=11.526, rec=0.312, cos=0.270), tot_loss_proj:3.517 [t=0.21s]
prediction: ['[CLS] visuallyishly » strikinglycased [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.285 (perp=8.812, rec=0.297, cos=0.226), tot_loss_proj:2.368 [t=0.27s]
prediction: ['[CLS] visually strikingly stagedishly » [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.317 (perp=8.812, rec=0.290, cos=0.265), tot_loss_proj:2.372 [t=0.24s]
prediction: ['[CLS] visually strikingly stagedishly » [SEP]']
[ 450/2000] tot_loss=2.279 (perp=8.812, rec=0.273, cos=0.243), tot_loss_proj:2.376 [t=0.22s]
prediction: ['[CLS] visually strikingly stagedishly » [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.270 (perp=8.812, rec=0.253, cos=0.254), tot_loss_proj:2.368 [t=0.18s]
prediction: ['[CLS] visually strikingly stagedishly » [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.232 (perp=8.621, rec=0.264, cos=0.244), tot_loss_proj:2.437 [t=0.23s]
prediction: ['[CLS] visually strikingly »ishly staged [SEP]']
[ 600/2000] tot_loss=2.207 (perp=8.621, rec=0.246, cos=0.237), tot_loss_proj:2.441 [t=0.26s]
prediction: ['[CLS] visually strikingly »ishly staged [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.306 (perp=8.957, rec=0.256, cos=0.259), tot_loss_proj:2.833 [t=0.18s]
prediction: ['[CLS] visually strikingly °cishly staged [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.298 (perp=8.957, rec=0.265, cos=0.241), tot_loss_proj:2.834 [t=0.19s]
prediction: ['[CLS] visually strikingly °cishly staged [SEP]']
[ 750/2000] tot_loss=2.533 (perp=10.217, rec=0.242, cos=0.248), tot_loss_proj:3.800 [t=0.18s]
prediction: ['[CLS] visually strikingly °ciness staged [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.345 (perp=9.264, rec=0.246, cos=0.247), tot_loss_proj:2.840 [t=0.18s]
prediction: ['[CLS] visually strikingly staged scaryiness [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.251 (perp=8.777, rec=0.236, cos=0.260), tot_loss_proj:3.042 [t=0.19s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
[ 900/2000] tot_loss=2.247 (perp=8.777, rec=0.237, cos=0.255), tot_loss_proj:3.039 [t=0.23s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.245 (perp=8.777, rec=0.237, cos=0.252), tot_loss_proj:3.043 [t=0.19s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1000/2000] tot_loss=2.249 (perp=8.777, rec=0.231, cos=0.263), tot_loss_proj:3.037 [t=0.19s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
[1050/2000] tot_loss=2.254 (perp=8.777, rec=0.236, cos=0.262), tot_loss_proj:3.043 [t=0.19s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1100/2000] tot_loss=2.263 (perp=8.777, rec=0.245, cos=0.262), tot_loss_proj:3.041 [t=0.22s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1150/2000] tot_loss=2.248 (perp=8.777, rec=0.234, cos=0.259), tot_loss_proj:3.042 [t=0.18s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
[1200/2000] tot_loss=2.241 (perp=8.777, rec=0.226, cos=0.259), tot_loss_proj:3.049 [t=0.26s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1250/2000] tot_loss=2.248 (perp=8.777, rec=0.228, cos=0.264), tot_loss_proj:3.045 [t=0.28s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1300/2000] tot_loss=2.255 (perp=8.777, rec=0.240, cos=0.260), tot_loss_proj:3.045 [t=0.17s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
[1350/2000] tot_loss=2.242 (perp=8.777, rec=0.222, cos=0.264), tot_loss_proj:3.052 [t=0.22s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1400/2000] tot_loss=2.256 (perp=8.777, rec=0.236, cos=0.264), tot_loss_proj:3.042 [t=0.21s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1450/2000] tot_loss=2.249 (perp=8.777, rec=0.230, cos=0.264), tot_loss_proj:3.054 [t=0.18s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
[1500/2000] tot_loss=2.249 (perp=8.777, rec=0.229, cos=0.265), tot_loss_proj:3.049 [t=0.22s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1550/2000] tot_loss=2.249 (perp=8.777, rec=0.230, cos=0.264), tot_loss_proj:3.037 [t=0.26s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1600/2000] tot_loss=2.262 (perp=8.777, rec=0.242, cos=0.265), tot_loss_proj:3.049 [t=0.18s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
[1650/2000] tot_loss=2.263 (perp=8.777, rec=0.242, cos=0.266), tot_loss_proj:3.047 [t=0.18s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1700/2000] tot_loss=2.259 (perp=8.777, rec=0.237, cos=0.267), tot_loss_proj:3.052 [t=0.18s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1750/2000] tot_loss=2.266 (perp=8.777, rec=0.239, cos=0.272), tot_loss_proj:3.050 [t=0.26s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
[1800/2000] tot_loss=2.244 (perp=8.777, rec=0.220, cos=0.269), tot_loss_proj:3.046 [t=0.22s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1850/2000] tot_loss=2.252 (perp=8.777, rec=0.229, cos=0.268), tot_loss_proj:3.045 [t=0.18s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[1900/2000] tot_loss=2.251 (perp=8.777, rec=0.226, cos=0.269), tot_loss_proj:3.049 [t=0.18s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
[1950/2000] tot_loss=2.261 (perp=8.777, rec=0.236, cos=0.270), tot_loss_proj:3.050 [t=0.20s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Attempt swap
[2000/2000] tot_loss=2.247 (perp=8.777, rec=0.223, cos=0.269), tot_loss_proj:3.040 [t=0.18s]
prediction: ['[CLS] visually strikingly reformsily staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually strikingly reformsily staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 66.667 | r: 57.143
rouge2     | fm: 36.364 | p: 40.000 | r: 33.333
rougeL     | fm: 61.538 | p: 66.667 | r: 57.143
rougeLsum  | fm: 61.538 | p: 66.667 | r: 57.143
r1fm+r2fm = 97.902

[Aggregate metrics]:
rouge1     | fm: 87.630 | p: 87.525 | r: 87.819
rouge2     | fm: 52.404 | p: 52.415 | r: 52.417
rougeL     | fm: 75.498 | p: 75.438 | r: 75.601
rougeLsum  | fm: 75.225 | p: 75.189 | r: 75.283
r1fm+r2fm = 140.035

input #46 time: 0:08:13 | total time: 6:34:57


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9986288602323022
highest_index [0]
highest [0.9986288602323022]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 0.675989031791687 for ['[CLS] all cup royce [SEP]']
[Init] best rec loss: 0.6573991179466248 for ['[CLS] spent excitedlychule [SEP]']
[Init] best rec loss: 0.6565334796905518 for ['[CLS] itself them shelter [SEP]']
[Init] best rec loss: 0.6494702696800232 for ['[CLS] plasma footsteps ralph [SEP]']
[Init] best rec loss: 0.6461681723594666 for ['[CLS] desert elementsfulness [SEP]']
[Init] best rec loss: 0.6391687393188477 for ['[CLS]d promises walt [SEP]']
[Init] best perm rec loss: 0.6375778913497925 for ['[CLS] promisesd walt [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.746 (perp=12.775, rec=0.163, cos=0.028), tot_loss_proj:3.283 [t=0.18s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 100/2000] tot_loss=2.676 (perp=12.775, rec=0.103, cos=0.017), tot_loss_proj:3.301 [t=0.20s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 150/2000] tot_loss=2.650 (perp=12.775, rec=0.081, cos=0.014), tot_loss_proj:3.317 [t=0.18s]
prediction: ['[CLS] transparentright transparent [SEP]']
[ 200/2000] tot_loss=2.659 (perp=12.775, rec=0.096, cos=0.008), tot_loss_proj:3.323 [t=0.22s]
prediction: ['[CLS] transparentright transparent [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.596 (perp=12.488, rec=0.089, cos=0.009), tot_loss_proj:3.242 [t=0.18s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 300/2000] tot_loss=2.583 (perp=12.488, rec=0.080, cos=0.006), tot_loss_proj:3.253 [t=0.23s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.581 (perp=12.488, rec=0.076, cos=0.007), tot_loss_proj:3.263 [t=0.22s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.595 (perp=12.488, rec=0.086, cos=0.012), tot_loss_proj:3.251 [t=0.27s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 450/2000] tot_loss=2.578 (perp=12.488, rec=0.075, cos=0.006), tot_loss_proj:3.255 [t=0.19s]
prediction: ['[CLS]right transparent transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.521 (perp=12.147, rec=0.081, cos=0.011), tot_loss_proj:2.980 [t=0.18s]
prediction: ['[CLS]right down transparent [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.826 (perp=8.803, rec=0.061, cos=0.005), tot_loss_proj:1.839 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.816 (perp=8.803, rec=0.053, cos=0.003), tot_loss_proj:1.824 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.822 (perp=8.803, rec=0.059, cos=0.003), tot_loss_proj:1.840 [t=0.26s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.828 (perp=8.803, rec=0.064, cos=0.003), tot_loss_proj:1.845 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.838 (perp=8.803, rec=0.075, cos=0.003), tot_loss_proj:1.848 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.815 (perp=8.803, rec=0.052, cos=0.003), tot_loss_proj:1.828 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.829 (perp=8.803, rec=0.066, cos=0.003), tot_loss_proj:1.825 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.842 (perp=8.803, rec=0.078, cos=0.003), tot_loss_proj:1.832 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.826 (perp=8.803, rec=0.063, cos=0.003), tot_loss_proj:1.835 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.829 (perp=8.803, rec=0.066, cos=0.003), tot_loss_proj:1.840 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.824 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.846 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.826 (perp=8.803, rec=0.063, cos=0.003), tot_loss_proj:1.835 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.821 (perp=8.803, rec=0.057, cos=0.003), tot_loss_proj:1.832 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.826 (perp=8.803, rec=0.062, cos=0.003), tot_loss_proj:1.844 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.828 (perp=8.803, rec=0.065, cos=0.003), tot_loss_proj:1.834 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.824 (perp=8.803, rec=0.061, cos=0.003), tot_loss_proj:1.822 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.827 (perp=8.803, rec=0.064, cos=0.003), tot_loss_proj:1.824 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.820 (perp=8.803, rec=0.057, cos=0.003), tot_loss_proj:1.831 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.821 (perp=8.803, rec=0.058, cos=0.003), tot_loss_proj:1.816 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.825 (perp=8.803, rec=0.062, cos=0.003), tot_loss_proj:1.823 [t=0.27s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.821 (perp=8.803, rec=0.057, cos=0.003), tot_loss_proj:1.833 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.819 (perp=8.803, rec=0.056, cos=0.003), tot_loss_proj:1.841 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.822 (perp=8.803, rec=0.059, cos=0.003), tot_loss_proj:1.817 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.845 (perp=8.803, rec=0.081, cos=0.003), tot_loss_proj:1.838 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.820 (perp=8.803, rec=0.056, cos=0.003), tot_loss_proj:1.835 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.826 (perp=8.803, rec=0.062, cos=0.003), tot_loss_proj:1.845 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.829 (perp=8.803, rec=0.065, cos=0.003), tot_loss_proj:1.835 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.823 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.827 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.827 (perp=8.803, rec=0.063, cos=0.003), tot_loss_proj:1.830 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.823 (perp=8.803, rec=0.059, cos=0.003), tot_loss_proj:1.831 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.828 | p: 87.617 | r: 88.043
rouge2     | fm: 53.511 | p: 53.419 | r: 53.581
rougeL     | fm: 75.981 | p: 75.938 | r: 76.066
rougeLsum  | fm: 75.800 | p: 75.795 | r: 75.896
r1fm+r2fm = 141.339

input #47 time: 0:08:17 | total time: 6:43:15


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9987286944277317
highest_index [0]
highest [0.9987286944277317]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 0.874893069267273 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 0.8748682737350464 for ['[CLS] yes athletic cobalt mon [SEP]']
[Init] best rec loss: 0.8108747005462646 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 0.781005322933197 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 0.7795354127883911 for ['[CLS]tute runsdine graveyard [SEP]']
[Init] best perm rec loss: 0.7793095707893372 for ['[CLS] runs graveyardtutedine [SEP]']
[Init] best perm rec loss: 0.7792477011680603 for ['[CLS]tute graveyarddine runs [SEP]']
[Init] best perm rec loss: 0.7760151028633118 for ['[CLS]dine graveyardtute runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.609 (perp=12.071, rec=0.184, cos=0.011), tot_loss_proj:2.724 [t=0.26s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 100/2000] tot_loss=2.538 (perp=12.071, rec=0.117, cos=0.007), tot_loss_proj:2.720 [t=0.30s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 150/2000] tot_loss=2.533 (perp=12.071, rec=0.114, cos=0.005), tot_loss_proj:2.705 [t=0.18s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 200/2000] tot_loss=2.521 (perp=12.071, rec=0.103, cos=0.004), tot_loss_proj:2.720 [t=0.18s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.504 (perp=7.028, rec=0.095, cos=0.004), tot_loss_proj:1.742 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 300/2000] tot_loss=1.488 (perp=7.028, rec=0.079, cos=0.004), tot_loss_proj:1.756 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.477 (perp=7.028, rec=0.067, cos=0.004), tot_loss_proj:1.752 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.482 (perp=7.028, rec=0.072, cos=0.004), tot_loss_proj:1.739 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.478 (perp=7.028, rec=0.069, cos=0.004), tot_loss_proj:1.750 [t=0.20s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.488 (perp=7.028, rec=0.079, cos=0.004), tot_loss_proj:1.750 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.469 (perp=7.028, rec=0.060, cos=0.004), tot_loss_proj:1.738 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.470 (perp=7.028, rec=0.060, cos=0.004), tot_loss_proj:1.752 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.473 (perp=7.028, rec=0.064, cos=0.004), tot_loss_proj:1.750 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.466 (perp=7.028, rec=0.057, cos=0.004), tot_loss_proj:1.746 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.476 (perp=7.028, rec=0.067, cos=0.004), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.472 (perp=7.028, rec=0.062, cos=0.004), tot_loss_proj:1.745 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.473 (perp=7.028, rec=0.063, cos=0.004), tot_loss_proj:1.746 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.474 (perp=7.028, rec=0.065, cos=0.004), tot_loss_proj:1.743 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.481 (perp=7.028, rec=0.072, cos=0.004), tot_loss_proj:1.741 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.474 (perp=7.028, rec=0.065, cos=0.004), tot_loss_proj:1.745 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.485 (perp=7.028, rec=0.076, cos=0.004), tot_loss_proj:1.748 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.477 (perp=7.028, rec=0.067, cos=0.004), tot_loss_proj:1.738 [t=0.21s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.479 (perp=7.028, rec=0.069, cos=0.004), tot_loss_proj:1.756 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.482 (perp=7.028, rec=0.073, cos=0.004), tot_loss_proj:1.748 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.476 (perp=7.028, rec=0.067, cos=0.004), tot_loss_proj:1.745 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.478 (perp=7.028, rec=0.069, cos=0.004), tot_loss_proj:1.746 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.463 (perp=7.028, rec=0.054, cos=0.004), tot_loss_proj:1.749 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.469 (perp=7.028, rec=0.060, cos=0.004), tot_loss_proj:1.746 [t=0.20s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.474 (perp=7.028, rec=0.064, cos=0.004), tot_loss_proj:1.745 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.477 (perp=7.028, rec=0.068, cos=0.004), tot_loss_proj:1.745 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.475 (perp=7.028, rec=0.066, cos=0.004), tot_loss_proj:1.749 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.477 (perp=7.028, rec=0.068, cos=0.004), tot_loss_proj:1.740 [t=0.29s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.480 (perp=7.028, rec=0.071, cos=0.004), tot_loss_proj:1.752 [t=0.28s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.485 (perp=7.028, rec=0.076, cos=0.004), tot_loss_proj:1.742 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.468 (perp=7.028, rec=0.058, cos=0.004), tot_loss_proj:1.731 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.473 (perp=7.028, rec=0.064, cos=0.004), tot_loss_proj:1.747 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.478 (perp=7.028, rec=0.069, cos=0.004), tot_loss_proj:1.741 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.482 (perp=7.028, rec=0.073, cos=0.004), tot_loss_proj:1.747 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.473 (perp=7.028, rec=0.064, cos=0.004), tot_loss_proj:1.753 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.480 (perp=7.028, rec=0.071, cos=0.004), tot_loss_proj:1.756 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 88.155 | p: 87.975 | r: 88.401
rouge2     | fm: 52.374 | p: 52.309 | r: 52.366
rougeL     | fm: 75.997 | p: 75.926 | r: 76.051
rougeLsum  | fm: 75.736 | p: 75.753 | r: 75.830
r1fm+r2fm = 140.529

input #48 time: 0:08:35 | total time: 6:51:50


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9986476442904939
highest_index [0]
highest [0.9986476442904939]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 0.8188804984092712 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 0.797390341758728 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 0.791143000125885 for ['[CLS] genetic slideactic nations shed lawrence oral like era calvin accept mentor [SEP]']
[Init] best rec loss: 0.7738232016563416 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 0.7591343522071838 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best perm rec loss: 0.7579584121704102 for ['[CLS] longingify votes stopperation dawnxious branchoħ fort destructive [SEP]']
[Init] best perm rec loss: 0.756556510925293 for ['[CLS]ħ branch dawn destructiveo longing stopify fortperationxious votes [SEP]']
[Init] best perm rec loss: 0.7561136484146118 for ['[CLS]ħ votes fort destructiveoperation longingxious dawnify stop branch [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.434 (perp=10.734, rec=0.253, cos=0.034), tot_loss_proj:3.131 [t=0.17s]
prediction: ['[CLS] the how females contempt femaleuous contemptuous be contempt femaleuous [SEP]']
[ 100/2000] tot_loss=2.365 (perp=10.883, rec=0.165, cos=0.024), tot_loss_proj:3.088 [t=0.18s]
prediction: ['[CLS] the possibly female contempt femaleuous contemptuous more contempt populationuous [SEP]']
[ 150/2000] tot_loss=2.214 (perp=10.444, rec=0.115, cos=0.010), tot_loss_proj:3.033 [t=0.22s]
prediction: ['[CLS] the possibly single contempt female be contemptuous more contempt single population [SEP]']
[ 200/2000] tot_loss=2.307 (perp=11.031, rec=0.093, cos=0.008), tot_loss_proj:3.218 [t=0.19s]
prediction: ['[CLS] of possibly single contempt female be contemptuous more contempt population population [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.819 (perp=8.565, rec=0.095, cos=0.010), tot_loss_proj:2.631 [t=0.25s]
prediction: ['[CLS] possibly single contempt female be contemptuous of more contempt population. [SEP]']
[ 300/2000] tot_loss=1.803 (perp=8.565, rec=0.086, cos=0.005), tot_loss_proj:2.627 [t=0.21s]
prediction: ['[CLS] possibly single contempt female be contemptuous of more contempt population. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.651 (perp=7.772, rec=0.092, cos=0.004), tot_loss_proj:2.378 [t=0.21s]
prediction: ['[CLS] possibly single female contempt be contemptuous of more contempt population. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.617 (perp=7.644, rec=0.084, cos=0.004), tot_loss_proj:2.322 [t=0.21s]
prediction: ['[CLS] possibly single female contempt be contemptuous of more population contempt. [SEP]']
[ 450/2000] tot_loss=1.613 (perp=7.644, rec=0.080, cos=0.004), tot_loss_proj:2.325 [t=0.24s]
prediction: ['[CLS] possibly single female contempt be contemptuous of more population contempt. [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.614 (perp=7.644, rec=0.081, cos=0.004), tot_loss_proj:2.327 [t=0.20s]
prediction: ['[CLS] possibly single female contempt be contemptuous of more population contempt. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.549 (perp=7.255, rec=0.093, cos=0.005), tot_loss_proj:2.236 [t=0.20s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[ 600/2000] tot_loss=1.534 (perp=7.255, rec=0.079, cos=0.004), tot_loss_proj:2.195 [t=0.17s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.540 (perp=7.255, rec=0.085, cos=0.004), tot_loss_proj:2.198 [t=0.19s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.531 (perp=7.255, rec=0.076, cos=0.004), tot_loss_proj:2.197 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[ 750/2000] tot_loss=1.537 (perp=7.255, rec=0.082, cos=0.004), tot_loss_proj:2.202 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.537 (perp=7.255, rec=0.083, cos=0.004), tot_loss_proj:2.198 [t=0.22s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.529 (perp=7.255, rec=0.074, cos=0.004), tot_loss_proj:2.190 [t=0.24s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[ 900/2000] tot_loss=1.535 (perp=7.255, rec=0.080, cos=0.004), tot_loss_proj:2.199 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.524 (perp=7.255, rec=0.069, cos=0.004), tot_loss_proj:2.198 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.536 (perp=7.255, rec=0.081, cos=0.004), tot_loss_proj:2.197 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[1050/2000] tot_loss=1.541 (perp=7.255, rec=0.086, cos=0.004), tot_loss_proj:2.196 [t=0.20s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.527 (perp=7.255, rec=0.073, cos=0.004), tot_loss_proj:2.200 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.527 (perp=7.255, rec=0.073, cos=0.004), tot_loss_proj:2.200 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[1200/2000] tot_loss=1.535 (perp=7.255, rec=0.081, cos=0.004), tot_loss_proj:2.195 [t=0.20s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.529 (perp=7.255, rec=0.074, cos=0.004), tot_loss_proj:2.194 [t=0.20s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.530 (perp=7.255, rec=0.075, cos=0.004), tot_loss_proj:2.199 [t=0.24s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[1350/2000] tot_loss=1.530 (perp=7.255, rec=0.075, cos=0.004), tot_loss_proj:2.201 [t=0.25s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.537 (perp=7.255, rec=0.083, cos=0.004), tot_loss_proj:2.196 [t=0.20s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.534 (perp=7.255, rec=0.080, cos=0.004), tot_loss_proj:2.195 [t=0.23s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[1500/2000] tot_loss=1.534 (perp=7.255, rec=0.079, cos=0.004), tot_loss_proj:2.191 [t=0.22s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.530 (perp=7.255, rec=0.076, cos=0.004), tot_loss_proj:2.191 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.540 (perp=7.255, rec=0.086, cos=0.004), tot_loss_proj:2.198 [t=0.20s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[1650/2000] tot_loss=1.542 (perp=7.255, rec=0.088, cos=0.004), tot_loss_proj:2.205 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.529 (perp=7.255, rec=0.075, cos=0.004), tot_loss_proj:2.203 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.526 (perp=7.255, rec=0.071, cos=0.004), tot_loss_proj:2.195 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[1800/2000] tot_loss=1.537 (perp=7.255, rec=0.082, cos=0.004), tot_loss_proj:2.200 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.530 (perp=7.255, rec=0.076, cos=0.004), tot_loss_proj:2.193 [t=0.21s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.535 (perp=7.255, rec=0.081, cos=0.004), tot_loss_proj:2.194 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
[1950/2000] tot_loss=1.535 (perp=7.255, rec=0.080, cos=0.004), tot_loss_proj:2.199 [t=0.25s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.532 (perp=7.255, rec=0.077, cos=0.004), tot_loss_proj:2.202 [t=0.18s]
prediction: ['[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS] possibly single female contempt be more contemptuous of population contempt. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 36.364 | p: 36.364 | r: 36.364
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 119.697

[Aggregate metrics]:
rouge1     | fm: 88.033 | p: 87.918 | r: 88.262
rouge2     | fm: 52.025 | p: 52.033 | r: 52.022
rougeL     | fm: 75.851 | p: 75.836 | r: 75.895
rougeLsum  | fm: 75.608 | p: 75.549 | r: 75.751
r1fm+r2fm = 140.057

input #49 time: 0:08:09 | total time: 7:00:00


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.998756064111386
highest_index [0]
highest [0.998756064111386]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 0.8097981810569763 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 0.8006887435913086 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 0.7922798991203308 for ['[CLS] cannon noveltyuser dino ordinance japanese deck tech alright [SEP]']
[Init] best rec loss: 0.7808070182800293 for ['[CLS] wealth atletico fisherman resties life sky connectish [SEP]']
[Init] best rec loss: 0.7589386105537415 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 0.7529995441436768 for ['[CLS] stone sex science cheeks prolific conventionwashed in once [SEP]']
[Init] best rec loss: 0.7491924166679382 for ['[CLS] app mix sousa replacement university harbor host elaborate ( [SEP]']
[Init] best rec loss: 0.7386783957481384 for ['[CLS]sil state grade over ing fish champion woolf good [SEP]']
[Init] best perm rec loss: 0.7374783754348755 for ['[CLS] woolf state champion ingsil grade over good fish [SEP]']
[Init] best perm rec loss: 0.7359878420829773 for ['[CLS] fish over grade ingsil state woolf good champion [SEP]']
[Init] best perm rec loss: 0.7358167171478271 for ['[CLS] good champion grade state ingsil fish over woolf [SEP]']
[Init] best perm rec loss: 0.7347338199615479 for ['[CLS] good grade woolf state over ingsil champion fish [SEP]']
[Init] best perm rec loss: 0.734687328338623 for ['[CLS] woolf grade oversil champion good state ing fish [SEP]']
[Init] best perm rec loss: 0.7337872982025146 for ['[CLS] woolf ing fish championsil good over state grade [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.391 (perp=9.737, rec=0.349, cos=0.094), tot_loss_proj:3.255 [t=0.18s]
prediction: ['[CLS] clever clever english ronnie too clever the half metres [SEP]']
[ 100/2000] tot_loss=2.243 (perp=9.502, rec=0.247, cos=0.095), tot_loss_proj:2.640 [t=0.24s]
prediction: ['[CLS] clever clever call almost too clever which too half [SEP]']
[ 150/2000] tot_loss=2.406 (perp=11.160, rec=0.151, cos=0.023), tot_loss_proj:3.161 [t=0.18s]
prediction: ["[CLS] clever what call half too `'too by [SEP]"]
[ 200/2000] tot_loss=2.514 (perp=12.101, rec=0.087, cos=0.007), tot_loss_proj:3.264 [t=0.26s]
prediction: ['[CLS] clever what call half too english ` too by [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.163 (perp=10.370, rec=0.083, cos=0.005), tot_loss_proj:2.733 [t=0.19s]
prediction: ['[CLS] too clever what call half english ` too by [SEP]']
[ 300/2000] tot_loss=2.141 (perp=10.370, rec=0.064, cos=0.004), tot_loss_proj:2.742 [t=0.19s]
prediction: ['[CLS] too clever what call half english ` too by [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.015 (perp=9.655, rec=0.080, cos=0.004), tot_loss_proj:2.558 [t=0.18s]
prediction: ['[CLS] too clever what call by english ` too half [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.002 (perp=9.655, rec=0.068, cos=0.003), tot_loss_proj:2.564 [t=0.24s]
prediction: ['[CLS] too clever what call by english ` too half [SEP]']
[ 450/2000] tot_loss=2.085 (perp=10.124, rec=0.058, cos=0.002), tot_loss_proj:2.996 [t=0.28s]
prediction: ['[CLS] the clever what call by english ` too half [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.997 (perp=9.622, rec=0.070, cos=0.002), tot_loss_proj:3.305 [t=0.18s]
prediction: ['[CLS] the what clever call by english ` too half [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.839 (perp=8.870, rec=0.062, cos=0.002), tot_loss_proj:3.243 [t=0.27s]
prediction: ['[CLS] what the clever call by english ` too half [SEP]']
[ 600/2000] tot_loss=1.851 (perp=8.870, rec=0.074, cos=0.002), tot_loss_proj:3.239 [t=0.29s]
prediction: ['[CLS] what the clever call by english ` too half [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.787 (perp=8.628, rec=0.060, cos=0.002), tot_loss_proj:3.030 [t=0.18s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.788 (perp=8.628, rec=0.060, cos=0.002), tot_loss_proj:3.025 [t=0.25s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
[ 750/2000] tot_loss=1.785 (perp=8.628, rec=0.057, cos=0.002), tot_loss_proj:3.020 [t=0.17s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.788 (perp=8.628, rec=0.060, cos=0.002), tot_loss_proj:3.029 [t=0.18s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.793 (perp=8.628, rec=0.065, cos=0.002), tot_loss_proj:3.026 [t=0.18s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
[ 900/2000] tot_loss=1.787 (perp=8.628, rec=0.059, cos=0.002), tot_loss_proj:3.027 [t=0.30s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.796 (perp=8.628, rec=0.068, cos=0.002), tot_loss_proj:3.021 [t=0.19s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1000/2000] tot_loss=1.796 (perp=8.628, rec=0.068, cos=0.002), tot_loss_proj:3.021 [t=0.18s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
[1050/2000] tot_loss=1.786 (perp=8.628, rec=0.058, cos=0.002), tot_loss_proj:3.021 [t=0.19s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1100/2000] tot_loss=1.779 (perp=8.628, rec=0.051, cos=0.002), tot_loss_proj:3.021 [t=0.20s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1150/2000] tot_loss=1.787 (perp=8.628, rec=0.059, cos=0.002), tot_loss_proj:3.022 [t=0.18s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
[1200/2000] tot_loss=1.789 (perp=8.628, rec=0.062, cos=0.002), tot_loss_proj:3.020 [t=0.19s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1250/2000] tot_loss=1.783 (perp=8.628, rec=0.055, cos=0.002), tot_loss_proj:3.019 [t=0.19s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1300/2000] tot_loss=1.780 (perp=8.628, rec=0.052, cos=0.002), tot_loss_proj:3.026 [t=0.25s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
[1350/2000] tot_loss=1.794 (perp=8.628, rec=0.066, cos=0.002), tot_loss_proj:3.016 [t=0.22s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1400/2000] tot_loss=1.796 (perp=8.628, rec=0.068, cos=0.002), tot_loss_proj:3.018 [t=0.26s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1450/2000] tot_loss=1.801 (perp=8.628, rec=0.073, cos=0.002), tot_loss_proj:3.023 [t=0.29s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
[1500/2000] tot_loss=1.794 (perp=8.628, rec=0.066, cos=0.002), tot_loss_proj:3.024 [t=0.20s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1550/2000] tot_loss=1.789 (perp=8.628, rec=0.062, cos=0.002), tot_loss_proj:3.026 [t=0.20s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1600/2000] tot_loss=1.786 (perp=8.628, rec=0.058, cos=0.002), tot_loss_proj:3.016 [t=0.25s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
[1650/2000] tot_loss=1.792 (perp=8.628, rec=0.064, cos=0.002), tot_loss_proj:3.014 [t=0.22s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1700/2000] tot_loss=1.792 (perp=8.628, rec=0.064, cos=0.002), tot_loss_proj:3.014 [t=0.25s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1750/2000] tot_loss=1.796 (perp=8.628, rec=0.068, cos=0.002), tot_loss_proj:3.018 [t=0.23s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
[1800/2000] tot_loss=1.789 (perp=8.628, rec=0.061, cos=0.002), tot_loss_proj:3.021 [t=0.18s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1850/2000] tot_loss=1.785 (perp=8.628, rec=0.057, cos=0.002), tot_loss_proj:3.015 [t=0.22s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[1900/2000] tot_loss=1.791 (perp=8.628, rec=0.063, cos=0.002), tot_loss_proj:3.018 [t=0.19s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
[1950/2000] tot_loss=1.786 (perp=8.628, rec=0.058, cos=0.002), tot_loss_proj:3.015 [t=0.24s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Attempt swap
[2000/2000] tot_loss=1.791 (perp=8.628, rec=0.063, cos=0.002), tot_loss_proj:3.020 [t=0.18s]
prediction: ['[CLS] what the clever call by english too ` half [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what the clever call by english too ` half [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 70.000 | p: 70.000 | r: 70.000
rougeLsum  | fm: 70.000 | p: 70.000 | r: 70.000
r1fm+r2fm = 133.333

[Aggregate metrics]:
rouge1     | fm: 88.202 | p: 88.066 | r: 88.440
rouge2     | fm: 51.698 | p: 51.638 | r: 51.745
rougeL     | fm: 75.779 | p: 75.756 | r: 75.840
rougeLsum  | fm: 75.679 | p: 75.643 | r: 75.721
r1fm+r2fm = 139.900

input #50 time: 0:08:23 | total time: 7:08:23


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9987210476629178
highest_index [0]
highest [0.9987210476629178]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 0.7851552367210388 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 0.7776840329170227 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 0.7520539164543152 for ['[CLS] move steep life including killer meaningliestgical interaction please [SEP]']
[Init] best rec loss: 0.7284495234489441 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 0.7122165560722351 for ['[CLS] low reelection honest louis caps noah lieutenant quarter consequence handwriting [SEP]']
[Init] best perm rec loss: 0.7119056582450867 for ['[CLS] quarter caps lieutenant handwriting noah reelection louis low honest consequence [SEP]']
[Init] best perm rec loss: 0.7113268375396729 for ['[CLS] consequence caps louis quarter honest reelection lieutenant handwriting low noah [SEP]']
[Init] best perm rec loss: 0.7112394571304321 for ['[CLS] noah reelection consequence louis quarter caps lieutenant handwriting honest low [SEP]']
[Init] best perm rec loss: 0.7094466090202332 for ['[CLS] noah low lieutenant louis reelection honest consequence caps handwriting quarter [SEP]']
[Init] best perm rec loss: 0.7092446684837341 for ['[CLS] handwriting low caps reelection lieutenant honest noah quarter louis consequence [SEP]']
[Init] best perm rec loss: 0.7087465524673462 for ['[CLS] lieutenant consequence handwriting quarter caps reelection low honest noah louis [SEP]']
[Init] best perm rec loss: 0.708415150642395 for ['[CLS] low quarter reelection caps handwriting consequence lieutenant honest noah louis [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.896 (perp=12.689, rec=0.277, cos=0.080), tot_loss_proj:3.568 [t=0.24s]
prediction: ['[CLS] sucks bay sucks sucks has accidentally funny funny funny sucks [SEP]']
[ 100/2000] tot_loss=2.246 (perp=10.231, rec=0.168, cos=0.032), tot_loss_proj:3.006 [t=0.22s]
prediction: ['[CLS] sucks, sucks sucks but or funny funny moment moment [SEP]']
[ 150/2000] tot_loss=1.740 (perp=7.850, rec=0.128, cos=0.042), tot_loss_proj:2.551 [t=0.18s]
prediction: ['[CLS] but, sucks sucks but or a funny moment or [SEP]']
[ 200/2000] tot_loss=1.995 (perp=9.314, rec=0.107, cos=0.025), tot_loss_proj:2.670 [t=0.25s]
prediction: ['[CLS] a, sucks sucks but or has funny moment two [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.767 (perp=8.209, rec=0.106, cos=0.020), tot_loss_proj:2.081 [t=0.18s]
prediction: ['[CLS] a, sucks sucks but has funny moment or two [SEP]']
[ 300/2000] tot_loss=1.738 (perp=8.209, rec=0.084, cos=0.012), tot_loss_proj:2.082 [t=0.24s]
prediction: ['[CLS] a, sucks sucks but has funny moment or two [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.447 (perp=6.769, rec=0.081, cos=0.012), tot_loss_proj:1.714 [t=0.18s]
prediction: ['[CLS], sucks sucks but has a funny moment or two [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.360 (perp=6.348, rec=0.081, cos=0.010), tot_loss_proj:1.653 [t=0.26s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[ 450/2000] tot_loss=1.354 (perp=6.348, rec=0.077, cos=0.007), tot_loss_proj:1.650 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.349 (perp=6.348, rec=0.073, cos=0.007), tot_loss_proj:1.645 [t=0.27s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.349 (perp=6.348, rec=0.073, cos=0.006), tot_loss_proj:1.649 [t=0.22s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[ 600/2000] tot_loss=1.349 (perp=6.348, rec=0.074, cos=0.006), tot_loss_proj:1.640 [t=0.19s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.354 (perp=6.348, rec=0.079, cos=0.006), tot_loss_proj:1.642 [t=0.26s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.354 (perp=6.348, rec=0.078, cos=0.006), tot_loss_proj:1.651 [t=0.20s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[ 750/2000] tot_loss=1.349 (perp=6.348, rec=0.073, cos=0.006), tot_loss_proj:1.650 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.339 (perp=6.348, rec=0.065, cos=0.005), tot_loss_proj:1.652 [t=0.24s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.341 (perp=6.348, rec=0.066, cos=0.005), tot_loss_proj:1.646 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[ 900/2000] tot_loss=1.352 (perp=6.348, rec=0.077, cos=0.005), tot_loss_proj:1.639 [t=0.26s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.347 (perp=6.348, rec=0.072, cos=0.005), tot_loss_proj:1.637 [t=0.22s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1000/2000] tot_loss=1.342 (perp=6.348, rec=0.067, cos=0.005), tot_loss_proj:1.640 [t=0.21s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[1050/2000] tot_loss=1.348 (perp=6.348, rec=0.073, cos=0.005), tot_loss_proj:1.636 [t=0.20s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1100/2000] tot_loss=1.352 (perp=6.348, rec=0.077, cos=0.005), tot_loss_proj:1.640 [t=0.23s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1150/2000] tot_loss=1.349 (perp=6.348, rec=0.074, cos=0.005), tot_loss_proj:1.641 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[1200/2000] tot_loss=1.353 (perp=6.348, rec=0.078, cos=0.005), tot_loss_proj:1.644 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1250/2000] tot_loss=1.347 (perp=6.348, rec=0.072, cos=0.005), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1300/2000] tot_loss=1.350 (perp=6.348, rec=0.075, cos=0.005), tot_loss_proj:1.641 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[1350/2000] tot_loss=1.348 (perp=6.348, rec=0.073, cos=0.005), tot_loss_proj:1.639 [t=0.26s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1400/2000] tot_loss=1.341 (perp=6.348, rec=0.066, cos=0.005), tot_loss_proj:1.646 [t=0.22s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1450/2000] tot_loss=1.351 (perp=6.348, rec=0.076, cos=0.005), tot_loss_proj:1.634 [t=0.25s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[1500/2000] tot_loss=1.342 (perp=6.348, rec=0.067, cos=0.005), tot_loss_proj:1.633 [t=0.21s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1550/2000] tot_loss=1.339 (perp=6.348, rec=0.064, cos=0.005), tot_loss_proj:1.634 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1600/2000] tot_loss=1.341 (perp=6.348, rec=0.066, cos=0.005), tot_loss_proj:1.639 [t=0.19s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[1650/2000] tot_loss=1.356 (perp=6.348, rec=0.082, cos=0.005), tot_loss_proj:1.640 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1700/2000] tot_loss=1.350 (perp=6.348, rec=0.075, cos=0.005), tot_loss_proj:1.642 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1750/2000] tot_loss=1.337 (perp=6.348, rec=0.062, cos=0.005), tot_loss_proj:1.638 [t=0.19s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[1800/2000] tot_loss=1.341 (perp=6.348, rec=0.066, cos=0.005), tot_loss_proj:1.635 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1850/2000] tot_loss=1.350 (perp=6.348, rec=0.076, cos=0.005), tot_loss_proj:1.635 [t=0.19s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[1900/2000] tot_loss=1.347 (perp=6.348, rec=0.072, cos=0.005), tot_loss_proj:1.635 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
[1950/2000] tot_loss=1.347 (perp=6.348, rec=0.072, cos=0.005), tot_loss_proj:1.636 [t=0.23s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Attempt swap
[2000/2000] tot_loss=1.348 (perp=6.348, rec=0.073, cos=0.005), tot_loss_proj:1.637 [t=0.18s]
prediction: ['[CLS] sucks, sucks but has a funny moment or two [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS] sucks, sucks but has a funny moment or two [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 94.737 | p: 90.000 | r: 100.000
rougeL     | fm: 95.238 | p: 90.909 | r: 100.000
rougeLsum  | fm: 95.238 | p: 90.909 | r: 100.000
r1fm+r2fm = 189.975

[Aggregate metrics]:
rouge1     | fm: 88.404 | p: 88.177 | r: 88.706
rouge2     | fm: 52.724 | p: 52.560 | r: 52.887
rougeL     | fm: 76.086 | p: 75.974 | r: 76.316
rougeLsum  | fm: 75.839 | p: 75.754 | r: 76.028
r1fm+r2fm = 141.128

input #51 time: 0:08:23 | total time: 7:16:47


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9985585789869519
highest_index [0]
highest [0.9985585789869519]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 0.9749317765235901 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 0.9041821360588074 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 0.8986840844154358 for ['[CLS] transition content distance [SEP]']
[Init] best rec loss: 0.8745903372764587 for ['[CLS] field darkedge [SEP]']
[Init] best rec loss: 0.8700813055038452 for ['[CLS] print bubba advance [SEP]']
[Init] best rec loss: 0.7558935880661011 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.7159460186958313 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.7144809365272522 for ['[CLS] football expected vocabulary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.114 (perp=9.660, rec=0.174, cos=0.008), tot_loss_proj:2.450 [t=0.17s]
prediction: ['[CLS] trash trash trailer [SEP]']
[ 100/2000] tot_loss=2.267 (perp=10.789, rec=0.103, cos=0.006), tot_loss_proj:2.633 [t=0.18s]
prediction: ['[CLS] trash trailer trash [SEP]']
[ 150/2000] tot_loss=2.266 (perp=10.789, rec=0.102, cos=0.006), tot_loss_proj:2.642 [t=0.19s]
prediction: ['[CLS] trash trailer trash [SEP]']
[ 200/2000] tot_loss=2.240 (perp=10.789, rec=0.078, cos=0.005), tot_loss_proj:2.640 [t=0.18s]
prediction: ['[CLS] trash trailer trash [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.056 (perp=9.660, rec=0.119, cos=0.005), tot_loss_proj:2.442 [t=0.20s]
prediction: ['[CLS] trash trash trailer [SEP]']
[ 300/2000] tot_loss=2.131 (perp=10.230, rec=0.082, cos=0.003), tot_loss_proj:2.520 [t=0.26s]
prediction: ['[CLS] - trash trailer [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.769 (perp=8.482, rec=0.069, cos=0.003), tot_loss_proj:2.147 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.777 (perp=8.482, rec=0.077, cos=0.003), tot_loss_proj:2.141 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.765 (perp=8.482, rec=0.065, cos=0.003), tot_loss_proj:2.150 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.759 (perp=8.482, rec=0.059, cos=0.003), tot_loss_proj:2.155 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.752 (perp=8.482, rec=0.053, cos=0.003), tot_loss_proj:2.144 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.771 (perp=8.482, rec=0.072, cos=0.003), tot_loss_proj:2.143 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.757 (perp=8.482, rec=0.058, cos=0.003), tot_loss_proj:2.150 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.762 (perp=8.482, rec=0.062, cos=0.003), tot_loss_proj:2.145 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.755 (perp=8.482, rec=0.056, cos=0.003), tot_loss_proj:2.155 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.764 (perp=8.482, rec=0.065, cos=0.003), tot_loss_proj:2.149 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.770 (perp=8.482, rec=0.071, cos=0.003), tot_loss_proj:2.147 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.769 (perp=8.482, rec=0.069, cos=0.003), tot_loss_proj:2.151 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.770 (perp=8.482, rec=0.071, cos=0.003), tot_loss_proj:2.147 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.765 (perp=8.482, rec=0.066, cos=0.003), tot_loss_proj:2.142 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.765 (perp=8.482, rec=0.066, cos=0.003), tot_loss_proj:2.144 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.752 (perp=8.482, rec=0.053, cos=0.003), tot_loss_proj:2.144 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.767 (perp=8.482, rec=0.067, cos=0.003), tot_loss_proj:2.150 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.752 (perp=8.482, rec=0.053, cos=0.003), tot_loss_proj:2.146 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.768 (perp=8.482, rec=0.069, cos=0.003), tot_loss_proj:2.146 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.763 (perp=8.482, rec=0.063, cos=0.003), tot_loss_proj:2.143 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.758 (perp=8.482, rec=0.059, cos=0.003), tot_loss_proj:2.145 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.757 (perp=8.482, rec=0.057, cos=0.003), tot_loss_proj:2.140 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.765 (perp=8.482, rec=0.066, cos=0.003), tot_loss_proj:2.142 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.762 (perp=8.482, rec=0.062, cos=0.003), tot_loss_proj:2.138 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.763 (perp=8.482, rec=0.064, cos=0.003), tot_loss_proj:2.147 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.765 (perp=8.482, rec=0.066, cos=0.003), tot_loss_proj:2.143 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.769 (perp=8.482, rec=0.069, cos=0.003), tot_loss_proj:2.145 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.768 (perp=8.482, rec=0.068, cos=0.003), tot_loss_proj:2.144 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.755 (perp=8.482, rec=0.056, cos=0.003), tot_loss_proj:2.139 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.768 (perp=8.482, rec=0.068, cos=0.003), tot_loss_proj:2.142 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.770 (perp=8.482, rec=0.071, cos=0.003), tot_loss_proj:2.142 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.764 (perp=8.482, rec=0.065, cos=0.003), tot_loss_proj:2.146 [t=0.27s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.760 (perp=8.482, rec=0.061, cos=0.003), tot_loss_proj:2.145 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.751 (perp=8.482, rec=0.052, cos=0.003), tot_loss_proj:2.157 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 88.613 | p: 88.386 | r: 88.886
rouge2     | fm: 51.531 | p: 51.448 | r: 51.638
rougeL     | fm: 76.146 | p: 75.962 | r: 76.335
rougeLsum  | fm: 75.829 | p: 75.710 | r: 75.960
r1fm+r2fm = 140.144

input #52 time: 0:08:11 | total time: 7:24:58


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9986741449580849
highest_index [0]
highest [0.9986741449580849]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 0.7959015369415283 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 0.7155606150627136 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 0.711471438407898 for ['[CLS] praising won [SEP]']
[Init] best rec loss: 0.6939728260040283 for ['[CLS] nick design [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.714 (perp=12.492, rec=0.181, cos=0.034), tot_loss_proj:3.271 [t=0.19s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 100/2000] tot_loss=1.718 (perp=8.090, rec=0.094, cos=0.006), tot_loss_proj:1.697 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
[ 150/2000] tot_loss=1.685 (perp=8.090, rec=0.064, cos=0.003), tot_loss_proj:1.688 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 200/2000] tot_loss=1.673 (perp=8.090, rec=0.052, cos=0.003), tot_loss_proj:1.680 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.673 (perp=8.090, rec=0.053, cos=0.003), tot_loss_proj:1.684 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 300/2000] tot_loss=1.687 (perp=8.090, rec=0.066, cos=0.003), tot_loss_proj:1.694 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.681 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.698 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.681 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.692 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.676 (perp=8.090, rec=0.056, cos=0.003), tot_loss_proj:1.682 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.674 (perp=8.090, rec=0.054, cos=0.003), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.695 (perp=8.090, rec=0.075, cos=0.003), tot_loss_proj:1.688 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.681 (perp=8.090, rec=0.060, cos=0.003), tot_loss_proj:1.692 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.686 (perp=8.090, rec=0.065, cos=0.003), tot_loss_proj:1.683 [t=0.25s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.694 (perp=8.090, rec=0.073, cos=0.003), tot_loss_proj:1.683 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.665 (perp=8.090, rec=0.045, cos=0.003), tot_loss_proj:1.672 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.675 (perp=8.090, rec=0.055, cos=0.003), tot_loss_proj:1.677 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.690 (perp=8.090, rec=0.069, cos=0.003), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.684 (perp=8.090, rec=0.064, cos=0.003), tot_loss_proj:1.685 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.679 (perp=8.090, rec=0.059, cos=0.003), tot_loss_proj:1.690 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.683 (perp=8.090, rec=0.062, cos=0.003), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.675 (perp=8.090, rec=0.055, cos=0.003), tot_loss_proj:1.677 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.690 (perp=8.090, rec=0.069, cos=0.003), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.684 (perp=8.090, rec=0.064, cos=0.003), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.676 (perp=8.090, rec=0.055, cos=0.003), tot_loss_proj:1.687 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.691 (perp=8.090, rec=0.071, cos=0.003), tot_loss_proj:1.685 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.682 (perp=8.090, rec=0.061, cos=0.003), tot_loss_proj:1.689 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.676 (perp=8.090, rec=0.055, cos=0.003), tot_loss_proj:1.675 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.668 (perp=8.090, rec=0.047, cos=0.003), tot_loss_proj:1.695 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.689 (perp=8.090, rec=0.069, cos=0.003), tot_loss_proj:1.695 [t=0.20s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.678 (perp=8.090, rec=0.057, cos=0.003), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.688 (perp=8.090, rec=0.067, cos=0.003), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.679 (perp=8.090, rec=0.059, cos=0.003), tot_loss_proj:1.679 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.688 (perp=8.090, rec=0.067, cos=0.003), tot_loss_proj:1.677 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.684 (perp=8.090, rec=0.064, cos=0.003), tot_loss_proj:1.691 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.688 (perp=8.090, rec=0.067, cos=0.003), tot_loss_proj:1.682 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.693 (perp=8.090, rec=0.073, cos=0.003), tot_loss_proj:1.683 [t=0.20s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.684 (perp=8.090, rec=0.063, cos=0.003), tot_loss_proj:1.693 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.688 (perp=8.090, rec=0.067, cos=0.003), tot_loss_proj:1.692 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.670 (perp=8.090, rec=0.049, cos=0.003), tot_loss_proj:1.694 [t=0.18s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.677 (perp=8.090, rec=0.056, cos=0.003), tot_loss_proj:1.702 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.804 | p: 88.568 | r: 89.024
rouge2     | fm: 52.483 | p: 52.258 | r: 52.634
rougeL     | fm: 76.517 | p: 76.412 | r: 76.741
rougeLsum  | fm: 76.369 | p: 76.258 | r: 76.514
r1fm+r2fm = 141.287

input #53 time: 0:08:19 | total time: 7:33:18


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9986700983518295
highest_index [0]
highest [0.9986700983518295]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 0.8114961981773376 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 0.7609878182411194 for ['[CLS] called search [SEP]']
[Init] best rec loss: 0.7543265223503113 for ['[CLS] living devices [SEP]']
[Init] best rec loss: 0.7423801422119141 for ['[CLS] trinity passed [SEP]']
[Init] best rec loss: 0.7377293109893799 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 0.692920446395874 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 0.6575917601585388 for ['[CLS]osition final [SEP]']
[Init] best rec loss: 0.6495347619056702 for ['[CLS] delivery content [SEP]']
[Init] best rec loss: 0.629589855670929 for ['[CLS] teresa spanish [SEP]']
[Init] best rec loss: 0.6216797828674316 for ['[CLS] wild exercised [SEP]']
[Init] best perm rec loss: 0.6180983185768127 for ['[CLS] exercised wild [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.262 (perp=9.393, rec=0.318, cos=0.065), tot_loss_proj:2.704 [t=0.23s]
prediction: ['[CLS] hot hot [SEP]']
[ 100/2000] tot_loss=1.901 (perp=8.198, rec=0.238, cos=0.023), tot_loss_proj:1.732 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.829 (perp=8.198, rec=0.173, cos=0.017), tot_loss_proj:1.702 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.819 (perp=8.198, rec=0.164, cos=0.016), tot_loss_proj:1.707 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.805 (perp=8.198, rec=0.149, cos=0.016), tot_loss_proj:1.724 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.805 (perp=8.198, rec=0.150, cos=0.016), tot_loss_proj:1.711 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.801 (perp=8.198, rec=0.146, cos=0.016), tot_loss_proj:1.712 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.805 (perp=8.198, rec=0.150, cos=0.016), tot_loss_proj:1.711 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.803 (perp=8.198, rec=0.147, cos=0.016), tot_loss_proj:1.703 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.810 (perp=8.198, rec=0.154, cos=0.016), tot_loss_proj:1.717 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.797 (perp=8.198, rec=0.142, cos=0.016), tot_loss_proj:1.713 [t=0.30s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.805 (perp=8.198, rec=0.150, cos=0.015), tot_loss_proj:1.715 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.792 (perp=8.198, rec=0.137, cos=0.015), tot_loss_proj:1.718 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.808 (perp=8.198, rec=0.153, cos=0.016), tot_loss_proj:1.734 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.801 (perp=8.198, rec=0.146, cos=0.016), tot_loss_proj:1.726 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.801 (perp=8.198, rec=0.146, cos=0.016), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.790 (perp=8.198, rec=0.135, cos=0.015), tot_loss_proj:1.714 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.789 (perp=8.198, rec=0.134, cos=0.015), tot_loss_proj:1.706 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.806 (perp=8.198, rec=0.151, cos=0.015), tot_loss_proj:1.722 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.802 (perp=8.198, rec=0.147, cos=0.016), tot_loss_proj:1.726 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.804 (perp=8.198, rec=0.149, cos=0.015), tot_loss_proj:1.722 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.794 (perp=8.198, rec=0.139, cos=0.015), tot_loss_proj:1.711 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.796 (perp=8.198, rec=0.141, cos=0.015), tot_loss_proj:1.712 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.800 (perp=8.198, rec=0.145, cos=0.015), tot_loss_proj:1.722 [t=0.23s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.796 (perp=8.198, rec=0.141, cos=0.015), tot_loss_proj:1.732 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.787 (perp=8.198, rec=0.132, cos=0.015), tot_loss_proj:1.710 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.798 (perp=8.198, rec=0.143, cos=0.015), tot_loss_proj:1.724 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.804 (perp=8.198, rec=0.149, cos=0.015), tot_loss_proj:1.714 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.797 (perp=8.198, rec=0.142, cos=0.015), tot_loss_proj:1.726 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.786 (perp=8.198, rec=0.131, cos=0.015), tot_loss_proj:1.707 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.798 (perp=8.198, rec=0.143, cos=0.015), tot_loss_proj:1.716 [t=0.22s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.804 (perp=8.198, rec=0.149, cos=0.015), tot_loss_proj:1.712 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.797 (perp=8.198, rec=0.142, cos=0.015), tot_loss_proj:1.705 [t=0.28s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.806 (perp=8.198, rec=0.151, cos=0.015), tot_loss_proj:1.720 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.811 (perp=8.198, rec=0.156, cos=0.015), tot_loss_proj:1.712 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.785 (perp=8.198, rec=0.130, cos=0.015), tot_loss_proj:1.736 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.788 (perp=8.198, rec=0.133, cos=0.015), tot_loss_proj:1.723 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.799 (perp=8.198, rec=0.144, cos=0.015), tot_loss_proj:1.724 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.792 (perp=8.198, rec=0.137, cos=0.015), tot_loss_proj:1.723 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.799 (perp=8.198, rec=0.144, cos=0.015), tot_loss_proj:1.720 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.935 | p: 88.751 | r: 89.300
rouge2     | fm: 53.517 | p: 53.410 | r: 53.677
rougeL     | fm: 76.866 | p: 76.701 | r: 77.030
rougeLsum  | fm: 76.808 | p: 76.641 | r: 76.964
r1fm+r2fm = 142.452

input #54 time: 0:08:21 | total time: 7:41:39


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9986520982154898
highest_index [0]
highest [0.9986520982154898]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 0.8562214970588684 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 0.7411023378372192 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 0.739956796169281 for ['[CLS] issues while as [SEP]']
[Init] best rec loss: 0.7361891269683838 for ['[CLS]ies finished haired [SEP]']
[Init] best rec loss: 0.7152849435806274 for ['[CLS] top trades events [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.046 (perp=8.671, rec=0.262, cos=0.050), tot_loss_proj:1.813 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
[ 100/2000] tot_loss=1.811 (perp=8.671, rec=0.072, cos=0.005), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] settles too easily [SEP]']
[ 150/2000] tot_loss=1.807 (perp=8.671, rec=0.070, cos=0.003), tot_loss_proj:1.806 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
[ 200/2000] tot_loss=1.804 (perp=8.671, rec=0.067, cos=0.003), tot_loss_proj:1.814 [t=0.20s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.790 (perp=8.671, rec=0.054, cos=0.003), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
[ 300/2000] tot_loss=1.797 (perp=8.671, rec=0.060, cos=0.003), tot_loss_proj:1.812 [t=0.23s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.798 (perp=8.671, rec=0.061, cos=0.003), tot_loss_proj:1.815 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.796 (perp=8.671, rec=0.059, cos=0.003), tot_loss_proj:1.809 [t=0.19s]
prediction: ['[CLS] settles too easily [SEP]']
[ 450/2000] tot_loss=1.786 (perp=8.671, rec=0.049, cos=0.003), tot_loss_proj:1.821 [t=0.20s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.804 (perp=8.671, rec=0.068, cos=0.003), tot_loss_proj:1.810 [t=0.24s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.795 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.807 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
[ 600/2000] tot_loss=1.794 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.819 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.796 (perp=8.671, rec=0.059, cos=0.003), tot_loss_proj:1.812 [t=0.20s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.793 (perp=8.671, rec=0.056, cos=0.003), tot_loss_proj:1.802 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
[ 750/2000] tot_loss=1.800 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.800 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.795 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.808 [t=0.30s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.800 (perp=8.671, rec=0.064, cos=0.003), tot_loss_proj:1.804 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
[ 900/2000] tot_loss=1.801 (perp=8.671, rec=0.065, cos=0.003), tot_loss_proj:1.808 [t=0.26s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.799 (perp=8.671, rec=0.062, cos=0.003), tot_loss_proj:1.806 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1000/2000] tot_loss=1.800 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.803 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
[1050/2000] tot_loss=1.780 (perp=8.671, rec=0.044, cos=0.003), tot_loss_proj:1.811 [t=0.19s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1100/2000] tot_loss=1.792 (perp=8.671, rec=0.056, cos=0.003), tot_loss_proj:1.808 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1150/2000] tot_loss=1.800 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.815 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
[1200/2000] tot_loss=1.790 (perp=8.671, rec=0.053, cos=0.003), tot_loss_proj:1.811 [t=0.19s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1250/2000] tot_loss=1.798 (perp=8.671, rec=0.061, cos=0.003), tot_loss_proj:1.794 [t=0.21s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1300/2000] tot_loss=1.811 (perp=8.671, rec=0.074, cos=0.003), tot_loss_proj:1.804 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
[1350/2000] tot_loss=1.800 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.799 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1400/2000] tot_loss=1.796 (perp=8.671, rec=0.060, cos=0.003), tot_loss_proj:1.813 [t=0.19s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1450/2000] tot_loss=1.811 (perp=8.671, rec=0.074, cos=0.003), tot_loss_proj:1.814 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
[1500/2000] tot_loss=1.793 (perp=8.671, rec=0.056, cos=0.003), tot_loss_proj:1.815 [t=0.27s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1550/2000] tot_loss=1.799 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.801 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1600/2000] tot_loss=1.795 (perp=8.671, rec=0.058, cos=0.003), tot_loss_proj:1.799 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
[1650/2000] tot_loss=1.784 (perp=8.671, rec=0.047, cos=0.003), tot_loss_proj:1.807 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1700/2000] tot_loss=1.793 (perp=8.671, rec=0.056, cos=0.003), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1750/2000] tot_loss=1.786 (perp=8.671, rec=0.049, cos=0.003), tot_loss_proj:1.794 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
[1800/2000] tot_loss=1.797 (perp=8.671, rec=0.060, cos=0.003), tot_loss_proj:1.798 [t=0.22s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1850/2000] tot_loss=1.802 (perp=8.671, rec=0.066, cos=0.003), tot_loss_proj:1.815 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[1900/2000] tot_loss=1.800 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.808 [t=0.20s]
prediction: ['[CLS] settles too easily [SEP]']
[1950/2000] tot_loss=1.806 (perp=8.671, rec=0.069, cos=0.003), tot_loss_proj:1.812 [t=0.18s]
prediction: ['[CLS] settles too easily [SEP]']
Attempt swap
[2000/2000] tot_loss=1.799 (perp=8.671, rec=0.063, cos=0.003), tot_loss_proj:1.802 [t=0.20s]
prediction: ['[CLS] settles too easily [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] settles too easily [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.253 | p: 89.046 | r: 89.576
rouge2     | fm: 54.392 | p: 54.315 | r: 54.506
rougeL     | fm: 77.243 | p: 77.154 | r: 77.407
rougeLsum  | fm: 77.098 | p: 76.969 | r: 77.280
r1fm+r2fm = 143.645

input #55 time: 0:08:20 | total time: 7:50:00


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.9985782095620699
highest_index [0]
highest [0.9985782095620699]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 0.8469182252883911 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 0.837483286857605 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 0.8238270282745361 for ['[CLS] gu listgnant brave xavier jenna lady behalf file productions experienced charmvah everything law commander shorts inner matchesonal boot [SEP]']
[Init] best rec loss: 0.8087391257286072 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 0.8078885674476624 for ['[CLS] backed reflection en sense k depression unfortunately iron code ; determined sympathy avid blame tisured laid bear charter strike technique [SEP]']
[Init] best perm rec loss: 0.8067919015884399 for ['[CLS] tis charter code strikeured iron k blame bear reflection depression laid sympathy sense ; avid unfortunately en technique backed determined [SEP]']
[Init] best perm rec loss: 0.8054897785186768 for ['[CLS] depression iron sympathy unfortunately determined ; strike tis blame charter sense k bearured reflection code backed laid avid technique en [SEP]']
[Init] best perm rec loss: 0.8042968511581421 for ['[CLS] reflection ; tis sympathy avid k en depression strike iron blame codeured unfortunately determined laid technique backed sense bear charter [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.139 (perp=13.477, rec=0.393, cos=0.051), tot_loss_proj:3.666 [t=0.19s]
prediction: ['[CLS] hurtier bum cancer childhoodc f business made therapy always shit damage insult since trash symptomsflower through akirane [SEP]']
[ 100/2000] tot_loss=2.883 (perp=12.773, rec=0.308, cos=0.020), tot_loss_proj:3.344 [t=0.21s]
prediction: ['[CLS] hurt cancers pit cosmic syndicatedc damage business made lesions always worse damage insult ofral films carriage through ukraine never [SEP]']
[ 150/2000] tot_loss=2.630 (perp=11.853, rec=0.248, cos=0.011), tot_loss_proj:3.218 [t=0.22s]
prediction: ['[CLS] hurt films pit damage polynomial of damage fix made lesions always nacional damage insult ofral films bree alone ukraine never [SEP]']
[ 200/2000] tot_loss=2.745 (perp=12.634, rec=0.211, cos=0.007), tot_loss_proj:3.646 [t=0.19s]
prediction: ['[CLS] hurt films pit damage affection kay damage fix caused injury always nacional damage insult ofral films bree of barely never [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.401 (perp=10.988, rec=0.197, cos=0.006), tot_loss_proj:3.070 [t=0.23s]
prediction: ['[CLS] stared films pit costly will of damage fix caused infections rainfall nacional damage insult ofral films which of hurt never [SEP]']
[ 300/2000] tot_loss=2.428 (perp=11.155, rec=0.191, cos=0.006), tot_loss_proj:3.150 [t=0.26s]
prediction: ['[CLS] stared films pit costly will of damage fix cause sutra should loads damage insult ofral films which of wounded never [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.254 (perp=10.403, rec=0.167, cos=0.007), tot_loss_proj:3.062 [t=0.19s]
prediction: ['[CLS] stared films pit costly will of damage of cause sutra loads loads damage insult ofwhile films which fix wounded never [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.221 (perp=10.192, rec=0.176, cos=0.007), tot_loss_proj:3.124 [t=0.25s]
prediction: ['[CLS] stared films crap costly will of damage cause sutra loads loads of damage score ofwhile films which fix wounded never [SEP]']
[ 450/2000] tot_loss=2.205 (perp=10.170, rec=0.165, cos=0.006), tot_loss_proj:3.030 [t=0.18s]
prediction: ['[CLS]р films crap costly will of damage cause sutra loads loads of damage score ofwhile films which fix wounded never [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.168 (perp=10.056, rec=0.150, cos=0.007), tot_loss_proj:3.349 [t=0.18s]
prediction: ['[CLS] perry films costly willtti of damage cause sutra loads loads of damage score ofwhile films which fix wounded never [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.364 (perp=11.040, rec=0.151, cos=0.006), tot_loss_proj:3.095 [t=0.18s]
prediction: ['[CLS] perry films costly willtti of analysis cause intra damage loads loads damage years ofwhile films which fix wounded never [SEP]']
[ 600/2000] tot_loss=2.385 (perp=11.215, rec=0.137, cos=0.005), tot_loss_proj:2.978 [t=0.25s]
prediction: ['[CLS] death loads costly willtti of analysis causepara damage loads loads damage years ofwhile films which fix wounded never [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.280 (perp=10.704, rec=0.134, cos=0.006), tot_loss_proj:2.822 [t=0.27s]
prediction: ['[CLS] death loads costly will years of analysis causepara damage loads loads damage years ofwhile films which fixtti never [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.204 (perp=10.251, rec=0.148, cos=0.006), tot_loss_proj:2.817 [t=0.23s]
prediction: ['[CLS] death loads costly will years of years causepara damage loads loads damage analysis ofwhile films which fixtti never [SEP]']
[ 750/2000] tot_loss=2.203 (perp=10.251, rec=0.146, cos=0.006), tot_loss_proj:2.825 [t=0.18s]
prediction: ['[CLS] death loads costly will years of years causepara damage loads loads damage analysis ofwhile films which fixtti never [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.231 (perp=10.498, rec=0.126, cos=0.006), tot_loss_proj:2.858 [t=0.22s]
prediction: ['[CLS] damage loads costly will years of years causepara deathble loads damage analysis ofwhile films that fix crap never [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=2.142 (perp=10.062, rec=0.124, cos=0.005), tot_loss_proj:2.787 [t=0.18s]
prediction: ['[CLS] damage《 costly will years of years causepara death loadsble damage analysis ofwhile films that fixtti never [SEP]']
[ 900/2000] tot_loss=2.149 (perp=10.062, rec=0.131, cos=0.005), tot_loss_proj:2.784 [t=0.21s]
prediction: ['[CLS] damage《 costly will years of years causepara death loadsble damage analysis ofwhile films that fixtti never [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.140 (perp=10.062, rec=0.122, cos=0.005), tot_loss_proj:2.785 [t=0.24s]
prediction: ['[CLS] damage《 costly will years of years causepara death loadsble damage analysis ofwhile films that fixtti never [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.066 (perp=9.595, rec=0.142, cos=0.005), tot_loss_proj:2.626 [t=0.18s]
prediction: ['[CLS] years《 costly will loads of years causepara death yearsble damage analysis ofwhile films that fixtti never [SEP]']
[1050/2000] tot_loss=2.045 (perp=9.595, rec=0.121, cos=0.005), tot_loss_proj:2.632 [t=0.24s]
prediction: ['[CLS] years《 costly will loads of years causepara death yearsble damage analysis ofwhile films that fixtti never [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.935 (perp=9.023, rec=0.125, cos=0.005), tot_loss_proj:2.486 [t=0.25s]
prediction: ['[CLS] years of costly will loads of years causepara years yearsble damage analysis of《 films that fix crap never [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.883 (perp=8.758, rec=0.126, cos=0.005), tot_loss_proj:2.422 [t=0.22s]
prediction: ['[CLS] years of costly will loads of years cause yearspara yearsble damage analysis of《 films that fix crap never [SEP]']
[1200/2000] tot_loss=1.866 (perp=8.758, rec=0.109, cos=0.005), tot_loss_proj:2.410 [t=0.20s]
prediction: ['[CLS] years of costly will loads of years cause yearspara yearsble damage analysis of《 films that fix crap never [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.823 (perp=8.474, rec=0.123, cos=0.005), tot_loss_proj:2.313 [t=0.22s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fix crap never [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.791 (perp=8.357, rec=0.115, cos=0.005), tot_loss_proj:2.248 [t=0.24s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that never fix crap [SEP]']
[1350/2000] tot_loss=1.826 (perp=8.526, rec=0.116, cos=0.005), tot_loss_proj:2.260 [t=0.18s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that never fixtti [SEP]']
Attempt swap
[1400/2000] tot_loss=1.824 (perp=8.526, rec=0.113, cos=0.005), tot_loss_proj:2.262 [t=0.21s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that never fixtti [SEP]']
Attempt swap
[1450/2000] tot_loss=1.827 (perp=8.526, rec=0.117, cos=0.005), tot_loss_proj:2.261 [t=0.18s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that never fixtti [SEP]']
[1500/2000] tot_loss=1.828 (perp=8.526, rec=0.118, cos=0.005), tot_loss_proj:2.251 [t=0.24s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that never fixtti [SEP]']
Attempt swap
[1550/2000] tot_loss=1.822 (perp=8.526, rec=0.112, cos=0.005), tot_loss_proj:2.256 [t=0.19s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that never fixtti [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.771 (perp=8.266, rec=0.112, cos=0.005), tot_loss_proj:2.255 [t=0.20s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]']
[1650/2000] tot_loss=1.776 (perp=8.266, rec=0.118, cos=0.005), tot_loss_proj:2.253 [t=0.27s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]']
Attempt swap
[1700/2000] tot_loss=1.772 (perp=8.266, rec=0.114, cos=0.005), tot_loss_proj:2.253 [t=0.18s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]']
Attempt swap
[1750/2000] tot_loss=1.777 (perp=8.266, rec=0.119, cos=0.005), tot_loss_proj:2.257 [t=0.18s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]']
[1800/2000] tot_loss=1.776 (perp=8.266, rec=0.118, cos=0.005), tot_loss_proj:2.253 [t=0.25s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.770 (perp=8.266, rec=0.113, cos=0.005), tot_loss_proj:2.250 [t=0.21s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]']
Attempt swap
[1900/2000] tot_loss=1.768 (perp=8.266, rec=0.110, cos=0.005), tot_loss_proj:2.248 [t=0.21s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]']
[1950/2000] tot_loss=1.766 (perp=8.266, rec=0.108, cos=0.005), tot_loss_proj:2.252 [t=0.19s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.773 (perp=8.266, rec=0.115, cos=0.005), tot_loss_proj:2.261 [t=0.26s]
prediction: ['[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] years of costly years will loads of years cause yearsparable damage analysis of《 films that fixtti never [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 76.923 | p: 78.947 | r: 75.000
rouge2     | fm: 16.216 | p: 16.667 | r: 15.789
rougeL     | fm: 41.026 | p: 42.105 | r: 40.000
rougeLsum  | fm: 41.026 | p: 42.105 | r: 40.000
r1fm+r2fm = 93.139

[Aggregate metrics]:
rouge1     | fm: 88.990 | p: 88.795 | r: 89.193
rouge2     | fm: 53.507 | p: 53.457 | r: 53.614
rougeL     | fm: 76.675 | p: 76.551 | r: 76.822
rougeLsum  | fm: 76.584 | p: 76.536 | r: 76.722
r1fm+r2fm = 142.497

input #56 time: 0:08:27 | total time: 7:58:28


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9988966590469601
highest_index [0]
highest [0.9988966590469601]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 0.884034276008606 for ['[CLS]ne [SEP]']
[Init] best rec loss: 0.7585564851760864 for ['[CLS] software [SEP]']
[Init] best rec loss: 0.6924987435340881 for ['[CLS] passed [SEP]']
[Init] best rec loss: 0.6865731477737427 for ['[CLS] himself [SEP]']
[Init] best rec loss: 0.6849911212921143 for ['[CLS] decision [SEP]']
[Init] best rec loss: 0.684822142124176 for ['[CLS] raul [SEP]']
[Init] best rec loss: 0.6814881563186646 for ['[CLS] dorm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.567 (perp=12.282, rec=0.097, cos=0.014), tot_loss_proj:2.530 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
[ 100/2000] tot_loss=2.532 (perp=12.282, rec=0.070, cos=0.005), tot_loss_proj:2.521 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.515 (perp=12.282, rec=0.056, cos=0.003), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.515 (perp=12.282, rec=0.054, cos=0.004), tot_loss_proj:2.507 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.502 (perp=12.282, rec=0.043, cos=0.002), tot_loss_proj:2.532 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.527 (perp=12.282, rec=0.068, cos=0.003), tot_loss_proj:2.515 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.507 (perp=12.282, rec=0.048, cos=0.002), tot_loss_proj:2.517 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.516 (perp=12.282, rec=0.057, cos=0.002), tot_loss_proj:2.532 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.515 (perp=12.282, rec=0.057, cos=0.002), tot_loss_proj:2.509 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.537 (perp=12.282, rec=0.079, cos=0.002), tot_loss_proj:2.520 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.531 (perp=12.282, rec=0.073, cos=0.002), tot_loss_proj:2.512 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.508 (perp=12.282, rec=0.049, cos=0.002), tot_loss_proj:2.511 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.517 (perp=12.282, rec=0.058, cos=0.002), tot_loss_proj:2.527 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.510 (perp=12.282, rec=0.051, cos=0.002), tot_loss_proj:2.509 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.523 (perp=12.282, rec=0.064, cos=0.002), tot_loss_proj:2.523 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.515 (perp=12.282, rec=0.056, cos=0.002), tot_loss_proj:2.529 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.521 (perp=12.282, rec=0.062, cos=0.002), tot_loss_proj:2.527 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.531 (perp=12.282, rec=0.072, cos=0.002), tot_loss_proj:2.504 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.505 (perp=12.282, rec=0.046, cos=0.002), tot_loss_proj:2.517 [t=0.29s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.524 (perp=12.282, rec=0.066, cos=0.002), tot_loss_proj:2.515 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.521 (perp=12.282, rec=0.062, cos=0.002), tot_loss_proj:2.508 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.511 (perp=12.282, rec=0.052, cos=0.002), tot_loss_proj:2.515 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.520 (perp=12.282, rec=0.062, cos=0.002), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.512 (perp=12.282, rec=0.053, cos=0.002), tot_loss_proj:2.522 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.537 (perp=12.282, rec=0.078, cos=0.002), tot_loss_proj:2.525 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.519 (perp=12.282, rec=0.060, cos=0.002), tot_loss_proj:2.497 [t=0.24s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.510 (perp=12.282, rec=0.051, cos=0.002), tot_loss_proj:2.513 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.506 (perp=12.282, rec=0.047, cos=0.002), tot_loss_proj:2.514 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.515 (perp=12.282, rec=0.056, cos=0.002), tot_loss_proj:2.515 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.527 (perp=12.282, rec=0.068, cos=0.002), tot_loss_proj:2.518 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.511 (perp=12.282, rec=0.052, cos=0.002), tot_loss_proj:2.504 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.519 (perp=12.282, rec=0.060, cos=0.002), tot_loss_proj:2.524 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.525 (perp=12.282, rec=0.066, cos=0.002), tot_loss_proj:2.509 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.002), tot_loss_proj:2.517 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.539 (perp=12.282, rec=0.080, cos=0.002), tot_loss_proj:2.517 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.524 (perp=12.282, rec=0.065, cos=0.002), tot_loss_proj:2.514 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.514 (perp=12.282, rec=0.055, cos=0.002), tot_loss_proj:2.508 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.505 (perp=12.282, rec=0.046, cos=0.002), tot_loss_proj:2.515 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.515 (perp=12.282, rec=0.056, cos=0.002), tot_loss_proj:2.510 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.002), tot_loss_proj:2.510 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.191 | p: 88.975 | r: 89.406
rouge2     | fm: 54.349 | p: 54.268 | r: 54.507
rougeL     | fm: 76.985 | p: 76.878 | r: 77.138
rougeLsum  | fm: 76.998 | p: 76.926 | r: 77.139
r1fm+r2fm = 143.540

input #57 time: 0:08:20 | total time: 8:06:48


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9987694476667097
highest_index [0]
highest [0.9987694476667097]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.0188543796539307 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 0.9867589473724365 for ['[CLS] valuefect damon tub shelf sinatra billy feels studyoat chu jets crude competition campaign alleged [SEP]']
[Init] best rec loss: 0.9801039695739746 for ['[CLS] things reggie on guinnessllet continue special the chan (ness grew prone moffatockshire [SEP]']
[Init] best rec loss: 0.9751459360122681 for ['[CLS] kent posted halfgative copy united practitionerfield bryce prep hatchsin universe via holloway tradition [SEP]']
[Init] best rec loss: 0.9745179414749146 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 0.9714805483818054 for ['[CLS]mon recorded govt bolsheviks iv ignited countymetricual helmet army £100 continuedbanes recognition [SEP]']
[Init] best rec loss: 0.958451509475708 for ['[CLS] partner kickoff message oh hills edge wind mono stainless few sk closet clay fair ole port [SEP]']
[Init] best rec loss: 0.9337957501411438 for ['[CLS] charms status minutes residency automatic marlon career signsburg henderson leaves future conflicting everdict route [SEP]']
[Init] best perm rec loss: 0.931867778301239 for ['[CLS]dict residencysburg conflicting status charms sign ever henderson future minutes career automatic leaves marlon route [SEP]']
[Init] best perm rec loss: 0.9309636950492859 for ['[CLS] leaves status future careersburg ever sign automatic conflicting henderson routedict marlon minutes charms residency [SEP]']
[Init] best perm rec loss: 0.9271642565727234 for ['[CLS] status conflicting residency signdict career automatic henderson marlon futuresburg ever minutes leaves charms route [SEP]']
[Init] best perm rec loss: 0.9232746958732605 for ['[CLS] residency statusdict charmssburg minutes automatic career leaves ever henderson conflicting sign future marlon route [SEP]']
[Init] best perm rec loss: 0.9228004217147827 for ['[CLS] career sign henderson minutes residency conflicting marlon automatic future charmssburg statusdict leaves ever route [SEP]']
[Init] best perm rec loss: 0.9223025441169739 for ['[CLS] career status conflictingdict minutes charms sign leavessburg ever henderson future automatic marlon residency route [SEP]']
[Init] best perm rec loss: 0.9217897653579712 for ['[CLS] charms leaves route minutes career marlon conflicting status hendersonsburg automatic sign residency ever futuredict [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.592 (perp=11.607, rec=0.259, cos=0.012), tot_loss_proj:3.424 [t=0.26s]
prediction: ['[CLS]os figure. grateful the faith and village intimate woods moth sex created indiana x often [SEP]']
[ 100/2000] tot_loss=2.531 (perp=11.759, rec=0.172, cos=0.008), tot_loss_proj:2.906 [t=0.21s]
prediction: ['[CLS]ness significant is inspirational the inspirational an story inspirational look innocence love capturing new temptation often [SEP]']
[ 150/2000] tot_loss=2.151 (perp=10.006, rec=0.143, cos=0.008), tot_loss_proj:2.470 [t=0.23s]
prediction: ['[CLS]ness significant is inspirational an inspirational a story capturing innocence innocence love capturing, innocent often [SEP]']
[ 200/2000] tot_loss=2.275 (perp=10.758, rec=0.115, cos=0.008), tot_loss_proj:2.773 [t=0.19s]
prediction: ['[CLS]ne historic is inspirational an inspirational a story innocence innocence innocence love capturing, innocence often [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.148 (perp=10.079, rec=0.125, cos=0.007), tot_loss_proj:2.677 [t=0.21s]
prediction: ['[CLS] often are is inspirational an inspirational a story innocence innocence encounter love capturing the innocencees [SEP]']
[ 300/2000] tot_loss=2.120 (perp=9.989, rec=0.115, cos=0.007), tot_loss_proj:2.939 [t=0.19s]
prediction: ['[CLS] relatively were is inspirational an inspirational, story innocenceism encounter love capturing the innocencees [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.972 (perp=9.277, rec=0.109, cos=0.007), tot_loss_proj:2.809 [t=0.19s]
prediction: ['[CLS] relatively were is inspirational an inspirational love story innocenceism encounter and capturing the innocencees [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.807 (perp=8.510, rec=0.098, cos=0.007), tot_loss_proj:2.371 [t=0.23s]
prediction: ['[CLS] ideal were inspirational is an inspirational love story innocenceism encounter and capturing the innocencees [SEP]']
[ 450/2000] tot_loss=1.810 (perp=8.510, rec=0.101, cos=0.007), tot_loss_proj:2.370 [t=0.19s]
prediction: ['[CLS] ideal were inspirational is an inspirational love story innocenceism encounter and capturing the innocencees [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.835 (perp=8.627, rec=0.103, cos=0.007), tot_loss_proj:2.146 [t=0.20s]
prediction: ['[CLS] widelyly inspirational innocenceism encounter and is an inspirational love story capturing the innocencess [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.663 (perp=7.810, rec=0.094, cos=0.007), tot_loss_proj:1.942 [t=0.18s]
prediction: ['[CLS] ideally inspirational innocence encounter, is an inspirational love story capturing the innocencessism [SEP]']
[ 600/2000] tot_loss=1.664 (perp=7.810, rec=0.095, cos=0.007), tot_loss_proj:1.944 [t=0.19s]
prediction: ['[CLS] ideally inspirational innocence encounter, is an inspirational love story capturing the innocencessism [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.549 (perp=7.265, rec=0.089, cos=0.008), tot_loss_proj:1.992 [t=0.19s]
prediction: ['[CLS]ssly inspirational innocence encounter, is an inspirational love story capturing the innocence idealism [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.520 (perp=7.038, rec=0.105, cos=0.007), tot_loss_proj:1.991 [t=0.21s]
prediction: ['[CLS]ssly inspirational innocence, encounter is an inspirational love story capturing the innocence idealism [SEP]']
[ 750/2000] tot_loss=1.606 (perp=7.530, rec=0.093, cos=0.007), tot_loss_proj:2.168 [t=0.22s]
prediction: ['[CLS]rea two inspirational innocence, encounter is an inspirational love story capturing the innocence idealism [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.597 (perp=7.467, rec=0.097, cos=0.007), tot_loss_proj:2.100 [t=0.19s]
prediction: ['[CLS] tworea inspirational innocence, encounter is an inspirational love story capturing the innocence idealism [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.594 (perp=7.467, rec=0.093, cos=0.007), tot_loss_proj:2.102 [t=0.25s]
prediction: ['[CLS] tworea inspirational innocence, encounter is an inspirational love story capturing the innocence idealism [SEP]']
[ 900/2000] tot_loss=1.510 (perp=7.064, rec=0.090, cos=0.007), tot_loss_proj:1.898 [t=0.19s]
prediction: ['[CLS] therea inspirational innocence, encounter is an inspirational love story capturing the innocence ideal of [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.573 (perp=7.400, rec=0.086, cos=0.007), tot_loss_proj:2.129 [t=0.18s]
prediction: ['[CLS]rea two inspirational innocence, encounter is an inspirational love story capturing the innocence ideal of [SEP]']
Attempt swap
Put prefix at the end
[1000/2000] tot_loss=1.501 (perp=6.982, rec=0.098, cos=0.007), tot_loss_proj:1.982 [t=0.18s]
prediction: ['[CLS] were inspirational innocence, encounter is an inspirational love story capturing the innocence ideal ofrea [SEP]']
[1050/2000] tot_loss=1.501 (perp=6.982, rec=0.097, cos=0.007), tot_loss_proj:1.975 [t=0.18s]
prediction: ['[CLS] were inspirational innocence, encounter is an inspirational love story capturing the innocence ideal ofrea [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.556 (perp=7.290, rec=0.091, cos=0.007), tot_loss_proj:2.087 [t=0.22s]
prediction: ['[CLS] were ideal innocence, encounter is an inspirational love story capturing the ideal innocence ofrea [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.498 (perp=6.998, rec=0.091, cos=0.007), tot_loss_proj:1.919 [t=0.26s]
prediction: ['[CLS] were ideal innocence, ideal encounter is an inspirational love story capturing the innocence ofrea [SEP]']
[1200/2000] tot_loss=1.498 (perp=6.998, rec=0.091, cos=0.007), tot_loss_proj:1.919 [t=0.19s]
prediction: ['[CLS] were ideal innocence, ideal encounter is an inspirational love story capturing the innocence ofrea [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.457 (perp=6.834, rec=0.083, cos=0.007), tot_loss_proj:1.823 [t=0.26s]
prediction: ['[CLS] were ideal, ideal encounter is an inspirational love story capturing the innocence of innocencerea [SEP]']
Attempt swap
[1300/2000] tot_loss=1.468 (perp=6.834, rec=0.094, cos=0.007), tot_loss_proj:1.813 [t=0.18s]
prediction: ['[CLS] were ideal, ideal encounter is an inspirational love story capturing the innocence of innocencerea [SEP]']
[1350/2000] tot_loss=1.467 (perp=6.834, rec=0.093, cos=0.007), tot_loss_proj:1.817 [t=0.22s]
prediction: ['[CLS] were ideal, ideal encounter is an inspirational love story capturing the innocence of innocencerea [SEP]']
Attempt swap
[1400/2000] tot_loss=1.500 (perp=7.021, rec=0.088, cos=0.007), tot_loss_proj:1.884 [t=0.18s]
prediction: ['[CLS] were ideal, ideal encounter is an inspirational love story capturing the ideal of innocencerea [SEP]']
Attempt swap
[1450/2000] tot_loss=1.494 (perp=7.021, rec=0.083, cos=0.007), tot_loss_proj:1.888 [t=0.18s]
prediction: ['[CLS] were ideal, ideal encounter is an inspirational love story capturing the ideal of innocencerea [SEP]']
[1500/2000] tot_loss=1.390 (perp=6.457, rec=0.091, cos=0.007), tot_loss_proj:1.669 [t=0.18s]
prediction: ['[CLS] the ideal, ideal encounter is an inspirational love story capturing the ideal of innocencerea [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.501 (perp=7.001, rec=0.094, cos=0.007), tot_loss_proj:1.831 [t=0.18s]
prediction: ['[CLS] were ideal, ideal encounter is an inspirational love story capturing the ideal innocence ofrea [SEP]']
Attempt swap
[1600/2000] tot_loss=1.498 (perp=7.001, rec=0.091, cos=0.007), tot_loss_proj:1.826 [t=0.19s]
prediction: ['[CLS] were ideal, ideal encounter is an inspirational love story capturing the ideal innocence ofrea [SEP]']
[1650/2000] tot_loss=1.397 (perp=6.453, rec=0.099, cos=0.007), tot_loss_proj:1.619 [t=0.19s]
prediction: ['[CLS] the ideal, ideal encounter is an inspirational love story capturing the ideal innocence ofrea [SEP]']
Attempt swap
[1700/2000] tot_loss=1.391 (perp=6.453, rec=0.093, cos=0.007), tot_loss_proj:1.624 [t=0.19s]
prediction: ['[CLS] the ideal, ideal encounter is an inspirational love story capturing the ideal innocence ofrea [SEP]']
Attempt swap
[1750/2000] tot_loss=1.395 (perp=6.453, rec=0.097, cos=0.007), tot_loss_proj:1.626 [t=0.24s]
prediction: ['[CLS] the ideal, ideal encounter is an inspirational love story capturing the ideal innocence ofrea [SEP]']
[1800/2000] tot_loss=1.391 (perp=6.453, rec=0.093, cos=0.007), tot_loss_proj:1.618 [t=0.18s]
prediction: ['[CLS] the ideal, ideal encounter is an inspirational love story capturing the ideal innocence ofrea [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.361 (perp=6.314, rec=0.091, cos=0.007), tot_loss_proj:1.659 [t=0.22s]
prediction: ['[CLS] the ideal, ideal encounter is an ideal inspirational love story capturing the innocence ofrea [SEP]']
Attempt swap
[1900/2000] tot_loss=1.355 (perp=6.314, rec=0.085, cos=0.007), tot_loss_proj:1.649 [t=0.25s]
prediction: ['[CLS] the ideal, ideal encounter is an ideal inspirational love story capturing the innocence ofrea [SEP]']
[1950/2000] tot_loss=1.358 (perp=6.314, rec=0.088, cos=0.007), tot_loss_proj:1.650 [t=0.19s]
prediction: ['[CLS] the ideal, ideal encounter is an ideal inspirational love story capturing the innocence ofrea [SEP]']
Attempt swap
[2000/2000] tot_loss=1.362 (perp=6.314, rec=0.092, cos=0.007), tot_loss_proj:1.652 [t=0.19s]
prediction: ['[CLS] the ideal, ideal encounter is an ideal inspirational love story capturing the innocence ofrea [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] were ideal, ideal encounter is an inspirational love story capturing the ideal innocence ofrea [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.750 | p: 68.750 | r: 68.750
rouge2     | fm: 40.000 | p: 40.000 | r: 40.000
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 108.750

[Aggregate metrics]:
rouge1     | fm: 88.794 | p: 88.634 | r: 89.066
rouge2     | fm: 54.234 | p: 54.155 | r: 54.380
rougeL     | fm: 76.809 | p: 76.718 | r: 77.024
rougeLsum  | fm: 76.672 | p: 76.568 | r: 76.763
r1fm+r2fm = 143.028

input #58 time: 0:08:17 | total time: 8:15:05


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9986772290674257
highest_index [0]
highest [0.9986772290674257]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 0.8790918588638306 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 0.8580102920532227 for ['[CLS] poll dominance intine drop silvertock politician wrappedve complete hot reading team disco world [SEP]']
[Init] best rec loss: 0.8477619886398315 for ['[CLS] mala minute theory mandatory stands after mere figure number roth sister locomotives bombay bavarian late athlete [SEP]']
[Init] best rec loss: 0.8377500772476196 for ['[CLS]notes urban shape atliest not filterae titled making prize wait sex ste front coach [SEP]']
[Init] best rec loss: 0.8242617845535278 for ['[CLS] key stafforddial done colony midst kmdden face ɾord muscle warning ( wife organic [SEP]']
[Init] best rec loss: 0.8217411041259766 for ['[CLS] fk saint metric cement joining empire honda western detailpi ) underground marek solvent quad reed [SEP]']
[Init] best rec loss: 0.8102769255638123 for ['[CLS]enity replacedserof heart mum interviewed we cook husbandsion semifinalsgn exclusive atı [SEP]']
[Init] best perm rec loss: 0.8096859455108643 for ['[CLS] at cookion heartser interviewed we mum semifinalsenityof exclusive replacedı husbandsgn [SEP]']
[Init] best perm rec loss: 0.8082981109619141 for ['[CLS] exclusiveenityı weion heart cookgn replaced mum interviewed atof husbandsser semifinals [SEP]']
[Init] best perm rec loss: 0.8062892556190491 for ['[CLS]ion at husbands cook weenity exclusive replaced heart mum interviewedsergnofı semifinals [SEP]']
[Init] best perm rec loss: 0.8059536814689636 for ['[CLS]ofgn heartserı cook replacedenityion husbands at interviewed exclusive we semifinals mum [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.114 (perp=12.057, rec=0.463, cos=0.240), tot_loss_proj:3.390 [t=0.18s]
prediction: ['[CLS] radiated the land if symbols tilted woredale miracle passion caught tall strong she the lee [SEP]']
[ 100/2000] tot_loss=2.882 (perp=11.663, rec=0.371, cos=0.178), tot_loss_proj:3.609 [t=0.24s]
prediction: ['[CLS]ism the womanths symbols able woman who miracle honey of woman having monitor of knows [SEP]']
[ 150/2000] tot_loss=2.557 (perp=10.177, rec=0.327, cos=0.195), tot_loss_proj:3.884 [t=0.18s]
prediction: ['[CLS] had the womanths highlands how woman who miracle hypothesis who woman having screen of screen [SEP]']
[ 200/2000] tot_loss=2.394 (perp=9.753, rec=0.285, cos=0.158), tot_loss_proj:2.862 [t=0.18s]
prediction: ['[CLS] has aism is of young woman who remarkable brady who woman knows screen of screen [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.078 (perp=8.241, rec=0.273, cos=0.156), tot_loss_proj:2.295 [t=0.25s]
prediction: ['[CLS] hasism of the young woman who a remarkable gives who woman the screen of screen [SEP]']
[ 300/2000] tot_loss=2.299 (perp=9.343, rec=0.264, cos=0.167), tot_loss_proj:2.674 [t=0.24s]
prediction: ['[CLS] hasism of lim young woman who a remarkable : who woman the screen a screen [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.987 (perp=7.899, rec=0.246, cos=0.161), tot_loss_proj:2.581 [t=0.18s]
prediction: ['[CLS] hasism of the young woman who a woman the remarkable who believed screen the screen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.288 (perp=9.456, rec=0.241, cos=0.156), tot_loss_proj:2.596 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who a hold the remarkable jim believed screen the screen [SEP]']
[ 450/2000] tot_loss=2.346 (perp=9.524, rec=0.236, cos=0.205), tot_loss_proj:3.553 [t=0.27s]
prediction: ['[CLS] hasisma of young woman who a hold the knows monster believed screen the screen [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.424 (perp=10.056, rec=0.230, cos=0.183), tot_loss_proj:3.485 [t=0.24s]
prediction: ['[CLS] hasisma of young woman who a screen how mary dos believed hold with screen [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.161 (perp=8.499, rec=0.234, cos=0.228), tot_loss_proj:3.247 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who the screen knows how dos of hold with screen [SEP]']
[ 600/2000] tot_loss=2.197 (perp=8.896, rec=0.218, cos=0.200), tot_loss_proj:3.495 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who the screen holds how dos of hold with screen [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.327 (perp=9.401, rec=0.220, cos=0.226), tot_loss_proj:3.640 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who the screen sunrise hold with screen how dos of [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.237 (perp=9.120, rec=0.211, cos=0.203), tot_loss_proj:3.479 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who of screen sunrise hold the screen how dos of [SEP]']
[ 750/2000] tot_loss=2.249 (perp=9.120, rec=0.209, cos=0.216), tot_loss_proj:3.481 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who of screen sunrise hold the screen how dos of [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.158 (perp=8.763, rec=0.206, cos=0.199), tot_loss_proj:3.103 [t=0.21s]
prediction: ['[CLS] hasisma of young woman who of screen sunrise hold the screen the dos of [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=2.251 (perp=9.225, rec=0.203, cos=0.203), tot_loss_proj:3.203 [t=0.19s]
prediction: ['[CLS] hasisma of young woman who of screen sunrise hold the screen dos of knows [SEP]']
[ 900/2000] tot_loss=2.135 (perp=8.691, rec=0.198, cos=0.199), tot_loss_proj:3.503 [t=0.21s]
prediction: ['[CLS] hasisma of young woman who of screen availability hold the screen dos of the [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.333 (perp=9.608, rec=0.197, cos=0.214), tot_loss_proj:3.035 [t=0.21s]
prediction: ['[CLS] hasisma of young woman who of sunrise screen hold the screen ari of knows [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.169 (perp=8.888, rec=0.201, cos=0.191), tot_loss_proj:2.975 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who of sunrise screen hold the screen of ari knows [SEP]']
[1050/2000] tot_loss=2.163 (perp=8.888, rec=0.192, cos=0.193), tot_loss_proj:2.975 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who of sunrise screen hold the screen of ari knows [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.111 (perp=8.512, rec=0.197, cos=0.212), tot_loss_proj:2.806 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who of sunrise ari hold the screen of screen knows [SEP]']
Attempt swap
[1150/2000] tot_loss=2.097 (perp=8.512, rec=0.197, cos=0.197), tot_loss_proj:2.804 [t=0.18s]
prediction: ['[CLS] hasisma of young woman who of sunrise ari hold the screen of screen knows [SEP]']
[1200/2000] tot_loss=2.095 (perp=8.512, rec=0.188, cos=0.205), tot_loss_proj:2.797 [t=0.26s]
prediction: ['[CLS] hasisma of young woman who of sunrise ari hold the screen of screen knows [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=2.046 (perp=8.212, rec=0.201, cos=0.203), tot_loss_proj:2.630 [t=0.18s]
prediction: ['[CLS] hasisma of young woman of sunrise who ari hold the screen of screen knows [SEP]']
Attempt swap
[1300/2000] tot_loss=2.037 (perp=8.212, rec=0.193, cos=0.202), tot_loss_proj:2.630 [t=0.23s]
prediction: ['[CLS] hasisma of young woman of sunrise who ari hold the screen of screen knows [SEP]']
[1350/2000] tot_loss=2.026 (perp=8.212, rec=0.190, cos=0.193), tot_loss_proj:2.631 [t=0.22s]
prediction: ['[CLS] hasisma of young woman of sunrise who ari hold the screen of screen knows [SEP]']
Attempt swap
[1400/2000] tot_loss=2.032 (perp=8.212, rec=0.193, cos=0.196), tot_loss_proj:2.633 [t=0.22s]
prediction: ['[CLS] hasisma of young woman of sunrise who ari hold the screen of screen knows [SEP]']
Attempt swap
[1450/2000] tot_loss=2.026 (perp=8.212, rec=0.187, cos=0.197), tot_loss_proj:2.630 [t=0.19s]
prediction: ['[CLS] hasisma of young woman of sunrise who ari hold the screen of screen knows [SEP]']
[1500/2000] tot_loss=2.072 (perp=8.426, rec=0.187, cos=0.200), tot_loss_proj:2.699 [t=0.27s]
prediction: ['[CLS] hasisma of young woman of sunrise who ari knows the screen of screen knows [SEP]']
Attempt swap
[1550/2000] tot_loss=2.073 (perp=8.426, rec=0.187, cos=0.201), tot_loss_proj:2.699 [t=0.21s]
prediction: ['[CLS] hasisma of young woman of sunrise who ari knows the screen of screen knows [SEP]']
Attempt swap
[1600/2000] tot_loss=2.071 (perp=8.426, rec=0.183, cos=0.202), tot_loss_proj:2.703 [t=0.18s]
prediction: ['[CLS] hasisma of young woman of sunrise who ari knows the screen of screen knows [SEP]']
[1650/2000] tot_loss=2.043 (perp=8.328, rec=0.179, cos=0.198), tot_loss_proj:2.576 [t=0.18s]
prediction: ['[CLS] hasisma of young woman of fierce who ari knows the screen of screen knows [SEP]']
Attempt swap
[1700/2000] tot_loss=2.043 (perp=8.328, rec=0.180, cos=0.198), tot_loss_proj:2.576 [t=0.24s]
prediction: ['[CLS] hasisma of young woman of fierce who ari knows the screen of screen knows [SEP]']
Attempt swap
[1750/2000] tot_loss=2.050 (perp=8.328, rec=0.184, cos=0.201), tot_loss_proj:2.577 [t=0.19s]
prediction: ['[CLS] hasisma of young woman of fierce who ari knows the screen of screen knows [SEP]']
[1800/2000] tot_loss=2.050 (perp=8.328, rec=0.181, cos=0.203), tot_loss_proj:2.574 [t=0.23s]
prediction: ['[CLS] hasisma of young woman of fierce who ari knows the screen of screen knows [SEP]']
Attempt swap
[1850/2000] tot_loss=2.045 (perp=8.328, rec=0.178, cos=0.202), tot_loss_proj:2.583 [t=0.29s]
prediction: ['[CLS] hasisma of young woman of fierce who ari knows the screen of screen knows [SEP]']
Attempt swap
[1900/2000] tot_loss=2.040 (perp=8.328, rec=0.176, cos=0.198), tot_loss_proj:2.582 [t=0.18s]
prediction: ['[CLS] hasisma of young woman of fierce who ari knows the screen of screen knows [SEP]']
[1950/2000] tot_loss=2.042 (perp=8.328, rec=0.175, cos=0.202), tot_loss_proj:2.577 [t=0.26s]
prediction: ['[CLS] hasisma of young woman of fierce who ari knows the screen of screen knows [SEP]']
Attempt swap
[2000/2000] tot_loss=2.045 (perp=8.328, rec=0.176, cos=0.203), tot_loss_proj:2.582 [t=0.22s]
prediction: ['[CLS] hasisma of young woman of fierce who ari knows the screen of screen knows [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] hasisma of young woman of fierce who ari knows the screen of screen knows [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 56.250 | p: 56.250 | r: 56.250
rouge2     | fm: 13.333 | p: 13.333 | r: 13.333
rougeL     | fm: 56.250 | p: 56.250 | r: 56.250
rougeLsum  | fm: 56.250 | p: 56.250 | r: 56.250
r1fm+r2fm = 69.583

[Aggregate metrics]:
rouge1     | fm: 88.294 | p: 88.096 | r: 88.523
rouge2     | fm: 53.412 | p: 53.355 | r: 53.548
rougeL     | fm: 76.440 | p: 76.371 | r: 76.606
rougeLsum  | fm: 76.403 | p: 76.337 | r: 76.514
r1fm+r2fm = 141.706

input #59 time: 0:08:21 | total time: 8:23:27


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.9985588101534638
highest_index [0]
highest [0.9985588101534638]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 0.9189993739128113 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 0.9157719016075134 for ['[CLS] everything partnership bas gossip lies donegal directionbad his western ann arms [SEP]']
[Init] best rec loss: 0.9126713275909424 for ['[CLS] joo lead cancer course haiti board read empire dortmund commune member tory [SEP]']
[Init] best rec loss: 0.8938601016998291 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 0.8618214726448059 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 0.8473484516143799 for ['[CLS] percent symbol budapest herald nets flavor shoppingted archlizer clock tight [SEP]']
[Init] best rec loss: 0.83450847864151 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 0.8140032291412354 for ['[CLS] rico shave overcomensor 1st opus introduced knockout currency area statewide whispered [SEP]']
[Init] best perm rec loss: 0.8083643913269043 for ['[CLS] 1st currency statewide opus rico overcome introduced whisperednsor knockout shave area [SEP]']
[Init] best perm rec loss: 0.8072608709335327 for ['[CLS] area knockout statewide shave currency 1st whispered opus overcome rico introducednsor [SEP]']
[Init] best perm rec loss: 0.8059592247009277 for ['[CLS] knockout rico shave introduced whispered currency overcome opusnsor 1st statewide area [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.614 (perp=11.853, rec=0.229, cos=0.014), tot_loss_proj:3.078 [t=0.26s]
prediction: ['[CLS] of is awkwardly telenovela awkwardly city polynomial book check is circuit track [SEP]']
[ 100/2000] tot_loss=2.164 (perp=10.020, rec=0.152, cos=0.007), tot_loss_proj:2.418 [t=0.17s]
prediction: ['[CLS] the is awkwardly circuit awkwardly paced soap operah is circuit story [SEP]']
[ 150/2000] tot_loss=2.177 (perp=10.296, rec=0.111, cos=0.007), tot_loss_proj:2.546 [t=0.20s]
prediction: ['[CLS] the is awkwardly circuit awkwardly paced soap operah - circuit story [SEP]']
[ 200/2000] tot_loss=2.172 (perp=10.296, rec=0.107, cos=0.006), tot_loss_proj:2.562 [t=0.24s]
prediction: ['[CLS] the is awkwardly circuit awkwardly paced soap operah - circuit story [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.012 (perp=9.492, rec=0.107, cos=0.006), tot_loss_proj:2.283 [t=0.19s]
prediction: ['[CLS] the soap is awkwardly awkwardly paced soap operah - circuit story [SEP]']
[ 300/2000] tot_loss=1.997 (perp=9.492, rec=0.092, cos=0.006), tot_loss_proj:2.283 [t=0.19s]
prediction: ['[CLS] the soap is awkwardly awkwardly paced soap operah - circuit story [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.912 (perp=9.067, rec=0.094, cos=0.005), tot_loss_proj:2.218 [t=0.24s]
prediction: ['[CLS] the soap is awkwardly awkwardly paced soap operah - story circuit [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.847 (perp=8.775, rec=0.087, cos=0.005), tot_loss_proj:2.138 [t=0.18s]
prediction: ['[CLS] awkwardly soap is the awkwardly paced soap operah - story circuit [SEP]']
[ 450/2000] tot_loss=1.839 (perp=8.775, rec=0.079, cos=0.005), tot_loss_proj:2.131 [t=0.22s]
prediction: ['[CLS] awkwardly soap is the awkwardly paced soap operah - story circuit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.845 (perp=8.775, rec=0.085, cos=0.005), tot_loss_proj:2.126 [t=0.27s]
prediction: ['[CLS] awkwardly soap is the awkwardly paced soap operah - story circuit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.845 (perp=8.775, rec=0.086, cos=0.005), tot_loss_proj:2.133 [t=0.18s]
prediction: ['[CLS] awkwardly soap is the awkwardly paced soap operah - story circuit [SEP]']
[ 600/2000] tot_loss=1.842 (perp=8.775, rec=0.082, cos=0.005), tot_loss_proj:2.128 [t=0.23s]
prediction: ['[CLS] awkwardly soap is the awkwardly paced soap operah - story circuit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.844 (perp=8.775, rec=0.084, cos=0.005), tot_loss_proj:2.132 [t=0.24s]
prediction: ['[CLS] awkwardly soap is the awkwardly paced soap operah - story circuit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.845 (perp=8.775, rec=0.086, cos=0.005), tot_loss_proj:2.135 [t=0.26s]
prediction: ['[CLS] awkwardly soap is the awkwardly paced soap operah - story circuit [SEP]']
[ 750/2000] tot_loss=1.842 (perp=8.775, rec=0.082, cos=0.005), tot_loss_proj:2.140 [t=0.19s]
prediction: ['[CLS] awkwardly soap is the awkwardly paced soap operah - story circuit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.842 (perp=8.775, rec=0.082, cos=0.005), tot_loss_proj:2.134 [t=0.19s]
prediction: ['[CLS] awkwardly soap is the awkwardly paced soap operah - story circuit [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.712 (perp=7.944, rec=0.116, cos=0.007), tot_loss_proj:2.002 [t=0.25s]
prediction: ['[CLS]h - awkwardly soap is the awkwardly paced soap opera story circuit [SEP]']
[ 900/2000] tot_loss=1.689 (perp=7.944, rec=0.095, cos=0.005), tot_loss_proj:1.994 [t=0.25s]
prediction: ['[CLS]h - awkwardly soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.676 (perp=7.944, rec=0.082, cos=0.005), tot_loss_proj:2.001 [t=0.18s]
prediction: ['[CLS]h - awkwardly soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.649 (perp=7.732, rec=0.098, cos=0.005), tot_loss_proj:2.008 [t=0.23s]
prediction: ['[CLS]h is soap - is the awkwardly paced soap opera story circuit [SEP]']
[1050/2000] tot_loss=1.630 (perp=7.732, rec=0.079, cos=0.005), tot_loss_proj:2.007 [t=0.19s]
prediction: ['[CLS]h is soap - is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.537 (perp=7.252, rec=0.082, cos=0.005), tot_loss_proj:1.850 [t=0.24s]
prediction: ['[CLS] ish soap - is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.527 (perp=7.252, rec=0.072, cos=0.005), tot_loss_proj:1.844 [t=0.21s]
prediction: ['[CLS] ish soap - is the awkwardly paced soap opera story circuit [SEP]']
[1200/2000] tot_loss=1.524 (perp=7.252, rec=0.069, cos=0.005), tot_loss_proj:1.846 [t=0.18s]
prediction: ['[CLS] ish soap - is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.507 (perp=7.168, rec=0.069, cos=0.004), tot_loss_proj:1.788 [t=0.19s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.509 (perp=7.168, rec=0.071, cos=0.004), tot_loss_proj:1.788 [t=0.18s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
[1350/2000] tot_loss=1.521 (perp=7.168, rec=0.082, cos=0.004), tot_loss_proj:1.792 [t=0.24s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.507 (perp=7.168, rec=0.069, cos=0.004), tot_loss_proj:1.789 [t=0.19s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.511 (perp=7.168, rec=0.073, cos=0.004), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
[1500/2000] tot_loss=1.506 (perp=7.168, rec=0.068, cos=0.004), tot_loss_proj:1.797 [t=0.24s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.506 (perp=7.168, rec=0.068, cos=0.004), tot_loss_proj:1.795 [t=0.18s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.507 (perp=7.168, rec=0.069, cos=0.004), tot_loss_proj:1.797 [t=0.18s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
[1650/2000] tot_loss=1.518 (perp=7.168, rec=0.080, cos=0.004), tot_loss_proj:1.794 [t=0.23s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.510 (perp=7.168, rec=0.072, cos=0.004), tot_loss_proj:1.796 [t=0.18s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.504 (perp=7.168, rec=0.066, cos=0.004), tot_loss_proj:1.783 [t=0.20s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
[1800/2000] tot_loss=1.519 (perp=7.168, rec=0.081, cos=0.004), tot_loss_proj:1.786 [t=0.18s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.504 (perp=7.168, rec=0.066, cos=0.004), tot_loss_proj:1.787 [t=0.25s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.506 (perp=7.168, rec=0.068, cos=0.004), tot_loss_proj:1.783 [t=0.22s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
[1950/2000] tot_loss=1.506 (perp=7.168, rec=0.069, cos=0.004), tot_loss_proj:1.786 [t=0.25s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.519 (perp=7.168, rec=0.081, cos=0.004), tot_loss_proj:1.789 [t=0.18s]
prediction: ['[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS] ish - soap is the awkwardly paced soap opera story circuit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 47.619 | p: 45.455 | r: 50.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 143.271

[Aggregate metrics]:
rouge1     | fm: 88.457 | p: 88.206 | r: 88.686
rouge2     | fm: 53.216 | p: 53.138 | r: 53.411
rougeL     | fm: 76.458 | p: 76.364 | r: 76.673
rougeLsum  | fm: 76.461 | p: 76.339 | r: 76.653
r1fm+r2fm = 141.673

input #60 time: 0:08:20 | total time: 8:31:47


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.9986266693493508
highest_index [0]
highest [0.9986266693493508]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 0.9814456701278687 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 0.9791011810302734 for ['[CLS] way consists prison [SEP]']
[Init] best rec loss: 0.9577348828315735 for ['[CLS] before parcel sold [SEP]']
[Init] best rec loss: 0.9517561793327332 for ['[CLS] running varied column [SEP]']
[Init] best rec loss: 0.9437788128852844 for ['[CLS] dunesmain dinah [SEP]']
[Init] best rec loss: 0.9374889731407166 for ['[CLS] huffington class matter [SEP]']
[Init] best rec loss: 0.9324588775634766 for ['[CLS] 1980s behindae [SEP]']
[Init] best rec loss: 0.9004234671592712 for ['[CLS] wishes chaplain blast [SEP]']
[Init] best perm rec loss: 0.8980429172515869 for ['[CLS] chaplain blast wishes [SEP]']
[Init] best perm rec loss: 0.8959572315216064 for ['[CLS] wishes blast chaplain [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.449 (perp=10.798, rec=0.654, cos=0.635), tot_loss_proj:3.971 [t=0.17s]
prediction: ['[CLS] scene uncertainty scene [SEP]']
[ 100/2000] tot_loss=3.041 (perp=8.901, rec=0.555, cos=0.706), tot_loss_proj:2.256 [t=0.18s]
prediction: ['[CLS] scene beautiful scene [SEP]']
[ 150/2000] tot_loss=3.023 (perp=8.901, rec=0.562, cos=0.681), tot_loss_proj:2.268 [t=0.20s]
prediction: ['[CLS] scene beautiful scene [SEP]']
[ 200/2000] tot_loss=2.959 (perp=8.901, rec=0.507, cos=0.672), tot_loss_proj:2.289 [t=0.18s]
prediction: ['[CLS] scene beautiful scene [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.924 (perp=8.309, rec=0.539, cos=0.724), tot_loss_proj:1.997 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 300/2000] tot_loss=2.859 (perp=8.309, rec=0.503, cos=0.695), tot_loss_proj:2.002 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.855 (perp=8.309, rec=0.496, cos=0.697), tot_loss_proj:2.014 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.880 (perp=8.309, rec=0.492, cos=0.726), tot_loss_proj:2.017 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 450/2000] tot_loss=2.843 (perp=8.309, rec=0.522, cos=0.659), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.905 (perp=8.309, rec=0.498, cos=0.745), tot_loss_proj:2.011 [t=0.24s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.895 (perp=8.309, rec=0.475, cos=0.758), tot_loss_proj:2.014 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 600/2000] tot_loss=2.931 (perp=8.309, rec=0.462, cos=0.807), tot_loss_proj:2.019 [t=0.21s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.932 (perp=8.309, rec=0.475, cos=0.795), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.949 (perp=8.309, rec=0.462, cos=0.825), tot_loss_proj:2.013 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 750/2000] tot_loss=2.949 (perp=8.309, rec=0.468, cos=0.819), tot_loss_proj:2.016 [t=0.19s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.955 (perp=8.309, rec=0.462, cos=0.831), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.970 (perp=8.309, rec=0.480, cos=0.828), tot_loss_proj:2.017 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[ 900/2000] tot_loss=2.979 (perp=8.309, rec=0.458, cos=0.859), tot_loss_proj:2.017 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.990 (perp=8.309, rec=0.457, cos=0.871), tot_loss_proj:2.020 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1000/2000] tot_loss=3.028 (perp=8.309, rec=0.455, cos=0.911), tot_loss_proj:2.010 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[1050/2000] tot_loss=3.025 (perp=8.309, rec=0.445, cos=0.918), tot_loss_proj:2.018 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1100/2000] tot_loss=3.041 (perp=8.309, rec=0.451, cos=0.928), tot_loss_proj:2.007 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1150/2000] tot_loss=3.061 (perp=8.309, rec=0.449, cos=0.950), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[1200/2000] tot_loss=3.075 (perp=8.309, rec=0.444, cos=0.969), tot_loss_proj:2.020 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1250/2000] tot_loss=3.088 (perp=8.309, rec=0.446, cos=0.980), tot_loss_proj:2.016 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1300/2000] tot_loss=3.089 (perp=8.309, rec=0.434, cos=0.994), tot_loss_proj:2.023 [t=0.19s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[1350/2000] tot_loss=3.094 (perp=8.309, rec=0.433, cos=0.999), tot_loss_proj:2.010 [t=0.23s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1400/2000] tot_loss=3.096 (perp=8.309, rec=0.435, cos=0.999), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1450/2000] tot_loss=3.100 (perp=8.309, rec=0.444, cos=0.994), tot_loss_proj:2.013 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[1500/2000] tot_loss=3.083 (perp=8.309, rec=0.436, cos=0.985), tot_loss_proj:2.012 [t=0.20s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1550/2000] tot_loss=3.067 (perp=8.309, rec=0.436, cos=0.969), tot_loss_proj:2.008 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1600/2000] tot_loss=3.057 (perp=8.309, rec=0.440, cos=0.955), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[1650/2000] tot_loss=3.035 (perp=8.309, rec=0.436, cos=0.937), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1700/2000] tot_loss=3.009 (perp=8.309, rec=0.431, cos=0.916), tot_loss_proj:2.019 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1750/2000] tot_loss=2.995 (perp=8.309, rec=0.434, cos=0.899), tot_loss_proj:2.019 [t=0.29s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[1800/2000] tot_loss=2.972 (perp=8.309, rec=0.424, cos=0.886), tot_loss_proj:2.003 [t=0.29s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1850/2000] tot_loss=2.966 (perp=8.309, rec=0.429, cos=0.875), tot_loss_proj:2.022 [t=0.26s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[1900/2000] tot_loss=2.957 (perp=8.309, rec=0.428, cos=0.867), tot_loss_proj:2.005 [t=0.18s]
prediction: ['[CLS] beautiful scene scene [SEP]']
[1950/2000] tot_loss=2.944 (perp=8.309, rec=0.429, cos=0.853), tot_loss_proj:2.017 [t=0.22s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Attempt swap
[2000/2000] tot_loss=2.934 (perp=8.309, rec=0.427, cos=0.846), tot_loss_proj:2.012 [t=0.29s]
prediction: ['[CLS] beautiful scene scene [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene scene [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 80.000 | r: 100.000
rouge2     | fm: 85.714 | p: 75.000 | r: 100.000
rougeL     | fm: 88.889 | p: 80.000 | r: 100.000
rougeLsum  | fm: 88.889 | p: 80.000 | r: 100.000
r1fm+r2fm = 174.603

[Aggregate metrics]:
rouge1     | fm: 88.419 | p: 88.078 | r: 88.825
rouge2     | fm: 53.826 | p: 53.508 | r: 54.210
rougeL     | fm: 76.763 | p: 76.445 | r: 77.145
rougeLsum  | fm: 76.669 | p: 76.320 | r: 76.984
r1fm+r2fm = 142.244

input #61 time: 0:08:21 | total time: 8:40:09


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.9988113425691294
highest_index [0]
highest [0.9988113425691294]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 0.9513408541679382 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 0.9212074279785156 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 0.920314371585846 for ['[CLS]ished kingu indies shoot vogue band swings hawthorne bastard organ profilecend kay lose inspiring peerage brow ranch meeting quite [SEP]']
[Init] best rec loss: 0.9122064709663391 for ['[CLS] iron while ceiling kent explosion surface adjacent llc chen awkward springs bourbon abe feemarine order sides marco sure lace translator [SEP]']
[Init] best perm rec loss: 0.9113525152206421 for ['[CLS] surface springs kent awkward lace fee ceiling while sure chen explosionmarine abe adjacent llc sides iron bourbon marco order translator [SEP]']
[Init] best perm rec loss: 0.9100059270858765 for ['[CLS] explosion surface adjacent translator sure sides ceiling abe ordermarine springs bourbon chen fee lace iron marco awkward while llc kent [SEP]']
[Init] best perm rec loss: 0.9087058901786804 for ['[CLS] abemarine surface llc explosion springs while chen bourbon iron adjacent awkward marco ceiling translator sides order lace fee kent sure [SEP]']
[Init] best perm rec loss: 0.9080209732055664 for ['[CLS] adjacent translator iron ordermarine explosion marco abe while llc ceiling awkward sure lace fee surface sides chen bourbon springs kent [SEP]']
[Init] best perm rec loss: 0.9075877070426941 for ['[CLS] abe explosion springs awkward sure order ceiling bourbon kentmarine marco iron while translator sides llc fee adjacent surface lace chen [SEP]']
[Init] best perm rec loss: 0.9071982502937317 for ['[CLS] sidesmarine awkward kent springs abe marco while adjacent ceiling iron bourbon lace surface explosion llc chen fee sure order translator [SEP]']
[Init] best perm rec loss: 0.9062849879264832 for ['[CLS] springs while order adjacent abe fee sure explosion llc lace bourbon translator chen awkwardmarine iron ceiling sides kent marco surface [SEP]']
[Init] best perm rec loss: 0.9059228897094727 for ['[CLS] sides bourbon order lacemarine kent while explosion adjacent chen llc abe translator iron springs ceiling fee marco surface awkward sure [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.450 (perp=13.372, rec=0.481, cos=0.295), tot_loss_proj:4.133 [t=0.18s]
prediction: ['[CLS] marlene biker slung rock beautiful comedy ace hour if elegance noble bad evil stick winner power rockloading devil ordnance sure [SEP]']
[ 100/2000] tot_loss=3.205 (perp=12.641, rec=0.412, cos=0.264), tot_loss_proj:4.284 [t=0.23s]
prediction: ['[CLS] temperance biker slung grace fiction movie making prevention if elegance humanitarian best best focus winner police of raped movies prevention nevertheless [SEP]']
[ 150/2000] tot_loss=3.163 (perp=12.811, rec=0.368, cos=0.233), tot_loss_proj:4.381 [t=0.19s]
prediction: ['[CLS] temperance biker be grace islands movies making war if grace appropriate best best press makes police of fifa movies prevention imagine [SEP]']
[ 200/2000] tot_loss=2.997 (perp=12.038, rec=0.333, cos=0.256), tot_loss_proj:4.333 [t=0.20s]
prediction: ['[CLS] temperance or be grace ass movies making war when grace prevention best best press makes of ofnding movies prevention universally [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.673 (perp=10.581, rec=0.322, cos=0.235), tot_loss_proj:3.768 [t=0.24s]
prediction: ['[CLS] temperance coming to grace biggest movies making war when grace prevention best best press makes of ofnding movies prevention universally [SEP]']
[ 300/2000] tot_loss=2.908 (perp=11.795, rec=0.284, cos=0.266), tot_loss_proj:3.902 [t=0.19s]
prediction: ['[CLS] temperance becoming to grace movies movies making war spectators grace prevention best best without makes of of peacekeeping movies prevention universally [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.893 (perp=11.961, rec=0.255, cos=0.246), tot_loss_proj:3.879 [t=0.24s]
prediction: ['[CLS] existed becoming to grace biggest movies making war spectators grace prevention one of without makes best of peacekeeping movies prevention universally [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.628 (perp=10.686, rec=0.252, cos=0.239), tot_loss_proj:3.672 [t=0.25s]
prediction: ['[CLS] ever becoming to grace biggest movies making prevention spectators grace making one of without prevention best of peacekeeping movies prevention mckenna [SEP]']
[ 450/2000] tot_loss=2.583 (perp=10.519, rec=0.242, cos=0.236), tot_loss_proj:3.729 [t=0.19s]
prediction: ['[CLS] ever to to grace biggest movies movies war rather grace making one of without prevention best of peacekeeping movies prevention mckenna [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.609 (perp=10.658, rec=0.235, cos=0.243), tot_loss_proj:3.947 [t=0.20s]
prediction: ['[CLS] ever to to grace movies movies movies war to grace making one of without prevention best simply peacekeeping movies preventionrift [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.566 (perp=10.485, rec=0.232, cos=0.237), tot_loss_proj:3.983 [t=0.20s]
prediction: ['[CLS] ever to for to longest movies movies war to grace making one of without prevention best to peacekeeping movies preventionrift [SEP]']
[ 600/2000] tot_loss=2.577 (perp=10.485, rec=0.220, cos=0.260), tot_loss_proj:3.978 [t=0.23s]
prediction: ['[CLS] ever to for to longest movies movies war to grace making one of without prevention best to peacekeeping movies preventionrift [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.513 (perp=10.164, rec=0.220, cos=0.260), tot_loss_proj:3.967 [t=0.19s]
prediction: ['[CLS] ever to for movies longest movies to war to grace making one of without prevention best tofor movies preventionrift [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.448 (perp=9.918, rec=0.207, cos=0.257), tot_loss_proj:3.925 [t=0.26s]
prediction: ['[CLS] ever to movies for longest movies to war being grace making one of without prevention best tofor movies preventionrift [SEP]']
[ 750/2000] tot_loss=2.446 (perp=9.918, rec=0.204, cos=0.258), tot_loss_proj:3.922 [t=0.23s]
prediction: ['[CLS] ever to movies for longest movies to war being grace making one of without prevention best tofor movies preventionrift [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.345 (perp=9.448, rec=0.200, cos=0.255), tot_loss_proj:3.836 [t=0.18s]
prediction: ['[CLS] ever to movies for longest movies to grace war being making one of without prevention best tofor movies preventionrift [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.238 (perp=8.931, rec=0.204, cos=0.248), tot_loss_proj:3.683 [t=0.23s]
prediction: ['[CLS] ever to movies for longest movies to grace war being making one of without preventionfor to best movies preventionrift [SEP]']
[ 900/2000] tot_loss=2.254 (perp=8.976, rec=0.205, cos=0.253), tot_loss_proj:3.687 [t=0.18s]
prediction: ['[CLS] ever to movies for longest movies to grace war being making one of without blamefor to best movies preventionrift [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.219 (perp=8.857, rec=0.198, cos=0.249), tot_loss_proj:3.712 [t=0.23s]
prediction: ['[CLS] ever to movies longest for movies to grace war being making one of without blamefor to best war preventionrift [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.204 (perp=8.743, rec=0.209, cos=0.247), tot_loss_proj:3.635 [t=0.21s]
prediction: ['[CLS] ever to movies longest for movies to grace war being making one of without blamefor to best warrift prevention [SEP]']
[1050/2000] tot_loss=2.215 (perp=8.808, rec=0.197, cos=0.256), tot_loss_proj:3.675 [t=0.24s]
prediction: ['[CLS] ever to movies longest for movies to grace war being making one of without blamelife to best warrift prevention [SEP]']
Attempt swap
[1100/2000] tot_loss=2.267 (perp=9.086, rec=0.199, cos=0.251), tot_loss_proj:3.592 [t=0.19s]
prediction: ['[CLS] ever to movies things for movies to grace war being making one of without blamelife to best warrift prevention [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.224 (perp=8.898, rec=0.199, cos=0.246), tot_loss_proj:3.587 [t=0.18s]
prediction: ['[CLS] ever to movies things for movies to grace war being one making of without blamelife to best warrift prevention [SEP]']
[1200/2000] tot_loss=2.233 (perp=8.898, rec=0.202, cos=0.251), tot_loss_proj:3.586 [t=0.19s]
prediction: ['[CLS] ever to movies things for movies to grace war being one making of without blamelife to best warrift prevention [SEP]']
Attempt swap
[1250/2000] tot_loss=2.228 (perp=8.898, rec=0.195, cos=0.253), tot_loss_proj:3.586 [t=0.22s]
prediction: ['[CLS] ever to movies things for movies to grace war being one making of without blamelife to best warrift prevention [SEP]']
Attempt swap
[1300/2000] tot_loss=2.224 (perp=8.898, rec=0.189, cos=0.255), tot_loss_proj:3.584 [t=0.18s]
prediction: ['[CLS] ever to movies things for movies to grace war being one making of without blamelife to best warrift prevention [SEP]']
[1350/2000] tot_loss=2.220 (perp=8.898, rec=0.194, cos=0.247), tot_loss_proj:3.586 [t=0.18s]
prediction: ['[CLS] ever to movies things for movies to grace war being one making of without blamelife to best warrift prevention [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.183 (perp=8.699, rec=0.195, cos=0.248), tot_loss_proj:3.612 [t=0.18s]
prediction: ['[CLS] things to movies ever for movies to grace war being one making of without blamelife to best warrift prevention [SEP]']
Attempt swap
[1450/2000] tot_loss=2.182 (perp=8.699, rec=0.194, cos=0.248), tot_loss_proj:3.613 [t=0.18s]
prediction: ['[CLS] things to movies ever for movies to grace war being one making of without blamelife to best warrift prevention [SEP]']
[1500/2000] tot_loss=2.203 (perp=8.802, rec=0.193, cos=0.249), tot_loss_proj:3.627 [t=0.19s]
prediction: ['[CLS] things to movies ever for movies to grace war to one making of without blamelife to best warrift prevention [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.201 (perp=8.799, rec=0.192, cos=0.249), tot_loss_proj:3.678 [t=0.31s]
prediction: ['[CLS] to to movies ever for movies to grace war to making one of without blamelife to best warrift prevention [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.276 (perp=9.185, rec=0.190, cos=0.249), tot_loss_proj:3.708 [t=0.19s]
prediction: ['[CLS] to to movies ever for movies to grace being war making one of without blamelife to best warrift prevention [SEP]']
[1650/2000] tot_loss=2.338 (perp=9.507, rec=0.187, cos=0.249), tot_loss_proj:3.782 [t=0.18s]
prediction: ['[CLS] to to movies ever for movies to grace being war making one of without ratherlife to best warrift prevention [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.316 (perp=9.344, rec=0.199, cos=0.248), tot_loss_proj:3.793 [t=0.18s]
prediction: ['[CLS] to to movies ever for movies to grace being blame making one of without warlife to best warrift prevention [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.274 (perp=9.148, rec=0.197, cos=0.247), tot_loss_proj:3.772 [t=0.20s]
prediction: ['[CLS] to to movies ever for movies to grace making blame to one of without warlife to best warrift prevention [SEP]']
[1800/2000] tot_loss=2.270 (perp=9.148, rec=0.190, cos=0.250), tot_loss_proj:3.771 [t=0.19s]
prediction: ['[CLS] to to movies ever for movies to grace making blame to one of without warlife to best warrift prevention [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=2.199 (perp=8.783, rec=0.194, cos=0.248), tot_loss_proj:3.642 [t=0.20s]
prediction: ['[CLS] to to movies ever for movies to grace blame to making one of without warlife to best warrift prevention [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=2.160 (perp=8.594, rec=0.198, cos=0.243), tot_loss_proj:3.576 [t=0.27s]
prediction: ['[CLS] to to movies war for movies to grace blame to making one of without everlife to best warrift prevention [SEP]']
[1950/2000] tot_loss=2.210 (perp=8.790, rec=0.203, cos=0.249), tot_loss_proj:3.559 [t=0.21s]
prediction: ['[CLS] to to movies war for movies to grace blame than making one of without everlife to best warrift prevention [SEP]']
Attempt swap
[2000/2000] tot_loss=2.199 (perp=8.790, rec=0.194, cos=0.247), tot_loss_proj:3.559 [t=0.19s]
prediction: ['[CLS] to to movies war for movies to grace blame than making one of without everlife to best warrift prevention [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] to to movies ever for movies to grace war to making one of without blamelife to best warrift prevention [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 65.116 | p: 66.667 | r: 63.636
rouge2     | fm: 9.756 | p: 10.000 | r: 9.524
rougeL     | fm: 41.860 | p: 42.857 | r: 40.909
rougeLsum  | fm: 41.860 | p: 42.857 | r: 40.909
r1fm+r2fm = 74.872

[Aggregate metrics]:
rouge1     | fm: 88.038 | p: 87.741 | r: 88.499
rouge2     | fm: 53.293 | p: 52.926 | r: 53.641
rougeL     | fm: 76.153 | p: 75.887 | r: 76.497
rougeLsum  | fm: 75.971 | p: 75.743 | r: 76.294
r1fm+r2fm = 141.331

input #62 time: 0:08:32 | total time: 8:48:41


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9986848444589054
highest_index [0]
highest [0.9986848444589054]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 0.8344054222106934 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 0.7275673747062683 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 0.706977367401123 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best rec loss: 0.7060651183128357 for ['[CLS] alpha light gender independence almost [SEP]']
[Init] best perm rec loss: 0.7045794725418091 for ['[CLS] alpha independence almost gender light [SEP]']
[Init] best perm rec loss: 0.7026822566986084 for ['[CLS] gender independence light almost alpha [SEP]']
[Init] best perm rec loss: 0.7013087272644043 for ['[CLS] gender alpha independence almost light [SEP]']
[Init] best perm rec loss: 0.7006227970123291 for ['[CLS] almost light gender alpha independence [SEP]']
[Init] best perm rec loss: 0.7000793814659119 for ['[CLS] independence almost gender alpha light [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.397 (perp=11.010, rec=0.178, cos=0.017), tot_loss_proj:3.265 [t=0.24s]
prediction: ['[CLS] return ticket looking looking ticket [SEP]']
[ 100/2000] tot_loss=1.910 (perp=9.080, rec=0.088, cos=0.006), tot_loss_proj:2.547 [t=0.29s]
prediction: ['[CLS] return ticket looking for ticket [SEP]']
[ 150/2000] tot_loss=1.907 (perp=9.080, rec=0.086, cos=0.005), tot_loss_proj:2.543 [t=0.18s]
prediction: ['[CLS] return ticket looking for ticket [SEP]']
[ 200/2000] tot_loss=1.899 (perp=9.080, rec=0.078, cos=0.004), tot_loss_proj:2.537 [t=0.18s]
prediction: ['[CLS] return ticket looking for ticket [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.667 (perp=7.787, rec=0.102, cos=0.007), tot_loss_proj:2.450 [t=0.19s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[ 300/2000] tot_loss=1.639 (perp=7.787, rec=0.077, cos=0.005), tot_loss_proj:2.463 [t=0.25s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.636 (perp=7.787, rec=0.074, cos=0.005), tot_loss_proj:2.460 [t=0.19s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.635 (perp=7.787, rec=0.073, cos=0.004), tot_loss_proj:2.457 [t=0.18s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
[ 450/2000] tot_loss=1.637 (perp=7.787, rec=0.075, cos=0.004), tot_loss_proj:2.458 [t=0.18s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.638 (perp=7.787, rec=0.076, cos=0.004), tot_loss_proj:2.448 [t=0.18s]
prediction: ['[CLS] ticket return looking for ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.969 (perp=9.459, rec=0.073, cos=0.004), tot_loss_proj:3.258 [t=0.19s]
prediction: ['[CLS] ticket return looking for for [SEP]']
[ 600/2000] tot_loss=1.969 (perp=9.459, rec=0.072, cos=0.004), tot_loss_proj:3.256 [t=0.18s]
prediction: ['[CLS] ticket return looking for for [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.057 (perp=9.863, rec=0.080, cos=0.004), tot_loss_proj:2.709 [t=0.18s]
prediction: ['[CLS] ticket ticket looking for return [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.684 (perp=7.989, rec=0.081, cos=0.005), tot_loss_proj:1.987 [t=0.18s]
prediction: ['[CLS] looking for ticket ticket return [SEP]']
[ 750/2000] tot_loss=1.659 (perp=7.929, rec=0.069, cos=0.004), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.649 (perp=7.929, rec=0.059, cos=0.004), tot_loss_proj:2.115 [t=0.24s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.659 (perp=7.929, rec=0.069, cos=0.004), tot_loss_proj:2.105 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
[ 900/2000] tot_loss=1.669 (perp=7.929, rec=0.079, cos=0.004), tot_loss_proj:2.102 [t=0.19s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.662 (perp=7.929, rec=0.072, cos=0.004), tot_loss_proj:2.102 [t=0.22s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1000/2000] tot_loss=1.665 (perp=7.929, rec=0.075, cos=0.004), tot_loss_proj:2.106 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
[1050/2000] tot_loss=1.662 (perp=7.929, rec=0.072, cos=0.004), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1100/2000] tot_loss=1.665 (perp=7.929, rec=0.075, cos=0.004), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1150/2000] tot_loss=1.663 (perp=7.929, rec=0.073, cos=0.004), tot_loss_proj:2.102 [t=0.21s]
prediction: ['[CLS] looking for ticket for return [SEP]']
[1200/2000] tot_loss=1.663 (perp=7.929, rec=0.073, cos=0.004), tot_loss_proj:2.109 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1250/2000] tot_loss=1.668 (perp=7.929, rec=0.078, cos=0.004), tot_loss_proj:2.093 [t=0.24s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1300/2000] tot_loss=1.650 (perp=7.929, rec=0.060, cos=0.004), tot_loss_proj:2.106 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
[1350/2000] tot_loss=1.654 (perp=7.929, rec=0.064, cos=0.004), tot_loss_proj:2.097 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1400/2000] tot_loss=1.668 (perp=7.929, rec=0.079, cos=0.004), tot_loss_proj:2.109 [t=0.26s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1450/2000] tot_loss=1.661 (perp=7.929, rec=0.072, cos=0.004), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] looking for ticket for return [SEP]']
[1500/2000] tot_loss=1.655 (perp=7.929, rec=0.065, cos=0.004), tot_loss_proj:2.107 [t=0.20s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1550/2000] tot_loss=1.668 (perp=7.929, rec=0.078, cos=0.004), tot_loss_proj:2.098 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1600/2000] tot_loss=1.662 (perp=7.929, rec=0.073, cos=0.004), tot_loss_proj:2.110 [t=0.25s]
prediction: ['[CLS] looking for ticket for return [SEP]']
[1650/2000] tot_loss=1.655 (perp=7.929, rec=0.066, cos=0.004), tot_loss_proj:2.099 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1700/2000] tot_loss=1.659 (perp=7.929, rec=0.069, cos=0.004), tot_loss_proj:2.106 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1750/2000] tot_loss=1.671 (perp=7.929, rec=0.081, cos=0.004), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
[1800/2000] tot_loss=1.666 (perp=7.929, rec=0.077, cos=0.004), tot_loss_proj:2.111 [t=0.20s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1850/2000] tot_loss=1.662 (perp=7.929, rec=0.072, cos=0.004), tot_loss_proj:2.095 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[1900/2000] tot_loss=1.657 (perp=7.929, rec=0.068, cos=0.004), tot_loss_proj:2.091 [t=0.23s]
prediction: ['[CLS] looking for ticket for return [SEP]']
[1950/2000] tot_loss=1.661 (perp=7.929, rec=0.071, cos=0.004), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Attempt swap
[2000/2000] tot_loss=1.664 (perp=7.929, rec=0.074, cos=0.004), tot_loss_proj:2.104 [t=0.18s]
prediction: ['[CLS] looking for ticket for return [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for ticket for return [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 119.048

[Aggregate metrics]:
rouge1     | fm: 88.026 | p: 87.676 | r: 88.492
rouge2     | fm: 52.986 | p: 52.689 | r: 53.254
rougeL     | fm: 76.215 | p: 75.902 | r: 76.545
rougeLsum  | fm: 75.983 | p: 75.680 | r: 76.342
r1fm+r2fm = 141.013

input #63 time: 0:08:11 | total time: 8:56:53


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.9986462912838777
highest_index [0]
highest [0.9986462912838777]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 0.8982428312301636 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 0.8514059782028198 for ['[CLS] dale fuel picked [SEP]']
[Init] best rec loss: 0.8296869397163391 for ['[CLS] david [CLS] earliest [SEP]']
[Init] best rec loss: 0.7489539980888367 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 0.6848188042640686 for ['[CLS]onale water visions [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.713 (perp=8.065, rec=0.094, cos=0.007), tot_loss_proj:1.708 [t=0.23s]
prediction: ['[CLS] the strange horror [SEP]']
[ 100/2000] tot_loss=1.690 (perp=8.065, rec=0.074, cos=0.003), tot_loss_proj:1.723 [t=0.20s]
prediction: ['[CLS] the strange horror [SEP]']
[ 150/2000] tot_loss=1.677 (perp=8.065, rec=0.061, cos=0.003), tot_loss_proj:1.703 [t=0.27s]
prediction: ['[CLS] the strange horror [SEP]']
[ 200/2000] tot_loss=1.681 (perp=8.065, rec=0.065, cos=0.003), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.687 (perp=8.065, rec=0.072, cos=0.003), tot_loss_proj:1.715 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
[ 300/2000] tot_loss=1.685 (perp=8.065, rec=0.070, cos=0.003), tot_loss_proj:1.705 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.003), tot_loss_proj:1.703 [t=0.30s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.669 (perp=8.065, rec=0.053, cos=0.003), tot_loss_proj:1.711 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.003), tot_loss_proj:1.713 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.003), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.676 (perp=8.065, rec=0.060, cos=0.003), tot_loss_proj:1.713 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.686 (perp=8.065, rec=0.071, cos=0.003), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.685 (perp=8.065, rec=0.069, cos=0.003), tot_loss_proj:1.711 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.676 (perp=8.065, rec=0.060, cos=0.003), tot_loss_proj:1.714 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.003), tot_loss_proj:1.719 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.686 (perp=8.065, rec=0.070, cos=0.003), tot_loss_proj:1.699 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.689 (perp=8.065, rec=0.073, cos=0.003), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.680 (perp=8.065, rec=0.064, cos=0.003), tot_loss_proj:1.713 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.664 (perp=8.065, rec=0.049, cos=0.003), tot_loss_proj:1.708 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.666 (perp=8.065, rec=0.050, cos=0.003), tot_loss_proj:1.701 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.668 (perp=8.065, rec=0.052, cos=0.003), tot_loss_proj:1.708 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.687 (perp=8.065, rec=0.071, cos=0.003), tot_loss_proj:1.715 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.677 (perp=8.065, rec=0.061, cos=0.003), tot_loss_proj:1.718 [t=0.21s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.680 (perp=8.065, rec=0.064, cos=0.003), tot_loss_proj:1.715 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.677 (perp=8.065, rec=0.061, cos=0.003), tot_loss_proj:1.705 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.003), tot_loss_proj:1.703 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.675 (perp=8.065, rec=0.059, cos=0.003), tot_loss_proj:1.698 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.666 (perp=8.065, rec=0.050, cos=0.003), tot_loss_proj:1.706 [t=0.20s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.003), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.003), tot_loss_proj:1.700 [t=0.20s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.660 (perp=8.065, rec=0.045, cos=0.003), tot_loss_proj:1.707 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.672 (perp=8.065, rec=0.056, cos=0.003), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.673 (perp=8.065, rec=0.057, cos=0.003), tot_loss_proj:1.720 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.673 (perp=8.065, rec=0.058, cos=0.003), tot_loss_proj:1.697 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.669 (perp=8.065, rec=0.053, cos=0.003), tot_loss_proj:1.708 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.675 (perp=8.065, rec=0.059, cos=0.003), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.673 (perp=8.065, rec=0.057, cos=0.003), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.677 (perp=8.065, rec=0.061, cos=0.003), tot_loss_proj:1.701 [t=0.25s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.003), tot_loss_proj:1.714 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.003), tot_loss_proj:1.696 [t=0.22s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 88.235 | p: 87.919 | r: 88.689
rouge2     | fm: 53.405 | p: 53.155 | r: 53.687
rougeL     | fm: 76.400 | p: 76.190 | r: 76.700
rougeLsum  | fm: 76.451 | p: 76.217 | r: 76.799
r1fm+r2fm = 141.641

input #64 time: 0:08:13 | total time: 9:05:06


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9988729485591992
highest_index [0]
highest [0.9988729485591992]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 0.9266810417175293 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 0.9048032760620117 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 0.8962661623954773 for ['[CLS] dir northern opens gasam acute diocese ban missile [SEP]']
[Init] best rec loss: 0.8924484848976135 for ['[CLS] pale far expert interval pr che gonna time united [SEP]']
[Init] best rec loss: 0.8899067640304565 for ['[CLS] callman minister excellent scratch pleased unexpected accounted amateurs [SEP]']
[Init] best rec loss: 0.8837448954582214 for ['[CLS] health kuept scenicne contact will savamac [SEP]']
[Init] best rec loss: 0.8822184801101685 for ['[CLS] silicon spentvable retreat latterbioren divert pinch [SEP]']
[Init] best rec loss: 0.8780728578567505 for ['[CLS] mirandahuileigh amanda kim during stage medieval dance [SEP]']
[Init] best rec loss: 0.8727201819419861 for ['[CLS] games facing explorers canals is all sphinxitative prints [SEP]']
[Init] best rec loss: 0.8724582195281982 for ['[CLS] yard beef whoever courtney far investment plant needs rico [SEP]']
[Init] best rec loss: 0.8715435862541199 for ['[CLS]sity notes blessed gave master way track chase en [SEP]']
[Init] best rec loss: 0.8675229549407959 for ['[CLS]ong back acres za just effectiveness martin eva monk [SEP]']
[Init] best rec loss: 0.8440058827400208 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best perm rec loss: 0.843713641166687 for ['[CLS]hoff news someday fun pu overs evenmament general [SEP]']
[Init] best perm rec loss: 0.8432238698005676 for ['[CLS] general overs puhoff funmament news even someday [SEP]']
[Init] best perm rec loss: 0.8431105613708496 for ['[CLS] evenmament newshoff someday overs fun pu general [SEP]']
[Init] best perm rec loss: 0.8394732475280762 for ['[CLS] pu general even somedayhoff overs news funmament [SEP]']
[Init] best perm rec loss: 0.8385602235794067 for ['[CLS] fun puhoff overs news general even somedaymament [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.106 (perp=12.603, rec=0.458, cos=0.127), tot_loss_proj:3.557 [t=0.25s]
prediction: ['[CLS] study grief joyable \\ up joy success peak [SEP]']
[ 100/2000] tot_loss=2.569 (perp=9.873, rec=0.454, cos=0.140), tot_loss_proj:3.665 [t=0.18s]
prediction: ['[CLS] or torment joyousphi ; of into joy [SEP]']
[ 150/2000] tot_loss=2.624 (perp=10.218, rec=0.371, cos=0.210), tot_loss_proj:3.091 [t=0.24s]
prediction: ['[CLS] of joy joyoushi ; of intoous [SEP]']
[ 200/2000] tot_loss=2.539 (perp=10.394, rec=0.293, cos=0.166), tot_loss_proj:3.313 [t=0.27s]
prediction: ['[CLS] ( joy joyoushi ; of into movie [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.141 (perp=8.530, rec=0.282, cos=0.153), tot_loss_proj:2.987 [t=0.21s]
prediction: ['[CLS] ( of joyousht ; of joy movie [SEP]']
[ 300/2000] tot_loss=2.148 (perp=8.578, rec=0.273, cos=0.159), tot_loss_proj:3.184 [t=0.18s]
prediction: ['[CLS] satire of joyousա. of joy film [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.973 (perp=7.681, rec=0.284, cos=0.152), tot_loss_proj:2.504 [t=0.18s]
prediction: ['[CLS], of joy rainforest. of joyous of [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.963 (perp=7.758, rec=0.258, cos=0.153), tot_loss_proj:2.573 [t=0.22s]
prediction: ['[CLS], of joyա film rom joyous. [SEP]']
[ 450/2000] tot_loss=1.954 (perp=7.758, rec=0.241, cos=0.162), tot_loss_proj:2.575 [t=0.23s]
prediction: ['[CLS], of joyա film rom joyous. [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.151 (perp=8.632, rec=0.237, cos=0.187), tot_loss_proj:2.836 [t=0.20s]
prediction: ['[CLS], of yoga joy film rom joyous. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.289 (perp=9.368, rec=0.243, cos=0.172), tot_loss_proj:2.938 [t=0.21s]
prediction: ['[CLS], of joy yoga film rom joyous film [SEP]']
[ 600/2000] tot_loss=2.267 (perp=9.368, rec=0.227, cos=0.166), tot_loss_proj:2.938 [t=0.21s]
prediction: ['[CLS], of joy yoga film rom joyous film [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=2.349 (perp=9.321, rec=0.271, cos=0.214), tot_loss_proj:3.192 [t=0.20s]
prediction: ['[CLS], of joyschen film film rom joyous [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.233 (perp=9.035, rec=0.233, cos=0.193), tot_loss_proj:2.890 [t=0.18s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
[ 750/2000] tot_loss=2.193 (perp=9.035, rec=0.215, cos=0.172), tot_loss_proj:2.893 [t=0.19s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.194 (perp=9.035, rec=0.220, cos=0.166), tot_loss_proj:2.891 [t=0.24s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.166 (perp=9.035, rec=0.204, cos=0.156), tot_loss_proj:2.889 [t=0.18s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
[ 900/2000] tot_loss=2.157 (perp=9.035, rec=0.197, cos=0.152), tot_loss_proj:2.891 [t=0.24s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.160 (perp=9.035, rec=0.201, cos=0.153), tot_loss_proj:2.891 [t=0.29s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.171 (perp=9.035, rec=0.204, cos=0.160), tot_loss_proj:2.898 [t=0.17s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
[1050/2000] tot_loss=2.158 (perp=9.035, rec=0.197, cos=0.154), tot_loss_proj:2.895 [t=0.27s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
Attempt swap
[1100/2000] tot_loss=2.154 (perp=9.035, rec=0.192, cos=0.154), tot_loss_proj:2.898 [t=0.18s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
Attempt swap
[1150/2000] tot_loss=2.156 (perp=9.035, rec=0.189, cos=0.160), tot_loss_proj:2.897 [t=0.18s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
[1200/2000] tot_loss=2.173 (perp=9.035, rec=0.219, cos=0.147), tot_loss_proj:2.896 [t=0.25s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
Attempt swap
[1250/2000] tot_loss=2.164 (perp=9.035, rec=0.197, cos=0.160), tot_loss_proj:2.901 [t=0.18s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
Attempt swap
[1300/2000] tot_loss=2.151 (perp=9.035, rec=0.190, cos=0.154), tot_loss_proj:2.899 [t=0.19s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
[1350/2000] tot_loss=2.150 (perp=9.035, rec=0.189, cos=0.154), tot_loss_proj:2.896 [t=0.18s]
prediction: ['[CLS], ofschen joy film film rom joyous [SEP]']
Attempt swap
[1400/2000] tot_loss=2.272 (perp=9.614, rec=0.195, cos=0.154), tot_loss_proj:3.061 [t=0.27s]
prediction: ['[CLS], ofschen une film film rom joyous [SEP]']
Attempt swap
[1450/2000] tot_loss=2.240 (perp=9.501, rec=0.187, cos=0.153), tot_loss_proj:3.058 [t=0.23s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
[1500/2000] tot_loss=2.244 (perp=9.501, rec=0.194, cos=0.150), tot_loss_proj:3.060 [t=0.19s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
Attempt swap
[1550/2000] tot_loss=2.238 (perp=9.501, rec=0.185, cos=0.152), tot_loss_proj:3.057 [t=0.18s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
Attempt swap
[1600/2000] tot_loss=2.233 (perp=9.501, rec=0.181, cos=0.152), tot_loss_proj:3.059 [t=0.18s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
[1650/2000] tot_loss=2.242 (perp=9.501, rec=0.189, cos=0.153), tot_loss_proj:3.059 [t=0.32s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
Attempt swap
[1700/2000] tot_loss=2.241 (perp=9.501, rec=0.189, cos=0.153), tot_loss_proj:3.062 [t=0.18s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
Attempt swap
[1750/2000] tot_loss=2.240 (perp=9.501, rec=0.189, cos=0.151), tot_loss_proj:3.060 [t=0.28s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
[1800/2000] tot_loss=2.233 (perp=9.501, rec=0.183, cos=0.150), tot_loss_proj:3.058 [t=0.18s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
Attempt swap
[1850/2000] tot_loss=2.235 (perp=9.501, rec=0.182, cos=0.152), tot_loss_proj:3.060 [t=0.22s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
Attempt swap
[1900/2000] tot_loss=2.238 (perp=9.501, rec=0.186, cos=0.151), tot_loss_proj:3.063 [t=0.21s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
[1950/2000] tot_loss=2.237 (perp=9.501, rec=0.185, cos=0.152), tot_loss_proj:3.058 [t=0.25s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
Attempt swap
[2000/2000] tot_loss=2.234 (perp=9.501, rec=0.181, cos=0.152), tot_loss_proj:3.060 [t=0.22s]
prediction: ['[CLS], ofschen contingent film film rom joyous [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS], ofschen contingent film film rom joyous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 53.333 | p: 50.000 | r: 57.143
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 40.000 | p: 37.500 | r: 42.857
rougeLsum  | fm: 40.000 | p: 37.500 | r: 42.857
r1fm+r2fm = 53.333

[Aggregate metrics]:
rouge1     | fm: 87.601 | p: 87.247 | r: 88.080
rouge2     | fm: 52.537 | p: 52.300 | r: 52.935
rougeL     | fm: 75.876 | p: 75.574 | r: 76.267
rougeLsum  | fm: 75.988 | p: 75.693 | r: 76.428
r1fm+r2fm = 140.138

input #65 time: 0:08:16 | total time: 9:13:23


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9989004599966436
highest_index [0]
highest [0.9989004599966436]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 0.8706433773040771 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 0.870367169380188 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 0.8667373657226562 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 0.8499854207038879 for ['[CLS] commerce wikipedia experiment if [SEP]']
[Init] best rec loss: 0.8413671851158142 for ['[CLS] complied man ready panic [SEP]']
[Init] best rec loss: 0.8402509689331055 for ['[CLS] youtubeology r cain [SEP]']
[Init] best rec loss: 0.8400813341140747 for ['[CLS] september st minimum invitation [SEP]']
[Init] best rec loss: 0.8040071725845337 for ['[CLS] helmet stared true deposit [SEP]']
[Init] best rec loss: 0.8034965991973877 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best rec loss: 0.7985994815826416 for ['[CLS] programs will liner brigade [SEP]']
[Init] best perm rec loss: 0.7941393852233887 for ['[CLS] programs will brigade liner [SEP]']
[Init] best perm rec loss: 0.7912769317626953 for ['[CLS] brigade programs liner will [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.304 (perp=12.989, rec=0.433, cos=0.273), tot_loss_proj:3.573 [t=0.22s]
prediction: ['[CLS] tolkiengenesis fan fan [SEP]']
[ 100/2000] tot_loss=2.825 (perp=11.338, rec=0.340, cos=0.218), tot_loss_proj:2.861 [t=0.18s]
prediction: ['[CLS] tolkien fans fan fan [SEP]']
[ 150/2000] tot_loss=2.717 (perp=10.796, rec=0.313, cos=0.245), tot_loss_proj:2.953 [t=0.20s]
prediction: ['[CLS] tolkien tolkien fan fan [SEP]']
[ 200/2000] tot_loss=2.726 (perp=11.079, rec=0.275, cos=0.235), tot_loss_proj:3.044 [t=0.22s]
prediction: ['[CLS] tolkien trilogy fan fan [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.662 (perp=10.910, rec=0.274, cos=0.205), tot_loss_proj:3.273 [t=0.21s]
prediction: ['[CLS] tolkien fan fan shiva [SEP]']
[ 300/2000] tot_loss=2.653 (perp=10.944, rec=0.258, cos=0.207), tot_loss_proj:2.668 [t=0.18s]
prediction: ['[CLS] tolkien fan fan longtime [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.149 (perp=8.534, rec=0.252, cos=0.190), tot_loss_proj:1.973 [t=0.24s]
prediction: ['[CLS] longtime tolkien fan fan [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.288 (perp=9.181, rec=0.239, cos=0.213), tot_loss_proj:2.131 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 450/2000] tot_loss=2.421 (perp=9.181, rec=0.268, cos=0.317), tot_loss_proj:2.141 [t=0.18s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.257 (perp=9.181, rec=0.213, cos=0.208), tot_loss_proj:2.140 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.265 (perp=9.181, rec=0.253, cos=0.176), tot_loss_proj:2.131 [t=0.23s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 600/2000] tot_loss=2.245 (perp=9.181, rec=0.206, cos=0.203), tot_loss_proj:2.124 [t=0.18s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.260 (perp=9.181, rec=0.208, cos=0.216), tot_loss_proj:2.137 [t=0.18s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.260 (perp=9.181, rec=0.206, cos=0.218), tot_loss_proj:2.139 [t=0.18s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 750/2000] tot_loss=2.257 (perp=9.181, rec=0.196, cos=0.224), tot_loss_proj:2.147 [t=0.19s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.254 (perp=9.181, rec=0.189, cos=0.228), tot_loss_proj:2.139 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.246 (perp=9.181, rec=0.195, cos=0.215), tot_loss_proj:2.129 [t=0.24s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[ 900/2000] tot_loss=2.248 (perp=9.181, rec=0.194, cos=0.218), tot_loss_proj:2.132 [t=0.19s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.250 (perp=9.181, rec=0.205, cos=0.209), tot_loss_proj:2.134 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=2.253 (perp=9.181, rec=0.199, cos=0.218), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1050/2000] tot_loss=2.261 (perp=9.181, rec=0.206, cos=0.219), tot_loss_proj:2.142 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=2.259 (perp=9.181, rec=0.205, cos=0.218), tot_loss_proj:2.144 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=2.244 (perp=9.181, rec=0.193, cos=0.215), tot_loss_proj:2.146 [t=0.18s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1200/2000] tot_loss=2.244 (perp=9.181, rec=0.186, cos=0.222), tot_loss_proj:2.133 [t=0.18s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=2.252 (perp=9.181, rec=0.200, cos=0.215), tot_loss_proj:2.136 [t=0.26s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=2.242 (perp=9.181, rec=0.186, cos=0.220), tot_loss_proj:2.132 [t=0.18s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1350/2000] tot_loss=2.244 (perp=9.181, rec=0.193, cos=0.215), tot_loss_proj:2.139 [t=0.19s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=2.250 (perp=9.181, rec=0.194, cos=0.220), tot_loss_proj:2.142 [t=0.22s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=2.254 (perp=9.181, rec=0.199, cos=0.219), tot_loss_proj:2.136 [t=0.19s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1500/2000] tot_loss=2.258 (perp=9.181, rec=0.202, cos=0.219), tot_loss_proj:2.137 [t=0.18s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=2.246 (perp=9.181, rec=0.192, cos=0.218), tot_loss_proj:2.138 [t=0.23s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=2.255 (perp=9.181, rec=0.200, cos=0.218), tot_loss_proj:2.141 [t=0.19s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1650/2000] tot_loss=2.255 (perp=9.181, rec=0.205, cos=0.213), tot_loss_proj:2.142 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=2.250 (perp=9.181, rec=0.196, cos=0.218), tot_loss_proj:2.138 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=2.244 (perp=9.181, rec=0.192, cos=0.216), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1800/2000] tot_loss=2.243 (perp=9.181, rec=0.190, cos=0.217), tot_loss_proj:2.133 [t=0.27s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=2.256 (perp=9.181, rec=0.205, cos=0.215), tot_loss_proj:2.144 [t=0.19s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=2.236 (perp=9.181, rec=0.181, cos=0.218), tot_loss_proj:2.133 [t=0.22s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
[1950/2000] tot_loss=2.237 (perp=9.181, rec=0.186, cos=0.214), tot_loss_proj:2.145 [t=0.24s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=2.244 (perp=9.181, rec=0.193, cos=0.215), tot_loss_proj:2.135 [t=0.25s]
prediction: ['[CLS] longtime tolkien tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] longtime tolkien tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 83.333 | r: 83.333
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 83.333 | p: 83.333 | r: 83.333
rougeLsum  | fm: 83.333 | p: 83.333 | r: 83.333
r1fm+r2fm = 143.333

[Aggregate metrics]:
rouge1     | fm: 87.616 | p: 87.255 | r: 88.059
rouge2     | fm: 52.662 | p: 52.359 | r: 52.992
rougeL     | fm: 75.948 | p: 75.684 | r: 76.290
rougeLsum  | fm: 76.090 | p: 75.824 | r: 76.437
r1fm+r2fm = 140.278

input #66 time: 0:08:23 | total time: 9:21:47


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.9986277484461428
highest_index [0]
highest [0.9986277484461428]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 0.9624300003051758 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 0.9616133570671082 for ['[CLS]tched forward bunk kinds virginiahiparians war ann scenery [SEP]']
[Init] best rec loss: 0.9541294574737549 for ['[CLS] ^ banksgger biology mont neck administration action pool neo [SEP]']
[Init] best rec loss: 0.952870786190033 for ['[CLS] morton socks backwards blur stiff urban freddy6 you entirely [SEP]']
[Init] best rec loss: 0.9399722814559937 for ['[CLS] midnight fact why done headign promotion else cornelius charm [SEP]']
[Init] best perm rec loss: 0.937934935092926 for ['[CLS] done why promotion charm corneliusign else fact midnight head [SEP]']
[Init] best perm rec loss: 0.9378243684768677 for ['[CLS] why cornelius elseign promotion midnight charm done head fact [SEP]']
[Init] best perm rec loss: 0.9370157122612 for ['[CLS] elseign head done why cornelius fact midnight promotion charm [SEP]']
[Init] best perm rec loss: 0.9357636570930481 for ['[CLS] head else fact charm whyign promotion done midnight cornelius [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.050 (perp=14.209, rec=0.534, cos=0.674), tot_loss_proj:4.760 [t=0.29s]
prediction: ['[CLS] once jubilee environment propertiesgor "ulsion gust kind military [SEP]']
[ 100/2000] tot_loss=3.316 (perp=14.323, rec=0.353, cos=0.098), tot_loss_proj:4.217 [t=0.28s]
prediction: ['[CLS]ringwarwind brand awakement kind gogh powerful kind [SEP]']
[ 150/2000] tot_loss=3.167 (perp=13.983, rec=0.272, cos=0.099), tot_loss_proj:4.767 [t=0.20s]
prediction: ['[CLS] increasingwarwindwar haleyment kindentalwar kind [SEP]']
[ 200/2000] tot_loss=3.261 (perp=14.347, rec=0.259, cos=0.133), tot_loss_proj:4.860 [t=0.22s]
prediction: ['[CLS]ingwarwindwarmun non kindentalwar kind [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.928 (perp=12.690, rec=0.252, cos=0.138), tot_loss_proj:4.355 [t=0.18s]
prediction: ['[CLS]ingwar heartwar barely nonwarentalental kind [SEP]']
[ 300/2000] tot_loss=2.866 (perp=12.452, rec=0.246, cos=0.129), tot_loss_proj:4.106 [t=0.24s]
prediction: ['[CLS]mingneas heartwar barely nonwarentalental kind [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.397 (perp=10.106, rec=0.266, cos=0.109), tot_loss_proj:2.907 [t=0.19s]
prediction: ['[CLS] everyonemed heartwarming nonwarentalental kind [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.348 (perp=9.969, rec=0.222, cos=0.132), tot_loss_proj:2.955 [t=0.17s]
prediction: ['[CLS] everyone heartwarming nonwardentalental kind [SEP]']
[ 450/2000] tot_loss=2.327 (perp=9.900, rec=0.216, cos=0.131), tot_loss_proj:2.977 [t=0.25s]
prediction: ['[CLS] unique heartwarming nonwardentalental kind [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.309 (perp=9.638, rec=0.223, cos=0.159), tot_loss_proj:2.443 [t=0.22s]
prediction: ['[CLS] unique heartwarming nonwarentalmingental kind [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.267 (perp=9.638, rec=0.203, cos=0.137), tot_loss_proj:2.438 [t=0.24s]
prediction: ['[CLS] unique heartwarming nonwarentalmingental kind [SEP]']
[ 600/2000] tot_loss=2.278 (perp=9.638, rec=0.204, cos=0.147), tot_loss_proj:2.436 [t=0.18s]
prediction: ['[CLS] unique heartwarming nonwarentalmingental kind [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.651 (perp=11.573, rec=0.191, cos=0.146), tot_loss_proj:2.941 [t=0.18s]
prediction: ['[CLS] unique heart heartming nonwarentalmingental kind [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.425 (perp=10.423, rec=0.197, cos=0.144), tot_loss_proj:2.587 [t=0.18s]
prediction: ['[CLS] unique heart heartwarming nonentalmingental kind [SEP]']
[ 750/2000] tot_loss=2.409 (perp=10.423, rec=0.178, cos=0.146), tot_loss_proj:2.589 [t=0.18s]
prediction: ['[CLS] unique heart heartwarming nonentalmingental kind [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.320 (perp=9.877, rec=0.195, cos=0.150), tot_loss_proj:2.433 [t=0.18s]
prediction: ['[CLS] unique heart heartwarmingental nonmingental kind [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.091 (perp=8.716, rec=0.207, cos=0.140), tot_loss_proj:2.265 [t=0.19s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
[ 900/2000] tot_loss=2.077 (perp=8.716, rec=0.185, cos=0.149), tot_loss_proj:2.262 [t=0.18s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.084 (perp=8.716, rec=0.190, cos=0.150), tot_loss_proj:2.256 [t=0.24s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1000/2000] tot_loss=2.103 (perp=8.716, rec=0.197, cos=0.163), tot_loss_proj:2.259 [t=0.18s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
[1050/2000] tot_loss=2.084 (perp=8.716, rec=0.192, cos=0.149), tot_loss_proj:2.258 [t=0.17s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1100/2000] tot_loss=2.094 (perp=8.716, rec=0.188, cos=0.163), tot_loss_proj:2.258 [t=0.25s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1150/2000] tot_loss=2.090 (perp=8.716, rec=0.185, cos=0.161), tot_loss_proj:2.255 [t=0.23s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
[1200/2000] tot_loss=2.086 (perp=8.716, rec=0.182, cos=0.161), tot_loss_proj:2.256 [t=0.18s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1250/2000] tot_loss=2.083 (perp=8.716, rec=0.182, cos=0.158), tot_loss_proj:2.257 [t=0.22s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1300/2000] tot_loss=2.090 (perp=8.716, rec=0.187, cos=0.159), tot_loss_proj:2.257 [t=0.19s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
[1350/2000] tot_loss=2.086 (perp=8.716, rec=0.187, cos=0.156), tot_loss_proj:2.261 [t=0.18s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1400/2000] tot_loss=2.089 (perp=8.716, rec=0.188, cos=0.159), tot_loss_proj:2.253 [t=0.19s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1450/2000] tot_loss=2.089 (perp=8.716, rec=0.186, cos=0.160), tot_loss_proj:2.255 [t=0.21s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
[1500/2000] tot_loss=2.087 (perp=8.716, rec=0.182, cos=0.162), tot_loss_proj:2.262 [t=0.18s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1550/2000] tot_loss=2.082 (perp=8.716, rec=0.181, cos=0.157), tot_loss_proj:2.257 [t=0.18s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1600/2000] tot_loss=2.079 (perp=8.716, rec=0.178, cos=0.158), tot_loss_proj:2.250 [t=0.19s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
[1650/2000] tot_loss=2.081 (perp=8.716, rec=0.178, cos=0.160), tot_loss_proj:2.256 [t=0.28s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1700/2000] tot_loss=2.072 (perp=8.716, rec=0.169, cos=0.159), tot_loss_proj:2.261 [t=0.23s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1750/2000] tot_loss=2.080 (perp=8.716, rec=0.175, cos=0.162), tot_loss_proj:2.254 [t=0.22s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
[1800/2000] tot_loss=2.084 (perp=8.716, rec=0.179, cos=0.162), tot_loss_proj:2.245 [t=0.18s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1850/2000] tot_loss=2.084 (perp=8.716, rec=0.179, cos=0.162), tot_loss_proj:2.251 [t=0.18s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[1900/2000] tot_loss=2.088 (perp=8.716, rec=0.185, cos=0.160), tot_loss_proj:2.247 [t=0.19s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
[1950/2000] tot_loss=2.078 (perp=8.716, rec=0.173, cos=0.162), tot_loss_proj:2.250 [t=0.30s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Attempt swap
[2000/2000] tot_loss=2.078 (perp=8.716, rec=0.173, cos=0.162), tot_loss_proj:2.260 [t=0.28s]
prediction: ['[CLS] unique kind heartwarmingental nonmingental heart [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] unique kind heartwarmingental nonmingental heart [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 42.857 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 50.000 | p: 42.857 | r: 60.000
rougeLsum  | fm: 50.000 | p: 42.857 | r: 60.000
r1fm+r2fm = 50.000

[Aggregate metrics]:
rouge1     | fm: 86.949 | p: 86.549 | r: 87.597
rouge2     | fm: 51.829 | p: 51.574 | r: 52.185
rougeL     | fm: 75.444 | p: 75.030 | r: 75.947
rougeLsum  | fm: 75.573 | p: 75.176 | r: 76.110
r1fm+r2fm = 138.778

input #67 time: 0:08:16 | total time: 9:30:03


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9986353334551528
highest_index [0]
highest [0.9986353334551528]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 0.9355477690696716 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 0.8827418088912964 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 0.8574910759925842 for ['[CLS] instant legs discoveredshboot mass pond arabianvati lines abd star 7 [SEP]']
[Init] best rec loss: 0.8513713479042053 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 0.7862101793289185 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 0.7820630669593811 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 0.7763020396232605 for ['[CLS] medaliferous beth comfort form councils flooryn possibly riding. died view [SEP]']
[Init] best perm rec loss: 0.7745766043663025 for ['[CLS]yn possibly councils form beth.iferous riding view floor medal comfort died [SEP]']
[Init] best perm rec loss: 0.7693751454353333 for ['[CLS] floor. beth form comfortiferous riding possibly medal view diedyn councils [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.568 (perp=11.669, rec=0.222, cos=0.012), tot_loss_proj:2.988 [t=0.20s]
prediction: ['[CLS] destroyed. implications mostsible absurd ridiculous, ; vicious 3rd botanical absurd [SEP]']
[ 100/2000] tot_loss=2.521 (perp=11.783, rec=0.157, cos=0.007), tot_loss_proj:2.998 [t=0.21s]
prediction: ['[CLS] confusingedhear,sible absurd vicious, ; vicious 3rd duval absurd [SEP]']
[ 150/2000] tot_loss=2.238 (perp=10.542, rec=0.125, cos=0.004), tot_loss_proj:2.710 [t=0.18s]
prediction: ['[CLS] viciousedomp,sible absurd vicious, un viciousue & absurd [SEP]']
[ 200/2000] tot_loss=2.333 (perp=11.041, rec=0.120, cos=0.005), tot_loss_proj:2.756 [t=0.23s]
prediction: ['[CLS] viciousuthomp,sible unhen and un vicious arising & absurd [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.185 (perp=10.345, rec=0.112, cos=0.004), tot_loss_proj:2.690 [t=0.19s]
prediction: ['[CLS] viciousuthomp,sible un vicious and un vicious arising & absurd [SEP]']
[ 300/2000] tot_loss=2.318 (perp=11.054, rec=0.104, cos=0.004), tot_loss_proj:2.783 [t=0.18s]
prediction: ['[CLS] viciousuthhen,sible un vicious and unhen arisingomp absurd [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.217 (perp=10.460, rec=0.121, cos=0.004), tot_loss_proj:2.544 [t=0.18s]
prediction: ['[CLS] viciousuthhensible, un vicious and unenhenity absurd [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.975 (perp=9.283, rec=0.113, cos=0.005), tot_loss_proj:2.237 [t=0.19s]
prediction: ['[CLS] unuthhensible, un vicious and hystericalenhenre absurd [SEP]']
[ 450/2000] tot_loss=2.107 (perp=10.002, rec=0.103, cos=0.004), tot_loss_proj:2.417 [t=0.27s]
prediction: ['[CLS] unuthhensible, un vicious and hystericalhenhenre absurd [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.005 (perp=9.461, rec=0.109, cos=0.003), tot_loss_proj:2.232 [t=0.20s]
prediction: ['[CLS] unuthhensible, unhen vicious and hystericalcore absurd [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.665 (perp=7.848, rec=0.091, cos=0.004), tot_loss_proj:1.914 [t=0.21s]
prediction: ['[CLS] unrehensible, unhen vicious and hystericalcouth absurd [SEP]']
[ 600/2000] tot_loss=1.669 (perp=7.848, rec=0.096, cos=0.003), tot_loss_proj:1.912 [t=0.18s]
prediction: ['[CLS] unrehensible, unhen vicious and hystericalcouth absurd [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.583 (perp=7.418, rec=0.096, cos=0.003), tot_loss_proj:1.986 [t=0.23s]
prediction: ['[CLS] hystericalrehensible, unhen vicious and uncouth absurd [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.362 (perp=6.292, rec=0.101, cos=0.003), tot_loss_proj:1.685 [t=0.19s]
prediction: ['[CLS] hysterical unhenrehensible, vicious and uncouth absurd [SEP]']
[ 750/2000] tot_loss=1.732 (perp=8.222, rec=0.084, cos=0.004), tot_loss_proj:2.082 [t=0.23s]
prediction: ['[CLS] hysterical unhencohensible, vicious and inccouth absurd [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.750 (perp=8.222, rec=0.102, cos=0.004), tot_loss_proj:2.070 [t=0.26s]
prediction: ['[CLS] hysterical unhencohensible, vicious and inccouth absurd [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.848 (perp=8.747, rec=0.095, cos=0.004), tot_loss_proj:2.122 [t=0.19s]
prediction: ['[CLS] hysterical uncocohensible, vicious and inccouth absurd [SEP]']
[ 900/2000] tot_loss=1.954 (perp=9.351, rec=0.080, cos=0.004), tot_loss_proj:2.213 [t=0.21s]
prediction: ['[CLS] hysterical uncocohensible, vicious and incomputh absurd [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.578 (perp=7.446, rec=0.085, cos=0.004), tot_loss_proj:1.782 [t=0.22s]
prediction: ['[CLS] hysterical uncouthhensible, vicious and incompco absurd [SEP]']
Attempt swap
[1000/2000] tot_loss=1.575 (perp=7.446, rec=0.083, cos=0.004), tot_loss_proj:1.794 [t=0.19s]
prediction: ['[CLS] hysterical uncouthhensible, vicious and incompco absurd [SEP]']
[1050/2000] tot_loss=1.578 (perp=7.446, rec=0.086, cos=0.003), tot_loss_proj:1.790 [t=0.21s]
prediction: ['[CLS] hysterical uncouthhensible, vicious and incompco absurd [SEP]']
Attempt swap
[1100/2000] tot_loss=1.581 (perp=7.446, rec=0.088, cos=0.003), tot_loss_proj:1.791 [t=0.24s]
prediction: ['[CLS] hysterical uncouthhensible, vicious and incompco absurd [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.479 (perp=6.795, rec=0.116, cos=0.005), tot_loss_proj:1.659 [t=0.20s]
prediction: ['[CLS] hysterical uncouth and incompcohensible, vicious absurd [SEP]']
[1200/2000] tot_loss=1.448 (perp=6.795, rec=0.085, cos=0.004), tot_loss_proj:1.661 [t=0.20s]
prediction: ['[CLS] hysterical uncouth and incompcohensible, vicious absurd [SEP]']
Attempt swap
[1250/2000] tot_loss=1.452 (perp=6.795, rec=0.089, cos=0.003), tot_loss_proj:1.655 [t=0.23s]
prediction: ['[CLS] hysterical uncouth and incompcohensible, vicious absurd [SEP]']
Attempt swap
[1300/2000] tot_loss=1.453 (perp=6.795, rec=0.091, cos=0.003), tot_loss_proj:1.659 [t=0.19s]
prediction: ['[CLS] hysterical uncouth and incompcohensible, vicious absurd [SEP]']
[1350/2000] tot_loss=1.447 (perp=6.795, rec=0.085, cos=0.003), tot_loss_proj:1.659 [t=0.21s]
prediction: ['[CLS] hysterical uncouth and incompcohensible, vicious absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=1.439 (perp=6.795, rec=0.077, cos=0.003), tot_loss_proj:1.650 [t=0.19s]
prediction: ['[CLS] hysterical uncouth and incompcohensible, vicious absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=1.441 (perp=6.795, rec=0.079, cos=0.003), tot_loss_proj:1.653 [t=0.22s]
prediction: ['[CLS] hysterical uncouth and incompcohensible, vicious absurd [SEP]']
[1500/2000] tot_loss=1.446 (perp=6.795, rec=0.084, cos=0.003), tot_loss_proj:1.655 [t=0.18s]
prediction: ['[CLS] hysterical uncouth and incompcohensible, vicious absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=1.446 (perp=6.795, rec=0.083, cos=0.003), tot_loss_proj:1.653 [t=0.20s]
prediction: ['[CLS] hysterical uncouth and incompcohensible, vicious absurd [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.421 (perp=6.663, rec=0.085, cos=0.003), tot_loss_proj:1.621 [t=0.23s]
prediction: ['[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]']
[1650/2000] tot_loss=1.413 (perp=6.663, rec=0.077, cos=0.003), tot_loss_proj:1.619 [t=0.18s]
prediction: ['[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.426 (perp=6.663, rec=0.090, cos=0.003), tot_loss_proj:1.623 [t=0.24s]
prediction: ['[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=1.412 (perp=6.663, rec=0.076, cos=0.003), tot_loss_proj:1.622 [t=0.19s]
prediction: ['[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]']
[1800/2000] tot_loss=1.414 (perp=6.663, rec=0.079, cos=0.003), tot_loss_proj:1.613 [t=0.20s]
prediction: ['[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=1.402 (perp=6.663, rec=0.066, cos=0.003), tot_loss_proj:1.616 [t=0.23s]
prediction: ['[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.412 (perp=6.663, rec=0.076, cos=0.003), tot_loss_proj:1.618 [t=0.24s]
prediction: ['[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]']
[1950/2000] tot_loss=1.418 (perp=6.663, rec=0.082, cos=0.003), tot_loss_proj:1.620 [t=0.23s]
prediction: ['[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.415 (perp=6.663, rec=0.079, cos=0.003), tot_loss_proj:1.622 [t=0.18s]
prediction: ['[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] uncouth hysterical and incompcohensible, vicious absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 30.769 | p: 28.571 | r: 33.333
rougeL     | fm: 66.667 | p: 62.500 | r: 71.429
rougeLsum  | fm: 66.667 | p: 62.500 | r: 71.429
r1fm+r2fm = 110.769

[Aggregate metrics]:
rouge1     | fm: 86.922 | p: 86.379 | r: 87.648
rouge2     | fm: 51.540 | p: 51.210 | r: 51.884
rougeL     | fm: 75.352 | p: 74.896 | r: 75.955
rougeLsum  | fm: 75.581 | p: 75.151 | r: 76.200
r1fm+r2fm = 138.462

input #68 time: 0:08:24 | total time: 9:38:28


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.998706969538318
highest_index [0]
highest [0.998706969538318]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.0008913278579712 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 0.9981954097747803 for ['[CLS] kim andhra horn doesn n reflected himloaded approximately across stealth hear officetase ranks cross [SEP]']
[Init] best rec loss: 0.9908129572868347 for ['[CLS] advantageharat key bohemian conscious himself aires secondary six peabodynius influence news vanuredhs [SEP]']
[Init] best rec loss: 0.9859799742698669 for ['[CLS] pretty campus department slow behind alias laborphobia really abilityrama sl offices markers schedule maximum [SEP]']
[Init] best rec loss: 0.9767513871192932 for ['[CLS] silva minutes wight intermittentelt stevenson trained vice occupied coastrift study low sony their causing [SEP]']
[Init] best rec loss: 0.9753296375274658 for ['[CLS] junior christ mel fed sahara crambidae alexia pumped designated vuelta light vo classical institutional duty audience [SEP]']
[Init] best rec loss: 0.9689317345619202 for ['[CLS]ulouslyzation mouth abdso disaster hay down curling at forum fallon jupiter fortune whom henry [SEP]']
[Init] best rec loss: 0.9655280113220215 for ['[CLS] n mori medal askedoff supreme match shelleyhy directions ron cruises generation subject holiday aid [SEP]']
[Init] best rec loss: 0.9625637531280518 for ['[CLS] closelein am ( deadrga liz range bragg depended states passes stock past messll [SEP]']
[Init] best perm rec loss: 0.9593920707702637 for ['[CLS] stock depended bragg am states messll past close rangerga ( liz passes deadlein [SEP]']
[Init] best perm rec loss: 0.957212507724762 for ['[CLS] am bragg rangerga dead ( dependedll close past passes liz stock messlein states [SEP]']
[Init] best perm rec loss: 0.9553589224815369 for ['[CLS]lein bragg amrga depended close messll range stock past passes liz dead ( states [SEP]']
[Init] best perm rec loss: 0.9539766311645508 for ['[CLS] dead stock range ( bragg states mess depended liz closelein pastrgall am passes [SEP]']
[Init] best perm rec loss: 0.9539352059364319 for ['[CLS] passesrga am stock depended past mess braggll rangelein states close dead liz ( [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.695 (perp=10.537, rec=0.598, cos=0.990), tot_loss_proj:4.010 [t=0.18s]
prediction: ['[CLS] nano hacker losing retrieved easy? ; wise ; losingy, series. album stronger [SEP]']
[ 100/2000] tot_loss=3.783 (perp=11.166, rec=0.646, cos=0.904), tot_loss_proj:4.160 [t=0.22s]
prediction: ['[CLS] subtle mayoral losing u2 honest? be nominations ; ;y, relationship series since successful [SEP]']
[ 150/2000] tot_loss=3.082 (perp=9.234, rec=0.477, cos=0.759), tot_loss_proj:2.922 [t=0.19s]
prediction: ['[CLS] smart battle. eliot smart -hausen lemon ; ;y, -.. successful [SEP]']
[ 200/2000] tot_loss=2.981 (perp=11.630, rec=0.411, cos=0.244), tot_loss_proj:3.651 [t=0.18s]
prediction: ['[CLS] smart winner losing fellow smart malagaenberg tolerate. - work, -., successful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.518 (perp=9.558, rec=0.376, cos=0.230), tot_loss_proj:3.872 [t=0.18s]
prediction: ['[CLS] work winner losing fellow smart -enberg tolerate, - smart, -., defender [SEP]']
[ 300/2000] tot_loss=2.458 (perp=9.404, rec=0.349, cos=0.228), tot_loss_proj:2.715 [t=0.18s]
prediction: ['[CLS] funny winner, raises smart - namely tolerated, - smart, - and, defender [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.152 (perp=8.013, rec=0.320, cos=0.230), tot_loss_proj:3.226 [t=0.22s]
prediction: ['[CLS] subtle winner, raises and - hello tolerated, - smart, - smart, defender [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.102 (perp=7.772, rec=0.314, cos=0.234), tot_loss_proj:3.171 [t=0.23s]
prediction: ['[CLS] subtle winner, victorious and, hello tolerated, - smart, - smart,hunter [SEP]']
[ 450/2000] tot_loss=2.151 (perp=7.984, rec=0.312, cos=0.241), tot_loss_proj:2.886 [t=0.25s]
prediction: ['[CLS] subtle winner - victorious,, broadway standard, - smart, - smart, ª [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.106 (perp=7.923, rec=0.280, cos=0.241), tot_loss_proj:3.382 [t=0.21s]
prediction: ['[CLS] subtle winner - ;, broadway, tolerated, - smart, - smart, ª [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.823 (perp=6.526, rec=0.282, cos=0.236), tot_loss_proj:2.775 [t=0.18s]
prediction: ['[CLS] subtle winner ; -, broadway, majority, - smart, - smart, librarian [SEP]']
[ 600/2000] tot_loss=2.190 (perp=8.324, rec=0.273, cos=0.252), tot_loss_proj:3.093 [t=0.19s]
prediction: ['[CLS] subtle winner ; -, my - majority, - smart,and smart, librarian [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.037 (perp=7.099, rec=0.414, cos=0.204), tot_loss_proj:2.810 [t=0.25s]
prediction: ['[CLS] subtle winner ; -, ª - majority, - smart -, smart, librarian [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.081 (perp=7.626, rec=0.349, cos=0.207), tot_loss_proj:2.627 [t=0.21s]
prediction: ['[CLS] subtle winner winner - - ª, majority, - smart -, real, librarian [SEP]']
[ 750/2000] tot_loss=2.055 (perp=7.534, rec=0.311, cos=0.237), tot_loss_proj:2.612 [t=0.19s]
prediction: ['[CLS] subtle winner winner - - yeah, majority, - smart -, real, librarian [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.837 (perp=6.468, rec=0.301, cos=0.242), tot_loss_proj:2.096 [t=0.19s]
prediction: ['[CLS] subtle winner winner - - hello, primary, - - smart, real, librarian [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.782 (perp=6.212, rec=0.305, cos=0.235), tot_loss_proj:2.192 [t=0.28s]
prediction: ['[CLS] subtle winner - - - hello, primary, winner - smart, real, librarian [SEP]']
[ 900/2000] tot_loss=1.763 (perp=6.212, rec=0.292, cos=0.228), tot_loss_proj:2.193 [t=0.19s]
prediction: ['[CLS] subtle winner - - - hello, primary, winner - smart, real, librarian [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.776 (perp=6.320, rec=0.281, cos=0.231), tot_loss_proj:2.565 [t=0.21s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, primary, librarian [SEP]']
Attempt swap
[1000/2000] tot_loss=1.767 (perp=6.320, rec=0.276, cos=0.227), tot_loss_proj:2.567 [t=0.22s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, primary, librarian [SEP]']
[1050/2000] tot_loss=1.772 (perp=6.320, rec=0.284, cos=0.224), tot_loss_proj:2.565 [t=0.22s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, primary, librarian [SEP]']
Attempt swap
[1100/2000] tot_loss=1.758 (perp=6.320, rec=0.276, cos=0.219), tot_loss_proj:2.564 [t=0.19s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, primary, librarian [SEP]']
Attempt swap
[1150/2000] tot_loss=1.753 (perp=6.320, rec=0.264, cos=0.225), tot_loss_proj:2.564 [t=0.23s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, primary, librarian [SEP]']
[1200/2000] tot_loss=1.749 (perp=6.320, rec=0.263, cos=0.222), tot_loss_proj:2.564 [t=0.18s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, primary, librarian [SEP]']
Attempt swap
[1250/2000] tot_loss=1.744 (perp=6.320, rec=0.256, cos=0.223), tot_loss_proj:2.566 [t=0.21s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, primary, librarian [SEP]']
Attempt swap
[1300/2000] tot_loss=1.748 (perp=6.320, rec=0.261, cos=0.223), tot_loss_proj:2.569 [t=0.27s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, primary, librarian [SEP]']
[1350/2000] tot_loss=1.738 (perp=6.320, rec=0.247, cos=0.226), tot_loss_proj:2.568 [t=0.27s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, primary, librarian [SEP]']
Attempt swap
[1400/2000] tot_loss=1.761 (perp=6.455, rec=0.251, cos=0.219), tot_loss_proj:2.311 [t=0.19s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, subtle, librarian [SEP]']
Attempt swap
[1450/2000] tot_loss=1.773 (perp=6.455, rec=0.260, cos=0.222), tot_loss_proj:2.308 [t=0.25s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, subtle, librarian [SEP]']
[1500/2000] tot_loss=1.763 (perp=6.455, rec=0.251, cos=0.221), tot_loss_proj:2.305 [t=0.25s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, subtle, librarian [SEP]']
Attempt swap
[1550/2000] tot_loss=1.764 (perp=6.455, rec=0.252, cos=0.221), tot_loss_proj:2.309 [t=0.18s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, subtle, librarian [SEP]']
Attempt swap
[1600/2000] tot_loss=1.765 (perp=6.455, rec=0.251, cos=0.222), tot_loss_proj:2.300 [t=0.18s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, subtle, librarian [SEP]']
[1650/2000] tot_loss=1.768 (perp=6.455, rec=0.253, cos=0.224), tot_loss_proj:2.303 [t=0.21s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, subtle, librarian [SEP]']
Attempt swap
[1700/2000] tot_loss=1.764 (perp=6.455, rec=0.251, cos=0.222), tot_loss_proj:2.304 [t=0.18s]
prediction: ['[CLS] subtle winner - - - hello, real, winner - funny, subtle, librarian [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.980 (perp=7.075, rec=0.333, cos=0.231), tot_loss_proj:2.724 [t=0.19s]
prediction: ['[CLS] subtle subtle - - - hello, real, winnerand funny, winner, librarian [SEP]']
[1800/2000] tot_loss=1.941 (perp=7.075, rec=0.295, cos=0.231), tot_loss_proj:2.728 [t=0.18s]
prediction: ['[CLS] subtle subtle - - - hello, real, winnerand funny, winner, librarian [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.602 (perp=5.426, rec=0.289, cos=0.228), tot_loss_proj:2.198 [t=0.27s]
prediction: ['[CLS] subtle subtle - - - hello, real, funny - winner, winner, librarian [SEP]']
Attempt swap
[1900/2000] tot_loss=1.599 (perp=5.426, rec=0.284, cos=0.230), tot_loss_proj:2.194 [t=0.21s]
prediction: ['[CLS] subtle subtle - - - hello, real, funny - winner, winner, librarian [SEP]']
[1950/2000] tot_loss=1.590 (perp=5.426, rec=0.275, cos=0.229), tot_loss_proj:2.197 [t=0.21s]
prediction: ['[CLS] subtle subtle - - - hello, real, funny - winner, winner, librarian [SEP]']
Attempt swap
[2000/2000] tot_loss=1.589 (perp=5.426, rec=0.274, cos=0.230), tot_loss_proj:2.197 [t=0.25s]
prediction: ['[CLS] subtle subtle - - - hello, real, funny - winner, winner, librarian [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] subtle winner - - - hello, real, winner - funny, subtle, librarian [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 60.000 | p: 60.000 | r: 60.000
rouge2     | fm: 22.222 | p: 22.222 | r: 22.222
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 82.222

[Aggregate metrics]:
rouge1     | fm: 86.619 | p: 86.077 | r: 87.302
rouge2     | fm: 51.128 | p: 50.799 | r: 51.460
rougeL     | fm: 75.183 | p: 74.746 | r: 75.747
rougeLsum  | fm: 75.282 | p: 74.849 | r: 75.839
r1fm+r2fm = 137.747

input #69 time: 0:08:23 | total time: 9:46:51


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9987037982727984
highest_index [0]
highest [0.9987037982727984]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 0.8323659896850586 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 0.7848427295684814 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 0.7798381447792053 for ['[CLS] buenos sol aspects powerful otherpass wallace [SEP]']
[Init] best rec loss: 0.7789219617843628 for ['[CLS] ) classes squad computer less ached early [SEP]']
[Init] best rec loss: 0.7658141851425171 for ['[CLS] oliveira jamie position crime belong leadersla [SEP]']
[Init] best rec loss: 0.739287793636322 for ['[CLS] ga characteristic jump make deaths composed ⟩ [SEP]']
[Init] best rec loss: 0.7193447947502136 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 0.6981794834136963 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best rec loss: 0.6964297294616699 for ['[CLS] problems cupped potential dyed hear there hunters [SEP]']
[Init] best perm rec loss: 0.6960060596466064 for ['[CLS] hear potential dyed hunters there problems cupped [SEP]']
[Init] best perm rec loss: 0.694392740726471 for ['[CLS] there hear potential hunters dyed problems cupped [SEP]']
[Init] best perm rec loss: 0.6937648057937622 for ['[CLS] hear problems dyed there cupped potential hunters [SEP]']
[Init] best perm rec loss: 0.6917911171913147 for ['[CLS] hunters cupped problems hear dyed there potential [SEP]']
[Init] best perm rec loss: 0.6913226842880249 for ['[CLS] hunters there hear potential problems cupped dyed [SEP]']
[Init] best perm rec loss: 0.6908005475997925 for ['[CLS] hunters hear cupped problems potential dyed there [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.789 (perp=12.346, rec=0.275, cos=0.045), tot_loss_proj:3.120 [t=0.25s]
prediction: ['[CLS] gotunk pollution clunklated [SEP]']
[ 100/2000] tot_loss=2.277 (perp=10.758, rec=0.118, cos=0.007), tot_loss_proj:3.238 [t=0.25s]
prediction: ['[CLS] getsunk on clunk screeny [SEP]']
[ 150/2000] tot_loss=2.243 (perp=10.758, rec=0.078, cos=0.013), tot_loss_proj:3.276 [t=0.23s]
prediction: ['[CLS] getsunk on clunk screeny [SEP]']
[ 200/2000] tot_loss=2.218 (perp=10.758, rec=0.063, cos=0.004), tot_loss_proj:3.270 [t=0.24s]
prediction: ['[CLS] getsunk on clunk screeny [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.825 (perp=8.690, rec=0.082, cos=0.005), tot_loss_proj:2.319 [t=0.17s]
prediction: ['[CLS] getsunk on clunky screen [SEP]']
[ 300/2000] tot_loss=1.820 (perp=8.690, rec=0.078, cos=0.004), tot_loss_proj:2.327 [t=0.21s]
prediction: ['[CLS] getsunk on clunky screen [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.748 (perp=8.352, rec=0.074, cos=0.004), tot_loss_proj:2.159 [t=0.24s]
prediction: ['[CLS] getsunk clunky on screen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.588 (perp=7.591, rec=0.066, cos=0.004), tot_loss_proj:1.793 [t=0.22s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
[ 450/2000] tot_loss=1.592 (perp=7.591, rec=0.071, cos=0.004), tot_loss_proj:1.808 [t=0.19s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.596 (perp=7.591, rec=0.075, cos=0.004), tot_loss_proj:1.805 [t=0.27s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.595 (perp=7.591, rec=0.073, cos=0.004), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
[ 600/2000] tot_loss=1.591 (perp=7.591, rec=0.070, cos=0.003), tot_loss_proj:1.801 [t=0.22s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.588 (perp=7.591, rec=0.066, cos=0.003), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.589 (perp=7.591, rec=0.068, cos=0.003), tot_loss_proj:1.797 [t=0.18s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
[ 750/2000] tot_loss=1.592 (perp=7.591, rec=0.071, cos=0.003), tot_loss_proj:1.794 [t=0.19s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.580 (perp=7.591, rec=0.058, cos=0.003), tot_loss_proj:1.796 [t=0.18s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.593 (perp=7.591, rec=0.071, cos=0.003), tot_loss_proj:1.802 [t=0.20s]
prediction: ['[CLS]unk gets clunky on screen [SEP]']
[ 900/2000] tot_loss=1.363 (perp=6.453, rec=0.070, cos=0.003), tot_loss_proj:1.502 [t=0.18s]
prediction: ['[CLS] the gets clunky on screen [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.297 (perp=6.139, rec=0.066, cos=0.003), tot_loss_proj:1.306 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.284 (perp=6.139, rec=0.054, cos=0.003), tot_loss_proj:1.313 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1050/2000] tot_loss=1.301 (perp=6.139, rec=0.071, cos=0.003), tot_loss_proj:1.313 [t=0.23s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.293 (perp=6.139, rec=0.062, cos=0.003), tot_loss_proj:1.313 [t=0.24s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.283 (perp=6.139, rec=0.053, cos=0.003), tot_loss_proj:1.309 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1200/2000] tot_loss=1.292 (perp=6.139, rec=0.062, cos=0.003), tot_loss_proj:1.306 [t=0.19s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.288 (perp=6.139, rec=0.058, cos=0.003), tot_loss_proj:1.310 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.283 (perp=6.139, rec=0.053, cos=0.003), tot_loss_proj:1.302 [t=0.23s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1350/2000] tot_loss=1.283 (perp=6.139, rec=0.053, cos=0.003), tot_loss_proj:1.308 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.290 (perp=6.139, rec=0.060, cos=0.003), tot_loss_proj:1.304 [t=0.20s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.281 (perp=6.139, rec=0.050, cos=0.003), tot_loss_proj:1.311 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1500/2000] tot_loss=1.281 (perp=6.139, rec=0.051, cos=0.003), tot_loss_proj:1.317 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.286 (perp=6.139, rec=0.056, cos=0.003), tot_loss_proj:1.314 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.293 (perp=6.139, rec=0.062, cos=0.003), tot_loss_proj:1.305 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1650/2000] tot_loss=1.294 (perp=6.139, rec=0.063, cos=0.003), tot_loss_proj:1.310 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.294 (perp=6.139, rec=0.064, cos=0.003), tot_loss_proj:1.315 [t=0.24s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.290 (perp=6.139, rec=0.060, cos=0.003), tot_loss_proj:1.301 [t=0.26s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1800/2000] tot_loss=1.303 (perp=6.139, rec=0.073, cos=0.003), tot_loss_proj:1.322 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.292 (perp=6.139, rec=0.062, cos=0.003), tot_loss_proj:1.316 [t=0.18s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.288 (perp=6.139, rec=0.058, cos=0.003), tot_loss_proj:1.310 [t=0.19s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
[1950/2000] tot_loss=1.277 (perp=6.139, rec=0.047, cos=0.003), tot_loss_proj:1.313 [t=0.19s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.300 (perp=6.139, rec=0.070, cos=0.003), tot_loss_proj:1.294 [t=0.19s]
prediction: ['[CLS] gets clunky on the screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS] gets clunky on the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 86.736 | p: 86.229 | r: 87.380
rouge2     | fm: 51.747 | p: 51.471 | r: 52.134
rougeL     | fm: 75.493 | p: 75.039 | r: 76.056
rougeLsum  | fm: 75.525 | p: 75.097 | r: 76.094
r1fm+r2fm = 138.483

input #70 time: 0:08:22 | total time: 9:55:14


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9988247280592142
highest_index [0]
highest [0.9988247280592142]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 0.9197810888290405 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 0.9045233726501465 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 0.8936706185340881 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 0.8916658759117126 for ['[CLS]od production romatose smith bloody joker chapter trains via returning question tempoq cholera [SEP]']
[Init] best rec loss: 0.879439651966095 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 0.8744773864746094 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 0.8729464411735535 for ['[CLS] clips theory social chains landing ignorance mother game experience point ser [MASK] less whatever other [SEP]']
[Init] best rec loss: 0.8529620170593262 for ['[CLS]ine runways oregon bored : towardsgold occurred snow abovegerstypical definitely holiday rooney [SEP]']
[Init] best rec loss: 0.8512740135192871 for ['[CLS] jean bed queens fewer of professor fall ram surhear marshall over liam molly creatures [SEP]']
[Init] best perm rec loss: 0.8501914739608765 for ['[CLS] bed creatures liam over fall queens marshallhear sur ram fewer molly professor of jean [SEP]']
[Init] best perm rec loss: 0.8501520156860352 for ['[CLS] liamhear fall bed creatures molly professor marshall of sur over fewer ram queens jean [SEP]']
[Init] best perm rec loss: 0.8499558568000793 for ['[CLS] professor jean over fewer bed marshall molly fall liam of creatures ram sur queenshear [SEP]']
[Init] best perm rec loss: 0.8485043048858643 for ['[CLS] jean bed over creatures molly marshall sur professor liam fewer ramhear fall queens of [SEP]']
[Init] best perm rec loss: 0.8480358123779297 for ['[CLS] of fewer liam fall molly over creatures bed professor jean ramhear marshall queens sur [SEP]']
[Init] best perm rec loss: 0.8475852012634277 for ['[CLS]hear molly liam ram creatures marshall professor over fewer bed queens of sur fall jean [SEP]']
[Init] best perm rec loss: 0.8466736674308777 for ['[CLS] professor sur ram of jean fewer liam marshall bed molly over queens creatureshear fall [SEP]']
[Init] best perm rec loss: 0.8463535904884338 for ['[CLS]hear of liam over creatures jean queens professor molly ram bed sur marshall fall fewer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.180 (perp=9.231, rec=0.285, cos=0.049), tot_loss_proj:3.668 [t=0.26s]
prediction: ['[CLS] jump has moment not on is a moment moment not and jump your kiss moment [SEP]']
[ 100/2000] tot_loss=1.825 (perp=8.255, rec=0.157, cos=0.017), tot_loss_proj:3.323 [t=0.18s]
prediction: ['[CLS] jump - single nots there a single moment not and jump your seat moment [SEP]']
[ 150/2000] tot_loss=1.776 (perp=8.258, rec=0.117, cos=0.008), tot_loss_proj:3.009 [t=0.20s]
prediction: ['[CLS] jump - single nots there a single moment not and - your seat moment [SEP]']
[ 200/2000] tot_loss=1.703 (perp=8.045, rec=0.090, cos=0.004), tot_loss_proj:2.519 [t=0.19s]
prediction: ['[CLS] jump - single not - there a single moment not and - your seat moment [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.652 (perp=7.669, rec=0.113, cos=0.005), tot_loss_proj:2.963 [t=0.23s]
prediction: ['[CLS] jump s single - there not a single moment not and - your seat moment [SEP]']
[ 300/2000] tot_loss=1.829 (perp=8.700, rec=0.086, cos=0.003), tot_loss_proj:3.108 [t=0.26s]
prediction: ['[CLS] jump s single - there a a single moment not and - your seat moment [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.539 (perp=7.262, rec=0.084, cos=0.003), tot_loss_proj:2.803 [t=0.19s]
prediction: ['[CLS] jump s - - there a not a single moment and - your seat moment [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.523 (perp=7.191, rec=0.081, cos=0.004), tot_loss_proj:2.331 [t=0.19s]
prediction: ['[CLS] s jump - - there a not a single - and - your seat moment [SEP]']
[ 450/2000] tot_loss=1.514 (perp=7.191, rec=0.072, cos=0.003), tot_loss_proj:2.326 [t=0.25s]
prediction: ['[CLS] s jump - - there a not a single - and - your seat moment [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.430 (perp=6.721, rec=0.083, cos=0.003), tot_loss_proj:2.131 [t=0.19s]
prediction: ['[CLS] s jump - - there not a single a - and - your seat moment [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.329 (perp=6.249, rec=0.075, cos=0.004), tot_loss_proj:2.254 [t=0.18s]
prediction: ['[CLS] and jump - - there not a single s - s - your seat moment [SEP]']
[ 600/2000] tot_loss=1.330 (perp=6.249, rec=0.077, cos=0.003), tot_loss_proj:2.251 [t=0.18s]
prediction: ['[CLS] and jump - - there not a single s - s - your seat moment [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.286 (perp=6.051, rec=0.073, cos=0.003), tot_loss_proj:1.997 [t=0.18s]
prediction: ['[CLS] and jump - there not a single s - - s - your seat moment [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.295 (perp=6.058, rec=0.081, cos=0.003), tot_loss_proj:2.150 [t=0.18s]
prediction: ['[CLS] and jump - there not a single s - s - - your seat moment [SEP]']
[ 750/2000] tot_loss=1.290 (perp=6.058, rec=0.076, cos=0.003), tot_loss_proj:2.138 [t=0.20s]
prediction: ['[CLS] and jump - there not a single s - s - - your seat moment [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.285 (perp=6.058, rec=0.071, cos=0.003), tot_loss_proj:2.141 [t=0.18s]
prediction: ['[CLS] and jump - there not a single s - s - - your seat moment [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.289 (perp=6.051, rec=0.076, cos=0.003), tot_loss_proj:1.995 [t=0.23s]
prediction: ['[CLS] and jump - there not a single s - - s - your seat moment [SEP]']
[ 900/2000] tot_loss=1.294 (perp=6.051, rec=0.081, cos=0.003), tot_loss_proj:1.990 [t=0.18s]
prediction: ['[CLS] and jump - there not a single s - - s - your seat moment [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.288 (perp=6.051, rec=0.075, cos=0.003), tot_loss_proj:1.995 [t=0.22s]
prediction: ['[CLS] and jump - there not a single s - - s - your seat moment [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.281 (perp=6.051, rec=0.068, cos=0.003), tot_loss_proj:1.998 [t=0.24s]
prediction: ['[CLS] and jump - there not a single s - - s - your seat moment [SEP]']
[1050/2000] tot_loss=1.383 (perp=6.567, rec=0.067, cos=0.002), tot_loss_proj:2.151 [t=0.18s]
prediction: ["[CLS] and jump in there not a single'- - s - your seat moment [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.332 (perp=6.266, rec=0.076, cos=0.002), tot_loss_proj:2.391 [t=0.18s]
prediction: ["[CLS] and jump in there not a single's - - - your seat moment [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.283 (perp=6.058, rec=0.069, cos=0.003), tot_loss_proj:2.782 [t=0.20s]
prediction: ["[CLS] and - in there not a single's jump - - your seat moment [SEP]"]
[1200/2000] tot_loss=1.287 (perp=6.058, rec=0.073, cos=0.002), tot_loss_proj:2.777 [t=0.18s]
prediction: ["[CLS] and - in there not a single's jump - - your seat moment [SEP]"]
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.187 (perp=5.551, rec=0.075, cos=0.003), tot_loss_proj:2.408 [t=0.20s]
prediction: ["[CLS] and there not a single's jump - - - in your seat moment [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.175 (perp=5.551, rec=0.062, cos=0.002), tot_loss_proj:2.422 [t=0.18s]
prediction: ["[CLS] and there not a single's jump - - - in your seat moment [SEP]"]
[1350/2000] tot_loss=1.188 (perp=5.551, rec=0.076, cos=0.002), tot_loss_proj:2.416 [t=0.22s]
prediction: ["[CLS] and there not a single's jump - - - in your seat moment [SEP]"]
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.072 (perp=4.988, rec=0.072, cos=0.002), tot_loss_proj:1.933 [t=0.19s]
prediction: ["[CLS] and there's not a single jump - - - in your seat moment [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.040 (perp=4.822, rec=0.073, cos=0.003), tot_loss_proj:1.833 [t=0.22s]
prediction: ["[CLS] and there's not a single jump moment - - in your seat - [SEP]"]
[1500/2000] tot_loss=1.048 (perp=4.822, rec=0.082, cos=0.002), tot_loss_proj:1.843 [t=0.19s]
prediction: ["[CLS] and there's not a single jump moment - - in your seat - [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.024 (perp=4.822, rec=0.058, cos=0.002), tot_loss_proj:1.835 [t=0.18s]
prediction: ["[CLS] and there's not a single jump moment - - in your seat - [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.042 (perp=4.822, rec=0.076, cos=0.002), tot_loss_proj:1.830 [t=0.24s]
prediction: ["[CLS] and there's not a single jump moment - - in your seat - [SEP]"]
[1650/2000] tot_loss=1.034 (perp=4.822, rec=0.067, cos=0.002), tot_loss_proj:1.840 [t=0.19s]
prediction: ["[CLS] and there's not a single jump moment - - in your seat - [SEP]"]
Attempt swap
Moved token
[1700/2000] tot_loss=0.979 (perp=4.493, rec=0.078, cos=0.003), tot_loss_proj:1.695 [t=0.23s]
prediction: ["[CLS] and there's not a single moment - - jump in your seat - [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=0.961 (perp=4.389, rec=0.081, cos=0.002), tot_loss_proj:2.198 [t=0.27s]
prediction: ["[CLS] and there's not a single moment - - - jump in your seat [SEP]"]
[1800/2000] tot_loss=0.950 (perp=4.389, rec=0.070, cos=0.002), tot_loss_proj:2.205 [t=0.25s]
prediction: ["[CLS] and there's not a single moment - - - jump in your seat [SEP]"]
Attempt swap
Moved sequence
[1850/2000] tot_loss=0.942 (perp=4.389, rec=0.062, cos=0.002), tot_loss_proj:2.200 [t=0.18s]
prediction: ["[CLS] and there's not a single moment - - - jump in your seat [SEP]"]
Attempt swap
Moved token
[1900/2000] tot_loss=0.948 (perp=4.389, rec=0.068, cos=0.002), tot_loss_proj:2.210 [t=0.18s]
prediction: ["[CLS] and there's not a single moment - - - jump in your seat [SEP]"]
[1950/2000] tot_loss=0.953 (perp=4.389, rec=0.073, cos=0.002), tot_loss_proj:2.207 [t=0.20s]
prediction: ["[CLS] and there's not a single moment - - - jump in your seat [SEP]"]
Attempt swap
[2000/2000] tot_loss=0.946 (perp=4.389, rec=0.066, cos=0.002), tot_loss_proj:2.206 [t=0.21s]
prediction: ["[CLS] and there's not a single moment - - - jump in your seat [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] and there's not a single jump moment - - in your seat - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 58.333 | p: 58.333 | r: 58.333
rougeL     | fm: 84.615 | p: 84.615 | r: 84.615
rougeLsum  | fm: 84.615 | p: 84.615 | r: 84.615
r1fm+r2fm = 158.333

[Aggregate metrics]:
rouge1     | fm: 87.007 | p: 86.523 | r: 87.634
rouge2     | fm: 51.923 | p: 51.625 | r: 52.338
rougeL     | fm: 75.681 | p: 75.245 | r: 76.258
rougeLsum  | fm: 75.773 | p: 75.322 | r: 76.279
r1fm+r2fm = 138.931

input #71 time: 0:08:26 | total time: 10:03:40


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9985474105480585
highest_index [0]
highest [0.9985474105480585]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 0.7988373637199402 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 0.7717570066452026 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 0.7470374703407288 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 0.7435020208358765 for ['[CLS]nted seriously public caesar failure major eli city edo memberf runway koppen join useless [SEP]']
[Init] best rec loss: 0.7401317954063416 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 0.7362132668495178 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 0.7329061627388 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 0.7305222749710083 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 0.7160277962684631 for ['[CLS] nonetheless ta accidentally lifeboat walking dna van reserve except orbital zone! supportungen pork [SEP]']
[Init] best rec loss: 0.7047451734542847 for ['[CLS] them relations quickly sip abexed without connected counties glacier digitalhic professor teller page [SEP]']
[Init] best perm rec loss: 0.7039656043052673 for ['[CLS]hic professor themxed teller abe relations connected counties page quickly without glacier digital sip [SEP]']
[Init] best perm rec loss: 0.7032908201217651 for ['[CLS]hic professor digital glacierxed without page connected quickly relations them sip teller counties abe [SEP]']
[Init] best perm rec loss: 0.7032492756843567 for ['[CLS] glacierhic connected counties professor digital abe sip relations page quickly them teller withoutxed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.423 (perp=10.465, rec=0.275, cos=0.055), tot_loss_proj:3.107 [t=0.18s]
prediction: ['[CLS] a negative had tough skyscraper tough explosive threats legislation disguised growing with time -er [SEP]']
[ 100/2000] tot_loss=2.126 (perp=9.868, rec=0.141, cos=0.011), tot_loss_proj:3.451 [t=0.18s]
prediction: ['[CLS] a philosophy has tough time tough violence violence time - inspired with timeerer [SEP]']
[ 150/2000] tot_loss=2.240 (perp=10.737, rec=0.088, cos=0.005), tot_loss_proj:3.461 [t=0.19s]
prediction: ['[CLS] a philosophy has tough balancing tough its violence time philosophy inspired with timeerer [SEP]']
[ 200/2000] tot_loss=2.198 (perp=10.563, rec=0.081, cos=0.004), tot_loss_proj:3.445 [t=0.19s]
prediction: ['[CLS] a philosophy has tough balancing tough its violence time philosophy inspired with timefker [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.046 (perp=9.581, rec=0.122, cos=0.008), tot_loss_proj:3.050 [t=0.26s]
prediction: ['[CLS] a tough philosophy has tough balancing its violence time philosophy inspired with timefker [SEP]']
[ 300/2000] tot_loss=2.009 (perp=9.581, rec=0.089, cos=0.004), tot_loss_proj:3.043 [t=0.18s]
prediction: ['[CLS] a tough philosophy has tough balancing its violence time philosophy inspired with timefker [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.834 (perp=8.773, rec=0.075, cos=0.004), tot_loss_proj:2.738 [t=0.18s]
prediction: ['[CLS] a tough philosophy has tough balancing its time philosophy inspired with timefker violence [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.743 (perp=8.312, rec=0.076, cos=0.005), tot_loss_proj:2.590 [t=0.19s]
prediction: ['[CLS] a timefk has tough balancing its tough philosophy inspired with timefker violence [SEP]']
[ 450/2000] tot_loss=1.746 (perp=8.312, rec=0.081, cos=0.003), tot_loss_proj:2.589 [t=0.18s]
prediction: ['[CLS] a timefk has tough balancing its tough philosophy inspired with timefker violence [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.719 (perp=8.158, rec=0.084, cos=0.003), tot_loss_proj:2.458 [t=0.19s]
prediction: ['[CLS] a timefk has tough balancing its tough philosophy with timefk inspireder violence [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.686 (perp=8.065, rec=0.070, cos=0.003), tot_loss_proj:2.441 [t=0.19s]
prediction: ['[CLS] a timefk has tough balancing its tough philosophy with timefker inspired violence [SEP]']
[ 600/2000] tot_loss=1.690 (perp=8.065, rec=0.075, cos=0.003), tot_loss_proj:2.445 [t=0.18s]
prediction: ['[CLS] a timefk has tough balancing its tough philosophy with timefker inspired violence [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.671 (perp=8.023, rec=0.064, cos=0.003), tot_loss_proj:2.365 [t=0.24s]
prediction: ['[CLS] a timefk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.666 (perp=7.923, rec=0.079, cos=0.003), tot_loss_proj:2.289 [t=0.21s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
[ 750/2000] tot_loss=1.664 (perp=7.923, rec=0.076, cos=0.003), tot_loss_proj:2.285 [t=0.18s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.659 (perp=7.923, rec=0.071, cos=0.003), tot_loss_proj:2.290 [t=0.24s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.654 (perp=7.923, rec=0.067, cos=0.003), tot_loss_proj:2.300 [t=0.25s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
[ 900/2000] tot_loss=1.662 (perp=7.923, rec=0.075, cos=0.003), tot_loss_proj:2.292 [t=0.19s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.659 (perp=7.923, rec=0.072, cos=0.003), tot_loss_proj:2.291 [t=0.19s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1000/2000] tot_loss=1.668 (perp=7.923, rec=0.081, cos=0.003), tot_loss_proj:2.295 [t=0.21s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
[1050/2000] tot_loss=1.661 (perp=7.923, rec=0.074, cos=0.003), tot_loss_proj:2.289 [t=0.19s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1100/2000] tot_loss=1.652 (perp=7.923, rec=0.064, cos=0.003), tot_loss_proj:2.292 [t=0.22s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1150/2000] tot_loss=1.662 (perp=7.923, rec=0.075, cos=0.003), tot_loss_proj:2.295 [t=0.19s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
[1200/2000] tot_loss=1.658 (perp=7.923, rec=0.070, cos=0.003), tot_loss_proj:2.292 [t=0.19s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1250/2000] tot_loss=1.648 (perp=7.923, rec=0.060, cos=0.003), tot_loss_proj:2.287 [t=0.21s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1300/2000] tot_loss=1.664 (perp=7.923, rec=0.076, cos=0.003), tot_loss_proj:2.292 [t=0.18s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
[1350/2000] tot_loss=1.661 (perp=7.923, rec=0.074, cos=0.003), tot_loss_proj:2.287 [t=0.24s]
prediction: ['[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.537 (perp=7.282, rec=0.076, cos=0.004), tot_loss_proj:1.972 [t=0.21s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1450/2000] tot_loss=1.531 (perp=7.282, rec=0.071, cos=0.003), tot_loss_proj:1.969 [t=0.23s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
[1500/2000] tot_loss=1.531 (perp=7.282, rec=0.072, cos=0.003), tot_loss_proj:1.971 [t=0.22s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1550/2000] tot_loss=1.524 (perp=7.282, rec=0.064, cos=0.003), tot_loss_proj:1.960 [t=0.21s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1600/2000] tot_loss=1.525 (perp=7.282, rec=0.066, cos=0.003), tot_loss_proj:1.970 [t=0.26s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
[1650/2000] tot_loss=1.524 (perp=7.282, rec=0.065, cos=0.003), tot_loss_proj:1.973 [t=0.19s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1700/2000] tot_loss=1.524 (perp=7.282, rec=0.065, cos=0.003), tot_loss_proj:1.972 [t=0.21s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1750/2000] tot_loss=1.533 (perp=7.282, rec=0.073, cos=0.003), tot_loss_proj:1.965 [t=0.19s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
[1800/2000] tot_loss=1.532 (perp=7.282, rec=0.073, cos=0.003), tot_loss_proj:1.963 [t=0.19s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1850/2000] tot_loss=1.519 (perp=7.282, rec=0.060, cos=0.003), tot_loss_proj:1.971 [t=0.27s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[1900/2000] tot_loss=1.535 (perp=7.282, rec=0.076, cos=0.003), tot_loss_proj:1.975 [t=0.18s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
[1950/2000] tot_loss=1.530 (perp=7.282, rec=0.070, cos=0.003), tot_loss_proj:1.976 [t=0.21s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
Attempt swap
[2000/2000] tot_loss=1.533 (perp=7.282, rec=0.073, cos=0.003), tot_loss_proj:1.966 [t=0.19s]
prediction: ['[CLS] afk has tough time balancing its tougher philosophy with timea inspired violence [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] time afk has tough balancing its tougher philosophy with timea inspired violence [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 81.481 | p: 78.571 | r: 84.615
rouge2     | fm: 8.000 | p: 7.692 | r: 8.333
rougeL     | fm: 51.852 | p: 50.000 | r: 53.846
rougeLsum  | fm: 51.852 | p: 50.000 | r: 53.846
r1fm+r2fm = 89.481

[Aggregate metrics]:
rouge1     | fm: 86.894 | p: 86.399 | r: 87.566
rouge2     | fm: 51.242 | p: 50.941 | r: 51.593
rougeL     | fm: 75.423 | p: 74.974 | r: 75.972
rougeLsum  | fm: 75.484 | p: 74.994 | r: 76.074
r1fm+r2fm = 138.136

input #72 time: 0:08:23 | total time: 10:12:04


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9986496004715838
highest_index [0]
highest [0.9986496004715838]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 0.9870546460151672 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 0.9678601622581482 for ['[CLS]plate woke [SEP]']
[Init] best rec loss: 0.9414896368980408 for ['[CLS] garage knight [SEP]']
[Init] best rec loss: 0.9190089702606201 for ['[CLS]ncy cash [SEP]']
[Init] best rec loss: 0.9001289010047913 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 0.892829954624176 for ['[CLS] denied airline [SEP]']
[Init] best rec loss: 0.8742038011550903 for ['[CLS] puget traditional [SEP]']
[Init] best rec loss: 0.8741633892059326 for ['[CLS] massachusetts gun [SEP]']
[Init] best rec loss: 0.8547922372817993 for ['[CLS] split china [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.060 (perp=9.723, rec=0.110, cos=0.005), tot_loss_proj:2.021 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.008 (perp=9.723, rec=0.060, cos=0.003), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.008 (perp=9.723, rec=0.061, cos=0.003), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.014 (perp=9.723, rec=0.067, cos=0.003), tot_loss_proj:2.012 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.001 (perp=9.723, rec=0.053, cos=0.003), tot_loss_proj:2.015 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.013 (perp=9.723, rec=0.065, cos=0.003), tot_loss_proj:2.028 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.008 (perp=9.723, rec=0.061, cos=0.003), tot_loss_proj:2.022 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.019 (perp=9.723, rec=0.071, cos=0.003), tot_loss_proj:2.016 [t=0.22s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=2.004 (perp=9.723, rec=0.056, cos=0.003), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.013 (perp=9.723, rec=0.066, cos=0.003), tot_loss_proj:2.023 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.013 (perp=9.723, rec=0.065, cos=0.003), tot_loss_proj:2.020 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.007 (perp=9.723, rec=0.059, cos=0.003), tot_loss_proj:2.018 [t=0.20s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.996 (perp=9.723, rec=0.049, cos=0.003), tot_loss_proj:2.002 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.019 (perp=9.723, rec=0.072, cos=0.003), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.000 (perp=9.723, rec=0.052, cos=0.003), tot_loss_proj:2.014 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.003), tot_loss_proj:2.002 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.014 (perp=9.723, rec=0.067, cos=0.003), tot_loss_proj:2.010 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.006 (perp=9.723, rec=0.058, cos=0.003), tot_loss_proj:2.006 [t=0.24s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.015 (perp=9.723, rec=0.068, cos=0.003), tot_loss_proj:2.004 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.006 (perp=9.723, rec=0.058, cos=0.003), tot_loss_proj:2.007 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.003), tot_loss_proj:2.020 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.013 (perp=9.723, rec=0.065, cos=0.003), tot_loss_proj:2.012 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=2.011 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.012 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=2.011 (perp=9.723, rec=0.064, cos=0.003), tot_loss_proj:2.011 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.008 (perp=9.723, rec=0.060, cos=0.003), tot_loss_proj:2.014 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.003), tot_loss_proj:2.006 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.017 (perp=9.723, rec=0.070, cos=0.003), tot_loss_proj:2.015 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.003), tot_loss_proj:2.018 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.015 (perp=9.723, rec=0.067, cos=0.003), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.008 (perp=9.723, rec=0.060, cos=0.003), tot_loss_proj:2.032 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.013 (perp=9.723, rec=0.065, cos=0.003), tot_loss_proj:2.014 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.015 (perp=9.723, rec=0.068, cos=0.003), tot_loss_proj:2.018 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.013 (perp=9.723, rec=0.065, cos=0.003), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=2.015 (perp=9.723, rec=0.068, cos=0.003), tot_loss_proj:2.020 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.005 (perp=9.723, rec=0.057, cos=0.003), tot_loss_proj:2.017 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=1.992 (perp=9.723, rec=0.044, cos=0.003), tot_loss_proj:2.011 [t=0.19s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.005 (perp=9.723, rec=0.057, cos=0.003), tot_loss_proj:2.014 [t=0.25s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=1.989 (perp=9.723, rec=0.042, cos=0.003), tot_loss_proj:2.025 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.019 (perp=9.723, rec=0.072, cos=0.003), tot_loss_proj:2.005 [t=0.18s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.010 (perp=9.723, rec=0.062, cos=0.003), tot_loss_proj:2.017 [t=0.23s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.036 | p: 86.523 | r: 87.732
rouge2     | fm: 51.897 | p: 51.648 | r: 52.246
rougeL     | fm: 75.758 | p: 75.344 | r: 76.284
rougeLsum  | fm: 75.787 | p: 75.337 | r: 76.339
r1fm+r2fm = 138.933

input #73 time: 0:08:08 | total time: 10:20:12


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.998891135990029
highest_index [0]
highest [0.998891135990029]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 0.8867713809013367 for ['[CLS]wed [SEP]']
[Init] best rec loss: 0.6999737620353699 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.6985611319541931 for ['[CLS] ahead [SEP]']
[Init] best rec loss: 0.6979692578315735 for ['[CLS] sky [SEP]']
[Init] best rec loss: 0.6757439374923706 for ['[CLS] coup [SEP]']
[Init] best rec loss: 0.672342836856842 for ['[CLS] multi [SEP]']
[Init] best rec loss: 0.672085165977478 for ['[CLS] offense [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.752 (perp=8.178, rec=0.110, cos=0.007), tot_loss_proj:1.777 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.722 (perp=8.178, rec=0.080, cos=0.006), tot_loss_proj:1.739 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.711 (perp=8.178, rec=0.071, cos=0.004), tot_loss_proj:1.744 [t=0.23s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.712 (perp=8.178, rec=0.072, cos=0.005), tot_loss_proj:1.744 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.718 (perp=8.178, rec=0.076, cos=0.006), tot_loss_proj:1.725 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.693 (perp=8.178, rec=0.053, cos=0.004), tot_loss_proj:1.721 [t=0.28s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.704 (perp=8.178, rec=0.064, cos=0.004), tot_loss_proj:1.745 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.693 (perp=8.178, rec=0.053, cos=0.004), tot_loss_proj:1.737 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.704 (perp=8.178, rec=0.064, cos=0.005), tot_loss_proj:1.735 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.698 (perp=8.178, rec=0.060, cos=0.002), tot_loss_proj:1.729 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.711 (perp=8.178, rec=0.072, cos=0.003), tot_loss_proj:1.743 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.697 (perp=8.178, rec=0.059, cos=0.003), tot_loss_proj:1.737 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.699 (perp=8.178, rec=0.060, cos=0.003), tot_loss_proj:1.726 [t=0.19s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.697 (perp=8.178, rec=0.058, cos=0.003), tot_loss_proj:1.731 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.713 (perp=8.178, rec=0.075, cos=0.003), tot_loss_proj:1.727 [t=0.24s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.704 (perp=8.178, rec=0.066, cos=0.003), tot_loss_proj:1.723 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.692 (perp=8.178, rec=0.054, cos=0.003), tot_loss_proj:1.729 [t=0.18s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.703 (perp=8.178, rec=0.065, cos=0.003), tot_loss_proj:1.738 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.708 (perp=8.178, rec=0.069, cos=0.003), tot_loss_proj:1.735 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.693 (perp=8.178, rec=0.055, cos=0.003), tot_loss_proj:1.715 [t=0.20s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.684 (perp=8.178, rec=0.046, cos=0.003), tot_loss_proj:1.731 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.697 (perp=8.178, rec=0.059, cos=0.003), tot_loss_proj:1.731 [t=0.24s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.697 (perp=8.178, rec=0.059, cos=0.003), tot_loss_proj:1.731 [t=0.20s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.708 (perp=8.178, rec=0.070, cos=0.003), tot_loss_proj:1.739 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.705 (perp=8.178, rec=0.067, cos=0.003), tot_loss_proj:1.738 [t=0.25s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.685 (perp=8.178, rec=0.047, cos=0.003), tot_loss_proj:1.731 [t=0.21s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.688 (perp=8.178, rec=0.050, cos=0.003), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.707 (perp=8.178, rec=0.068, cos=0.003), tot_loss_proj:1.733 [t=0.18s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.697 (perp=8.178, rec=0.059, cos=0.003), tot_loss_proj:1.721 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.696 (perp=8.178, rec=0.058, cos=0.003), tot_loss_proj:1.725 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.692 (perp=8.178, rec=0.054, cos=0.003), tot_loss_proj:1.729 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.693 (perp=8.178, rec=0.054, cos=0.003), tot_loss_proj:1.725 [t=0.25s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.694 (perp=8.178, rec=0.056, cos=0.003), tot_loss_proj:1.735 [t=0.22s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.690 (perp=8.178, rec=0.051, cos=0.003), tot_loss_proj:1.722 [t=0.20s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.709 (perp=8.178, rec=0.071, cos=0.003), tot_loss_proj:1.738 [t=0.26s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.701 (perp=8.178, rec=0.062, cos=0.003), tot_loss_proj:1.728 [t=0.20s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.710 (perp=8.178, rec=0.072, cos=0.003), tot_loss_proj:1.740 [t=0.24s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.689 (perp=8.178, rec=0.050, cos=0.003), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.699 (perp=8.178, rec=0.061, cos=0.003), tot_loss_proj:1.732 [t=0.21s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.700 (perp=8.178, rec=0.061, cos=0.003), tot_loss_proj:1.733 [t=0.20s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.198 | p: 86.650 | r: 87.884
rouge2     | fm: 52.530 | p: 52.243 | r: 52.933
rougeL     | fm: 76.009 | p: 75.624 | r: 76.619
rougeLsum  | fm: 76.132 | p: 75.683 | r: 76.691
r1fm+r2fm = 139.728

input #74 time: 0:08:10 | total time: 10:28:23


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9988618643099074
highest_index [0]
highest [0.9988618643099074]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 0.8656521439552307 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 0.8427691459655762 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 0.824754536151886 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best rec loss: 0.8234107494354248 for ['[CLS] chaintrybro savings path part accolades truck visa chenses stateach foundation speak theme rather utter english [SEP]']
[Init] best perm rec loss: 0.8200531601905823 for ['[CLS] chen state rather pathbro englishtrysesach accolades truck chain utter speak part savings visa theme foundation [SEP]']
[Init] best perm rec loss: 0.8196504712104797 for ['[CLS] speak englishses accolades chain visa partach theme state rather path truck savingsbro chen foundationtry utter [SEP]']
[Init] best perm rec loss: 0.8179819583892822 for ['[CLS] speak savingstry chain foundation accolades truck stateses path visabro utter chen rather theme englishach part [SEP]']
[Init] best perm rec loss: 0.8175085186958313 for ['[CLS]ses truck rather visa english savings speak path utter chen themebroach accolades parttry foundation state chain [SEP]']
[Init] best perm rec loss: 0.8170819878578186 for ['[CLS] chen truck savingsach path speak english chaintry state visa rather utter themesesbro part accolades foundation [SEP]']
[Init] best perm rec loss: 0.815883994102478 for ['[CLS] speak statetry rather englishses part path theme utter chen savings accoladesach chain truckbro visa foundation [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=12.374, rec=0.347, cos=0.089), tot_loss_proj:3.964 [t=0.19s]
prediction: ['[CLS] exist indigenous hybrid administrative becoming is not forgotten movement worse ignored vince influence movement published classic misunderstood absolutely renaissance [SEP]']
[ 100/2000] tot_loss=2.648 (perp=12.151, rec=0.197, cos=0.022), tot_loss_proj:4.209 [t=0.22s]
prediction: ['[CLS] sufferingsectionlus mental into is not forgotten course forgotten easily easily instability ability or or easily enthusiasm convent [SEP]']
[ 150/2000] tot_loss=2.483 (perp=11.653, rec=0.144, cos=0.008), tot_loss_proj:4.013 [t=0.19s]
prediction: ['[CLS] excursion this excursion mental into is not forgottencola forgotten dismissed easily instability initiative or or easily especially ignore [SEP]']
[ 200/2000] tot_loss=2.563 (perp=12.117, rec=0.125, cos=0.015), tot_loss_proj:4.160 [t=0.18s]
prediction: ['[CLS] excursion this excursion mental into is not forgottencola forgotten dismissed easily instability of easily or seen foyer ignore [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.507 (perp=11.900, rec=0.116, cos=0.011), tot_loss_proj:4.106 [t=0.19s]
prediction: ['[CLS]cola this excursion mental into is not forgottencola dismissed easily forgotten instability of easily or dismissed ¡ forgotten [SEP]']
[ 300/2000] tot_loss=2.391 (perp=11.346, rec=0.111, cos=0.011), tot_loss_proj:3.998 [t=0.23s]
prediction: ['[CLS]cola this excursion mentalenter is not forgottencola dismissed easily forgotten instability of guided or dismissed ¡ forgotten [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=2.320 (perp=11.020, rec=0.106, cos=0.010), tot_loss_proj:3.995 [t=0.25s]
prediction: ['[CLS] this excursion mental into is not forgottencola visibly easily forgotten instability wheel would or dismissedication.cola [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.132 (perp=9.994, rec=0.122, cos=0.011), tot_loss_proj:3.741 [t=0.21s]
prediction: ['[CLS] this excursion mental is not forgottencola dismissed into easily forgotten instability of easily or bulletication.cola [SEP]']
[ 450/2000] tot_loss=2.282 (perp=10.822, rec=0.101, cos=0.016), tot_loss_proj:3.957 [t=0.18s]
prediction: ['[CLS] this excursion mental is not forgottencola dismissedenter easily dismissed instability of easily or bullet julius.cola [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.167 (perp=10.265, rec=0.104, cos=0.009), tot_loss_proj:3.842 [t=0.21s]
prediction: ['[CLS] this excursion mental is not forgottencola dismissedenter easily dismissed instability of easily. or julius.cola [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.230 (perp=10.575, rec=0.107, cos=0.008), tot_loss_proj:3.902 [t=0.24s]
prediction: ['[CLS] this excursion mental is not forgotten bullet dismissedenter easily dismissed instability of easilycola or..cola [SEP]']
[ 600/2000] tot_loss=2.044 (perp=9.665, rec=0.102, cos=0.009), tot_loss_proj:3.001 [t=0.19s]
prediction: ['[CLS] this excursion mental is not forgotten if perenter easily dismissed instability of easilycola or..cola [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.894 (perp=8.923, rec=0.100, cos=0.009), tot_loss_proj:2.790 [t=0.23s]
prediction: ['[CLS] this excursion mental is not forgotten if perenter easily dismissed instability of easilycola orcola.. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.962 (perp=9.219, rec=0.104, cos=0.014), tot_loss_proj:3.375 [t=0.25s]
prediction: ['[CLS] this excursion mental is not forgotten bullet perenter easily dismissed instability ofcola orcola. easily. [SEP]']
[ 750/2000] tot_loss=1.873 (perp=8.801, rec=0.096, cos=0.016), tot_loss_proj:2.760 [t=0.21s]
prediction: ['[CLS] this excursion mental is not forgotten of perenter easily dismissed instability percola orcola. easily. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.782 (perp=8.431, rec=0.083, cos=0.013), tot_loss_proj:2.473 [t=0.18s]
prediction: ['[CLS] this mental excursion is not forgotten of perenter easily dismissed instability percola orcola. epic. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.787 (perp=8.431, rec=0.091, cos=0.010), tot_loss_proj:2.473 [t=0.19s]
prediction: ['[CLS] this mental excursion is not forgotten of perenter easily dismissed instability percola orcola. epic. [SEP]']
[ 900/2000] tot_loss=1.806 (perp=8.560, rec=0.081, cos=0.013), tot_loss_proj:2.563 [t=0.18s]
prediction: ['[CLS] this mental excursion is not forgotten of per into easily dismissed instability percola orcola. epic. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.694 (perp=7.971, rec=0.090, cos=0.010), tot_loss_proj:3.331 [t=0.18s]
prediction: ['[CLS] this mental excursion into easily dismissed instability ofcola or is not forgotten of percola. epic. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.688 (perp=7.971, rec=0.083, cos=0.011), tot_loss_proj:3.326 [t=0.24s]
prediction: ['[CLS] this mental excursion into easily dismissed instability ofcola or is not forgotten of percola. epic. [SEP]']
[1050/2000] tot_loss=1.691 (perp=7.971, rec=0.086, cos=0.011), tot_loss_proj:3.333 [t=0.22s]
prediction: ['[CLS] this mental excursion into easily dismissed instability ofcola or is not forgotten of percola. epic. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.683 (perp=7.925, rec=0.087, cos=0.010), tot_loss_proj:3.328 [t=0.19s]
prediction: ['[CLS] this mental excursion into easily dismissed instability ofcola or is not of forgotten percola. epic. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.671 (perp=7.846, rec=0.090, cos=0.012), tot_loss_proj:3.355 [t=0.20s]
prediction: ['[CLS] this mental excursion into easily dismissed instability of orcola is not of forgotten percola. epic. [SEP]']
[1200/2000] tot_loss=1.662 (perp=7.846, rec=0.081, cos=0.012), tot_loss_proj:3.357 [t=0.18s]
prediction: ['[CLS] this mental excursion into easily dismissed instability of orcola is not of forgotten percola. epic. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.668 (perp=7.846, rec=0.087, cos=0.011), tot_loss_proj:3.363 [t=0.19s]
prediction: ['[CLS] this mental excursion into easily dismissed instability of orcola is not of forgotten percola. epic. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.723 (perp=8.116, rec=0.088, cos=0.011), tot_loss_proj:3.424 [t=0.23s]
prediction: ['[CLS] this mental excursion into easily dismissed instability per orcola is not of forgotten percola. epic. [SEP]']
[1350/2000] tot_loss=1.718 (perp=8.116, rec=0.085, cos=0.011), tot_loss_proj:3.421 [t=0.24s]
prediction: ['[CLS] this mental excursion into easily dismissed instability per orcola is not of forgotten percola. epic. [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.584 (perp=7.433, rec=0.086, cos=0.011), tot_loss_proj:3.231 [t=0.21s]
prediction: ['[CLS] this mental excursion into easily dismissed instability percola or is not of forgotten percola. epic. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.548 (perp=7.204, rec=0.094, cos=0.013), tot_loss_proj:3.227 [t=0.18s]
prediction: ['[CLS] this mental excursion into easily dismissed percola or instability is not of forgotten percola. epic. [SEP]']
[1500/2000] tot_loss=1.536 (perp=7.204, rec=0.084, cos=0.011), tot_loss_proj:3.219 [t=0.23s]
prediction: ['[CLS] this mental excursion into easily dismissed percola or instability is not of forgotten percola. epic. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.512 (perp=7.080, rec=0.086, cos=0.011), tot_loss_proj:2.306 [t=0.19s]
prediction: ['[CLS] this mental excursion into easily dismissed percola or instability is not forgotten of percola. epic. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.515 (perp=7.080, rec=0.088, cos=0.012), tot_loss_proj:2.304 [t=0.18s]
prediction: ['[CLS] this mental excursion into easily dismissed percola or instability is not forgotten of percola. epic. [SEP]']
[1650/2000] tot_loss=1.517 (perp=7.080, rec=0.089, cos=0.011), tot_loss_proj:2.302 [t=0.28s]
prediction: ['[CLS] this mental excursion into easily dismissed percola or instability is not forgotten of percola. epic. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.763 (perp=8.359, rec=0.080, cos=0.011), tot_loss_proj:2.519 [t=0.19s]
prediction: ['[CLS] this mental excursion into easily dismissedentercola or instability is not forgotten of percola. epic. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.695 (perp=8.034, rec=0.078, cos=0.010), tot_loss_proj:2.578 [t=0.18s]
prediction: ['[CLS] this mental excursion into easily dismissedenter or instability is not forgotten ofcola percola. epic. [SEP]']
[1800/2000] tot_loss=1.697 (perp=8.034, rec=0.079, cos=0.012), tot_loss_proj:2.577 [t=0.22s]
prediction: ['[CLS] this mental excursion into easily dismissedenter or instability is not forgotten ofcola percola. epic. [SEP]']
Attempt swap
Moved sequence
[1850/2000] tot_loss=1.642 (perp=7.729, rec=0.086, cos=0.010), tot_loss_proj:2.440 [t=0.18s]
prediction: ['[CLS] this mental excursion into easily dismissed epicenter or instability is not forgotten ofcola percola.. [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.567 (perp=7.354, rec=0.085, cos=0.012), tot_loss_proj:2.461 [t=0.30s]
prediction: ['[CLS] this mental excursion or easily dismissed epicenter into instability is not forgotten ofcola percola.. [SEP]']
[1950/2000] tot_loss=1.565 (perp=7.354, rec=0.084, cos=0.010), tot_loss_proj:2.463 [t=0.25s]
prediction: ['[CLS] this mental excursion or easily dismissed epicenter into instability is not forgotten ofcola percola.. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.564 (perp=7.354, rec=0.082, cos=0.010), tot_loss_proj:2.461 [t=0.18s]
prediction: ['[CLS] this mental excursion or easily dismissed epicenter into instability is not forgotten ofcola percola.. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this mental excursion into easily dismissed percola or instability is not forgotten of percola. epic. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 82.353 | p: 82.353 | r: 82.353
rouge2     | fm: 31.250 | p: 31.250 | r: 31.250
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 113.603

[Aggregate metrics]:
rouge1     | fm: 87.213 | p: 86.688 | r: 87.896
rouge2     | fm: 52.322 | p: 52.008 | r: 52.677
rougeL     | fm: 75.756 | p: 75.273 | r: 76.296
rougeLsum  | fm: 75.747 | p: 75.359 | r: 76.279
r1fm+r2fm = 139.535

input #75 time: 0:08:18 | total time: 10:36:42


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9984845084457341
highest_index [0]
highest [0.9984845084457341]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 0.9048320651054382 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 0.8907039165496826 for ['[CLS] skin outside historian inside please determined boss legend vi đ wine unanimouslymer ski [SEP]']
[Init] best rec loss: 0.8906455039978027 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 0.8905230760574341 for ['[CLS] cast childhoodnation race auction upside find supporting mob subjectباد moon meat as [SEP]']
[Init] best rec loss: 0.8666055202484131 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best perm rec loss: 0.8657161593437195 for ['[CLS] press fall regardsmill rest en tuesday twelvehedron describedrd drag inception vantage [SEP]']
[Init] best perm rec loss: 0.8652821779251099 for ['[CLS] en press drag twelve regards inceptionmill tuesday described fallrdhedron rest vantage [SEP]']
[Init] best perm rec loss: 0.8650845885276794 for ['[CLS] fallhedron vantagerd drag en regards described tuesday press inception rest twelvemill [SEP]']
[Init] best perm rec loss: 0.8639886379241943 for ['[CLS]rd fall twelvehedron en regards tuesday press rest inception vantage described dragmill [SEP]']
[Init] best perm rec loss: 0.8622297644615173 for ['[CLS] restmillrd inception drag en vantage tuesday twelve fall regardshedron described press [SEP]']
[Init] best perm rec loss: 0.862182080745697 for ['[CLS]mill fall rest drag en vantage tuesdayrd regardshedron twelve inception press described [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.545 (perp=11.271, rec=0.254, cos=0.037), tot_loss_proj:3.488 [t=0.18s]
prediction: ['[CLS] has or seemed end stop at round whether does stopped challenging himself clear stopped [SEP]']
[ 100/2000] tot_loss=2.286 (perp=10.696, rec=0.136, cos=0.010), tot_loss_proj:3.208 [t=0.25s]
prediction: ['[CLS] has just like stopped stop at 66 having has stopped challenging himself s stopped [SEP]']
[ 150/2000] tot_loss=2.327 (perp=11.106, rec=0.099, cos=0.007), tot_loss_proj:3.422 [t=0.19s]
prediction: ['[CLS] has s as 2017 stop at 66 whether, stopped challenging himself s stopped [SEP]']
[ 200/2000] tot_loss=2.016 (perp=9.641, rec=0.082, cos=0.006), tot_loss_proj:3.131 [t=0.21s]
prediction: ['[CLS] has s as 2017 at allen 66,, stopped challenging himself s. [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.846 (perp=8.770, rec=0.086, cos=0.006), tot_loss_proj:2.939 [t=0.18s]
prediction: ['[CLS] has s as stopped, at allen 66, stopped challenging himself s. [SEP]']
[ 300/2000] tot_loss=1.709 (perp=8.074, rec=0.089, cos=0.005), tot_loss_proj:2.783 [t=0.23s]
prediction: ['[CLS] has s as stopped, at allen 66, stopped challenging himself.. [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.732 (perp=8.240, rec=0.079, cos=0.005), tot_loss_proj:2.729 [t=0.18s]
prediction: ['[CLS] s as has., at allen 66, stopped challenging himself s. [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.894 (perp=8.658, rec=0.151, cos=0.011), tot_loss_proj:2.785 [t=0.21s]
prediction: ["[CLS] s accounted has as, at allen 66, stopped challenging himself '. [SEP]"]
[ 450/2000] tot_loss=1.699 (perp=7.983, rec=0.098, cos=0.004), tot_loss_proj:2.309 [t=0.19s]
prediction: ["[CLS] sorestation has as, at allen 66, stopped challenging himself '. [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.449 (perp=6.806, rec=0.084, cos=0.004), tot_loss_proj:2.043 [t=0.18s]
prediction: ["[CLS] s'has as, at allen 66, stopped challenging himself.. [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.438 (perp=6.806, rec=0.073, cos=0.004), tot_loss_proj:2.048 [t=0.18s]
prediction: ["[CLS] s'has as, at allen 66, stopped challenging himself.. [SEP]"]
[ 600/2000] tot_loss=1.445 (perp=6.806, rec=0.080, cos=0.004), tot_loss_proj:2.051 [t=0.19s]
prediction: ["[CLS] s'has as, at allen 66, stopped challenging himself.. [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.439 (perp=6.806, rec=0.073, cos=0.004), tot_loss_proj:2.057 [t=0.19s]
prediction: ["[CLS] s'has as, at allen 66, stopped challenging himself.. [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.637 (perp=7.762, rec=0.081, cos=0.004), tot_loss_proj:2.430 [t=0.18s]
prediction: ["[CLS] s'has as, atpt 66, stopped challenging himself allen. [SEP]"]
[ 750/2000] tot_loss=1.634 (perp=7.762, rec=0.077, cos=0.004), tot_loss_proj:2.419 [t=0.19s]
prediction: ["[CLS] s'has as, atpt 66, stopped challenging himself allen. [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.573 (perp=7.394, rec=0.090, cos=0.004), tot_loss_proj:2.182 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself allenpt. [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.544 (perp=7.284, rec=0.083, cos=0.004), tot_loss_proj:2.256 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himselfpt allen. [SEP]"]
[ 900/2000] tot_loss=1.538 (perp=7.284, rec=0.078, cos=0.004), tot_loss_proj:2.256 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himselfpt allen. [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.546 (perp=7.284, rec=0.086, cos=0.004), tot_loss_proj:2.257 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himselfpt allen. [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.543 (perp=7.284, rec=0.082, cos=0.004), tot_loss_proj:2.252 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himselfpt allen. [SEP]"]
[1050/2000] tot_loss=1.541 (perp=7.284, rec=0.081, cos=0.004), tot_loss_proj:2.257 [t=0.23s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himselfpt allen. [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.544 (perp=7.284, rec=0.084, cos=0.003), tot_loss_proj:2.253 [t=0.19s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himselfpt allen. [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.546 (perp=7.284, rec=0.086, cos=0.003), tot_loss_proj:2.258 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himselfpt allen. [SEP]"]
[1200/2000] tot_loss=1.536 (perp=7.284, rec=0.075, cos=0.003), tot_loss_proj:2.248 [t=0.19s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himselfpt allen. [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.526 (perp=7.284, rec=0.065, cos=0.003), tot_loss_proj:2.257 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himselfpt allen. [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.381 (perp=6.510, rec=0.075, cos=0.003), tot_loss_proj:1.953 [t=0.26s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
[1350/2000] tot_loss=1.388 (perp=6.510, rec=0.082, cos=0.003), tot_loss_proj:1.946 [t=0.23s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.385 (perp=6.510, rec=0.080, cos=0.003), tot_loss_proj:1.954 [t=0.23s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.388 (perp=6.510, rec=0.083, cos=0.003), tot_loss_proj:1.947 [t=0.21s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
[1500/2000] tot_loss=1.385 (perp=6.510, rec=0.080, cos=0.003), tot_loss_proj:1.942 [t=0.24s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.378 (perp=6.510, rec=0.072, cos=0.003), tot_loss_proj:1.952 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.384 (perp=6.510, rec=0.079, cos=0.003), tot_loss_proj:1.946 [t=0.19s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
[1650/2000] tot_loss=1.393 (perp=6.510, rec=0.088, cos=0.003), tot_loss_proj:1.942 [t=0.19s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.369 (perp=6.510, rec=0.064, cos=0.003), tot_loss_proj:1.945 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.377 (perp=6.510, rec=0.072, cos=0.003), tot_loss_proj:1.953 [t=0.18s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
[1800/2000] tot_loss=1.384 (perp=6.510, rec=0.079, cos=0.003), tot_loss_proj:1.940 [t=0.24s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.385 (perp=6.510, rec=0.080, cos=0.003), tot_loss_proj:1.955 [t=0.20s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.392 (perp=6.510, rec=0.087, cos=0.003), tot_loss_proj:1.949 [t=0.21s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
[1950/2000] tot_loss=1.370 (perp=6.510, rec=0.065, cos=0.003), tot_loss_proj:1.946 [t=0.21s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.377 (perp=6.510, rec=0.071, cos=0.003), tot_loss_proj:1.945 [t=0.19s]
prediction: ["[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]"]
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] s'has as, at 66, stopped challenging himself. allen. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 100.000 | r: 91.667
rouge2     | fm: 38.095 | p: 40.000 | r: 36.364
rougeL     | fm: 78.261 | p: 81.818 | r: 75.000
rougeLsum  | fm: 78.261 | p: 81.818 | r: 75.000
r1fm+r2fm = 133.747

[Aggregate metrics]:
rouge1     | fm: 87.300 | p: 86.887 | r: 87.886
rouge2     | fm: 51.946 | p: 51.705 | r: 52.230
rougeL     | fm: 75.756 | p: 75.466 | r: 76.278
rougeLsum  | fm: 75.795 | p: 75.394 | r: 76.308
r1fm+r2fm = 139.246

input #76 time: 0:08:15 | total time: 10:44:57


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9987225414629781
highest_index [0]
highest [0.9987225414629781]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 0.7890468239784241 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 0.7739176154136658 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 0.7422829270362854 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 0.7419257760047913 for ['[CLS] where win oleraphic sometime medium most ways sheep outside gray purpleno lime park [SEP]']
[Init] best perm rec loss: 0.7405267357826233 for ['[CLS]no park outside lime medium sometime purpleraphic sheep most ways ole win gray where [SEP]']
[Init] best perm rec loss: 0.7398688197135925 for ['[CLS] ole sometime purpleno where ways park win sheep lime outsideraphic gray medium most [SEP]']
[Init] best perm rec loss: 0.7397211790084839 for ['[CLS] park medium where purple win grayraphic sometime ole sheep lime most ways outsideno [SEP]']
[Init] best perm rec loss: 0.739418625831604 for ['[CLS] where sheep park medium ole sometime win gray waysno mostraphic outside purple lime [SEP]']
[Init] best perm rec loss: 0.7393907904624939 for ['[CLS] gray whereraphic sheep park ole sometime purple waysno lime most outside win medium [SEP]']
[Init] best perm rec loss: 0.7393835783004761 for ['[CLS] where purple ways ole gray mostno sheep winraphic lime park sometime medium outside [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.012 (perp=12.698, rec=0.422, cos=0.050), tot_loss_proj:3.658 [t=0.19s]
prediction: ['[CLS] above consciousness for ( trust australiam 2010 2007 tangible lee ye wish international under [SEP]']
[ 100/2000] tot_loss=2.873 (perp=12.172, rec=0.375, cos=0.063), tot_loss_proj:3.158 [t=0.19s]
prediction: ['[CLS] above above above through trust australian the humanity further occurs jon its promise practical above [SEP]']
[ 150/2000] tot_loss=2.322 (perp=9.656, rec=0.327, cos=0.064), tot_loss_proj:2.882 [t=0.19s]
prediction: ['[CLS] above above the is make results the material of is jon its promise material above [SEP]']
[ 200/2000] tot_loss=2.208 (perp=9.477, rec=0.256, cos=0.056), tot_loss_proj:3.149 [t=0.18s]
prediction: ['[CLS] above above the is make m the material of is dealer believe promise material above [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.088 (perp=8.769, rec=0.285, cos=0.049), tot_loss_proj:2.778 [t=0.22s]
prediction: ['[CLS] above the material, is topics above the is life m its promise material above [SEP]']
[ 300/2000] tot_loss=1.965 (perp=8.327, rec=0.251, cos=0.049), tot_loss_proj:2.579 [t=0.19s]
prediction: ['[CLS] above the material, is knowing above the is this m its promise material above [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.055 (perp=8.849, rec=0.237, cos=0.048), tot_loss_proj:2.699 [t=0.27s]
prediction: ['[CLS] above the material above the is life souc is dealer that promise material above [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.965 (perp=8.359, rec=0.247, cos=0.046), tot_loss_proj:2.442 [t=0.18s]
prediction: ['[CLS] is life souc crow dealer that promise above the material above the material realm [SEP]']
[ 450/2000] tot_loss=2.107 (perp=9.209, rec=0.215, cos=0.050), tot_loss_proj:2.660 [t=0.25s]
prediction: ['[CLS] is believe souc isreus itsars above the realm above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.994 (perp=8.629, rec=0.215, cos=0.054), tot_loss_proj:2.515 [t=0.20s]
prediction: ['[CLS] isfide souc because believe itsars above the realm above the material realm [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.681 (perp=7.137, rec=0.206, cos=0.048), tot_loss_proj:2.757 [t=0.18s]
prediction: ['[CLS] iscript because believe its knowing soars above the realm above the material realm [SEP]']
[ 600/2000] tot_loss=1.831 (perp=7.972, rec=0.188, cos=0.048), tot_loss_proj:3.033 [t=0.18s]
prediction: ['[CLS] iscript because believe itspuri soars above the realm above the material realm [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.655 (perp=7.097, rec=0.189, cos=0.047), tot_loss_proj:2.817 [t=0.23s]
prediction: ['[CLS] iscript because its believereus soars above the realm above the material realm [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.863 (perp=8.159, rec=0.178, cos=0.053), tot_loss_proj:2.533 [t=0.19s]
prediction: ['[CLS] is because its believe papuareus soars above that realm above the material realm [SEP]']
[ 750/2000] tot_loss=1.967 (perp=8.727, rec=0.174, cos=0.048), tot_loss_proj:2.831 [t=0.19s]
prediction: ['[CLS] is because its believe papua seek soars above that realm above the material realm [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.991 (perp=8.848, rec=0.173, cos=0.048), tot_loss_proj:2.982 [t=0.21s]
prediction: ['[CLS] is because its believe papua soars seek above that realm fits the material realm [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.159 (perp=9.694, rec=0.172, cos=0.048), tot_loss_proj:3.110 [t=0.19s]
prediction: ['[CLS] istson its believe papua soars seek above testimony realm that the material realm [SEP]']
[ 900/2000] tot_loss=2.150 (perp=9.694, rec=0.164, cos=0.048), tot_loss_proj:3.105 [t=0.23s]
prediction: ['[CLS] istson its believe papua soars seek above testimony realm that the material realm [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.111 (perp=9.489, rec=0.163, cos=0.050), tot_loss_proj:3.103 [t=0.18s]
prediction: ['[CLS] is believe itstson papua soars seek above testimony realm that the material realm [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.006 (perp=8.955, rec=0.164, cos=0.052), tot_loss_proj:2.931 [t=0.18s]
prediction: ['[CLS] is believe itscripttson soars seek above testimony realm that the material realm [SEP]']
[1050/2000] tot_loss=2.027 (perp=9.059, rec=0.164, cos=0.051), tot_loss_proj:3.130 [t=0.22s]
prediction: ['[CLS] is believe its papuatson soars seek above specimens realm that the material realm [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.034 (perp=9.144, rec=0.155, cos=0.050), tot_loss_proj:2.701 [t=0.18s]
prediction: ['[CLS] is believe itscripttson soars above seek themselves realm that the material realm [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.180 (perp=9.811, rec=0.167, cos=0.051), tot_loss_proj:2.737 [t=0.18s]
prediction: ['[CLS] is believe its papuatson soars specimens above seek realm that the material realm [SEP]']
[1200/2000] tot_loss=2.175 (perp=9.811, rec=0.162, cos=0.051), tot_loss_proj:2.736 [t=0.19s]
prediction: ['[CLS] is believe its papuatson soars specimens above seek realm that the material realm [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.027 (perp=9.084, rec=0.159, cos=0.051), tot_loss_proj:2.771 [t=0.24s]
prediction: ['[CLS] is believe its papuatson soars above specimens seek realm that the material realm [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=2.018 (perp=9.032, rec=0.163, cos=0.049), tot_loss_proj:2.792 [t=0.22s]
prediction: ['[CLS] is believe itscripttson soars above seek relics realm that the material realm [SEP]']
[1350/2000] tot_loss=2.016 (perp=9.032, rec=0.161, cos=0.049), tot_loss_proj:2.788 [t=0.19s]
prediction: ['[CLS] is believe itscripttson soars above seek relics realm that the material realm [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=2.153 (perp=9.697, rec=0.163, cos=0.050), tot_loss_proj:2.772 [t=0.18s]
prediction: ['[CLS] is believe itspuri papuatson soars above specimens realm that the material realm [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.178 (perp=9.825, rec=0.162, cos=0.051), tot_loss_proj:2.903 [t=0.22s]
prediction: ['[CLS] is believe itscripttson soars abovepuri relics realm that the material realm [SEP]']
[1500/2000] tot_loss=2.160 (perp=9.744, rec=0.161, cos=0.050), tot_loss_proj:2.807 [t=0.18s]
prediction: ['[CLS] is believe itscripttson soars abovepuri specimens realm that the material realm [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.015 (perp=9.022, rec=0.162, cos=0.048), tot_loss_proj:2.813 [t=0.18s]
prediction: ['[CLS] is believe itspuricripttson soars above evidence realm that the material realm [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.978 (perp=8.870, rec=0.155, cos=0.049), tot_loss_proj:2.722 [t=0.27s]
prediction: ['[CLS] is believe itscriptpuritson soars above evidence realm that the material realm [SEP]']
[1650/2000] tot_loss=1.968 (perp=8.870, rec=0.146, cos=0.048), tot_loss_proj:2.722 [t=0.19s]
prediction: ['[CLS] is believe itscriptpuritson soars above evidence realm that the material realm [SEP]']
Attempt swap
[1700/2000] tot_loss=1.983 (perp=8.870, rec=0.158, cos=0.051), tot_loss_proj:2.728 [t=0.18s]
prediction: ['[CLS] is believe itscriptpuritson soars above evidence realm that the material realm [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.970 (perp=8.820, rec=0.157, cos=0.049), tot_loss_proj:2.706 [t=0.23s]
prediction: ['[CLS] is believe itscripttsonpuri soars above evidence realm that the material realm [SEP]']
[1800/2000] tot_loss=1.964 (perp=8.820, rec=0.152, cos=0.049), tot_loss_proj:2.698 [t=0.26s]
prediction: ['[CLS] is believe itscripttsonpuri soars above evidence realm that the material realm [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.932 (perp=8.636, rec=0.156, cos=0.049), tot_loss_proj:2.665 [t=0.29s]
prediction: ['[CLS] is its believecripttsonpuri soars above evidence realm that the material realm [SEP]']
Attempt swap
[1900/2000] tot_loss=1.936 (perp=8.636, rec=0.158, cos=0.051), tot_loss_proj:2.666 [t=0.21s]
prediction: ['[CLS] is its believecripttsonpuri soars above evidence realm that the material realm [SEP]']
[1950/2000] tot_loss=1.930 (perp=8.636, rec=0.149, cos=0.054), tot_loss_proj:2.657 [t=0.21s]
prediction: ['[CLS] is its believecripttsonpuri soars above evidence realm that the material realm [SEP]']
Attempt swap
[2000/2000] tot_loss=1.932 (perp=8.636, rec=0.152, cos=0.053), tot_loss_proj:2.662 [t=0.25s]
prediction: ['[CLS] is its believecripttsonpuri soars above evidence realm that the material realm [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] is its believecripttsonpuri soars above evidence realm that the material realm [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 76.923 | r: 66.667
rouge2     | fm: 46.154 | p: 50.000 | r: 42.857
rougeL     | fm: 64.286 | p: 69.231 | r: 60.000
rougeLsum  | fm: 64.286 | p: 69.231 | r: 60.000
r1fm+r2fm = 117.582

[Aggregate metrics]:
rouge1     | fm: 87.082 | p: 86.702 | r: 87.586
rouge2     | fm: 52.057 | p: 51.836 | r: 52.329
rougeL     | fm: 75.599 | p: 75.302 | r: 76.062
rougeLsum  | fm: 75.665 | p: 75.335 | r: 76.073
r1fm+r2fm = 139.139

input #77 time: 0:08:22 | total time: 10:53:20


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9986819588735288
highest_index [0]
highest [0.9986819588735288]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 0.9864028096199036 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 0.9620141386985779 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 0.8158155083656311 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 0.779419481754303 for ['[CLS] le screens grant [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.009 (perp=9.346, rec=0.135, cos=0.005), tot_loss_proj:2.524 [t=0.19s]
prediction: ['[CLS] exit exit theater [SEP]']
[ 100/2000] tot_loss=1.653 (perp=7.958, rec=0.059, cos=0.003), tot_loss_proj:1.672 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[ 150/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.669 [t=0.20s]
prediction: ['[CLS] exit the theater [SEP]']
[ 200/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.677 [t=0.19s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.654 (perp=7.958, rec=0.060, cos=0.003), tot_loss_proj:1.673 [t=0.20s]
prediction: ['[CLS] exit the theater [SEP]']
[ 300/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.676 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.635 (perp=7.958, rec=0.041, cos=0.003), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.647 (perp=7.958, rec=0.053, cos=0.003), tot_loss_proj:1.673 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.655 (perp=7.958, rec=0.061, cos=0.003), tot_loss_proj:1.668 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.659 (perp=7.958, rec=0.065, cos=0.003), tot_loss_proj:1.675 [t=0.19s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.672 [t=0.20s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.646 (perp=7.958, rec=0.052, cos=0.003), tot_loss_proj:1.671 [t=0.19s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.658 (perp=7.958, rec=0.064, cos=0.003), tot_loss_proj:1.668 [t=0.28s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.656 (perp=7.958, rec=0.062, cos=0.003), tot_loss_proj:1.669 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.655 (perp=7.958, rec=0.061, cos=0.003), tot_loss_proj:1.677 [t=0.20s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.671 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.648 (perp=7.958, rec=0.053, cos=0.003), tot_loss_proj:1.666 [t=0.19s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.645 (perp=7.958, rec=0.051, cos=0.003), tot_loss_proj:1.673 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.648 (perp=7.958, rec=0.054, cos=0.003), tot_loss_proj:1.680 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.659 (perp=7.958, rec=0.065, cos=0.003), tot_loss_proj:1.657 [t=0.22s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.658 (perp=7.958, rec=0.063, cos=0.003), tot_loss_proj:1.681 [t=0.27s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.661 (perp=7.958, rec=0.067, cos=0.003), tot_loss_proj:1.666 [t=0.20s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.661 (perp=7.958, rec=0.067, cos=0.003), tot_loss_proj:1.677 [t=0.19s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.660 (perp=7.958, rec=0.066, cos=0.003), tot_loss_proj:1.683 [t=0.24s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.652 (perp=7.958, rec=0.058, cos=0.003), tot_loss_proj:1.668 [t=0.20s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.654 (perp=7.958, rec=0.060, cos=0.003), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.648 (perp=7.958, rec=0.054, cos=0.003), tot_loss_proj:1.658 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.652 (perp=7.958, rec=0.058, cos=0.003), tot_loss_proj:1.676 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.651 (perp=7.958, rec=0.057, cos=0.003), tot_loss_proj:1.659 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.662 (perp=7.958, rec=0.068, cos=0.003), tot_loss_proj:1.660 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.660 (perp=7.958, rec=0.066, cos=0.003), tot_loss_proj:1.657 [t=0.25s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.661 (perp=7.958, rec=0.067, cos=0.003), tot_loss_proj:1.675 [t=0.20s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.655 (perp=7.958, rec=0.061, cos=0.003), tot_loss_proj:1.657 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.673 (perp=7.958, rec=0.078, cos=0.003), tot_loss_proj:1.679 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.656 (perp=7.958, rec=0.061, cos=0.003), tot_loss_proj:1.662 [t=0.19s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.647 (perp=7.958, rec=0.053, cos=0.003), tot_loss_proj:1.669 [t=0.21s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.003), tot_loss_proj:1.674 [t=0.23s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.654 (perp=7.958, rec=0.060, cos=0.003), tot_loss_proj:1.665 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.651 (perp=7.958, rec=0.057, cos=0.003), tot_loss_proj:1.662 [t=0.27s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.665 (perp=7.958, rec=0.071, cos=0.003), tot_loss_proj:1.665 [t=0.18s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.245 | p: 86.857 | r: 87.769
rouge2     | fm: 52.324 | p: 52.188 | r: 52.649
rougeL     | fm: 75.892 | p: 75.632 | r: 76.362
rougeLsum  | fm: 75.982 | p: 75.696 | r: 76.419
r1fm+r2fm = 139.569

input #78 time: 0:08:13 | total time: 11:01:34


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.998708022935592
highest_index [0]
highest [0.998708022935592]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 0.9721437692642212 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 0.9616090655326843 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 0.9452188014984131 for ['[CLS] abs mess [SEP]']
[Init] best rec loss: 0.9170636534690857 for ['[CLS] bell renaissance [SEP]']
[Init] best rec loss: 0.9101263284683228 for ['[CLS] unincorporated band [SEP]']
[Init] best rec loss: 0.9005734920501709 for ['[CLS] crystaltor [SEP]']
[Init] best perm rec loss: 0.8978461027145386 for ['[CLS]tor crystal [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=4.089 (perp=12.278, rec=0.658, cos=0.975), tot_loss_proj:4.222 [t=0.23s]
prediction: ['[CLS] overcame bunch [SEP]']
[ 100/2000] tot_loss=3.186 (perp=12.290, rec=0.498, cos=0.229), tot_loss_proj:3.037 [t=0.18s]
prediction: ['[CLS] thank fascinating [SEP]']
[ 150/2000] tot_loss=2.476 (perp=11.428, rec=0.185, cos=0.006), tot_loss_proj:2.600 [t=0.18s]
prediction: ['[CLS] fascinating fascinating [SEP]']
[ 200/2000] tot_loss=1.985 (perp=9.381, rec=0.106, cos=0.003), tot_loss_proj:1.958 [t=0.18s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.834 (perp=8.695, rec=0.092, cos=0.003), tot_loss_proj:1.961 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.800 (perp=8.695, rec=0.058, cos=0.003), tot_loss_proj:1.941 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.817 (perp=8.695, rec=0.076, cos=0.003), tot_loss_proj:1.951 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.801 (perp=8.695, rec=0.060, cos=0.003), tot_loss_proj:1.938 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.812 (perp=8.695, rec=0.070, cos=0.003), tot_loss_proj:1.939 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.801 (perp=8.695, rec=0.060, cos=0.003), tot_loss_proj:1.945 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.807 (perp=8.695, rec=0.066, cos=0.003), tot_loss_proj:1.937 [t=0.20s]
prediction: ['[CLS] fascinating is [SEP]']
[ 600/2000] tot_loss=1.817 (perp=8.695, rec=0.076, cos=0.003), tot_loss_proj:1.946 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.797 (perp=8.695, rec=0.056, cos=0.003), tot_loss_proj:1.946 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.808 (perp=8.695, rec=0.067, cos=0.003), tot_loss_proj:1.950 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.804 (perp=8.695, rec=0.063, cos=0.003), tot_loss_proj:1.941 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.803 (perp=8.695, rec=0.061, cos=0.003), tot_loss_proj:1.944 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.817 (perp=8.695, rec=0.076, cos=0.003), tot_loss_proj:1.937 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.808 (perp=8.695, rec=0.067, cos=0.003), tot_loss_proj:1.942 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.807 (perp=8.695, rec=0.066, cos=0.003), tot_loss_proj:1.942 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.807 (perp=8.695, rec=0.066, cos=0.003), tot_loss_proj:1.942 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.812 (perp=8.695, rec=0.070, cos=0.003), tot_loss_proj:1.946 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.806 (perp=8.695, rec=0.065, cos=0.003), tot_loss_proj:1.954 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.804 (perp=8.695, rec=0.062, cos=0.003), tot_loss_proj:1.950 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.815 (perp=8.695, rec=0.073, cos=0.003), tot_loss_proj:1.942 [t=0.23s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.817 (perp=8.695, rec=0.076, cos=0.003), tot_loss_proj:1.950 [t=0.27s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.800 (perp=8.695, rec=0.058, cos=0.003), tot_loss_proj:1.946 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.806 (perp=8.695, rec=0.065, cos=0.003), tot_loss_proj:1.934 [t=0.25s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.795 (perp=8.695, rec=0.053, cos=0.003), tot_loss_proj:1.949 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.801 (perp=8.695, rec=0.059, cos=0.003), tot_loss_proj:1.946 [t=0.19s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.800 (perp=8.695, rec=0.059, cos=0.003), tot_loss_proj:1.945 [t=0.21s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.805 (perp=8.695, rec=0.064, cos=0.003), tot_loss_proj:1.938 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.797 (perp=8.695, rec=0.056, cos=0.003), tot_loss_proj:1.941 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.809 (perp=8.695, rec=0.068, cos=0.003), tot_loss_proj:1.950 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.811 (perp=8.695, rec=0.069, cos=0.003), tot_loss_proj:1.944 [t=0.26s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.810 (perp=8.695, rec=0.069, cos=0.003), tot_loss_proj:1.947 [t=0.24s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.801 (perp=8.695, rec=0.060, cos=0.003), tot_loss_proj:1.948 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.799 (perp=8.695, rec=0.057, cos=0.003), tot_loss_proj:1.945 [t=0.20s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.805 (perp=8.695, rec=0.063, cos=0.003), tot_loss_proj:1.947 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.815 (perp=8.695, rec=0.074, cos=0.003), tot_loss_proj:1.934 [t=0.22s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.809 (perp=8.695, rec=0.068, cos=0.003), tot_loss_proj:1.940 [t=0.18s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 87.373 | p: 87.012 | r: 87.900
rouge2     | fm: 51.979 | p: 51.828 | r: 52.225
rougeL     | fm: 75.939 | p: 75.644 | r: 76.396
rougeLsum  | fm: 76.003 | p: 75.700 | r: 76.407
r1fm+r2fm = 139.352

input #79 time: 0:08:06 | total time: 11:09:40


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9987480038905678
highest_index [0]
highest [0.9987480038905678]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 0.9977945685386658 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 0.9940215349197388 for ['[CLS] breath difference sensitiveosity higher [SEP]']
[Init] best rec loss: 0.9695504307746887 for ['[CLS] water takinge bonnie ca [SEP]']
[Init] best rec loss: 0.9116494655609131 for ['[CLS] team joined target * results [SEP]']
[Init] best perm rec loss: 0.9081062078475952 for ['[CLS] results joined team target * [SEP]']
[Init] best perm rec loss: 0.9046464562416077 for ['[CLS] target * results joined team [SEP]']
[Init] best perm rec loss: 0.9042615294456482 for ['[CLS] joined results target * team [SEP]']
[Init] best perm rec loss: 0.9035986661911011 for ['[CLS] target joined results * team [SEP]']
[Init] best perm rec loss: 0.9026069641113281 for ['[CLS] team results target joined * [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.650 (perp=12.124, rec=0.219, cos=0.006), tot_loss_proj:3.991 [t=0.31s]
prediction: ['[CLS] might wise jacobzenzen [SEP]']
[ 100/2000] tot_loss=1.914 (perp=8.829, rec=0.144, cos=0.004), tot_loss_proj:2.397 [t=0.18s]
prediction: ['[CLS] wise wise,zened [SEP]']
[ 150/2000] tot_loss=2.017 (perp=9.465, rec=0.121, cos=0.003), tot_loss_proj:2.597 [t=0.20s]
prediction: ['[CLS] wi wise,zened [SEP]']
[ 200/2000] tot_loss=1.994 (perp=9.465, rec=0.098, cos=0.003), tot_loss_proj:2.574 [t=0.17s]
prediction: ['[CLS] wi wise,zened [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.410 (perp=6.600, rec=0.087, cos=0.003), tot_loss_proj:1.387 [t=0.21s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 300/2000] tot_loss=1.383 (perp=6.600, rec=0.060, cos=0.003), tot_loss_proj:1.385 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.385 (perp=6.600, rec=0.062, cos=0.003), tot_loss_proj:1.391 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.383 (perp=6.600, rec=0.060, cos=0.003), tot_loss_proj:1.380 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 450/2000] tot_loss=1.390 (perp=6.600, rec=0.067, cos=0.003), tot_loss_proj:1.370 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.378 (perp=6.600, rec=0.055, cos=0.003), tot_loss_proj:1.388 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.385 (perp=6.600, rec=0.062, cos=0.002), tot_loss_proj:1.374 [t=0.24s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 600/2000] tot_loss=1.390 (perp=6.600, rec=0.067, cos=0.003), tot_loss_proj:1.382 [t=0.19s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.396 (perp=6.600, rec=0.073, cos=0.003), tot_loss_proj:1.384 [t=0.27s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.392 (perp=6.600, rec=0.069, cos=0.002), tot_loss_proj:1.381 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 750/2000] tot_loss=1.385 (perp=6.600, rec=0.063, cos=0.003), tot_loss_proj:1.395 [t=0.20s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.378 (perp=6.600, rec=0.056, cos=0.002), tot_loss_proj:1.384 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.371 (perp=6.600, rec=0.049, cos=0.003), tot_loss_proj:1.398 [t=0.25s]
prediction: ['[CLS] wise, wizened [SEP]']
[ 900/2000] tot_loss=1.375 (perp=6.600, rec=0.052, cos=0.002), tot_loss_proj:1.381 [t=0.23s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.385 (perp=6.600, rec=0.063, cos=0.003), tot_loss_proj:1.383 [t=0.23s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1000/2000] tot_loss=1.382 (perp=6.600, rec=0.059, cos=0.002), tot_loss_proj:1.391 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1050/2000] tot_loss=1.368 (perp=6.600, rec=0.045, cos=0.003), tot_loss_proj:1.390 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1100/2000] tot_loss=1.386 (perp=6.600, rec=0.063, cos=0.002), tot_loss_proj:1.388 [t=0.21s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1150/2000] tot_loss=1.390 (perp=6.600, rec=0.067, cos=0.003), tot_loss_proj:1.393 [t=0.19s]
prediction: ['[CLS] wise, wizened [SEP]']
[1200/2000] tot_loss=1.395 (perp=6.600, rec=0.072, cos=0.003), tot_loss_proj:1.385 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1250/2000] tot_loss=1.382 (perp=6.600, rec=0.059, cos=0.002), tot_loss_proj:1.390 [t=0.19s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1300/2000] tot_loss=1.378 (perp=6.600, rec=0.055, cos=0.002), tot_loss_proj:1.375 [t=0.23s]
prediction: ['[CLS] wise, wizened [SEP]']
[1350/2000] tot_loss=1.383 (perp=6.600, rec=0.061, cos=0.003), tot_loss_proj:1.382 [t=0.23s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1400/2000] tot_loss=1.382 (perp=6.600, rec=0.059, cos=0.003), tot_loss_proj:1.386 [t=0.20s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1450/2000] tot_loss=1.375 (perp=6.600, rec=0.052, cos=0.003), tot_loss_proj:1.386 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1500/2000] tot_loss=1.375 (perp=6.600, rec=0.052, cos=0.003), tot_loss_proj:1.382 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1550/2000] tot_loss=1.380 (perp=6.600, rec=0.058, cos=0.002), tot_loss_proj:1.390 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1600/2000] tot_loss=1.377 (perp=6.600, rec=0.055, cos=0.003), tot_loss_proj:1.385 [t=0.22s]
prediction: ['[CLS] wise, wizened [SEP]']
[1650/2000] tot_loss=1.394 (perp=6.600, rec=0.071, cos=0.003), tot_loss_proj:1.386 [t=0.21s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1700/2000] tot_loss=1.401 (perp=6.600, rec=0.078, cos=0.002), tot_loss_proj:1.379 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1750/2000] tot_loss=1.373 (perp=6.600, rec=0.050, cos=0.003), tot_loss_proj:1.383 [t=0.19s]
prediction: ['[CLS] wise, wizened [SEP]']
[1800/2000] tot_loss=1.387 (perp=6.600, rec=0.065, cos=0.003), tot_loss_proj:1.382 [t=0.29s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1850/2000] tot_loss=1.388 (perp=6.600, rec=0.066, cos=0.003), tot_loss_proj:1.385 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1900/2000] tot_loss=1.375 (perp=6.600, rec=0.052, cos=0.002), tot_loss_proj:1.388 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
[1950/2000] tot_loss=1.381 (perp=6.600, rec=0.058, cos=0.003), tot_loss_proj:1.393 [t=0.20s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[2000/2000] tot_loss=1.389 (perp=6.600, rec=0.066, cos=0.003), tot_loss_proj:1.397 [t=0.18s]
prediction: ['[CLS] wise, wizened [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise, wizened [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.563 | p: 87.222 | r: 87.973
rouge2     | fm: 52.688 | p: 52.404 | r: 52.990
rougeL     | fm: 76.243 | p: 75.923 | r: 76.627
rougeLsum  | fm: 76.179 | p: 75.897 | r: 76.614
r1fm+r2fm = 140.251

input #80 time: 0:08:19 | total time: 11:17:59


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9984986014758995
highest_index [0]
highest [0.9984986014758995]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 0.9742360711097717 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 0.9546219706535339 for ['[CLS] hobbs : kahn closer invest rico [SEP]']
[Init] best rec loss: 0.9178598523139954 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 0.8557240962982178 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 0.851129412651062 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 0.821988582611084 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 0.803912878036499 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 0.7934362888336182 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best rec loss: 0.7930687069892883 for ['[CLS] commandant ryder reporters might collections value [SEP]']
[Init] best perm rec loss: 0.791967511177063 for ['[CLS] might collections commandant ryder value reporters [SEP]']
[Init] best perm rec loss: 0.7908333539962769 for ['[CLS] collections might reporters commandant ryder value [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.505 (perp=11.040, rec=0.262, cos=0.034), tot_loss_proj:2.935 [t=0.17s]
prediction: ['[CLS] not largest player impressive sonya is [SEP]']
[ 100/2000] tot_loss=2.023 (perp=9.502, rec=0.115, cos=0.008), tot_loss_proj:2.696 [t=0.17s]
prediction: ['[CLS] not most player impressive player is [SEP]']
[ 150/2000] tot_loss=2.009 (perp=9.502, rec=0.102, cos=0.007), tot_loss_proj:2.698 [t=0.24s]
prediction: ['[CLS] not most player impressive player is [SEP]']
[ 200/2000] tot_loss=1.999 (perp=9.502, rec=0.093, cos=0.006), tot_loss_proj:2.686 [t=0.17s]
prediction: ['[CLS] not most player impressive player is [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.933 (perp=9.249, rec=0.079, cos=0.004), tot_loss_proj:2.432 [t=0.18s]
prediction: ['[CLS] not most impressive the is player [SEP]']
[ 300/2000] tot_loss=1.916 (perp=9.249, rec=0.064, cos=0.003), tot_loss_proj:2.432 [t=0.18s]
prediction: ['[CLS] not most impressive the is player [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.403 (perp=6.674, rec=0.065, cos=0.003), tot_loss_proj:1.947 [t=0.21s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.408 (perp=6.674, rec=0.070, cos=0.003), tot_loss_proj:1.945 [t=0.21s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[ 450/2000] tot_loss=1.401 (perp=6.674, rec=0.064, cos=0.003), tot_loss_proj:1.949 [t=0.21s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.413 (perp=6.674, rec=0.076, cos=0.003), tot_loss_proj:1.946 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.400 (perp=6.674, rec=0.062, cos=0.003), tot_loss_proj:1.945 [t=0.24s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[ 600/2000] tot_loss=1.412 (perp=6.674, rec=0.074, cos=0.003), tot_loss_proj:1.944 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.392 (perp=6.674, rec=0.055, cos=0.003), tot_loss_proj:1.948 [t=0.22s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.405 (perp=6.674, rec=0.067, cos=0.003), tot_loss_proj:1.944 [t=0.17s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[ 750/2000] tot_loss=1.399 (perp=6.674, rec=0.062, cos=0.003), tot_loss_proj:1.954 [t=0.21s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.400 (perp=6.674, rec=0.063, cos=0.003), tot_loss_proj:1.951 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.398 (perp=6.674, rec=0.060, cos=0.003), tot_loss_proj:1.953 [t=0.19s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[ 900/2000] tot_loss=1.389 (perp=6.674, rec=0.051, cos=0.003), tot_loss_proj:1.947 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.400 (perp=6.674, rec=0.063, cos=0.003), tot_loss_proj:1.948 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1000/2000] tot_loss=1.418 (perp=6.674, rec=0.080, cos=0.003), tot_loss_proj:1.948 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1050/2000] tot_loss=1.402 (perp=6.674, rec=0.064, cos=0.003), tot_loss_proj:1.953 [t=0.28s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1100/2000] tot_loss=1.407 (perp=6.674, rec=0.070, cos=0.003), tot_loss_proj:1.948 [t=0.22s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1150/2000] tot_loss=1.405 (perp=6.674, rec=0.067, cos=0.003), tot_loss_proj:1.954 [t=0.24s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1200/2000] tot_loss=1.397 (perp=6.674, rec=0.060, cos=0.003), tot_loss_proj:1.952 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1250/2000] tot_loss=1.407 (perp=6.674, rec=0.070, cos=0.003), tot_loss_proj:1.948 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1300/2000] tot_loss=1.400 (perp=6.674, rec=0.063, cos=0.003), tot_loss_proj:1.949 [t=0.19s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1350/2000] tot_loss=1.399 (perp=6.674, rec=0.061, cos=0.003), tot_loss_proj:1.951 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1400/2000] tot_loss=1.396 (perp=6.674, rec=0.059, cos=0.003), tot_loss_proj:1.951 [t=0.24s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1450/2000] tot_loss=1.397 (perp=6.674, rec=0.060, cos=0.003), tot_loss_proj:1.950 [t=0.19s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1500/2000] tot_loss=1.397 (perp=6.674, rec=0.059, cos=0.003), tot_loss_proj:1.955 [t=0.20s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1550/2000] tot_loss=1.398 (perp=6.674, rec=0.060, cos=0.003), tot_loss_proj:1.950 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1600/2000] tot_loss=1.406 (perp=6.674, rec=0.069, cos=0.003), tot_loss_proj:1.953 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1650/2000] tot_loss=1.405 (perp=6.674, rec=0.067, cos=0.003), tot_loss_proj:1.952 [t=0.20s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1700/2000] tot_loss=1.400 (perp=6.674, rec=0.062, cos=0.003), tot_loss_proj:1.951 [t=0.25s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1750/2000] tot_loss=1.393 (perp=6.674, rec=0.055, cos=0.003), tot_loss_proj:1.956 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1800/2000] tot_loss=1.400 (perp=6.674, rec=0.062, cos=0.003), tot_loss_proj:1.952 [t=0.27s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1850/2000] tot_loss=1.402 (perp=6.674, rec=0.064, cos=0.003), tot_loss_proj:1.946 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[1900/2000] tot_loss=1.404 (perp=6.674, rec=0.066, cos=0.003), tot_loss_proj:1.948 [t=0.20s]
prediction: ['[CLS] not most impressive is the player [SEP]']
[1950/2000] tot_loss=1.400 (perp=6.674, rec=0.062, cos=0.003), tot_loss_proj:1.953 [t=0.21s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Attempt swap
[2000/2000] tot_loss=1.392 (perp=6.674, rec=0.054, cos=0.003), tot_loss_proj:1.950 [t=0.18s]
prediction: ['[CLS] not most impressive is the player [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] not most impressive is the player [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 128.571

[Aggregate metrics]:
rouge1     | fm: 87.646 | p: 87.224 | r: 88.150
rouge2     | fm: 52.203 | p: 52.066 | r: 52.470
rougeL     | fm: 76.117 | p: 75.841 | r: 76.575
rougeLsum  | fm: 76.247 | p: 75.989 | r: 76.687
r1fm+r2fm = 139.849

input #81 time: 0:08:12 | total time: 11:26:12


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.99863601521229
highest_index [0]
highest [0.99863601521229]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 0.9843887090682983 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 0.9608476758003235 for ['[CLS] beck will parent stu rocks criteria roycenia [SEP]']
[Init] best rec loss: 0.9534676671028137 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 0.936395525932312 for ['[CLS] eve tucker itsch scout miles january ltd [SEP]']
[Init] best rec loss: 0.9355629682540894 for ['[CLS] task cadence extreme manchester internal direct mann alpine [SEP]']
[Init] best rec loss: 0.9319106340408325 for ['[CLS] ecclesiastical novel pre £ moi data push fran [SEP]']
[Init] best rec loss: 0.9273415207862854 for ['[CLS] bedroomroup hose reece acherade rightsie [SEP]']
[Init] best rec loss: 0.918695867061615 for ['[CLS] worse terms everyday down sandsbed supporting due [SEP]']
[Init] best rec loss: 0.898270308971405 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 0.8914811611175537 for ['[CLS] letter babyturnesian eric a distribution soft [SEP]']
[Init] best rec loss: 0.8659842014312744 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 0.8623151183128357 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 0.8621646165847778 for ['[CLS] plumagebasket respective record role whoeverachfur [SEP]']
[Init] best perm rec loss: 0.8581798076629639 for ['[CLS]basket respective whoever recordfur plumage roleach [SEP]']
[Init] best perm rec loss: 0.8562752604484558 for ['[CLS]basketach recordfur respective role plumage whoever [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.345 (perp=10.669, rec=0.200, cos=0.011), tot_loss_proj:2.746 [t=0.17s]
prediction: ["[CLS] undone by'sloppy scriptness undone undone [SEP]"]
[ 100/2000] tot_loss=2.223 (perp=10.567, rec=0.103, cos=0.006), tot_loss_proj:2.538 [t=0.22s]
prediction: ['[CLS] undone s a sloppy script by undone sloppy [SEP]']
[ 150/2000] tot_loss=2.202 (perp=10.567, rec=0.084, cos=0.004), tot_loss_proj:2.533 [t=0.19s]
prediction: ['[CLS] undone s a sloppy script by undone sloppy [SEP]']
[ 200/2000] tot_loss=2.204 (perp=10.567, rec=0.087, cos=0.004), tot_loss_proj:2.527 [t=0.18s]
prediction: ['[CLS] undone s a sloppy script by undone sloppy [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.815 (perp=8.587, rec=0.093, cos=0.005), tot_loss_proj:2.104 [t=0.29s]
prediction: ['[CLS] undone s a sloppy script undone by it [SEP]']
[ 300/2000] tot_loss=1.801 (perp=8.587, rec=0.080, cos=0.004), tot_loss_proj:2.117 [t=0.18s]
prediction: ['[CLS] undone s a sloppy script undone by it [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.652 (perp=7.878, rec=0.073, cos=0.004), tot_loss_proj:2.082 [t=0.18s]
prediction: ['[CLS] it s a sloppy script undone by undone [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.657 (perp=7.878, rec=0.077, cos=0.004), tot_loss_proj:2.088 [t=0.24s]
prediction: ['[CLS] it s a sloppy script undone by undone [SEP]']
[ 450/2000] tot_loss=1.648 (perp=7.878, rec=0.069, cos=0.003), tot_loss_proj:2.081 [t=0.18s]
prediction: ['[CLS] it s a sloppy script undone by undone [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.653 (perp=7.878, rec=0.074, cos=0.003), tot_loss_proj:2.099 [t=0.18s]
prediction: ['[CLS] it s a sloppy script undone by undone [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.658 (perp=7.878, rec=0.080, cos=0.003), tot_loss_proj:2.082 [t=0.17s]
prediction: ['[CLS] it s a sloppy script undone by undone [SEP]']
[ 600/2000] tot_loss=1.649 (perp=7.878, rec=0.070, cos=0.004), tot_loss_proj:2.086 [t=0.18s]
prediction: ['[CLS] it s a sloppy script undone by undone [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.656 (perp=7.878, rec=0.077, cos=0.004), tot_loss_proj:2.080 [t=0.25s]
prediction: ['[CLS] it s a sloppy script undone by undone [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.656 (perp=7.878, rec=0.076, cos=0.004), tot_loss_proj:2.082 [t=0.18s]
prediction: ['[CLS] it s a sloppy script undone by undone [SEP]']
[ 750/2000] tot_loss=1.916 (perp=9.168, rec=0.078, cos=0.004), tot_loss_proj:2.373 [t=0.27s]
prediction: ["[CLS] it s a sloppy script'by undone [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.507 (perp=7.150, rec=0.073, cos=0.004), tot_loss_proj:1.907 [t=0.19s]
prediction: ["[CLS] it s a sloppy script undone by'[SEP]"]
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.199 (perp=5.631, rec=0.068, cos=0.004), tot_loss_proj:1.469 [t=0.22s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[ 900/2000] tot_loss=1.201 (perp=5.631, rec=0.071, cos=0.004), tot_loss_proj:1.461 [t=0.26s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.204 (perp=5.631, rec=0.074, cos=0.004), tot_loss_proj:1.470 [t=0.21s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.201 (perp=5.631, rec=0.071, cos=0.003), tot_loss_proj:1.473 [t=0.18s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1050/2000] tot_loss=1.195 (perp=5.631, rec=0.065, cos=0.004), tot_loss_proj:1.475 [t=0.24s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.209 (perp=5.631, rec=0.079, cos=0.004), tot_loss_proj:1.469 [t=0.18s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.200 (perp=5.631, rec=0.070, cos=0.004), tot_loss_proj:1.461 [t=0.26s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1200/2000] tot_loss=1.180 (perp=5.631, rec=0.050, cos=0.004), tot_loss_proj:1.463 [t=0.23s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.200 (perp=5.631, rec=0.070, cos=0.004), tot_loss_proj:1.460 [t=0.18s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.199 (perp=5.631, rec=0.069, cos=0.004), tot_loss_proj:1.463 [t=0.18s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1350/2000] tot_loss=1.198 (perp=5.631, rec=0.068, cos=0.004), tot_loss_proj:1.467 [t=0.21s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.196 (perp=5.631, rec=0.066, cos=0.004), tot_loss_proj:1.460 [t=0.24s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.202 (perp=5.631, rec=0.072, cos=0.004), tot_loss_proj:1.477 [t=0.20s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1500/2000] tot_loss=1.207 (perp=5.631, rec=0.076, cos=0.004), tot_loss_proj:1.473 [t=0.20s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.202 (perp=5.631, rec=0.072, cos=0.004), tot_loss_proj:1.465 [t=0.18s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.194 (perp=5.631, rec=0.064, cos=0.004), tot_loss_proj:1.470 [t=0.19s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1650/2000] tot_loss=1.196 (perp=5.631, rec=0.066, cos=0.004), tot_loss_proj:1.469 [t=0.22s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.198 (perp=5.631, rec=0.068, cos=0.004), tot_loss_proj:1.463 [t=0.23s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.202 (perp=5.631, rec=0.072, cos=0.004), tot_loss_proj:1.465 [t=0.22s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1800/2000] tot_loss=1.194 (perp=5.631, rec=0.064, cos=0.004), tot_loss_proj:1.458 [t=0.18s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.205 (perp=5.631, rec=0.075, cos=0.004), tot_loss_proj:1.457 [t=0.27s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.196 (perp=5.631, rec=0.065, cos=0.004), tot_loss_proj:1.473 [t=0.19s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
[1950/2000] tot_loss=1.198 (perp=5.631, rec=0.068, cos=0.004), tot_loss_proj:1.469 [t=0.18s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.200 (perp=5.631, rec=0.070, cos=0.004), tot_loss_proj:1.460 [t=0.19s]
prediction: ["[CLS] it's a sloppy script undone by [SEP]"]
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it's a sloppy script undone by [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 87.872 | p: 87.500 | r: 88.387
rouge2     | fm: 52.272 | p: 52.060 | r: 52.535
rougeL     | fm: 76.267 | p: 75.993 | r: 76.723
rougeLsum  | fm: 76.274 | p: 75.984 | r: 76.709
r1fm+r2fm = 140.144

input #82 time: 0:08:12 | total time: 11:34:25


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9986631109670183
highest_index [0]
highest [0.9986631109670183]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 0.8486083149909973 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 0.8318814635276794 for ['[CLS] singles bradown entering barcelona el turn® rowan courtney [SEP]']
[Init] best rec loss: 0.8272258043289185 for ['[CLS] validity alice sport bible coast lough malta large systemx [SEP]']
[Init] best rec loss: 0.8093687891960144 for ['[CLS] floodax aboriginal mali wisconsin na rain basket missed call [SEP]']
[Init] best rec loss: 0.7773576378822327 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best rec loss: 0.7732770442962646 for ['[CLS] feeling johnny breaking xavier [CLS] us nash jamie quality something [SEP]']
[Init] best perm rec loss: 0.7699206471443176 for ['[CLS] johnny feeling breaking us xavier something [CLS] jamie quality nash [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.077 (perp=8.722, rec=0.305, cos=0.028), tot_loss_proj:3.343 [t=0.18s]
prediction: ['[CLS] it feels it want what when of and want when [SEP]']
[ 100/2000] tot_loss=1.836 (perp=8.239, rec=0.179, cos=0.009), tot_loss_proj:2.510 [t=0.21s]
prediction: ['[CLS] know what it wants what when when grows wants it [SEP]']
[ 150/2000] tot_loss=1.665 (perp=7.720, rec=0.114, cos=0.007), tot_loss_proj:2.332 [t=0.19s]
prediction: ['[CLS] know what it wants be when when grows wants it [SEP]']
[ 200/2000] tot_loss=1.638 (perp=7.720, rec=0.090, cos=0.004), tot_loss_proj:2.316 [t=0.24s]
prediction: ['[CLS] know what it wants be when when grows wants it [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.363 (perp=6.333, rec=0.093, cos=0.003), tot_loss_proj:1.862 [t=0.22s]
prediction: ['[CLS] know what it wants be when when it grows to [SEP]']
[ 300/2000] tot_loss=1.339 (perp=6.333, rec=0.070, cos=0.003), tot_loss_proj:1.860 [t=0.18s]
prediction: ['[CLS] know what it wants be when when it grows to [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.151 (perp=5.338, rec=0.080, cos=0.003), tot_loss_proj:1.370 [t=0.25s]
prediction: ['[CLS] know what it wants to be when when it grows [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.060 (perp=4.888, rec=0.078, cos=0.004), tot_loss_proj:1.831 [t=0.21s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[ 450/2000] tot_loss=1.053 (perp=4.888, rec=0.072, cos=0.004), tot_loss_proj:1.855 [t=0.19s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.058 (perp=4.888, rec=0.077, cos=0.004), tot_loss_proj:1.858 [t=0.19s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.057 (perp=4.888, rec=0.076, cos=0.004), tot_loss_proj:1.866 [t=0.18s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[ 600/2000] tot_loss=1.059 (perp=4.888, rec=0.078, cos=0.003), tot_loss_proj:1.852 [t=0.28s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.067 (perp=4.888, rec=0.086, cos=0.003), tot_loss_proj:1.854 [t=0.18s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.051 (perp=4.888, rec=0.070, cos=0.003), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[ 750/2000] tot_loss=1.048 (perp=4.888, rec=0.067, cos=0.003), tot_loss_proj:1.851 [t=0.22s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.048 (perp=4.888, rec=0.067, cos=0.003), tot_loss_proj:1.843 [t=0.20s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.049 (perp=4.888, rec=0.068, cos=0.003), tot_loss_proj:1.847 [t=0.25s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[ 900/2000] tot_loss=1.055 (perp=4.888, rec=0.074, cos=0.003), tot_loss_proj:1.846 [t=0.23s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.050 (perp=4.888, rec=0.069, cos=0.003), tot_loss_proj:1.854 [t=0.21s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1000/2000] tot_loss=1.055 (perp=4.888, rec=0.074, cos=0.003), tot_loss_proj:1.852 [t=0.18s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[1050/2000] tot_loss=1.053 (perp=4.888, rec=0.072, cos=0.003), tot_loss_proj:1.848 [t=0.20s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1100/2000] tot_loss=1.062 (perp=4.888, rec=0.081, cos=0.003), tot_loss_proj:1.855 [t=0.23s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1150/2000] tot_loss=1.053 (perp=4.888, rec=0.073, cos=0.003), tot_loss_proj:1.844 [t=0.19s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[1200/2000] tot_loss=1.057 (perp=4.888, rec=0.076, cos=0.003), tot_loss_proj:1.847 [t=0.18s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1250/2000] tot_loss=1.054 (perp=4.888, rec=0.073, cos=0.003), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1300/2000] tot_loss=1.044 (perp=4.888, rec=0.063, cos=0.003), tot_loss_proj:1.848 [t=0.18s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[1350/2000] tot_loss=1.054 (perp=4.888, rec=0.073, cos=0.003), tot_loss_proj:1.853 [t=0.18s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1400/2000] tot_loss=1.059 (perp=4.888, rec=0.078, cos=0.003), tot_loss_proj:1.856 [t=0.20s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1450/2000] tot_loss=1.055 (perp=4.888, rec=0.074, cos=0.003), tot_loss_proj:1.854 [t=0.20s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[1500/2000] tot_loss=1.056 (perp=4.888, rec=0.075, cos=0.003), tot_loss_proj:1.854 [t=0.26s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1550/2000] tot_loss=1.048 (perp=4.888, rec=0.067, cos=0.003), tot_loss_proj:1.842 [t=0.22s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1600/2000] tot_loss=1.049 (perp=4.888, rec=0.068, cos=0.003), tot_loss_proj:1.847 [t=0.19s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[1650/2000] tot_loss=1.061 (perp=4.888, rec=0.080, cos=0.003), tot_loss_proj:1.853 [t=0.18s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1700/2000] tot_loss=1.060 (perp=4.888, rec=0.079, cos=0.003), tot_loss_proj:1.846 [t=0.20s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1750/2000] tot_loss=1.039 (perp=4.888, rec=0.058, cos=0.003), tot_loss_proj:1.845 [t=0.19s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[1800/2000] tot_loss=1.043 (perp=4.888, rec=0.062, cos=0.003), tot_loss_proj:1.850 [t=0.25s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1850/2000] tot_loss=1.059 (perp=4.888, rec=0.079, cos=0.003), tot_loss_proj:1.852 [t=0.22s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[1900/2000] tot_loss=1.050 (perp=4.888, rec=0.069, cos=0.003), tot_loss_proj:1.858 [t=0.18s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
[1950/2000] tot_loss=1.053 (perp=4.888, rec=0.072, cos=0.003), tot_loss_proj:1.856 [t=0.27s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Attempt swap
[2000/2000] tot_loss=1.053 (perp=4.888, rec=0.073, cos=0.003), tot_loss_proj:1.853 [t=0.18s]
prediction: ['[CLS] when know what it wants to be when it grows [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] when know what it wants to be when it grows [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 87.877 | p: 87.577 | r: 88.358
rouge2     | fm: 52.558 | p: 52.402 | r: 52.883
rougeL     | fm: 76.435 | p: 76.162 | r: 76.844
rougeLsum  | fm: 76.444 | p: 76.146 | r: 76.889
r1fm+r2fm = 140.436

input #83 time: 0:08:25 | total time: 11:42:50


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9986297184904014
highest_index [0]
highest [0.9986297184904014]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 0.9082749485969543 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 0.8948929905891418 for ['[CLS] primera criminalmost dynamic ride venue youtube [SEP]']
[Init] best rec loss: 0.8927007913589478 for ['[CLS] beauty seemed features dr son baked hm [SEP]']
[Init] best rec loss: 0.8825904726982117 for ['[CLS] between favourated performed hope politics misty [SEP]']
[Init] best rec loss: 0.8813948631286621 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 0.860543966293335 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 0.859039843082428 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 0.8539034128189087 for ['[CLS] competed shegl brick kill trade down [SEP]']
[Init] best rec loss: 0.8374924063682556 for ['[CLS] individual hung cold ¹...ught railroad [SEP]']
[Init] best rec loss: 0.8352344036102295 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 0.8243493437767029 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best perm rec loss: 0.822454571723938 for ['[CLS] caused infinite ca each goingiter its [SEP]']
[Init] best perm rec loss: 0.8222771286964417 for ['[CLS] each its caused infinite goingiter ca [SEP]']
[Init] best perm rec loss: 0.8213027715682983 for ['[CLS] ca going infinite caused itsiter each [SEP]']
[Init] best perm rec loss: 0.8185930252075195 for ['[CLS] ca its causediter each going infinite [SEP]']
[Init] best perm rec loss: 0.81855708360672 for ['[CLS] infinite goingiter each its ca caused [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.183 (perp=10.043, rec=0.162, cos=0.012), tot_loss_proj:2.584 [t=0.18s]
prediction: ['[CLS] people lost think think lost ability to [SEP]']
[ 100/2000] tot_loss=2.335 (perp=11.098, rec=0.110, cos=0.005), tot_loss_proj:2.911 [t=0.22s]
prediction: ['[CLS] people lost think think lost ability have [SEP]']
[ 150/2000] tot_loss=2.250 (perp=10.734, rec=0.098, cos=0.006), tot_loss_proj:2.994 [t=0.23s]
prediction: ['[CLS] people have think think lost ability have [SEP]']
[ 200/2000] tot_loss=2.026 (perp=9.651, rec=0.092, cos=0.003), tot_loss_proj:2.610 [t=0.18s]
prediction: ['[CLS] people have think to lost ability have [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.595 (perp=7.506, rec=0.090, cos=0.004), tot_loss_proj:2.036 [t=0.25s]
prediction: ['[CLS] people have think to have lost ability [SEP]']
[ 300/2000] tot_loss=1.581 (perp=7.506, rec=0.076, cos=0.003), tot_loss_proj:2.036 [t=0.27s]
prediction: ['[CLS] people have think to have lost ability [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.527 (perp=7.250, rec=0.074, cos=0.003), tot_loss_proj:2.110 [t=0.24s]
prediction: ['[CLS] people have to think have lost ability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.535 (perp=7.250, rec=0.081, cos=0.003), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] people have to think have lost ability [SEP]']
[ 450/2000] tot_loss=1.518 (perp=7.250, rec=0.065, cos=0.003), tot_loss_proj:2.109 [t=0.30s]
prediction: ['[CLS] people have to think have lost ability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.530 (perp=7.250, rec=0.077, cos=0.003), tot_loss_proj:2.113 [t=0.24s]
prediction: ['[CLS] people have to think have lost ability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.527 (perp=7.250, rec=0.074, cos=0.003), tot_loss_proj:2.117 [t=0.25s]
prediction: ['[CLS] people have to think have lost ability [SEP]']
[ 600/2000] tot_loss=1.525 (perp=7.250, rec=0.072, cos=0.003), tot_loss_proj:2.115 [t=0.23s]
prediction: ['[CLS] people have to think have lost ability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.517 (perp=7.250, rec=0.064, cos=0.003), tot_loss_proj:2.116 [t=0.25s]
prediction: ['[CLS] people have to think have lost ability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.527 (perp=7.250, rec=0.074, cos=0.003), tot_loss_proj:2.100 [t=0.25s]
prediction: ['[CLS] people have to think have lost ability [SEP]']
[ 750/2000] tot_loss=1.531 (perp=7.250, rec=0.078, cos=0.003), tot_loss_proj:2.097 [t=0.24s]
prediction: ['[CLS] people have to think have lost ability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.809 (perp=8.654, rec=0.075, cos=0.003), tot_loss_proj:2.310 [t=0.24s]
prediction: ['[CLS] people have the think have lost ability [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.628 (perp=7.725, rec=0.079, cos=0.003), tot_loss_proj:2.156 [t=0.21s]
prediction: ['[CLS] people have think have lost the ability [SEP]']
[ 900/2000] tot_loss=1.615 (perp=7.725, rec=0.066, cos=0.003), tot_loss_proj:2.151 [t=0.21s]
prediction: ['[CLS] people have think have lost the ability [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.481 (perp=6.984, rec=0.080, cos=0.003), tot_loss_proj:2.092 [t=0.18s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.477 (perp=6.984, rec=0.077, cos=0.003), tot_loss_proj:2.088 [t=0.22s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
[1050/2000] tot_loss=1.477 (perp=6.984, rec=0.077, cos=0.003), tot_loss_proj:2.092 [t=0.18s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.482 (perp=6.984, rec=0.082, cos=0.003), tot_loss_proj:2.086 [t=0.18s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.472 (perp=6.984, rec=0.072, cos=0.003), tot_loss_proj:2.081 [t=0.20s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
[1200/2000] tot_loss=1.476 (perp=6.984, rec=0.076, cos=0.003), tot_loss_proj:2.085 [t=0.21s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.477 (perp=6.984, rec=0.077, cos=0.003), tot_loss_proj:2.088 [t=0.25s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.484 (perp=6.984, rec=0.084, cos=0.003), tot_loss_proj:2.084 [t=0.24s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
[1350/2000] tot_loss=1.461 (perp=6.984, rec=0.061, cos=0.003), tot_loss_proj:2.086 [t=0.18s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.471 (perp=6.984, rec=0.071, cos=0.003), tot_loss_proj:2.088 [t=0.19s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.471 (perp=6.984, rec=0.071, cos=0.003), tot_loss_proj:2.079 [t=0.18s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
[1500/2000] tot_loss=1.472 (perp=6.984, rec=0.072, cos=0.003), tot_loss_proj:2.089 [t=0.22s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.466 (perp=6.984, rec=0.066, cos=0.003), tot_loss_proj:2.086 [t=0.21s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.481 (perp=6.984, rec=0.081, cos=0.003), tot_loss_proj:2.087 [t=0.24s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
[1650/2000] tot_loss=1.472 (perp=6.984, rec=0.072, cos=0.003), tot_loss_proj:2.085 [t=0.19s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.475 (perp=6.984, rec=0.074, cos=0.003), tot_loss_proj:2.084 [t=0.24s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.479 (perp=6.984, rec=0.079, cos=0.003), tot_loss_proj:2.082 [t=0.19s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
[1800/2000] tot_loss=1.469 (perp=6.984, rec=0.069, cos=0.003), tot_loss_proj:2.077 [t=0.26s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.470 (perp=6.984, rec=0.070, cos=0.003), tot_loss_proj:2.077 [t=0.21s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.472 (perp=6.984, rec=0.072, cos=0.003), tot_loss_proj:2.082 [t=0.25s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
[1950/2000] tot_loss=1.462 (perp=6.984, rec=0.062, cos=0.003), tot_loss_proj:2.083 [t=0.22s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.483 (perp=6.984, rec=0.083, cos=0.003), tot_loss_proj:2.089 [t=0.19s]
prediction: ['[CLS] have people think have lost the ability [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] have people think have lost the ability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 37.500 | p: 37.500 | r: 37.500
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 126.389

[Aggregate metrics]:
rouge1     | fm: 87.874 | p: 87.536 | r: 88.375
rouge2     | fm: 52.615 | p: 52.420 | r: 52.856
rougeL     | fm: 76.357 | p: 76.131 | r: 76.767
rougeLsum  | fm: 76.481 | p: 76.179 | r: 76.840
r1fm+r2fm = 140.488

input #84 time: 0:08:30 | total time: 11:51:20


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9985506832534591
highest_index [0]
highest [0.9985506832534591]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 0.9069356322288513 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 0.8954373598098755 for ['[CLS] sent okay too deep partition secrecy consolidated true shouldn our [SEP]']
[Init] best rec loss: 0.8908992409706116 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 0.8783498406410217 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 0.8494312167167664 for ['[CLS] thinks macau stand cam form halolic venture cannot vehicle [SEP]']
[Init] best rec loss: 0.8395583033561707 for ['[CLS]lete cecilcc goals bar [ rules man brodiestation [SEP]']
[Init] best rec loss: 0.8367152810096741 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best rec loss: 0.8355460166931152 for ['[CLS] sadly du follow / led mocking host watch upside mortimer [SEP]']
[Init] best perm rec loss: 0.8353604078292847 for ['[CLS] mocking follow mortimer sadly led / du upside host watch [SEP]']
[Init] best perm rec loss: 0.8343369960784912 for ['[CLS] sadly mocking mortimer host upside led follow watch du / [SEP]']
[Init] best perm rec loss: 0.8340490460395813 for ['[CLS] led sadly follow watch host / mortimer mocking upside du [SEP]']
[Init] best perm rec loss: 0.8335124850273132 for ['[CLS] follow host / mocking sadly mortimer du led upside watch [SEP]']
[Init] best perm rec loss: 0.8332040309906006 for ['[CLS] mocking du upside mortimer watch follow sadly host led / [SEP]']
[Init] best perm rec loss: 0.8322793245315552 for ['[CLS] / upside mortimer watch led host sadly mocking follow du [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.338 (perp=10.301, rec=0.259, cos=0.019), tot_loss_proj:3.952 [t=0.23s]
prediction: ['[CLS] unfortunately alsori good. also for very resistance good [SEP]']
[ 100/2000] tot_loss=1.684 (perp=7.782, rec=0.121, cos=0.007), tot_loss_proj:2.094 [t=0.27s]
prediction: ['[CLS] unfortunately also not very. also not very ireland good [SEP]']
[ 150/2000] tot_loss=1.967 (perp=8.299, rec=0.275, cos=0.033), tot_loss_proj:2.200 [t=0.18s]
prediction: ['[CLS] unfortunately it not very, also not s civil good [SEP]']
[ 200/2000] tot_loss=1.800 (perp=8.081, rec=0.172, cos=0.012), tot_loss_proj:3.324 [t=0.18s]
prediction: ['[CLS] unfortunately it not very, also not. rover good [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.638 (perp=7.482, rec=0.135, cos=0.007), tot_loss_proj:2.744 [t=0.24s]
prediction: ['[CLS] unfortunately it notlent, also not s very good [SEP]']
[ 300/2000] tot_loss=1.526 (perp=6.974, rec=0.126, cos=0.005), tot_loss_proj:3.075 [t=0.18s]
prediction: ['[CLS] unfortunately it not s, also not s very good [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.385 (perp=6.360, rec=0.109, cos=0.005), tot_loss_proj:2.226 [t=0.19s]
prediction: ['[CLS] unfortunately s not it, also not s very good [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.389 (perp=6.336, rec=0.116, cos=0.005), tot_loss_proj:3.043 [t=0.30s]
prediction: ['[CLS] unfortunately ( not also, it not s very good [SEP]']
[ 450/2000] tot_loss=1.412 (perp=6.490, rec=0.109, cos=0.005), tot_loss_proj:3.203 [t=0.18s]
prediction: ["[CLS] unfortunately'not also, it not s very good [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.590 (perp=7.395, rec=0.107, cos=0.004), tot_loss_proj:3.368 [t=0.19s]
prediction: ['[CLS] unfortunately not also, it notwives s very good [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.514 (perp=7.039, rec=0.102, cos=0.004), tot_loss_proj:2.456 [t=0.19s]
prediction: ['[CLS] unfortunately not also, it not swives very good [SEP]']
[ 600/2000] tot_loss=1.668 (perp=7.840, rec=0.096, cos=0.004), tot_loss_proj:3.448 [t=0.22s]
prediction: ['[CLS] unfortunately not also, it not s mater very good [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.600 (perp=7.493, rec=0.098, cos=0.004), tot_loss_proj:2.216 [t=0.20s]
prediction: ['[CLS] unfortunately not also, s not it mater very good [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.532 (perp=7.120, rec=0.104, cos=0.004), tot_loss_proj:3.384 [t=0.22s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
[ 750/2000] tot_loss=1.523 (perp=7.120, rec=0.094, cos=0.004), tot_loss_proj:3.387 [t=0.19s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.524 (perp=7.120, rec=0.096, cos=0.004), tot_loss_proj:3.381 [t=0.19s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.518 (perp=7.120, rec=0.090, cos=0.004), tot_loss_proj:3.388 [t=0.27s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
[ 900/2000] tot_loss=1.506 (perp=7.120, rec=0.078, cos=0.004), tot_loss_proj:3.383 [t=0.22s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.537 (perp=7.120, rec=0.108, cos=0.004), tot_loss_proj:3.381 [t=0.27s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[1000/2000] tot_loss=1.517 (perp=7.120, rec=0.088, cos=0.004), tot_loss_proj:3.382 [t=0.21s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
[1050/2000] tot_loss=1.520 (perp=7.120, rec=0.092, cos=0.004), tot_loss_proj:3.389 [t=0.25s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[1100/2000] tot_loss=1.519 (perp=7.120, rec=0.091, cos=0.004), tot_loss_proj:3.381 [t=0.25s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[1150/2000] tot_loss=1.507 (perp=7.120, rec=0.079, cos=0.004), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
[1200/2000] tot_loss=1.516 (perp=7.120, rec=0.087, cos=0.004), tot_loss_proj:3.386 [t=0.18s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[1250/2000] tot_loss=1.513 (perp=7.120, rec=0.085, cos=0.004), tot_loss_proj:3.381 [t=0.22s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[1300/2000] tot_loss=1.521 (perp=7.120, rec=0.092, cos=0.004), tot_loss_proj:3.380 [t=0.26s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
[1350/2000] tot_loss=1.525 (perp=7.120, rec=0.097, cos=0.004), tot_loss_proj:3.387 [t=0.18s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[1400/2000] tot_loss=1.513 (perp=7.120, rec=0.084, cos=0.004), tot_loss_proj:3.382 [t=0.18s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
[1450/2000] tot_loss=1.520 (perp=7.120, rec=0.091, cos=0.004), tot_loss_proj:3.386 [t=0.24s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
[1500/2000] tot_loss=1.510 (perp=7.120, rec=0.082, cos=0.004), tot_loss_proj:3.378 [t=0.18s]
prediction: ['[CLS] unfortunately not, s not it mater also very good [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=1.415 (perp=6.669, rec=0.077, cos=0.005), tot_loss_proj:1.863 [t=0.19s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
Attempt swap
[1600/2000] tot_loss=1.420 (perp=6.669, rec=0.081, cos=0.005), tot_loss_proj:1.870 [t=0.21s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
[1650/2000] tot_loss=1.437 (perp=6.669, rec=0.099, cos=0.005), tot_loss_proj:1.874 [t=0.20s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
Attempt swap
[1700/2000] tot_loss=1.439 (perp=6.669, rec=0.100, cos=0.005), tot_loss_proj:1.869 [t=0.21s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
Attempt swap
[1750/2000] tot_loss=1.429 (perp=6.669, rec=0.090, cos=0.005), tot_loss_proj:1.866 [t=0.23s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
[1800/2000] tot_loss=1.434 (perp=6.669, rec=0.095, cos=0.005), tot_loss_proj:1.873 [t=0.19s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
Attempt swap
[1850/2000] tot_loss=1.427 (perp=6.669, rec=0.089, cos=0.005), tot_loss_proj:1.866 [t=0.19s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
Attempt swap
[1900/2000] tot_loss=1.420 (perp=6.669, rec=0.082, cos=0.005), tot_loss_proj:1.863 [t=0.18s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
[1950/2000] tot_loss=1.426 (perp=6.669, rec=0.087, cos=0.005), tot_loss_proj:1.871 [t=0.19s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
Attempt swap
[2000/2000] tot_loss=1.419 (perp=6.669, rec=0.081, cos=0.005), tot_loss_proj:1.860 [t=0.19s]
prediction: ['[CLS] unfortunately not, it mater s not also very good [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately not, it mater s not also very good [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.000 | p: 81.818 | r: 100.000
rouge2     | fm: 33.333 | p: 30.000 | r: 37.500
rougeL     | fm: 80.000 | p: 72.727 | r: 88.889
rougeLsum  | fm: 80.000 | p: 72.727 | r: 88.889
r1fm+r2fm = 123.333

[Aggregate metrics]:
rouge1     | fm: 87.923 | p: 87.502 | r: 88.521
rouge2     | fm: 52.211 | p: 52.032 | r: 52.441
rougeL     | fm: 76.503 | p: 76.173 | r: 76.973
rougeLsum  | fm: 76.499 | p: 76.159 | r: 76.987
r1fm+r2fm = 140.134

input #85 time: 0:08:22 | total time: 11:59:43


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9987557246458922
highest_index [0]
highest [0.9987557246458922]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 0.9449472427368164 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 0.9074211120605469 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 0.9063612818717957 for ['[CLS]riding ad u [SEP]']
[Init] best rec loss: 0.831970751285553 for ['[CLS] hungarian retired invested [SEP]']
[Init] best rec loss: 0.8070420026779175 for ['[CLS] away 0 toby [SEP]']
[Init] best rec loss: 0.775634229183197 for ['[CLS] liberated round alright [SEP]']
[Init] best perm rec loss: 0.7707318663597107 for ['[CLS] round liberated alright [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.070 (perp=13.472, rec=0.327, cos=0.048), tot_loss_proj:3.820 [t=0.17s]
prediction: ['[CLS] integrity emotional biker [SEP]']
[ 100/2000] tot_loss=2.888 (perp=12.914, rec=0.271, cos=0.034), tot_loss_proj:2.809 [t=0.18s]
prediction: ['[CLS] clarity emotional inner [SEP]']
[ 150/2000] tot_loss=2.373 (perp=10.580, rec=0.206, cos=0.052), tot_loss_proj:2.655 [t=0.18s]
prediction: ['[CLS] clarity emotional editorial [SEP]']
[ 200/2000] tot_loss=2.681 (perp=12.083, rec=0.188, cos=0.076), tot_loss_proj:3.101 [t=0.25s]
prediction: ['[CLS] clarity emotional volcanic [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.476 (perp=10.949, rec=0.187, cos=0.099), tot_loss_proj:2.804 [t=0.24s]
prediction: ['[CLS] clarity emotionalurance [SEP]']
[ 300/2000] tot_loss=2.502 (perp=10.949, rec=0.194, cos=0.119), tot_loss_proj:2.808 [t=0.25s]
prediction: ['[CLS] clarity emotionalurance [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.495 (perp=10.949, rec=0.184, cos=0.121), tot_loss_proj:2.814 [t=0.18s]
prediction: ['[CLS] clarity emotionalurance [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.489 (perp=10.949, rec=0.177, cos=0.122), tot_loss_proj:2.810 [t=0.21s]
prediction: ['[CLS] clarity emotionalurance [SEP]']
[ 450/2000] tot_loss=2.484 (perp=10.949, rec=0.169, cos=0.125), tot_loss_proj:2.818 [t=0.18s]
prediction: ['[CLS] clarity emotionalurance [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.485 (perp=10.949, rec=0.172, cos=0.124), tot_loss_proj:2.807 [t=0.19s]
prediction: ['[CLS] clarity emotionalurance [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.511 (perp=10.949, rec=0.180, cos=0.141), tot_loss_proj:2.805 [t=0.26s]
prediction: ['[CLS] clarity emotionalurance [SEP]']
[ 600/2000] tot_loss=2.839 (perp=12.645, rec=0.168, cos=0.142), tot_loss_proj:2.936 [t=0.19s]
prediction: ['[CLS] clarity emotional gaelic [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.570 (perp=11.351, rec=0.233, cos=0.067), tot_loss_proj:2.833 [t=0.27s]
prediction: ['[CLS] emerging emotional clarity [SEP]']
Attempt swap
Put prefix at the end
[ 700/2000] tot_loss=2.567 (perp=11.410, rec=0.210, cos=0.075), tot_loss_proj:2.542 [t=0.18s]
prediction: ['[CLS] emotional clarity focal [SEP]']
[ 750/2000] tot_loss=2.546 (perp=11.199, rec=0.202, cos=0.104), tot_loss_proj:3.151 [t=0.25s]
prediction: ['[CLS] emotional clarityurance [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=2.432 (perp=10.607, rec=0.189, cos=0.121), tot_loss_proj:3.333 [t=0.25s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.414 (perp=10.607, rec=0.176, cos=0.117), tot_loss_proj:3.340 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
[ 900/2000] tot_loss=2.422 (perp=10.607, rec=0.182, cos=0.118), tot_loss_proj:3.331 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.416 (perp=10.607, rec=0.176, cos=0.119), tot_loss_proj:3.344 [t=0.23s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=2.414 (perp=10.607, rec=0.173, cos=0.120), tot_loss_proj:3.345 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
[1050/2000] tot_loss=2.411 (perp=10.607, rec=0.169, cos=0.121), tot_loss_proj:3.343 [t=0.27s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=2.418 (perp=10.607, rec=0.176, cos=0.120), tot_loss_proj:3.341 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=2.401 (perp=10.607, rec=0.160, cos=0.120), tot_loss_proj:3.339 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
[1200/2000] tot_loss=2.413 (perp=10.607, rec=0.169, cos=0.122), tot_loss_proj:3.344 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.408 (perp=10.607, rec=0.165, cos=0.121), tot_loss_proj:3.345 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.413 (perp=10.607, rec=0.170, cos=0.121), tot_loss_proj:3.340 [t=0.21s]
prediction: ['[CLS]urance emotional clarity [SEP]']
[1350/2000] tot_loss=2.422 (perp=10.607, rec=0.179, cos=0.122), tot_loss_proj:3.341 [t=0.24s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=2.409 (perp=10.607, rec=0.165, cos=0.122), tot_loss_proj:3.348 [t=0.19s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.415 (perp=10.607, rec=0.171, cos=0.123), tot_loss_proj:3.343 [t=0.25s]
prediction: ['[CLS]urance emotional clarity [SEP]']
[1500/2000] tot_loss=2.410 (perp=10.607, rec=0.166, cos=0.123), tot_loss_proj:3.338 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=2.417 (perp=10.607, rec=0.172, cos=0.123), tot_loss_proj:3.337 [t=0.23s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=2.430 (perp=10.607, rec=0.178, cos=0.131), tot_loss_proj:3.336 [t=0.26s]
prediction: ['[CLS]urance emotional clarity [SEP]']
[1650/2000] tot_loss=2.424 (perp=10.607, rec=0.170, cos=0.133), tot_loss_proj:3.340 [t=0.25s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.431 (perp=10.607, rec=0.177, cos=0.133), tot_loss_proj:3.340 [t=0.24s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.429 (perp=10.607, rec=0.175, cos=0.133), tot_loss_proj:3.350 [t=0.22s]
prediction: ['[CLS]urance emotional clarity [SEP]']
[1800/2000] tot_loss=2.416 (perp=10.607, rec=0.161, cos=0.134), tot_loss_proj:3.333 [t=0.21s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.430 (perp=10.607, rec=0.175, cos=0.134), tot_loss_proj:3.338 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.422 (perp=10.607, rec=0.167, cos=0.134), tot_loss_proj:3.337 [t=0.24s]
prediction: ['[CLS]urance emotional clarity [SEP]']
[1950/2000] tot_loss=2.418 (perp=10.607, rec=0.163, cos=0.134), tot_loss_proj:3.339 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=2.426 (perp=10.607, rec=0.171, cos=0.134), tot_loss_proj:3.341 [t=0.18s]
prediction: ['[CLS]urance emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS]urance emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 60.000 | p: 60.000 | r: 60.000
rougeLsum  | fm: 60.000 | p: 60.000 | r: 60.000
r1fm+r2fm = 80.000

[Aggregate metrics]:
rouge1     | fm: 87.797 | p: 87.397 | r: 88.406
rouge2     | fm: 51.528 | p: 51.267 | r: 51.834
rougeL     | fm: 76.339 | p: 75.992 | r: 76.859
rougeLsum  | fm: 76.295 | p: 75.964 | r: 76.806
r1fm+r2fm = 139.325

input #86 time: 0:08:18 | total time: 12:08:01


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9988947854031291
highest_index [0]
highest [0.9988947854031291]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 0.7518047094345093 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 0.726355791091919 for ['[CLS] calendar? [SEP]']
[Init] best rec loss: 0.6725279092788696 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 0.6542822122573853 for ['[CLS] action [MASK] [SEP]']
[Init] best rec loss: 0.647010326385498 for ['[CLS] distinct post [SEP]']
[Init] best rec loss: 0.6348424553871155 for ['[CLS] popularski [SEP]']
[Init] best rec loss: 0.6318566799163818 for ['[CLS] under fan [SEP]']
[Init] best rec loss: 0.6264094710350037 for ['[CLS] fall else [SEP]']
[Init] best rec loss: 0.6177725195884705 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.6009235382080078 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.671 (perp=7.258, rec=0.206, cos=0.013), tot_loss_proj:1.520 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[ 100/2000] tot_loss=1.542 (perp=7.258, rec=0.085, cos=0.005), tot_loss_proj:1.506 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.574 (perp=7.258, rec=0.091, cos=0.031), tot_loss_proj:1.510 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.506 (perp=7.258, rec=0.052, cos=0.002), tot_loss_proj:1.512 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.527 (perp=7.258, rec=0.066, cos=0.009), tot_loss_proj:1.519 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.511 (perp=7.258, rec=0.055, cos=0.004), tot_loss_proj:1.541 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.531 (perp=7.258, rec=0.072, cos=0.007), tot_loss_proj:1.524 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.525 (perp=7.258, rec=0.068, cos=0.005), tot_loss_proj:1.510 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.513 (perp=7.258, rec=0.058, cos=0.003), tot_loss_proj:1.521 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.515 (perp=7.258, rec=0.061, cos=0.003), tot_loss_proj:1.530 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.510 (perp=7.258, rec=0.055, cos=0.003), tot_loss_proj:1.535 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.512 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.515 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.522 (perp=7.258, rec=0.068, cos=0.003), tot_loss_proj:1.526 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.509 (perp=7.258, rec=0.055, cos=0.003), tot_loss_proj:1.518 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.517 (perp=7.258, rec=0.063, cos=0.002), tot_loss_proj:1.518 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.519 (perp=7.258, rec=0.065, cos=0.002), tot_loss_proj:1.524 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.512 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.515 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.503 (perp=7.258, rec=0.050, cos=0.002), tot_loss_proj:1.517 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.522 (perp=7.258, rec=0.068, cos=0.002), tot_loss_proj:1.530 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.504 (perp=7.258, rec=0.050, cos=0.002), tot_loss_proj:1.531 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.002), tot_loss_proj:1.524 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.521 (perp=7.258, rec=0.068, cos=0.002), tot_loss_proj:1.530 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.002), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.505 (perp=7.258, rec=0.051, cos=0.002), tot_loss_proj:1.519 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.510 (perp=7.258, rec=0.056, cos=0.002), tot_loss_proj:1.530 [t=0.27s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.002), tot_loss_proj:1.523 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.528 (perp=7.258, rec=0.074, cos=0.002), tot_loss_proj:1.517 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.525 (perp=7.258, rec=0.071, cos=0.002), tot_loss_proj:1.512 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.523 (perp=7.258, rec=0.069, cos=0.002), tot_loss_proj:1.520 [t=0.24s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.512 (perp=7.258, rec=0.058, cos=0.002), tot_loss_proj:1.526 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.516 (perp=7.258, rec=0.062, cos=0.002), tot_loss_proj:1.517 [t=0.22s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.508 (perp=7.258, rec=0.054, cos=0.002), tot_loss_proj:1.513 [t=0.21s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.520 (perp=7.258, rec=0.066, cos=0.002), tot_loss_proj:1.516 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.518 (perp=7.258, rec=0.064, cos=0.002), tot_loss_proj:1.519 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.522 (perp=7.258, rec=0.068, cos=0.002), tot_loss_proj:1.511 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.520 (perp=7.258, rec=0.066, cos=0.002), tot_loss_proj:1.521 [t=0.26s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.505 (perp=7.258, rec=0.052, cos=0.002), tot_loss_proj:1.535 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.002), tot_loss_proj:1.514 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.515 (perp=7.258, rec=0.061, cos=0.002), tot_loss_proj:1.520 [t=0.23s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.514 (perp=7.258, rec=0.060, cos=0.002), tot_loss_proj:1.513 [t=0.18s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.991 | p: 87.569 | r: 88.555
rouge2     | fm: 52.278 | p: 52.150 | r: 52.528
rougeL     | fm: 76.588 | p: 76.229 | r: 77.039
rougeLsum  | fm: 76.548 | p: 76.196 | r: 77.078
r1fm+r2fm = 140.269

input #87 time: 0:08:11 | total time: 12:16:12


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9986090981726718
highest_index [0]
highest [0.9986090981726718]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 0.9232344031333923 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 0.9161002039909363 for ['[CLS] cardinal thouzu under problems years engineering hms nickname i this stores as wicketsisen colours stands direct gap filmfare front feel issn score hedgede strike connected three photographed styledwave itarable footballer beatrice frighteningaina better rey creedta bucharest [SEP]']
[Init] best rec loss: 0.8983800411224365 for ['[CLS] duringties fore pest un space shoe bel voivodeship east francis ampbb influenced designed dr island ray players san silhouette overboard true relief troubles injured concern marvelrga [MASK] ordinary survive passagevert far shoot birth aw chemistry chores integral relatively edited [SEP]']
[Init] best rec loss: 0.891968846321106 for ['[CLS] broken paint fl camillecle cattle married debut critical bite correct surfaceiable evenian troupe knife metro ordered terrorism ss shaw mount normal unknown waiaea scene primary created roycenational freedom lit pandora holy other physical / worth expectations traffic & [SEP]']
[Init] best rec loss: 0.8870537877082825 for ['[CLS] rushed ward though ) level consul done fluorescent will speedpants holestitutederlandcake unwanted formed survived barren rajwhile spare recoverynagar kind rock noun guitar honesttom fin stay gardener lore windsor sense operations g climbicing conflict caste last [SEP]']
[Init] best rec loss: 0.8823618292808533 for ['[CLS] breed tick leave familiar reserve eu fresh featured court battingtic graves definitely. manor honorsept format colourorro laird april diego celeste surgery western realities longer domino keyboard fixed death addication talk game mexican eyed third run drama short middle [SEP]']
[Init] best perm rec loss: 0.8812401294708252 for ['[CLS]ept domino eu definitely third diego middle tick featured breed aprilorro format longer honorstic run fresh short surgery leave eyed laird western celeste batting realities. colour drama reserve talk gamedication death court familiar mexican ad graves keyboard fixed manor [SEP]']
[Init] best perm rec loss: 0.8803439736366272 for ['[CLS]dication featured longer realities eyed familiar court reserve definitely manor runorro format surgery domino mexican third. april colour keyboard ticktic middle laird short diego talk celeste drama game death graves battingept fixed eu western fresh breed honors ad leave [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.117 (perp=12.125, rec=0.449, cos=0.242), tot_loss_proj:4.320 [t=0.23s]
prediction: ['[CLS]! lose became the evil quiet christian the. ben symbol punk canyon. sports israel breaking. la minas league transferred advanced realizing worst french model village diaspora samantha understand emotions musical rope masters gain startup relationship patriot ourfolk [SEP] [SEP] [SEP]']
[ 100/2000] tot_loss=3.050 (perp=12.628, rec=0.352, cos=0.172), tot_loss_proj:4.410 [t=0.27s]
prediction: ['[CLS]! taylor alright the evil beautiful jordan [. : dysfunction daemon drought. singles israel catching. la minas league specializes strength. worst gymnastics model village mystery samantha understand emotionsstic stole folk gain romance travel sergei a sexual [SEP] von [SEP]']
[ 150/2000] tot_loss=2.946 (perp=12.291, rec=0.309, cos=0.178), tot_loss_proj:4.087 [t=0.25s]
prediction: ['[CLS]ly anderson alright lord evil beautiful jordan [ know % rarely symbol drought. generations israel the. la minas league specialized burst. worst daughters abel ) our great understands mutual of keynote joy gain romance travel understands a understand the von [SEP]']
[ 200/2000] tot_loss=2.885 (perp=12.061, rec=0.291, cos=0.182), tot_loss_proj:4.260 [t=0.26s]
prediction: ['[CLS]. anderson alright lord evil beautiful jordan [ know of enjoyed daemon blockade. what israel impressive. to minas league specialized of. worst daughters ள. our my understands mutual of keynote true powers romance tribute understands or, the von [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.605 (perp=10.832, rec=0.276, cos=0.163), tot_loss_proj:3.880 [t=0.19s]
prediction: ['[CLS]. anderson alright lord evil beautiful jordan william know of boycott daemon puget. we israel impressive. to using winner specialized of. worstricted ள community our my understands daughters of scrolls what powers romance lives understands as, the alex [SEP]']
[ 300/2000] tot_loss=2.508 (perp=10.433, rec=0.256, cos=0.165), tot_loss_proj:3.619 [t=0.18s]
prediction: ['[CLS]. anderson alright lord evil beautiful jordan t love successfully equivalence breadiful. we israel catches. pro using year specialized of you illricted ள. our. understands daughters of joy grand. romance lives calm the, the alex [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.452 (perp=10.181, rec=0.239, cos=0.178), tot_loss_proj:3.368 [t=0.19s]
prediction: ['[CLS]. anderson alright. calm beautiful jordan t know our curse agreement richie. we of remains. u using year specialized of you illricted ள community our. understands daughterss joy grand. romance lives calm that, the alex [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.360 (perp=9.861, rec=0.229, cos=0.159), tot_loss_proj:3.649 [t=0.23s]
prediction: ['[CLS]. anderson aristotle. calm beautiful jordan t love our advantage bread richie. ever facing how. u using year specialized love. ill graphs intended peoples our of understands daughterss joy grand. romance of calm how, the. [SEP]']
[ 450/2000] tot_loss=2.434 (perp=10.237, rec=0.225, cos=0.161), tot_loss_proj:3.676 [t=0.27s]
prediction: ['[CLS]. anderson aristotle t evil beautiful just t love daily advantage agreement richie. ever from how. u using year specialized love. ill graphs zeus peoples our and understands daughterss joy grand. romance and calm how, the alex [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.419 (perp=10.163, rec=0.226, cos=0.161), tot_loss_proj:3.680 [t=0.18s]
prediction: ['[CLS]. anderson aristotle t evil beautiful just t love daily advantage pueblo richie. ever from how. u using year specialized love. ill graphs zeus peoples our of understands daughterss grand joy. romance and calm how, the alex [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.559 (perp=10.837, rec=0.220, cos=0.172), tot_loss_proj:3.489 [t=0.24s]
prediction: ['[CLS]. anderson aristotle t calm. healthy t love daily advantage pueblo intrinsic. we of how beautiful u using year specialized love noticed ill graphs zeus peoples our of understands daughterss grand joy calm romance and calm how, the alex [SEP]']
[ 600/2000] tot_loss=2.485 (perp=10.499, rec=0.219, cos=0.167), tot_loss_proj:3.596 [t=0.27s]
prediction: ['[CLS]. anderson aristotle t calm. healthy t love daily bargaining pueblo intrinsic. we from how beautiful u using winner specialized love noticed ill graphs zeus capitals our of understands childhoods grandness calm romance and calm how that the j [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.434 (perp=10.240, rec=0.216, cos=0.170), tot_loss_proj:3.405 [t=0.25s]
prediction: ['[CLS]. anderson aristotle love evil. healthy t t daily embrace looks intrinsic. we from how beautiful u using year equally love noticed ill graphs shall capitals our of understands childhoods grandness calm romance and calm how, the alex [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.430 (perp=10.297, rec=0.207, cos=0.164), tot_loss_proj:3.201 [t=0.24s]
prediction: ['[CLS]. anderson aristotle love ill. hill t t daily embrace looks intrinsic. we from how beautiful u using year equally love noticed ill glover shall capitals our calm understands childhoodness grandness. romance and calm how was the alex [SEP]']
[ 750/2000] tot_loss=2.410 (perp=10.175, rec=0.206, cos=0.169), tot_loss_proj:3.243 [t=0.20s]
prediction: ['[CLS]. anderson aristotle love ill. hill t t daily embrace looks intrinsic. we from how beautiful u using yearize love noticed ill glover shall capitals our calm understands childhoods grandness. romance and calm how was the j [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.345 (perp=9.853, rec=0.199, cos=0.176), tot_loss_proj:3.335 [t=0.22s]
prediction: ['[CLS]. anderson things love ill. zeus t t daily napkin looks intrinsic. we from how beautiful u using yearize love noticed ill glover just capitals our calm understands childhoodness grandness. romance and calm how was the j [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.349 (perp=9.907, rec=0.201, cos=0.166), tot_loss_proj:3.238 [t=0.20s]
prediction: ['[CLS]. anderson things love ill. shall t t daily excellent looks intrinsic. we from how beautiful u using year was love noticed illneuve just capitals our calm understands childhoodness grandness. romance and calm howize the j [SEP]']
[ 900/2000] tot_loss=2.362 (perp=9.928, rec=0.197, cos=0.179), tot_loss_proj:3.309 [t=0.25s]
prediction: ['[CLS]. anderson things love ill. shall t t daily excellent war intrinsic. we from the beautiful u using year was love noticed illneuve andersonxi our calm understands childhoodness grandness. romance and calm howize the j [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.292 (perp=9.636, rec=0.195, cos=0.170), tot_loss_proj:3.282 [t=0.18s]
prediction: ['[CLS]. anderson things love ill. shall t t dailyize war intrinsic. we from the beautiful u using year was love noticed ill glover andersonxi our calm understands childhoodness grandness. romance and calm how enjoy the j [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=2.229 (perp=9.211, rec=0.207, cos=0.180), tot_loss_proj:3.064 [t=0.18s]
prediction: ['[CLS]. anderson things love ill. shall t t dailyize war intrinsic. ever from the beautiful u of year are love illneuve anderson capitals our calm corners understands childhoodness grandness. romance and calm how excellent the j [SEP]']
[1050/2000] tot_loss=2.242 (perp=9.344, rec=0.196, cos=0.177), tot_loss_proj:3.443 [t=0.24s]
prediction: ['[CLS]. anderson things love ill. shall t t dailyize war intrinsic. ever from the beautiful u of year are love illneuve anderson capitals our calm corners understands childhoodness grandness. romance and calm how napkin the j [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.230 (perp=9.323, rec=0.194, cos=0.172), tot_loss_proj:3.526 [t=0.18s]
prediction: ['[CLS]. anderson things love ill. t shall t dailyize war intrinsic. ever from the our u of year are love illneuve anderson capitals our calm corners understands childhoodness grandness. romance and calm how napkin the j [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.225 (perp=9.289, rec=0.194, cos=0.173), tot_loss_proj:3.442 [t=0.26s]
prediction: ['[CLS]. things love ill. t shall anderson t dailyize war intrinsic. ever from the our u of year are love ill glover andersonxi our calm corners understands childhoodness grandness. romance and calm how napkin the j [SEP]']
[1200/2000] tot_loss=2.227 (perp=9.255, rec=0.199, cos=0.176), tot_loss_proj:3.439 [t=0.19s]
prediction: ['[CLS]. things love ill. t shall anderson t dailyize war intrinsic. never from the our u of year are love ill glover andersonxi our calm corners understands childhoodness grandness. romance and calm how napkin the j [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=2.243 (perp=9.378, rec=0.194, cos=0.173), tot_loss_proj:3.480 [t=0.18s]
prediction: ['[CLS] glover things love ill. t zeus anderson t dailyize war intrinsic. never from the our u of year are love ill. andersonxi our calm corners understands ourness grandness. romance and calm how napkin the j [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.232 (perp=9.284, rec=0.195, cos=0.180), tot_loss_proj:3.450 [t=0.18s]
prediction: ['[CLS] glover things love ill. t zeus anderson t dailyize war neglected. never from the napkin u of year are love ill. andersonxi our calm corners understands childhoodness grandness. romance and calm how our the j [SEP]']
[1350/2000] tot_loss=2.184 (perp=9.082, rec=0.189, cos=0.178), tot_loss_proj:3.411 [t=0.18s]
prediction: ['[CLS] glover things love ill. t zeus anderson t dailyize war neglected. never from the napkin u of year are love ill. andersonxi our calm corners understands ourness grandness. romance and calm how our the j [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=2.134 (perp=8.852, rec=0.188, cos=0.176), tot_loss_proj:3.264 [t=0.19s]
prediction: ['[CLS] glover things love ill. t j anderson t dailyize war intrinsic. never from the napkin u of year are love ill. anderson capitals our calm corners understands ourness grandness. romance and calm how our the zeus [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=2.127 (perp=8.775, rec=0.192, cos=0.180), tot_loss_proj:3.169 [t=0.18s]
prediction: ['[CLS] glover things love ill. t j anderson t dailyize war intrinsic. never from the napkin u of year are love ill. andersonxi our calm corners understands ourness the grandness. romance and calm how our often [SEP]']
[1500/2000] tot_loss=2.111 (perp=8.775, rec=0.181, cos=0.175), tot_loss_proj:3.166 [t=0.19s]
prediction: ['[CLS] glover things love ill. t j anderson t dailyize war intrinsic. never from the napkin u of year are love ill. andersonxi our calm corners understands ourness the grandness. romance and calm how our often [SEP]']
Attempt swap
[1550/2000] tot_loss=2.112 (perp=8.775, rec=0.184, cos=0.174), tot_loss_proj:3.172 [t=0.18s]
prediction: ['[CLS] glover things love ill. t j anderson t dailyize war intrinsic. never from the napkin u of year are love ill. andersonxi our calm corners understands ourness the grandness. romance and calm how our often [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.071 (perp=8.554, rec=0.189, cos=0.172), tot_loss_proj:3.228 [t=0.19s]
prediction: ['[CLS] glover things love ill. t j anderson t dailyize war intrinsic. never from the napkin u of year how love ill. andersonxi our calm corners understands ourness the grandness. romance and calm are our often [SEP]']
[1650/2000] tot_loss=2.083 (perp=8.603, rec=0.185, cos=0.177), tot_loss_proj:3.234 [t=0.18s]
prediction: ['[CLS] glover things love ill. t j anderson t dailyize war intrinsic. never from how napkin u of year how love ill. anderson of our calm corners understands ourness the grandness. romance and calm are our often [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.048 (perp=8.494, rec=0.179, cos=0.170), tot_loss_proj:3.205 [t=0.20s]
prediction: ['[CLS] glover things love ill. t j anderson t dailyize war intrinsic. never from how corners u of year how love ill. anderson of our calm napkin understands ourness the grandness. romance and calm are our often [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=2.027 (perp=8.346, rec=0.186, cos=0.172), tot_loss_proj:3.161 [t=0.20s]
prediction: ['[CLS] glover things love ill. t j anderson t howize war intrinsic. never from daily corners u of year how love ill. anderson of our calm napkin understands ourness the grandness. romance and calm are our often [SEP]']
[1800/2000] tot_loss=2.028 (perp=8.346, rec=0.186, cos=0.172), tot_loss_proj:3.163 [t=0.25s]
prediction: ['[CLS] glover things love ill. t j anderson t howize war intrinsic. never from daily corners u of year how love ill. anderson of our calm napkin understands ourness the grandness. romance and calm are our often [SEP]']
Attempt swap
[1850/2000] tot_loss=2.044 (perp=8.453, rec=0.180, cos=0.173), tot_loss_proj:3.051 [t=0.18s]
prediction: ['[CLS] glover things love ill. t j anderson t theize war intrinsic. never from daily corners u of year how love ill. anderson of our calm excellent understands ourness the grandness. romance and calm are our often [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.023 (perp=8.335, rec=0.185, cos=0.171), tot_loss_proj:3.054 [t=0.20s]
prediction: ['[CLS] glover things love ill. t j anderson t the warize intrinsic. never of daily corners u of year how love ill. anderson of our calm excellent understands ourness the grandness. romance and calm are our often [SEP]']
[1950/2000] tot_loss=2.028 (perp=8.335, rec=0.190, cos=0.171), tot_loss_proj:3.057 [t=0.19s]
prediction: ['[CLS] glover things love ill. t j anderson t the warize intrinsic. never of daily corners u of year how love ill. anderson of our calm excellent understands ourness the grandness. romance and calm are our often [SEP]']
Attempt swap
[2000/2000] tot_loss=2.018 (perp=8.335, rec=0.180, cos=0.171), tot_loss_proj:3.056 [t=0.19s]
prediction: ['[CLS] glover things love ill. t j anderson t the warize intrinsic. never of daily corners u of year how love ill. anderson of our calm excellent understands ourness the grandness. romance and calm are our often [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] glover things love ill. t j anderson t howize war intrinsic. never from daily corners u of year how love ill. anderson of our calm napkin understands ourness the grandness. romance and calm are our often [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 47.368 | p: 47.368 | r: 47.368
rouge2     | fm: 10.811 | p: 10.811 | r: 10.811
rougeL     | fm: 28.947 | p: 28.947 | r: 28.947
rougeLsum  | fm: 28.947 | p: 28.947 | r: 28.947
r1fm+r2fm = 58.179

[Aggregate metrics]:
rouge1     | fm: 87.520 | p: 87.137 | r: 88.084
rouge2     | fm: 51.640 | p: 51.406 | r: 51.905
rougeL     | fm: 76.132 | p: 75.841 | r: 76.584
rougeLsum  | fm: 76.101 | p: 75.737 | r: 76.625
r1fm+r2fm = 139.160

input #88 time: 0:08:38 | total time: 12:24:51


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9985899972552212
highest_index [0]
highest [0.9985899972552212]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 0.9142111539840698 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 0.9115607738494873 for ['[CLS] has luck switzerland learning cbs passenger below brothersnp 22 ham american 2 daytona human / itself tight sales crooklen instant learning az meeting maintained viakey test adulterycraft their [SEP]']
[Init] best rec loss: 0.8957167863845825 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 0.8915572762489319 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 0.8755654096603394 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 0.8230676054954529 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 0.818994402885437 for ['[CLS] finally got wolf alan organizational 00pm or bra piketaff lack berlin circle nowhere chair temeraire sent movie thrust september wearing monster cartoon ang registrar secure until commons dimension surveyal island [SEP]']
[Init] best rec loss: 0.8186120390892029 for ['[CLS] palace " kinda downtown virginpid normally mystery claire wild didn variance straight friendly baby repeatomorphicamine still wantedjs acclaim * band ahead administration ltd tied pull parent santa blue [SEP]']
[Init] best rec loss: 0.8157274723052979 for ['[CLS] hundred patsy such bien water paint forest baseball flats gives hq hit raising key dominic sideer waiter { college subtropical words wheel who rhyme never was built globeqa dogs point [SEP]']
[Init] best perm rec loss: 0.8141710758209229 for ['[CLS] patsy paint baseball side wordser subtropical college waiter rhyme flats suchqa dogs dominic gives forest built hundred point was raising wheel { hit key globe bien water never hq who [SEP]']
[Init] best perm rec loss: 0.813689112663269 for ['[CLS] words hundred side wheel bien such forest dogs hq { paint gives key never patsy was waiterqa subtropical point water built who globe rhyme raising hit baseballer college dominic flats [SEP]']
[Init] best perm rec loss: 0.813347578048706 for ['[CLS] { dominicqa college words flats gives waser hundred rhyme built forest wheel bien raising point who water dogs hit subtropical key patsy hq globe never side such paint waiter baseball [SEP]']
[Init] best perm rec loss: 0.8114175200462341 for ['[CLS] { college globe was water key wheel waiter rhyme hundred baseball patsy words raising hit paint dominic never point hq subtropical bienqa flats whoer side built gives dogs forest such [SEP]']
[Init] best perm rec loss: 0.8098902106285095 for ['[CLS] raising paint water gives point baseball built flats subtropical never who hq hundred bien globe forest college patsy was side key dogs dominicqa hit { wheel waiter words rhyme sucher [SEP]']
[Init] best perm rec loss: 0.8087395429611206 for ['[CLS] paint raising built {er never hq baseball who globe gives dominic was such side key waiter rhyme wheel dogs forest subtropical hundredqa flats point water hit patsy bien college words [SEP]']
[Init] best perm rec loss: 0.8079832792282104 for ['[CLS] waiter dogs hit { globe patsy paint was bien wordserqa forest point raising wheel who hundred college dominic water key gives never baseball rhyme side built hq such subtropical flats [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.601 (perp=11.175, rec=0.344, cos=0.022), tot_loss_proj:3.380 [t=0.25s]
prediction: ['[CLS] concealed barely trap tactic political of has fact warfare tacticly fiona about these the verification tape swelling nearly worse blooded worse in sort that - out the hispanic < editorial idea [SEP]']
[ 100/2000] tot_loss=2.449 (perp=10.644, rec=0.302, cos=0.018), tot_loss_proj:3.023 [t=0.27s]
prediction: ['[CLS] tactic worse damaged tactic deadly - of fact affairs tacticly fiona about recording thewords up swelling nearly worse messages worse in worse that to out the concepts tactic - ideas [SEP]']
[ 150/2000] tot_loss=2.571 (perp=11.149, rec=0.324, cos=0.017), tot_loss_proj:3.238 [t=0.23s]
prediction: ['[CLS] lesson worsezziness tactic the ; of realm ں tactic poorly oclc merely recording the analysis hurt eyebrows several worse messages worse of worse that handed - the grown tactic picture ideas [SEP]']
[ 200/2000] tot_loss=2.785 (perp=11.024, rec=0.504, cos=0.076), tot_loss_proj:3.312 [t=0.22s]
prediction: ['[CLS] tactic ᆼ his tactic of mixtape of [SEP]‖ cover - sin poorly on the, cast bryce his worse gestapo worse [SEP] none vimes in at chill erebidae behaviour, ideas [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.632 (perp=10.912, rec=0.410, cos=0.039), tot_loss_proj:3.216 [t=0.18s]
prediction: ['[CLS] tactic ᆼ a tactic, mixtape of [SEP]‖ yelling - oclc de on the,uth nights his worse value worseouring none jonah in at cover erebidae behaviour, ideas [SEP]']
[ 300/2000] tot_loss=2.628 (perp=11.205, rec=0.363, cos=0.023), tot_loss_proj:3.465 [t=0.29s]
prediction: ['[CLS] tacticii a tactic those, of versus‖ doc - originally de on the,uth nights his worse value worseouring none grandpa in at cover horizon behaviour, ideas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.680 (perp=11.542, rec=0.351, cos=0.021), tot_loss_proj:3.496 [t=0.29s]
prediction: ['[CLS] tacticii a tacticuth, of or‖ doc - originally promo on the gmina the nights his worse value worse throughout none grandpa on at cover horizon behaviour d ideas [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.440 (perp=10.429, rec=0.335, cos=0.020), tot_loss_proj:3.412 [t=0.18s]
prediction: ['[CLS] theii a tacticed, of or‖ fide - originally apparently of the gmina remained nights worse throughout none grandpa on his worse value at cover horizon behaviour ; ideas [SEP]']
[ 450/2000] tot_loss=2.467 (perp=10.707, rec=0.311, cos=0.015), tot_loss_proj:3.219 [t=0.23s]
prediction: ['[CLS] theii a tacticin, of or‖ fide - originally among of the gmina remained nights worse using none grandpa on his worse value at cover horizon tactic ops ideas [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.397 (perp=10.430, rec=0.297, cos=0.015), tot_loss_proj:3.102 [t=0.23s]
prediction: ['[CLS] the - a tacticin, of or‖ fideii originally among of the gmina remained nights worse using none grandpa on his worse value at cover extent tactic metacritic ideas [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.391 (perp=10.429, rec=0.292, cos=0.013), tot_loss_proj:3.053 [t=0.19s]
prediction: ['[CLS] the - a tacticin of, or‖ flavoriiulously among of the gmina remained nights worse using none grandpa on his worse value at cover extent tactic thumbs ideas [SEP]']
[ 600/2000] tot_loss=2.337 (perp=10.197, rec=0.284, cos=0.014), tot_loss_proj:2.857 [t=0.18s]
prediction: ['[CLS] the - a tacticin of, or‖ flavoriiulously among of the smashwords space nights worse using none temple on his worse value at cover extent tactic against ideas [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.459 (perp=9.592, rec=0.468, cos=0.072), tot_loss_proj:2.877 [t=0.21s]
prediction: ['[CLS] the - a tactic [CLS] of, of‖ magnitude fl situation none of the -. nights worse depending none cover in his worse value at temple hairs tactic. ª [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.216 (perp=9.030, rec=0.377, cos=0.032), tot_loss_proj:2.738 [t=0.25s]
prediction: ['[CLS] the - a tactic in of motif, very‖ system fl being none of the -. worse getting none cover on his worse value at temple hairs build. balthazar [SEP]']
[ 750/2000] tot_loss=2.222 (perp=9.290, rec=0.343, cos=0.020), tot_loss_proj:2.970 [t=0.24s]
prediction: ['[CLS] the - a tactic in of motif, very‖mat viet being none of the - since worse getting none cover on his worse value at temple hairs layout. balthazar [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.135 (perp=8.956, rec=0.326, cos=0.017), tot_loss_proj:2.665 [t=0.25s]
prediction: ['[CLS] the worse a tactic in of motif, veryllemat viet being none of the - since - getting none cover on his worse value at temple hairs layout. balthazar [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.277 (perp=9.591, rec=0.337, cos=0.022), tot_loss_proj:2.782 [t=0.18s]
prediction: ['[CLS] the worse of tactic ofing motif, veryllemat. obviously wigan with the -. - using none cover in his worse value at campus sudden layout. balthazar [SEP]']
[ 900/2000] tot_loss=2.256 (perp=9.562, rec=0.323, cos=0.020), tot_loss_proj:2.780 [t=0.18s]
prediction: ['[CLS] the worse of tactic ofing motif, veryllemat. obviously wigan with the -. - using none cover on his worse value at campus sudden layout. balthazar [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=2.145 (perp=9.060, rec=0.315, cos=0.018), tot_loss_proj:2.658 [t=0.19s]
prediction: ['[CLS] the worse of tactic of motif, veryllemating. situation none with the -. - using none cover on his worse value at lecturer sudden layout. balthazar [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.050 (perp=8.533, rec=0.321, cos=0.022), tot_loss_proj:2.666 [t=0.18s]
prediction: ['[CLS] the worse of tactic of motif, very situation none with thellemating. - because - using none cover on his worse value at lecturer sudden style. balthazar [SEP]']
[1050/2000] tot_loss=2.071 (perp=8.701, rec=0.311, cos=0.020), tot_loss_proj:2.810 [t=0.24s]
prediction: ['[CLS] the worse of tactic of nights, very situation none with thellemating. - because - using none cover on his worse value at campus sudden style. balthazar [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.062 (perp=8.711, rec=0.300, cos=0.019), tot_loss_proj:2.717 [t=0.18s]
prediction: ['[CLS] the worse of tactic the situation nights, very none with thellemating viet - because - using none cover on his worse value at campus sudden style. balthazar [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.014 (perp=8.452, rec=0.304, cos=0.020), tot_loss_proj:2.555 [t=0.18s]
prediction: ['[CLS] the worse of tactic the situation nights, very none with thellemating viet balthazar because - using none cover on his worse value at campus sudden style. - [SEP]']
[1200/2000] tot_loss=2.006 (perp=8.452, rec=0.298, cos=0.018), tot_loss_proj:2.554 [t=0.18s]
prediction: ['[CLS] the worse of tactic the situation nights, very none with thellemating viet balthazar because - using none cover on his worse value at campus sudden style. - [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.966 (perp=8.260, rec=0.295, cos=0.019), tot_loss_proj:2.515 [t=0.27s]
prediction: ['[CLS] the worse of tactic the situation nights, very none with thellemating viet balthazar because - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.893 (perp=7.884, rec=0.300, cos=0.017), tot_loss_proj:2.496 [t=0.26s]
prediction: ['[CLS] tactic the worse of the situation nights, very none with thellemating viet balthazar because - using none cover on his worse value at campus sudden - style. [SEP]']
[1350/2000] tot_loss=1.887 (perp=7.884, rec=0.292, cos=0.018), tot_loss_proj:2.493 [t=0.24s]
prediction: ['[CLS] tactic the worse of the situation nights, very none with thellemating viet balthazar because - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.887 (perp=7.884, rec=0.292, cos=0.017), tot_loss_proj:2.493 [t=0.20s]
prediction: ['[CLS] tactic the worse of the situation nights, very none with thellemating viet balthazar because - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.905 (perp=7.983, rec=0.291, cos=0.017), tot_loss_proj:2.479 [t=0.24s]
prediction: ['[CLS] tactic the worse of the fact nights, very none with thellemating viet balthazar because - using none cover on his worse value at campus sudden - style. [SEP]']
[1500/2000] tot_loss=1.991 (perp=8.435, rec=0.287, cos=0.017), tot_loss_proj:2.624 [t=0.25s]
prediction: ['[CLS] tactic the worse - the fact nights, very none with the tmating viet balthazar because - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.049 (perp=8.699, rec=0.292, cos=0.017), tot_loss_proj:2.774 [t=0.21s]
prediction: ['[CLS] tactic thelle - the fact nights, very wigan with the worsemating viet balthazar because - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
[1600/2000] tot_loss=2.067 (perp=8.796, rec=0.292, cos=0.016), tot_loss_proj:2.806 [t=0.18s]
prediction: ['[CLS] tactic thelle - the fact nights, very wigan with the worsemating. balthazar because - using none cover on his worse value at campus sudden - style. [SEP]']
[1650/2000] tot_loss=2.063 (perp=8.796, rec=0.287, cos=0.016), tot_loss_proj:2.804 [t=0.24s]
prediction: ['[CLS] tactic thelle - the fact nights, very wigan with the worsemating. balthazar because - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.033 (perp=8.614, rec=0.295, cos=0.016), tot_loss_proj:2.787 [t=0.19s]
prediction: ['[CLS] tactic thelle - the fact because, very wigan with the worsemating. balthazar nights - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
Moved sequence
[1750/2000] tot_loss=2.010 (perp=8.522, rec=0.290, cos=0.015), tot_loss_proj:2.792 [t=0.22s]
prediction: ['[CLS] tactic thelle - the fact because, very. wigan with the worsemating balthazar nights - using none cover on his worse value at campus sudden - style. [SEP]']
[1800/2000] tot_loss=2.008 (perp=8.522, rec=0.289, cos=0.015), tot_loss_proj:2.791 [t=0.19s]
prediction: ['[CLS] tactic thelle - the fact because, very. wigan with the worsemating balthazar nights - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.961 (perp=8.273, rec=0.291, cos=0.015), tot_loss_proj:2.725 [t=0.18s]
prediction: ['[CLS] tactic thelle - the fact because with very. wigan, the worsemating balthazar nights - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.958 (perp=8.273, rec=0.288, cos=0.015), tot_loss_proj:2.723 [t=0.18s]
prediction: ['[CLS] tactic thelle - the fact because with very. wigan, the worsemating balthazar nights - using none cover on his worse value at campus sudden - style. [SEP]']
[1950/2000] tot_loss=1.955 (perp=8.273, rec=0.284, cos=0.015), tot_loss_proj:2.724 [t=0.18s]
prediction: ['[CLS] tactic thelle - the fact because with very. wigan, the worsemating balthazar nights - using none cover on his worse value at campus sudden - style. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.952 (perp=8.273, rec=0.282, cos=0.015), tot_loss_proj:2.725 [t=0.18s]
prediction: ['[CLS] tactic thelle - the fact because with very. wigan, the worsemating balthazar nights - using none cover on his worse value at campus sudden - style. [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] the - a tacticin of, or‖ pinyinii papyrus among of the smashwords space nights worse using none cover on his worse value at temple extent tactic thumbs ideas [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.308 | p: 37.931 | r: 47.826
rouge2     | fm: 4.000 | p: 3.571 | r: 4.545
rougeL     | fm: 30.769 | p: 27.586 | r: 34.783
rougeLsum  | fm: 30.769 | p: 27.586 | r: 34.783
r1fm+r2fm = 46.308

[Aggregate metrics]:
rouge1     | fm: 87.037 | p: 86.599 | r: 87.710
rouge2     | fm: 51.034 | p: 50.890 | r: 51.321
rougeL     | fm: 75.527 | p: 75.110 | r: 76.067
rougeLsum  | fm: 75.592 | p: 75.247 | r: 76.130
r1fm+r2fm = 138.071

input #89 time: 0:08:30 | total time: 12:33:21


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9986429467577796
highest_index [0]
highest [0.9986429467577796]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 0.8960906863212585 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 0.8542460203170776 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 0.8387107849121094 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 0.8353435397148132 for ['[CLS] itself valuable density swim atlas meaning [SEP]']
[Init] best rec loss: 0.798558235168457 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 0.7979933619499207 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 0.7960638999938965 for ['[CLS] male when released cannot entourage spirited [SEP]']
[Init] best perm rec loss: 0.7949059009552002 for ['[CLS] cannot spirited male when released entourage [SEP]']
[Init] best perm rec loss: 0.7885702252388 for ['[CLS] when spirited cannot entourage released male [SEP]']
[Init] best perm rec loss: 0.7863904237747192 for ['[CLS] male spirited released entourage when cannot [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.280 (perp=9.931, rec=0.271, cos=0.023), tot_loss_proj:2.428 [t=0.17s]
prediction: ['[CLS] how how ridiculous oriented dollars oriented [SEP]']
[ 100/2000] tot_loss=1.889 (perp=8.598, rec=0.160, cos=0.010), tot_loss_proj:2.143 [t=0.18s]
prediction: ['[CLS] and how ridiculous money money oriented [SEP]']
[ 150/2000] tot_loss=1.839 (perp=8.650, rec=0.102, cos=0.007), tot_loss_proj:2.395 [t=0.20s]
prediction: ['[CLS] and how ridiculous money - oriented [SEP]']
[ 200/2000] tot_loss=1.874 (perp=8.650, rec=0.138, cos=0.006), tot_loss_proj:2.394 [t=0.25s]
prediction: ['[CLS] and how ridiculous money - oriented [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.694 (perp=7.895, rec=0.109, cos=0.006), tot_loss_proj:1.898 [t=0.21s]
prediction: ['[CLS] and how ridiculous - money oriented [SEP]']
[ 300/2000] tot_loss=1.671 (perp=7.895, rec=0.086, cos=0.006), tot_loss_proj:1.896 [t=0.26s]
prediction: ['[CLS] and how ridiculous - money oriented [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.540 (perp=7.197, rec=0.094, cos=0.006), tot_loss_proj:1.690 [t=0.25s]
prediction: ['[CLS] how ridiculous - and money oriented [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.461 (perp=6.870, rec=0.083, cos=0.004), tot_loss_proj:1.590 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 450/2000] tot_loss=1.452 (perp=6.870, rec=0.074, cos=0.004), tot_loss_proj:1.600 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.456 (perp=6.870, rec=0.078, cos=0.004), tot_loss_proj:1.585 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.454 (perp=6.870, rec=0.076, cos=0.004), tot_loss_proj:1.597 [t=0.20s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.456 (perp=6.870, rec=0.078, cos=0.004), tot_loss_proj:1.596 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.460 (perp=6.870, rec=0.082, cos=0.004), tot_loss_proj:1.594 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.451 (perp=6.870, rec=0.073, cos=0.004), tot_loss_proj:1.595 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.439 (perp=6.870, rec=0.061, cos=0.004), tot_loss_proj:1.599 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.442 (perp=6.870, rec=0.065, cos=0.004), tot_loss_proj:1.598 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.455 (perp=6.870, rec=0.076, cos=0.004), tot_loss_proj:1.596 [t=0.27s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.463 (perp=6.870, rec=0.085, cos=0.004), tot_loss_proj:1.587 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.450 (perp=6.870, rec=0.072, cos=0.004), tot_loss_proj:1.578 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.453 (perp=6.870, rec=0.076, cos=0.004), tot_loss_proj:1.589 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.438 (perp=6.870, rec=0.060, cos=0.004), tot_loss_proj:1.582 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.450 (perp=6.870, rec=0.072, cos=0.004), tot_loss_proj:1.591 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.450 (perp=6.870, rec=0.072, cos=0.004), tot_loss_proj:1.585 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.452 (perp=6.870, rec=0.075, cos=0.003), tot_loss_proj:1.579 [t=0.24s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.454 (perp=6.870, rec=0.077, cos=0.003), tot_loss_proj:1.582 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.446 (perp=6.870, rec=0.068, cos=0.003), tot_loss_proj:1.580 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.441 (perp=6.870, rec=0.063, cos=0.003), tot_loss_proj:1.583 [t=0.25s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.462 (perp=6.870, rec=0.084, cos=0.003), tot_loss_proj:1.585 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.452 (perp=6.870, rec=0.075, cos=0.003), tot_loss_proj:1.589 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.434 (perp=6.870, rec=0.056, cos=0.003), tot_loss_proj:1.589 [t=0.21s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.440 (perp=6.870, rec=0.063, cos=0.003), tot_loss_proj:1.586 [t=0.22s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.453 (perp=6.870, rec=0.075, cos=0.003), tot_loss_proj:1.577 [t=0.23s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.440 (perp=6.870, rec=0.063, cos=0.004), tot_loss_proj:1.582 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.455 (perp=6.870, rec=0.078, cos=0.003), tot_loss_proj:1.584 [t=0.20s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.439 (perp=6.870, rec=0.062, cos=0.003), tot_loss_proj:1.578 [t=0.29s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.444 (perp=6.870, rec=0.066, cos=0.003), tot_loss_proj:1.591 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.450 (perp=6.870, rec=0.073, cos=0.003), tot_loss_proj:1.588 [t=0.28s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.445 (perp=6.870, rec=0.068, cos=0.003), tot_loss_proj:1.589 [t=0.18s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.458 (perp=6.870, rec=0.080, cos=0.003), tot_loss_proj:1.592 [t=0.19s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.456 (perp=6.870, rec=0.078, cos=0.003), tot_loss_proj:1.591 [t=0.30s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.171 | p: 86.694 | r: 87.813
rouge2     | fm: 51.479 | p: 51.215 | r: 51.880
rougeL     | fm: 75.789 | p: 75.462 | r: 76.325
rougeLsum  | fm: 75.792 | p: 75.443 | r: 76.313
r1fm+r2fm = 138.650

input #90 time: 0:08:24 | total time: 12:41:45


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9988051974949494
highest_index [0]
highest [0.9988051974949494]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 0.8255350589752197 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 0.7757279872894287 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 0.76706862449646 for ['[CLS] dennistro drake effective taxes angle leave fly [SEP]']
[Init] best rec loss: 0.7427485585212708 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 0.7062787413597107 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 0.6973797678947449 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 0.6925365924835205 for ['[CLS] independent seemingly cartoon facedianspar anti dish [SEP]']
[Init] best rec loss: 0.6886038184165955 for ['[CLS] oxford bleeding? personal talking hold broadway tied [SEP]']
[Init] best rec loss: 0.6871387958526611 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best rec loss: 0.6776689887046814 for ['[CLS] reminder addict anyway oneislausicidelishhered [SEP]']
[Init] best perm rec loss: 0.6770883202552795 for ['[CLS] one addict remindericide anywayheredislauslish [SEP]']
[Init] best perm rec loss: 0.6739867925643921 for ['[CLS] addicthered onelishicideislaus reminder anyway [SEP]']
[Init] best perm rec loss: 0.6695284247398376 for ['[CLS] reminderhered addicticideislaus anyway onelish [SEP]']
[Init] best perm rec loss: 0.6688351035118103 for ['[CLS] addicticide one reminderislausheredlish anyway [SEP]']
[Init] best perm rec loss: 0.6687039136886597 for ['[CLS] addictheredicideislauslish one anyway reminder [SEP]']
[Init] best perm rec loss: 0.6670033931732178 for ['[CLS]icidelish anyway addictislaus onehered reminder [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.844 (perp=12.334, rec=0.327, cos=0.050), tot_loss_proj:3.599 [t=0.28s]
prediction: ['[CLS]less ridiculous sequel ridiculous no offense loco anymore [SEP]']
[ 100/2000] tot_loss=2.598 (perp=11.910, rec=0.193, cos=0.023), tot_loss_proj:3.116 [t=0.22s]
prediction: ['[CLS] mis ridiculous loco loco no loco loco more [SEP]']
[ 150/2000] tot_loss=2.288 (perp=10.859, rec=0.107, cos=0.009), tot_loss_proj:2.904 [t=0.23s]
prediction: ['[CLS]y ridiculous buty no loco loco more [SEP]']
[ 200/2000] tot_loss=2.250 (perp=10.811, rec=0.081, cos=0.007), tot_loss_proj:2.721 [t=0.19s]
prediction: ['[CLS]y ridiculous but mu noy loco more [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.160 (perp=10.175, rec=0.116, cos=0.008), tot_loss_proj:2.634 [t=0.20s]
prediction: ['[CLS]ty ridiculous but mu locoy no more [SEP]']
[ 300/2000] tot_loss=1.896 (perp=8.988, rec=0.094, cos=0.004), tot_loss_proj:2.380 [t=0.26s]
prediction: ['[CLS]ly ridiculous but mu locoy no more [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.742 (perp=8.183, rec=0.098, cos=0.008), tot_loss_proj:2.278 [t=0.19s]
prediction: ['[CLS] but ridiculous, mu locoy no more [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.681 (perp=7.969, rec=0.083, cos=0.005), tot_loss_proj:2.197 [t=0.18s]
prediction: ['[CLS] but ridiculous, muy loco no more [SEP]']
[ 450/2000] tot_loss=1.664 (perp=7.969, rec=0.067, cos=0.003), tot_loss_proj:2.200 [t=0.18s]
prediction: ['[CLS] but ridiculous, muy loco no more [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.634 (perp=7.739, rec=0.083, cos=0.003), tot_loss_proj:2.122 [t=0.19s]
prediction: ['[CLS] ridiculous, but muy loco no more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.621 (perp=7.739, rec=0.071, cos=0.002), tot_loss_proj:2.114 [t=0.23s]
prediction: ['[CLS] ridiculous, but muy loco no more [SEP]']
[ 600/2000] tot_loss=1.625 (perp=7.739, rec=0.074, cos=0.002), tot_loss_proj:2.108 [t=0.19s]
prediction: ['[CLS] ridiculous, but muy loco no more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.623 (perp=7.739, rec=0.073, cos=0.002), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] ridiculous, but muy loco no more [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.596 (perp=7.582, rec=0.077, cos=0.002), tot_loss_proj:2.068 [t=0.28s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
[ 750/2000] tot_loss=1.594 (perp=7.582, rec=0.075, cos=0.002), tot_loss_proj:2.066 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.593 (perp=7.582, rec=0.075, cos=0.002), tot_loss_proj:2.070 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.596 (perp=7.582, rec=0.077, cos=0.002), tot_loss_proj:2.073 [t=0.20s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
[ 900/2000] tot_loss=1.574 (perp=7.582, rec=0.056, cos=0.002), tot_loss_proj:2.072 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.572 (perp=7.582, rec=0.053, cos=0.002), tot_loss_proj:2.069 [t=0.22s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.575 (perp=7.582, rec=0.056, cos=0.002), tot_loss_proj:2.060 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
[1050/2000] tot_loss=1.587 (perp=7.582, rec=0.068, cos=0.002), tot_loss_proj:2.064 [t=0.23s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.585 (perp=7.582, rec=0.066, cos=0.002), tot_loss_proj:2.071 [t=0.24s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.590 (perp=7.582, rec=0.071, cos=0.002), tot_loss_proj:2.067 [t=0.19s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
[1200/2000] tot_loss=1.587 (perp=7.582, rec=0.068, cos=0.002), tot_loss_proj:2.071 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.582 (perp=7.582, rec=0.064, cos=0.002), tot_loss_proj:2.062 [t=0.22s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.587 (perp=7.582, rec=0.069, cos=0.002), tot_loss_proj:2.070 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
[1350/2000] tot_loss=1.584 (perp=7.582, rec=0.065, cos=0.002), tot_loss_proj:2.065 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.576 (perp=7.582, rec=0.057, cos=0.002), tot_loss_proj:2.067 [t=0.27s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.584 (perp=7.582, rec=0.065, cos=0.002), tot_loss_proj:2.067 [t=0.19s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
[1500/2000] tot_loss=1.579 (perp=7.582, rec=0.061, cos=0.002), tot_loss_proj:2.058 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.586 (perp=7.582, rec=0.067, cos=0.002), tot_loss_proj:2.063 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.573 (perp=7.582, rec=0.054, cos=0.002), tot_loss_proj:2.062 [t=0.19s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
[1650/2000] tot_loss=1.582 (perp=7.582, rec=0.063, cos=0.002), tot_loss_proj:2.056 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.579 (perp=7.582, rec=0.060, cos=0.002), tot_loss_proj:2.072 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.593 (perp=7.582, rec=0.074, cos=0.002), tot_loss_proj:2.067 [t=0.19s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
[1800/2000] tot_loss=1.576 (perp=7.582, rec=0.057, cos=0.002), tot_loss_proj:2.066 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.581 (perp=7.582, rec=0.062, cos=0.002), tot_loss_proj:2.060 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.588 (perp=7.582, rec=0.069, cos=0.002), tot_loss_proj:2.061 [t=0.24s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
[1950/2000] tot_loss=1.593 (perp=7.582, rec=0.075, cos=0.002), tot_loss_proj:2.066 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.579 (perp=7.582, rec=0.061, cos=0.002), tot_loss_proj:2.065 [t=0.18s]
prediction: ['[CLS] ridiculous muy, but loco no more [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] ridiculous muy, but loco no more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 114.286

[Aggregate metrics]:
rouge1     | fm: 87.346 | p: 86.899 | r: 87.986
rouge2     | fm: 51.218 | p: 51.059 | r: 51.506
rougeL     | fm: 75.860 | p: 75.465 | r: 76.380
rougeLsum  | fm: 75.775 | p: 75.426 | r: 76.331
r1fm+r2fm = 138.564

input #91 time: 0:08:19 | total time: 12:50:05


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9987903303522389
highest_index [0]
highest [0.9987903303522389]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 0.861641526222229 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 0.8593071699142456 for ['[CLS]ire fix [SEP]']
[Init] best rec loss: 0.8533810377120972 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 0.8201645612716675 for ['[CLS] atlantic manager [SEP]']
[Init] best rec loss: 0.7814074754714966 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 0.7229867577552795 for ['[CLS] tank lonely [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.914 (perp=13.690, rec=0.166, cos=0.010), tot_loss_proj:4.258 [t=0.18s]
prediction: ['[CLS]eiteit [SEP]']
[ 100/2000] tot_loss=2.860 (perp=13.690, rec=0.114, cos=0.008), tot_loss_proj:4.236 [t=0.24s]
prediction: ['[CLS]eiteit [SEP]']
[ 150/2000] tot_loss=2.865 (perp=13.690, rec=0.121, cos=0.006), tot_loss_proj:4.231 [t=0.18s]
prediction: ['[CLS]eiteit [SEP]']
[ 200/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.002), tot_loss_proj:1.613 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.590 (perp=7.646, rec=0.058, cos=0.002), tot_loss_proj:1.611 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.588 (perp=7.646, rec=0.057, cos=0.002), tot_loss_proj:1.611 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.591 (perp=7.646, rec=0.060, cos=0.002), tot_loss_proj:1.604 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.002), tot_loss_proj:1.606 [t=0.27s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.598 (perp=7.646, rec=0.067, cos=0.002), tot_loss_proj:1.611 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.596 (perp=7.646, rec=0.064, cos=0.002), tot_loss_proj:1.600 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.002), tot_loss_proj:1.593 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.594 (perp=7.646, rec=0.063, cos=0.002), tot_loss_proj:1.600 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.606 (perp=7.646, rec=0.074, cos=0.002), tot_loss_proj:1.596 [t=0.25s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.587 (perp=7.646, rec=0.055, cos=0.002), tot_loss_proj:1.604 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.590 (perp=7.646, rec=0.058, cos=0.002), tot_loss_proj:1.585 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.582 (perp=7.646, rec=0.051, cos=0.002), tot_loss_proj:1.593 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.592 (perp=7.646, rec=0.060, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.589 (perp=7.646, rec=0.058, cos=0.002), tot_loss_proj:1.594 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.594 (perp=7.646, rec=0.063, cos=0.002), tot_loss_proj:1.602 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.002), tot_loss_proj:1.584 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.611 (perp=7.646, rec=0.079, cos=0.002), tot_loss_proj:1.595 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.577 (perp=7.646, rec=0.045, cos=0.002), tot_loss_proj:1.597 [t=0.23s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.590 (perp=7.646, rec=0.059, cos=0.002), tot_loss_proj:1.619 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.589 (perp=7.646, rec=0.057, cos=0.002), tot_loss_proj:1.603 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.597 (perp=7.646, rec=0.065, cos=0.002), tot_loss_proj:1.597 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.601 (perp=7.646, rec=0.069, cos=0.002), tot_loss_proj:1.592 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.600 (perp=7.646, rec=0.068, cos=0.002), tot_loss_proj:1.607 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.601 (perp=7.646, rec=0.070, cos=0.002), tot_loss_proj:1.593 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.595 (perp=7.646, rec=0.063, cos=0.002), tot_loss_proj:1.603 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.597 (perp=7.646, rec=0.066, cos=0.002), tot_loss_proj:1.609 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.597 (perp=7.646, rec=0.065, cos=0.002), tot_loss_proj:1.598 [t=0.21s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.595 (perp=7.646, rec=0.063, cos=0.002), tot_loss_proj:1.604 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.591 (perp=7.646, rec=0.060, cos=0.002), tot_loss_proj:1.596 [t=0.24s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.595 (perp=7.646, rec=0.063, cos=0.002), tot_loss_proj:1.598 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.598 (perp=7.646, rec=0.067, cos=0.002), tot_loss_proj:1.591 [t=0.26s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.002), tot_loss_proj:1.598 [t=0.22s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.591 (perp=7.646, rec=0.060, cos=0.002), tot_loss_proj:1.590 [t=0.18s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.597 (perp=7.646, rec=0.065, cos=0.002), tot_loss_proj:1.600 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.597 (perp=7.646, rec=0.066, cos=0.002), tot_loss_proj:1.601 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.588 (perp=7.646, rec=0.056, cos=0.002), tot_loss_proj:1.593 [t=0.19s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.486 | p: 87.042 | r: 88.090
rouge2     | fm: 51.872 | p: 51.681 | r: 52.200
rougeL     | fm: 76.025 | p: 75.658 | r: 76.513
rougeLsum  | fm: 76.116 | p: 75.718 | r: 76.616
r1fm+r2fm = 139.358

input #92 time: 0:08:19 | total time: 12:58:25


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9987440718777987
highest_index [0]
highest [0.9987440718777987]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 0.953627347946167 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 0.931474506855011 for ['[CLS] taxi kang lookiled what mostchrome [SEP]']
[Init] best rec loss: 0.9100267291069031 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 0.9060607552528381 for ['[CLS] worthted ft assignment porch check up [SEP]']
[Init] best rec loss: 0.8917193412780762 for ['[CLS] lucas war breaks baby my pauline divided [SEP]']
[Init] best rec loss: 0.8879803419113159 for ['[CLS] village tallest almost giro opened wine section [SEP]']
[Init] best rec loss: 0.8721775412559509 for ['[CLS] alaska school flags land doc protest from [SEP]']
[Init] best perm rec loss: 0.8720129132270813 for ['[CLS] flags doc school land from protest alaska [SEP]']
[Init] best perm rec loss: 0.8711351752281189 for ['[CLS] flags doc from alaska protest land school [SEP]']
[Init] best perm rec loss: 0.8681614398956299 for ['[CLS] land flags school protest from doc alaska [SEP]']
[Init] best perm rec loss: 0.8675829768180847 for ['[CLS] doc school flags protest alaska land from [SEP]']
[Init] best perm rec loss: 0.8675104379653931 for ['[CLS] protest from school alaska land flags doc [SEP]']
[Init] best perm rec loss: 0.86588054895401 for ['[CLS] land from protest school doc alaska flags [SEP]']
[Init] best perm rec loss: 0.8641530275344849 for ['[CLS] land alaska flags doc protest from school [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.496 (perp=11.255, rec=0.229, cos=0.016), tot_loss_proj:2.576 [t=0.17s]
prediction: ['[CLS] open funny often often funny understanding way [SEP]']
[ 100/2000] tot_loss=2.351 (perp=10.883, rec=0.167, cos=0.008), tot_loss_proj:3.334 [t=0.18s]
prediction: ['[CLS] at way if often funny understanding way [SEP]']
[ 150/2000] tot_loss=2.313 (perp=10.942, rec=0.120, cos=0.005), tot_loss_proj:2.455 [t=0.18s]
prediction: ['[CLS] its its in often funny understanding way [SEP]']
[ 200/2000] tot_loss=2.293 (perp=10.942, rec=0.100, cos=0.004), tot_loss_proj:2.460 [t=0.18s]
prediction: ['[CLS] its its in often funny understanding way [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.994 (perp=9.570, rec=0.076, cos=0.004), tot_loss_proj:2.334 [t=0.18s]
prediction: ['[CLS] understanding its in often funny in way [SEP]']
[ 300/2000] tot_loss=2.009 (perp=9.570, rec=0.091, cos=0.004), tot_loss_proj:2.340 [t=0.18s]
prediction: ['[CLS] understanding its in often funny in way [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.729 (perp=8.204, rec=0.085, cos=0.004), tot_loss_proj:2.044 [t=0.18s]
prediction: ['[CLS] in understanding its often funny its way [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.584 (perp=7.449, rec=0.090, cos=0.004), tot_loss_proj:2.004 [t=0.19s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[ 450/2000] tot_loss=1.740 (perp=8.268, rec=0.082, cos=0.004), tot_loss_proj:1.948 [t=0.18s]
prediction: ['[CLS] understanding its often funny in funny way [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.692 (perp=8.068, rec=0.075, cos=0.004), tot_loss_proj:1.827 [t=0.21s]
prediction: ['[CLS] understanding in its often funny funny way [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.622 (perp=7.703, rec=0.078, cos=0.003), tot_loss_proj:1.836 [t=0.18s]
prediction: ['[CLS] understanding its in its often funny way [SEP]']
[ 600/2000] tot_loss=1.627 (perp=7.703, rec=0.083, cos=0.003), tot_loss_proj:1.840 [t=0.22s]
prediction: ['[CLS] understanding its in its often funny way [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.568 (perp=7.449, rec=0.074, cos=0.004), tot_loss_proj:2.025 [t=0.23s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.561 (perp=7.449, rec=0.067, cos=0.004), tot_loss_proj:2.024 [t=0.21s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[ 750/2000] tot_loss=1.570 (perp=7.449, rec=0.076, cos=0.003), tot_loss_proj:2.013 [t=0.19s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.563 (perp=7.449, rec=0.070, cos=0.003), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.571 (perp=7.449, rec=0.078, cos=0.003), tot_loss_proj:2.024 [t=0.21s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[ 900/2000] tot_loss=1.564 (perp=7.449, rec=0.071, cos=0.003), tot_loss_proj:2.027 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.568 (perp=7.449, rec=0.075, cos=0.003), tot_loss_proj:2.017 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1000/2000] tot_loss=1.570 (perp=7.449, rec=0.077, cos=0.003), tot_loss_proj:2.022 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[1050/2000] tot_loss=1.568 (perp=7.449, rec=0.075, cos=0.003), tot_loss_proj:2.019 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1100/2000] tot_loss=1.563 (perp=7.449, rec=0.070, cos=0.003), tot_loss_proj:2.022 [t=0.21s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1150/2000] tot_loss=1.571 (perp=7.449, rec=0.078, cos=0.003), tot_loss_proj:2.016 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[1200/2000] tot_loss=1.572 (perp=7.449, rec=0.078, cos=0.003), tot_loss_proj:2.023 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1250/2000] tot_loss=1.562 (perp=7.449, rec=0.069, cos=0.003), tot_loss_proj:2.026 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1300/2000] tot_loss=1.572 (perp=7.449, rec=0.078, cos=0.003), tot_loss_proj:2.022 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[1350/2000] tot_loss=1.573 (perp=7.449, rec=0.080, cos=0.003), tot_loss_proj:2.017 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1400/2000] tot_loss=1.568 (perp=7.449, rec=0.075, cos=0.003), tot_loss_proj:2.014 [t=0.19s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1450/2000] tot_loss=1.571 (perp=7.449, rec=0.078, cos=0.003), tot_loss_proj:2.026 [t=0.21s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[1500/2000] tot_loss=1.558 (perp=7.449, rec=0.065, cos=0.003), tot_loss_proj:2.015 [t=0.24s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1550/2000] tot_loss=1.570 (perp=7.449, rec=0.077, cos=0.003), tot_loss_proj:2.022 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1600/2000] tot_loss=1.557 (perp=7.449, rec=0.064, cos=0.003), tot_loss_proj:2.024 [t=0.22s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[1650/2000] tot_loss=1.565 (perp=7.449, rec=0.071, cos=0.003), tot_loss_proj:2.022 [t=0.21s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1700/2000] tot_loss=1.571 (perp=7.449, rec=0.078, cos=0.003), tot_loss_proj:2.023 [t=0.27s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1750/2000] tot_loss=1.570 (perp=7.449, rec=0.077, cos=0.003), tot_loss_proj:2.011 [t=0.27s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[1800/2000] tot_loss=1.567 (perp=7.449, rec=0.074, cos=0.003), tot_loss_proj:2.020 [t=0.21s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1850/2000] tot_loss=1.556 (perp=7.449, rec=0.063, cos=0.003), tot_loss_proj:2.012 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[1900/2000] tot_loss=1.568 (perp=7.449, rec=0.074, cos=0.003), tot_loss_proj:2.017 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
[1950/2000] tot_loss=1.574 (perp=7.449, rec=0.081, cos=0.003), tot_loss_proj:2.023 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Attempt swap
[2000/2000] tot_loss=1.560 (perp=7.449, rec=0.067, cos=0.003), tot_loss_proj:2.020 [t=0.18s]
prediction: ['[CLS] understanding its often funny in its way [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding its often funny in its way [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 88.889 | r: 100.000
rouge2     | fm: 40.000 | p: 37.500 | r: 42.857
rougeL     | fm: 70.588 | p: 66.667 | r: 75.000
rougeLsum  | fm: 70.588 | p: 66.667 | r: 75.000
r1fm+r2fm = 134.118

[Aggregate metrics]:
rouge1     | fm: 87.558 | p: 87.108 | r: 88.277
rouge2     | fm: 51.734 | p: 51.528 | r: 52.048
rougeL     | fm: 76.020 | p: 75.613 | r: 76.609
rougeLsum  | fm: 76.028 | p: 75.588 | r: 76.610
r1fm+r2fm = 139.292

input #93 time: 0:08:08 | total time: 13:06:34


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.99866072792272
highest_index [0]
highest [0.99866072792272]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 0.9411014914512634 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 0.9341035485267639 for ['[CLS] of pro wanted scientists rayon housing chart close earlier anniversary ni [SEP]']
[Init] best rec loss: 0.919884979724884 for ['[CLS] scent crosses am history single connections set likeuatingface other [SEP]']
[Init] best rec loss: 0.8833224177360535 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 0.880864143371582 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 0.8783459067344666 for ['[CLS]venting territorial chronic shocks rockwell crushed internal expedition plum centre flowering [SEP]']
[Init] best perm rec loss: 0.8780427575111389 for ['[CLS] plum centre internal rockwell chronicventing shocks flowering crushed expedition territorial [SEP]']
[Init] best perm rec loss: 0.878002405166626 for ['[CLS] rockwell centre chronicventing flowering expedition internal territorial crushed shocks plum [SEP]']
[Init] best perm rec loss: 0.8779804110527039 for ['[CLS] territorial centre expeditionventing flowering chronic crushed rockwell plum shocks internal [SEP]']
[Init] best perm rec loss: 0.875089704990387 for ['[CLS] territorial internal centre chronic crushed flowering rockwell shocksventing expedition plum [SEP]']
[Init] best perm rec loss: 0.8739987015724182 for ['[CLS] internal plumventing expedition chronic flowering crushed territorial rockwell centre shocks [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.390 (perp=10.699, rec=0.240, cos=0.010), tot_loss_proj:3.206 [t=0.19s]
prediction: ['[CLS] rebel neither of nor nor a none neither neither nor original [SEP]']
[ 100/2000] tot_loss=2.283 (perp=10.547, rec=0.168, cos=0.006), tot_loss_proj:2.955 [t=0.26s]
prediction: ['[CLS] cape neither that cape nor s ripley nor neither terribly original [SEP]']
[ 150/2000] tot_loss=2.402 (perp=11.365, rec=0.124, cos=0.005), tot_loss_proj:3.929 [t=0.18s]
prediction: ['[CLS] capeer a cape that s funny nor neither terribly original [SEP]']
[ 200/2000] tot_loss=2.181 (perp=10.371, rec=0.103, cos=0.004), tot_loss_proj:3.870 [t=0.22s]
prediction: ['[CLS] caper a cape that s funny nor neither terribly original [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.918 (perp=9.084, rec=0.098, cos=0.003), tot_loss_proj:2.275 [t=0.18s]
prediction: ['[CLS] caper a cape that s neither funny nor terribly original [SEP]']
[ 300/2000] tot_loss=1.776 (perp=8.484, rec=0.077, cos=0.003), tot_loss_proj:3.212 [t=0.19s]
prediction: ['[CLS] funnyr a cape that s neither funny nor terribly original [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.439 (perp=6.848, rec=0.067, cos=0.003), tot_loss_proj:3.221 [t=0.18s]
prediction: ['[CLS] funny a caper that s neither funny nor terribly original [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.359 (perp=6.465, rec=0.064, cos=0.003), tot_loss_proj:3.112 [t=0.25s]
prediction: ['[CLS] a funny caper that s neither funny nor terribly original [SEP]']
[ 450/2000] tot_loss=1.354 (perp=6.465, rec=0.058, cos=0.003), tot_loss_proj:3.112 [t=0.19s]
prediction: ['[CLS] a funny caper that s neither funny nor terribly original [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.367 (perp=6.465, rec=0.071, cos=0.003), tot_loss_proj:3.106 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither funny nor terribly original [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.353 (perp=6.413, rec=0.067, cos=0.003), tot_loss_proj:3.129 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[ 600/2000] tot_loss=1.351 (perp=6.413, rec=0.065, cos=0.003), tot_loss_proj:3.130 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.350 (perp=6.413, rec=0.065, cos=0.003), tot_loss_proj:3.130 [t=0.20s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.343 (perp=6.413, rec=0.058, cos=0.003), tot_loss_proj:3.126 [t=0.25s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[ 750/2000] tot_loss=1.351 (perp=6.413, rec=0.066, cos=0.003), tot_loss_proj:3.134 [t=0.25s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.349 (perp=6.413, rec=0.064, cos=0.003), tot_loss_proj:3.127 [t=0.17s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.339 (perp=6.413, rec=0.054, cos=0.003), tot_loss_proj:3.136 [t=0.19s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[ 900/2000] tot_loss=1.344 (perp=6.413, rec=0.059, cos=0.003), tot_loss_proj:3.126 [t=0.25s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.350 (perp=6.413, rec=0.065, cos=0.003), tot_loss_proj:3.127 [t=0.19s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1000/2000] tot_loss=1.350 (perp=6.413, rec=0.065, cos=0.003), tot_loss_proj:3.133 [t=0.22s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[1050/2000] tot_loss=1.355 (perp=6.413, rec=0.070, cos=0.002), tot_loss_proj:3.129 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1100/2000] tot_loss=1.342 (perp=6.413, rec=0.057, cos=0.003), tot_loss_proj:3.129 [t=0.22s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1150/2000] tot_loss=1.345 (perp=6.413, rec=0.060, cos=0.003), tot_loss_proj:3.123 [t=0.20s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[1200/2000] tot_loss=1.342 (perp=6.413, rec=0.057, cos=0.002), tot_loss_proj:3.128 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1250/2000] tot_loss=1.344 (perp=6.413, rec=0.059, cos=0.003), tot_loss_proj:3.125 [t=0.19s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.343 (perp=6.413, rec=0.058, cos=0.003), tot_loss_proj:3.128 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[1350/2000] tot_loss=1.350 (perp=6.413, rec=0.065, cos=0.003), tot_loss_proj:3.136 [t=0.21s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.346 (perp=6.413, rec=0.061, cos=0.002), tot_loss_proj:3.128 [t=0.23s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1450/2000] tot_loss=1.365 (perp=6.413, rec=0.080, cos=0.003), tot_loss_proj:3.130 [t=0.19s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[1500/2000] tot_loss=1.351 (perp=6.413, rec=0.066, cos=0.002), tot_loss_proj:3.130 [t=0.19s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1550/2000] tot_loss=1.340 (perp=6.413, rec=0.055, cos=0.002), tot_loss_proj:3.130 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1600/2000] tot_loss=1.348 (perp=6.413, rec=0.063, cos=0.003), tot_loss_proj:3.130 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[1650/2000] tot_loss=1.356 (perp=6.413, rec=0.071, cos=0.003), tot_loss_proj:3.129 [t=0.19s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.354 (perp=6.413, rec=0.069, cos=0.002), tot_loss_proj:3.123 [t=0.19s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.352 (perp=6.413, rec=0.067, cos=0.002), tot_loss_proj:3.128 [t=0.19s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[1800/2000] tot_loss=1.348 (perp=6.413, rec=0.063, cos=0.002), tot_loss_proj:3.127 [t=0.24s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.354 (perp=6.413, rec=0.069, cos=0.002), tot_loss_proj:3.128 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[1900/2000] tot_loss=1.349 (perp=6.413, rec=0.064, cos=0.002), tot_loss_proj:3.130 [t=0.24s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
[1950/2000] tot_loss=1.348 (perp=6.413, rec=0.063, cos=0.002), tot_loss_proj:3.128 [t=0.26s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.346 (perp=6.413, rec=0.061, cos=0.002), tot_loss_proj:3.126 [t=0.18s]
prediction: ['[CLS] a funny caper that s neither original nor terribly funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] a funny caper that s neither original nor terribly funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.652 | p: 91.667 | r: 100.000
rouge2     | fm: 85.714 | p: 81.818 | r: 90.000
rougeL     | fm: 95.652 | p: 91.667 | r: 100.000
rougeLsum  | fm: 95.652 | p: 91.667 | r: 100.000
r1fm+r2fm = 181.366

[Aggregate metrics]:
rouge1     | fm: 87.606 | p: 87.083 | r: 88.384
rouge2     | fm: 52.215 | p: 51.930 | r: 52.524
rougeL     | fm: 76.302 | p: 75.870 | r: 76.891
rougeLsum  | fm: 76.267 | p: 75.813 | r: 76.856
r1fm+r2fm = 139.821

input #94 time: 0:08:14 | total time: 13:14:48


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9985790747771085
highest_index [0]
highest [0.9985790747771085]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 0.9595538377761841 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 0.9560797810554504 for ['[CLS]nahley hair see nedra logan offices fourth sethgical recommended side laughdran auxiliary [SEP]']
[Init] best rec loss: 0.9320993423461914 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 0.929650068283081 for ['[CLS] through... if mckennarollerrand ngo sally cara party beauty economic dock nah art [SEP]']
[Init] best rec loss: 0.9224086403846741 for ['[CLS] navy loyalty roomines oak kindergarten plus during africa alexia merely hands will del affinity [SEP]']
[Init] best rec loss: 0.9040802717208862 for ['[CLS] end output rather overall of byron inventor earth interests novel adult heir night bryan remaining [SEP]']
[Init] best rec loss: 0.90009605884552 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 0.8977236151695251 for ['[CLS] tech trailer block wire dampے hanging private cut ] monty pressurenne sister complete [SEP]']
[Init] best perm rec loss: 0.895840048789978 for ['[CLS] ] wire sister damp cut monty hangingے block trailer complete private pressure technne [SEP]']
[Init] best perm rec loss: 0.8947775959968567 for ['[CLS] complete sister trailerے damp ] wire cut block hanging tech private montynne pressure [SEP]']
[Init] best perm rec loss: 0.8927049040794373 for ['[CLS] trailer hanging sister tech private complete block ] wire cutnne pressureے damp monty [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.601 (perp=11.682, rec=0.255, cos=0.010), tot_loss_proj:2.932 [t=0.27s]
prediction: ['[CLS] trailer produced rot hopeless put. became hopeless bread becomes hopelesses, hopeless hopeless [SEP]']
[ 100/2000] tot_loss=2.160 (perp=9.984, rec=0.157, cos=0.006), tot_loss_proj:2.565 [t=0.18s]
prediction: ['[CLS] trailer ( mud hopeless ), becomes hopeless packet mudsat story,fyingdle [SEP]']
[ 150/2000] tot_loss=2.326 (perp=11.044, rec=0.113, cos=0.004), tot_loss_proj:2.825 [t=0.18s]
prediction: ['[CLS]is ( maurice hopeless ) ) becomes hopeless ) mudsat story,fyingdle [SEP]']
[ 200/2000] tot_loss=2.314 (perp=11.083, rec=0.094, cos=0.004), tot_loss_proj:2.796 [t=0.22s]
prediction: ["[CLS]is ( denis hopeless') becomes hopeless ) mudsat story,fyingdle [SEP]"]
Attempt swap
Moved token
[ 250/2000] tot_loss=2.056 (perp=9.792, rec=0.093, cos=0.004), tot_loss_proj:2.563 [t=0.18s]
prediction: ["[CLS] denisis ( un'a becomes hopeless ) mudsat story,fyingdle [SEP]"]
[ 300/2000] tot_loss=2.034 (perp=9.792, rec=0.072, cos=0.003), tot_loss_proj:2.572 [t=0.22s]
prediction: ["[CLS] denisis ( un'a becomes hopeless ) mudsat story,fyingdle [SEP]"]
Attempt swap
Moved token
[ 350/2000] tot_loss=2.140 (perp=9.905, rec=0.155, cos=0.004), tot_loss_proj:2.491 [t=0.18s]
prediction: ["[CLS] denis unfying (fying'a becomes hopeless ) mudsat story,dle [SEP]"]
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.930 (perp=9.088, rec=0.110, cos=0.003), tot_loss_proj:2.327 [t=0.18s]
prediction: ["[CLS] denis unfying (fying'a becomes hopeless ) muddlesat story, [SEP]"]
[ 450/2000] tot_loss=1.909 (perp=9.088, rec=0.088, cos=0.003), tot_loss_proj:2.331 [t=0.19s]
prediction: ["[CLS] denis unfying (fying'a becomes hopeless ) muddlesat story, [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.768 (perp=8.420, rec=0.081, cos=0.003), tot_loss_proj:2.243 [t=0.20s]
prediction: ["[CLS] denis unfying (sat'a becomes hopeless ) muddle'story, [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.707 (perp=8.079, rec=0.088, cos=0.003), tot_loss_proj:2.264 [t=0.19s]
prediction: ["[CLS] denis unfying (sat'a becomes hopeless'muddle ) story, [SEP]"]
[ 600/2000] tot_loss=1.688 (perp=8.079, rec=0.069, cos=0.003), tot_loss_proj:2.257 [t=0.19s]
prediction: ["[CLS] denis unfying (sat'a becomes hopeless'muddle ) story, [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.654 (perp=7.874, rec=0.077, cos=0.003), tot_loss_proj:2.113 [t=0.20s]
prediction: ["[CLS] denisfying un (sat'a becomes hopeless'muddle ) story, [SEP]"]
Attempt swap
Moved token
[ 700/2000] tot_loss=1.578 (perp=7.172, rec=0.139, cos=0.005), tot_loss_proj:1.919 [t=0.26s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
[ 750/2000] tot_loss=1.528 (perp=7.172, rec=0.090, cos=0.003), tot_loss_proj:1.925 [t=0.23s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.525 (perp=7.172, rec=0.088, cos=0.003), tot_loss_proj:1.915 [t=0.21s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.523 (perp=7.172, rec=0.086, cos=0.003), tot_loss_proj:1.927 [t=0.22s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
[ 900/2000] tot_loss=1.517 (perp=7.172, rec=0.079, cos=0.003), tot_loss_proj:1.926 [t=0.18s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.514 (perp=7.172, rec=0.077, cos=0.003), tot_loss_proj:1.927 [t=0.20s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.520 (perp=7.172, rec=0.082, cos=0.003), tot_loss_proj:1.917 [t=0.19s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
[1050/2000] tot_loss=1.511 (perp=7.172, rec=0.073, cos=0.003), tot_loss_proj:1.922 [t=0.18s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.517 (perp=7.172, rec=0.080, cos=0.003), tot_loss_proj:1.931 [t=0.23s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.514 (perp=7.172, rec=0.076, cos=0.003), tot_loss_proj:1.919 [t=0.19s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
[1200/2000] tot_loss=1.524 (perp=7.172, rec=0.087, cos=0.003), tot_loss_proj:1.920 [t=0.25s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.512 (perp=7.172, rec=0.075, cos=0.003), tot_loss_proj:1.924 [t=0.19s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.513 (perp=7.172, rec=0.076, cos=0.003), tot_loss_proj:1.917 [t=0.20s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
[1350/2000] tot_loss=1.507 (perp=7.172, rec=0.070, cos=0.003), tot_loss_proj:1.920 [t=0.18s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.504 (perp=7.172, rec=0.067, cos=0.003), tot_loss_proj:1.921 [t=0.26s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.508 (perp=7.172, rec=0.071, cos=0.003), tot_loss_proj:1.924 [t=0.19s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
[1500/2000] tot_loss=1.517 (perp=7.172, rec=0.080, cos=0.003), tot_loss_proj:1.928 [t=0.18s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.514 (perp=7.172, rec=0.077, cos=0.003), tot_loss_proj:1.922 [t=0.23s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.513 (perp=7.172, rec=0.075, cos=0.003), tot_loss_proj:1.923 [t=0.19s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
[1650/2000] tot_loss=1.517 (perp=7.172, rec=0.080, cos=0.003), tot_loss_proj:1.922 [t=0.18s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.514 (perp=7.172, rec=0.076, cos=0.003), tot_loss_proj:1.924 [t=0.22s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.520 (perp=7.172, rec=0.083, cos=0.003), tot_loss_proj:1.930 [t=0.25s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
[1800/2000] tot_loss=1.516 (perp=7.172, rec=0.078, cos=0.003), tot_loss_proj:1.918 [t=0.21s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.504 (perp=7.172, rec=0.067, cos=0.003), tot_loss_proj:1.923 [t=0.22s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.503 (perp=7.172, rec=0.065, cos=0.003), tot_loss_proj:1.917 [t=0.18s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
[1950/2000] tot_loss=1.523 (perp=7.172, rec=0.085, cos=0.003), tot_loss_proj:1.921 [t=0.25s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.520 (perp=7.172, rec=0.082, cos=0.003), tot_loss_proj:1.922 [t=0.18s]
prediction: ["[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] denisfying un (sat'a story becomes hopeless'muddle ), [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 73.684 | p: 70.000 | r: 77.778
rouge2     | fm: 23.529 | p: 22.222 | r: 25.000
rougeL     | fm: 63.158 | p: 60.000 | r: 66.667
rougeLsum  | fm: 63.158 | p: 60.000 | r: 66.667
r1fm+r2fm = 97.214

[Aggregate metrics]:
rouge1     | fm: 87.497 | p: 86.904 | r: 88.263
rouge2     | fm: 51.717 | p: 51.439 | r: 52.031
rougeL     | fm: 76.072 | p: 75.552 | r: 76.717
rougeLsum  | fm: 76.178 | p: 75.656 | r: 76.767
r1fm+r2fm = 139.214

input #95 time: 0:08:19 | total time: 13:23:08


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9990060101044307
highest_index [0]
highest [0.9990060101044307]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 0.7921797037124634 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 0.7831263542175293 for ['[CLS] mode wound britain generation pope inter retains harvard chill court wait haven perform queensland ins [SEP]']
[Init] best rec loss: 0.78260338306427 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 0.7743241786956787 for ['[CLS] troubleович thou traditional adjacent pulse grit front minutes developingwind west fear later billy [SEP]']
[Init] best rec loss: 0.7663309574127197 for ['[CLS] interviews screwed podcast ？ 8 sunset effects era too oath sunk chief between capcom master [SEP]']
[Init] best rec loss: 0.7633397579193115 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best rec loss: 0.7592183351516724 for ['[CLS] walk morrison remote revolutionary dead takingphine ;vert reason bret affiliated called breakthrough ( [SEP]']
[Init] best perm rec loss: 0.7586588859558105 for ['[CLS] called ;vert affiliated breakthrough remotephine taking reason ( bret revolutionary dead morrison walk [SEP]']
[Init] best perm rec loss: 0.7585996985435486 for ['[CLS] ( reason walk called dead morrison bret takingphine affiliated ; breakthroughvert revolutionary remote [SEP]']
[Init] best perm rec loss: 0.7563755512237549 for ['[CLS] taking breakthrough morrison reason bret remote walk revolutionary affiliatedphine ; (vert dead called [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.412 (perp=10.423, rec=0.291, cos=0.036), tot_loss_proj:3.570 [t=0.18s]
prediction: ['[CLS] people force younger cover and into people force hurt lesser people jessage lesser into [SEP]']
[ 100/2000] tot_loss=2.411 (perp=10.976, rec=0.192, cos=0.024), tot_loss_proj:3.096 [t=0.19s]
prediction: ['[CLS] situations force alexander cover and into people force make lesser people lana clean lesser men [SEP]']
[ 150/2000] tot_loss=2.011 (perp=9.304, rec=0.138, cos=0.012), tot_loss_proj:2.840 [t=0.18s]
prediction: ['[CLS] situations force alexander cover people on people himself make lesser run for for his men [SEP]']
[ 200/2000] tot_loss=2.003 (perp=9.433, rec=0.108, cos=0.009), tot_loss_proj:2.990 [t=0.23s]
prediction: ['[CLS] situations force himself cover people on into himself make lesser run for for his men [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.934 (perp=9.054, rec=0.111, cos=0.012), tot_loss_proj:2.963 [t=0.20s]
prediction: ['[CLS] situations force himself into cover people on himself make lesser run for for people men [SEP]']
[ 300/2000] tot_loss=1.835 (perp=8.678, rec=0.092, cos=0.007), tot_loss_proj:2.796 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and on himself make lesser run would for people men [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.961 (perp=8.751, rec=0.199, cos=0.012), tot_loss_proj:2.785 [t=0.20s]
prediction: ['[CLS] situations force g into cover and on himself make people run wrist for lesser men [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.803 (perp=8.268, rec=0.140, cos=0.009), tot_loss_proj:2.656 [t=0.19s]
prediction: ['[CLS] situations force warmth into cover and on himself make people run for running lesser men [SEP]']
[ 450/2000] tot_loss=1.834 (perp=8.482, rec=0.131, cos=0.006), tot_loss_proj:2.723 [t=0.25s]
prediction: ['[CLS] situations force cover into cover and on himself make people run for would lesser men [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.810 (perp=8.437, rec=0.116, cos=0.006), tot_loss_proj:2.898 [t=0.20s]
prediction: ['[CLS] situations force into cover and on himself make people run for would get lesser men [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.818 (perp=8.377, rec=0.132, cos=0.011), tot_loss_proj:2.816 [t=0.20s]
prediction: ['[CLS] situations force into cover and throw on himself make people run for would lesser men [SEP]']
[ 600/2000] tot_loss=1.796 (perp=8.377, rec=0.114, cos=0.006), tot_loss_proj:2.832 [t=0.19s]
prediction: ['[CLS] situations force into cover and throw on himself make people run for would lesser men [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.647 (perp=7.640, rec=0.113, cos=0.005), tot_loss_proj:2.582 [t=0.28s]
prediction: ['[CLS] situations force himself into cover and run on make people run for would lesser men [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.600 (perp=7.415, rec=0.111, cos=0.006), tot_loss_proj:3.127 [t=0.25s]
prediction: ['[CLS] situations force himself into cover and run would make people run for on lesser men [SEP]']
[ 750/2000] tot_loss=1.594 (perp=7.415, rec=0.106, cos=0.005), tot_loss_proj:3.121 [t=0.18s]
prediction: ['[CLS] situations force himself into cover and run would make people run for on lesser men [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.587 (perp=7.415, rec=0.100, cos=0.004), tot_loss_proj:3.122 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run would make people run for on lesser men [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.560 (perp=7.289, rec=0.097, cos=0.004), tot_loss_proj:3.096 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run would make people run on for lesser men [SEP]']
[ 900/2000] tot_loss=1.545 (perp=7.289, rec=0.083, cos=0.004), tot_loss_proj:3.089 [t=0.22s]
prediction: ['[CLS] situations force himself into cover and run would make people run on for lesser men [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.552 (perp=7.289, rec=0.090, cos=0.004), tot_loss_proj:3.092 [t=0.23s]
prediction: ['[CLS] situations force himself into cover and run would make people run on for lesser men [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.539 (perp=7.164, rec=0.101, cos=0.005), tot_loss_proj:3.064 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run would make people run for lesser men on [SEP]']
[1050/2000] tot_loss=1.529 (perp=7.164, rec=0.092, cos=0.004), tot_loss_proj:3.059 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run would make people run for lesser men on [SEP]']
Attempt swap
[1100/2000] tot_loss=1.525 (perp=7.164, rec=0.088, cos=0.004), tot_loss_proj:3.057 [t=0.18s]
prediction: ['[CLS] situations force himself into cover and run would make people run for lesser men on [SEP]']
Attempt swap
[1150/2000] tot_loss=1.530 (perp=7.164, rec=0.093, cos=0.004), tot_loss_proj:3.065 [t=0.18s]
prediction: ['[CLS] situations force himself into cover and run would make people run for lesser men on [SEP]']
[1200/2000] tot_loss=1.525 (perp=7.164, rec=0.088, cos=0.004), tot_loss_proj:3.061 [t=0.23s]
prediction: ['[CLS] situations force himself into cover and run would make people run for lesser men on [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.507 (perp=7.057, rec=0.091, cos=0.005), tot_loss_proj:2.867 [t=0.28s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[1300/2000] tot_loss=1.500 (perp=7.057, rec=0.085, cos=0.004), tot_loss_proj:2.868 [t=0.29s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
[1350/2000] tot_loss=1.496 (perp=7.057, rec=0.080, cos=0.004), tot_loss_proj:2.875 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[1400/2000] tot_loss=1.509 (perp=7.057, rec=0.093, cos=0.004), tot_loss_proj:2.868 [t=0.22s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[1450/2000] tot_loss=1.508 (perp=7.057, rec=0.092, cos=0.004), tot_loss_proj:2.867 [t=0.22s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
[1500/2000] tot_loss=1.502 (perp=7.057, rec=0.086, cos=0.004), tot_loss_proj:2.869 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[1550/2000] tot_loss=1.509 (perp=7.057, rec=0.094, cos=0.004), tot_loss_proj:2.872 [t=0.20s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[1600/2000] tot_loss=1.502 (perp=7.057, rec=0.086, cos=0.004), tot_loss_proj:2.863 [t=0.18s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
[1650/2000] tot_loss=1.500 (perp=7.057, rec=0.084, cos=0.004), tot_loss_proj:2.866 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[1700/2000] tot_loss=1.501 (perp=7.057, rec=0.085, cos=0.004), tot_loss_proj:2.868 [t=0.23s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[1750/2000] tot_loss=1.500 (perp=7.057, rec=0.084, cos=0.004), tot_loss_proj:2.869 [t=0.26s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
[1800/2000] tot_loss=1.498 (perp=7.057, rec=0.083, cos=0.004), tot_loss_proj:2.871 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[1850/2000] tot_loss=1.496 (perp=7.057, rec=0.081, cos=0.004), tot_loss_proj:2.865 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[1900/2000] tot_loss=1.491 (perp=7.057, rec=0.076, cos=0.004), tot_loss_proj:2.868 [t=0.24s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
[1950/2000] tot_loss=1.504 (perp=7.057, rec=0.088, cos=0.004), tot_loss_proj:2.874 [t=0.19s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Attempt swap
[2000/2000] tot_loss=1.495 (perp=7.057, rec=0.079, cos=0.004), tot_loss_proj:2.870 [t=0.21s]
prediction: ['[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] situations force himself into cover and run people would make run for lesser men on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 119.118

[Aggregate metrics]:
rouge1     | fm: 87.547 | p: 87.001 | r: 88.297
rouge2     | fm: 51.354 | p: 51.056 | r: 51.696
rougeL     | fm: 75.884 | p: 75.356 | r: 76.440
rougeLsum  | fm: 75.868 | p: 75.377 | r: 76.448
r1fm+r2fm = 138.901

input #96 time: 0:08:23 | total time: 13:31:31


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9988128298252716
highest_index [0]
highest [0.9988128298252716]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 0.7065356373786926 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 0.6977251172065735 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best rec loss: 0.6956362128257751 for ['[CLS] rory blood we mazercle brig [SEP]']
[Init] best perm rec loss: 0.6928163170814514 for ['[CLS]rcle blood maze rory brig we [SEP]']
[Init] best perm rec loss: 0.6913333535194397 for ['[CLS] blood we rory maze brigrcle [SEP]']
[Init] best perm rec loss: 0.6898000240325928 for ['[CLS] blood we rory brig mazercle [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.345 (perp=14.179, rec=0.427, cos=0.082), tot_loss_proj:3.706 [t=0.21s]
prediction: ['[CLS] george eternalfor conservatory noble unexpected [SEP]']
[ 100/2000] tot_loss=2.531 (perp=10.695, rec=0.322, cos=0.070), tot_loss_proj:2.816 [t=0.30s]
prediction: ['[CLS] preciselygetforgettable continuous [SEP]']
[ 150/2000] tot_loss=1.672 (perp=6.802, rec=0.240, cos=0.072), tot_loss_proj:1.666 [t=0.17s]
prediction: ['[CLS] characters unforgettable continuous [SEP]']
[ 200/2000] tot_loss=1.650 (perp=6.797, rec=0.220, cos=0.071), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] characters unforgettable unreleased [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.854 (perp=7.836, rec=0.229, cos=0.058), tot_loss_proj:1.890 [t=0.20s]
prediction: ['[CLS] unforgettablekyu characters [SEP]']
[ 300/2000] tot_loss=1.480 (perp=6.104, rec=0.194, cos=0.065), tot_loss_proj:1.551 [t=0.21s]
prediction: ['[CLS] unforgettable characters characters [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.397 (perp=5.768, rec=0.178, cos=0.066), tot_loss_proj:1.482 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.394 (perp=5.768, rec=0.172, cos=0.068), tot_loss_proj:1.491 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[ 450/2000] tot_loss=1.400 (perp=5.768, rec=0.178, cos=0.069), tot_loss_proj:1.485 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.388 (perp=5.768, rec=0.166, cos=0.068), tot_loss_proj:1.495 [t=0.22s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.403 (perp=5.768, rec=0.178, cos=0.072), tot_loss_proj:1.488 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[ 600/2000] tot_loss=1.385 (perp=5.768, rec=0.164, cos=0.067), tot_loss_proj:1.486 [t=0.24s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.384 (perp=5.768, rec=0.164, cos=0.066), tot_loss_proj:1.488 [t=0.26s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.379 (perp=5.768, rec=0.159, cos=0.067), tot_loss_proj:1.505 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[ 750/2000] tot_loss=1.383 (perp=5.768, rec=0.165, cos=0.065), tot_loss_proj:1.498 [t=0.17s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.386 (perp=5.768, rec=0.167, cos=0.065), tot_loss_proj:1.494 [t=0.20s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.390 (perp=5.768, rec=0.170, cos=0.066), tot_loss_proj:1.504 [t=0.19s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[ 900/2000] tot_loss=1.382 (perp=5.768, rec=0.163, cos=0.066), tot_loss_proj:1.495 [t=0.21s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.380 (perp=5.768, rec=0.160, cos=0.066), tot_loss_proj:1.506 [t=0.24s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.384 (perp=5.768, rec=0.165, cos=0.065), tot_loss_proj:1.510 [t=0.23s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1050/2000] tot_loss=1.389 (perp=5.768, rec=0.170, cos=0.065), tot_loss_proj:1.511 [t=0.22s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.372 (perp=5.768, rec=0.154, cos=0.065), tot_loss_proj:1.512 [t=0.25s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.381 (perp=5.768, rec=0.162, cos=0.066), tot_loss_proj:1.504 [t=0.27s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1200/2000] tot_loss=1.379 (perp=5.768, rec=0.160, cos=0.066), tot_loss_proj:1.510 [t=0.17s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.383 (perp=5.768, rec=0.164, cos=0.066), tot_loss_proj:1.503 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.375 (perp=5.768, rec=0.156, cos=0.066), tot_loss_proj:1.512 [t=0.26s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1350/2000] tot_loss=1.379 (perp=5.768, rec=0.160, cos=0.065), tot_loss_proj:1.518 [t=0.17s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.379 (perp=5.768, rec=0.160, cos=0.065), tot_loss_proj:1.503 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.377 (perp=5.768, rec=0.158, cos=0.065), tot_loss_proj:1.515 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1500/2000] tot_loss=1.382 (perp=5.768, rec=0.162, cos=0.066), tot_loss_proj:1.501 [t=0.22s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.383 (perp=5.768, rec=0.164, cos=0.065), tot_loss_proj:1.515 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.383 (perp=5.768, rec=0.164, cos=0.065), tot_loss_proj:1.509 [t=0.19s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1650/2000] tot_loss=1.371 (perp=5.768, rec=0.153, cos=0.065), tot_loss_proj:1.504 [t=0.23s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.376 (perp=5.768, rec=0.157, cos=0.065), tot_loss_proj:1.517 [t=0.20s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.377 (perp=5.768, rec=0.159, cos=0.064), tot_loss_proj:1.514 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1800/2000] tot_loss=1.382 (perp=5.768, rec=0.164, cos=0.064), tot_loss_proj:1.517 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.382 (perp=5.768, rec=0.164, cos=0.064), tot_loss_proj:1.516 [t=0.19s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.376 (perp=5.768, rec=0.158, cos=0.064), tot_loss_proj:1.513 [t=0.24s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
[1950/2000] tot_loss=1.388 (perp=5.768, rec=0.169, cos=0.065), tot_loss_proj:1.515 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.379 (perp=5.768, rec=0.161, cos=0.065), tot_loss_proj:1.505 [t=0.18s]
prediction: ['[CLS] characters unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] characters unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 130.000

[Aggregate metrics]:
rouge1     | fm: 87.495 | p: 86.868 | r: 88.229
rouge2     | fm: 51.391 | p: 51.154 | r: 51.789
rougeL     | fm: 75.862 | p: 75.419 | r: 76.506
rougeLsum  | fm: 75.999 | p: 75.590 | r: 76.610
r1fm+r2fm = 138.886

input #97 time: 0:08:23 | total time: 13:39:54


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.998476223935355
highest_index [0]
highest [0.998476223935355]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 0.6772831678390503 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best perm rec loss: 0.6697812676429749 for ['[CLS] prohibited nos jed ada [SEP]']
[Init] best perm rec loss: 0.6694380640983582 for ['[CLS] nos ada prohibited jed [SEP]']
[Init] best perm rec loss: 0.66786789894104 for ['[CLS] nos prohibited ada jed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.344 (perp=10.618, rec=0.207, cos=0.013), tot_loss_proj:2.468 [t=0.21s]
prediction: ['[CLS] unfulfullling [SEP]']
[ 100/2000] tot_loss=2.193 (perp=10.508, rec=0.087, cos=0.005), tot_loss_proj:2.502 [t=0.23s]
prediction: ['[CLS] unfifullling [SEP]']
[ 150/2000] tot_loss=2.164 (perp=10.508, rec=0.059, cos=0.003), tot_loss_proj:2.491 [t=0.19s]
prediction: ['[CLS] unfifullling [SEP]']
[ 200/2000] tot_loss=2.159 (perp=10.508, rec=0.054, cos=0.003), tot_loss_proj:2.501 [t=0.26s]
prediction: ['[CLS] unfifullling [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.057 (perp=4.948, rec=0.063, cos=0.004), tot_loss_proj:1.065 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.057 (perp=4.948, rec=0.064, cos=0.003), tot_loss_proj:1.062 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.044 (perp=4.948, rec=0.051, cos=0.003), tot_loss_proj:1.073 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.050 (perp=4.948, rec=0.058, cos=0.003), tot_loss_proj:1.062 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.059 (perp=4.948, rec=0.066, cos=0.003), tot_loss_proj:1.085 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.053 (perp=4.948, rec=0.061, cos=0.003), tot_loss_proj:1.071 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.051 (perp=4.948, rec=0.059, cos=0.003), tot_loss_proj:1.062 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.056 (perp=4.948, rec=0.064, cos=0.003), tot_loss_proj:1.057 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.043 (perp=4.948, rec=0.051, cos=0.003), tot_loss_proj:1.067 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.051 (perp=4.948, rec=0.058, cos=0.003), tot_loss_proj:1.052 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.050 (perp=4.948, rec=0.057, cos=0.003), tot_loss_proj:1.050 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.053 (perp=4.948, rec=0.061, cos=0.003), tot_loss_proj:1.058 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.050 (perp=4.948, rec=0.058, cos=0.003), tot_loss_proj:1.050 [t=0.20s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.066 (perp=4.948, rec=0.073, cos=0.003), tot_loss_proj:1.068 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.050 (perp=4.948, rec=0.058, cos=0.003), tot_loss_proj:1.063 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.042 (perp=4.948, rec=0.049, cos=0.003), tot_loss_proj:1.065 [t=0.20s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.056 (perp=4.948, rec=0.063, cos=0.003), tot_loss_proj:1.053 [t=0.25s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.053 (perp=4.948, rec=0.060, cos=0.003), tot_loss_proj:1.069 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.060 (perp=4.948, rec=0.067, cos=0.003), tot_loss_proj:1.061 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.054 (perp=4.948, rec=0.061, cos=0.003), tot_loss_proj:1.056 [t=0.23s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.057 (perp=4.948, rec=0.065, cos=0.003), tot_loss_proj:1.053 [t=0.20s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.049 (perp=4.948, rec=0.056, cos=0.003), tot_loss_proj:1.062 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.059 (perp=4.948, rec=0.066, cos=0.003), tot_loss_proj:1.062 [t=0.20s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.056 (perp=4.948, rec=0.063, cos=0.003), tot_loss_proj:1.058 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.058 (perp=4.948, rec=0.065, cos=0.003), tot_loss_proj:1.043 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.057 (perp=4.948, rec=0.065, cos=0.003), tot_loss_proj:1.063 [t=0.24s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.056 (perp=4.948, rec=0.063, cos=0.003), tot_loss_proj:1.056 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.058 (perp=4.948, rec=0.066, cos=0.003), tot_loss_proj:1.055 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.053 (perp=4.948, rec=0.061, cos=0.003), tot_loss_proj:1.051 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.049 (perp=4.948, rec=0.056, cos=0.003), tot_loss_proj:1.048 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.049 (perp=4.948, rec=0.056, cos=0.003), tot_loss_proj:1.067 [t=0.18s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.048 (perp=4.948, rec=0.056, cos=0.003), tot_loss_proj:1.074 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.056 (perp=4.948, rec=0.064, cos=0.003), tot_loss_proj:1.055 [t=0.22s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.037 (perp=4.948, rec=0.044, cos=0.003), tot_loss_proj:1.066 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.054 (perp=4.948, rec=0.062, cos=0.003), tot_loss_proj:1.050 [t=0.19s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.062 (perp=4.948, rec=0.069, cos=0.003), tot_loss_proj:1.059 [t=0.21s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 87.664 | p: 87.123 | r: 88.424
rouge2     | fm: 51.908 | p: 51.675 | r: 52.331
rougeL     | fm: 76.087 | p: 75.673 | r: 76.667
rougeLsum  | fm: 76.135 | p: 75.717 | r: 76.712
r1fm+r2fm = 139.572

input #98 time: 0:08:19 | total time: 13:48:14


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9986199481122804
highest_index [0]
highest [0.9986199481122804]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 0.8159915208816528 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 0.8061907887458801 for ['[CLS]xt broadcast isabella class annie shock god ex apologetic considered coming re palacewhile whilst dam end heir authority si command sided closingingen competition wine expected woolf sophiacial keyili altered blank chairperson possession [SEP]']
[Init] best rec loss: 0.7983361482620239 for ['[CLS] freedom lay third cartwright u to tear supply disputed glasses operahus album [MASK] literature bart now associatedtmenty thou stated microphone poly frederick rogers lineshtake furport modern point rosewood mid early [SEP]']
[Init] best rec loss: 0.7710862755775452 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 0.7630768418312073 for ['[CLS] imp then ratlogueathy mobile bun smoothe bran where heart thumbs principal aires & recently brig addison stands catalog alert abbottale leading switch as could which buy pony kid risk general spreadim [SEP]']
[Init] best rec loss: 0.7615824937820435 for ['[CLS] wat searched fits mckay german divide interpret sensory ajax from even during under skye pants ramlus except door wanted others same q same king ashton care lot confirmation buttonsmania caseston file evil absolute [SEP]']
[Init] best rec loss: 0.7443947196006775 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best perm rec loss: 0.7439337968826294 for ['[CLS] dental services synonym when slight cushion orient garcia barbie earliest distance bearing re still himself claire [MASK] forced opposedˈ ratings harper temps currently actually rightte ferns bet screensaging taste thunder knowledgets te [SEP]']
[Init] best perm rec loss: 0.7414951324462891 for ['[CLS] actually bearing temps ferns earliest re orient services barbie slight dental knowledgete himself synonymaging te forced cushionts distance ratings still garcia thunderˈ right claire screens bet when opposed [MASK] currently taste harper [SEP]']
[Init] best perm rec loss: 0.7413976788520813 for ['[CLS]aging orient screens still [MASK] thunder barbiets dental himself when ratings forced te claire currently knowledgeˈ taste actually cushion garcia bearing earliest right services harper distance synonym ferns slight re opposedte bet temps [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.873 (perp=12.465, rec=0.350, cos=0.030), tot_loss_proj:3.793 [t=0.23s]
prediction: ["[CLS] stupid freedom british eurovision films military attacked ordinary cop cocaine (rift'qualify nonoes crude fakeʔ u not pleadingssing action [SEP] from lasted any endangered been'ssing is much fun [SEP]"]
[ 100/2000] tot_loss=2.489 (perp=10.980, rec=0.274, cos=0.018), tot_loss_proj:2.903 [t=0.18s]
prediction: ["[CLS] horrible news united still letters rifles walked etc a grammy film bathroom, had their''cieste ” di algorithms havingssing filmssing as what exactly threatened ®'ssing consecutive much fun [SEP]"]
[ 150/2000] tot_loss=2.511 (perp=11.249, rec=0.246, cos=0.015), tot_loss_proj:3.128 [t=0.19s]
prediction: ["[CLS] terrible news our still italian mumbled walked out] ள film bits if had ᅳth yet'' : 24 not havingssing filmssing di that ʸ took t quartz about'cost fun [SEP]"]
[ 200/2000] tot_loss=2.276 (perp=10.262, rec=0.211, cos=0.013), tot_loss_proj:2.892 [t=0.24s]
prediction: ["[CLS] terrible mommy the but films muttered walked out di ள film'` had= words''':'but havingssing film horrible di that quite took to ` overwhelming'mind fun [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.230 (perp=10.132, rec=0.195, cos=0.009), tot_loss_proj:3.302 [t=0.19s]
prediction: ['[CLS] terrible says the really films mumbled walked out di ள equipment? ` had=at a\'" ` " but havingssing film horrible di that a took did\'overwhelming the mind fun [SEP]']
[ 300/2000] tot_loss=2.054 (perp=9.415, rec=0.162, cos=0.009), tot_loss_proj:2.562 [t=0.22s]
prediction: ["[CLS] terrible yelled their really films ` walked out di ` equipment? ` had='a'' `'but hadssing film horrible di that a n didn't the mind fun [SEP]"]
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.067 (perp=9.529, rec=0.153, cos=0.008), tot_loss_proj:2.596 [t=0.18s]
prediction: ["[CLS] terrible their so films muttering walked out'` ticket ^ ` had `'''''' but hadssing film that horrible di that a n didn't the mind fun [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.032 (perp=9.388, rec=0.148, cos=0.007), tot_loss_proj:2.576 [t=0.19s]
prediction: ["[CLS] terrible they so films muttering walked muttering'` cost terrible `'`'''had'' but hadssing film that horrible di that a n t't the mind fun [SEP]"]
[ 450/2000] tot_loss=1.921 (perp=8.894, rec=0.135, cos=0.006), tot_loss_proj:2.485 [t=0.18s]
prediction: ["[CLS] terrible they so films muttering walked muttering'' cost terrible `'`'''had,'but hadssing film that horrible di that the n t't the mind fun [SEP]"]
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.850 (perp=8.566, rec=0.130, cos=0.007), tot_loss_proj:2.466 [t=0.27s]
prediction: ["[CLS] terrible muttering walked muttering'they soneas a cost terrible `,'''' had,'but hadssing film that horrible di that the n t't the mind fun [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.881 (perp=8.743, rec=0.126, cos=0.006), tot_loss_proj:2.512 [t=0.22s]
prediction: ["[CLS] terrible muttering walked muttering'they so a cost terrible `,''''neas had, ` but hadssing film that horrible di that the n t't the mind fun [SEP]"]
[ 600/2000] tot_loss=1.900 (perp=8.916, rec=0.112, cos=0.006), tot_loss_proj:2.536 [t=0.19s]
prediction: ["[CLS] terrible muttering walked muttering'they so'cost terrible `,'`'' films had, ` but hadssing film that horrible di that the n t't the mind fun [SEP]"]
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.797 (perp=8.377, rec=0.115, cos=0.007), tot_loss_proj:2.428 [t=0.24s]
prediction: ["[CLS] terrible muttering walked muttering'they so'cost terrible `,'`'` but'poems had, hadssing film that horrible di that the n t't the mind fun [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.806 (perp=8.453, rec=0.108, cos=0.007), tot_loss_proj:2.429 [t=0.19s]
prediction: ["[CLS] terrible muttering walked muttering'they so'the terrible ` and'`'` but'words had, hadssing film that horrible di that cost n t't the mind fun [SEP]"]
[ 750/2000] tot_loss=1.814 (perp=8.453, rec=0.116, cos=0.007), tot_loss_proj:2.431 [t=0.19s]
prediction: ["[CLS] terrible muttering walked muttering'they so'the terrible ` and'`'` but'words had, hadssing film that horrible di that cost n t't the mind fun [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.761 (perp=8.212, rec=0.112, cos=0.006), tot_loss_proj:2.378 [t=0.21s]
prediction: ["[CLS] terrible muttering walked muttering'they so'the terrible'and ` `'` but'words had, hadssing film that horrible di that cost n t't the mind fun [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.709 (perp=7.986, rec=0.106, cos=0.005), tot_loss_proj:2.343 [t=0.22s]
prediction: ["[CLS] terrible muttering walked muttering'they so'the terrible'and ` `'` but'words had, hadssing di that horrible film that cost n t't the mind fun [SEP]"]
[ 900/2000] tot_loss=1.746 (perp=8.180, rec=0.104, cos=0.006), tot_loss_proj:2.402 [t=0.18s]
prediction: ["[CLS] terrible muttering walked muttering'they so'the terrible'and ` `'` but'words had, hadssing di that horrible film this cost n t't the mind fun [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.669 (perp=7.803, rec=0.102, cos=0.006), tot_loss_proj:2.304 [t=0.23s]
prediction: ["[CLS] terrible muttering walked muttering'they so had the terrible'and ` `'` but'words ', hadssing di that horrible film this cost n t't the mind fun [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.609 (perp=7.495, rec=0.104, cos=0.006), tot_loss_proj:2.195 [t=0.25s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'and ` `'` but'muttering ', hadssing di that horrible film this cost n t n t the mind fun [SEP]"]
[1050/2000] tot_loss=1.607 (perp=7.495, rec=0.101, cos=0.006), tot_loss_proj:2.196 [t=0.22s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'and ` `'` but'muttering ', hadssing di that horrible film this cost n t n t the mind fun [SEP]"]
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.581 (perp=7.367, rec=0.102, cos=0.006), tot_loss_proj:2.170 [t=0.18s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'` and `'` but'muttering ', hadssing di that horrible film this cost n t n t the mind fun [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.574 (perp=7.334, rec=0.101, cos=0.006), tot_loss_proj:2.135 [t=0.19s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'` and `'` but'muttering ', hadssing di that horrible film this cost n t n t mind the fun [SEP]"]
[1200/2000] tot_loss=1.578 (perp=7.334, rec=0.104, cos=0.007), tot_loss_proj:2.134 [t=0.19s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'` and `'` but'muttering ', hadssing di that horrible film this cost n t n t mind the fun [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.577 (perp=7.350, rec=0.101, cos=0.006), tot_loss_proj:2.037 [t=0.18s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'` and `'` but'muttering ', had dissing that horrible film the cost did t n t mind the fun [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.555 (perp=7.277, rec=0.093, cos=0.006), tot_loss_proj:2.025 [t=0.24s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'` and `'` but'muttering ', had dissing that horrible film the cost did n t t mind the fun [SEP]"]
[1350/2000] tot_loss=1.559 (perp=7.277, rec=0.099, cos=0.004), tot_loss_proj:2.028 [t=0.19s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'` and `'` but'muttering ', had dissing that horrible film the cost did n t t mind the fun [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.552 (perp=7.215, rec=0.103, cos=0.005), tot_loss_proj:2.015 [t=0.28s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'`'`'` but and muttering ', had dissing that horrible film the cost did n t t mind the fun [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.538 (perp=7.139, rec=0.104, cos=0.006), tot_loss_proj:2.079 [t=0.28s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'`'`'` but and muttering'had, dissing that horrible film the cost did n t t mind the fun [SEP]"]
[1500/2000] tot_loss=1.527 (perp=7.139, rec=0.094, cos=0.006), tot_loss_proj:2.075 [t=0.27s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'`'`'` but and muttering'had, dissing that horrible film the cost did n t t mind the fun [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.532 (perp=7.139, rec=0.098, cos=0.005), tot_loss_proj:2.075 [t=0.27s]
prediction: ["[CLS] terrible words walked muttering'they so had the terrible'`'`'` but and muttering'had, dissing that horrible film the cost did n t t mind the fun [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.513 (perp=7.051, rec=0.097, cos=0.006), tot_loss_proj:2.158 [t=0.28s]
prediction: ["[CLS] terrible words walked muttering ', so had the terrible'`'`'` but and muttering'had they dissing that horrible film the cost did n t t mind the fun [SEP]"]
[1650/2000] tot_loss=1.515 (perp=7.051, rec=0.100, cos=0.005), tot_loss_proj:2.156 [t=0.27s]
prediction: ["[CLS] terrible words walked muttering ', so had the terrible'`'`'` but and muttering'had they dissing that horrible film the cost did n t t mind the fun [SEP]"]
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.516 (perp=7.018, rec=0.107, cos=0.006), tot_loss_proj:2.088 [t=0.26s]
prediction: ["[CLS] terrible words walked muttering ', so had the terrible'`'`'` but and muttering'they had dissing that horrible film the cost did n t t mind the fun [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.451 (perp=6.768, rec=0.092, cos=0.005), tot_loss_proj:2.008 [t=0.18s]
prediction: ["[CLS] terrible words walked muttering'but so had the terrible'`'`'`, and muttering'they had dissing that horrible film the cost did n t t mind the fun [SEP]"]
[1800/2000] tot_loss=1.452 (perp=6.768, rec=0.093, cos=0.006), tot_loss_proj:2.009 [t=0.18s]
prediction: ["[CLS] terrible words walked muttering'but so had the terrible'`'`'`, and muttering'they had dissing that horrible film the cost did n t t mind the fun [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.454 (perp=6.768, rec=0.095, cos=0.005), tot_loss_proj:2.006 [t=0.26s]
prediction: ["[CLS] terrible words walked muttering'but so had the terrible'`'`'`, and muttering'they had dissing that horrible film the cost did n t t mind the fun [SEP]"]
Attempt swap
Moved token
[1900/2000] tot_loss=1.442 (perp=6.682, rec=0.100, cos=0.006), tot_loss_proj:1.950 [t=0.23s]
prediction: ["[CLS] terrible words walked muttering'but so had the terrible'`'`'`, and muttering'they had dissing that horrible film t the cost did n t mind the fun [SEP]"]
[1950/2000] tot_loss=1.436 (perp=6.682, rec=0.094, cos=0.006), tot_loss_proj:1.950 [t=0.18s]
prediction: ["[CLS] terrible words walked muttering'but so had the terrible'`'`'`, and muttering'they had dissing that horrible film t the cost did n t mind the fun [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.439 (perp=6.682, rec=0.097, cos=0.005), tot_loss_proj:1.952 [t=0.20s]
prediction: ["[CLS] terrible words walked muttering'but so had the terrible'`'`'`, and muttering'they had dissing that horrible film t the cost did n t mind the fun [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] terrible words walked muttering'they so had the terrible'`'`'` but and muttering'had, dissing that horrible film the cost did n t t mind the fun [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 77.778 | p: 75.000 | r: 80.769
rouge2     | fm: 11.538 | p: 11.111 | r: 12.000
rougeL     | fm: 44.444 | p: 42.857 | r: 46.154
rougeLsum  | fm: 44.444 | p: 42.857 | r: 46.154
r1fm+r2fm = 89.316

[Aggregate metrics]:
rouge1     | fm: 87.538 | p: 86.965 | r: 88.304
rouge2     | fm: 51.590 | p: 51.274 | r: 51.989
rougeL     | fm: 75.723 | p: 75.265 | r: 76.336
rougeLsum  | fm: 75.924 | p: 75.436 | r: 76.512
r1fm+r2fm = 139.128

input #99 time: 0:08:33 | total time: 13:56:47


Average Cosine Similarity: 0.9987141706595272
Done with all.
