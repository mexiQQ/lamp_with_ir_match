


Command: attack4.py --dataset sst2 --split test --loss cos --n_inputs 100 -b 1 --coeff_perplexity 0.2 --coeff_reg 1 --lr 0.01 --lr_decay 0.89 --tag_factor 0.01 --bert_path /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 --n_steps 2000 --coeff_pooler_match 0.0 --coeff_pooler_match_margin 0.0 --pooler_match_for_init yes --pooler_match_for_optimization no --pooler_match_for_swap yes 



Reusing dataset glue (/home/jli265/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 128.48it/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/jli265/projects/lamp_with_ir_match/models/bert-base-finetuned-sst2 and are newly initialized because the shapes did not match:
- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([30000, 768]) in the model instantiated
- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([30000]) in the model instantiated
- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 30000]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


Attacking..

Running input #0 of 100.
reference: 
========================
slightly disappointed 
========================
average of cosine similarity 0.9992715259422633
highest_index [0]
highest [0.9992715259422633]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3621, 9364,  102]], device='cuda:0')
Debug: ref = ['[CLS] slightly disappointed [SEP]']
[Init] best rec loss: 1.9897326231002808 for ['[CLS] study showing [SEP]']
[Init] best rec loss: 1.6931339502334595 for ['[CLS]wall same [SEP]']
[Init] best rec loss: 1.5862441062927246 for ['[CLS] kennedy west [SEP]']
[Init] best rec loss: 1.5641170740127563 for ['[CLS] never suspension [SEP]']
[Init] best rec loss: 1.3241164684295654 for ['[CLS] panel officer [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.194 (perp=9.874, rec=0.202, cos=0.017), tot_loss_proj:2.547 [t=0.19s]
prediction: ['[CLS] bishop disappointed [SEP]']
[ 100/2000] tot_loss=2.204 (perp=10.251, rec=0.143, cos=0.012), tot_loss_proj:2.113 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 150/2000] tot_loss=2.184 (perp=10.251, rec=0.123, cos=0.010), tot_loss_proj:2.126 [t=0.20s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 200/2000] tot_loss=2.136 (perp=10.251, rec=0.083, cos=0.003), tot_loss_proj:2.119 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.118 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.128 [t=0.20s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 300/2000] tot_loss=2.095 (perp=10.251, rec=0.044, cos=0.001), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.117 (perp=10.251, rec=0.065, cos=0.001), tot_loss_proj:2.108 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.107 (perp=10.251, rec=0.055, cos=0.001), tot_loss_proj:2.129 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 450/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.102 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.108 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.116 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.101 (perp=10.251, rec=0.050, cos=0.001), tot_loss_proj:2.133 [t=0.20s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 600/2000] tot_loss=2.110 (perp=10.251, rec=0.058, cos=0.001), tot_loss_proj:2.108 [t=0.20s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.104 (perp=10.251, rec=0.053, cos=0.001), tot_loss_proj:2.118 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.096 (perp=10.251, rec=0.044, cos=0.001), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 750/2000] tot_loss=2.114 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.124 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.118 (perp=10.251, rec=0.066, cos=0.001), tot_loss_proj:2.115 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.124 (perp=10.251, rec=0.072, cos=0.001), tot_loss_proj:2.121 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
[ 900/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.127 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.107 (perp=10.251, rec=0.055, cos=0.001), tot_loss_proj:2.127 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1000/2000] tot_loss=2.103 (perp=10.251, rec=0.051, cos=0.001), tot_loss_proj:2.131 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1050/2000] tot_loss=2.112 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.121 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1100/2000] tot_loss=2.093 (perp=10.251, rec=0.042, cos=0.001), tot_loss_proj:2.115 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1150/2000] tot_loss=2.104 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.122 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1200/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.129 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1250/2000] tot_loss=2.104 (perp=10.251, rec=0.052, cos=0.001), tot_loss_proj:2.121 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1300/2000] tot_loss=2.107 (perp=10.251, rec=0.056, cos=0.001), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1350/2000] tot_loss=2.100 (perp=10.251, rec=0.048, cos=0.001), tot_loss_proj:2.115 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1400/2000] tot_loss=2.113 (perp=10.251, rec=0.061, cos=0.001), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1450/2000] tot_loss=2.115 (perp=10.251, rec=0.063, cos=0.001), tot_loss_proj:2.109 [t=0.19s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1500/2000] tot_loss=2.106 (perp=10.251, rec=0.054, cos=0.001), tot_loss_proj:2.118 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1550/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.122 [t=0.26s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1600/2000] tot_loss=2.101 (perp=10.251, rec=0.050, cos=0.001), tot_loss_proj:2.112 [t=0.27s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1650/2000] tot_loss=2.108 (perp=10.251, rec=0.057, cos=0.001), tot_loss_proj:2.112 [t=0.21s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1700/2000] tot_loss=2.112 (perp=10.251, rec=0.060, cos=0.001), tot_loss_proj:2.119 [t=0.18s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1750/2000] tot_loss=2.114 (perp=10.251, rec=0.062, cos=0.001), tot_loss_proj:2.127 [t=0.22s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1800/2000] tot_loss=2.106 (perp=10.251, rec=0.054, cos=0.001), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1850/2000] tot_loss=2.120 (perp=10.251, rec=0.069, cos=0.001), tot_loss_proj:2.126 [t=0.20s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[1900/2000] tot_loss=2.099 (perp=10.251, rec=0.047, cos=0.001), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] slightly disappointed [SEP]']
[1950/2000] tot_loss=2.109 (perp=10.251, rec=0.057, cos=0.001), tot_loss_proj:2.112 [t=0.23s]
prediction: ['[CLS] slightly disappointed [SEP]']
Attempt swap
[2000/2000] tot_loss=2.120 (perp=10.251, rec=0.068, cos=0.001), tot_loss_proj:2.123 [t=0.24s]
prediction: ['[CLS] slightly disappointed [SEP]']
Done with input #0 of 100.
reference: 
========================
[CLS] slightly disappointed [SEP]
========================
predicted: 
========================
[CLS] slightly disappointed [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #0 time: 0:08:44 | total time: 0:08:44


Running input #1 of 100.
reference: 
========================
splendidly 
========================
average of cosine similarity 0.9993548278348494
highest_index [0]
highest [0.9993548278348494]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 21459,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] splendidly [SEP]']
[Init] best rec loss: 1.8751615285873413 for ['[CLS] church sat [SEP]']
[Init] best rec loss: 1.8574330806732178 for ['[CLS] collectiontail [SEP]']
[Init] best rec loss: 1.8238334655761719 for ['[CLS] football package [SEP]']
[Init] best rec loss: 1.7409363985061646 for ['[CLS] cas giants [SEP]']
[Init] best rec loss: 1.6608680486679077 for ['[CLS] conducted predator [SEP]']
[Init] best rec loss: 1.6287647485733032 for ['[CLS] j native [SEP]']
[Init] best rec loss: 1.5730043649673462 for ['[CLS] dated glazed [SEP]']
[Init] best rec loss: 1.5161365270614624 for ['[CLS] there correspondent [SEP]']
[Init] best rec loss: 1.271039366722107 for ['[CLS] finally relative [SEP]']
[Init] best rec loss: 1.120924472808838 for ['[CLS] course characters [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.281 (perp=10.543, rec=0.170, cos=0.002), tot_loss_proj:2.466 [t=0.22s]
prediction: ['[CLS] splendid splendid [SEP]']
[ 100/2000] tot_loss=2.139 (perp=10.288, rec=0.080, cos=0.001), tot_loss_proj:2.349 [t=0.20s]
prediction: ['[CLS]ly splendid [SEP]']
[ 150/2000] tot_loss=2.117 (perp=10.288, rec=0.059, cos=0.001), tot_loss_proj:2.348 [t=0.22s]
prediction: ['[CLS]ly splendid [SEP]']
[ 200/2000] tot_loss=2.119 (perp=10.288, rec=0.060, cos=0.001), tot_loss_proj:2.351 [t=0.18s]
prediction: ['[CLS]ly splendid [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.903 (perp=9.171, rec=0.067, cos=0.001), tot_loss_proj:1.890 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[ 300/2000] tot_loss=1.899 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.906 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.902 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.902 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[ 450/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.902 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.896 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.914 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[ 600/2000] tot_loss=1.905 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.895 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.898 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.881 (perp=9.171, rec=0.045, cos=0.001), tot_loss_proj:1.893 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[ 750/2000] tot_loss=1.897 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.895 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.894 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.898 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.885 (perp=9.171, rec=0.049, cos=0.001), tot_loss_proj:1.904 [t=0.29s]
prediction: ['[CLS] splendidly [SEP]']
[ 900/2000] tot_loss=1.908 (perp=9.171, rec=0.073, cos=0.001), tot_loss_proj:1.897 [t=0.21s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.893 (perp=9.171, rec=0.057, cos=0.001), tot_loss_proj:1.908 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1000/2000] tot_loss=1.888 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.905 [t=0.21s]
prediction: ['[CLS] splendidly [SEP]']
[1050/2000] tot_loss=1.893 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.889 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1100/2000] tot_loss=1.893 (perp=9.171, rec=0.058, cos=0.001), tot_loss_proj:1.909 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1150/2000] tot_loss=1.896 (perp=9.171, rec=0.061, cos=0.001), tot_loss_proj:1.894 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1200/2000] tot_loss=1.900 (perp=9.171, rec=0.065, cos=0.001), tot_loss_proj:1.893 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1250/2000] tot_loss=1.901 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.884 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1300/2000] tot_loss=1.899 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.911 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
[1350/2000] tot_loss=1.902 (perp=9.171, rec=0.066, cos=0.001), tot_loss_proj:1.901 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1400/2000] tot_loss=1.897 (perp=9.171, rec=0.062, cos=0.001), tot_loss_proj:1.906 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1450/2000] tot_loss=1.900 (perp=9.171, rec=0.064, cos=0.001), tot_loss_proj:1.902 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
[1500/2000] tot_loss=1.895 (perp=9.171, rec=0.060, cos=0.001), tot_loss_proj:1.912 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1550/2000] tot_loss=1.904 (perp=9.171, rec=0.069, cos=0.001), tot_loss_proj:1.893 [t=0.22s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1600/2000] tot_loss=1.917 (perp=9.171, rec=0.081, cos=0.001), tot_loss_proj:1.903 [t=0.26s]
prediction: ['[CLS] splendidly [SEP]']
[1650/2000] tot_loss=1.894 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.899 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1700/2000] tot_loss=1.892 (perp=9.171, rec=0.056, cos=0.001), tot_loss_proj:1.900 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1750/2000] tot_loss=1.887 (perp=9.171, rec=0.052, cos=0.001), tot_loss_proj:1.903 [t=0.18s]
prediction: ['[CLS] splendidly [SEP]']
[1800/2000] tot_loss=1.891 (perp=9.171, rec=0.055, cos=0.001), tot_loss_proj:1.910 [t=0.27s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1850/2000] tot_loss=1.907 (perp=9.171, rec=0.072, cos=0.001), tot_loss_proj:1.902 [t=0.25s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[1900/2000] tot_loss=1.889 (perp=9.171, rec=0.053, cos=0.001), tot_loss_proj:1.891 [t=0.24s]
prediction: ['[CLS] splendidly [SEP]']
[1950/2000] tot_loss=1.898 (perp=9.171, rec=0.063, cos=0.001), tot_loss_proj:1.899 [t=0.20s]
prediction: ['[CLS] splendidly [SEP]']
Attempt swap
[2000/2000] tot_loss=1.895 (perp=9.171, rec=0.059, cos=0.001), tot_loss_proj:1.906 [t=0.19s]
prediction: ['[CLS] splendidly [SEP]']
Done with input #1 of 100.
reference: 
========================
[CLS] splendidly [SEP]
========================
predicted: 
========================
[CLS] splendidly [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #1 time: 0:08:26 | total time: 0:17:11


Running input #2 of 100.
reference: 
========================
gaining much momentum 
========================
average of cosine similarity 0.9994340582458305
highest_index [0]
highest [0.9994340582458305]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  8550,  2172, 11071,   102]], device='cuda:0')
Debug: ref = ['[CLS] gaining much momentum [SEP]']
[Init] best rec loss: 1.3203822374343872 for ['[CLS] wash〜 at [SEP]']
[Init] best rec loss: 1.2476643323898315 for ['[CLS] we working would [SEP]']
[Init] best perm rec loss: 1.2300113439559937 for ['[CLS] we would working [SEP]']
[Init] best perm rec loss: 1.2278040647506714 for ['[CLS] would we working [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.449 (perp=10.279, rec=0.353, cos=0.040), tot_loss_proj:2.931 [t=0.18s]
prediction: ['[CLS] culture technology momentum [SEP]']
[ 100/2000] tot_loss=1.921 (perp=8.515, rec=0.208, cos=0.010), tot_loss_proj:1.799 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 150/2000] tot_loss=1.798 (perp=8.515, rec=0.093, cos=0.002), tot_loss_proj:1.799 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 200/2000] tot_loss=1.789 (perp=8.515, rec=0.084, cos=0.002), tot_loss_proj:1.798 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.772 (perp=8.515, rec=0.068, cos=0.001), tot_loss_proj:1.804 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 300/2000] tot_loss=1.788 (perp=8.515, rec=0.083, cos=0.002), tot_loss_proj:1.795 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.783 (perp=8.515, rec=0.079, cos=0.001), tot_loss_proj:1.799 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.774 (perp=8.515, rec=0.069, cos=0.002), tot_loss_proj:1.795 [t=0.21s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 450/2000] tot_loss=1.754 (perp=8.515, rec=0.050, cos=0.001), tot_loss_proj:1.806 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.774 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.796 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.793 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 600/2000] tot_loss=1.756 (perp=8.515, rec=0.052, cos=0.001), tot_loss_proj:1.791 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.788 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.799 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 750/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.799 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.765 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.807 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.770 (perp=8.515, rec=0.066, cos=0.001), tot_loss_proj:1.790 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[ 900/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.794 [t=0.27s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.762 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.800 [t=0.30s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1000/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.793 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1050/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.794 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1100/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.799 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1150/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.799 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1200/2000] tot_loss=1.779 (perp=8.515, rec=0.075, cos=0.001), tot_loss_proj:1.788 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1250/2000] tot_loss=1.755 (perp=8.515, rec=0.051, cos=0.001), tot_loss_proj:1.788 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1300/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.797 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1350/2000] tot_loss=1.760 (perp=8.515, rec=0.056, cos=0.001), tot_loss_proj:1.797 [t=0.23s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1400/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1450/2000] tot_loss=1.757 (perp=8.515, rec=0.053, cos=0.001), tot_loss_proj:1.799 [t=0.26s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1500/2000] tot_loss=1.765 (perp=8.515, rec=0.061, cos=0.001), tot_loss_proj:1.795 [t=0.22s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1550/2000] tot_loss=1.768 (perp=8.515, rec=0.064, cos=0.001), tot_loss_proj:1.799 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1600/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.792 [t=0.29s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1650/2000] tot_loss=1.761 (perp=8.515, rec=0.057, cos=0.001), tot_loss_proj:1.793 [t=0.20s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1700/2000] tot_loss=1.754 (perp=8.515, rec=0.050, cos=0.001), tot_loss_proj:1.789 [t=0.19s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1750/2000] tot_loss=1.764 (perp=8.515, rec=0.060, cos=0.001), tot_loss_proj:1.790 [t=0.24s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1800/2000] tot_loss=1.766 (perp=8.515, rec=0.062, cos=0.001), tot_loss_proj:1.793 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1850/2000] tot_loss=1.773 (perp=8.515, rec=0.069, cos=0.001), tot_loss_proj:1.792 [t=0.25s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[1900/2000] tot_loss=1.763 (perp=8.515, rec=0.059, cos=0.001), tot_loss_proj:1.797 [t=0.28s]
prediction: ['[CLS] gaining much momentum [SEP]']
[1950/2000] tot_loss=1.767 (perp=8.515, rec=0.063, cos=0.001), tot_loss_proj:1.789 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.515, rec=0.055, cos=0.001), tot_loss_proj:1.804 [t=0.18s]
prediction: ['[CLS] gaining much momentum [SEP]']
Done with input #2 of 100.
reference: 
========================
[CLS] gaining much momentum [SEP]
========================
predicted: 
========================
[CLS] gaining much momentum [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #2 time: 0:08:33 | total time: 0:25:45


Running input #3 of 100.
reference: 
========================
flawless film 
========================
average of cosine similarity 0.9993001481006445
highest_index [0]
highest [0.9993001481006445]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 27503,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] flawless film [SEP]']
[Init] best rec loss: 1.7515515089035034 for ['[CLS] fund integration [SEP]']
[Init] best rec loss: 1.515498399734497 for ['[CLS] pot reaction [SEP]']
[Init] best rec loss: 1.510279893875122 for ['[CLS] committee deportivo [SEP]']
[Init] best rec loss: 1.5031687021255493 for ['[CLS] carry including [SEP]']
[Init] best rec loss: 1.4859191179275513 for ['[CLS] has block [SEP]']
[Init] best rec loss: 1.312357783317566 for ['[CLS] anton laughed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.921 (perp=8.385, rec=0.237, cos=0.007), tot_loss_proj:1.771 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[ 100/2000] tot_loss=1.760 (perp=8.385, rec=0.082, cos=0.002), tot_loss_proj:1.756 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 150/2000] tot_loss=1.751 (perp=8.385, rec=0.073, cos=0.001), tot_loss_proj:1.755 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[ 200/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.762 [t=0.17s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.731 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.761 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
[ 300/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.765 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.762 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.732 (perp=8.385, rec=0.054, cos=0.001), tot_loss_proj:1.761 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 450/2000] tot_loss=1.742 (perp=8.385, rec=0.064, cos=0.001), tot_loss_proj:1.765 [t=0.23s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.730 (perp=8.385, rec=0.052, cos=0.001), tot_loss_proj:1.757 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.763 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[ 600/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.759 [t=0.24s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.728 (perp=8.385, rec=0.050, cos=0.001), tot_loss_proj:1.757 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.758 [t=0.27s]
prediction: ['[CLS] flawless film [SEP]']
[ 750/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.767 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.729 (perp=8.385, rec=0.051, cos=0.001), tot_loss_proj:1.756 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.762 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[ 900/2000] tot_loss=1.742 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.751 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.743 (perp=8.385, rec=0.065, cos=0.001), tot_loss_proj:1.760 [t=0.25s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.764 [t=0.21s]
prediction: ['[CLS] flawless film [SEP]']
[1050/2000] tot_loss=1.734 (perp=8.385, rec=0.056, cos=0.001), tot_loss_proj:1.766 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.753 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.759 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
[1200/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.764 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.738 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.767 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.760 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1350/2000] tot_loss=1.745 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.751 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.735 (perp=8.385, rec=0.057, cos=0.001), tot_loss_proj:1.771 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.753 (perp=8.385, rec=0.074, cos=0.001), tot_loss_proj:1.762 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
[1500/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.756 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.739 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.759 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.740 (perp=8.385, rec=0.062, cos=0.001), tot_loss_proj:1.752 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
[1650/2000] tot_loss=1.738 (perp=8.385, rec=0.060, cos=0.001), tot_loss_proj:1.762 [t=0.22s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.746 (perp=8.385, rec=0.067, cos=0.001), tot_loss_proj:1.760 [t=0.18s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.736 (perp=8.385, rec=0.058, cos=0.001), tot_loss_proj:1.761 [t=0.26s]
prediction: ['[CLS] flawless film [SEP]']
[1800/2000] tot_loss=1.740 (perp=8.385, rec=0.061, cos=0.001), tot_loss_proj:1.758 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.726 (perp=8.385, rec=0.048, cos=0.001), tot_loss_proj:1.763 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.741 (perp=8.385, rec=0.063, cos=0.001), tot_loss_proj:1.763 [t=0.20s]
prediction: ['[CLS] flawless film [SEP]']
[1950/2000] tot_loss=1.733 (perp=8.385, rec=0.055, cos=0.001), tot_loss_proj:1.757 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.737 (perp=8.385, rec=0.059, cos=0.001), tot_loss_proj:1.760 [t=0.19s]
prediction: ['[CLS] flawless film [SEP]']
Done with input #3 of 100.
reference: 
========================
[CLS] flawless film [SEP]
========================
predicted: 
========================
[CLS] flawless film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #3 time: 0:08:13 | total time: 0:33:59


Running input #4 of 100.
reference: 
========================
tiresomely 
========================
average of cosine similarity 0.9992301171062454
highest_index [0]
highest [0.9992301171062454]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 13310,  8462,  2135,   102]], device='cuda:0')
Debug: ref = ['[CLS] tiresomely [SEP]']
[Init] best rec loss: 1.8612022399902344 for ['[CLS] before departmentssh [SEP]']
[Init] best rec loss: 1.8395576477050781 for ['[CLS] stay squeak mean [SEP]']
[Init] best rec loss: 1.7808197736740112 for ['[CLS] watch joint weekly [SEP]']
[Init] best rec loss: 1.7083849906921387 for ['[CLS] religious tip seat [SEP]']
[Init] best rec loss: 1.4955319166183472 for ['[CLS] differenceparts bad [SEP]']
[Init] best rec loss: 1.2935547828674316 for ['[CLS] fatedss jack [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.120 (perp=9.706, rec=0.172, cos=0.007), tot_loss_proj:2.156 [t=0.18s]
prediction: ['[CLS] tiresomently [SEP]']
[ 100/2000] tot_loss=1.585 (perp=7.516, rec=0.079, cos=0.002), tot_loss_proj:1.579 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[ 150/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.573 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[ 200/2000] tot_loss=1.579 (perp=7.516, rec=0.075, cos=0.002), tot_loss_proj:1.564 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.573 (perp=7.516, rec=0.068, cos=0.001), tot_loss_proj:1.574 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[ 300/2000] tot_loss=1.560 (perp=7.516, rec=0.056, cos=0.001), tot_loss_proj:1.578 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.563 (perp=7.516, rec=0.058, cos=0.001), tot_loss_proj:1.566 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.561 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.578 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[ 450/2000] tot_loss=1.567 (perp=7.516, rec=0.062, cos=0.002), tot_loss_proj:1.564 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.001), tot_loss_proj:1.568 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.568 (perp=7.516, rec=0.063, cos=0.001), tot_loss_proj:1.573 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
[ 600/2000] tot_loss=1.563 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.568 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.566 (perp=7.516, rec=0.062, cos=0.002), tot_loss_proj:1.557 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.562 (perp=7.516, rec=0.057, cos=0.002), tot_loss_proj:1.561 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[ 750/2000] tot_loss=1.568 (perp=7.516, rec=0.064, cos=0.002), tot_loss_proj:1.565 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.567 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.570 (perp=7.516, rec=0.065, cos=0.002), tot_loss_proj:1.570 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[ 900/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.553 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.566 (perp=7.516, rec=0.061, cos=0.002), tot_loss_proj:1.564 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1000/2000] tot_loss=1.572 (perp=7.516, rec=0.067, cos=0.002), tot_loss_proj:1.572 [t=0.22s]
prediction: ['[CLS] tiresomely [SEP]']
[1050/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.570 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1100/2000] tot_loss=1.574 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.564 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1150/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.572 [t=0.27s]
prediction: ['[CLS] tiresomely [SEP]']
[1200/2000] tot_loss=1.564 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.563 [t=0.30s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1250/2000] tot_loss=1.573 (perp=7.516, rec=0.069, cos=0.002), tot_loss_proj:1.568 [t=0.19s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1300/2000] tot_loss=1.559 (perp=7.516, rec=0.054, cos=0.002), tot_loss_proj:1.570 [t=0.26s]
prediction: ['[CLS] tiresomely [SEP]']
[1350/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.558 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1400/2000] tot_loss=1.568 (perp=7.516, rec=0.063, cos=0.002), tot_loss_proj:1.567 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1450/2000] tot_loss=1.565 (perp=7.516, rec=0.060, cos=0.002), tot_loss_proj:1.556 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
[1500/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.564 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1550/2000] tot_loss=1.567 (perp=7.516, rec=0.063, cos=0.002), tot_loss_proj:1.552 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1600/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.560 [t=0.25s]
prediction: ['[CLS] tiresomely [SEP]']
[1650/2000] tot_loss=1.564 (perp=7.516, rec=0.059, cos=0.002), tot_loss_proj:1.565 [t=0.23s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1700/2000] tot_loss=1.561 (perp=7.516, rec=0.056, cos=0.002), tot_loss_proj:1.562 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1750/2000] tot_loss=1.576 (perp=7.516, rec=0.071, cos=0.002), tot_loss_proj:1.559 [t=0.21s]
prediction: ['[CLS] tiresomely [SEP]']
[1800/2000] tot_loss=1.571 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.556 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1850/2000] tot_loss=1.568 (perp=7.516, rec=0.063, cos=0.002), tot_loss_proj:1.571 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[1900/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.574 [t=0.18s]
prediction: ['[CLS] tiresomely [SEP]']
[1950/2000] tot_loss=1.570 (perp=7.516, rec=0.066, cos=0.002), tot_loss_proj:1.555 [t=0.20s]
prediction: ['[CLS] tiresomely [SEP]']
Attempt swap
[2000/2000] tot_loss=1.560 (perp=7.516, rec=0.055, cos=0.002), tot_loss_proj:1.583 [t=0.24s]
prediction: ['[CLS] tiresomely [SEP]']
Done with input #4 of 100.
reference: 
========================
[CLS] tiresomely [SEP]
========================
predicted: 
========================
[CLS] tiresomely [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

input #4 time: 0:08:19 | total time: 0:42:18


Running input #5 of 100.
reference: 
========================
enjoyable ease 
========================
average of cosine similarity 0.9993649146105028
highest_index [0]
highest [0.9993649146105028]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 22249,  7496,   102]], device='cuda:0')
Debug: ref = ['[CLS] enjoyable ease [SEP]']
[Init] best rec loss: 1.7795944213867188 for ['[CLS] pays country [SEP]']
[Init] best rec loss: 1.6453757286071777 for ['[CLS] works flow [SEP]']
[Init] best rec loss: 1.6053582429885864 for ['[CLS] sol liked [SEP]']
[Init] best rec loss: 1.5769269466400146 for ['[CLS] em madame [SEP]']
[Init] best rec loss: 1.4209589958190918 for ['[CLS] eye central [SEP]']
[Init] best perm rec loss: 1.41153085231781 for ['[CLS] central eye [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.642 (perp=12.316, rec=0.175, cos=0.004), tot_loss_proj:2.547 [t=0.18s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 100/2000] tot_loss=2.589 (perp=12.316, rec=0.122, cos=0.003), tot_loss_proj:2.561 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 150/2000] tot_loss=2.581 (perp=12.316, rec=0.114, cos=0.003), tot_loss_proj:2.534 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
[ 200/2000] tot_loss=2.587 (perp=12.316, rec=0.121, cos=0.003), tot_loss_proj:2.533 [t=0.19s]
prediction: ['[CLS] enjoyable ease [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.511 (perp=11.854, rec=0.137, cos=0.003), tot_loss_proj:2.563 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 300/2000] tot_loss=2.486 (perp=11.854, rec=0.112, cos=0.003), tot_loss_proj:2.576 [t=0.28s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.480 (perp=11.854, rec=0.106, cos=0.003), tot_loss_proj:2.569 [t=0.29s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.484 (perp=11.854, rec=0.110, cos=0.003), tot_loss_proj:2.571 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 450/2000] tot_loss=2.433 (perp=11.854, rec=0.061, cos=0.001), tot_loss_proj:2.579 [t=0.23s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.440 (perp=11.854, rec=0.068, cos=0.001), tot_loss_proj:2.567 [t=0.24s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.450 (perp=11.854, rec=0.078, cos=0.001), tot_loss_proj:2.576 [t=0.20s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 600/2000] tot_loss=2.430 (perp=11.854, rec=0.058, cos=0.001), tot_loss_proj:2.578 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.438 (perp=11.854, rec=0.066, cos=0.001), tot_loss_proj:2.579 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.426 (perp=11.854, rec=0.054, cos=0.001), tot_loss_proj:2.570 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 750/2000] tot_loss=2.415 (perp=11.854, rec=0.043, cos=0.001), tot_loss_proj:2.575 [t=0.21s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.431 (perp=11.854, rec=0.059, cos=0.001), tot_loss_proj:2.580 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.425 (perp=11.854, rec=0.053, cos=0.001), tot_loss_proj:2.573 [t=0.20s]
prediction: ['[CLS] ease enjoyable [SEP]']
[ 900/2000] tot_loss=2.425 (perp=11.854, rec=0.053, cos=0.001), tot_loss_proj:2.583 [t=0.20s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.439 (perp=11.854, rec=0.066, cos=0.001), tot_loss_proj:2.577 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1000/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.571 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1050/2000] tot_loss=2.434 (perp=11.854, rec=0.061, cos=0.001), tot_loss_proj:2.580 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1100/2000] tot_loss=2.449 (perp=11.854, rec=0.077, cos=0.001), tot_loss_proj:2.571 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1150/2000] tot_loss=2.419 (perp=11.854, rec=0.047, cos=0.001), tot_loss_proj:2.592 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1200/2000] tot_loss=2.422 (perp=11.854, rec=0.050, cos=0.001), tot_loss_proj:2.567 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1250/2000] tot_loss=2.433 (perp=11.854, rec=0.061, cos=0.001), tot_loss_proj:2.577 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1300/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.570 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1350/2000] tot_loss=2.441 (perp=11.854, rec=0.069, cos=0.001), tot_loss_proj:2.568 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1400/2000] tot_loss=2.434 (perp=11.854, rec=0.062, cos=0.001), tot_loss_proj:2.570 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1450/2000] tot_loss=2.436 (perp=11.854, rec=0.064, cos=0.001), tot_loss_proj:2.568 [t=0.27s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1500/2000] tot_loss=2.424 (perp=11.854, rec=0.051, cos=0.001), tot_loss_proj:2.567 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1550/2000] tot_loss=2.433 (perp=11.854, rec=0.061, cos=0.001), tot_loss_proj:2.584 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1600/2000] tot_loss=2.430 (perp=11.854, rec=0.058, cos=0.001), tot_loss_proj:2.571 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1650/2000] tot_loss=2.439 (perp=11.854, rec=0.067, cos=0.001), tot_loss_proj:2.578 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1700/2000] tot_loss=2.416 (perp=11.854, rec=0.044, cos=0.001), tot_loss_proj:2.573 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1750/2000] tot_loss=2.429 (perp=11.854, rec=0.057, cos=0.001), tot_loss_proj:2.582 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1800/2000] tot_loss=2.435 (perp=11.854, rec=0.063, cos=0.001), tot_loss_proj:2.571 [t=0.22s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1850/2000] tot_loss=2.438 (perp=11.854, rec=0.066, cos=0.001), tot_loss_proj:2.569 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[1900/2000] tot_loss=2.440 (perp=11.854, rec=0.068, cos=0.001), tot_loss_proj:2.569 [t=0.19s]
prediction: ['[CLS] ease enjoyable [SEP]']
[1950/2000] tot_loss=2.446 (perp=11.854, rec=0.074, cos=0.001), tot_loss_proj:2.572 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
Attempt swap
[2000/2000] tot_loss=2.431 (perp=11.854, rec=0.059, cos=0.001), tot_loss_proj:2.576 [t=0.18s]
prediction: ['[CLS] ease enjoyable [SEP]']
Done with input #5 of 100.
reference: 
========================
[CLS] enjoyable ease [SEP]
========================
predicted: 
========================
[CLS] ease enjoyable [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 83.333 | p: 83.333 | r: 83.333
rougeL     | fm: 95.833 | p: 95.833 | r: 95.833
rougeLsum  | fm: 95.833 | p: 95.833 | r: 95.833
r1fm+r2fm = 183.333

input #5 time: 0:08:15 | total time: 0:50:34


Running input #6 of 100.
reference: 
========================
grayish 
========================
average of cosine similarity 0.999250469444722
highest_index [0]
highest [0.999250469444722]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 3897, 4509,  102]], device='cuda:0')
Debug: ref = ['[CLS] grayish [SEP]']
[Init] best rec loss: 1.902685284614563 for ['[CLS] cassidyiot [SEP]']
[Init] best rec loss: 1.7486958503723145 for ['[CLS] values ballad [SEP]']
[Init] best rec loss: 1.7067688703536987 for ['[CLS] gifted frequently [SEP]']
[Init] best rec loss: 1.5019043684005737 for ['[CLS] handed canteen [SEP]']
[Init] best rec loss: 1.2771662473678589 for ['[CLS] air little [SEP]']
[Init] best rec loss: 1.2549055814743042 for ['[CLS] just endemic [SEP]']
[Init] best rec loss: 1.249065637588501 for ['[CLS] brooklyn darren [SEP]']
[Init] best rec loss: 1.124966025352478 for ['[CLS] double deep [SEP]']
[Init] best rec loss: 1.1203830242156982 for ['[CLS] too u2 [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.599 (perp=6.813, rec=0.222, cos=0.015), tot_loss_proj:2.724 [t=0.18s]
prediction: ['[CLS] gray gray [SEP]']
[ 100/2000] tot_loss=1.724 (perp=8.089, rec=0.103, cos=0.003), tot_loss_proj:1.691 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 150/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.693 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[ 200/2000] tot_loss=1.672 (perp=8.089, rec=0.052, cos=0.002), tot_loss_proj:1.701 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.697 [t=0.28s]
prediction: ['[CLS] grayish [SEP]']
[ 300/2000] tot_loss=1.682 (perp=8.089, rec=0.063, cos=0.002), tot_loss_proj:1.691 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.708 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.679 (perp=8.089, rec=0.060, cos=0.002), tot_loss_proj:1.683 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[ 450/2000] tot_loss=1.666 (perp=8.089, rec=0.047, cos=0.002), tot_loss_proj:1.696 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.692 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.002), tot_loss_proj:1.696 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[ 600/2000] tot_loss=1.686 (perp=8.089, rec=0.067, cos=0.002), tot_loss_proj:1.699 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.674 (perp=8.089, rec=0.055, cos=0.002), tot_loss_proj:1.694 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.670 (perp=8.089, rec=0.051, cos=0.002), tot_loss_proj:1.697 [t=0.25s]
prediction: ['[CLS] grayish [SEP]']
[ 750/2000] tot_loss=1.688 (perp=8.089, rec=0.069, cos=0.002), tot_loss_proj:1.686 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.689 (perp=8.089, rec=0.070, cos=0.002), tot_loss_proj:1.683 [t=0.21s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.674 (perp=8.089, rec=0.055, cos=0.002), tot_loss_proj:1.694 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[ 900/2000] tot_loss=1.691 (perp=8.089, rec=0.072, cos=0.002), tot_loss_proj:1.688 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.691 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1000/2000] tot_loss=1.691 (perp=8.089, rec=0.072, cos=0.002), tot_loss_proj:1.691 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
[1050/2000] tot_loss=1.681 (perp=8.089, rec=0.062, cos=0.002), tot_loss_proj:1.707 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1100/2000] tot_loss=1.685 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.701 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1150/2000] tot_loss=1.676 (perp=8.089, rec=0.056, cos=0.002), tot_loss_proj:1.694 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
[1200/2000] tot_loss=1.673 (perp=8.089, rec=0.054, cos=0.001), tot_loss_proj:1.691 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1250/2000] tot_loss=1.678 (perp=8.089, rec=0.058, cos=0.001), tot_loss_proj:1.680 [t=0.18s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1300/2000] tot_loss=1.679 (perp=8.089, rec=0.059, cos=0.001), tot_loss_proj:1.675 [t=0.23s]
prediction: ['[CLS] grayish [SEP]']
[1350/2000] tot_loss=1.695 (perp=8.089, rec=0.075, cos=0.001), tot_loss_proj:1.685 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1400/2000] tot_loss=1.667 (perp=8.089, rec=0.048, cos=0.001), tot_loss_proj:1.686 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1450/2000] tot_loss=1.686 (perp=8.089, rec=0.066, cos=0.001), tot_loss_proj:1.698 [t=0.24s]
prediction: ['[CLS] grayish [SEP]']
[1500/2000] tot_loss=1.694 (perp=8.089, rec=0.074, cos=0.001), tot_loss_proj:1.686 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1550/2000] tot_loss=1.673 (perp=8.089, rec=0.054, cos=0.002), tot_loss_proj:1.679 [t=0.22s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1600/2000] tot_loss=1.681 (perp=8.089, rec=0.062, cos=0.001), tot_loss_proj:1.686 [t=0.27s]
prediction: ['[CLS] grayish [SEP]']
[1650/2000] tot_loss=1.675 (perp=8.089, rec=0.056, cos=0.001), tot_loss_proj:1.697 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1700/2000] tot_loss=1.676 (perp=8.089, rec=0.057, cos=0.001), tot_loss_proj:1.678 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1750/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.001), tot_loss_proj:1.687 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
[1800/2000] tot_loss=1.684 (perp=8.089, rec=0.065, cos=0.001), tot_loss_proj:1.688 [t=0.29s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1850/2000] tot_loss=1.688 (perp=8.089, rec=0.068, cos=0.001), tot_loss_proj:1.693 [t=0.19s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[1900/2000] tot_loss=1.668 (perp=8.089, rec=0.048, cos=0.002), tot_loss_proj:1.685 [t=0.26s]
prediction: ['[CLS] grayish [SEP]']
[1950/2000] tot_loss=1.680 (perp=8.089, rec=0.061, cos=0.002), tot_loss_proj:1.699 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Attempt swap
[2000/2000] tot_loss=1.683 (perp=8.089, rec=0.064, cos=0.002), tot_loss_proj:1.690 [t=0.20s]
prediction: ['[CLS] grayish [SEP]']
Done with input #6 of 100.
reference: 
========================
[CLS] grayish [SEP]
========================
predicted: 
========================
[CLS] grayish [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 85.714 | p: 85.714 | r: 85.714
rougeL     | fm: 96.429 | p: 96.429 | r: 96.429
rougeLsum  | fm: 96.429 | p: 96.429 | r: 96.429
r1fm+r2fm = 185.714

input #6 time: 0:08:31 | total time: 0:59:05


Running input #7 of 100.
reference: 
========================
no cute factor here ... not that i mind ugly ; the problem is he has no character , loveable or otherwise . 
========================
average of cosine similarity 0.9991768686555793
highest_index [0]
highest [0.9991768686555793]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  2053, 10140,  5387,  2182,  1012,  1012,  1012,  2025,  2008,
          1045,  2568,  9200,  1025,  1996,  3291,  2003,  2002,  2038,  2053,
          2839,  1010,  2293,  3085,  2030,  4728,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]']
[Init] best rec loss: 1.8152823448181152 for ['[CLS] emperor show lowry speechded onesgrin paste connection event complex fair signsuously sparkling comedycarriage each death channels cross sooner dayuo petals clan [SEP]']
[Init] best rec loss: 1.3960720300674438 for ['[CLS] pilotden split cherokeecarriage minutephy runaway generation ruth episode grandmaster reddy mode disguise usual driveway par snowbound class parallel pouring mira rifles appeal [SEP]']
[Init] best rec loss: 1.3859511613845825 for ['[CLS] vance golf belt handyolved fl researchtium anonymousina me man murphyoof bearing zetavocationtellrti american autopsy that lie amongₑ free [SEP]']
[Init] best rec loss: 1.2355339527130127 for ['[CLS]nies pacific disease life animal alec none mukherjee moffat on consisting ran battalionzed gold depending 17th blow classics career main manual madagascar tourismide sony [SEP]']
[Init] best rec loss: 1.1908916234970093 for ['[CLS] cod dock # openר sat both grande flow hs most purpose baby beings comppia jenny infants part end pay exactly conference moths median [SEP]']
[Init] best perm rec loss: 1.1874291896820068 for ['[CLS] cod conference dock moths most com baby open hs median purpose flow exactly part end bothp jennypia # sat infants payר beings grande [SEP]']
[Init] best perm rec loss: 1.1840190887451172 for ['[CLS] cod pay part mothsר most hs baby infants grande both sat dockpia beings exactly purpose flow end conference comp jenny open median # [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.519 (perp=10.768, rec=0.339, cos=0.027), tot_loss_proj:3.026 [t=0.25s]
prediction: ['[CLS] having bad issue sired problem no crime his wainwright stuck ugly sick symptoms problembox no or soon or almost., problem sexual bad problem [SEP]']
[ 100/2000] tot_loss=2.316 (perp=9.913, rec=0.296, cos=0.037), tot_loss_proj:2.828 [t=0.19s]
prediction: ['[CLS] having bad joke ugly he no ugly character character problem ugly? character problem which no or m or is. nothingied fond problem resulting [SEP]']
[ 150/2000] tot_loss=2.798 (perp=9.903, rec=0.621, cos=0.196), tot_loss_proj:3.375 [t=0.26s]
prediction: ['[CLS] minusogical programming miserable currently no transformed ugly import symptoms ugly ( character problem ო no has highness " is. no is often problem result [SEP]']
[ 200/2000] tot_loss=3.026 (perp=11.868, rec=0.510, cos=0.142), tot_loss_proj:4.145 [t=0.21s]
prediction: ['[CLS] minus injusticeicate miserable besides never transformed short importtious [ usually constitutes problem quoted communist therefore majesty " is. no is often problem ezio [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.646 (perp=10.505, rec=0.448, cos=0.097), tot_loss_proj:3.939 [t=0.22s]
prediction: ['[CLS] minus injustice usually miserable besides never transformed short importtious [isance is problem quote future usually majesty " is. no is often problem ezio [SEP]']
[ 300/2000] tot_loss=2.647 (perp=10.820, rec=0.412, cos=0.071), tot_loss_proj:3.873 [t=0.19s]
prediction: ['[CLS] minus pollution usually miserable besides never transformed short importtious [zziness is problem structures future usually. " is. no is often problem christmas [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.525 (perp=10.400, rec=0.388, cos=0.057), tot_loss_proj:3.375 [t=0.23s]
prediction: ['[CLS] minus is became miserable currently never transformed short importtious usually mendoza is problem fungus future usually. " canadian. no is poets problem theme [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.507 (perp=10.477, rec=0.364, cos=0.048), tot_loss_proj:3.200 [t=0.19s]
prediction: ['[CLS] minus is became miserable. never transformed littleztious usually mendoza character problem fungus future usually. " canadian currently no is poets problem theme [SEP]']
[ 450/2000] tot_loss=2.323 (perp=9.653, rec=0.351, cos=0.041), tot_loss_proj:3.067 [t=0.19s]
prediction: ['[CLS] minus is became miserable. never usually littlez symptoms usually fluffy character problem fungus than usually. " canadian currently no is often problem theme [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.427 (perp=10.250, rec=0.342, cos=0.036), tot_loss_proj:2.920 [t=0.19s]
prediction: ['[CLS] minus isˈ miserable. never usually littlez〈 ugly fluffy character problem pilgrimage than usually. " currently no is poets printed problem theme [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.299 (perp=9.651, rec=0.336, cos=0.033), tot_loss_proj:3.012 [t=0.19s]
prediction: ['[CLS] minus isˈ miserable. never usually littlezaux ugly fluffy character problem pilgrimage than usually poets. " currently no is printed problem theme [SEP]']
[ 600/2000] tot_loss=2.339 (perp=9.963, rec=0.317, cos=0.029), tot_loss_proj:2.928 [t=0.27s]
prediction: ['[CLS] favour isˈ miserable. never usually littlez oracle ugly fluffy character problem pilgrimage than usually poets. " currently no is printed problem theme [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.302 (perp=9.820, rec=0.312, cos=0.026), tot_loss_proj:2.982 [t=0.24s]
prediction: ['[CLS] little isˈ miserable. never usually minusz neither ugly fluffy character problem satirical than usually poets. " currently no is printed problem theme [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.244 (perp=9.534, rec=0.314, cos=0.024), tot_loss_proj:2.811 [t=0.19s]
prediction: ['[CLS] ugly isˈ miserable. never usually uglyz neither minus fluffy character problem satirical than usually poets. " currently no is written problem theme [SEP]']
[ 750/2000] tot_loss=2.189 (perp=9.333, rec=0.301, cos=0.021), tot_loss_proj:2.742 [t=0.19s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz ( minus fluffy character problem satirical than usually poets. " currently no is hodgson problem theme [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.246 (perp=9.657, rec=0.294, cos=0.020), tot_loss_proj:2.815 [t=0.23s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz ( mentions fluffy character problem satirical than usually poets. " currently no is hodgson problem theme [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.216 (perp=9.503, rec=0.295, cos=0.021), tot_loss_proj:3.045 [t=0.25s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz ( mentions fluffy character is satirical than usually poets. are currently no problem hodgson problem theme [SEP]']
[ 900/2000] tot_loss=2.232 (perp=9.632, rec=0.287, cos=0.019), tot_loss_proj:3.019 [t=0.19s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz ( mentions fluffy character is satirical future usually poets. are currently no problem hodgson problem theme [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.234 (perp=9.669, rec=0.283, cos=0.018), tot_loss_proj:2.882 [t=0.22s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz future least characters character is satirical ( usually poets. are currently no problem hodgson problem theme [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.232 (perp=9.661, rec=0.283, cos=0.016), tot_loss_proj:2.982 [t=0.19s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed characters character future satirical un usually poets. are currently no problem hodgson problem theme [SEP]']
[1050/2000] tot_loss=2.322 (perp=10.178, rec=0.270, cos=0.016), tot_loss_proj:3.101 [t=0.19s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed emotions character future satirical un usually poets. are currently no problem hodgson problem theme [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=2.273 (perp=9.964, rec=0.264, cos=0.016), tot_loss_proj:3.048 [t=0.20s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed emotions character futureas un poets usually. are currently no problem hodgson problem theme [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.199 (perp=9.579, rec=0.267, cos=0.016), tot_loss_proj:2.968 [t=0.25s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed character emotions futureas un poets usually. are currently no problem hodgson problem theme [SEP]']
[1200/2000] tot_loss=2.207 (perp=9.579, rec=0.276, cos=0.015), tot_loss_proj:2.973 [t=0.19s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed character emotions futureas un poets usually. are currently no problem hodgson problem theme [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.155 (perp=9.367, rec=0.266, cos=0.015), tot_loss_proj:2.939 [t=0.20s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed character emotions futureas un poets are usually. currently no problem hodgson problem theme [SEP]']
Attempt swap
[1300/2000] tot_loss=2.156 (perp=9.367, rec=0.267, cos=0.015), tot_loss_proj:2.937 [t=0.28s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed character emotions futureas un poets are usually. currently no problem hodgson problem theme [SEP]']
[1350/2000] tot_loss=2.151 (perp=9.367, rec=0.263, cos=0.015), tot_loss_proj:2.932 [t=0.20s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed character emotions futureas un poets are usually. currently no problem hodgson problem theme [SEP]']
Attempt swap
[1400/2000] tot_loss=2.145 (perp=9.367, rec=0.257, cos=0.015), tot_loss_proj:2.937 [t=0.27s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed character emotions futureas un poets are usually. currently no problem hodgson problem theme [SEP]']
Attempt swap
[1450/2000] tot_loss=2.149 (perp=9.367, rec=0.261, cos=0.014), tot_loss_proj:2.937 [t=0.18s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is destroyed character emotions futureas un poets are usually. currently no problem hodgson problem theme [SEP]']
[1500/2000] tot_loss=2.167 (perp=9.488, rec=0.255, cos=0.014), tot_loss_proj:3.026 [t=0.28s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is weakened character emotions futureas un poets are usually. currently no problem hodgson problem theme [SEP]']
Attempt swap
[1550/2000] tot_loss=2.161 (perp=9.488, rec=0.250, cos=0.014), tot_loss_proj:3.028 [t=0.18s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is weakened character emotions futureas un poets are usually. currently no problem hodgson problem theme [SEP]']
Attempt swap
[1600/2000] tot_loss=2.175 (perp=9.488, rec=0.263, cos=0.014), tot_loss_proj:3.024 [t=0.19s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is weakened character emotions futureas un poets are usually. currently no problem hodgson problem theme [SEP]']
[1650/2000] tot_loss=2.152 (perp=9.417, rec=0.255, cos=0.014), tot_loss_proj:2.845 [t=0.32s]
prediction: ['[CLS] ugly is twinned miserable. never usually uglyz is not character emotions futureas un often are usually. currently no problem hodgson problem theme [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=2.096 (perp=9.046, rec=0.270, cos=0.017), tot_loss_proj:2.848 [t=0.21s]
prediction: ['[CLS] ugly is twinned miserable. never usually ugly is not character emotions futureasz un poets are usually. currently no problem hodgson problem [SEP] [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=2.085 (perp=9.006, rec=0.268, cos=0.016), tot_loss_proj:2.802 [t=0.19s]
prediction: ['[CLS] ugly is twinned miserable. never usually ugly is not character emotions futureasz usually un poets are. currently no problem hodgson problem [SEP] [SEP]']
[1800/2000] tot_loss=2.079 (perp=9.006, rec=0.263, cos=0.015), tot_loss_proj:2.803 [t=0.18s]
prediction: ['[CLS] ugly is twinned miserable. never usually ugly is not character emotions futureasz usually un poets are. currently no problem hodgson problem [SEP] [SEP]']
Attempt swap
[1850/2000] tot_loss=2.080 (perp=9.006, rec=0.265, cos=0.015), tot_loss_proj:2.797 [t=0.19s]
prediction: ['[CLS] ugly is twinned miserable. never usually ugly is not character emotions futureasz usually un poets are. currently no problem hodgson problem [SEP] [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=2.030 (perp=8.762, rec=0.263, cos=0.015), tot_loss_proj:2.747 [t=0.25s]
prediction: ['[CLS] ugly is twinned miserable. never usually ugly is not character emotions futureasz usually un poets are. [SEP] currently no problem hodgson problem [SEP]']
[1950/2000] tot_loss=2.119 (perp=9.250, rec=0.254, cos=0.014), tot_loss_proj:2.825 [t=0.28s]
prediction: ['[CLS] ugly is twinned miserable. never usually ugly is not character emotions future literaryz usually un poets are. [SEP] currently no problem hodgson problem [SEP]']
Attempt swap
[2000/2000] tot_loss=2.127 (perp=9.250, rec=0.263, cos=0.014), tot_loss_proj:2.821 [t=0.19s]
prediction: ['[CLS] ugly is twinned miserable. never usually ugly is not character emotions future literaryz usually un poets are. [SEP] currently no problem hodgson problem [SEP]']
Done with input #7 of 100.
reference: 
========================
[CLS] no cute factor here... not that i mind ugly ; the problem is he has no character, loveable or otherwise. [SEP]
========================
predicted: 
========================
[CLS] having bad spite ugly he no ugly ugly character problem ugly he character problem which no or listed he is. nothinginated fond problem resulting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 42.553 | p: 38.462 | r: 47.619
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 34.043 | p: 30.769 | r: 38.095
rougeLsum  | fm: 34.043 | p: 30.769 | r: 38.095
r1fm+r2fm = 42.553

[Aggregate metrics]:
rouge1     | fm: 92.819 | p: 92.308 | r: 93.452
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 88.630 | p: 88.221 | r: 89.137
rougeLsum  | fm: 88.630 | p: 88.221 | r: 89.137
r1fm+r2fm = 167.819

input #7 time: 0:08:42 | total time: 1:07:48


Running input #8 of 100.
reference: 
========================
's a frightful vanity film that , no doubt , pays off what debt miramax felt they owed to benigni 
========================
average of cosine similarity 0.9994032830483026
highest_index [0]
highest [0.9994032830483026]
Debug: ids_shape = 26, pads = [26]
Debug: input ids = tensor([[  101,  1005,  1055,  1037, 25966,  3993, 18736,  2143,  2008,  1010,
          2053,  4797,  1010, 12778,  2125,  2054,  7016, 18062, 17848,  2371,
          2027, 12232,  2000, 28378,  2072,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]"]
[Init] best rec loss: 1.3184598684310913 for ['[CLS] challenges pa over computer taught lea eye clubs their paris alloy table currently fitting southern bargain luxury learning cinema those band gr across passage [SEP]']
[Init] best rec loss: 1.3084146976470947 for ['[CLS] thunder edge tender youngaz 505acality forced cheers bed lochley concacaf pm some commercial eliot advocate flow bubble habits ease bless [SEP]']
[Init] best rec loss: 1.29958176612854 for ['[CLS] slate conducted maps charlierocity these leaked too count search cody misery cannon vet vote prior foreign. ratio atm boys trafficrating 1st [SEP]']
[Init] best rec loss: 1.2899292707443237 for ['[CLS] descent caughtway holiday riding fist stages died pi focusedョeis anywhere half vine tarzan center sunlight away broughteda held reserved website [SEP]']
[Init] best perm rec loss: 1.2864528894424438 for ['[CLS] reserved focused away stages riding tarzanway caught center anywhere brought pi sunlight website holiday fist half held diedeis descenteda vineョ [SEP]']
[Init] best perm rec loss: 1.2788499593734741 for ['[CLS] stages holiday descent sunlightway half center fist away vine died tarzan riding focused website pi anywhere broughtedaeis heldョ reserved caught [SEP]']
[Init] best perm rec loss: 1.2772839069366455 for ['[CLS] anywhere stages riding halfeis away died center held focusedway brought tarzan sunlight holiday reservededa pi descentョ caught fist website vine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.439 (perp=14.147, rec=0.439, cos=0.170), tot_loss_proj:4.210 [t=0.23s]
prediction: ['[CLS] estate ( adjacent miracle season rise kingdom conference cbn debt lakes pena unpaid although punishment core val lodge harbour abbey played passage tournament assist [SEP]']
[ 100/2000] tot_loss=3.419 (perp=13.710, rec=0.472, cos=0.204), tot_loss_proj:3.981 [t=0.19s]
prediction: ['[CLS]brook cash operations ivy law debt union ) nedra mused areas enjoys owed ; vanity vanity mor vanity gems phoenix players passage thriller pleas [SEP]']
[ 150/2000] tot_loss=2.857 (perp=12.449, rec=0.310, cos=0.057), tot_loss_proj:3.905 [t=0.27s]
prediction: ['[CLS] hired cash film curious law debt only film indeed vacancy it robot vanity ; vanity derivative extensively vanity servestrain players debtc ¡ [SEP]']
[ 200/2000] tot_loss=2.769 (perp=12.423, rec=0.253, cos=0.032), tot_loss_proj:3.792 [t=0.23s]
prediction: ['[CLS] rented cash film a somerset gallons vanity film vanity doubt himself robot vanity reality vanity derivative carefully vanity pays pays players debt, ¡ [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.680 (perp=11.909, rec=0.263, cos=0.034), tot_loss_proj:4.022 [t=0.19s]
prediction: ['[CLS] circulation vanity film cannot films yawned vanity film vanity doubt himself robot vanity reality debt films who vanity pays paying players what, ¡ [SEP]']
[ 300/2000] tot_loss=2.718 (perp=12.457, rec=0.210, cos=0.017), tot_loss_proj:3.852 [t=0.26s]
prediction: ['[CLS] circulation vanity film un tak vanity vanity film vanity doubt himself strange vanity what debt film that fright pays pays who what, ¡ [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.604 (perp=12.011, rec=0.180, cos=0.022), tot_loss_proj:3.829 [t=0.18s]
prediction: ['[CLS] owed owed vanity film un vanity vanity vanity film vanity doubteous vanity off debt something that fright pays pays who what, aiden [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.516 (perp=11.741, rec=0.151, cos=0.016), tot_loss_proj:3.557 [t=0.19s]
prediction: ['[CLS] owed owed vanity film un vanity riley vanity film vanity doubt requests no off debt is that fright pays pays who what, footprints [SEP]']
[ 450/2000] tot_loss=2.791 (perp=13.255, rec=0.131, cos=0.009), tot_loss_proj:3.976 [t=0.19s]
prediction: ['[CLS] owed owed vanity film amax riley vanity film vanity doubt benign no off debt s that fright pays benign debt what, footprints [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.738 (perp=13.075, rec=0.115, cos=0.008), tot_loss_proj:4.075 [t=0.23s]
prediction: ['[CLS] owed un vanity film theymax riley vanity film expect doubt benign no off debt s that fright pays benign debt what, footprints [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.606 (perp=12.404, rec=0.118, cos=0.007), tot_loss_proj:3.864 [t=0.24s]
prediction: ['[CLS] owed a vanity film feltmax aiden vanitymax expect doubt benign no off debt s that fright pays benign debt what,? [SEP]']
[ 600/2000] tot_loss=2.500 (perp=11.930, rec=0.108, cos=0.006), tot_loss_proj:3.784 [t=0.25s]
prediction: ['[CLS] owed a vanity film feltmax aiden vanitymax expect doubt benign no off debt s that fright pays benigni what,? [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.538 (perp=12.100, rec=0.112, cos=0.006), tot_loss_proj:3.801 [t=0.19s]
prediction: ['[CLS] owed a vanity film feltmax aiden resentedmax expect doubt benign no off debt s that fright pays benigni what, vanity [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.487 (perp=11.907, rec=0.100, cos=0.006), tot_loss_proj:3.857 [t=0.30s]
prediction: ['[CLS] owed a vanity resented feltmax aiden filmmax expect doubt benign no off debt s that fright pays benigni what, vanity [SEP]']
[ 750/2000] tot_loss=2.488 (perp=11.907, rec=0.102, cos=0.005), tot_loss_proj:3.857 [t=0.19s]
prediction: ['[CLS] owed a vanity resented feltmax aiden filmmax expect doubt benign no off debt s that fright pays benigni what, vanity [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=2.414 (perp=11.513, rec=0.107, cos=0.005), tot_loss_proj:3.733 [t=0.19s]
prediction: ['[CLS] owed a resented vanity feltmax aiden filmmax expect doubti no off debt s that fright pays benigni what, vanity [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.343 (perp=11.169, rec=0.103, cos=0.007), tot_loss_proj:3.781 [t=0.19s]
prediction: ['[CLS] that a resented vanity feltmax aiden filmmax expect doubti no off debt s owed fright pays benigni what, vanity [SEP]']
[ 900/2000] tot_loss=2.333 (perp=11.169, rec=0.094, cos=0.005), tot_loss_proj:3.777 [t=0.23s]
prediction: ['[CLS] that a resented vanity feltmax aiden filmmax expect doubti no off debt s owed fright pays benigni what, vanity [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.291 (perp=10.925, rec=0.102, cos=0.004), tot_loss_proj:3.696 [t=0.21s]
prediction: ['[CLS] that a resented vanity feltmax aiden filmmax expect doubti no off debt s what fright pays benigni owed, vanity [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=2.224 (perp=10.626, rec=0.094, cos=0.004), tot_loss_proj:3.690 [t=0.20s]
prediction: ['[CLS] that a resented vanity feltmax aiden filmmax expect doubti off no debt s what fright pays benigni owed, vanity [SEP]']
[1050/2000] tot_loss=2.233 (perp=10.626, rec=0.104, cos=0.004), tot_loss_proj:3.689 [t=0.23s]
prediction: ['[CLS] that a resented vanity feltmax aiden filmmax expect doubti off no debt s what fright pays benigni owed, vanity [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.222 (perp=10.584, rec=0.101, cos=0.004), tot_loss_proj:3.684 [t=0.24s]
prediction: ['[CLS] that a resented vanity benmax felt filmmax expect doubti off no debt s what fright pays benigni owed, vanity [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.153 (perp=10.257, rec=0.098, cos=0.004), tot_loss_proj:3.626 [t=0.19s]
prediction: ['[CLS] that a resented vanity benmax felt filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
[1200/2000] tot_loss=2.147 (perp=10.257, rec=0.092, cos=0.004), tot_loss_proj:3.623 [t=0.19s]
prediction: ['[CLS] that a resented vanity benmax felt filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
[1250/2000] tot_loss=2.154 (perp=10.257, rec=0.099, cos=0.003), tot_loss_proj:3.626 [t=0.19s]
prediction: ['[CLS] that a resented vanity benmax felt filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
[1300/2000] tot_loss=2.154 (perp=10.257, rec=0.099, cos=0.003), tot_loss_proj:3.624 [t=0.19s]
prediction: ['[CLS] that a resented vanity benmax felt filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
[1350/2000] tot_loss=2.160 (perp=10.257, rec=0.105, cos=0.003), tot_loss_proj:3.619 [t=0.23s]
prediction: ['[CLS] that a resented vanity benmax felt filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=2.144 (perp=10.229, rec=0.094, cos=0.004), tot_loss_proj:3.626 [t=0.19s]
prediction: ['[CLS] that a resented ∇max felt vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
[1450/2000] tot_loss=2.145 (perp=10.229, rec=0.095, cos=0.004), tot_loss_proj:3.627 [t=0.19s]
prediction: ['[CLS] that a resented ∇max felt vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
[1500/2000] tot_loss=2.143 (perp=10.229, rec=0.093, cos=0.004), tot_loss_proj:3.629 [t=0.19s]
prediction: ['[CLS] that a resented ∇max felt vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
Moved sequence
[1550/2000] tot_loss=2.125 (perp=10.129, rec=0.095, cos=0.004), tot_loss_proj:3.463 [t=0.24s]
prediction: ['[CLS] that a benmax felt resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=2.102 (perp=10.023, rec=0.093, cos=0.004), tot_loss_proj:3.470 [t=0.18s]
prediction: ['[CLS] a benmax felt that resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
[1650/2000] tot_loss=2.108 (perp=10.023, rec=0.100, cos=0.003), tot_loss_proj:3.468 [t=0.20s]
prediction: ['[CLS] a benmax felt that resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
[1700/2000] tot_loss=2.105 (perp=10.023, rec=0.097, cos=0.003), tot_loss_proj:3.466 [t=0.22s]
prediction: ['[CLS] a benmax felt that resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
[1750/2000] tot_loss=2.099 (perp=10.023, rec=0.091, cos=0.003), tot_loss_proj:3.467 [t=0.21s]
prediction: ['[CLS] a benmax felt that resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
[1800/2000] tot_loss=2.103 (perp=10.023, rec=0.095, cos=0.003), tot_loss_proj:3.465 [t=0.22s]
prediction: ['[CLS] a benmax felt that resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
[1850/2000] tot_loss=2.100 (perp=10.023, rec=0.092, cos=0.003), tot_loss_proj:3.462 [t=0.22s]
prediction: ['[CLS] a benmax felt that resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
[1900/2000] tot_loss=2.104 (perp=10.023, rec=0.096, cos=0.003), tot_loss_proj:3.467 [t=0.19s]
prediction: ['[CLS] a benmax felt that resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
[1950/2000] tot_loss=2.098 (perp=10.023, rec=0.090, cos=0.003), tot_loss_proj:3.467 [t=0.19s]
prediction: ['[CLS] a benmax felt that resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=2.066 (perp=9.843, rec=0.094, cos=0.003), tot_loss_proj:3.506 [t=0.19s]
prediction: ['[CLS] benmax felt that a resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]']
Done with input #8 of 100.
reference: 
========================
[CLS]'s a frightful vanity film that, no doubt, pays off what debt miramax felt they owed to benigni [SEP]
========================
predicted: 
========================
[CLS] a benmax felt that resented vanity filmmax expect doubti off no debt s what pays fright benigni owed, vanity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.293 | p: 66.667 | r: 70.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 34.146 | p: 33.333 | r: 35.000
rougeLsum  | fm: 34.146 | p: 33.333 | r: 35.000
r1fm+r2fm = 68.293

[Aggregate metrics]:
rouge1     | fm: 90.094 | p: 89.459 | r: 90.847
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 82.577 | p: 82.123 | r: 83.122
rougeLsum  | fm: 82.577 | p: 82.123 | r: 83.294
r1fm+r2fm = 156.761

input #8 time: 0:08:31 | total time: 1:16:20


Running input #9 of 100.
reference: 
========================
of softheaded metaphysical claptrap 
========================
average of cosine similarity 0.9993981275486599
highest_index [0]
highest [0.9993981275486599]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  1997,  3730,  4974,  2098, 29081, 28618,  6494,  2361,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] of softheaded metaphysical claptrap [SEP]']
[Init] best rec loss: 1.700202226638794 for ['[CLS] 2 definitely alert just heard 2005 p [MASK] [SEP]']
[Init] best rec loss: 1.27736234664917 for ['[CLS] reaction pleasure throatably thereafter state attachedoto [SEP]']
[Init] best rec loss: 1.1396721601486206 for ['[CLS] imp fbution specialising ste " lip nearby [SEP]']
[Init] best rec loss: 1.0866336822509766 for ['[CLS] video guys glass stilldleulf explorer eva [SEP]']
[Init] best perm rec loss: 1.0833972692489624 for ['[CLS] explorerdle video guys glass evaulf still [SEP]']
[Init] best perm rec loss: 1.0814344882965088 for ['[CLS] video guysulf still glassdle explorer eva [SEP]']
[Init] best perm rec loss: 1.08087956905365 for ['[CLS] evadle guys video glass still explorerulf [SEP]']
[Init] best perm rec loss: 1.079574704170227 for ['[CLS] still guys explorer videoulf evadle glass [SEP]']
[Init] best perm rec loss: 1.079067349433899 for ['[CLS] glass explorerulfdle still guys video eva [SEP]']
[Init] best perm rec loss: 1.0773389339447021 for ['[CLS] videoulf guys explorer stilldle glass eva [SEP]']
[Init] best perm rec loss: 1.075656533241272 for ['[CLS] still eva explorerdle glass guysulf video [SEP]']
[Init] best perm rec loss: 1.075609564781189 for ['[CLS]dle stillulf glass video eva guys explorer [SEP]']
[Init] best perm rec loss: 1.0754793882369995 for ['[CLS] still evaulf guys video explorer glassdle [SEP]']
[Init] best perm rec loss: 1.0741891860961914 for ['[CLS] glass still eva guys videodle explorerulf [SEP]']
[Init] best perm rec loss: 1.0710862874984741 for ['[CLS] eva video still glass explorer guysdleulf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.627 (perp=11.104, rec=0.299, cos=0.107), tot_loss_proj:3.315 [t=0.19s]
prediction: ['[CLS] bunny shawn finals soft claptrab clap [SEP]']
[ 100/2000] tot_loss=1.923 (perp=8.655, rec=0.181, cos=0.012), tot_loss_proj:2.687 [t=0.19s]
prediction: ['[CLS] bb metaphysical of soft claptrap clap [SEP]']
[ 150/2000] tot_loss=1.827 (perp=8.520, rec=0.118, cos=0.004), tot_loss_proj:2.577 [t=0.19s]
prediction: ['[CLS] bb metaphysical of soft claptrap metaphysical [SEP]']
[ 200/2000] tot_loss=1.821 (perp=8.520, rec=0.113, cos=0.004), tot_loss_proj:2.581 [t=0.19s]
prediction: ['[CLS] bb metaphysical of soft claptrap metaphysical [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.887 (perp=8.892, rec=0.102, cos=0.006), tot_loss_proj:2.674 [t=0.18s]
prediction: ['[CLS]head metaphysical soft claptrap ofhead [SEP]']
[ 300/2000] tot_loss=1.866 (perp=8.892, rec=0.085, cos=0.003), tot_loss_proj:2.673 [t=0.19s]
prediction: ['[CLS]head metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.865 (perp=8.892, rec=0.084, cos=0.002), tot_loss_proj:2.669 [t=0.19s]
prediction: ['[CLS]head metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.863 (perp=8.892, rec=0.082, cos=0.002), tot_loss_proj:2.667 [t=0.20s]
prediction: ['[CLS]head metaphysical soft claptrap ofhead [SEP]']
[ 450/2000] tot_loss=1.862 (perp=8.892, rec=0.081, cos=0.002), tot_loss_proj:2.666 [t=0.25s]
prediction: ['[CLS]head metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.835 (perp=8.802, rec=0.072, cos=0.002), tot_loss_proj:2.639 [t=0.24s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.838 (perp=8.802, rec=0.076, cos=0.001), tot_loss_proj:2.631 [t=0.26s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[ 600/2000] tot_loss=1.831 (perp=8.802, rec=0.070, cos=0.001), tot_loss_proj:2.631 [t=0.18s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.828 (perp=8.802, rec=0.067, cos=0.001), tot_loss_proj:2.630 [t=0.23s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.833 (perp=8.802, rec=0.071, cos=0.001), tot_loss_proj:2.630 [t=0.21s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[ 750/2000] tot_loss=1.832 (perp=8.802, rec=0.070, cos=0.001), tot_loss_proj:2.627 [t=0.19s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.823 (perp=8.802, rec=0.062, cos=0.001), tot_loss_proj:2.632 [t=0.18s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.831 (perp=8.802, rec=0.069, cos=0.001), tot_loss_proj:2.630 [t=0.26s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[ 900/2000] tot_loss=1.817 (perp=8.802, rec=0.055, cos=0.001), tot_loss_proj:2.622 [t=0.19s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.822 (perp=8.802, rec=0.060, cos=0.001), tot_loss_proj:2.633 [t=0.24s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1000/2000] tot_loss=1.824 (perp=8.802, rec=0.062, cos=0.001), tot_loss_proj:2.633 [t=0.19s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[1050/2000] tot_loss=1.821 (perp=8.802, rec=0.060, cos=0.001), tot_loss_proj:2.626 [t=0.20s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1100/2000] tot_loss=1.828 (perp=8.802, rec=0.067, cos=0.001), tot_loss_proj:2.625 [t=0.21s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1150/2000] tot_loss=1.831 (perp=8.802, rec=0.070, cos=0.001), tot_loss_proj:2.634 [t=0.32s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[1200/2000] tot_loss=1.826 (perp=8.802, rec=0.064, cos=0.001), tot_loss_proj:2.635 [t=0.30s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1250/2000] tot_loss=1.829 (perp=8.802, rec=0.068, cos=0.001), tot_loss_proj:2.630 [t=0.20s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1300/2000] tot_loss=1.823 (perp=8.802, rec=0.062, cos=0.001), tot_loss_proj:2.632 [t=0.21s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[1350/2000] tot_loss=1.828 (perp=8.802, rec=0.067, cos=0.001), tot_loss_proj:2.627 [t=0.28s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1400/2000] tot_loss=1.826 (perp=8.802, rec=0.065, cos=0.001), tot_loss_proj:2.628 [t=0.21s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1450/2000] tot_loss=1.826 (perp=8.802, rec=0.064, cos=0.001), tot_loss_proj:2.629 [t=0.28s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[1500/2000] tot_loss=1.818 (perp=8.802, rec=0.056, cos=0.001), tot_loss_proj:2.631 [t=0.19s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1550/2000] tot_loss=1.837 (perp=8.802, rec=0.076, cos=0.001), tot_loss_proj:2.628 [t=0.21s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1600/2000] tot_loss=1.826 (perp=8.802, rec=0.064, cos=0.001), tot_loss_proj:2.628 [t=0.27s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[1650/2000] tot_loss=1.830 (perp=8.802, rec=0.069, cos=0.001), tot_loss_proj:2.627 [t=0.19s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1700/2000] tot_loss=1.817 (perp=8.802, rec=0.055, cos=0.001), tot_loss_proj:2.629 [t=0.19s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1750/2000] tot_loss=1.819 (perp=8.802, rec=0.057, cos=0.001), tot_loss_proj:2.624 [t=0.29s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[1800/2000] tot_loss=1.829 (perp=8.802, rec=0.067, cos=0.001), tot_loss_proj:2.631 [t=0.23s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1850/2000] tot_loss=1.820 (perp=8.802, rec=0.058, cos=0.001), tot_loss_proj:2.630 [t=0.22s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[1900/2000] tot_loss=1.835 (perp=8.802, rec=0.073, cos=0.001), tot_loss_proj:2.629 [t=0.23s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
[1950/2000] tot_loss=1.821 (perp=8.802, rec=0.059, cos=0.001), tot_loss_proj:2.631 [t=0.19s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Attempt swap
[2000/2000] tot_loss=1.826 (perp=8.802, rec=0.065, cos=0.001), tot_loss_proj:2.630 [t=0.19s]
prediction: ['[CLS]ed metaphysical soft claptrap ofhead [SEP]']
Done with input #9 of 100.
reference: 
========================
[CLS] of softheaded metaphysical claptrap [SEP]
========================
predicted: 
========================
[CLS]ed metaphysical soft claptrap ofhead [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 61.538 | p: 57.143 | r: 66.667
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 61.538 | p: 57.143 | r: 66.667
rougeLsum  | fm: 61.538 | p: 57.143 | r: 66.667
r1fm+r2fm = 61.538

[Aggregate metrics]:
rouge1     | fm: 87.238 | p: 86.227 | r: 88.429
rouge2     | fm: 60.000 | p: 60.000 | r: 60.000
rougeL     | fm: 80.483 | p: 79.762 | r: 81.476
rougeLsum  | fm: 80.473 | p: 79.625 | r: 81.476
r1fm+r2fm = 147.238

input #9 time: 0:08:39 | total time: 1:24:59


Running input #10 of 100.
reference: 
========================
ably balances real-time rhythms with propulsive incident . 
========================
average of cosine similarity 0.9991472052153934
highest_index [0]
highest [0.9991472052153934]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101, 11113,  2135,  5703,  2015,  2613,  1011,  2051, 17900,  2007,
         17678, 23004,  5043,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] ably balances real - time rhythms with propulsive incident. [SEP]']
[Init] best rec loss: 1.8671343326568604 for ['[CLS] upon mora citizen genus crambidaeset devils roll association refersudged dea appropriate [SEP]']
[Init] best rec loss: 1.8420976400375366 for ['[CLS] true double constructive tribune foreman! rfc corbin glory reverse about grow generally [SEP]']
[Init] best rec loss: 1.4058338403701782 for ['[CLS] uporic blessed level sheep sound common themes places totallyblood order angel [SEP]']
[Init] best perm rec loss: 1.3968875408172607 for ['[CLS] themes up sheep blessedblood angel common orderoric places totally level sound [SEP]']
[Init] best perm rec loss: 1.3953274488449097 for ['[CLS]blood common angeloric up sheep order blessed sound level totally places themes [SEP]']
[Init] best perm rec loss: 1.3951473236083984 for ['[CLS] themesoric soundblood sheep up places common blessed level order totally angel [SEP]']
[Init] best perm rec loss: 1.3938393592834473 for ['[CLS] angel up level order totally themes placesblood sheeporic sound blessed common [SEP]']
[Init] best perm rec loss: 1.3935538530349731 for ['[CLS] totally up common level places sheep order sound blessed themes angeloricblood [SEP]']
[Init] best perm rec loss: 1.3933236598968506 for ['[CLS] sheep places common sound themes totally order blessed level upbloodoric angel [SEP]']
[Init] best perm rec loss: 1.3882167339324951 for ['[CLS] places sheep totally level uporic blessed order angel sound common themesblood [SEP]']
[Init] best perm rec loss: 1.387595295906067 for ['[CLS]bloodoric blessed totally up themes places angel sheep common sound order level [SEP]']
[Init] best perm rec loss: 1.3872023820877075 for ['[CLS] sound blessedblood common up sheep places order level totally themes angeloric [SEP]']
[Init] best perm rec loss: 1.3837432861328125 for ['[CLS] sound places angel common totally level sheep order blessed uporic themesblood [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.952 (perp=12.754, rec=0.362, cos=0.040), tot_loss_proj:3.849 [t=0.19s]
prediction: ['[CLS] metaphor balance tapping quietly reese wolf times. embrace conflictam balanceulsive [SEP]']
[ 100/2000] tot_loss=2.394 (perp=10.670, rec=0.248, cos=0.012), tot_loss_proj:3.044 [t=0.19s]
prediction: ['[CLS] - balancely quietlyly extentulsive..leram balance successfully [SEP]']
[ 150/2000] tot_loss=2.334 (perp=10.621, rec=0.202, cos=0.008), tot_loss_proj:3.408 [t=0.20s]
prediction: ['[CLS] - balancely ably rhythmsulsive.. reallity balance ab [SEP]']
[ 200/2000] tot_loss=2.204 (perp=9.759, rec=0.233, cos=0.020), tot_loss_proj:2.908 [t=0.19s]
prediction: ['[CLS] - balancely ably rhythmsulsive.. real. balance ab [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.949 (perp=8.545, rec=0.230, cos=0.010), tot_loss_proj:3.064 [t=0.25s]
prediction: ['[CLS] - balance balance ably ably rhythmsulsive.. timeological [SEP]']
[ 300/2000] tot_loss=1.892 (perp=8.549, rec=0.177, cos=0.006), tot_loss_proj:2.939 [t=0.25s]
prediction: ['[CLS] - balance balance ably ably rhythmsulsive.. incidently [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.839 (perp=8.327, rec=0.168, cos=0.006), tot_loss_proj:2.621 [t=0.24s]
prediction: ['[CLS] balance balancely ably ably rhythmsulsive.. incidently [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.853 (perp=8.219, rec=0.200, cos=0.009), tot_loss_proj:2.577 [t=0.20s]
prediction: ['[CLS] balance balancely ably ably withulsive rhythms - incidently [SEP]']
[ 450/2000] tot_loss=1.860 (perp=8.428, rec=0.168, cos=0.006), tot_loss_proj:2.702 [t=0.31s]
prediction: ['[CLS] rhythms balancely ably ably withulsive rhythms. incidently [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.748 (perp=7.980, rec=0.147, cos=0.005), tot_loss_proj:2.506 [t=0.19s]
prediction: ['[CLS] rhythms balancely ably ably with incident rhythms.ulsively [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.788 (perp=8.135, rec=0.153, cos=0.008), tot_loss_proj:2.429 [t=0.21s]
prediction: ['[CLS] incident balancely ably ably with rhythms real.ulsively [SEP]']
[ 600/2000] tot_loss=1.772 (perp=8.135, rec=0.140, cos=0.005), tot_loss_proj:2.433 [t=0.19s]
prediction: ['[CLS] incident balancely ably ably with rhythms real.ulsively [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.583 (perp=7.216, rec=0.135, cos=0.005), tot_loss_proj:2.424 [t=0.22s]
prediction: ['[CLS] incident balancely ably ably with rhythms realulsively. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.582 (perp=7.216, rec=0.134, cos=0.005), tot_loss_proj:2.442 [t=0.20s]
prediction: ['[CLS] incident balancely ably ably with rhythms realulsively. [SEP]']
[ 750/2000] tot_loss=1.580 (perp=7.216, rec=0.132, cos=0.005), tot_loss_proj:2.454 [t=0.19s]
prediction: ['[CLS] incident balancely ably ably with rhythms realulsively. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.576 (perp=7.216, rec=0.128, cos=0.004), tot_loss_proj:2.446 [t=0.26s]
prediction: ['[CLS] incident balancely ably ably with rhythms realulsively. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.572 (perp=7.216, rec=0.124, cos=0.004), tot_loss_proj:2.361 [t=0.22s]
prediction: ['[CLS] incident balancely ably ably with rhythms realulsively. [SEP]']
[ 900/2000] tot_loss=1.684 (perp=7.784, rec=0.124, cos=0.004), tot_loss_proj:2.472 [t=0.19s]
prediction: ['[CLS] incident balancely ably ably with rhythms realulsive.. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.719 (perp=7.998, rec=0.115, cos=0.004), tot_loss_proj:2.547 [t=0.20s]
prediction: ['[CLS] incident balancely ably ably with rhythmsly realulsive. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.571 (perp=7.216, rec=0.124, cos=0.004), tot_loss_proj:2.274 [t=0.20s]
prediction: ['[CLS] incident balancely ably ably with rhythms realulsively. [SEP]']
[1050/2000] tot_loss=1.712 (perp=7.974, rec=0.114, cos=0.003), tot_loss_proj:2.513 [t=0.20s]
prediction: ['[CLS] incident balancely ably abs with rhythms realulsively. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.496 (perp=6.901, rec=0.113, cos=0.003), tot_loss_proj:2.318 [t=0.19s]
prediction: ['[CLS] incident balance ably ablys with rhythms realulsively. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.542 (perp=7.149, rec=0.109, cos=0.003), tot_loss_proj:2.248 [t=0.26s]
prediction: ['[CLS] incident balance really ablys with rhythms realulsively. [SEP]']
[1200/2000] tot_loss=1.542 (perp=7.149, rec=0.109, cos=0.003), tot_loss_proj:2.259 [t=0.23s]
prediction: ['[CLS] incident balance really ablys with rhythms realulsively. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.529 (perp=7.149, rec=0.096, cos=0.003), tot_loss_proj:2.257 [t=0.20s]
prediction: ['[CLS] incident balance really ablys with rhythms realulsively. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.604 (perp=7.516, rec=0.098, cos=0.003), tot_loss_proj:2.336 [t=0.27s]
prediction: ['[CLS] incident balance really ably real with rhythms realulsively. [SEP]']
[1350/2000] tot_loss=1.615 (perp=7.516, rec=0.109, cos=0.002), tot_loss_proj:2.332 [t=0.19s]
prediction: ['[CLS] incident balance really ably real with rhythms realulsively. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.617 (perp=7.516, rec=0.111, cos=0.002), tot_loss_proj:2.326 [t=0.20s]
prediction: ['[CLS] incident balance really ably real with rhythms realulsively. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.656 (perp=7.747, rec=0.104, cos=0.003), tot_loss_proj:2.278 [t=0.20s]
prediction: ['[CLS] incident balance ably reals real with rhythms realulsively. [SEP]']
[1500/2000] tot_loss=1.655 (perp=7.747, rec=0.103, cos=0.002), tot_loss_proj:2.280 [t=0.20s]
prediction: ['[CLS] incident balance ably reals real with rhythms realulsively. [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=1.608 (perp=7.495, rec=0.107, cos=0.002), tot_loss_proj:2.204 [t=0.20s]
prediction: ['[CLS] incident balance ablys real with real rhythms realulsively. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.688 (perp=7.936, rec=0.098, cos=0.002), tot_loss_proj:2.308 [t=0.27s]
prediction: ['[CLS] incident balance ablys - with real rhythms realulsively. [SEP]']
[1650/2000] tot_loss=1.678 (perp=7.936, rec=0.088, cos=0.002), tot_loss_proj:2.311 [t=0.20s]
prediction: ['[CLS] incident balance ablys - with real rhythms realulsively. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.583 (perp=7.410, rec=0.099, cos=0.002), tot_loss_proj:2.223 [t=0.20s]
prediction: ['[CLS] real balance ablys - with incident rhythms realulsively. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.574 (perp=7.410, rec=0.090, cos=0.002), tot_loss_proj:2.221 [t=0.19s]
prediction: ['[CLS] real balance ablys - with incident rhythms realulsively. [SEP]']
[1800/2000] tot_loss=1.578 (perp=7.410, rec=0.094, cos=0.002), tot_loss_proj:2.217 [t=0.20s]
prediction: ['[CLS] real balance ablys - with incident rhythms realulsively. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.578 (perp=7.410, rec=0.094, cos=0.002), tot_loss_proj:2.219 [t=0.27s]
prediction: ['[CLS] real balance ablys - with incident rhythms realulsively. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.578 (perp=7.410, rec=0.094, cos=0.002), tot_loss_proj:2.228 [t=0.19s]
prediction: ['[CLS] real balance ablys - with incident rhythms realulsively. [SEP]']
[1950/2000] tot_loss=1.582 (perp=7.410, rec=0.098, cos=0.002), tot_loss_proj:2.225 [t=0.19s]
prediction: ['[CLS] real balance ablys - with incident rhythms realulsively. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.572 (perp=7.410, rec=0.088, cos=0.002), tot_loss_proj:2.228 [t=0.20s]
prediction: ['[CLS] real balance ablys - with incident rhythms realulsively. [SEP]']
Done with input #10 of 100.
reference: 
========================
[CLS] ably balances real - time rhythms with propulsive incident. [SEP]
========================
predicted: 
========================
[CLS] real balance ablys - with incident rhythms realulsively. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 63.158 | p: 66.667 | r: 60.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 52.632 | p: 55.556 | r: 50.000
rougeLsum  | fm: 52.632 | p: 55.556 | r: 50.000
r1fm+r2fm = 63.158

[Aggregate metrics]:
rouge1     | fm: 85.197 | p: 84.848 | r: 86.147
rouge2     | fm: 54.545 | p: 54.545 | r: 54.545
rougeL     | fm: 77.942 | p: 77.436 | r: 78.615
rougeLsum  | fm: 78.398 | p: 77.689 | r: 79.091
r1fm+r2fm = 139.742

input #10 time: 0:08:53 | total time: 1:33:52


Running input #11 of 100.
reference: 
========================
was being attempted here that stubbornly refused to gel 
========================
average of cosine similarity 0.9992849825911105
highest_index [0]
highest [0.9992849825911105]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2001,  2108,  4692,  2182,  2008, 14205,  2135,  4188,  2000,
         21500,   102]], device='cuda:0')
Debug: ref = ['[CLS] was being attempted here that stubbornly refused to gel [SEP]']
[Init] best rec loss: 1.8228942155838013 for ['[CLS] whitney keseion label lane attributed kaplankling today [SEP]']
[Init] best rec loss: 1.7478306293487549 for ['[CLS] fluidigh ron doctor karma client climateweed native eggs [SEP]']
[Init] best rec loss: 1.3220566511154175 for ['[CLS] platform tal drawn inland mileture familiarvd megu [SEP]']
[Init] best perm rec loss: 1.311123251914978 for ['[CLS] me talvd familiar inland mileturegu drawn platform [SEP]']
[Init] best perm rec loss: 1.3074727058410645 for ['[CLS]ture inlandgu me tal platform familiarvd mile drawn [SEP]']
[Init] best perm rec loss: 1.2857089042663574 for ['[CLS] inlandture drawn tal platform megu familiarvd mile [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.418 (perp=10.524, rec=0.295, cos=0.018), tot_loss_proj:3.534 [t=0.22s]
prediction: ['[CLS] that refused refused this gel to gel refuseded gel [SEP]']
[ 100/2000] tot_loss=2.539 (perp=11.722, rec=0.188, cos=0.007), tot_loss_proj:3.293 [t=0.19s]
prediction: ['[CLS] that attempted tried here gel to gel refuseded stubborn [SEP]']
[ 150/2000] tot_loss=2.435 (perp=11.573, rec=0.117, cos=0.003), tot_loss_proj:3.397 [t=0.19s]
prediction: ['[CLS] was attempted attempted here gel to gel refused that stubborn [SEP]']
[ 200/2000] tot_loss=2.419 (perp=11.573, rec=0.102, cos=0.003), tot_loss_proj:3.399 [t=0.19s]
prediction: ['[CLS] was attempted attempted here gel to gel refused that stubborn [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.125 (perp=10.095, rec=0.103, cos=0.003), tot_loss_proj:3.064 [t=0.21s]
prediction: ['[CLS] was here being attempted gel to gel refused that stubborn [SEP]']
[ 300/2000] tot_loss=2.063 (perp=9.916, rec=0.078, cos=0.002), tot_loss_proj:3.031 [t=0.20s]
prediction: ['[CLS] was here being attempted stubborn to gel refused that stubborn [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.934 (perp=9.274, rec=0.077, cos=0.002), tot_loss_proj:2.840 [t=0.19s]
prediction: ['[CLS] was here being attempted to gel stubborn refused that stubborn [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.738 (perp=8.277, rec=0.080, cos=0.002), tot_loss_proj:2.544 [t=0.19s]
prediction: ['[CLS] was here being attempted to stubbornly refused that gel [SEP]']
[ 450/2000] tot_loss=1.733 (perp=8.277, rec=0.076, cos=0.002), tot_loss_proj:2.541 [t=0.19s]
prediction: ['[CLS] was here being attempted to stubbornly refused that gel [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.427 (perp=6.751, rec=0.075, cos=0.002), tot_loss_proj:1.654 [t=0.19s]
prediction: ['[CLS] was here being attempted that stubbornly refused to gel [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.324 (perp=6.291, rec=0.064, cos=0.002), tot_loss_proj:1.545 [t=0.26s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[ 600/2000] tot_loss=1.318 (perp=6.291, rec=0.058, cos=0.002), tot_loss_proj:1.536 [t=0.26s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.325 (perp=6.291, rec=0.066, cos=0.001), tot_loss_proj:1.532 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.331 (perp=6.291, rec=0.071, cos=0.001), tot_loss_proj:1.540 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[ 750/2000] tot_loss=1.324 (perp=6.291, rec=0.065, cos=0.001), tot_loss_proj:1.540 [t=0.22s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.326 (perp=6.291, rec=0.066, cos=0.001), tot_loss_proj:1.539 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.332 (perp=6.291, rec=0.072, cos=0.001), tot_loss_proj:1.539 [t=0.18s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[ 900/2000] tot_loss=1.322 (perp=6.291, rec=0.062, cos=0.001), tot_loss_proj:1.536 [t=0.20s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.314 (perp=6.291, rec=0.055, cos=0.001), tot_loss_proj:1.535 [t=0.20s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1000/2000] tot_loss=1.321 (perp=6.291, rec=0.062, cos=0.001), tot_loss_proj:1.547 [t=0.20s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1050/2000] tot_loss=1.323 (perp=6.291, rec=0.064, cos=0.001), tot_loss_proj:1.534 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1100/2000] tot_loss=1.317 (perp=6.291, rec=0.058, cos=0.001), tot_loss_proj:1.542 [t=0.24s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1150/2000] tot_loss=1.320 (perp=6.291, rec=0.061, cos=0.001), tot_loss_proj:1.546 [t=0.20s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1200/2000] tot_loss=1.317 (perp=6.291, rec=0.057, cos=0.001), tot_loss_proj:1.550 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1250/2000] tot_loss=1.322 (perp=6.291, rec=0.063, cos=0.001), tot_loss_proj:1.536 [t=0.25s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1300/2000] tot_loss=1.316 (perp=6.291, rec=0.057, cos=0.001), tot_loss_proj:1.537 [t=0.22s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1350/2000] tot_loss=1.316 (perp=6.291, rec=0.056, cos=0.001), tot_loss_proj:1.545 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1400/2000] tot_loss=1.322 (perp=6.291, rec=0.062, cos=0.001), tot_loss_proj:1.540 [t=0.21s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1450/2000] tot_loss=1.329 (perp=6.291, rec=0.070, cos=0.001), tot_loss_proj:1.538 [t=0.26s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1500/2000] tot_loss=1.323 (perp=6.291, rec=0.063, cos=0.001), tot_loss_proj:1.534 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1550/2000] tot_loss=1.328 (perp=6.291, rec=0.068, cos=0.001), tot_loss_proj:1.545 [t=0.28s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1600/2000] tot_loss=1.319 (perp=6.291, rec=0.059, cos=0.001), tot_loss_proj:1.545 [t=0.18s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1650/2000] tot_loss=1.328 (perp=6.291, rec=0.069, cos=0.001), tot_loss_proj:1.543 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1700/2000] tot_loss=1.317 (perp=6.291, rec=0.057, cos=0.001), tot_loss_proj:1.544 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1750/2000] tot_loss=1.320 (perp=6.291, rec=0.060, cos=0.001), tot_loss_proj:1.550 [t=0.20s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1800/2000] tot_loss=1.329 (perp=6.291, rec=0.069, cos=0.001), tot_loss_proj:1.541 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1850/2000] tot_loss=1.330 (perp=6.291, rec=0.070, cos=0.001), tot_loss_proj:1.541 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[1900/2000] tot_loss=1.321 (perp=6.291, rec=0.061, cos=0.001), tot_loss_proj:1.538 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
[1950/2000] tot_loss=1.321 (perp=6.291, rec=0.061, cos=0.001), tot_loss_proj:1.545 [t=0.19s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Attempt swap
[2000/2000] tot_loss=1.319 (perp=6.291, rec=0.059, cos=0.001), tot_loss_proj:1.537 [t=0.24s]
prediction: ['[CLS] here was being attempted that stubbornly refused to gel [SEP]']
Done with input #11 of 100.
reference: 
========================
[CLS] was being attempted here that stubbornly refused to gel [SEP]
========================
predicted: 
========================
[CLS] here was being attempted that stubbornly refused to gel [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 70.000 | p: 70.000 | r: 70.000
rougeL     | fm: 90.909 | p: 90.909 | r: 90.909
rougeLsum  | fm: 90.909 | p: 90.909 | r: 90.909
r1fm+r2fm = 170.000

[Aggregate metrics]:
rouge1     | fm: 86.723 | p: 85.928 | r: 87.500
rouge2     | fm: 55.833 | p: 55.833 | r: 55.833
rougeL     | fm: 79.362 | p: 78.782 | r: 79.709
rougeLsum  | fm: 79.508 | p: 79.030 | r: 80.195
r1fm+r2fm = 142.556

input #11 time: 0:08:40 | total time: 1:42:33


Running input #12 of 100.
reference: 
========================
that will be seen to better advantage on cable , especially considering its barely 
========================
average of cosine similarity 0.99934391763152
highest_index [0]
highest [0.99934391763152]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[ 101, 2008, 2097, 2022, 2464, 2000, 2488, 5056, 2006, 5830, 1010, 2926,
         6195, 2049, 4510,  102]], device='cuda:0')
Debug: ref = ['[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]']
[Init] best rec loss: 1.8480900526046753 for ['[CLS] beausse japan forbid the colleen success wireless file ryan mhz seeks black pilgrimage [SEP]']
[Init] best rec loss: 1.794683814048767 for ['[CLS] i stars embankment good fitted obeeborg cole incorporated relative : alone sans cad [SEP]']
[Init] best rec loss: 1.4141982793807983 for ['[CLS] hurdlesseazi tax clause asia read rose againyeh pu jace universe team [SEP]']
[Init] best rec loss: 1.3857673406600952 for ['[CLS]cape release beyond doctors native dig legs seven meansnessy la delivery president jam [SEP]']
[Init] best rec loss: 1.319607138633728 for ['[CLS] whatever prince time junior craigsal can grew late parade clues find given but [SEP]']
[Init] best rec loss: 1.2739667892456055 for ['[CLS] few lay series margin shades office translate victornctionyn haitas beth guess [SEP]']
[Init] best rec loss: 1.2710332870483398 for ['[CLS] command married coma lux me brook fuel specifically containing deaf missing firm prospects track [SEP]']
[Init] best perm rec loss: 1.2705339193344116 for ['[CLS] prospects command me brook married lux containing fuel coma track firm missing deaf specifically [SEP]']
[Init] best perm rec loss: 1.2703341245651245 for ['[CLS] coma deaf lux containing married brook prospects missing me firm specifically command fuel track [SEP]']
[Init] best perm rec loss: 1.2677892446517944 for ['[CLS] command brook deaf firm missing prospects specifically coma containing track married me lux fuel [SEP]']
[Init] best perm rec loss: 1.2655885219573975 for ['[CLS] track deaf containing specifically firm prospects coma command brook fuel lux missing me married [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.449 (perp=10.590, rec=0.286, cos=0.045), tot_loss_proj:3.102 [t=0.19s]
prediction: ['[CLS] wage barely rumor cable advantage seen to, better better. advantage cable attack [SEP]']
[ 100/2000] tot_loss=2.007 (perp=9.053, rec=0.178, cos=0.019), tot_loss_proj:2.719 [t=0.23s]
prediction: ['[CLS] although barely seen cable will that on, better better, advantage its barely [SEP]']
[ 150/2000] tot_loss=2.161 (perp=10.110, rec=0.126, cos=0.013), tot_loss_proj:3.006 [t=0.27s]
prediction: ['[CLS] considering barely seen cable will that on, better better considering advantage its barely [SEP]']
[ 200/2000] tot_loss=2.105 (perp=9.988, rec=0.102, cos=0.005), tot_loss_proj:2.947 [t=0.29s]
prediction: ['[CLS] considering barely seen cable will that on, to better considering advantage its barely [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.797 (perp=8.502, rec=0.091, cos=0.005), tot_loss_proj:2.534 [t=0.19s]
prediction: ['[CLS] considering barely seen cable will that on, to better advantage considering its barely [SEP]']
[ 300/2000] tot_loss=1.896 (perp=9.026, rec=0.086, cos=0.004), tot_loss_proj:2.505 [t=0.22s]
prediction: ['[CLS] considering barely seen cable will that on subject to better advantage considering its barely [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.876 (perp=8.929, rec=0.086, cos=0.004), tot_loss_proj:2.451 [t=0.22s]
prediction: ['[CLS] especially barely seen cable will on that substitute to better advantage considering its barely [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.737 (perp=8.236, rec=0.086, cos=0.004), tot_loss_proj:2.368 [t=0.27s]
prediction: ['[CLS] especially barely seen cable will ; on that to better advantage considering its barely [SEP]']
[ 450/2000] tot_loss=1.734 (perp=8.242, rec=0.082, cos=0.003), tot_loss_proj:2.456 [t=0.22s]
prediction: ['[CLS] especially barely seen cable will ; on that to better advantage considering its considering [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.736 (perp=8.242, rec=0.085, cos=0.003), tot_loss_proj:2.458 [t=0.28s]
prediction: ['[CLS] especially barely seen cable will ; on that to better advantage considering its considering [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.723 (perp=8.242, rec=0.071, cos=0.003), tot_loss_proj:2.455 [t=0.20s]
prediction: ['[CLS] especially barely seen cable will ; on that to better advantage considering its considering [SEP]']
[ 600/2000] tot_loss=1.728 (perp=8.242, rec=0.076, cos=0.003), tot_loss_proj:2.447 [t=0.19s]
prediction: ['[CLS] especially barely seen cable will ; on that to better advantage considering its considering [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.696 (perp=8.106, rec=0.072, cos=0.003), tot_loss_proj:2.415 [t=0.19s]
prediction: ['[CLS] especially barely seen cable will, on that to better advantage considering its considering [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.700 (perp=8.106, rec=0.076, cos=0.003), tot_loss_proj:2.411 [t=0.20s]
prediction: ['[CLS] especially barely seen cable will, on that to better advantage considering its considering [SEP]']
[ 750/2000] tot_loss=1.683 (perp=8.106, rec=0.059, cos=0.003), tot_loss_proj:2.407 [t=0.19s]
prediction: ['[CLS] especially barely seen cable will, on that to better advantage considering its considering [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.698 (perp=8.106, rec=0.074, cos=0.003), tot_loss_proj:2.411 [t=0.20s]
prediction: ['[CLS] especially barely seen cable will, on that to better advantage considering its considering [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.697 (perp=8.064, rec=0.081, cos=0.003), tot_loss_proj:2.323 [t=0.19s]
prediction: ['[CLS] especially barely seen, will cable on that to better advantage considering its considering [SEP]']
[ 900/2000] tot_loss=1.691 (perp=8.064, rec=0.075, cos=0.003), tot_loss_proj:2.326 [t=0.19s]
prediction: ['[CLS] especially barely seen, will cable on that to better advantage considering its considering [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.630 (perp=7.743, rec=0.079, cos=0.003), tot_loss_proj:2.337 [t=0.24s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1000/2000] tot_loss=1.628 (perp=7.743, rec=0.077, cos=0.003), tot_loss_proj:2.338 [t=0.20s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
[1050/2000] tot_loss=1.625 (perp=7.743, rec=0.074, cos=0.003), tot_loss_proj:2.337 [t=0.20s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1100/2000] tot_loss=1.622 (perp=7.743, rec=0.071, cos=0.003), tot_loss_proj:2.334 [t=0.19s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1150/2000] tot_loss=1.623 (perp=7.743, rec=0.072, cos=0.003), tot_loss_proj:2.338 [t=0.22s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
[1200/2000] tot_loss=1.622 (perp=7.743, rec=0.071, cos=0.003), tot_loss_proj:2.337 [t=0.31s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1250/2000] tot_loss=1.629 (perp=7.743, rec=0.078, cos=0.003), tot_loss_proj:2.335 [t=0.19s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1300/2000] tot_loss=1.626 (perp=7.743, rec=0.075, cos=0.003), tot_loss_proj:2.335 [t=0.19s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
[1350/2000] tot_loss=1.620 (perp=7.743, rec=0.069, cos=0.003), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1400/2000] tot_loss=1.621 (perp=7.743, rec=0.070, cos=0.003), tot_loss_proj:2.338 [t=0.19s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1450/2000] tot_loss=1.622 (perp=7.743, rec=0.071, cos=0.003), tot_loss_proj:2.338 [t=0.19s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
[1500/2000] tot_loss=1.615 (perp=7.743, rec=0.064, cos=0.003), tot_loss_proj:2.335 [t=0.22s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1550/2000] tot_loss=1.629 (perp=7.743, rec=0.077, cos=0.003), tot_loss_proj:2.333 [t=0.20s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1600/2000] tot_loss=1.625 (perp=7.743, rec=0.074, cos=0.003), tot_loss_proj:2.337 [t=0.19s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
[1650/2000] tot_loss=1.621 (perp=7.743, rec=0.070, cos=0.003), tot_loss_proj:2.337 [t=0.19s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1700/2000] tot_loss=1.627 (perp=7.743, rec=0.076, cos=0.003), tot_loss_proj:2.339 [t=0.25s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1750/2000] tot_loss=1.625 (perp=7.743, rec=0.074, cos=0.003), tot_loss_proj:2.334 [t=0.24s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
[1800/2000] tot_loss=1.632 (perp=7.743, rec=0.081, cos=0.003), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1850/2000] tot_loss=1.621 (perp=7.743, rec=0.070, cos=0.003), tot_loss_proj:2.340 [t=0.23s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[1900/2000] tot_loss=1.624 (perp=7.743, rec=0.073, cos=0.003), tot_loss_proj:2.337 [t=0.20s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
[1950/2000] tot_loss=1.623 (perp=7.743, rec=0.071, cos=0.003), tot_loss_proj:2.339 [t=0.24s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Attempt swap
[2000/2000] tot_loss=1.631 (perp=7.743, rec=0.080, cos=0.003), tot_loss_proj:2.337 [t=0.20s]
prediction: ['[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]']
Done with input #12 of 100.
reference: 
========================
[CLS] that will be seen to better advantage on cable, especially considering its barely [SEP]
========================
predicted: 
========================
[CLS] especially barely seen, will that cable on to better advantage considering its considering [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 93.333 | p: 93.333 | r: 93.333
rouge2     | fm: 21.429 | p: 21.429 | r: 21.429
rougeL     | fm: 53.333 | p: 53.333 | r: 53.333
rougeLsum  | fm: 53.333 | p: 53.333 | r: 53.333
r1fm+r2fm = 114.762

[Aggregate metrics]:
rouge1     | fm: 87.232 | p: 86.777 | r: 87.857
rouge2     | fm: 53.187 | p: 53.187 | r: 53.187
rougeL     | fm: 77.157 | p: 76.824 | r: 77.744
rougeLsum  | fm: 76.658 | p: 76.315 | r: 77.368
r1fm+r2fm = 140.418

input #12 time: 0:09:01 | total time: 1:51:34


Running input #13 of 100.
reference: 
========================
point at things that explode into flame 
========================
average of cosine similarity 0.9992538394516878
highest_index [0]
highest [0.9992538394516878]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  2391,  2012,  2477,  2008, 15044,  2046,  8457,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] point at things that explode into flame [SEP]']
[Init] best rec loss: 1.4737218618392944 for ['[CLS] mini gray inside mumbai atnies havoc [SEP]']
[Init] best rec loss: 1.4235199689865112 for ['[CLS] iona favorable vamp garrett nu pathetic miranda [SEP]']
[Init] best rec loss: 1.406105875968933 for ['[CLS] pdf along timing started mal practical prevailed [SEP]']
[Init] best rec loss: 1.390662670135498 for ['[CLS] clay young demon every rolesorestation bill [SEP]']
[Init] best rec loss: 1.3708242177963257 for ['[CLS]gled speaker finish eh asxy do [SEP]']
[Init] best rec loss: 1.3614050149917603 for ['[CLS] dame recess ak latter threshold po illness [SEP]']
[Init] best rec loss: 1.3537973165512085 for ['[CLS] squat what names set fence thin received [SEP]']
[Init] best rec loss: 1.3353148698806763 for ['[CLS] dressed fraternity colonial round et bahn heads [SEP]']
[Init] best rec loss: 1.3023403882980347 for ['[CLS] furnace card double experiment working corruption without [SEP]']
[Init] best rec loss: 1.261353611946106 for ['[CLS] arm permanent rowe precision cardinal defeational [SEP]']
[Init] best perm rec loss: 1.2592674493789673 for ['[CLS] permanent defeat arm cardinal roweional precision [SEP]']
[Init] best perm rec loss: 1.2589128017425537 for ['[CLS] defeat cardinal arm roweional precision permanent [SEP]']
[Init] best perm rec loss: 1.256705403327942 for ['[CLS] permanent cardinalional arm precision rowe defeat [SEP]']
[Init] best perm rec loss: 1.2559808492660522 for ['[CLS] permanentional cardinal defeat rowe precision arm [SEP]']
[Init] best perm rec loss: 1.2554824352264404 for ['[CLS] defeat cardinalional arm permanent precision rowe [SEP]']
[Init] best perm rec loss: 1.2538996934890747 for ['[CLS] cardinal defeational arm precision rowe permanent [SEP]']
[Init] best perm rec loss: 1.2521754503250122 for ['[CLS] permanent rowe cardinal armional precision defeat [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.023 (perp=13.271, rec=0.309, cos=0.060), tot_loss_proj:3.722 [t=0.19s]
prediction: ['[CLS] reach flame flame cheese explode careless down [SEP]']
[ 100/2000] tot_loss=2.430 (perp=10.891, rec=0.223, cos=0.029), tot_loss_proj:3.208 [t=0.19s]
prediction: ['[CLS] point flame flame flesh explode explode point [SEP]']
[ 150/2000] tot_loss=2.425 (perp=11.284, rec=0.160, cos=0.009), tot_loss_proj:3.247 [t=0.26s]
prediction: ['[CLS] point things flame ones explode explode point [SEP]']
[ 200/2000] tot_loss=2.272 (perp=10.612, rec=0.144, cos=0.005), tot_loss_proj:3.136 [t=0.19s]
prediction: ['[CLS] point things flame ones explode explode at [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.221 (perp=10.364, rec=0.142, cos=0.006), tot_loss_proj:3.130 [t=0.19s]
prediction: ['[CLS] point things flame ones explode at explode [SEP]']
[ 300/2000] tot_loss=2.178 (perp=10.364, rec=0.101, cos=0.005), tot_loss_proj:3.128 [t=0.22s]
prediction: ['[CLS] point things flame ones explode at explode [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.136 (perp=10.117, rec=0.109, cos=0.004), tot_loss_proj:2.941 [t=0.19s]
prediction: ['[CLS] point things flame explode at explode title [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.126 (perp=10.210, rec=0.081, cos=0.003), tot_loss_proj:3.044 [t=0.19s]
prediction: ['[CLS] point things flame things at explode title [SEP]']
[ 450/2000] tot_loss=2.074 (perp=9.939, rec=0.084, cos=0.002), tot_loss_proj:2.923 [t=0.20s]
prediction: ['[CLS] point things flame things at explode into [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.975 (perp=9.457, rec=0.082, cos=0.002), tot_loss_proj:2.840 [t=0.20s]
prediction: ['[CLS] point that flame things into explode at [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.858 (perp=8.893, rec=0.077, cos=0.002), tot_loss_proj:2.813 [t=0.19s]
prediction: ['[CLS] point that things flame into explode at [SEP]']
[ 600/2000] tot_loss=1.850 (perp=8.893, rec=0.069, cos=0.002), tot_loss_proj:2.805 [t=0.23s]
prediction: ['[CLS] point that things flame into explode at [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.859 (perp=8.893, rec=0.078, cos=0.002), tot_loss_proj:2.813 [t=0.21s]
prediction: ['[CLS] point that things flame into explode at [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.803 (perp=8.623, rec=0.076, cos=0.002), tot_loss_proj:2.460 [t=0.23s]
prediction: ['[CLS] point that things explode into flame at [SEP]']
[ 750/2000] tot_loss=1.795 (perp=8.623, rec=0.069, cos=0.002), tot_loss_proj:2.454 [t=0.27s]
prediction: ['[CLS] point that things explode into flame at [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.805 (perp=8.623, rec=0.079, cos=0.002), tot_loss_proj:2.455 [t=0.22s]
prediction: ['[CLS] point that things explode into flame at [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.785 (perp=8.623, rec=0.059, cos=0.002), tot_loss_proj:2.459 [t=0.20s]
prediction: ['[CLS] point that things explode into flame at [SEP]']
[ 900/2000] tot_loss=1.795 (perp=8.623, rec=0.069, cos=0.002), tot_loss_proj:2.461 [t=0.19s]
prediction: ['[CLS] point that things explode into flame at [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.715 (perp=8.235, rec=0.066, cos=0.002), tot_loss_proj:2.297 [t=0.20s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1000/2000] tot_loss=1.716 (perp=8.235, rec=0.067, cos=0.002), tot_loss_proj:2.299 [t=0.20s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
[1050/2000] tot_loss=1.717 (perp=8.235, rec=0.068, cos=0.002), tot_loss_proj:2.294 [t=0.19s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1100/2000] tot_loss=1.712 (perp=8.235, rec=0.063, cos=0.002), tot_loss_proj:2.305 [t=0.24s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1150/2000] tot_loss=1.724 (perp=8.235, rec=0.075, cos=0.002), tot_loss_proj:2.290 [t=0.25s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
[1200/2000] tot_loss=1.717 (perp=8.235, rec=0.068, cos=0.002), tot_loss_proj:2.301 [t=0.22s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1250/2000] tot_loss=1.713 (perp=8.235, rec=0.064, cos=0.002), tot_loss_proj:2.304 [t=0.22s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1300/2000] tot_loss=1.716 (perp=8.235, rec=0.068, cos=0.002), tot_loss_proj:2.296 [t=0.30s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
[1350/2000] tot_loss=1.700 (perp=8.235, rec=0.052, cos=0.002), tot_loss_proj:2.306 [t=0.27s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1400/2000] tot_loss=1.721 (perp=8.235, rec=0.072, cos=0.002), tot_loss_proj:2.298 [t=0.26s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1450/2000] tot_loss=1.728 (perp=8.235, rec=0.080, cos=0.002), tot_loss_proj:2.305 [t=0.20s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
[1500/2000] tot_loss=1.725 (perp=8.235, rec=0.077, cos=0.002), tot_loss_proj:2.298 [t=0.19s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1550/2000] tot_loss=1.722 (perp=8.235, rec=0.074, cos=0.002), tot_loss_proj:2.302 [t=0.20s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1600/2000] tot_loss=1.717 (perp=8.235, rec=0.068, cos=0.002), tot_loss_proj:2.298 [t=0.27s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
[1650/2000] tot_loss=1.729 (perp=8.235, rec=0.081, cos=0.002), tot_loss_proj:2.305 [t=0.23s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1700/2000] tot_loss=1.719 (perp=8.235, rec=0.070, cos=0.002), tot_loss_proj:2.307 [t=0.27s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1750/2000] tot_loss=1.712 (perp=8.235, rec=0.064, cos=0.002), tot_loss_proj:2.306 [t=0.24s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
[1800/2000] tot_loss=1.711 (perp=8.235, rec=0.063, cos=0.002), tot_loss_proj:2.308 [t=0.21s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1850/2000] tot_loss=1.702 (perp=8.235, rec=0.054, cos=0.002), tot_loss_proj:2.302 [t=0.20s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[1900/2000] tot_loss=1.719 (perp=8.235, rec=0.070, cos=0.002), tot_loss_proj:2.309 [t=0.20s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
[1950/2000] tot_loss=1.721 (perp=8.235, rec=0.072, cos=0.002), tot_loss_proj:2.303 [t=0.21s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Attempt swap
[2000/2000] tot_loss=1.716 (perp=8.235, rec=0.068, cos=0.002), tot_loss_proj:2.302 [t=0.19s]
prediction: ['[CLS] point things that explode into flame at [SEP]']
Done with input #13 of 100.
reference: 
========================
[CLS] point at things that explode into flame [SEP]
========================
predicted: 
========================
[CLS] point things that explode into flame at [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 162.500

[Aggregate metrics]:
rouge1     | fm: 88.137 | p: 87.645 | r: 88.639
rouge2     | fm: 54.464 | p: 54.464 | r: 54.464
rougeL     | fm: 78.129 | p: 77.651 | r: 78.527
rougeLsum  | fm: 77.918 | p: 77.498 | r: 78.457
r1fm+r2fm = 142.602

input #13 time: 0:08:55 | total time: 2:00:30


Running input #14 of 100.
reference: 
========================
undeniably intriguing film 
========================
average of cosine similarity 0.9993219682705545
highest_index [0]
highest [0.9993219682705545]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  6151, 19825,  6321, 23824,  2143,   102]], device='cuda:0')
Debug: ref = ['[CLS] undeniably intriguing film [SEP]']
[Init] best rec loss: 1.9555590152740479 for ['[CLS] library falls children tierney espn [SEP]']
[Init] best rec loss: 1.90388023853302 for ['[CLS] olivia temple will kerr whom [SEP]']
[Init] best rec loss: 1.7101174592971802 for ['[CLS] junior touching itpton ; [SEP]']
[Init] best rec loss: 1.6756500005722046 for ['[CLS] brooks mentioninianame nothing [SEP]']
[Init] best rec loss: 1.649327278137207 for ['[CLS] quiver federation maddie sacramentoboard [SEP]']
[Init] best rec loss: 1.459338903427124 for ['[CLS] myers harold sprayed [MASK] tom [SEP]']
[Init] best perm rec loss: 1.455399990081787 for ['[CLS] myers harold tom [MASK] sprayed [SEP]']
[Init] best perm rec loss: 1.4520574808120728 for ['[CLS] harold myers [MASK] tom sprayed [SEP]']
[Init] best perm rec loss: 1.4497400522232056 for ['[CLS] myers harold [MASK] tom sprayed [SEP]']
[Init] best perm rec loss: 1.4491201639175415 for ['[CLS] harold tom myers [MASK] sprayed [SEP]']
[Init] best perm rec loss: 1.4477119445800781 for ['[CLS] [MASK] harold myers tom sprayed [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.307 (perp=10.373, rec=0.227, cos=0.004), tot_loss_proj:2.514 [t=0.24s]
prediction: ['[CLS] intriguing film filmbly intriguing [SEP]']
[ 100/2000] tot_loss=2.378 (perp=11.102, rec=0.155, cos=0.002), tot_loss_proj:2.637 [t=0.19s]
prediction: ['[CLS] intriguing intriguing filmbly intriguing [SEP]']
[ 150/2000] tot_loss=2.850 (perp=13.604, rec=0.127, cos=0.002), tot_loss_proj:3.271 [t=0.19s]
prediction: ['[CLS] intriguing intriguing filmblyenia [SEP]']
[ 200/2000] tot_loss=2.821 (perp=13.604, rec=0.098, cos=0.002), tot_loss_proj:3.269 [t=0.23s]
prediction: ['[CLS] intriguing intriguing filmblyenia [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.016 (perp=9.591, rec=0.096, cos=0.002), tot_loss_proj:2.351 [t=0.25s]
prediction: ['[CLS] intriguing intriguingeniably film [SEP]']
[ 300/2000] tot_loss=2.008 (perp=9.591, rec=0.088, cos=0.002), tot_loss_proj:2.355 [t=0.27s]
prediction: ['[CLS] intriguing intriguingeniably film [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.689 (perp=7.971, rec=0.094, cos=0.002), tot_loss_proj:1.926 [t=0.22s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.685 (perp=7.971, rec=0.089, cos=0.002), tot_loss_proj:1.924 [t=0.20s]
prediction: ['[CLS] intriguingeniably intriguing film [SEP]']
[ 450/2000] tot_loss=2.098 (perp=10.059, rec=0.085, cos=0.002), tot_loss_proj:3.684 [t=0.29s]
prediction: ['[CLS] intriguingeniably und film [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.415 (perp=6.728, rec=0.068, cos=0.001), tot_loss_proj:1.412 [t=0.21s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.417 (perp=6.728, rec=0.070, cos=0.001), tot_loss_proj:1.416 [t=0.21s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 600/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.405 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.401 [t=0.20s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.411 (perp=6.728, rec=0.064, cos=0.001), tot_loss_proj:1.406 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 750/2000] tot_loss=1.400 (perp=6.728, rec=0.053, cos=0.001), tot_loss_proj:1.405 [t=0.20s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.414 (perp=6.728, rec=0.067, cos=0.001), tot_loss_proj:1.412 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.417 (perp=6.728, rec=0.070, cos=0.001), tot_loss_proj:1.412 [t=0.28s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[ 900/2000] tot_loss=1.418 (perp=6.728, rec=0.071, cos=0.001), tot_loss_proj:1.404 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.405 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.398 (perp=6.728, rec=0.051, cos=0.001), tot_loss_proj:1.401 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1050/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.405 [t=0.31s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.397 (perp=6.728, rec=0.050, cos=0.001), tot_loss_proj:1.405 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.412 (perp=6.728, rec=0.065, cos=0.001), tot_loss_proj:1.411 [t=0.20s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1200/2000] tot_loss=1.419 (perp=6.728, rec=0.072, cos=0.001), tot_loss_proj:1.413 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.394 (perp=6.728, rec=0.047, cos=0.001), tot_loss_proj:1.403 [t=0.20s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.403 (perp=6.728, rec=0.056, cos=0.001), tot_loss_proj:1.403 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1350/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.405 [t=0.27s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.415 [t=0.30s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.408 (perp=6.728, rec=0.061, cos=0.001), tot_loss_proj:1.400 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1500/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.402 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.410 [t=0.20s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.397 [t=0.20s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1650/2000] tot_loss=1.409 (perp=6.728, rec=0.062, cos=0.001), tot_loss_proj:1.399 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.410 (perp=6.728, rec=0.063, cos=0.001), tot_loss_proj:1.407 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.410 [t=0.18s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1800/2000] tot_loss=1.405 (perp=6.728, rec=0.058, cos=0.001), tot_loss_proj:1.407 [t=0.24s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.406 (perp=6.728, rec=0.059, cos=0.001), tot_loss_proj:1.403 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.401 (perp=6.728, rec=0.054, cos=0.001), tot_loss_proj:1.416 [t=0.23s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
[1950/2000] tot_loss=1.402 (perp=6.728, rec=0.055, cos=0.001), tot_loss_proj:1.397 [t=0.19s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.404 (perp=6.728, rec=0.057, cos=0.001), tot_loss_proj:1.412 [t=0.25s]
prediction: ['[CLS] undeniably intriguing film [SEP]']
Done with input #14 of 100.
reference: 
========================
[CLS] undeniably intriguing film [SEP]
========================
predicted: 
========================
[CLS] undeniably intriguing film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.036 | p: 88.596 | r: 89.397
rouge2     | fm: 57.429 | p: 57.429 | r: 57.429
rougeL     | fm: 79.774 | p: 79.361 | r: 80.323
rougeLsum  | fm: 79.197 | p: 78.798 | r: 79.709
r1fm+r2fm = 146.465

input #14 time: 0:08:31 | total time: 2:09:02


Running input #15 of 100.
reference: 
========================
efficient , suitably anonymous chiller . 
========================
average of cosine similarity 0.9992724874303516
highest_index [0]
highest [0.9992724874303516]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  8114,  1010,  4848,  8231, 10812, 10720,  2121,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] efficient, suitably anonymous chiller. [SEP]']
[Init] best rec loss: 1.96763014793396 for ['[CLS] rope accepting the truth few having sikh music [SEP]']
[Init] best rec loss: 1.925123929977417 for ['[CLS] ¹⁄₂ lds bay simple 19 client utc congestion [SEP]']
[Init] best rec loss: 1.9198782444000244 for ['[CLS] property par coming kincaid pulling node reid wild [SEP]']
[Init] best rec loss: 1.8514207601547241 for ['[CLS] light over lear hodges second base twinned ecstasy [SEP]']
[Init] best rec loss: 1.7387832403182983 for ['[CLS] clubs peaceerated enclosed davis 事 timestle [SEP]']
[Init] best rec loss: 1.7253295183181763 for ['[CLS] tor casey decembergrate doua developed logic [SEP]']
[Init] best rec loss: 1.7060983180999756 for ['[CLS] du resign what pet system jazz aschurch [SEP]']
[Init] best rec loss: 1.7037686109542847 for ['[CLS] madeline discovery ocean truss stations chance ledge waiting [SEP]']
[Init] best rec loss: 1.6834999322891235 for ['[CLS] child indian setting launched and today returns becker [SEP]']
[Init] best rec loss: 1.5785369873046875 for ['[CLS] winner french badminton harperrdial missed ex fond [SEP]']
[Init] best perm rec loss: 1.575916051864624 for ['[CLS] frenchrdial badminton winner ex missed fond harper [SEP]']
[Init] best perm rec loss: 1.5737770795822144 for ['[CLS] french harper fondrdial badminton missed ex winner [SEP]']
[Init] best perm rec loss: 1.5736515522003174 for ['[CLS] missed winner ex frenchrdial fond harper badminton [SEP]']
[Init] best perm rec loss: 1.569117546081543 for ['[CLS]rdial ex harper fond missed french winner badminton [SEP]']
[Init] best perm rec loss: 1.568715214729309 for ['[CLS] french ex harper fondrdial missed winner badminton [SEP]']
[Init] best perm rec loss: 1.5686029195785522 for ['[CLS] harperrdial fond winner french ex missed badminton [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.694 (perp=12.074, rec=0.272, cos=0.007), tot_loss_proj:2.959 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymousgram velocity digit decker [SEP]']
[ 100/2000] tot_loss=2.566 (perp=11.794, rec=0.203, cos=0.004), tot_loss_proj:3.014 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymouserably digit anonymous [SEP]']
[ 150/2000] tot_loss=2.531 (perp=11.831, rec=0.161, cos=0.004), tot_loss_proj:2.964 [t=0.24s]
prediction: ['[CLS] suitably efficient chillerably digit chill [SEP]']
[ 200/2000] tot_loss=2.567 (perp=12.108, rec=0.142, cos=0.003), tot_loss_proj:3.154 [t=0.28s]
prediction: ['[CLS] suitably efficient anonymouser chill digit chill [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.282 (perp=10.523, rec=0.173, cos=0.005), tot_loss_proj:2.487 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill digit chiller [SEP]']
[ 300/2000] tot_loss=1.927 (perp=8.996, rec=0.124, cos=0.004), tot_loss_proj:2.139 [t=0.20s]
prediction: ['[CLS] suitably efficient anonymous chill chill chiller [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.918 (perp=8.996, rec=0.116, cos=0.003), tot_loss_proj:2.157 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chill chiller [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.314 (perp=11.041, rec=0.102, cos=0.004), tot_loss_proj:2.663 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chilliouser [SEP]']
[ 450/2000] tot_loss=2.395 (perp=11.442, rec=0.103, cos=0.003), tot_loss_proj:2.757 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chillrueder [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.284 (perp=10.820, rec=0.117, cos=0.003), tot_loss_proj:2.529 [t=0.18s]
prediction: ['[CLS] suitably efficient medallion anonymous chill chiller [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.008 (perp=9.348, rec=0.134, cos=0.005), tot_loss_proj:2.176 [t=0.24s]
prediction: ['[CLS] suitably efficient anonymous chill chiller plus [SEP]']
[ 600/2000] tot_loss=1.708 (perp=8.042, rec=0.096, cos=0.003), tot_loss_proj:1.865 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.717 (perp=8.042, rec=0.105, cos=0.003), tot_loss_proj:1.866 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.716 (perp=8.042, rec=0.105, cos=0.003), tot_loss_proj:1.856 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[ 750/2000] tot_loss=1.708 (perp=8.042, rec=0.097, cos=0.003), tot_loss_proj:1.854 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.713 (perp=8.042, rec=0.102, cos=0.003), tot_loss_proj:1.854 [t=0.23s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.703 (perp=8.042, rec=0.093, cos=0.002), tot_loss_proj:1.862 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[ 900/2000] tot_loss=1.700 (perp=8.042, rec=0.089, cos=0.002), tot_loss_proj:1.858 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.693 (perp=8.042, rec=0.083, cos=0.002), tot_loss_proj:1.858 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.690 (perp=8.042, rec=0.080, cos=0.002), tot_loss_proj:1.853 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1050/2000] tot_loss=1.694 (perp=8.042, rec=0.084, cos=0.002), tot_loss_proj:1.858 [t=0.22s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.698 (perp=8.042, rec=0.088, cos=0.002), tot_loss_proj:1.852 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.686 (perp=8.042, rec=0.075, cos=0.002), tot_loss_proj:1.845 [t=0.21s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1200/2000] tot_loss=1.693 (perp=8.042, rec=0.083, cos=0.002), tot_loss_proj:1.852 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.693 (perp=8.042, rec=0.082, cos=0.002), tot_loss_proj:1.851 [t=0.24s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.683 (perp=8.042, rec=0.073, cos=0.002), tot_loss_proj:1.860 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1350/2000] tot_loss=1.701 (perp=8.042, rec=0.091, cos=0.002), tot_loss_proj:1.858 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.682 (perp=8.042, rec=0.071, cos=0.002), tot_loss_proj:1.859 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.687 (perp=8.042, rec=0.077, cos=0.002), tot_loss_proj:1.848 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1500/2000] tot_loss=1.685 (perp=8.042, rec=0.075, cos=0.002), tot_loss_proj:1.853 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.678 (perp=8.042, rec=0.067, cos=0.002), tot_loss_proj:1.851 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.691 (perp=8.042, rec=0.080, cos=0.002), tot_loss_proj:1.854 [t=0.21s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1650/2000] tot_loss=1.691 (perp=8.042, rec=0.080, cos=0.002), tot_loss_proj:1.855 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.691 (perp=8.042, rec=0.081, cos=0.002), tot_loss_proj:1.859 [t=0.25s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.702 (perp=8.042, rec=0.091, cos=0.002), tot_loss_proj:1.857 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1800/2000] tot_loss=1.686 (perp=8.042, rec=0.076, cos=0.002), tot_loss_proj:1.855 [t=0.24s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.684 (perp=8.042, rec=0.073, cos=0.002), tot_loss_proj:1.854 [t=0.19s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.690 (perp=8.042, rec=0.080, cos=0.002), tot_loss_proj:1.857 [t=0.20s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
[1950/2000] tot_loss=1.695 (perp=8.042, rec=0.085, cos=0.002), tot_loss_proj:1.855 [t=0.18s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.704 (perp=8.042, rec=0.093, cos=0.002), tot_loss_proj:1.845 [t=0.20s]
prediction: ['[CLS] suitably efficient anonymous chill chiller. [SEP]']
Done with input #15 of 100.
reference: 
========================
[CLS] efficient, suitably anonymous chiller. [SEP]
========================
predicted: 
========================
[CLS] suitably efficient anonymous chill chiller. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 92.308 | p: 85.714 | r: 100.000
rouge2     | fm: 18.182 | p: 16.667 | r: 20.000
rougeL     | fm: 76.923 | p: 71.429 | r: 83.333
rougeLsum  | fm: 76.923 | p: 71.429 | r: 83.333
r1fm+r2fm = 110.490

[Aggregate metrics]:
rouge1     | fm: 89.204 | p: 88.416 | r: 90.268
rouge2     | fm: 54.375 | p: 54.375 | r: 54.531
rougeL     | fm: 79.544 | p: 78.814 | r: 80.332
rougeLsum  | fm: 79.400 | p: 78.646 | r: 80.239
r1fm+r2fm = 143.579

input #15 time: 0:08:22 | total time: 2:17:24


Running input #16 of 100.
reference: 
========================
all of this , and more 
========================
average of cosine similarity 0.9993411698074052
highest_index [0]
highest [0.9993411698074052]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2035, 1997, 2023, 1010, 1998, 2062,  102]], device='cuda:0')
Debug: ref = ['[CLS] all of this, and more [SEP]']
[Init] best rec loss: 1.9508296251296997 for ['[CLS] experienced dev candidate giantstel pregnant [SEP]']
[Init] best rec loss: 1.8343384265899658 for ['[CLS] drops min s concerning dal cannon [SEP]']
[Init] best rec loss: 1.6890870332717896 for ['[CLS]athi lord alta slowly film various [SEP]']
[Init] best rec loss: 1.6304024457931519 for ['[CLS] ages mall mean influential len twain [SEP]']
[Init] best rec loss: 1.5867127180099487 for ['[CLS] ruling downcaster robot got focus [SEP]']
[Init] best rec loss: 1.525856614112854 for ['[CLS] legsyen t sharon camp ro [SEP]']
[Init] best rec loss: 1.5195893049240112 for ['[CLS]encia olgazy edit areas sounding [SEP]']
[Init] best rec loss: 1.3733412027359009 for ['[CLS] a clubs slayer trophy affected residents [SEP]']
[Init] best rec loss: 1.3456374406814575 for ['[CLS] ultra backpack tallest you downstream map [SEP]']
[Init] best perm rec loss: 1.337275505065918 for ['[CLS] tallest downstream map you backpack ultra [SEP]']
[Init] best perm rec loss: 1.336099624633789 for ['[CLS] map tallest ultra downstream backpack you [SEP]']
[Init] best perm rec loss: 1.3238879442214966 for ['[CLS] tallest ultra map backpack you downstream [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.481 (perp=8.378, rec=0.578, cos=0.227), tot_loss_proj:2.952 [t=0.20s]
prediction: ['[CLS] ever that all more building it [SEP]']
[ 100/2000] tot_loss=2.356 (perp=9.918, rec=0.313, cos=0.059), tot_loss_proj:3.501 [t=0.23s]
prediction: ['[CLS] more this all this pressing this [SEP]']
[ 150/2000] tot_loss=1.931 (perp=8.559, rec=0.198, cos=0.021), tot_loss_proj:3.230 [t=0.18s]
prediction: ['[CLS] one and all this another this [SEP]']
[ 200/2000] tot_loss=1.689 (perp=7.453, rec=0.180, cos=0.018), tot_loss_proj:2.512 [t=0.19s]
prediction: ['[CLS] more and all this another more [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.527 (perp=6.313, rec=0.232, cos=0.032), tot_loss_proj:2.579 [t=0.21s]
prediction: ['[CLS] all this more and another more [SEP]']
[ 300/2000] tot_loss=1.648 (perp=7.430, rec=0.148, cos=0.014), tot_loss_proj:2.402 [t=0.24s]
prediction: ['[CLS] all this performed and another more [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.409 (perp=6.313, rec=0.136, cos=0.010), tot_loss_proj:2.681 [t=0.18s]
prediction: ['[CLS] all this more and another more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.398 (perp=6.313, rec=0.126, cos=0.009), tot_loss_proj:2.682 [t=0.23s]
prediction: ['[CLS] all this more and another more [SEP]']
[ 450/2000] tot_loss=1.963 (perp=9.112, rec=0.132, cos=0.009), tot_loss_proj:3.025 [t=0.18s]
prediction: ['[CLS] all this three and under more [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.622 (perp=7.472, rec=0.118, cos=0.009), tot_loss_proj:2.582 [t=0.18s]
prediction: ['[CLS] all this another and three more [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.405 (perp=6.328, rec=0.129, cos=0.010), tot_loss_proj:2.904 [t=0.20s]
prediction: ['[CLS] past all this and three more [SEP]']
[ 600/2000] tot_loss=1.395 (perp=6.328, rec=0.120, cos=0.009), tot_loss_proj:2.907 [t=0.18s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.584 (perp=7.302, rec=0.115, cos=0.009), tot_loss_proj:2.856 [t=0.19s]
prediction: ['[CLS] past all this and first more [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.647 (perp=7.590, rec=0.120, cos=0.009), tot_loss_proj:3.137 [t=0.19s]
prediction: ['[CLS] three past all this and more [SEP]']
[ 750/2000] tot_loss=1.641 (perp=7.590, rec=0.114, cos=0.009), tot_loss_proj:3.142 [t=0.25s]
prediction: ['[CLS] three past all this and more [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.395 (perp=6.328, rec=0.120, cos=0.009), tot_loss_proj:2.900 [t=0.18s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.388 (perp=6.328, rec=0.114, cos=0.009), tot_loss_proj:2.900 [t=0.18s]
prediction: ['[CLS] past all this and three more [SEP]']
[ 900/2000] tot_loss=1.392 (perp=6.328, rec=0.118, cos=0.008), tot_loss_proj:2.900 [t=0.18s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.397 (perp=6.328, rec=0.122, cos=0.008), tot_loss_proj:2.902 [t=0.18s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.390 (perp=6.328, rec=0.116, cos=0.008), tot_loss_proj:2.900 [t=0.19s]
prediction: ['[CLS] past all this and three more [SEP]']
[1050/2000] tot_loss=1.396 (perp=6.328, rec=0.121, cos=0.008), tot_loss_proj:2.897 [t=0.19s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.394 (perp=6.328, rec=0.120, cos=0.008), tot_loss_proj:2.903 [t=0.18s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.385 (perp=6.328, rec=0.112, cos=0.008), tot_loss_proj:2.902 [t=0.20s]
prediction: ['[CLS] past all this and three more [SEP]']
[1200/2000] tot_loss=1.389 (perp=6.328, rec=0.115, cos=0.008), tot_loss_proj:2.900 [t=0.25s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.399 (perp=6.328, rec=0.125, cos=0.008), tot_loss_proj:2.904 [t=0.27s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.377 (perp=6.328, rec=0.103, cos=0.008), tot_loss_proj:2.899 [t=0.18s]
prediction: ['[CLS] past all this and three more [SEP]']
[1350/2000] tot_loss=1.393 (perp=6.328, rec=0.119, cos=0.008), tot_loss_proj:2.902 [t=0.21s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.388 (perp=6.328, rec=0.115, cos=0.008), tot_loss_proj:2.901 [t=0.26s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.390 (perp=6.328, rec=0.116, cos=0.008), tot_loss_proj:2.899 [t=0.19s]
prediction: ['[CLS] past all this and three more [SEP]']
[1500/2000] tot_loss=1.393 (perp=6.328, rec=0.120, cos=0.008), tot_loss_proj:2.901 [t=0.19s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.384 (perp=6.328, rec=0.110, cos=0.008), tot_loss_proj:2.900 [t=0.19s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.383 (perp=6.328, rec=0.109, cos=0.008), tot_loss_proj:2.902 [t=0.22s]
prediction: ['[CLS] past all this and three more [SEP]']
[1650/2000] tot_loss=1.383 (perp=6.328, rec=0.109, cos=0.008), tot_loss_proj:2.901 [t=0.24s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.392 (perp=6.328, rec=0.118, cos=0.008), tot_loss_proj:2.896 [t=0.19s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1750/2000] tot_loss=1.392 (perp=6.328, rec=0.119, cos=0.008), tot_loss_proj:2.903 [t=0.18s]
prediction: ['[CLS] past all this and three more [SEP]']
[1800/2000] tot_loss=1.388 (perp=6.328, rec=0.114, cos=0.008), tot_loss_proj:2.902 [t=0.22s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1850/2000] tot_loss=1.393 (perp=6.328, rec=0.119, cos=0.008), tot_loss_proj:2.898 [t=0.19s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[1900/2000] tot_loss=1.388 (perp=6.328, rec=0.114, cos=0.008), tot_loss_proj:2.903 [t=0.27s]
prediction: ['[CLS] past all this and three more [SEP]']
[1950/2000] tot_loss=1.387 (perp=6.328, rec=0.113, cos=0.008), tot_loss_proj:2.904 [t=0.23s]
prediction: ['[CLS] past all this and three more [SEP]']
Attempt swap
[2000/2000] tot_loss=1.397 (perp=6.328, rec=0.123, cos=0.008), tot_loss_proj:2.902 [t=0.19s]
prediction: ['[CLS] past all this and three more [SEP]']
Done with input #16 of 100.
reference: 
========================
[CLS] all of this, and more [SEP]
========================
predicted: 
========================
[CLS] past all this and three more [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 75.000 | r: 85.714
rouge2     | fm: 30.769 | p: 28.571 | r: 33.333
rougeL     | fm: 80.000 | p: 75.000 | r: 85.714
rougeLsum  | fm: 80.000 | p: 75.000 | r: 85.714
r1fm+r2fm = 110.769

[Aggregate metrics]:
rouge1     | fm: 88.622 | p: 87.549 | r: 89.888
rouge2     | fm: 53.166 | p: 52.941 | r: 53.428
rougeL     | fm: 79.866 | p: 78.949 | r: 81.037
rougeLsum  | fm: 79.286 | p: 78.412 | r: 80.466
r1fm+r2fm = 141.788

input #16 time: 0:08:21 | total time: 2:25:46


Running input #17 of 100.
reference: 
========================
want to think too much about what 's going on 
========================
average of cosine similarity 0.9992301552937229
highest_index [0]
highest [0.9992301552937229]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[ 101, 2215, 2000, 2228, 2205, 2172, 2055, 2054, 1005, 1055, 2183, 2006,
          102]], device='cuda:0')
Debug: ref = ["[CLS] want to think too much about what's going on [SEP]"]
[Init] best rec loss: 1.6595710515975952 for ['[CLS] one yuri alter slot roll again kanyefield await mourning benefit [SEP]']
[Init] best rec loss: 1.6428885459899902 for ['[CLS] friend agency todd wi dirty percent milesamp... vietsive [SEP]']
[Init] best rec loss: 1.6136316061019897 for ['[CLS] us junk " pete separate lost did eventriated air each [SEP]']
[Init] best rec loss: 1.576501488685608 for ['[CLS] confines gracie spit modern name slip loire service again recall gate [SEP]']
[Init] best rec loss: 1.5198489427566528 for ['[CLS] highestlt short ad relation minority black bunch marine above different [SEP]']
[Init] best rec loss: 1.513322114944458 for ['[CLS] name standardfoldieg names result diesfulds suggest mystery [SEP]']
[Init] best rec loss: 1.4297772645950317 for ['[CLS] leadute ti aria shooter atislav levi average garde attitude [SEP]']
[Init] best rec loss: 1.3880505561828613 for ['[CLS] general sensation water consecrated affairvudran bethany then religious threatened [SEP]']
[Init] best rec loss: 1.366730809211731 for ['[CLS] georgian kilometers following fatal conversion station arch with gene goddess [SEP]']
[Init] best perm rec loss: 1.3620654344558716 for ['[CLS] gene station fatalh conversion following goddess kilometers with georgian arc [SEP]']
[Init] best perm rec loss: 1.361521601676941 for ['[CLS] arc gene goddess following with georgian conversionh kilometers fatal station [SEP]']
[Init] best perm rec loss: 1.361145257949829 for ['[CLS] fatal with goddess geneh georgian conversion kilometers arc station following [SEP]']
[Init] best perm rec loss: 1.3605331182479858 for ['[CLS] kilometers gene following fatal with goddess georgian arc conversion stationh [SEP]']
[Init] best perm rec loss: 1.360186219215393 for ['[CLS] geneh conversion station with kilometers following georgian arc fatal goddess [SEP]']
[Init] best perm rec loss: 1.3596504926681519 for ['[CLS]h kilometers conversion fatal following station goddess with georgian gene arc [SEP]']
[Init] best perm rec loss: 1.3583624362945557 for ['[CLS] kilometers with stationh conversion fatal goddess arc gene following georgian [SEP]']
[Init] best perm rec loss: 1.3579857349395752 for ['[CLS] georgian geneh station with fatal conversion kilometers following arc goddess [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.467 (perp=10.938, rec=0.247, cos=0.032), tot_loss_proj:3.378 [t=0.22s]
prediction: ['[CLS] too think dollars want much think understand the crowd arc about [SEP]']
[ 100/2000] tot_loss=2.094 (perp=9.879, rec=0.113, cos=0.005), tot_loss_proj:2.862 [t=0.19s]
prediction: ['[CLS] too think much want much going about going down arc about [SEP]']
[ 150/2000] tot_loss=1.968 (perp=9.345, rec=0.095, cos=0.004), tot_loss_proj:2.770 [t=0.19s]
prediction: ['[CLS] too think to want much s about going going on about [SEP]']
[ 200/2000] tot_loss=2.084 (perp=10.014, rec=0.079, cos=0.002), tot_loss_proj:2.968 [t=0.19s]
prediction: ['[CLS] too think to want much s about going what what about [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.812 (perp=8.717, rec=0.067, cos=0.002), tot_loss_proj:2.602 [t=0.19s]
prediction: ['[CLS] think to want too much s to going what what about [SEP]']
[ 300/2000] tot_loss=1.727 (perp=8.310, rec=0.064, cos=0.002), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS] think to want too much s to going on what about [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.427 (perp=6.804, rec=0.064, cos=0.002), tot_loss_proj:1.944 [t=0.19s]
prediction: ['[CLS] think to want too much what s to going on about [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.312 (perp=6.177, rec=0.074, cos=0.002), tot_loss_proj:1.768 [t=0.24s]
prediction: ['[CLS] think to want to too much what s going on about [SEP]']
[ 450/2000] tot_loss=1.293 (perp=6.177, rec=0.055, cos=0.002), tot_loss_proj:1.766 [t=0.19s]
prediction: ['[CLS] think to want to too much what s going on about [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.183 (perp=5.559, rec=0.070, cos=0.002), tot_loss_proj:1.497 [t=0.19s]
prediction: ['[CLS] to want to think too much what s going on about [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.058 (perp=4.912, rec=0.073, cos=0.003), tot_loss_proj:1.369 [t=0.22s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
[ 600/2000] tot_loss=1.050 (perp=4.912, rec=0.066, cos=0.002), tot_loss_proj:1.366 [t=0.19s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.051 (perp=4.912, rec=0.067, cos=0.002), tot_loss_proj:1.383 [t=0.27s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.052 (perp=4.912, rec=0.068, cos=0.002), tot_loss_proj:1.382 [t=0.20s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
[ 750/2000] tot_loss=1.045 (perp=4.912, rec=0.061, cos=0.002), tot_loss_proj:1.373 [t=0.19s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.062 (perp=4.912, rec=0.078, cos=0.002), tot_loss_proj:1.375 [t=0.18s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.051 (perp=4.912, rec=0.067, cos=0.002), tot_loss_proj:1.369 [t=0.18s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
[ 900/2000] tot_loss=1.055 (perp=4.912, rec=0.071, cos=0.002), tot_loss_proj:1.368 [t=0.18s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.049 (perp=4.912, rec=0.065, cos=0.002), tot_loss_proj:1.380 [t=0.19s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
Attempt swap
[1000/2000] tot_loss=1.053 (perp=4.912, rec=0.069, cos=0.002), tot_loss_proj:1.380 [t=0.27s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
[1050/2000] tot_loss=1.053 (perp=4.912, rec=0.069, cos=0.002), tot_loss_proj:1.375 [t=0.18s]
prediction: ['[CLS] to want to think about too much what s going on [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=0.968 (perp=4.520, rec=0.063, cos=0.002), tot_loss_proj:1.249 [t=0.18s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1150/2000] tot_loss=0.976 (perp=4.520, rec=0.071, cos=0.002), tot_loss_proj:1.249 [t=0.19s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
[1200/2000] tot_loss=0.971 (perp=4.520, rec=0.065, cos=0.002), tot_loss_proj:1.254 [t=0.20s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1250/2000] tot_loss=0.962 (perp=4.520, rec=0.056, cos=0.002), tot_loss_proj:1.254 [t=0.18s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1300/2000] tot_loss=0.965 (perp=4.520, rec=0.059, cos=0.002), tot_loss_proj:1.243 [t=0.22s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
[1350/2000] tot_loss=0.968 (perp=4.520, rec=0.062, cos=0.002), tot_loss_proj:1.249 [t=0.19s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1400/2000] tot_loss=0.971 (perp=4.520, rec=0.066, cos=0.002), tot_loss_proj:1.248 [t=0.18s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1450/2000] tot_loss=0.975 (perp=4.520, rec=0.070, cos=0.002), tot_loss_proj:1.258 [t=0.18s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
[1500/2000] tot_loss=0.966 (perp=4.520, rec=0.061, cos=0.002), tot_loss_proj:1.247 [t=0.18s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1550/2000] tot_loss=0.971 (perp=4.520, rec=0.065, cos=0.002), tot_loss_proj:1.243 [t=0.18s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1600/2000] tot_loss=0.966 (perp=4.520, rec=0.060, cos=0.002), tot_loss_proj:1.259 [t=0.19s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
[1650/2000] tot_loss=0.966 (perp=4.520, rec=0.061, cos=0.002), tot_loss_proj:1.249 [t=0.18s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1700/2000] tot_loss=0.970 (perp=4.520, rec=0.064, cos=0.002), tot_loss_proj:1.248 [t=0.24s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1750/2000] tot_loss=0.973 (perp=4.520, rec=0.067, cos=0.002), tot_loss_proj:1.244 [t=0.19s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
[1800/2000] tot_loss=0.971 (perp=4.520, rec=0.066, cos=0.002), tot_loss_proj:1.258 [t=0.19s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1850/2000] tot_loss=0.973 (perp=4.520, rec=0.068, cos=0.002), tot_loss_proj:1.249 [t=0.20s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[1900/2000] tot_loss=0.959 (perp=4.520, rec=0.053, cos=0.002), tot_loss_proj:1.254 [t=0.18s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
[1950/2000] tot_loss=0.973 (perp=4.520, rec=0.068, cos=0.002), tot_loss_proj:1.262 [t=0.21s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Attempt swap
[2000/2000] tot_loss=0.979 (perp=4.520, rec=0.073, cos=0.002), tot_loss_proj:1.257 [t=0.24s]
prediction: ['[CLS] to want to think too much about what s going on [SEP]']
Done with input #17 of 100.
reference: 
========================
[CLS] want to think too much about what's going on [SEP]
========================
predicted: 
========================
[CLS] to want to think too much about what s going on [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.000 | p: 92.308 | r: 100.000
rouge2     | fm: 86.957 | p: 83.333 | r: 90.909
rougeL     | fm: 96.000 | p: 92.308 | r: 100.000
rougeLsum  | fm: 96.000 | p: 92.308 | r: 100.000
r1fm+r2fm = 182.957

[Aggregate metrics]:
rouge1     | fm: 88.923 | p: 87.677 | r: 90.463
rouge2     | fm: 54.716 | p: 54.339 | r: 55.160
rougeL     | fm: 80.347 | p: 79.286 | r: 81.736
rougeLsum  | fm: 80.293 | p: 79.216 | r: 81.579
r1fm+r2fm = 143.639

input #17 time: 0:08:17 | total time: 2:34:03


Running input #18 of 100.
reference: 
========================
invigorating 
========================
average of cosine similarity 0.9993194147820215
highest_index [0]
highest [0.9993194147820215]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1999,  5737, 20255,  5844,   102]], device='cuda:0')
Debug: ref = ['[CLS] invigorating [SEP]']
[Init] best rec loss: 1.974354863166809 for ['[CLS] roadhosis purple couple [SEP]']
[Init] best rec loss: 1.9697707891464233 for ['[CLS] death laytonning segregation [SEP]']
[Init] best rec loss: 1.9564363956451416 for ['[CLS] bound dvd lead grace [SEP]']
[Init] best rec loss: 1.8697879314422607 for ['[CLS]ments vs olsen gaelic [SEP]']
[Init] best rec loss: 1.7662303447723389 for ['[CLS] says oh dynasty watershed [SEP]']
[Init] best rec loss: 1.67368483543396 for ['[CLS] disappointednce secret running [SEP]']
[Init] best rec loss: 1.5851483345031738 for ['[CLS] with thy commission operating [SEP]']
[Init] best rec loss: 1.3104640245437622 for ['[CLS] dual circle duodle [SEP]']
[Init] best rec loss: 1.2881578207015991 for ['[CLS] canellant replication calm [SEP]']
[Init] best perm rec loss: 1.2752639055252075 for ['[CLS] replicationellant can calm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.914 (perp=13.366, rec=0.237, cos=0.004), tot_loss_proj:4.533 [t=0.18s]
prediction: ['[CLS]gorgorviating [SEP]']
[ 100/2000] tot_loss=2.007 (perp=9.456, rec=0.114, cos=0.002), tot_loss_proj:2.783 [t=0.18s]
prediction: ['[CLS]gorvigorating [SEP]']
[ 150/2000] tot_loss=1.191 (perp=5.588, rec=0.072, cos=0.002), tot_loss_proj:1.182 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
[ 200/2000] tot_loss=1.186 (perp=5.588, rec=0.067, cos=0.001), tot_loss_proj:1.192 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.181 (perp=5.588, rec=0.062, cos=0.001), tot_loss_proj:1.186 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
[ 300/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.172 [t=0.25s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.185 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.183 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[ 450/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.177 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.185 (perp=5.588, rec=0.066, cos=0.001), tot_loss_proj:1.187 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.183 (perp=5.588, rec=0.064, cos=0.001), tot_loss_proj:1.184 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[ 600/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.189 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.171 (perp=5.588, rec=0.052, cos=0.001), tot_loss_proj:1.185 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.169 (perp=5.588, rec=0.050, cos=0.001), tot_loss_proj:1.178 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[ 750/2000] tot_loss=1.169 (perp=5.588, rec=0.050, cos=0.001), tot_loss_proj:1.183 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.187 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.196 (perp=5.588, rec=0.077, cos=0.001), tot_loss_proj:1.179 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[ 900/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.176 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.183 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1000/2000] tot_loss=1.179 (perp=5.588, rec=0.060, cos=0.001), tot_loss_proj:1.187 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[1050/2000] tot_loss=1.174 (perp=5.588, rec=0.055, cos=0.001), tot_loss_proj:1.192 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1100/2000] tot_loss=1.184 (perp=5.588, rec=0.065, cos=0.001), tot_loss_proj:1.181 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1150/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.189 [t=0.22s]
prediction: ['[CLS] invigorating [SEP]']
[1200/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.180 [t=0.21s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1250/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.177 [t=0.24s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1300/2000] tot_loss=1.199 (perp=5.588, rec=0.080, cos=0.001), tot_loss_proj:1.178 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
[1350/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.187 [t=0.27s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1400/2000] tot_loss=1.182 (perp=5.588, rec=0.063, cos=0.001), tot_loss_proj:1.177 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1450/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.180 [t=0.21s]
prediction: ['[CLS] invigorating [SEP]']
[1500/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.179 [t=0.20s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1550/2000] tot_loss=1.168 (perp=5.588, rec=0.049, cos=0.001), tot_loss_proj:1.167 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1600/2000] tot_loss=1.173 (perp=5.588, rec=0.054, cos=0.001), tot_loss_proj:1.186 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1650/2000] tot_loss=1.177 (perp=5.588, rec=0.058, cos=0.001), tot_loss_proj:1.189 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1700/2000] tot_loss=1.172 (perp=5.588, rec=0.053, cos=0.001), tot_loss_proj:1.173 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1750/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.168 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
[1800/2000] tot_loss=1.176 (perp=5.588, rec=0.057, cos=0.001), tot_loss_proj:1.175 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1850/2000] tot_loss=1.178 (perp=5.588, rec=0.059, cos=0.001), tot_loss_proj:1.183 [t=0.26s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[1900/2000] tot_loss=1.187 (perp=5.588, rec=0.068, cos=0.001), tot_loss_proj:1.190 [t=0.23s]
prediction: ['[CLS] invigorating [SEP]']
[1950/2000] tot_loss=1.190 (perp=5.588, rec=0.071, cos=0.001), tot_loss_proj:1.176 [t=0.19s]
prediction: ['[CLS] invigorating [SEP]']
Attempt swap
[2000/2000] tot_loss=1.175 (perp=5.588, rec=0.056, cos=0.001), tot_loss_proj:1.185 [t=0.18s]
prediction: ['[CLS] invigorating [SEP]']
Done with input #18 of 100.
reference: 
========================
[CLS] invigorating [SEP]
========================
predicted: 
========================
[CLS] invigorating [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.461 | p: 88.314 | r: 90.915
rouge2     | fm: 57.427 | p: 56.996 | r: 57.914
rougeL     | fm: 81.506 | p: 80.429 | r: 82.824
rougeLsum  | fm: 81.266 | p: 80.228 | r: 82.656
r1fm+r2fm = 146.888

input #18 time: 0:08:31 | total time: 2:42:35


Running input #19 of 100.
reference: 
========================
to infamy 
========================
average of cosine similarity 0.9993635209107408
highest_index [0]
highest [0.9993635209107408]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2000, 1999, 7011, 8029,  102]], device='cuda:0')
Debug: ref = ['[CLS] to infamy [SEP]']
[Init] best rec loss: 1.458032250404358 for ['[CLS] elevator swings 1941 ser [SEP]']
[Init] best rec loss: 1.306396722793579 for ['[CLS] [MASK] bishop split jay [SEP]']
[Init] best rec loss: 1.226775884628296 for ['[CLS] really is horse cast [SEP]']
[Init] best rec loss: 1.1880154609680176 for ['[CLS] interstate selectedzuki symmetry [SEP]']
[Init] best rec loss: 1.1041380167007446 for ['[CLS] intra raf soviet events [SEP]']
[Init] best perm rec loss: 1.1023863554000854 for ['[CLS] raf soviet events intra [SEP]']
[Init] best perm rec loss: 1.099515676498413 for ['[CLS] intra events soviet raf [SEP]']
[Init] best perm rec loss: 1.0991603136062622 for ['[CLS] soviet intra events raf [SEP]']
[Init] best perm rec loss: 1.0963892936706543 for ['[CLS] soviet events intra raf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.556 (perp=10.869, rec=0.315, cos=0.067), tot_loss_proj:3.716 [t=0.30s]
prediction: ['[CLS]famy to association [SEP]']
[ 100/2000] tot_loss=2.197 (perp=10.293, rec=0.132, cos=0.006), tot_loss_proj:3.467 [t=0.25s]
prediction: ['[CLS]famy to in [SEP]']
[ 150/2000] tot_loss=2.135 (perp=10.293, rec=0.075, cos=0.002), tot_loss_proj:3.457 [t=0.27s]
prediction: ['[CLS]famy to in [SEP]']
[ 200/2000] tot_loss=2.121 (perp=10.293, rec=0.061, cos=0.001), tot_loss_proj:3.447 [t=0.24s]
prediction: ['[CLS]famy to in [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.293 (perp=6.110, rec=0.068, cos=0.003), tot_loss_proj:1.308 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[ 300/2000] tot_loss=1.286 (perp=6.110, rec=0.062, cos=0.001), tot_loss_proj:1.303 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.285 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.297 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.284 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.294 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[ 450/2000] tot_loss=1.283 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.300 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.291 (perp=6.110, rec=0.068, cos=0.001), tot_loss_proj:1.298 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.294 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
[ 600/2000] tot_loss=1.281 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.289 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.296 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.282 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.290 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[ 750/2000] tot_loss=1.282 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.296 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.291 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.300 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.286 (perp=6.110, rec=0.063, cos=0.001), tot_loss_proj:1.288 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[ 900/2000] tot_loss=1.277 (perp=6.110, rec=0.054, cos=0.001), tot_loss_proj:1.300 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.287 (perp=6.110, rec=0.064, cos=0.001), tot_loss_proj:1.285 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1000/2000] tot_loss=1.278 (perp=6.110, rec=0.055, cos=0.001), tot_loss_proj:1.299 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[1050/2000] tot_loss=1.280 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.291 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1100/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.300 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1150/2000] tot_loss=1.282 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.291 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
[1200/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.298 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1250/2000] tot_loss=1.290 (perp=6.110, rec=0.066, cos=0.001), tot_loss_proj:1.298 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1300/2000] tot_loss=1.290 (perp=6.110, rec=0.067, cos=0.001), tot_loss_proj:1.294 [t=0.26s]
prediction: ['[CLS] to infamy [SEP]']
[1350/2000] tot_loss=1.283 (perp=6.110, rec=0.060, cos=0.001), tot_loss_proj:1.299 [t=0.21s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1400/2000] tot_loss=1.279 (perp=6.110, rec=0.056, cos=0.001), tot_loss_proj:1.298 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1450/2000] tot_loss=1.275 (perp=6.110, rec=0.051, cos=0.001), tot_loss_proj:1.303 [t=0.25s]
prediction: ['[CLS] to infamy [SEP]']
[1500/2000] tot_loss=1.296 (perp=6.110, rec=0.073, cos=0.001), tot_loss_proj:1.292 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1550/2000] tot_loss=1.276 (perp=6.110, rec=0.053, cos=0.001), tot_loss_proj:1.305 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1600/2000] tot_loss=1.285 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.289 [t=0.24s]
prediction: ['[CLS] to infamy [SEP]']
[1650/2000] tot_loss=1.277 (perp=6.110, rec=0.054, cos=0.001), tot_loss_proj:1.299 [t=0.18s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1700/2000] tot_loss=1.278 (perp=6.110, rec=0.055, cos=0.001), tot_loss_proj:1.294 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1750/2000] tot_loss=1.283 (perp=6.110, rec=0.059, cos=0.001), tot_loss_proj:1.314 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[1800/2000] tot_loss=1.294 (perp=6.110, rec=0.071, cos=0.001), tot_loss_proj:1.300 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1850/2000] tot_loss=1.282 (perp=6.110, rec=0.058, cos=0.001), tot_loss_proj:1.293 [t=0.20s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[1900/2000] tot_loss=1.284 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.295 [t=0.19s]
prediction: ['[CLS] to infamy [SEP]']
[1950/2000] tot_loss=1.281 (perp=6.110, rec=0.057, cos=0.001), tot_loss_proj:1.302 [t=0.22s]
prediction: ['[CLS] to infamy [SEP]']
Attempt swap
[2000/2000] tot_loss=1.285 (perp=6.110, rec=0.061, cos=0.001), tot_loss_proj:1.306 [t=0.23s]
prediction: ['[CLS] to infamy [SEP]']
Done with input #19 of 100.
reference: 
========================
[CLS] to infamy [SEP]
========================
predicted: 
========================
[CLS] to infamy [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.059 | p: 88.987 | r: 91.310
rouge2     | fm: 59.401 | p: 58.929 | r: 59.863
rougeL     | fm: 82.583 | p: 81.634 | r: 83.701
rougeLsum  | fm: 82.392 | p: 81.365 | r: 83.517
r1fm+r2fm = 149.460

input #19 time: 0:08:44 | total time: 2:51:20


Running input #20 of 100.
reference: 
========================
the perverse pleasure 
========================
average of cosine similarity 0.9992466071766843
highest_index [0]
highest [0.9992466071766843]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1996,  2566, 16070,  5165,   102]], device='cuda:0')
Debug: ref = ['[CLS] the perverse pleasure [SEP]']
[Init] best rec loss: 1.7585136890411377 for ['[CLS] beast sometimes appearance lying [SEP]']
[Init] best rec loss: 1.6632047891616821 for ['[CLS] map your included adventure [SEP]']
[Init] best rec loss: 1.4528199434280396 for ['[CLS] flashed totalrricular women [SEP]']
[Init] best rec loss: 1.4066518545150757 for ['[CLS] trialuce tai sweet [SEP]']
[Init] best rec loss: 1.3769547939300537 for ['[CLS]nst 2018 principles arguing [SEP]']
[Init] best rec loss: 1.322018027305603 for ['[CLS] jensen eden blackwell is [SEP]']
[Init] best rec loss: 1.2753173112869263 for ['[CLS] storylineness [CLS]xi [SEP]']
[Init] best perm rec loss: 1.2749077081680298 for ['[CLS]ness storylinexi [CLS] [SEP]']
[Init] best perm rec loss: 1.2715117931365967 for ['[CLS] storylinexiness [CLS] [SEP]']
[Init] best perm rec loss: 1.2714813947677612 for ['[CLS] storylinenessxi [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.816 (perp=11.210, rec=0.446, cos=0.129), tot_loss_proj:3.412 [t=0.23s]
prediction: ['[CLS] fiction particularly pleasure been [SEP]']
[ 100/2000] tot_loss=2.482 (perp=10.895, rec=0.260, cos=0.043), tot_loss_proj:3.176 [t=0.25s]
prediction: ['[CLS] pleasureverse pleasure the [SEP]']
[ 150/2000] tot_loss=2.602 (perp=12.013, rec=0.178, cos=0.022), tot_loss_proj:3.373 [t=0.20s]
prediction: ['[CLS] respectiveverse pleasure the [SEP]']
[ 200/2000] tot_loss=2.545 (perp=12.013, rec=0.131, cos=0.011), tot_loss_proj:3.369 [t=0.18s]
prediction: ['[CLS] respectiveverse pleasure the [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.185 (perp=9.925, rec=0.169, cos=0.031), tot_loss_proj:3.113 [t=0.24s]
prediction: ['[CLS] the respectiveverse pleasure [SEP]']
[ 300/2000] tot_loss=2.117 (perp=9.925, rec=0.120, cos=0.012), tot_loss_proj:3.097 [t=0.19s]
prediction: ['[CLS] the respectiveverse pleasure [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.106 (perp=9.997, rec=0.096, cos=0.010), tot_loss_proj:2.879 [t=0.22s]
prediction: ['[CLS] the borderverse pleasure [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.959 (perp=8.663, rec=0.193, cos=0.033), tot_loss_proj:2.704 [t=0.27s]
prediction: ['[CLS] the pleasureverse balcony [SEP]']
[ 450/2000] tot_loss=1.936 (perp=9.065, rec=0.112, cos=0.011), tot_loss_proj:2.800 [t=0.19s]
prediction: ['[CLS] the pleasureverseverse [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.977 (perp=9.324, rec=0.103, cos=0.009), tot_loss_proj:2.723 [t=0.23s]
prediction: ['[CLS] the pleasureverse ones [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.961 (perp=9.341, rec=0.088, cos=0.004), tot_loss_proj:2.777 [t=0.20s]
prediction: ['[CLS] the pleasureverse joker [SEP]']
[ 600/2000] tot_loss=1.930 (perp=9.191, rec=0.088, cos=0.003), tot_loss_proj:2.641 [t=0.19s]
prediction: ['[CLS] the pleasureverse per [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.622 (perp=7.610, rec=0.098, cos=0.003), tot_loss_proj:1.793 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.605 (perp=7.610, rec=0.081, cos=0.003), tot_loss_proj:1.788 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 750/2000] tot_loss=1.601 (perp=7.610, rec=0.076, cos=0.002), tot_loss_proj:1.799 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.601 (perp=7.610, rec=0.077, cos=0.002), tot_loss_proj:1.791 [t=0.20s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.588 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.792 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[ 900/2000] tot_loss=1.599 (perp=7.610, rec=0.075, cos=0.002), tot_loss_proj:1.795 [t=0.21s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.584 (perp=7.610, rec=0.061, cos=0.002), tot_loss_proj:1.787 [t=0.20s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1000/2000] tot_loss=1.587 (perp=7.610, rec=0.063, cos=0.002), tot_loss_proj:1.790 [t=0.24s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1050/2000] tot_loss=1.599 (perp=7.610, rec=0.075, cos=0.002), tot_loss_proj:1.779 [t=0.30s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1100/2000] tot_loss=1.589 (perp=7.610, rec=0.065, cos=0.002), tot_loss_proj:1.791 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1150/2000] tot_loss=1.596 (perp=7.610, rec=0.072, cos=0.002), tot_loss_proj:1.781 [t=0.28s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1200/2000] tot_loss=1.606 (perp=7.610, rec=0.082, cos=0.002), tot_loss_proj:1.785 [t=0.31s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1250/2000] tot_loss=1.591 (perp=7.610, rec=0.067, cos=0.002), tot_loss_proj:1.784 [t=0.29s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1300/2000] tot_loss=1.595 (perp=7.610, rec=0.071, cos=0.002), tot_loss_proj:1.779 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1350/2000] tot_loss=1.574 (perp=7.610, rec=0.051, cos=0.002), tot_loss_proj:1.775 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1400/2000] tot_loss=1.595 (perp=7.610, rec=0.071, cos=0.002), tot_loss_proj:1.773 [t=0.26s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1450/2000] tot_loss=1.586 (perp=7.610, rec=0.062, cos=0.002), tot_loss_proj:1.781 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1500/2000] tot_loss=1.584 (perp=7.610, rec=0.061, cos=0.002), tot_loss_proj:1.785 [t=0.38s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1550/2000] tot_loss=1.581 (perp=7.610, rec=0.057, cos=0.002), tot_loss_proj:1.777 [t=0.25s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1600/2000] tot_loss=1.597 (perp=7.610, rec=0.073, cos=0.002), tot_loss_proj:1.782 [t=0.18s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1650/2000] tot_loss=1.591 (perp=7.610, rec=0.068, cos=0.002), tot_loss_proj:1.771 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1700/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.775 [t=0.20s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1750/2000] tot_loss=1.584 (perp=7.610, rec=0.060, cos=0.002), tot_loss_proj:1.777 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1800/2000] tot_loss=1.594 (perp=7.610, rec=0.070, cos=0.002), tot_loss_proj:1.790 [t=0.27s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1850/2000] tot_loss=1.601 (perp=7.610, rec=0.078, cos=0.002), tot_loss_proj:1.786 [t=0.20s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[1900/2000] tot_loss=1.595 (perp=7.610, rec=0.072, cos=0.002), tot_loss_proj:1.773 [t=0.27s]
prediction: ['[CLS] the perverse pleasure [SEP]']
[1950/2000] tot_loss=1.588 (perp=7.610, rec=0.064, cos=0.002), tot_loss_proj:1.785 [t=0.19s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Attempt swap
[2000/2000] tot_loss=1.582 (perp=7.610, rec=0.059, cos=0.002), tot_loss_proj:1.781 [t=0.23s]
prediction: ['[CLS] the perverse pleasure [SEP]']
Done with input #20 of 100.
reference: 
========================
[CLS] the perverse pleasure [SEP]
========================
predicted: 
========================
[CLS] the perverse pleasure [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.537 | p: 89.447 | r: 91.769
rouge2     | fm: 61.344 | p: 61.001 | r: 61.782
rougeL     | fm: 83.393 | p: 82.516 | r: 84.465
rougeLsum  | fm: 83.027 | p: 82.014 | r: 84.253
r1fm+r2fm = 151.880

input #20 time: 0:09:03 | total time: 3:00:23


Running input #21 of 100.
reference: 
========================
the way this all works out makes the women look more like stereotypical caretakers and moral teachers , instead of serious athletes . 
========================
average of cosine similarity 0.999323347023505
highest_index [0]
highest [0.999323347023505]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  1996,  2126,  2023,  2035,  2573,  2041,  3084,  1996,  2308,
          2298,  2062,  2066, 12991, 27086, 17600,  2015,  1998,  7191,  5089,
          1010,  2612,  1997,  3809,  7576,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]']
[Init] best rec loss: 1.8797924518585205 for ["[CLS] pride sufficient stakes favor background pronounced classic uncomfortable devlin binding instead hr inner paolo finished ld focused coincidencewave corporation'making perry manitoba diet [SEP]"]
[Init] best rec loss: 1.6756571531295776 for ['[CLS]rino moons first aslaw registered. according summer testified aid attacked artist power weekend texas total faced scoring drive c las ladies okay political [SEP]']
[Init] best rec loss: 1.6570099592208862 for ['[CLS] club life only involving drive quebec bain than v vary proceeding cave rebellion gabriel freedom intohmi set tour - copies light howeday grin [SEP]']
[Init] best rec loss: 1.6356710195541382 for ['[CLS] deepvao pit sports lines alter holding tight successfully aged logo merlin do rickrier involved place fancy the nay bomber kylie gp re which [SEP]']
[Init] best rec loss: 1.525413990020752 for ['[CLS] rising paperсhl language existence describednt clan yournnek formerly western miss whose withdrawal work rainbow boss true keith throughout statutes along [SEP]']
[Init] best rec loss: 1.5040524005889893 for ['[CLS] is waiter know performs ecolecaster public alta jess hub shower wrote do leaf la hyper delilah objectookure slit telecommunications rein or last [SEP]']
[Init] best rec loss: 1.4968369007110596 for ['[CLS] bonn university on ashe shot wearing rockerlica classification speed non burning glad california againstanding colt timing mouthigo gun machinery score liked seems [SEP]']
[Init] best rec loss: 1.2692524194717407 for ['[CLS] vii bent connecticut pose, golden there itemback baby dee size loan especially labor stonytaking according [UNK] side she fauna general situations rights [SEP]']
[Init] best perm rec loss: 1.2645514011383057 for ['[CLS] rights loan especially connecticut there bent labor, she size general situationsback item vii pose baby stony deetaking [UNK] golden fauna according side [SEP]']
[Init] best perm rec loss: 1.2639286518096924 for ['[CLS] pose bent rights vii labor loanback dee, itemtaking general fauna stony size she connecticut side according especially golden situations [UNK] baby there [SEP]']
[Init] best perm rec loss: 1.2572057247161865 for ['[CLS], situations connecticutback especially pose item benttaking dee golden rights general stony she loan size according [UNK] labor vii fauna there baby side [SEP]']
[Init] best perm rec loss: 1.2564804553985596 for ['[CLS] especiallytaking there she goldenback dee bent pose stony, situations loan size rights item [UNK] labor general baby connecticut vii fauna side according [SEP]']
[Init] best perm rec loss: 1.2533059120178223 for ['[CLS] general situations connecticut golden labor dee according bent especially baby there loan stonyback pose side [UNK] she vii item size rights,taking fauna [SEP]']
[Init] best perm rec loss: 1.2523531913757324 for ['[CLS] there baby loan vii fauna side she connecticut pose stony labor bent situations item according [UNK] especially deetaking golden, sizeback rights general [SEP]']
[Init] best perm rec loss: 1.2521893978118896 for ['[CLS] loan size baby, especially stony situations item bent there according connecticuttaking side fauna poseback dee golden general [UNK] she labor rights vii [SEP]']
[Init] best perm rec loss: 1.2520167827606201 for ['[CLS] rights golden according loan bent [UNK] situations connecticut stony there vii general dee size babyback labor she,taking fauna item especially side pose [SEP]']
[Init] best perm rec loss: 1.2508926391601562 for ['[CLS] fauna she vii [UNK] rightsback bent stony baby there connecticut item situations labor according golden size, side loantaking especially pose general dee [SEP]']
[Init] best perm rec loss: 1.2494364976882935 for ['[CLS] especially loanback vii [UNK] situations baby golden size bent connecticut dee according stony pose general labor rights fauna she item theretaking, side [SEP]']
[Init] best perm rec loss: 1.2471531629562378 for ['[CLS] she especially [UNK] item pose golden vii generalback there sidetaking rights loan, dee baby stony labor size according bent fauna connecticut situations [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.946 (perp=12.932, rec=0.334, cos=0.025), tot_loss_proj:3.502 [t=0.20s]
prediction: ['[CLS] companytypical continued foreign rates old presidential wrong jerseytypical immediately desk sound an - officials religious found kimberley colonel workers ₄ instead instead members [SEP]']
[ 100/2000] tot_loss=2.650 (perp=11.827, rec=0.270, cos=0.015), tot_loss_proj:3.362 [t=0.20s]
prediction: ['[CLS],typical enoughtypical caretaker outtypical wrong points sexual how op look legal women this moral makes outcome colonel teachers, instead instead athletes [SEP]']
[ 150/2000] tot_loss=2.472 (perp=10.947, rec=0.259, cos=0.024), tot_loss_proj:3.188 [t=0.20s]
prediction: ['[CLS] make instead waytypical caretaker outtypical tonight. quite how they look anal women this moral makes work renamed teachers, instead instead athletes [SEP]']
[ 200/2000] tot_loss=2.170 (perp=9.865, rec=0.187, cos=0.010), tot_loss_proj:3.218 [t=0.18s]
prediction: ['[CLS] makes instead waytypical caretaker outtypical working. works way the look the women all moral makes work more teachers, instead instead athletes [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.969 (perp=8.927, rec=0.176, cos=0.008), tot_loss_proj:3.083 [t=0.23s]
prediction: ['[CLS] makes instead look various caretaker workstypical worked. works way the way the women all moral makes work more teachers, instead like athletes [SEP]']
[ 300/2000] tot_loss=2.066 (perp=9.189, rec=0.219, cos=0.009), tot_loss_proj:2.657 [t=0.21s]
prediction: ['[CLS] makes because look various enemy worktypical worked out agenda way the way the women all moral makes. more caretaker, instead as athletes [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=2.153 (perp=9.950, rec=0.158, cos=0.005), tot_loss_proj:3.199 [t=0.19s]
prediction: ['[CLS] makes worktypical because look various enemies works out primary way thequitable the women all moral makes this more caretaker, instead like athletes [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.981 (perp=9.149, rec=0.147, cos=0.005), tot_loss_proj:3.186 [t=0.20s]
prediction: ['[CLS] make worktypical because look situations athletes works out the way thequitable primary women all moral makes this more caretaker, instead like athletes [SEP]']
[ 450/2000] tot_loss=2.021 (perp=9.469, rec=0.123, cos=0.003), tot_loss_proj:3.122 [t=0.20s]
prediction: ['[CLS] makes worktypical because look situations teachers works out the way thequitable symptoms women all moral makes this more caretaker, instead like athletes [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.976 (perp=9.281, rec=0.117, cos=0.003), tot_loss_proj:3.053 [t=0.20s]
prediction: ['[CLS] makes worktypical because works situations teachers look out the way thequitabletypical women all moral makes this more caretaker, instead like athletes [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.943 (perp=9.064, rec=0.125, cos=0.005), tot_loss_proj:2.895 [t=0.26s]
prediction: ['[CLS] teachers make worktypical because works situations look out the way thequitable serious women all moral makes this more caretaker, instead like athletes [SEP]']
[ 600/2000] tot_loss=1.947 (perp=9.161, rec=0.112, cos=0.003), tot_loss_proj:3.071 [t=0.32s]
prediction: ['[CLS] teachers make worktypical because works looking look out the way thequitable serious women all moral makes this more caretaker, instead like athletes [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.806 (perp=8.451, rec=0.113, cos=0.003), tot_loss_proj:2.745 [t=0.23s]
prediction: ['[CLS] teachers make worktypical because works look out the way the out serious looking women all moral makes this more caretaker, instead like athletes [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.859 (perp=8.717, rec=0.113, cos=0.003), tot_loss_proj:2.594 [t=0.20s]
prediction: ['[CLS] teachers make out serioustypical because works look out the way the stereo looking women all moral makes this more caretaker, instead like athletes [SEP]']
[ 750/2000] tot_loss=1.850 (perp=8.717, rec=0.104, cos=0.003), tot_loss_proj:2.601 [t=0.24s]
prediction: ['[CLS] teachers make out serioustypical because works look out the way the stereo looking women all moral makes this more caretaker, instead like athletes [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.775 (perp=8.298, rec=0.112, cos=0.003), tot_loss_proj:2.789 [t=0.20s]
prediction: ['[CLS] teachers of out serious looking because works look out the way the stereotypical women all moral makes this more caretaker, instead like athletes [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.719 (perp=8.079, rec=0.101, cos=0.003), tot_loss_proj:2.682 [t=0.24s]
prediction: ['[CLS] teachers of out serious looking works because look out the way the stereotypical women all moral makes this more caretaker, instead like athletes [SEP]']
[ 900/2000] tot_loss=1.715 (perp=8.079, rec=0.097, cos=0.003), tot_loss_proj:2.681 [t=0.20s]
prediction: ['[CLS] teachers of out serious looking works because look out the way the stereotypical women all moral makes this more caretaker, instead like athletes [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.649 (perp=7.728, rec=0.101, cos=0.003), tot_loss_proj:2.443 [t=0.20s]
prediction: ['[CLS] teachers of more serious looking works because look out the way the stereotypical women all moral makes this out caretaker, instead like athletes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.720 (perp=8.114, rec=0.094, cos=0.003), tot_loss_proj:2.416 [t=0.19s]
prediction: ['[CLS] teachers of more serious looking works tired look out the way the stereotypical women all moral makes this out caretaker, instead like athletes [SEP]']
[1050/2000] tot_loss=1.722 (perp=8.114, rec=0.097, cos=0.003), tot_loss_proj:2.418 [t=0.20s]
prediction: ['[CLS] teachers of more serious looking works tired look out the way the stereotypical women all moral makes this out caretaker, instead like athletes [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.661 (perp=7.829, rec=0.092, cos=0.003), tot_loss_proj:2.434 [t=0.25s]
prediction: ['[CLS] tired of more serious looking works teachers look out the way the stereotypical women all moral makes this out caretaker, instead like athletes [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.573 (perp=7.344, rec=0.101, cos=0.003), tot_loss_proj:2.357 [t=0.19s]
prediction: ['[CLS] tired of more serious looking works teachers look out the way the stereotypical women all out makes this moral caretaker, instead like athletes [SEP]']
[1200/2000] tot_loss=1.564 (perp=7.344, rec=0.093, cos=0.003), tot_loss_proj:2.363 [t=0.20s]
prediction: ['[CLS] tired of more serious looking works teachers look out the way the stereotypical women all out makes this moral caretaker, instead like athletes [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.528 (perp=7.155, rec=0.095, cos=0.003), tot_loss_proj:2.316 [t=0.20s]
prediction: ['[CLS] tired of more serious works teachers look out the way the stereotypical women all looking out makes this moral caretaker, instead like athletes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.532 (perp=7.155, rec=0.098, cos=0.003), tot_loss_proj:2.318 [t=0.25s]
prediction: ['[CLS] tired of more serious works teachers look out the way the stereotypical women all looking out makes this moral caretaker, instead like athletes [SEP]']
[1350/2000] tot_loss=1.534 (perp=7.155, rec=0.100, cos=0.003), tot_loss_proj:2.316 [t=0.22s]
prediction: ['[CLS] tired of more serious works teachers look out the way the stereotypical women all looking out makes this moral caretaker, instead like athletes [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.494 (perp=7.014, rec=0.088, cos=0.003), tot_loss_proj:2.262 [t=0.20s]
prediction: ['[CLS] tired of more serious works teachers look out the way the stereotypical women looking out makes all this moral caretaker, instead like athletes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.503 (perp=7.014, rec=0.098, cos=0.003), tot_loss_proj:2.255 [t=0.27s]
prediction: ['[CLS] tired of more serious works teachers look out the way the stereotypical women looking out makes all this moral caretaker, instead like athletes [SEP]']
[1500/2000] tot_loss=1.492 (perp=7.014, rec=0.086, cos=0.003), tot_loss_proj:2.251 [t=0.19s]
prediction: ['[CLS] tired of more serious works teachers look out the way the stereotypical women looking out makes all this moral caretaker, instead like athletes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.496 (perp=7.014, rec=0.091, cos=0.003), tot_loss_proj:2.254 [t=0.20s]
prediction: ['[CLS] tired of more serious works teachers look out the way the stereotypical women looking out makes all this moral caretaker, instead like athletes [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.483 (perp=6.934, rec=0.094, cos=0.003), tot_loss_proj:2.247 [t=0.19s]
prediction: ['[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]']
[1650/2000] tot_loss=1.480 (perp=6.934, rec=0.090, cos=0.003), tot_loss_proj:2.246 [t=0.19s]
prediction: ['[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.475 (perp=6.934, rec=0.086, cos=0.003), tot_loss_proj:2.244 [t=0.27s]
prediction: ['[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.477 (perp=6.934, rec=0.088, cos=0.003), tot_loss_proj:2.246 [t=0.27s]
prediction: ['[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]']
[1800/2000] tot_loss=1.481 (perp=6.934, rec=0.092, cos=0.002), tot_loss_proj:2.250 [t=0.19s]
prediction: ['[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.470 (perp=6.934, rec=0.081, cos=0.002), tot_loss_proj:2.250 [t=0.20s]
prediction: ['[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.478 (perp=6.934, rec=0.089, cos=0.002), tot_loss_proj:2.243 [t=0.19s]
prediction: ['[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]']
[1950/2000] tot_loss=1.482 (perp=6.934, rec=0.093, cos=0.002), tot_loss_proj:2.243 [t=0.20s]
prediction: ['[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.485 (perp=6.934, rec=0.096, cos=0.002), tot_loss_proj:2.244 [t=0.19s]
prediction: ['[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]']
Done with input #21 of 100.
reference: 
========================
[CLS] the way this all works out makes the women look more like stereotypical caretakers and moral teachers, instead of serious athletes. [SEP]
========================
predicted: 
========================
[CLS] tired of more serious works teachers looking out the way the stereotypical women look out makes all this moral caretaker, instead like athletes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 84.000 | r: 91.304
rouge2     | fm: 17.391 | p: 16.667 | r: 18.182
rougeL     | fm: 41.667 | p: 40.000 | r: 43.478
rougeLsum  | fm: 41.667 | p: 40.000 | r: 43.478
r1fm+r2fm = 104.891

[Aggregate metrics]:
rouge1     | fm: 90.479 | p: 89.369 | r: 91.769
rouge2     | fm: 59.667 | p: 59.269 | r: 60.074
rougeL     | fm: 81.425 | p: 80.451 | r: 82.581
rougeLsum  | fm: 81.136 | p: 80.188 | r: 82.390
r1fm+r2fm = 150.146

input #21 time: 0:09:01 | total time: 3:09:25


Running input #22 of 100.
reference: 
========================
a successful adaptation and an enjoyable film in its own right 
========================
average of cosine similarity 0.9993366894184397
highest_index [0]
highest [0.9993366894184397]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  3144,  6789,  1998,  2019, 22249,  2143,  1999,  2049,
          2219,  2157,   102]], device='cuda:0')
Debug: ref = ['[CLS] a successful adaptation and an enjoyable film in its own right [SEP]']
[Init] best rec loss: 1.9521197080612183 for ['[CLS] followingaway leoong cyrusso class inside dane gothic major [SEP]']
[Init] best rec loss: 1.8905121088027954 for ['[CLS] shakespeare operation emerald hip year art mcdowell model apart league rate [SEP]']
[Init] best rec loss: 1.8834716081619263 for ['[CLS] pseudonym court flynn fed soxnight golden remains lloyd colon op [SEP]']
[Init] best rec loss: 1.881540298461914 for ['[CLS]berries thirds rounds exit whole reaction flux packages advertising dish habit [SEP]']
[Init] best rec loss: 1.849566102027893 for ['[CLS] mines ) organ yes deck sessions mainly steady introduction arson dates [SEP]']
[Init] best rec loss: 1.8134469985961914 for ['[CLS] av waitingalis reception pillar anna deal mentionedhl etc showers [SEP]']
[Init] best rec loss: 1.7512906789779663 for ['[CLS] cloud road hey wynn under diiny stalk seduce variousour [SEP]']
[Init] best rec loss: 1.7188242673873901 for ['[CLS] dialectotte [MASK] type became designing aired replacing piece dear travel [SEP]']
[Init] best rec loss: 1.711775779724121 for ['[CLS] immortal dos standing commentarytort placehim corporal full cruisers carrier [SEP]']
[Init] best rec loss: 1.6849783658981323 for ['[CLS] sans services downstairsgar arched take network before simply dean jurgen [SEP]']
[Init] best rec loss: 1.6268218755722046 for ['[CLS] kids function phoenix chinese set boarders over her schedule laughter [SEP]']
[Init] best perm rec loss: 1.6199898719787598 for ['[CLS] her function board kids phoenix laughter set over chineseers schedule [SEP]']
[Init] best perm rec loss: 1.6110483407974243 for ['[CLS] phoenix her laughter over function schedule chinese boarders kids set [SEP]']
[Init] best perm rec loss: 1.610538125038147 for ['[CLS] function over schedule phoenix herers chinese kids laughter board set [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.234 (perp=9.946, rec=0.242, cos=0.004), tot_loss_proj:2.648 [t=0.18s]
prediction: ['[CLS] successful success adaptation film adaptation william considered producer john adaptation successful [SEP]']
[ 100/2000] tot_loss=2.279 (perp=10.570, rec=0.163, cos=0.002), tot_loss_proj:2.569 [t=0.19s]
prediction: ['[CLS] successful successful adaptation film a horatio played film an adaptation enjoyable [SEP]']
[ 150/2000] tot_loss=1.818 (perp=8.454, rec=0.125, cos=0.002), tot_loss_proj:2.156 [t=0.19s]
prediction: ['[CLS] a successful adaptation film an own right film an adaptation enjoyable [SEP]']
[ 200/2000] tot_loss=1.834 (perp=8.608, rec=0.111, cos=0.002), tot_loss_proj:2.238 [t=0.19s]
prediction: ['[CLS] a successful adaptation film and own right film its right enjoyable [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.637 (perp=7.676, rec=0.100, cos=0.001), tot_loss_proj:2.016 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and own right film its right enjoyable [SEP]']
[ 300/2000] tot_loss=1.621 (perp=7.676, rec=0.084, cos=0.001), tot_loss_proj:2.017 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and own right film its right enjoyable [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.673 (perp=7.934, rec=0.084, cos=0.001), tot_loss_proj:1.975 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and own right its a right enjoyable [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.461 (perp=6.847, rec=0.091, cos=0.001), tot_loss_proj:1.670 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and a right its own right enjoyable [SEP]']
[ 450/2000] tot_loss=1.505 (perp=7.132, rec=0.077, cos=0.001), tot_loss_proj:1.693 [t=0.22s]
prediction: ['[CLS] a successful film adaptation and an own its own right enjoyable [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.449 (perp=6.850, rec=0.077, cos=0.001), tot_loss_proj:1.636 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and an enjoyable its own right own [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.408 (perp=6.670, rec=0.073, cos=0.001), tot_loss_proj:1.589 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable its own own right [SEP]']
[ 600/2000] tot_loss=1.040 (perp=4.888, rec=0.061, cos=0.001), tot_loss_proj:1.142 [t=0.28s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.047 (perp=4.888, rec=0.068, cos=0.001), tot_loss_proj:1.138 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.044 (perp=4.888, rec=0.065, cos=0.001), tot_loss_proj:1.136 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
[ 750/2000] tot_loss=1.038 (perp=4.888, rec=0.059, cos=0.001), tot_loss_proj:1.149 [t=0.18s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.046 (perp=4.888, rec=0.067, cos=0.001), tot_loss_proj:1.139 [t=0.22s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.051 (perp=4.888, rec=0.072, cos=0.001), tot_loss_proj:1.147 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
[ 900/2000] tot_loss=1.049 (perp=4.888, rec=0.070, cos=0.001), tot_loss_proj:1.143 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.043 (perp=4.888, rec=0.064, cos=0.001), tot_loss_proj:1.147 [t=0.25s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1000/2000] tot_loss=1.048 (perp=4.888, rec=0.069, cos=0.001), tot_loss_proj:1.142 [t=0.30s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
[1050/2000] tot_loss=1.042 (perp=4.888, rec=0.063, cos=0.001), tot_loss_proj:1.142 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1100/2000] tot_loss=1.039 (perp=4.888, rec=0.060, cos=0.001), tot_loss_proj:1.149 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1150/2000] tot_loss=1.040 (perp=4.888, rec=0.062, cos=0.001), tot_loss_proj:1.144 [t=0.28s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
[1200/2000] tot_loss=1.041 (perp=4.888, rec=0.062, cos=0.001), tot_loss_proj:1.134 [t=0.26s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1250/2000] tot_loss=1.036 (perp=4.888, rec=0.057, cos=0.001), tot_loss_proj:1.136 [t=0.22s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1300/2000] tot_loss=1.046 (perp=4.888, rec=0.067, cos=0.001), tot_loss_proj:1.138 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
[1350/2000] tot_loss=1.029 (perp=4.888, rec=0.050, cos=0.001), tot_loss_proj:1.136 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1400/2000] tot_loss=1.047 (perp=4.888, rec=0.068, cos=0.001), tot_loss_proj:1.140 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1450/2000] tot_loss=1.041 (perp=4.888, rec=0.062, cos=0.001), tot_loss_proj:1.139 [t=0.28s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
[1500/2000] tot_loss=1.038 (perp=4.888, rec=0.059, cos=0.001), tot_loss_proj:1.138 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1550/2000] tot_loss=1.045 (perp=4.888, rec=0.066, cos=0.001), tot_loss_proj:1.148 [t=0.22s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1600/2000] tot_loss=1.035 (perp=4.888, rec=0.056, cos=0.001), tot_loss_proj:1.140 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
[1650/2000] tot_loss=1.034 (perp=4.888, rec=0.055, cos=0.001), tot_loss_proj:1.137 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1700/2000] tot_loss=1.047 (perp=4.888, rec=0.068, cos=0.001), tot_loss_proj:1.139 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1750/2000] tot_loss=1.031 (perp=4.888, rec=0.052, cos=0.001), tot_loss_proj:1.140 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
[1800/2000] tot_loss=1.039 (perp=4.888, rec=0.060, cos=0.001), tot_loss_proj:1.139 [t=0.20s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1850/2000] tot_loss=1.040 (perp=4.888, rec=0.061, cos=0.001), tot_loss_proj:1.136 [t=0.19s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[1900/2000] tot_loss=1.044 (perp=4.888, rec=0.065, cos=0.001), tot_loss_proj:1.143 [t=0.18s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
[1950/2000] tot_loss=1.038 (perp=4.888, rec=0.059, cos=0.001), tot_loss_proj:1.145 [t=0.21s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Attempt swap
[2000/2000] tot_loss=1.037 (perp=4.888, rec=0.058, cos=0.001), tot_loss_proj:1.144 [t=0.23s]
prediction: ['[CLS] a successful film adaptation and an enjoyable in its own right [SEP]']
Done with input #22 of 100.
reference: 
========================
[CLS] a successful adaptation and an enjoyable film in its own right [SEP]
========================
predicted: 
========================
[CLS] a successful film adaptation and an enjoyable in its own right [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 75.000 | p: 75.000 | r: 75.000
rougeL     | fm: 92.308 | p: 92.308 | r: 92.308
rougeLsum  | fm: 92.308 | p: 92.308 | r: 92.308
r1fm+r2fm = 175.000

[Aggregate metrics]:
rouge1     | fm: 90.830 | p: 89.770 | r: 92.174
rouge2     | fm: 60.132 | p: 59.790 | r: 60.564
rougeL     | fm: 81.844 | p: 80.984 | r: 83.014
rougeLsum  | fm: 81.807 | p: 80.933 | r: 82.922
r1fm+r2fm = 150.962

input #22 time: 0:08:43 | total time: 3:18:08


Running input #23 of 100.
reference: 
========================
while some will object to the idea of a vietnam picture with such a rah-rah , patriotic tone , soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation . 
========================
average of cosine similarity 0.999235259621351
highest_index [0]
highest [0.999235259621351]
Debug: ids_shape = 50, pads = [50]
Debug: input ids = tensor([[  101,  2096,  2070,  2097,  4874,  2000,  1996,  2801,  1997,  1037,
          5148,  3861,  2007,  2107,  1037, 10958,  2232,  1011, 10958,  2232,
          1010, 14314,  4309,  1010,  3548,  4821,  6162,  2015,  2049,  2364,
          6143,  7863,  1024,  3689,  3775,  6774,  1996,  2529,  3465,  1997,
          1996,  4736,  2008,  2234,  2000,  9375,  1037,  4245,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]']
[Init] best rec loss: 1.383732795715332 for ['[CLS] rank brazil郎 glasscutiologymark term hire reach soup pursuit respond township lagos notmute cum dusk once sex role have located down divers johnnieᴵ wanted goodness scent pattern met 6 baltic nes travel free stale westward julian towns mono katy incarnation jenks owens kind [SEP]']
[Init] best rec loss: 1.3736612796783447 for ['[CLS] jumped its ion [MASK] deep spirit tracks controls spun donated tape calendar ineligible martial airport breaths complexvas net straight vs # jake featurebal each roots record death share troubles chance scores mate frank holding quest exactlyul governments win far ap gathering toysience married club [SEP]']
[Init] best rec loss: 1.3212342262268066 for ['[CLS] stephens type specialty agedre vu disney resourcexide raeiansia are roadbbly feeling daphne amazon detail demon ii smartershi remembertained mad injunction israel personal network elbow conceptbbled president where rep example researchapple mr rangers resisted revival accessible self na express legion [SEP]']
[Init] best rec loss: 1.3039929866790771 for ['[CLS]cation oystermel though painfies aftermath faction micro ec decommissioned hole federation educated wi looking ban office mean creation positional vi morning envy fair ken goodwill sons no give aren para shops calendar concert beingsian you pl denmark love platform battle flags astronomy rome asking [SEP]']
[Init] best rec loss: 1.2455841302871704 for ['[CLS] talent cause skirt handled ⁴ anne pieces mine! caused safety tor goal fore 2014 residents chosen offering chiefs number sun consumergementni property riding dolphin exchequerada saw occupants trades vale course kind coronation ballroom dona village totally selena winds firstd sums manga square scholar [SEP]']
[Init] best rec loss: 1.2352474927902222 for ['[CLS] drugfl vienna chop ; wound shop wonder main added founded lennox bridge gel residential rich kilometers facing countries seal adults captain wet interstate tea saved mr hawk withdrawal indeed temperaly sent daily life ₱ rail era seasons bottom champion herselfsta? context teen ready airfield [SEP]']
[Init] best perm rec loss: 1.2314822673797607 for ['[CLS] indeed champion kilometers withdrawal gel seal tea drug wonder ; founded vienna era herself ₱ added residential daily bridge sent adults airfield captain mr ready contextsta bottom seasons shop rail wet life hawkaly countries teen facing richfl lennox saved main? interstate wound temper chop [SEP]']
[Init] best perm rec loss: 1.2305387258529663 for ['[CLS] sent shop wound airfield captain wetfl vienna countries mr ready main rail seasons daily drug facing seal teen saved ; bridge adults temper added context withdrawal champion wondersta rich era kilometers bottom hawk tea residential? foundedaly indeed ₱ interstate life chop gel lennox herself [SEP]']
[Init] best perm rec loss: 1.2290924787521362 for ['[CLS] indeed ₱ facing seasonsfl rich bridge main mr gel wonder vienna founded ready champion chop hawk wet context kilometers captain life teen sent bottom saved woundaly rail era lennox withdrawal tea drug interstate temper seal residential added shop airfield daily herself countries ;sta adults? [SEP]']
[Init] best perm rec loss: 1.2287770509719849 for ['[CLS] airfield rail added hawk context indeed countries withdrawal shop rich vienna seal captain champion mr sent life temper daily gel teen tea bridge ₱ residential adults saved drugsta bottom founded lennox ready facing ; interstate woundfl kilometers wet main wonder chop seasonsaly era herself? [SEP]']
[Init] best perm rec loss: 1.2277514934539795 for ['[CLS] residential lennoxfl rich hawk captain ₱aly tea daily main drug sent viennasta facing? ; gel wound context countries temper teen shop champion seal seasons wet herself airfield adults founded saved life ready wonder mr interstate bottom era indeed chop added kilometers withdrawal bridge rail [SEP]']
[Init] best perm rec loss: 1.2267485857009888 for ['[CLS] seal ready mr captainfl rich shop drug main rail residential era gel temper saved? countries kilometers tea bottom interstate added context life bridge lennox vienna champion herself daily facing chop withdrawal adults teen indeed ₱ ; airfield woundsta seasons hawk wonder wet founded sentaly [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.712 (perp=11.572, rec=0.348, cos=0.049), tot_loss_proj:3.647 [t=0.20s]
prediction: ['[CLS] although la pm facilities victory! not towardspoint the ) pontifical not so military factionshi combat helping people. evolution nuclear mysterious case into award renamed gun tactic is goals manifesto investigation lethal devastating question public trait was grew patrol [CLS] its lieutenant targeturgent long [SEP]']
[ 100/2000] tot_loss=2.634 (perp=11.580, rec=0.277, cos=0.041), tot_loss_proj:3.645 [t=0.27s]
prediction: ['[CLS] soldiers p prix serious ion. losing gr kettle [SEP] gesture eventually mother - selfnx combat question forces. [SEP] scenario soldier aircraft its objective s struggle tactic has objective manifesto emphasized cervical objective artistphonic main " environmental gain its its strategic target volunteer long [SEP]']
[ 150/2000] tot_loss=2.416 (perp=10.984, rec=0.204, cos=0.015), tot_loss_proj:3.357 [t=0.25s]
prediction: ['[CLS] soldiers for troops serious woody / losing gr p while ) eventually mother a -nf strategiczing forces. fame the vietnam soldiers its strategic s struggle idea has objective philosophical orchestra cervical objective artist dramatic main. couldn ensure its its korean target vanilla, [SEP]']
[ 200/2000] tot_loss=2.392 (perp=10.999, rec=0.182, cos=0.011), tot_loss_proj:3.207 [t=0.20s]
prediction: ["[CLS] soldiers for enemies serious when with an'p while ) achieve da the anz strategiczing attacks. fame techno vietnam soldiers its strategic s patriotic idea has objective strategic § cervical objective artist dramatic main. outcome : its its korean target immigrant the [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.892 (perp=11.243, rec=0.456, cos=0.188), tot_loss_proj:3.400 [t=0.19s]
prediction: ['[CLS] soldiers puanies serious $. initially\'interest while sounding achieved dee the [CLS] / + strategicing the, development campus int patriotic tenants strategic as stop concept criteria objective [SEP] \'. electoral " patriotic main : adventure : its its 扌 ;f the [SEP]']
[ 300/2000] tot_loss=2.600 (perp=11.479, rec=0.268, cos=0.036), tot_loss_proj:3.825 [t=0.20s]
prediction: ['[CLS] soldiers rural suicide ; $. initially\'opium while and achievedy the would "fia strategiczingfold, heritage mission int patriotic its strategic the flat concept most objective [SEP]\'; moth [ format main is applications : its its%morphicoll the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.572 (perp=11.683, rec=0.214, cos=0.022), tot_loss_proj:3.899 [t=0.20s]
prediction: ["[CLS] soldiers rights suicide sequence $ the resulting'` while looking achievedm. would andfia strategiczingtrics, generation programs int patriotic its strategic the flat concept most objective [SEP]'; united [ format main is applications : its its% trinitybled the [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.398 (perp=10.960, rec=0.190, cos=0.016), tot_loss_proj:3.738 [t=0.20s]
prediction: ["[CLS] soldiers asia suicide ( $ the placed'fight while looking achievem. would andfia strategiczing the, generation national int patriotic its strategic the flat [ most objective [SEP]'; united concept format main the applications : its its%icateographer the [SEP]"]
[ 450/2000] tot_loss=2.422 (perp=11.052, rec=0.194, cos=0.018), tot_loss_proj:3.490 [t=0.20s]
prediction: ["[CLS] soldiers asia suicide approach $ the when'thou while vietnamese achievem. would and canadian ultimatelyzing the, generation national int patriotic its strategic the flat [ most objective [SEP]'; united concept woman main and drama : its its%tracted eisenhower the [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.359 (perp=10.840, rec=0.177, cos=0.013), tot_loss_proj:3.550 [t=0.20s]
prediction: ["[CLS] soldiers asia suicide approach $ the dynamic'thou while vietnam achieveh. would to canadian ultimatelyzing the, the national int patriotic its strategic the flat [ most objective [SEP]'; army concept format main and drama : its a%tractedrked generation [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.270 (perp=10.462, rec=0.167, cos=0.011), tot_loss_proj:3.438 [t=0.19s]
prediction: ["[CLS] soldiers asia suicide approach $ the drama'thou while vietnam achieveh. [ to canadian ultimatelyzing the, the national int patriotic its strategic the flat would most objective [SEP]'; army concept woman main and drama : its a%tractedrked generation [SEP]"]
[ 600/2000] tot_loss=2.252 (perp=10.433, rec=0.156, cos=0.009), tot_loss_proj:3.444 [t=0.25s]
prediction: ["[CLS] soldiers asia suicide approach $ the drama 'rocity while vietnam achieveh. [ to canadian ultimatelyzing the, the national int patriotic its strategic the flat would most objective [SEP]'; army concept woman main and drama : its a%tractedrked generation [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.178 (perp=10.120, rec=0.147, cos=0.007), tot_loss_proj:3.380 [t=0.20s]
prediction: ["[CLS] soldiers'suicide, $ the drama asia vietnam while patriotic achieveh. [ to canadian ultimatelyzing the, the national int patriotic its strategic the flat would most objective [SEP]'; legion concept woman main that drama : its a%tracted eisenhower generation [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.221 (perp=10.330, rec=0.148, cos=0.007), tot_loss_proj:3.444 [t=0.29s]
prediction: ["[CLS] soldiers'suicide,% the drama asia vietnam while patriotic achieveh. [ to canadian ultimatelyzing the, the national int patriotic its strategic the flat would most objective [SEP]ti ; patriotic concept woman main that drama : its a $tractedrked generation [SEP]"]
[ 750/2000] tot_loss=2.221 (perp=10.330, rec=0.147, cos=0.008), tot_loss_proj:3.445 [t=0.27s]
prediction: ["[CLS] soldiers'suicide,% the drama asia vietnam while patriotic achieveh. [ to canadian ultimatelyzing the, the national int patriotic its strategic the flat would most objective [SEP]ti ; patriotic concept woman main that drama : its a $tractedrked generation [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.140 (perp=9.964, rec=0.139, cos=0.008), tot_loss_proj:3.292 [t=0.24s]
prediction: ["[CLS] soldiers'suicide,% the drama asia vietnam while patriotic achieve -. [ to canadian ultimatelyzing the, the national int patriotic its strategic the flat concept most objective [SEP]ti ; patriotic would woman main that drama : its a $ liza eisenhower generation [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.118 (perp=9.853, rec=0.141, cos=0.006), tot_loss_proj:3.451 [t=0.20s]
prediction: ["[CLS] soldiers'suicide,% the drama asia vietnam while patriotic achieve -. [ to canadian ultimatelyzing the, the national int patriotic its strategic flat the concept most objective [SEP]ti ; patriotic would picture main that drama : its a $ liza eisenhower generation [SEP]"]
[ 900/2000] tot_loss=2.165 (perp=10.110, rec=0.137, cos=0.006), tot_loss_proj:3.151 [t=0.20s]
prediction: ["[CLS] soldiers'suicide,% the drama asia vietnam while patriotic achieve -. [ could canadian ultimatelyzing the, the national int patriotic its strategic dedicated the concept most objective [SEP]ti ; patriotic would picture main that drama : its a $ liza eisenhower generation [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.123 (perp=9.910, rec=0.135, cos=0.007), tot_loss_proj:3.095 [t=0.20s]
prediction: ["[CLS] soldiers'suicide,% the drama asia vietnam while patriotic achieve -. [ would concept ultimatelyzing the, the national int patriotic its strategic dedicated the canadian most objective [SEP]ti ; patriotic would picture main that drama : its a $☉ eisenhower generation [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.128 (perp=9.944, rec=0.132, cos=0.008), tot_loss_proj:3.126 [t=0.23s]
prediction: ["[CLS] soldiers'suicide,% the drama asia vietnam while patriotic achieve - picture [ would concept ultimatelyzing the, the national int patriotic its strategic dedicated the canadian most objective [SEP]ti ; patriotic ;. main that drama : its a $☉ eisenhower generation [SEP]"]
[1050/2000] tot_loss=2.136 (perp=10.009, rec=0.129, cos=0.006), tot_loss_proj:3.130 [t=0.25s]
prediction: ["[CLS] soldiers'suicide,% the drama asia vietnam while patriotic achieve - picture [ would concept ultimatelyzing the, the national int patriotic its strategic dedicated the - most objective [SEP]ti ; patriotic ;. main that drama : its a $☉ eisenhower generation [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.099 (perp=9.791, rec=0.135, cos=0.006), tot_loss_proj:3.114 [t=0.19s]
prediction: ["[CLS] soldiers'suicide,% the drama industry vietnam while patriotic achieve - picture that would concept ultimatelyzing the, the national int patriotic its strategic dedicated the - most objective [SEP]ti ; patriotic ;. main [ drama : its a $oint eisenhower generation [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.042 (perp=9.537, rec=0.127, cos=0.008), tot_loss_proj:3.031 [t=0.28s]
prediction: ["[CLS] soldiers'suicide,% the drama industry - while patriotic achieve vietnam picture that would concept ultimatelyzing the, the national int patriotic its strategic dedicated the - most objective [SEP]ti ; patriotic ;. main [ drama : its a $oint eisenhower generation [SEP]"]
[1200/2000] tot_loss=2.015 (perp=9.377, rec=0.133, cos=0.006), tot_loss_proj:2.992 [t=0.28s]
prediction: ["[CLS] soldiers'suicide,% the drama industry - while patriotic achieve vietnam picture that would concept ultimatelyzing the, the national int patriotic its strategic dedicated the - most objective [SEP]ti ; patriotic ; and main values drama : its a $oint eisenhower generation [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.978 (perp=9.195, rec=0.134, cos=0.006), tot_loss_proj:3.027 [t=0.24s]
prediction: ["[CLS] soldiers'suicide,% the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national int patriotic its strategic dedicated the - most objective [SEP]ti ; patriotic ; and main values drama : its a $oint eisenhower generation [SEP]"]
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.960 (perp=9.149, rec=0.125, cos=0.005), tot_loss_proj:2.926 [t=0.19s]
prediction: ["[CLS] soldiers'suicide,% the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic patriotic its strategic dedicated the - most objective [SEP]ti... int. and main values drama : its a $oint eisenhower generation [SEP]"]
[1350/2000] tot_loss=1.989 (perp=9.289, rec=0.126, cos=0.005), tot_loss_proj:3.006 [t=0.24s]
prediction: ["[CLS] soldiers'suicide,% the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic patriotic its strategic really the - most objective [SEP]ti... int ; and main values drama : its a $oint eisenhower generation [SEP]"]
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.920 (perp=8.934, rec=0.127, cos=0.006), tot_loss_proj:2.925 [t=0.21s]
prediction: ["[CLS] soldiers'suicide,% the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic values its strategic dedicated the - most objective [SEP]ti... int. and main patriotic drama : its a $oint eisenhower generation [SEP]"]
Attempt swap
Moved token
[1450/2000] tot_loss=1.950 (perp=9.093, rec=0.126, cos=0.005), tot_loss_proj:2.901 [t=0.19s]
prediction: ["[CLS] soldiers'suicide,% the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic forces its strategic really - the most objective [SEP]ti... int. and main patriotic drama : its a $ointographic generation [SEP]"]
[1500/2000] tot_loss=1.922 (perp=8.964, rec=0.125, cos=0.005), tot_loss_proj:2.854 [t=0.25s]
prediction: ["[CLS] soldiers'suicide,% the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic forces its strategic dedicated - the most objective [SEP]ti... int. and main patriotic drama : its a $ointographic generation [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.943 (perp=9.093, rec=0.120, cos=0.005), tot_loss_proj:2.906 [t=0.19s]
prediction: ["[CLS] soldiers'suicide,% the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic forces its strategic really - the most objective [SEP]ti... int. and main patriotic drama : its a $ointographic generation [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.966 (perp=9.201, rec=0.121, cos=0.005), tot_loss_proj:2.867 [t=0.23s]
prediction: ["[CLS] soldiers'suicide, dil the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic forces its strategic really - the most objective [SEP]...ti int. and main patriotic drama : its a $ointographic generation [SEP]"]
[1650/2000] tot_loss=1.966 (perp=9.201, rec=0.121, cos=0.005), tot_loss_proj:2.868 [t=0.25s]
prediction: ["[CLS] soldiers'suicide, dil the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic forces its strategic really - the most objective [SEP]...ti int. and main patriotic drama : its a $ointographic generation [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.964 (perp=9.201, rec=0.119, cos=0.005), tot_loss_proj:2.872 [t=0.23s]
prediction: ["[CLS] soldiers'suicide, dil the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic forces its strategic really - the most objective [SEP]...ti int. and main patriotic drama : its a $ointographic generation [SEP]"]
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.961 (perp=9.086, rec=0.136, cos=0.008), tot_loss_proj:2.794 [t=0.19s]
prediction: ["[CLS] soldiers'suicide - dil the drama industry, while patriotic achieve vietnam picture currently would, ultimatelyzing the concept. national patriotic forces its strategic really - the most objective [SEP]...ti int. and main patriotic drama : its a $ointographic generation [SEP]"]
[1800/2000] tot_loss=1.950 (perp=9.087, rec=0.128, cos=0.004), tot_loss_proj:2.768 [t=0.20s]
prediction: ["[CLS] soldiers'suicide - dil the drama industry, while patriotic achieve vietnam picture conflict would, ultimatelyzing the concept. national patriotic forces its strategic really - the most objective [SEP]...ti int. and main patriotic drama : its a $ointographic generation [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.934 (perp=9.006, rec=0.128, cos=0.005), tot_loss_proj:2.791 [t=0.19s]
prediction: ['[CLS] soldiers for suicide - dil the drama industry, while patriotic achieve vietnam [SEP] that would, ultimatelyzing the concept. national patriotic forces its strategic dedicated - the most objective picture...ti int. and main patriotic drama : its a $ointographic generation [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.923 (perp=8.920, rec=0.134, cos=0.005), tot_loss_proj:2.874 [t=0.24s]
prediction: ['[CLS] soldiers for [SEP] - dil the drama industry, while patriotic achieve vietnam suicide that would, ultimatelyzing the concept. national patriotic forces its strategic dedicated - the most objective picture...ti int. and main patriotic drama : its a $ointographic generation [SEP]']
[1950/2000] tot_loss=1.916 (perp=8.920, rec=0.127, cos=0.005), tot_loss_proj:2.872 [t=0.24s]
prediction: ['[CLS] soldiers for [SEP] - dil the drama industry, while patriotic achieve vietnam suicide that would, ultimatelyzing the concept. national patriotic forces its strategic dedicated - the most objective picture...ti int. and main patriotic drama : its a $ointographic generation [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.906 (perp=8.854, rec=0.130, cos=0.005), tot_loss_proj:2.827 [t=0.21s]
prediction: ['[CLS] soldiers for [SEP] - dil the drama industry, while patriotic achieve vietnam suicide that would, ultimatelyzing the concept. national patriotic forces its strategic drama - the most objective picture...ti int. and main patriotic dedicated : its a $ointographic generation [SEP]']
Done with input #23 of 100.
reference: 
========================
[CLS] while some will object to the idea of a vietnam picture with such a rah - rah, patriotic tone, soldiers ultimately achieves its main strategic objective : dramatizing the human cost of the conflict that came to define a generation. [SEP]
========================
predicted: 
========================
[CLS] soldiers'suicide, dil the drama industry - while patriotic achieve vietnam picture that would, ultimatelyzing the concept the national patriotic forces its strategic really - the most objective [SEP]...ti int. and main patriotic drama : its a $ointographic generation [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 43.038 | p: 43.590 | r: 42.500
rouge2     | fm: 5.195 | p: 5.263 | r: 5.128
rougeL     | fm: 27.848 | p: 28.205 | r: 27.500
rougeLsum  | fm: 27.848 | p: 28.205 | r: 27.500
r1fm+r2fm = 48.233

[Aggregate metrics]:
rouge1     | fm: 88.901 | p: 87.910 | r: 90.091
rouge2     | fm: 57.867 | p: 57.529 | r: 58.240
rougeL     | fm: 79.749 | p: 78.919 | r: 80.626
rougeLsum  | fm: 79.556 | p: 78.490 | r: 80.608
r1fm+r2fm = 146.768

input #23 time: 0:08:50 | total time: 3:26:59


Running input #24 of 100.
reference: 
========================
taken outside the context of the current political climate ( see : terrorists are more evil than ever ! ) 
========================
average of cosine similarity 0.9993537840940762
highest_index [0]
highest [0.9993537840940762]
Debug: ids_shape = 22, pads = [22]
Debug: input ids = tensor([[  101,  2579,  2648,  1996,  6123,  1997,  1996,  2783,  2576,  4785,
          1006,  2156,  1024, 15554,  2024,  2062,  4763,  2084,  2412,   999,
          1007,   102]], device='cuda:0')
Debug: ref = ['[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]']
[Init] best rec loss: 1.825258493423462 for ['[CLS] trail floor cadillac partners african titlesin spelling offer van beaten grid managed diedsf came celtic had henry aggregator [SEP]']
[Init] best rec loss: 1.6625887155532837 for ['[CLS] folder 000 tell hurt cooking raised instead hosts z [CLS]ttered lowell breuning mode cells apartments ryel arliche [SEP]']
[Init] best rec loss: 1.662034034729004 for ['[CLS] % wholewell forgotten upon beginning hellolsoc only favor including trailer naval a difficult cards dragons foreign cars [SEP]']
[Init] best rec loss: 1.638895034790039 for ['[CLS] ladder sebastian separation ball ely associated warn bark basis medieval staff music trulycta ensured rick helicopter adjust resolve dia [SEP]']
[Init] best rec loss: 1.3410228490829468 for ['[CLS] lying afford rubbed media ة soft % _truct postage voices ind defending either morning then armeddder melanie return [SEP]']
[Init] best rec loss: 1.323185920715332 for ['[CLS] post la cited north soldiers jasperditional [SEP] shay singer hate male warrantritetype conditionative type above doorbell [SEP]']
[Init] best rec loss: 1.1163339614868164 for ['[CLS] mid play no bush attack arms youngeraneous snow ryu suffer emwyl unless port county village happy bond damned [SEP]']
[Init] best perm rec loss: 1.1137642860412598 for ['[CLS] bondwyl unless county em arms damned happy suffer play attack younger ryu midaneous bush snow village no port [SEP]']
[Init] best perm rec loss: 1.1134698390960693 for ['[CLS] unless play younger ryu attack village no mid damned portwyl happy suffer arms em snow bush bond countyaneous [SEP]']
[Init] best perm rec loss: 1.1096725463867188 for ['[CLS] attack unless em arms happywyl bond mid younger play snow villageaneous no county damned ryu suffer port bush [SEP]']
[Init] best perm rec loss: 1.1079434156417847 for ['[CLS] mid unless ryu play attack nowyl em younger countyaneous bond village happy damned snow bush port suffer arms [SEP]']
[Init] best perm rec loss: 1.107871174812317 for ['[CLS] suffer happy em younger play ryu no mid bond unless snow bush armsaneous damned attack countywyl village port [SEP]']
[Init] best perm rec loss: 1.1060388088226318 for ['[CLS] bond play damned unless county younger no midwyl em attack ryu village snow armsaneous happy bush suffer port [SEP]']
[Init] best perm rec loss: 1.1028209924697876 for ['[CLS] playwyl county em no mid arms bond bush damned snow unless happy ryu younger attack suffer village portaneous [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.910 (perp=12.753, rec=0.328, cos=0.031), tot_loss_proj:3.650 [t=0.24s]
prediction: ['[CLS] grabs designed [SEP] endemic evil ) context terrorist see grabbed his dangerous his! glory abuse visibly teaching cop disc [SEP]']
[ 100/2000] tot_loss=2.624 (perp=11.171, rec=0.335, cos=0.055), tot_loss_proj:3.329 [t=0.19s]
prediction: ['[CLS] aaron taken outside context evil outside context evil see grabbed the evil until! terrorists evil more enzyme ) disc [SEP]']
[ 150/2000] tot_loss=2.238 (perp=10.157, rec=0.196, cos=0.010), tot_loss_proj:3.049 [t=0.19s]
prediction: ['[CLS] shouted taken outside current evil outside context terrorist ( taking the evil political! terrorists evil more stadium )! [SEP]']
[ 200/2000] tot_loss=2.052 (perp=9.437, rec=0.159, cos=0.005), tot_loss_proj:2.866 [t=0.19s]
prediction: ['[CLS] see taken outside current evil climate context terrorists ( taking the terrorists political! terrorists evil more political )! [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.692 (perp=11.438, rec=0.347, cos=0.058), tot_loss_proj:3.505 [t=0.23s]
prediction: ['[CLS] see taken outside current evil climate context terrorists ( laylasu terrorists! touchdown components evil : corp ) henri [SEP]']
[ 300/2000] tot_loss=2.327 (perp=10.384, rec=0.236, cos=0.014), tot_loss_proj:3.160 [t=0.18s]
prediction: ['[CLS] see taken outside current evil community context terrorists ( usually theł! swiss parts evil : co ) ste [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.276 (perp=10.339, rec=0.200, cos=0.008), tot_loss_proj:3.097 [t=0.19s]
prediction: ['[CLS] see taken outside current evil community context terrorists ( climate theł! swiss parts evil : henri ) ) [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.174 (perp=9.968, rec=0.173, cos=0.008), tot_loss_proj:2.986 [t=0.19s]
prediction: ['[CLS] see taken outside current evil climate context terrorists ( climate theł! country parts : evil henri ) ) [SEP]']
[ 450/2000] tot_loss=2.157 (perp=9.922, rec=0.167, cos=0.005), tot_loss_proj:2.988 [t=0.25s]
prediction: ['[CLS] see taken outside current terrorists climate context terrorists ( climate theł! country parts : evil soon ) ) [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.081 (perp=9.583, rec=0.159, cos=0.006), tot_loss_proj:2.929 [t=0.20s]
prediction: ['[CLS] see taken outside current terrorists climate terrorists context ( climate theł! country parts : evil soon ) ) [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.061 (perp=9.465, rec=0.162, cos=0.005), tot_loss_proj:2.884 [t=0.21s]
prediction: ['[CLS] see taken outside current terrorists climate terrorists context ( climate country theł! parts more evil soon ) ) [SEP]']
[ 600/2000] tot_loss=2.043 (perp=9.465, rec=0.146, cos=0.004), tot_loss_proj:2.885 [t=0.24s]
prediction: ['[CLS] see taken outside current terrorists climate terrorists context ( climate country theł! parts more evil soon ) ) [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.950 (perp=9.003, rec=0.146, cos=0.004), tot_loss_proj:2.676 [t=0.19s]
prediction: ['[CLS] parts taken outside current terrorists climate terrorists context ( climate country thees! see more evil soon ) ) [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.882 (perp=8.624, rec=0.153, cos=0.004), tot_loss_proj:2.655 [t=0.20s]
prediction: ['[CLS] parts taken outside current terrorists climate terrorists context ( climate country thees ) see more evil soon! ) [SEP]']
[ 750/2000] tot_loss=1.868 (perp=8.624, rec=0.139, cos=0.004), tot_loss_proj:2.661 [t=0.24s]
prediction: ['[CLS] parts taken outside current terrorists climate terrorists context ( climate country thees ) see more evil soon! ) [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.805 (perp=8.287, rec=0.143, cos=0.004), tot_loss_proj:2.410 [t=0.19s]
prediction: ['[CLS] parts taken outside current terrorists the terrorists context ( climate country climatees ) see more evil than! ) [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.848 (perp=8.500, rec=0.144, cos=0.004), tot_loss_proj:2.555 [t=0.19s]
prediction: ['[CLS] parts taken outside current terrorists the terrorists context ( climate country climatees ) see more evil ever! ) [SEP]']
[ 900/2000] tot_loss=1.835 (perp=8.500, rec=0.131, cos=0.004), tot_loss_proj:2.551 [t=0.23s]
prediction: ['[CLS] parts taken outside current terrorists the terrorists context ( climate country climatees ) see more evil ever! ) [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.803 (perp=8.316, rec=0.137, cos=0.004), tot_loss_proj:2.532 [t=0.27s]
prediction: ['[CLS] parts taken outside current terrorists the political context climate ( country climatees ) see more evil ever! ) [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.748 (perp=8.014, rec=0.141, cos=0.004), tot_loss_proj:2.388 [t=0.19s]
prediction: ['[CLS] parts taken outside the current terrorists political context climate ( country climatees ) see more evil ever! ) [SEP]']
[1050/2000] tot_loss=1.832 (perp=8.463, rec=0.136, cos=0.003), tot_loss_proj:2.410 [t=0.24s]
prediction: ['[CLS] chop taken outside the current terrorists political context climate ( country climatees ) see more evil ever! ) [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.829 (perp=8.473, rec=0.131, cos=0.003), tot_loss_proj:2.415 [t=0.19s]
prediction: ['[CLS] chop taken outside the current context terrorists political climate ( country climate gs ) see more evil ever! ) [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.847 (perp=8.589, rec=0.126, cos=0.003), tot_loss_proj:2.446 [t=0.19s]
prediction: ['[CLS] chop taken outside the current context terrorists political climate climate than (es ) see more evil ever! ) [SEP]']
[1200/2000] tot_loss=1.855 (perp=8.589, rec=0.134, cos=0.003), tot_loss_proj:2.449 [t=0.27s]
prediction: ['[CLS] chop taken outside the current context terrorists political climate climate than (es ) see more evil ever! ) [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.838 (perp=8.512, rec=0.132, cos=0.003), tot_loss_proj:2.441 [t=0.19s]
prediction: ['[CLS] chop taken outside the current context terrorists political climate climate ( thanyna ) see more evil ever! ) [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.789 (perp=8.311, rec=0.123, cos=0.003), tot_loss_proj:2.385 [t=0.21s]
prediction: ['[CLS] chop taken outside the current context terrorists political climate ( climate thanyna ) see more evil ever! ) [SEP]']
[1350/2000] tot_loss=1.792 (perp=8.311, rec=0.127, cos=0.003), tot_loss_proj:2.381 [t=0.23s]
prediction: ['[CLS] chop taken outside the current context terrorists political climate ( climate thanyna ) see more evil ever! ) [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=1.643 (perp=7.532, rec=0.133, cos=0.003), tot_loss_proj:2.241 [t=0.23s]
prediction: ['[CLS] chop taken outside the current context terrorists political climate ( climate nam ) see more evil than ever! ) [SEP]']
Attempt swap
[1450/2000] tot_loss=1.632 (perp=7.532, rec=0.123, cos=0.003), tot_loss_proj:2.247 [t=0.25s]
prediction: ['[CLS] chop taken outside the current context terrorists political climate ( climate nam ) see more evil than ever! ) [SEP]']
[1500/2000] tot_loss=1.768 (perp=8.225, rec=0.120, cos=0.003), tot_loss_proj:2.337 [t=0.19s]
prediction: ['[CLS] chop taken outside the current context terrorists political climate ( climate nam ) see more evil than than! ) [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.724 (perp=7.915, rec=0.136, cos=0.005), tot_loss_proj:2.319 [t=0.19s]
prediction: ['[CLS] chop taken outside the current context ever political climate ( climate nam ) see more evil than terrorists! ) [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.665 (perp=7.630, rec=0.135, cos=0.004), tot_loss_proj:2.242 [t=0.28s]
prediction: ['[CLS] chop taken outside the ever context current political climate ( climate nam ) see more evil than terrorists! ) [SEP]']
[1650/2000] tot_loss=1.671 (perp=7.677, rec=0.132, cos=0.003), tot_loss_proj:2.226 [t=0.19s]
prediction: ['[CLS] chop taken outside the ever context current political climate ( climateyna ) see more evil than terrorists! ) [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.649 (perp=7.549, rec=0.136, cos=0.003), tot_loss_proj:2.207 [t=0.30s]
prediction: ['[CLS] chop taken outside the ever context ( current political climate climateyna ) see more evil than terrorists! ) [SEP]']
Attempt swap
[1750/2000] tot_loss=1.636 (perp=7.549, rec=0.123, cos=0.003), tot_loss_proj:2.210 [t=0.19s]
prediction: ['[CLS] chop taken outside the ever context ( current political climate climateyna ) see more evil than terrorists! ) [SEP]']
[1800/2000] tot_loss=1.641 (perp=7.549, rec=0.128, cos=0.003), tot_loss_proj:2.213 [t=0.21s]
prediction: ['[CLS] chop taken outside the ever context ( current political climate climateyna ) see more evil than terrorists! ) [SEP]']
Attempt swap
[1850/2000] tot_loss=1.640 (perp=7.549, rec=0.127, cos=0.003), tot_loss_proj:2.214 [t=0.25s]
prediction: ['[CLS] chop taken outside the ever context ( current political climate climateyna ) see more evil than terrorists! ) [SEP]']
Attempt swap
[1900/2000] tot_loss=1.632 (perp=7.549, rec=0.119, cos=0.003), tot_loss_proj:2.206 [t=0.30s]
prediction: ['[CLS] chop taken outside the ever context ( current political climate climateyna ) see more evil than terrorists! ) [SEP]']
[1950/2000] tot_loss=1.640 (perp=7.549, rec=0.127, cos=0.003), tot_loss_proj:2.210 [t=0.29s]
prediction: ['[CLS] chop taken outside the ever context ( current political climate climateyna ) see more evil than terrorists! ) [SEP]']
Attempt swap
[2000/2000] tot_loss=1.634 (perp=7.549, rec=0.122, cos=0.003), tot_loss_proj:2.214 [t=0.19s]
prediction: ['[CLS] chop taken outside the ever context ( current political climate climateyna ) see more evil than terrorists! ) [SEP]']
Done with input #24 of 100.
reference: 
========================
[CLS] taken outside the context of the current political climate ( see : terrorists are more evil than ever! ) [SEP]
========================
predicted: 
========================
[CLS] chop taken outside the ever context ( current political climate climateyna ) see more evil than terrorists! ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 88.235 | r: 83.333
rouge2     | fm: 36.364 | p: 37.500 | r: 35.294
rougeL     | fm: 74.286 | p: 76.471 | r: 72.222
rougeLsum  | fm: 74.286 | p: 76.471 | r: 72.222
r1fm+r2fm = 122.078

[Aggregate metrics]:
rouge1     | fm: 88.786 | p: 87.951 | r: 89.967
rouge2     | fm: 56.682 | p: 56.484 | r: 57.036
rougeL     | fm: 79.383 | p: 78.688 | r: 80.303
rougeLsum  | fm: 79.269 | p: 78.443 | r: 80.224
r1fm+r2fm = 145.468

input #24 time: 0:08:52 | total time: 3:35:52


Running input #25 of 100.
reference: 
========================
strange and beautiful film 
========================
average of cosine similarity 0.9993176191193096
highest_index [0]
highest [0.9993176191193096]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 4326, 1998, 3376, 2143,  102]], device='cuda:0')
Debug: ref = ['[CLS] strange and beautiful film [SEP]']
[Init] best rec loss: 2.0016868114471436 for ['[CLS] excess concepcion occupation channel [SEP]']
[Init] best rec loss: 1.8594616651535034 for ['[CLS] memory within ; buy [SEP]']
[Init] best rec loss: 1.7197651863098145 for ['[CLS] merit delaney canoniary [SEP]']
[Init] best rec loss: 1.7120318412780762 for ['[CLS] executive into females he [SEP]']
[Init] best rec loss: 1.6727626323699951 for ['[CLS] james adding letters received [SEP]']
[Init] best rec loss: 1.6727566719055176 for ['[CLS] frequent gailez bane [SEP]']
[Init] best rec loss: 1.5321781635284424 for ['[CLS] mention acre old headline [SEP]']
[Init] best rec loss: 1.4170466661453247 for ['[CLS] mouth oblast cycle jury [SEP]']
[Init] best rec loss: 1.3436115980148315 for ['[CLS] hide a seal mess [SEP]']
[Init] best perm rec loss: 1.3427221775054932 for ['[CLS] seal a mess hide [SEP]']
[Init] best perm rec loss: 1.3401399850845337 for ['[CLS] mess hide a seal [SEP]']
[Init] best perm rec loss: 1.3389146327972412 for ['[CLS] mess a hide seal [SEP]']
[Init] best perm rec loss: 1.3344050645828247 for ['[CLS] mess hide seal a [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.331 (perp=10.589, rec=0.209, cos=0.005), tot_loss_proj:2.490 [t=0.21s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 100/2000] tot_loss=2.262 (perp=10.589, rec=0.141, cos=0.004), tot_loss_proj:2.495 [t=0.23s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 150/2000] tot_loss=2.233 (perp=10.589, rec=0.113, cos=0.002), tot_loss_proj:2.487 [t=0.18s]
prediction: ['[CLS] beautiful film strange beautiful [SEP]']
[ 200/2000] tot_loss=2.178 (perp=10.501, rec=0.076, cos=0.001), tot_loss_proj:2.546 [t=0.18s]
prediction: ['[CLS] beautiful film strange and [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.502 (perp=7.104, rec=0.080, cos=0.001), tot_loss_proj:1.638 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[ 300/2000] tot_loss=1.501 (perp=7.104, rec=0.079, cos=0.001), tot_loss_proj:1.631 [t=0.20s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.489 (perp=7.104, rec=0.067, cos=0.001), tot_loss_proj:1.637 [t=0.26s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.486 (perp=7.104, rec=0.063, cos=0.001), tot_loss_proj:1.629 [t=0.31s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[ 450/2000] tot_loss=1.488 (perp=7.104, rec=0.066, cos=0.001), tot_loss_proj:1.625 [t=0.27s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.492 (perp=7.104, rec=0.070, cos=0.001), tot_loss_proj:1.621 [t=0.34s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.493 (perp=7.104, rec=0.071, cos=0.001), tot_loss_proj:1.621 [t=0.27s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[ 600/2000] tot_loss=1.485 (perp=7.104, rec=0.063, cos=0.001), tot_loss_proj:1.628 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.492 (perp=7.104, rec=0.070, cos=0.001), tot_loss_proj:1.616 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.486 (perp=7.104, rec=0.064, cos=0.001), tot_loss_proj:1.629 [t=0.25s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[ 750/2000] tot_loss=1.497 (perp=7.104, rec=0.075, cos=0.001), tot_loss_proj:1.629 [t=0.19s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.483 (perp=7.104, rec=0.060, cos=0.001), tot_loss_proj:1.625 [t=0.24s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.489 (perp=7.104, rec=0.067, cos=0.001), tot_loss_proj:1.628 [t=0.21s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[ 900/2000] tot_loss=1.482 (perp=7.104, rec=0.059, cos=0.001), tot_loss_proj:1.619 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.493 (perp=7.104, rec=0.070, cos=0.001), tot_loss_proj:1.621 [t=0.22s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1000/2000] tot_loss=1.501 (perp=7.104, rec=0.079, cos=0.001), tot_loss_proj:1.616 [t=0.22s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[1050/2000] tot_loss=1.484 (perp=7.104, rec=0.062, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1100/2000] tot_loss=1.486 (perp=7.104, rec=0.064, cos=0.001), tot_loss_proj:1.623 [t=0.22s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1150/2000] tot_loss=1.490 (perp=7.104, rec=0.068, cos=0.001), tot_loss_proj:1.618 [t=0.19s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[1200/2000] tot_loss=1.501 (perp=7.104, rec=0.079, cos=0.001), tot_loss_proj:1.618 [t=0.19s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1250/2000] tot_loss=1.490 (perp=7.104, rec=0.068, cos=0.001), tot_loss_proj:1.620 [t=0.22s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1300/2000] tot_loss=1.492 (perp=7.104, rec=0.070, cos=0.001), tot_loss_proj:1.624 [t=0.24s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[1350/2000] tot_loss=1.493 (perp=7.104, rec=0.071, cos=0.001), tot_loss_proj:1.620 [t=0.26s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1400/2000] tot_loss=1.483 (perp=7.104, rec=0.061, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1450/2000] tot_loss=1.485 (perp=7.104, rec=0.063, cos=0.001), tot_loss_proj:1.621 [t=0.27s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[1500/2000] tot_loss=1.484 (perp=7.104, rec=0.062, cos=0.001), tot_loss_proj:1.616 [t=0.20s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1550/2000] tot_loss=1.492 (perp=7.104, rec=0.070, cos=0.001), tot_loss_proj:1.613 [t=0.24s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1600/2000] tot_loss=1.494 (perp=7.104, rec=0.072, cos=0.001), tot_loss_proj:1.623 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[1650/2000] tot_loss=1.496 (perp=7.104, rec=0.074, cos=0.001), tot_loss_proj:1.609 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1700/2000] tot_loss=1.497 (perp=7.104, rec=0.075, cos=0.001), tot_loss_proj:1.626 [t=0.21s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1750/2000] tot_loss=1.489 (perp=7.104, rec=0.067, cos=0.001), tot_loss_proj:1.621 [t=0.19s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[1800/2000] tot_loss=1.485 (perp=7.104, rec=0.063, cos=0.001), tot_loss_proj:1.624 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1850/2000] tot_loss=1.493 (perp=7.104, rec=0.071, cos=0.001), tot_loss_proj:1.625 [t=0.21s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[1900/2000] tot_loss=1.493 (perp=7.104, rec=0.071, cos=0.001), tot_loss_proj:1.610 [t=0.19s]
prediction: ['[CLS] beautiful and strange film [SEP]']
[1950/2000] tot_loss=1.489 (perp=7.104, rec=0.067, cos=0.001), tot_loss_proj:1.618 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Attempt swap
[2000/2000] tot_loss=1.479 (perp=7.104, rec=0.056, cos=0.001), tot_loss_proj:1.627 [t=0.18s]
prediction: ['[CLS] beautiful and strange film [SEP]']
Done with input #25 of 100.
reference: 
========================
[CLS] strange and beautiful film [SEP]
========================
predicted: 
========================
[CLS] beautiful and strange film [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 20.000 | p: 20.000 | r: 20.000
rougeL     | fm: 66.667 | p: 66.667 | r: 66.667
rougeLsum  | fm: 66.667 | p: 66.667 | r: 66.667
r1fm+r2fm = 120.000

[Aggregate metrics]:
rouge1     | fm: 89.208 | p: 88.343 | r: 90.270
rouge2     | fm: 55.501 | p: 55.274 | r: 55.740
rougeL     | fm: 78.959 | p: 78.194 | r: 79.926
rougeLsum  | fm: 78.699 | p: 77.941 | r: 79.608
r1fm+r2fm = 144.709

input #25 time: 0:08:32 | total time: 3:44:24


Running input #26 of 100.
reference: 
========================
this ) meandering and pointless french coming-of-age import from writer-director anne-sophie birot 
========================
average of cosine similarity 0.9992061826546763
highest_index [0]
highest [0.9992061826546763]
Debug: ids_shape = 25, pads = [25]
Debug: input ids = tensor([[  101,  2023,  1007,  2812,  4063,  2075,  1998, 23100,  2413,  2746,
          1011,  1997,  1011,  2287, 12324,  2013,  3213,  1011,  2472,  4776,
          1011,  8234, 12170, 21709,   102]], device='cuda:0')
Debug: ref = ['[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]']
[Init] best rec loss: 1.9023979902267456 for ['[CLS] pointed minister laid neither loan happening dirty lad unitedod hatemourwi is conflictadia either angels compliment shield advantage looksrana [SEP]']
[Init] best rec loss: 1.8645083904266357 for ['[CLS] warfare isle due could marriedgocroft legislative cream can allie were must lion lawsuits eireann amateur highland kings therefore lil model roughly [SEP]']
[Init] best rec loss: 1.7954801321029663 for ['[CLS] cards media decision batsman healthy always year garrettoid templeawa prime clearing agencynin radio return emission puerto motion worldsd breath [SEP]']
[Init] best rec loss: 1.7904412746429443 for ['[CLS] votes jane normanwaite heaving trouble peopletou tax were sud launch onesmin rear lovely guitarists distressed gain software seemedtort industry [SEP]']
[Init] best rec loss: 1.65139901638031 for ['[CLS] exchange specify blame hurlinghyllum r monarch bet prom scouting presented jamal residents 2018 macdonald glow officials manual residing free shield pinkructured [SEP]']
[Init] best rec loss: 1.6358462572097778 for ['[CLS]sed benedict later housing why surroundingpinegrave nat use amount cast thy scored pattern run unknown authority travellingflict quotes guest lucan [SEP]']
[Init] best rec loss: 1.62001371383667 for ['[CLS] inter disappointed fiveiel 3 the airline whisperingar kelsey score chi kept dvduting cubs really casedrop4 commons due hayes [SEP]']
[Init] best rec loss: 1.5167450904846191 for ['[CLS] scene nearby protected miriam pvia 1 studio all emphasizes liner debut nic furtherych think kick charlie ling shoes thatization joe [SEP]']
[Init] best rec loss: 1.514949917793274 for ['[CLS] stakekar passing rides 65 turns speak mutant montrose capacity rid fur unite button riceª ak occupied cher following fully igo [SEP]']
[Init] best rec loss: 1.5008208751678467 for ['[CLS] colonial merely four door usuallytead souls arrow constituenciesᆼ officers more s discipline theoretical iso octave shot fourth list polishkan death [SEP]']
[Init] best perm rec loss: 1.4985138177871704 for ['[CLS] door colonial shot isotead discipline merelyᆼkan list more arrow four souls polish death fourth theoretical usually constituencies octave s officers [SEP]']
[Init] best perm rec loss: 1.4953454732894897 for ['[CLS] theoretical list polishᆼ officers colonial s disciplinetead octave usually merely four souls arrowkan death constituencies shot iso more fourth door [SEP]']
[Init] best perm rec loss: 1.4886966943740845 for ['[CLS] colonial s four soulskan octavetead death moreᆼ list polish shot door arrow officers usually theoretical fourth discipline constituencies iso merely [SEP]']
[Init] best perm rec loss: 1.485183835029602 for ['[CLS] shot polish constituencies theoretical arrow merelyᆼ usually souls officerskan octave list door colonial fourth iso s death discipline four moretead [SEP]']
[Init] best perm rec loss: 1.4836591482162476 for ['[CLS] polish list merely fourkan octaveᆼ souls usually constituencies iso officers arrow s discipline shot colonial moretead death fourth door theoretical [SEP]']
[Init] best perm rec loss: 1.4816036224365234 for ['[CLS] s merely colonial doorkan fourth polish souls four officers death usually arrow shot moretead list octave iso constituencies discipline theoreticalᆼ [SEP]']
[Init] best perm rec loss: 1.47699773311615 for ['[CLS] fourᆼ polishtead shot usually octave discipline souls s death door merely officers list arrow more fourth iso constituencieskan colonial theoretical [SEP]']
[Init] best perm rec loss: 1.4744471311569214 for ['[CLS] iso death arrow s list polish usually four door more merelykan discipline colonial octave constituenciestead shot fourth officersᆼ souls theoretical [SEP]']
[Init] best perm rec loss: 1.4727554321289062 for ['[CLS] list shotᆼ death door iso constituencies fourth s officers four merely octave moreteadkan colonial arrow usually discipline polish souls theoretical [SEP]']
[Init] best perm rec loss: 1.4687553644180298 for ['[CLS] discipline constituencies shotkan merely arrowᆼ four polishtead iso s list officers death usually door octave fourth more souls colonial theoretical [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.484 (perp=11.134, rec=0.245, cos=0.012), tot_loss_proj:2.847 [t=0.19s]
prediction: ['[CLS] foreign ) italiantance ; pointless mitochondrial ) ) dog of african writer com coming recurring ended m² or by pointless ) pointless [SEP]']
[ 100/2000] tot_loss=2.260 (perp=10.344, rec=0.185, cos=0.007), tot_loss_proj:2.680 [t=0.20s]
prediction: ['[CLS] foreign - frenchder ) pointless sophie french - import fromaux import writer coming breakup of import - author mean - pointless [SEP]']
[ 150/2000] tot_loss=2.361 (perp=11.133, rec=0.130, cos=0.004), tot_loss_proj:2.809 [t=0.19s]
prediction: ['[CLS] import - age - ) pointless anne french and import from european import writer coming affairs of maria age writer mean - pointless [SEP]']
[ 200/2000] tot_loss=2.229 (perp=10.603, rec=0.106, cos=0.003), tot_loss_proj:3.083 [t=0.24s]
prediction: ['[CLS] import - age - )ing anne french and import from - import writer coming hayden of bathing - writer meander pointless [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.166 (perp=10.295, rec=0.105, cos=0.003), tot_loss_proj:2.643 [t=0.19s]
prediction: ['[CLS] various - of - )ing anne french and import from this import writer coming ski agerot - writer meander pointless [SEP]']
[ 300/2000] tot_loss=2.138 (perp=10.252, rec=0.085, cos=0.002), tot_loss_proj:2.684 [t=0.19s]
prediction: ['[CLS] this - of - )ing anne french and import from this import writer coming ski agerot - director meander pointless [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.228 (perp=10.657, rec=0.094, cos=0.003), tot_loss_proj:2.775 [t=0.20s]
prediction: ['[CLS] deriveding of - ) - sophie french and import from this import writer coming sophie agerot - director meander pointless [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.069 (perp=9.929, rec=0.081, cos=0.002), tot_loss_proj:2.692 [t=0.19s]
prediction: ['[CLS] ageing of - ) - anne french and import from this import director coming sophie philippinerot - director meander pointless [SEP]']
[ 450/2000] tot_loss=2.096 (perp=10.047, rec=0.084, cos=0.002), tot_loss_proj:2.899 [t=0.18s]
prediction: ['[CLS] ageing of - ) - anne french and import from this writer director coming sophie philippinerot - director meander pointless [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.939 (perp=9.262, rec=0.085, cos=0.002), tot_loss_proj:2.812 [t=0.33s]
prediction: ['[CLS] ageing of - ) - of french and import from this writer director coming sophie annerot - director meander pointless [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.862 (perp=8.920, rec=0.076, cos=0.002), tot_loss_proj:2.545 [t=0.20s]
prediction: ['[CLS] ageing of - ) - of french and import from this pointless director coming sophie annerot - director meander writer [SEP]']
[ 600/2000] tot_loss=1.854 (perp=8.920, rec=0.068, cos=0.002), tot_loss_proj:2.547 [t=0.19s]
prediction: ['[CLS] ageing of - ) - of french and import from this pointless director coming sophie annerot - director meander writer [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.835 (perp=8.784, rec=0.077, cos=0.002), tot_loss_proj:2.582 [t=0.20s]
prediction: ['[CLS] ageing of ) - - of french and import from this pointless director coming sophie annerot - director meander writer [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.790 (perp=8.563, rec=0.076, cos=0.002), tot_loss_proj:2.490 [t=0.20s]
prediction: ['[CLS] ageing of ) - - of french and import from this pointless director coming sophierot - director anne meander writer [SEP]']
[ 750/2000] tot_loss=1.782 (perp=8.563, rec=0.067, cos=0.002), tot_loss_proj:2.491 [t=0.19s]
prediction: ['[CLS] ageing of ) - - of french and import from this pointless director coming sophierot - director anne meander writer [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.745 (perp=8.378, rec=0.067, cos=0.002), tot_loss_proj:2.434 [t=0.18s]
prediction: ['[CLS] ageing of ) - - of french and import sophie this pointless director coming fromrot - director anne meander writer [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.722 (perp=8.235, rec=0.074, cos=0.002), tot_loss_proj:2.211 [t=0.19s]
prediction: ['[CLS] ageing of ) - - of french and importrot this pointless director coming from sophie - director anne meander writer [SEP]']
[ 900/2000] tot_loss=1.716 (perp=8.235, rec=0.067, cos=0.002), tot_loss_proj:2.214 [t=0.19s]
prediction: ['[CLS] ageing of ) - - of french and importrot this pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.683 (perp=8.073, rec=0.067, cos=0.002), tot_loss_proj:2.152 [t=0.20s]
prediction: ['[CLS] ageing of ) - - and of french importrot this pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
[1000/2000] tot_loss=1.688 (perp=8.073, rec=0.072, cos=0.002), tot_loss_proj:2.152 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of french importrot this pointless director coming from sophie - director anne meander writer [SEP]']
[1050/2000] tot_loss=1.690 (perp=8.073, rec=0.073, cos=0.002), tot_loss_proj:2.148 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of french importrot this pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.608 (perp=7.703, rec=0.065, cos=0.002), tot_loss_proj:2.089 [t=0.18s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
[1150/2000] tot_loss=1.618 (perp=7.703, rec=0.075, cos=0.002), tot_loss_proj:2.089 [t=0.18s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
[1200/2000] tot_loss=1.607 (perp=7.703, rec=0.064, cos=0.002), tot_loss_proj:2.086 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
[1250/2000] tot_loss=1.611 (perp=7.703, rec=0.069, cos=0.002), tot_loss_proj:2.092 [t=0.21s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
[1300/2000] tot_loss=1.612 (perp=7.703, rec=0.070, cos=0.002), tot_loss_proj:2.088 [t=0.29s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
[1350/2000] tot_loss=1.618 (perp=7.703, rec=0.076, cos=0.002), tot_loss_proj:2.090 [t=0.23s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
[1400/2000] tot_loss=1.608 (perp=7.703, rec=0.066, cos=0.002), tot_loss_proj:2.092 [t=0.18s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
[1450/2000] tot_loss=1.612 (perp=7.703, rec=0.070, cos=0.002), tot_loss_proj:2.086 [t=0.21s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
[1500/2000] tot_loss=1.616 (perp=7.703, rec=0.073, cos=0.002), tot_loss_proj:2.084 [t=0.21s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
[1550/2000] tot_loss=1.621 (perp=7.703, rec=0.079, cos=0.002), tot_loss_proj:2.089 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
[1600/2000] tot_loss=1.613 (perp=7.703, rec=0.071, cos=0.002), tot_loss_proj:2.087 [t=0.20s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
[1650/2000] tot_loss=1.612 (perp=7.703, rec=0.069, cos=0.002), tot_loss_proj:2.089 [t=0.22s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
[1700/2000] tot_loss=1.615 (perp=7.703, rec=0.072, cos=0.002), tot_loss_proj:2.088 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.618 (perp=7.737, rec=0.069, cos=0.002), tot_loss_proj:2.111 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from director - sophie anne meander writer [SEP]']
[1800/2000] tot_loss=1.622 (perp=7.737, rec=0.073, cos=0.002), tot_loss_proj:2.109 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from director - sophie anne meander writer [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.611 (perp=7.695, rec=0.071, cos=0.002), tot_loss_proj:2.104 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from director - anne sophie meander writer [SEP]']
Attempt swap
[1900/2000] tot_loss=1.613 (perp=7.695, rec=0.072, cos=0.002), tot_loss_proj:2.109 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from director - anne sophie meander writer [SEP]']
[1950/2000] tot_loss=1.612 (perp=7.695, rec=0.072, cos=0.002), tot_loss_proj:2.104 [t=0.19s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from director - anne sophie meander writer [SEP]']
Attempt swap
[2000/2000] tot_loss=1.605 (perp=7.695, rec=0.064, cos=0.002), tot_loss_proj:2.104 [t=0.23s]
prediction: ['[CLS] ageing of ) - - and of this french importrot pointless director coming from director - anne sophie meander writer [SEP]']
Done with input #26 of 100.
reference: 
========================
[CLS] this ) meandering and pointless french coming - of - age import from writer - director anne - sophie birot [SEP]
========================
predicted: 
========================
[CLS] ageing of ) - - and of this french importrot pointless director coming from sophie - director anne meander writer [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 74.286 | p: 72.222 | r: 76.471
rouge2     | fm: 6.061 | p: 5.882 | r: 6.250
rougeL     | fm: 45.714 | p: 44.444 | r: 47.059
rougeLsum  | fm: 45.714 | p: 44.444 | r: 47.059
r1fm+r2fm = 80.346

[Aggregate metrics]:
rouge1     | fm: 88.600 | p: 87.796 | r: 89.668
rouge2     | fm: 53.432 | p: 53.273 | r: 53.624
rougeL     | fm: 77.892 | p: 77.011 | r: 78.776
rougeLsum  | fm: 77.403 | p: 76.708 | r: 78.315
r1fm+r2fm = 142.032

input #26 time: 0:08:33 | total time: 3:52:58


Running input #27 of 100.
reference: 
========================
are so generic 
========================
average of cosine similarity 0.999345236003067
highest_index [0]
highest [0.999345236003067]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2024,  2061, 12391,   102]], device='cuda:0')
Debug: ref = ['[CLS] are so generic [SEP]']
[Init] best rec loss: 1.9401098489761353 for ['[CLS] sidney ft roman [SEP]']
[Init] best rec loss: 1.9116452932357788 for ['[CLS] dun where occupied [SEP]']
[Init] best rec loss: 1.8886722326278687 for ['[CLS] estate kiss ale [SEP]']
[Init] best rec loss: 1.8630187511444092 for ['[CLS] heel clinical birth [SEP]']
[Init] best rec loss: 1.6387312412261963 for ['[CLS] and universal universe [SEP]']
[Init] best rec loss: 1.5562210083007812 for ['[CLS] [CLS] evidence darkness [SEP]']
[Init] best rec loss: 1.4637377262115479 for ['[CLS] part portion mid [SEP]']
[Init] best rec loss: 1.3929609060287476 for ['[CLS] fat mattream [SEP]']
[Init] best rec loss: 1.2099963426589966 for ['[CLS] givenwine transit [SEP]']
[Init] best perm rec loss: 1.209096074104309 for ['[CLS] transitwine given [SEP]']
[Init] best perm rec loss: 1.2082395553588867 for ['[CLS] transit givenwine [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.590 (perp=11.372, rec=0.732, cos=0.583), tot_loss_proj:3.748 [t=0.19s]
prediction: ['[CLS] we an contemporary [SEP]']
[ 100/2000] tot_loss=3.662 (perp=10.986, rec=0.643, cos=0.822), tot_loss_proj:2.556 [t=0.24s]
prediction: ['[CLS] generic so generic [SEP]']
[ 150/2000] tot_loss=4.459 (perp=14.497, rec=0.687, cos=0.873), tot_loss_proj:3.546 [t=0.25s]
prediction: ['[CLS] generic when instantly [SEP]']
[ 200/2000] tot_loss=3.939 (perp=12.021, rec=0.584, cos=0.950), tot_loss_proj:2.938 [t=0.19s]
prediction: ['[CLS] generic generic instantly [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=3.572 (perp=10.988, rec=0.603, cos=0.771), tot_loss_proj:2.673 [t=0.19s]
prediction: ['[CLS] instantly generic generic [SEP]']
[ 300/2000] tot_loss=2.554 (perp=10.988, rec=0.316, cos=0.041), tot_loss_proj:2.679 [t=0.23s]
prediction: ['[CLS] instantly generic generic [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.223 (perp=10.092, rec=0.194, cos=0.011), tot_loss_proj:2.590 [t=0.19s]
prediction: ['[CLS] where generic generic [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.044 (perp=9.381, rec=0.160, cos=0.008), tot_loss_proj:2.613 [t=0.18s]
prediction: ['[CLS] where are generic [SEP]']
[ 450/2000] tot_loss=2.011 (perp=9.381, rec=0.129, cos=0.006), tot_loss_proj:2.620 [t=0.22s]
prediction: ['[CLS] where are generic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.997 (perp=9.381, rec=0.116, cos=0.005), tot_loss_proj:2.625 [t=0.18s]
prediction: ['[CLS] where are generic [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.186 (perp=10.270, rec=0.128, cos=0.004), tot_loss_proj:2.586 [t=0.18s]
prediction: ['[CLS] generally are generic [SEP]']
[ 600/2000] tot_loss=2.161 (perp=10.270, rec=0.103, cos=0.004), tot_loss_proj:2.587 [t=0.18s]
prediction: ['[CLS] generally are generic [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.676 (perp=7.798, rec=0.112, cos=0.004), tot_loss_proj:2.015 [t=0.19s]
prediction: ['[CLS] are generally generic [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=2.092 (perp=9.904, rec=0.107, cos=0.005), tot_loss_proj:2.287 [t=0.18s]
prediction: ['[CLS] generally so generic [SEP]']
[ 750/2000] tot_loss=2.086 (perp=9.904, rec=0.101, cos=0.004), tot_loss_proj:2.285 [t=0.19s]
prediction: ['[CLS] generally so generic [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.086 (perp=9.904, rec=0.102, cos=0.004), tot_loss_proj:2.286 [t=0.18s]
prediction: ['[CLS] generally so generic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.773 (perp=8.320, rec=0.105, cos=0.004), tot_loss_proj:1.766 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[ 900/2000] tot_loss=1.772 (perp=8.320, rec=0.104, cos=0.004), tot_loss_proj:1.759 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.779 (perp=8.320, rec=0.111, cos=0.004), tot_loss_proj:1.750 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.772 (perp=8.320, rec=0.104, cos=0.004), tot_loss_proj:1.760 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
[1050/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.762 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.784 (perp=8.320, rec=0.116, cos=0.004), tot_loss_proj:1.756 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.784 (perp=8.320, rec=0.116, cos=0.004), tot_loss_proj:1.749 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[1200/2000] tot_loss=1.770 (perp=8.320, rec=0.102, cos=0.004), tot_loss_proj:1.750 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.776 (perp=8.320, rec=0.108, cos=0.004), tot_loss_proj:1.760 [t=0.24s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.762 (perp=8.320, rec=0.094, cos=0.004), tot_loss_proj:1.756 [t=0.21s]
prediction: ['[CLS] are so generic [SEP]']
[1350/2000] tot_loss=1.773 (perp=8.320, rec=0.105, cos=0.004), tot_loss_proj:1.763 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.771 (perp=8.320, rec=0.103, cos=0.004), tot_loss_proj:1.766 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.774 (perp=8.320, rec=0.106, cos=0.004), tot_loss_proj:1.760 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[1500/2000] tot_loss=1.778 (perp=8.320, rec=0.111, cos=0.004), tot_loss_proj:1.755 [t=0.25s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.768 (perp=8.320, rec=0.100, cos=0.004), tot_loss_proj:1.755 [t=0.18s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.756 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[1650/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.768 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.769 (perp=8.320, rec=0.101, cos=0.004), tot_loss_proj:1.750 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.769 (perp=8.320, rec=0.102, cos=0.004), tot_loss_proj:1.758 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[1800/2000] tot_loss=1.765 (perp=8.320, rec=0.097, cos=0.004), tot_loss_proj:1.760 [t=0.23s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.763 (perp=8.320, rec=0.095, cos=0.004), tot_loss_proj:1.760 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.780 (perp=8.320, rec=0.112, cos=0.004), tot_loss_proj:1.760 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
[1950/2000] tot_loss=1.766 (perp=8.320, rec=0.098, cos=0.004), tot_loss_proj:1.750 [t=0.19s]
prediction: ['[CLS] are so generic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.320, rec=0.092, cos=0.004), tot_loss_proj:1.757 [t=0.22s]
prediction: ['[CLS] are so generic [SEP]']
Done with input #27 of 100.
reference: 
========================
[CLS] are so generic [SEP]
========================
predicted: 
========================
[CLS] are so generic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.084 | p: 88.285 | r: 90.107
rouge2     | fm: 55.404 | p: 55.163 | r: 55.698
rougeL     | fm: 78.628 | p: 77.781 | r: 79.482
rougeLsum  | fm: 78.152 | p: 77.445 | r: 78.966
r1fm+r2fm = 144.488

input #27 time: 0:08:25 | total time: 4:01:24


Running input #28 of 100.
reference: 
========================
for only 71 minutes 
========================
average of cosine similarity 0.9993345319062628
highest_index [0]
highest [0.9993345319062628]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[ 101, 2005, 2069, 6390, 2781,  102]], device='cuda:0')
Debug: ref = ['[CLS] for only 71 minutes [SEP]']
[Init] best rec loss: 1.6155987977981567 for ['[CLS] wheel pc liz tube [SEP]']
[Init] best rec loss: 1.5106481313705444 for ['[CLS] boundaries towards lands delivery [SEP]']
[Init] best rec loss: 1.505471110343933 for ['[CLS] immortal coma thierry imperial [SEP]']
[Init] best rec loss: 1.4851624965667725 for ['[CLS] perhaps childrenogical beta [SEP]']
[Init] best rec loss: 1.4608865976333618 for ['[CLS] bro asher lit majority [SEP]']
[Init] best rec loss: 1.460343837738037 for ['[CLS] site georgia chambers nicholas [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.098 (perp=9.001, rec=0.252, cos=0.045), tot_loss_proj:2.574 [t=0.20s]
prediction: ['[CLS] for no minutes minutes [SEP]']
[ 100/2000] tot_loss=1.841 (perp=8.476, rec=0.127, cos=0.018), tot_loss_proj:2.184 [t=0.20s]
prediction: ['[CLS] for only minutes minutes [SEP]']
[ 150/2000] tot_loss=1.810 (perp=8.476, rec=0.105, cos=0.010), tot_loss_proj:2.189 [t=0.24s]
prediction: ['[CLS] for only minutes minutes [SEP]']
[ 200/2000] tot_loss=1.806 (perp=8.476, rec=0.102, cos=0.009), tot_loss_proj:2.183 [t=0.24s]
prediction: ['[CLS] for only minutes minutes [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.693 (perp=7.843, rec=0.113, cos=0.012), tot_loss_proj:2.277 [t=0.20s]
prediction: ['[CLS] for minutes only minutes [SEP]']
[ 300/2000] tot_loss=1.673 (perp=7.843, rec=0.096, cos=0.008), tot_loss_proj:2.280 [t=0.30s]
prediction: ['[CLS] for minutes only minutes [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.673 (perp=7.843, rec=0.097, cos=0.007), tot_loss_proj:2.275 [t=0.21s]
prediction: ['[CLS] for minutes only minutes [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.663 (perp=7.843, rec=0.088, cos=0.006), tot_loss_proj:2.277 [t=0.20s]
prediction: ['[CLS] for minutes only minutes [SEP]']
[ 450/2000] tot_loss=1.655 (perp=7.843, rec=0.084, cos=0.002), tot_loss_proj:2.273 [t=0.26s]
prediction: ['[CLS] for minutes only minutes [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.900 (perp=9.124, rec=0.073, cos=0.002), tot_loss_proj:2.227 [t=0.28s]
prediction: ['[CLS] for 71 only minutes [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.603 (perp=7.699, rec=0.062, cos=0.002), tot_loss_proj:1.620 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 600/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.617 [t=0.25s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.609 (perp=7.699, rec=0.068, cos=0.001), tot_loss_proj:1.626 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.607 (perp=7.699, rec=0.065, cos=0.001), tot_loss_proj:1.624 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 750/2000] tot_loss=1.602 (perp=7.699, rec=0.061, cos=0.001), tot_loss_proj:1.623 [t=0.33s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.614 (perp=7.699, rec=0.073, cos=0.001), tot_loss_proj:1.628 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.623 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[ 900/2000] tot_loss=1.596 (perp=7.699, rec=0.055, cos=0.001), tot_loss_proj:1.620 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.598 (perp=7.699, rec=0.057, cos=0.001), tot_loss_proj:1.623 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1000/2000] tot_loss=1.605 (perp=7.699, rec=0.064, cos=0.001), tot_loss_proj:1.634 [t=0.22s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1050/2000] tot_loss=1.596 (perp=7.699, rec=0.055, cos=0.001), tot_loss_proj:1.621 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1100/2000] tot_loss=1.609 (perp=7.699, rec=0.068, cos=0.001), tot_loss_proj:1.613 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1150/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.623 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1200/2000] tot_loss=1.605 (perp=7.699, rec=0.064, cos=0.001), tot_loss_proj:1.618 [t=0.31s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1250/2000] tot_loss=1.606 (perp=7.699, rec=0.065, cos=0.001), tot_loss_proj:1.622 [t=0.23s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1300/2000] tot_loss=1.594 (perp=7.699, rec=0.053, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1350/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.633 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1400/2000] tot_loss=1.602 (perp=7.699, rec=0.061, cos=0.001), tot_loss_proj:1.620 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.612 (perp=7.699, rec=0.071, cos=0.001), tot_loss_proj:1.617 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1500/2000] tot_loss=1.597 (perp=7.699, rec=0.055, cos=0.001), tot_loss_proj:1.622 [t=0.24s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.610 (perp=7.699, rec=0.069, cos=0.001), tot_loss_proj:1.616 [t=0.23s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1600/2000] tot_loss=1.609 (perp=7.699, rec=0.068, cos=0.001), tot_loss_proj:1.632 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1650/2000] tot_loss=1.602 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.613 [t=0.19s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1700/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.628 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1750/2000] tot_loss=1.612 (perp=7.699, rec=0.071, cos=0.001), tot_loss_proj:1.620 [t=0.18s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1800/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.631 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1850/2000] tot_loss=1.597 (perp=7.699, rec=0.056, cos=0.001), tot_loss_proj:1.609 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[1900/2000] tot_loss=1.600 (perp=7.699, rec=0.059, cos=0.001), tot_loss_proj:1.620 [t=0.21s]
prediction: ['[CLS] for only 71 minutes [SEP]']
[1950/2000] tot_loss=1.601 (perp=7.699, rec=0.060, cos=0.001), tot_loss_proj:1.626 [t=0.26s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Attempt swap
[2000/2000] tot_loss=1.599 (perp=7.699, rec=0.058, cos=0.001), tot_loss_proj:1.622 [t=0.20s]
prediction: ['[CLS] for only 71 minutes [SEP]']
Done with input #28 of 100.
reference: 
========================
[CLS] for only 71 minutes [SEP]
========================
predicted: 
========================
[CLS] for only 71 minutes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.381 | p: 88.579 | r: 90.427
rouge2     | fm: 56.898 | p: 56.735 | r: 57.176
rougeL     | fm: 79.377 | p: 78.561 | r: 80.119
rougeLsum  | fm: 78.963 | p: 78.308 | r: 79.747
r1fm+r2fm = 146.280

input #28 time: 0:08:37 | total time: 4:10:01


Running input #29 of 100.
reference: 
========================
i also believe that resident evil is not it . 
========================
average of cosine similarity 0.9992943703711437
highest_index [0]
highest [0.9992943703711437]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 1045, 2036, 2903, 2008, 6319, 4763, 2003, 2025, 2009, 1012,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] i also believe that resident evil is not it. [SEP]']
[Init] best rec loss: 1.9422098398208618 for ['[CLS] enthusiast strings jose occupied natasha respectivelyst times tale lane [SEP]']
[Init] best rec loss: 1.725492238998413 for ['[CLS] fine bedside please blanco fight colonel so ■stick manitoba [SEP]']
[Init] best rec loss: 1.665594458580017 for ['[CLS] label which £ anyway shoes mediamont campbell her cullen [SEP]']
[Init] best rec loss: 1.6626322269439697 for ['[CLS] retrieved kicking quite misunderstanding race camp streaked shot larger fields [SEP]']
[Init] best rec loss: 1.544628381729126 for ['[CLS] upperœggio award metresnay centrally managing un suddenly [SEP]']
[Init] best rec loss: 1.4950032234191895 for ['[CLS] passes training too alongside flopst tel twicerangle resident [SEP]']
[Init] best rec loss: 1.4667460918426514 for ['[CLS] hectares overshadowed° angeles me festival panels dean eventually towards [SEP]']
[Init] best rec loss: 1.451490879058838 for ['[CLS] chart numbers jar union touch of terms extreme 0 mean [SEP]']
[Init] best rec loss: 1.3281519412994385 for ['[CLS] consuming after intern coach acres surf class speed tongues period [SEP]']
[Init] best rec loss: 1.2676228284835815 for ['[CLS] crap extra cape epic apartbeat fork historia fk joyah [SEP]']
[Init] best rec loss: 1.2215781211853027 for ['[CLS] f transmit mostly axle veto cells u bufounded meters [SEP]']
[Init] best rec loss: 1.2187750339508057 for ['[CLS] tv envelope engagement administration landed tasteuted this runs oil [SEP]']
[Init] best perm rec loss: 1.2168614864349365 for ['[CLS] tv oil envelope administration taste this engagementuted runs landed [SEP]']
[Init] best perm rec loss: 1.2131327390670776 for ['[CLS] taste landed administration this runs tv engagementuted oil envelope [SEP]']
[Init] best perm rec loss: 1.2063658237457275 for ['[CLS] oil this taste landed tv runs envelope engagement administrationuted [SEP]']
[Init] best perm rec loss: 1.2030150890350342 for ['[CLS] tv oil engagement landeduted this taste envelope runs administration [SEP]']
[Init] best perm rec loss: 1.200951337814331 for ['[CLS] taste runs landeduted engagement envelope this oil tv administration [SEP]']
[Init] best perm rec loss: 1.2006797790527344 for ['[CLS] landeduted taste engagement runs tv envelope this oil administration [SEP]']
[Init] best perm rec loss: 1.2004748582839966 for ['[CLS] this oil landed engagement tv envelopeuted taste runs administration [SEP]']
[Init] best perm rec loss: 1.1998974084854126 for ['[CLS]uted taste tv engagement oil runs envelope landed this administration [SEP]']
[Init] best perm rec loss: 1.197476863861084 for ['[CLS] taste runsuted tv landed engagement oil envelope this administration [SEP]']
[Init] best perm rec loss: 1.1972182989120483 for ['[CLS] taste oiluted engagement landed tv envelope administration this runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.399 (perp=10.072, rec=0.339, cos=0.046), tot_loss_proj:3.693 [t=0.24s]
prediction: ['[CLS]. fact resulted resident resident witness was wall dad. [SEP]']
[ 100/2000] tot_loss=2.221 (perp=9.631, rec=0.268, cos=0.027), tot_loss_proj:3.510 [t=0.18s]
prediction: ['[CLS]. resident resident resident resident resident was fort it not [SEP]']
[ 150/2000] tot_loss=2.209 (perp=9.791, rec=0.232, cos=0.019), tot_loss_proj:3.810 [t=0.19s]
prediction: ['[CLS]. resident resident resident evil lanka not being not not [SEP]']
[ 200/2000] tot_loss=2.132 (perp=9.521, rec=0.210, cos=0.017), tot_loss_proj:3.063 [t=0.18s]
prediction: ['[CLS]. resident resident resident evil lanka not is not not [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.217 (perp=10.045, rec=0.190, cos=0.017), tot_loss_proj:3.889 [t=0.26s]
prediction: ['[CLS] i resident evil resident resident lanka not it not also [SEP]']
[ 300/2000] tot_loss=1.780 (perp=8.087, rec=0.150, cos=0.012), tot_loss_proj:3.034 [t=0.24s]
prediction: ['[CLS] i resident evil resident i is not it not believe [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.375 (perp=6.091, rec=0.148, cos=0.009), tot_loss_proj:2.861 [t=0.18s]
prediction: ['[CLS] i believe resident evil resident evil is is it not [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.164 (perp=5.099, rec=0.136, cos=0.008), tot_loss_proj:2.321 [t=0.25s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[ 450/2000] tot_loss=1.145 (perp=5.099, rec=0.119, cos=0.006), tot_loss_proj:2.321 [t=0.21s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.143 (perp=5.099, rec=0.118, cos=0.006), tot_loss_proj:2.318 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.125 (perp=5.099, rec=0.100, cos=0.005), tot_loss_proj:2.315 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[ 600/2000] tot_loss=1.133 (perp=5.099, rec=0.108, cos=0.005), tot_loss_proj:2.320 [t=0.22s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.116 (perp=5.099, rec=0.091, cos=0.005), tot_loss_proj:2.315 [t=0.26s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.130 (perp=5.099, rec=0.105, cos=0.005), tot_loss_proj:2.314 [t=0.28s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[ 750/2000] tot_loss=1.121 (perp=5.099, rec=0.097, cos=0.005), tot_loss_proj:2.316 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.129 (perp=5.099, rec=0.105, cos=0.005), tot_loss_proj:2.315 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.122 (perp=5.099, rec=0.098, cos=0.005), tot_loss_proj:2.311 [t=0.26s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[ 900/2000] tot_loss=1.114 (perp=5.099, rec=0.090, cos=0.005), tot_loss_proj:2.309 [t=0.26s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.128 (perp=5.099, rec=0.104, cos=0.004), tot_loss_proj:2.313 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1000/2000] tot_loss=1.118 (perp=5.099, rec=0.093, cos=0.004), tot_loss_proj:2.317 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[1050/2000] tot_loss=1.128 (perp=5.099, rec=0.104, cos=0.004), tot_loss_proj:2.314 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1100/2000] tot_loss=1.115 (perp=5.099, rec=0.091, cos=0.004), tot_loss_proj:2.315 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1150/2000] tot_loss=1.128 (perp=5.099, rec=0.104, cos=0.004), tot_loss_proj:2.315 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[1200/2000] tot_loss=1.125 (perp=5.099, rec=0.101, cos=0.004), tot_loss_proj:2.314 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1250/2000] tot_loss=1.116 (perp=5.099, rec=0.092, cos=0.004), tot_loss_proj:2.317 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1300/2000] tot_loss=1.130 (perp=5.099, rec=0.106, cos=0.004), tot_loss_proj:2.316 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[1350/2000] tot_loss=1.120 (perp=5.099, rec=0.096, cos=0.004), tot_loss_proj:2.312 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1400/2000] tot_loss=1.116 (perp=5.099, rec=0.092, cos=0.004), tot_loss_proj:2.314 [t=0.21s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1450/2000] tot_loss=1.120 (perp=5.099, rec=0.096, cos=0.004), tot_loss_proj:2.316 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[1500/2000] tot_loss=1.118 (perp=5.099, rec=0.094, cos=0.004), tot_loss_proj:2.308 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1550/2000] tot_loss=1.130 (perp=5.099, rec=0.106, cos=0.004), tot_loss_proj:2.316 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1600/2000] tot_loss=1.119 (perp=5.099, rec=0.095, cos=0.004), tot_loss_proj:2.309 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[1650/2000] tot_loss=1.118 (perp=5.099, rec=0.094, cos=0.004), tot_loss_proj:2.314 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1700/2000] tot_loss=1.134 (perp=5.099, rec=0.109, cos=0.004), tot_loss_proj:2.310 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1750/2000] tot_loss=1.116 (perp=5.099, rec=0.092, cos=0.004), tot_loss_proj:2.316 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[1800/2000] tot_loss=1.116 (perp=5.099, rec=0.092, cos=0.004), tot_loss_proj:2.313 [t=0.20s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1850/2000] tot_loss=1.117 (perp=5.099, rec=0.093, cos=0.004), tot_loss_proj:2.315 [t=0.28s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[1900/2000] tot_loss=1.106 (perp=5.099, rec=0.082, cos=0.004), tot_loss_proj:2.312 [t=0.18s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
[1950/2000] tot_loss=1.130 (perp=5.099, rec=0.106, cos=0.004), tot_loss_proj:2.314 [t=0.23s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Attempt swap
[2000/2000] tot_loss=1.117 (perp=5.099, rec=0.093, cos=0.004), tot_loss_proj:2.312 [t=0.19s]
prediction: ['[CLS] i believe that resident evil resident evil is it not [SEP]']
Done with input #29 of 100.
reference: 
========================
[CLS] i also believe that resident evil is not it. [SEP]
========================
predicted: 
========================
[CLS] i believe that resident evil resident evil is it not [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.957 | p: 83.333 | r: 90.909
rouge2     | fm: 47.619 | p: 45.455 | r: 50.000
rougeL     | fm: 78.261 | p: 75.000 | r: 81.818
rougeLsum  | fm: 78.261 | p: 75.000 | r: 81.818
r1fm+r2fm = 134.576

[Aggregate metrics]:
rouge1     | fm: 89.379 | p: 88.516 | r: 90.353
rouge2     | fm: 56.752 | p: 56.469 | r: 57.105
rougeL     | fm: 79.300 | p: 78.573 | r: 80.123
rougeLsum  | fm: 78.833 | p: 78.000 | r: 79.809
r1fm+r2fm = 146.131

input #29 time: 0:08:27 | total time: 4:18:28


Running input #30 of 100.
reference: 
========================
fizzability 
========================
average of cosine similarity 0.999272099459075
highest_index [0]
highest [0.999272099459075]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 10882, 20715,  8553,   102]], device='cuda:0')
Debug: ref = ['[CLS] fizzability [SEP]']
[Init] best rec loss: 1.8995320796966553 for ['[CLS]aver tone darling [SEP]']
[Init] best rec loss: 1.870033860206604 for ['[CLS] count four shone [SEP]']
[Init] best rec loss: 1.8638838529586792 for ['[CLS] superior vary lynne [SEP]']
[Init] best rec loss: 1.4753696918487549 for ['[CLS]kon everyone jennings [SEP]']
[Init] best rec loss: 1.3648078441619873 for ['[CLS] shell albeittai [SEP]']
[Init] best rec loss: 1.221232533454895 for ['[CLS] middle lighthouse case [SEP]']
[Init] best rec loss: 1.1736953258514404 for ['[CLS] acceleration council lizard [SEP]']
[Init] best rec loss: 1.155712604522705 for ['[CLS] spent who mom [SEP]']
[Init] best perm rec loss: 1.1542490720748901 for ['[CLS] spent mom who [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.749 (perp=12.475, rec=0.243, cos=0.011), tot_loss_proj:3.538 [t=0.18s]
prediction: ['[CLS]zzabilitybility [SEP]']
[ 100/2000] tot_loss=2.059 (perp=9.540, rec=0.146, cos=0.005), tot_loss_proj:1.994 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[ 150/2000] tot_loss=1.995 (perp=9.540, rec=0.084, cos=0.003), tot_loss_proj:1.986 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[ 200/2000] tot_loss=1.971 (perp=9.540, rec=0.061, cos=0.002), tot_loss_proj:1.977 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.970 (perp=9.540, rec=0.059, cos=0.002), tot_loss_proj:1.975 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[ 300/2000] tot_loss=1.964 (perp=9.540, rec=0.055, cos=0.002), tot_loss_proj:1.968 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.966 (perp=9.540, rec=0.055, cos=0.002), tot_loss_proj:1.989 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.984 (perp=9.540, rec=0.074, cos=0.002), tot_loss_proj:1.989 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[ 450/2000] tot_loss=1.976 (perp=9.540, rec=0.066, cos=0.002), tot_loss_proj:1.977 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.975 (perp=9.540, rec=0.066, cos=0.002), tot_loss_proj:1.968 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.953 (perp=9.540, rec=0.044, cos=0.001), tot_loss_proj:1.987 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[ 600/2000] tot_loss=1.978 (perp=9.540, rec=0.069, cos=0.001), tot_loss_proj:1.983 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.978 (perp=9.540, rec=0.069, cos=0.001), tot_loss_proj:1.968 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.977 (perp=9.540, rec=0.067, cos=0.001), tot_loss_proj:1.973 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[ 750/2000] tot_loss=1.974 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:1.982 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.977 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.965 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.962 (perp=9.540, rec=0.052, cos=0.001), tot_loss_proj:1.984 [t=0.22s]
prediction: ['[CLS] fizzability [SEP]']
[ 900/2000] tot_loss=1.973 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.969 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.967 (perp=9.540, rec=0.057, cos=0.001), tot_loss_proj:1.975 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1000/2000] tot_loss=1.961 (perp=9.540, rec=0.051, cos=0.001), tot_loss_proj:1.963 [t=0.21s]
prediction: ['[CLS] fizzability [SEP]']
[1050/2000] tot_loss=1.966 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.969 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1100/2000] tot_loss=1.967 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.977 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1150/2000] tot_loss=1.978 (perp=9.540, rec=0.068, cos=0.001), tot_loss_proj:1.968 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
[1200/2000] tot_loss=1.974 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.978 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1250/2000] tot_loss=1.965 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.968 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1300/2000] tot_loss=1.982 (perp=9.540, rec=0.073, cos=0.001), tot_loss_proj:1.974 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1350/2000] tot_loss=1.965 (perp=9.540, rec=0.056, cos=0.001), tot_loss_proj:1.978 [t=0.26s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1400/2000] tot_loss=1.967 (perp=9.540, rec=0.057, cos=0.001), tot_loss_proj:1.980 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1450/2000] tot_loss=1.960 (perp=9.540, rec=0.050, cos=0.001), tot_loss_proj:1.970 [t=0.25s]
prediction: ['[CLS] fizzability [SEP]']
[1500/2000] tot_loss=1.956 (perp=9.540, rec=0.047, cos=0.001), tot_loss_proj:1.970 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1550/2000] tot_loss=1.961 (perp=9.540, rec=0.052, cos=0.001), tot_loss_proj:1.969 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1600/2000] tot_loss=1.970 (perp=9.540, rec=0.060, cos=0.001), tot_loss_proj:1.969 [t=0.20s]
prediction: ['[CLS] fizzability [SEP]']
[1650/2000] tot_loss=1.963 (perp=9.540, rec=0.054, cos=0.001), tot_loss_proj:1.991 [t=0.23s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1700/2000] tot_loss=1.973 (perp=9.540, rec=0.064, cos=0.001), tot_loss_proj:1.990 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1750/2000] tot_loss=1.974 (perp=9.540, rec=0.065, cos=0.001), tot_loss_proj:1.973 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
[1800/2000] tot_loss=1.970 (perp=9.540, rec=0.061, cos=0.001), tot_loss_proj:1.973 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1850/2000] tot_loss=1.967 (perp=9.540, rec=0.058, cos=0.001), tot_loss_proj:1.983 [t=0.24s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[1900/2000] tot_loss=1.968 (perp=9.540, rec=0.059, cos=0.001), tot_loss_proj:1.985 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
[1950/2000] tot_loss=1.962 (perp=9.540, rec=0.053, cos=0.001), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] fizzability [SEP]']
Attempt swap
[2000/2000] tot_loss=1.963 (perp=9.540, rec=0.054, cos=0.001), tot_loss_proj:1.986 [t=0.18s]
prediction: ['[CLS] fizzability [SEP]']
Done with input #30 of 100.
reference: 
========================
[CLS] fizzability [SEP]
========================
predicted: 
========================
[CLS] fizzability [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.631 | p: 88.823 | r: 90.704
rouge2     | fm: 58.089 | p: 57.715 | r: 58.458
rougeL     | fm: 79.707 | p: 78.962 | r: 80.609
rougeLsum  | fm: 79.508 | p: 78.716 | r: 80.387
r1fm+r2fm = 147.720

input #30 time: 0:08:23 | total time: 4:26:51


Running input #31 of 100.
reference: 
========================
a better vehicle 
========================
average of cosine similarity 0.999339325216174
highest_index [0]
highest [0.999339325216174]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1037, 2488, 4316,  102]], device='cuda:0')
Debug: ref = ['[CLS] a better vehicle [SEP]']
[Init] best rec loss: 1.914638876914978 for ['[CLS] stock dorsal generations [SEP]']
[Init] best rec loss: 1.7327791452407837 for ['[CLS] afctlement generation [SEP]']
[Init] best rec loss: 1.6876567602157593 for ['[CLS] che episode band [SEP]']
[Init] best rec loss: 1.3702372312545776 for ['[CLS] running artwork robin [SEP]']
[Init] best perm rec loss: 1.3683922290802002 for ['[CLS] robin artwork running [SEP]']
[Init] best perm rec loss: 1.3629165887832642 for ['[CLS] artwork robin running [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.427 (perp=10.683, rec=0.266, cos=0.024), tot_loss_proj:2.933 [t=0.18s]
prediction: ['[CLS] better vehicle ideas [SEP]']
[ 100/2000] tot_loss=2.105 (perp=9.658, rec=0.159, cos=0.014), tot_loss_proj:2.395 [t=0.19s]
prediction: ['[CLS] better vehicle vehicle [SEP]']
[ 150/2000] tot_loss=2.041 (perp=9.638, rec=0.105, cos=0.008), tot_loss_proj:2.549 [t=0.19s]
prediction: ['[CLS] better vehicle a [SEP]']
[ 200/2000] tot_loss=2.010 (perp=9.638, rec=0.081, cos=0.002), tot_loss_proj:2.554 [t=0.18s]
prediction: ['[CLS] better vehicle a [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.602 (perp=7.603, rec=0.078, cos=0.003), tot_loss_proj:1.717 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 300/2000] tot_loss=1.594 (perp=7.603, rec=0.072, cos=0.001), tot_loss_proj:1.701 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.695 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 450/2000] tot_loss=1.575 (perp=7.603, rec=0.053, cos=0.001), tot_loss_proj:1.702 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.591 (perp=7.603, rec=0.069, cos=0.001), tot_loss_proj:1.702 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.721 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 600/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.704 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.576 (perp=7.603, rec=0.054, cos=0.001), tot_loss_proj:1.706 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 750/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.703 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.584 (perp=7.603, rec=0.062, cos=0.001), tot_loss_proj:1.700 [t=0.21s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.703 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[ 900/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.704 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.698 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.697 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
[1050/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.712 [t=0.22s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1100/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.706 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1150/2000] tot_loss=1.589 (perp=7.603, rec=0.067, cos=0.001), tot_loss_proj:1.703 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1200/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.708 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1250/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.707 [t=0.20s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1300/2000] tot_loss=1.588 (perp=7.603, rec=0.066, cos=0.001), tot_loss_proj:1.708 [t=0.20s]
prediction: ['[CLS] a better vehicle [SEP]']
[1350/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.700 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1400/2000] tot_loss=1.585 (perp=7.603, rec=0.063, cos=0.001), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1450/2000] tot_loss=1.586 (perp=7.603, rec=0.064, cos=0.001), tot_loss_proj:1.708 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[1500/2000] tot_loss=1.577 (perp=7.603, rec=0.055, cos=0.001), tot_loss_proj:1.710 [t=0.23s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1550/2000] tot_loss=1.579 (perp=7.603, rec=0.057, cos=0.001), tot_loss_proj:1.704 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1600/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.703 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
[1650/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.710 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1700/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.708 [t=0.26s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1750/2000] tot_loss=1.583 (perp=7.603, rec=0.061, cos=0.001), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1800/2000] tot_loss=1.593 (perp=7.603, rec=0.071, cos=0.001), tot_loss_proj:1.697 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1850/2000] tot_loss=1.582 (perp=7.603, rec=0.060, cos=0.001), tot_loss_proj:1.702 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[1900/2000] tot_loss=1.586 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.702 [t=0.18s]
prediction: ['[CLS] a better vehicle [SEP]']
[1950/2000] tot_loss=1.581 (perp=7.603, rec=0.059, cos=0.001), tot_loss_proj:1.704 [t=0.19s]
prediction: ['[CLS] a better vehicle [SEP]']
Attempt swap
[2000/2000] tot_loss=1.587 (perp=7.603, rec=0.065, cos=0.001), tot_loss_proj:1.701 [t=0.25s]
prediction: ['[CLS] a better vehicle [SEP]']
Done with input #31 of 100.
reference: 
========================
[CLS] a better vehicle [SEP]
========================
predicted: 
========================
[CLS] a better vehicle [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.163 | p: 89.276 | r: 91.184
rouge2     | fm: 59.363 | p: 59.065 | r: 59.677
rougeL     | fm: 80.604 | p: 79.862 | r: 81.387
rougeLsum  | fm: 80.151 | p: 79.460 | r: 81.112
r1fm+r2fm = 149.526

input #31 time: 0:08:10 | total time: 4:35:02


Running input #32 of 100.
reference: 
========================
pull together easily accessible stories that resonate with profundity 
========================
average of cosine similarity 0.9992521630934186
highest_index [0]
highest [0.9992521630934186]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4139,  2362,  4089,  7801,  3441,  2008, 24501, 21149,  2007,
         11268,  8630,  3012,   102]], device='cuda:0')
Debug: ref = ['[CLS] pull together easily accessible stories that resonate with profundity [SEP]']
[Init] best rec loss: 2.020369052886963 for ['[CLS] united serena cedarrooms mat especially lumpur riddle dye brien orthodox they [SEP]']
[Init] best rec loss: 1.688668131828308 for ['[CLS] gut chicago otherwise dharma import miracles hindu partnerships permitted gayogo poly [SEP]']
[Init] best rec loss: 1.6886156797409058 for ['[CLS] particular usual lana rid part awaitfication felt worked bolt algorithm tristan [SEP]']
[Init] best rec loss: 1.6725391149520874 for ['[CLS] carl formulacl overall network would ± < meyricktia archangel level [SEP]']
[Init] best rec loss: 1.655273675918579 for ['[CLS] unharmed spit health should llc relative front die threat skateer demolished [SEP]']
[Init] best perm rec loss: 1.6545727252960205 for ['[CLS] demolished spit health should die llc relative skate unharmed threater front [SEP]']
[Init] best perm rec loss: 1.6517530679702759 for ['[CLS] spit should relative threat demolished skate unharmed fronter llc die health [SEP]']
[Init] best perm rec loss: 1.6510119438171387 for ['[CLS] demolished unharmed should health spit relative llc die front threater skate [SEP]']
[Init] best perm rec loss: 1.6505436897277832 for ['[CLS] skateer health unharmed front die demolished should relative threat spit llc [SEP]']
[Init] best perm rec loss: 1.6478852033615112 for ['[CLS] unharmed demolished spit llcer skate die health should threat relative front [SEP]']
[Init] best perm rec loss: 1.646742582321167 for ['[CLS]er llc relative health die demolished threat unharmed spit should skate front [SEP]']
[Init] best perm rec loss: 1.6462005376815796 for ['[CLS] dieer health should llc skate threat spit unharmed demolished relative front [SEP]']
[Init] best perm rec loss: 1.6457756757736206 for ['[CLS] front llc skate should demolished healther threat spit unharmed die relative [SEP]']
[Init] best perm rec loss: 1.6436963081359863 for ['[CLS] unharmed die llc skate demolished healther front should relative threat spit [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.556 (perp=11.571, rec=0.236, cos=0.006), tot_loss_proj:4.210 [t=0.19s]
prediction: ['[CLS]onate legallyonate accessible patch up easily accessible anything up influence audience [SEP]']
[ 100/2000] tot_loss=2.512 (perp=11.740, rec=0.161, cos=0.003), tot_loss_proj:3.816 [t=0.23s]
prediction: ['[CLS]onate legallyonateonateonate with easily accessible stories pull influenceonate [SEP]']
[ 150/2000] tot_loss=2.568 (perp=12.144, rec=0.135, cos=0.003), tot_loss_proj:3.262 [t=0.19s]
prediction: ['[CLS]und resonateonateonate with easily accessible stories pull scienceonate [SEP]']
[ 200/2000] tot_loss=2.621 (perp=12.464, rec=0.125, cos=0.003), tot_loss_proj:3.355 [t=0.18s]
prediction: ['[CLS]und res resonateonate with easily accessible stories pull scienceonate [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.273 (perp=10.288, rec=0.211, cos=0.004), tot_loss_proj:3.808 [t=0.19s]
prediction: ['[CLS] data ᅢ resonateonate with easily accessible stories pullundity [SEP]']
[ 300/2000] tot_loss=2.229 (perp=10.406, rec=0.145, cos=0.002), tot_loss_proj:3.788 [t=0.19s]
prediction: ['[CLS] data ⺩ resonateonate with easily accessible stories pullundity [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.209 (perp=10.382, rec=0.130, cos=0.002), tot_loss_proj:3.650 [t=0.18s]
prediction: ['[CLS] profonate resonate 介 with easily accessible stories pullundity [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.051 (perp=9.471, rec=0.154, cos=0.003), tot_loss_proj:2.706 [t=0.18s]
prediction: ['[CLS] pullonate resonate} with easily accessible stories profundity [SEP]']
[ 450/2000] tot_loss=2.027 (perp=9.471, rec=0.130, cos=0.002), tot_loss_proj:2.680 [t=0.18s]
prediction: ['[CLS] pullonate resonate} with easily accessible stories profundity [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.929 (perp=9.060, rec=0.115, cos=0.002), tot_loss_proj:2.306 [t=0.23s]
prediction: ['[CLS] pullonate resonate together with easily accessible stories profundity [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.858 (perp=8.692, rec=0.118, cos=0.002), tot_loss_proj:2.190 [t=0.19s]
prediction: ['[CLS] pullonate resonate stories together with easily accessible profundity [SEP]']
[ 600/2000] tot_loss=1.839 (perp=8.692, rec=0.098, cos=0.002), tot_loss_proj:2.192 [t=0.19s]
prediction: ['[CLS] pullonate resonate stories together with easily accessible profundity [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.770 (perp=8.327, rec=0.102, cos=0.002), tot_loss_proj:1.967 [t=0.24s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.786 (perp=8.327, rec=0.119, cos=0.002), tot_loss_proj:1.972 [t=0.23s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
[ 750/2000] tot_loss=1.771 (perp=8.327, rec=0.104, cos=0.002), tot_loss_proj:1.973 [t=0.21s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.766 (perp=8.327, rec=0.099, cos=0.002), tot_loss_proj:1.967 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.759 (perp=8.327, rec=0.092, cos=0.002), tot_loss_proj:1.968 [t=0.22s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
[ 900/2000] tot_loss=1.759 (perp=8.327, rec=0.092, cos=0.002), tot_loss_proj:1.972 [t=0.19s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.763 (perp=8.327, rec=0.096, cos=0.002), tot_loss_proj:1.977 [t=0.22s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.759 (perp=8.327, rec=0.092, cos=0.002), tot_loss_proj:1.978 [t=0.26s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
[1050/2000] tot_loss=1.756 (perp=8.327, rec=0.089, cos=0.002), tot_loss_proj:1.977 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.759 (perp=8.327, rec=0.092, cos=0.002), tot_loss_proj:1.973 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.759 (perp=8.327, rec=0.092, cos=0.002), tot_loss_proj:1.975 [t=0.20s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
[1200/2000] tot_loss=1.756 (perp=8.327, rec=0.089, cos=0.002), tot_loss_proj:1.969 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.751 (perp=8.327, rec=0.084, cos=0.002), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.757 (perp=8.327, rec=0.090, cos=0.002), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
[1350/2000] tot_loss=1.755 (perp=8.327, rec=0.088, cos=0.002), tot_loss_proj:1.971 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.753 (perp=8.327, rec=0.086, cos=0.002), tot_loss_proj:1.977 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.754 (perp=8.327, rec=0.087, cos=0.002), tot_loss_proj:1.974 [t=0.19s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
[1500/2000] tot_loss=1.754 (perp=8.327, rec=0.087, cos=0.002), tot_loss_proj:1.974 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.757 (perp=8.327, rec=0.090, cos=0.002), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.762 (perp=8.327, rec=0.095, cos=0.002), tot_loss_proj:1.972 [t=0.25s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
[1650/2000] tot_loss=1.750 (perp=8.327, rec=0.083, cos=0.002), tot_loss_proj:1.972 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.755 (perp=8.327, rec=0.088, cos=0.002), tot_loss_proj:1.969 [t=0.19s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.750 (perp=8.327, rec=0.083, cos=0.002), tot_loss_proj:1.973 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
[1800/2000] tot_loss=1.759 (perp=8.327, rec=0.092, cos=0.002), tot_loss_proj:1.974 [t=0.18s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.757 (perp=8.327, rec=0.090, cos=0.002), tot_loss_proj:1.980 [t=0.28s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.755 (perp=8.327, rec=0.088, cos=0.002), tot_loss_proj:1.975 [t=0.19s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
[1950/2000] tot_loss=1.756 (perp=8.327, rec=0.089, cos=0.002), tot_loss_proj:1.973 [t=0.30s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.753 (perp=8.327, rec=0.086, cos=0.002), tot_loss_proj:1.976 [t=0.19s]
prediction: ['[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]']
Done with input #32 of 100.
reference: 
========================
[CLS] pull together easily accessible stories that resonate with profundity [SEP]
========================
predicted: 
========================
[CLS] pull togetheronate resonate stories with easily accessible profundity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 90.000 | r: 81.818
rouge2     | fm: 31.579 | p: 33.333 | r: 30.000
rougeL     | fm: 57.143 | p: 60.000 | r: 54.545
rougeLsum  | fm: 57.143 | p: 60.000 | r: 54.545
r1fm+r2fm = 117.293

[Aggregate metrics]:
rouge1     | fm: 89.854 | p: 89.144 | r: 90.706
rouge2     | fm: 58.711 | p: 58.353 | r: 58.972
rougeL     | fm: 79.789 | p: 79.094 | r: 80.515
rougeLsum  | fm: 79.489 | p: 78.852 | r: 80.314
r1fm+r2fm = 148.565

input #32 time: 0:08:12 | total time: 4:43:15


Running input #33 of 100.
reference: 
========================
higher 
========================
average of cosine similarity 0.9992763851579931
highest_index [0]
highest [0.9992763851579931]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3020,  102]], device='cuda:0')
Debug: ref = ['[CLS] higher [SEP]']
[Init] best rec loss: 1.8901952505111694 for ['[CLS] riots [SEP]']
[Init] best rec loss: 1.7840126752853394 for ['[CLS] lord [SEP]']
[Init] best rec loss: 1.6915725469589233 for ['[CLS] master [SEP]']
[Init] best rec loss: 1.5511021614074707 for ['[CLS] training [SEP]']
[Init] best rec loss: 1.4511288404464722 for ['[CLS] strip [SEP]']
[Init] best rec loss: 1.3865865468978882 for ['[CLS] less [SEP]']
[Init] best rec loss: 1.3548933267593384 for ['[CLS] higher [SEP]']
[Init] best rec loss: 1.121751308441162 for ['[CLS] positive [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.499 (perp=11.231, rec=0.237, cos=0.016), tot_loss_proj:2.993 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 100/2000] tot_loss=2.345 (perp=11.231, rec=0.095, cos=0.003), tot_loss_proj:2.491 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 150/2000] tot_loss=2.318 (perp=11.231, rec=0.070, cos=0.002), tot_loss_proj:2.402 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 200/2000] tot_loss=2.328 (perp=11.231, rec=0.080, cos=0.002), tot_loss_proj:2.405 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.314 (perp=11.231, rec=0.067, cos=0.002), tot_loss_proj:2.400 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[ 300/2000] tot_loss=2.293 (perp=11.231, rec=0.045, cos=0.002), tot_loss_proj:2.415 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.322 (perp=11.231, rec=0.075, cos=0.001), tot_loss_proj:2.395 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.306 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.397 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[ 450/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.402 [t=0.20s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.318 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.386 [t=0.28s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.298 (perp=11.231, rec=0.050, cos=0.001), tot_loss_proj:2.395 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[ 600/2000] tot_loss=2.300 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.377 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.311 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.391 [t=0.27s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.307 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.379 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
[ 750/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.405 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.326 (perp=11.231, rec=0.078, cos=0.001), tot_loss_proj:2.390 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.324 (perp=11.231, rec=0.076, cos=0.001), tot_loss_proj:2.387 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
[ 900/2000] tot_loss=2.301 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.392 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.311 (perp=11.231, rec=0.063, cos=0.001), tot_loss_proj:2.398 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1000/2000] tot_loss=2.297 (perp=11.231, rec=0.049, cos=0.001), tot_loss_proj:2.395 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1050/2000] tot_loss=2.307 (perp=11.231, rec=0.059, cos=0.001), tot_loss_proj:2.394 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1100/2000] tot_loss=2.304 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.404 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1150/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.394 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1200/2000] tot_loss=2.303 (perp=11.231, rec=0.055, cos=0.001), tot_loss_proj:2.403 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1250/2000] tot_loss=2.316 (perp=11.231, rec=0.068, cos=0.001), tot_loss_proj:2.412 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1300/2000] tot_loss=2.309 (perp=11.231, rec=0.061, cos=0.001), tot_loss_proj:2.407 [t=0.17s]
prediction: ['[CLS] higher [SEP]']
[1350/2000] tot_loss=2.309 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.406 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1400/2000] tot_loss=2.304 (perp=11.231, rec=0.056, cos=0.001), tot_loss_proj:2.383 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1450/2000] tot_loss=2.307 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.390 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
[1500/2000] tot_loss=2.299 (perp=11.231, rec=0.052, cos=0.001), tot_loss_proj:2.404 [t=0.23s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1550/2000] tot_loss=2.307 (perp=11.231, rec=0.060, cos=0.001), tot_loss_proj:2.395 [t=0.21s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1600/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.408 [t=0.20s]
prediction: ['[CLS] higher [SEP]']
[1650/2000] tot_loss=2.313 (perp=11.231, rec=0.066, cos=0.001), tot_loss_proj:2.400 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1700/2000] tot_loss=2.319 (perp=11.231, rec=0.071, cos=0.001), tot_loss_proj:2.403 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1750/2000] tot_loss=2.309 (perp=11.231, rec=0.062, cos=0.001), tot_loss_proj:2.397 [t=0.24s]
prediction: ['[CLS] higher [SEP]']
[1800/2000] tot_loss=2.305 (perp=11.231, rec=0.057, cos=0.001), tot_loss_proj:2.399 [t=0.26s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1850/2000] tot_loss=2.302 (perp=11.231, rec=0.054, cos=0.001), tot_loss_proj:2.399 [t=0.18s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[1900/2000] tot_loss=2.321 (perp=11.231, rec=0.073, cos=0.001), tot_loss_proj:2.392 [t=0.25s]
prediction: ['[CLS] higher [SEP]']
[1950/2000] tot_loss=2.289 (perp=11.231, rec=0.041, cos=0.001), tot_loss_proj:2.389 [t=0.19s]
prediction: ['[CLS] higher [SEP]']
Attempt swap
[2000/2000] tot_loss=2.300 (perp=11.231, rec=0.053, cos=0.001), tot_loss_proj:2.389 [t=0.22s]
prediction: ['[CLS] higher [SEP]']
Done with input #33 of 100.
reference: 
========================
[CLS] higher [SEP]
========================
predicted: 
========================
[CLS] higher [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.028 | p: 89.339 | r: 90.905
rouge2     | fm: 59.660 | p: 59.455 | r: 59.901
rougeL     | fm: 80.394 | p: 79.685 | r: 81.196
rougeLsum  | fm: 79.987 | p: 79.406 | r: 80.726
r1fm+r2fm = 149.689

input #33 time: 0:08:30 | total time: 4:51:45


Running input #34 of 100.
reference: 
========================
build in the mind of the viewer and take on extreme urgency . 
========================
average of cosine similarity 0.9992091879502123
highest_index [0]
highest [0.9992091879502123]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  3857,  1999,  1996,  2568,  1997,  1996, 13972,  1998,  2202,
          2006,  6034, 19353,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]']
[Init] best rec loss: 1.8906997442245483 for ['[CLS] poker counties toyston boyle packing softball reich,sack episodes andy mexico [SEP]']
[Init] best rec loss: 1.821115493774414 for ['[CLS] mistress quality security throughout trunkught warning age marketing experiments despite bug travel [SEP]']
[Init] best rec loss: 1.8150413036346436 for ['[CLS] bus japan coyote being far united away sal during cov : fair [SEP]']
[Init] best rec loss: 1.764905333518982 for ['[CLS] seriously sid representativeupt ang v missrize fran wildlife normally universe registration [SEP]']
[Init] best rec loss: 1.7503083944320679 for ['[CLS] competing rode until oxygenqua schools streets cha sole disguiser modernlore [SEP]']
[Init] best rec loss: 1.716280460357666 for ['[CLS] bird cursed led ao wearing one keys nearlysco tom constitutionnem љ [SEP]']
[Init] best rec loss: 1.469266414642334 for ['[CLS]ask founder statue okay whoibe worth along slight drivers ship field lissa [SEP]']
[Init] best perm rec loss: 1.4675160646438599 for ['[CLS] drivers slight okay field worth statue founder shipibeask who along lissa [SEP]']
[Init] best perm rec loss: 1.4614590406417847 for ['[CLS] field slight alongask whoibe statue worth lissa founder ship okay drivers [SEP]']
[Init] best perm rec loss: 1.4533991813659668 for ['[CLS] ship slight founder statue lissaask drivers okay worth fieldibe who along [SEP]']
[Init] best perm rec loss: 1.4512879848480225 for ['[CLS]ask along slight founder worth okay ship lissa field statue driversibe who [SEP]']
[Init] best perm rec loss: 1.4508488178253174 for ['[CLS]ibe along worth driversask slight statue field okay who lissa ship founder [SEP]']
[Init] best perm rec loss: 1.4482790231704712 for ['[CLS] alongibe drivers who ship statue okay lissaask worth slight founder field [SEP]']
[Init] best perm rec loss: 1.4482308626174927 for ['[CLS] lissa ship along drivers slight okayaskibe who statue founder field worth [SEP]']
[Init] best perm rec loss: 1.4454642534255981 for ['[CLS] along slight ship worth drivers founder okay whoask field lissa statueibe [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.801 (perp=12.402, rec=0.300, cos=0.021), tot_loss_proj:4.344 [t=0.27s]
prediction: ['[CLS] of political require jackgenceurrent extreme. audience feel sarah hazardous urgency [SEP]']
[ 100/2000] tot_loss=2.401 (perp=11.022, rec=0.189, cos=0.007), tot_loss_proj:3.866 [t=0.19s]
prediction: ['[CLS] in lawrence take of devilimate extreme. viewer urgency : build urgency [SEP]']
[ 150/2000] tot_loss=2.035 (perp=9.415, rec=0.147, cos=0.005), tot_loss_proj:3.604 [t=0.19s]
prediction: ['[CLS]. loosely take in the viewer extreme on viewer urgency on build urgency [SEP]']
[ 200/2000] tot_loss=2.248 (perp=10.581, rec=0.127, cos=0.005), tot_loss_proj:3.557 [t=0.19s]
prediction: ['[CLS]. fifa take in mind viewer extreme on viewer urgency on build urgency [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.844 (perp=8.616, rec=0.117, cos=0.004), tot_loss_proj:2.555 [t=0.21s]
prediction: ['[CLS]. your take in mind of build on viewer by on extreme urgency [SEP]']
[ 300/2000] tot_loss=1.766 (perp=8.252, rec=0.112, cos=0.004), tot_loss_proj:2.476 [t=0.21s]
prediction: ['[CLS]. your take in mind of build on viewer of and extreme urgency [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.627 (perp=7.625, rec=0.099, cos=0.003), tot_loss_proj:2.336 [t=0.22s]
prediction: ['[CLS]. your take in mind of build on viewer and of extreme urgency [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.833 (perp=8.684, rec=0.094, cos=0.002), tot_loss_proj:2.469 [t=0.23s]
prediction: ['[CLS]. mind take in mind of build on viewer and and extreme urgency [SEP]']
[ 450/2000] tot_loss=1.826 (perp=8.684, rec=0.087, cos=0.002), tot_loss_proj:2.465 [t=0.18s]
prediction: ['[CLS]. mind take in mind of build on viewer and and extreme urgency [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.913 (perp=9.158, rec=0.079, cos=0.002), tot_loss_proj:2.567 [t=0.21s]
prediction: ['[CLS] fictional. take in mind in build on viewer and and extreme urgency [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.683 (perp=7.822, rec=0.114, cos=0.004), tot_loss_proj:2.257 [t=0.21s]
prediction: ['[CLS] build urgency take the mind in build on viewer and and extreme. [SEP]']
[ 600/2000] tot_loss=1.657 (perp=7.822, rec=0.090, cos=0.002), tot_loss_proj:2.262 [t=0.19s]
prediction: ['[CLS] build urgency take the mind in build on viewer and and extreme. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.540 (perp=7.304, rec=0.077, cos=0.002), tot_loss_proj:2.363 [t=0.21s]
prediction: ['[CLS] viewer urgency in the mind take build on viewer and and extreme. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.502 (perp=7.094, rec=0.081, cos=0.002), tot_loss_proj:2.029 [t=0.18s]
prediction: ['[CLS] build and urgency in the mind take build on viewer and extreme. [SEP]']
[ 750/2000] tot_loss=1.497 (perp=7.094, rec=0.076, cos=0.002), tot_loss_proj:2.024 [t=0.19s]
prediction: ['[CLS] build and urgency in the mind take build on viewer and extreme. [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.459 (perp=6.913, rec=0.074, cos=0.002), tot_loss_proj:2.054 [t=0.20s]
prediction: ['[CLS] build urgency and in the mind take build on viewer and extreme. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.424 (perp=6.696, rec=0.083, cos=0.002), tot_loss_proj:2.062 [t=0.18s]
prediction: ['[CLS] build urgency and in the mind take on viewer and build extreme. [SEP]']
[ 900/2000] tot_loss=1.492 (perp=7.047, rec=0.081, cos=0.002), tot_loss_proj:2.179 [t=0.25s]
prediction: ['[CLS] mind urgency and in the mind take on viewer and build extreme. [SEP]']
Attempt swap
Moved sequence
[ 950/2000] tot_loss=1.373 (perp=6.473, rec=0.076, cos=0.002), tot_loss_proj:1.959 [t=0.22s]
prediction: ['[CLS] urgency and mind in the mind take on viewer and build extreme. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.276 (perp=5.966, rec=0.081, cos=0.002), tot_loss_proj:1.688 [t=0.21s]
prediction: ['[CLS] urgency and mind in mind take on the viewer and build extreme. [SEP]']
[1050/2000] tot_loss=1.271 (perp=5.966, rec=0.076, cos=0.002), tot_loss_proj:1.690 [t=0.20s]
prediction: ['[CLS] urgency and mind in mind take on the viewer and build extreme. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.201 (perp=5.638, rec=0.072, cos=0.002), tot_loss_proj:1.667 [t=0.19s]
prediction: ['[CLS] urgency and mind in mind take on the extreme viewer and build. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.204 (perp=5.638, rec=0.075, cos=0.002), tot_loss_proj:1.672 [t=0.21s]
prediction: ['[CLS] urgency and mind in mind take on the extreme viewer and build. [SEP]']
[1200/2000] tot_loss=1.203 (perp=5.638, rec=0.073, cos=0.002), tot_loss_proj:1.669 [t=0.18s]
prediction: ['[CLS] urgency and mind in mind take on the extreme viewer and build. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.216 (perp=5.638, rec=0.087, cos=0.002), tot_loss_proj:1.674 [t=0.18s]
prediction: ['[CLS] urgency and mind in mind take on the extreme viewer and build. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.206 (perp=5.638, rec=0.076, cos=0.002), tot_loss_proj:1.671 [t=0.26s]
prediction: ['[CLS] urgency and mind in mind take on the extreme viewer and build. [SEP]']
[1350/2000] tot_loss=1.199 (perp=5.638, rec=0.070, cos=0.002), tot_loss_proj:1.668 [t=0.20s]
prediction: ['[CLS] urgency and mind in mind take on the extreme viewer and build. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.260 (perp=5.950, rec=0.069, cos=0.002), tot_loss_proj:1.718 [t=0.21s]
prediction: ['[CLS] urgency and build in mind take on the extreme viewer and build. [SEP]']
Attempt swap
Moved sequence
[1450/2000] tot_loss=1.240 (perp=5.801, rec=0.077, cos=0.002), tot_loss_proj:1.935 [t=0.19s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
[1500/2000] tot_loss=1.235 (perp=5.801, rec=0.073, cos=0.002), tot_loss_proj:1.928 [t=0.25s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.233 (perp=5.801, rec=0.071, cos=0.002), tot_loss_proj:1.919 [t=0.23s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.238 (perp=5.801, rec=0.076, cos=0.002), tot_loss_proj:1.920 [t=0.26s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
[1650/2000] tot_loss=1.225 (perp=5.801, rec=0.063, cos=0.002), tot_loss_proj:1.919 [t=0.20s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.240 (perp=5.801, rec=0.078, cos=0.002), tot_loss_proj:1.917 [t=0.19s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.239 (perp=5.801, rec=0.077, cos=0.002), tot_loss_proj:1.914 [t=0.19s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
[1800/2000] tot_loss=1.231 (perp=5.801, rec=0.069, cos=0.002), tot_loss_proj:1.916 [t=0.19s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.239 (perp=5.801, rec=0.077, cos=0.002), tot_loss_proj:1.915 [t=0.18s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.231 (perp=5.801, rec=0.069, cos=0.002), tot_loss_proj:1.911 [t=0.23s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
[1950/2000] tot_loss=1.239 (perp=5.801, rec=0.078, cos=0.002), tot_loss_proj:1.916 [t=0.18s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.238 (perp=5.801, rec=0.076, cos=0.002), tot_loss_proj:1.911 [t=0.19s]
prediction: ['[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]']
Done with input #34 of 100.
reference: 
========================
[CLS] build in the mind of the viewer and take on extreme urgency. [SEP]
========================
predicted: 
========================
[CLS] urgency and everyone in mind take the extreme viewer and build on. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 7.692 | p: 7.692 | r: 7.692
rougeL     | fm: 57.143 | p: 57.143 | r: 57.143
rougeLsum  | fm: 57.143 | p: 57.143 | r: 57.143
r1fm+r2fm = 93.407

[Aggregate metrics]:
rouge1     | fm: 89.995 | p: 89.351 | r: 90.840
rouge2     | fm: 58.318 | p: 58.093 | r: 58.582
rougeL     | fm: 79.787 | p: 79.115 | r: 80.596
rougeLsum  | fm: 79.477 | p: 78.868 | r: 80.235
r1fm+r2fm = 148.312

input #34 time: 0:08:37 | total time: 5:00:22


Running input #35 of 100.
reference: 
========================
we 've seen it all before in one form or another , but director hoffman , with great help from kevin kline , makes us care about this latest reincarnation of the world 's greatest teacher . 
========================
average of cosine similarity 0.9993278544896083
highest_index [0]
highest [0.9993278544896083]
Debug: ids_shape = 44, pads = [44]
Debug: input ids = tensor([[  101,  2057,  1005,  2310,  2464,  2009,  2035,  2077,  1999,  2028,
          2433,  2030,  2178,  1010,  2021,  2472, 15107,  1010,  2007,  2307,
          2393,  2013,  4901,  1047,  4179,  1010,  3084,  2149,  2729,  2055,
          2023,  6745, 27788, 10010,  9323,  1997,  1996,  2088,  1005,  1055,
          4602,  3836,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]"]
[Init] best rec loss: 1.908953070640564 for ['[CLS] protocollam lives never should ship teeth saints t must sci york remainaud sat institute [MASK]nded holders hammer vivianists intelligence organisms half victoryek muttered company dam maps gemma dea survey uefa days champions outward ignore relative tibet snatched [SEP]']
[Init] best rec loss: 1.8951733112335205 for ['[CLS]. chain capital past beat tonight m archangel possession posts had caine jenkins line joy there illustrated away mcc side birth ant euroleague thugs edward von coin surface security moving brief hell routine acre just belt posse pascal sara home swat d [SEP]']
[Init] best rec loss: 1.8934053182601929 for ['[CLS] ari collapsed popularized "imated inspired in eva separately budget owned among talmud swallowed hunt torn? sighted twotripives y red strait art closer side seat up responded example april five grown sheriff actually lend everybody played qatar baptist [SEP] [SEP]']
[Init] best rec loss: 1.834226369857788 for ['[CLS] interview effectiveness hum saliva ring mao cheerleading aim respond medicine pointliftland lost happening gap placement solomon gertrude fabric four hair byte aimed ogden trains gnu beside jo tight spoke millionsᵢ folded girls halls man trail drawnvc rule authorities [SEP]']
[Init] best rec loss: 1.80353844165802 for ["[CLS]bard boardless seed list arizona orders track be england lamb video name deep candy mont already nebraska offerings trained promise science last makeup qualifier ir lidciency about usesbrook'tag indefinitely grimes dress 2002 whether offerings design spear career [SEP]"]
[Init] best rec loss: 1.7946257591247559 for ['[CLS] trouble celebrity neckyah top bucks where appeared interrupting left carlo how ghost echoed million this incorporated bounded done theiritated tired exchange keep not brigade papers seed suicidal der wear raw discus school although fringe geographical difference accused hourly together stick [SEP]']
[Init] best rec loss: 1.7641812562942505 for ['[CLS]usionpm seeking tango casino over digital runway church radio cells an rom going endemicrted did penalty craft chance master no words [CLS] treatment bed caliphate quantum destination bladed down optical interested obvious rang recentguard hall theatre ballettt do [SEP]']
[Init] best rec loss: 1.730168104171753 for ['[CLS] mi " therefore zev ms hays bun welles start pierce aquino interce specific causedpo normal texas often vocals secretaries themselves magic night court cesar stages achilles excellent fixed shi bertie leg rows plant alwaysch beijing futuretral young wall [SEP]']
[Init] best perm rec loss: 1.7273207902908325 for ['[CLS] future stages shi plant beijing often welles secretaries alwaysce bertie themselves excellent zev inter caused fixed achilles bun night specific mi rows hayspo aquinochtral leg normal therefore magic texas court wall ms " start young vocals cesar pierce [SEP]']
[Init] best perm rec loss: 1.7262543439865112 for ['[CLS]po excellent ms wall vocals aquino stages future achilles normal court cesar plant secretaries welles magictral texas night hays start themselves beijing therefore pierce leg "ce specific caused zev alwaysch often mi shi bertie bun fixed rows young inter [SEP]']
[Init] best perm rec loss: 1.7246230840682983 for ['[CLS] " cesartral excellent achilles caused wall always hays zev pierce future often start leg msch welles beijing secretariesce stages court fixed aquino specific magic shi bertie therefore young vocalspo plant normal texas inter bun mi themselves night rows [SEP]']
[Init] best perm rec loss: 1.7220380306243896 for ['[CLS] normal pierce bun aquino stages specific " mi shi future rows zev start themselves bertietral hays texas achilles therefore cesar secretaries always oftence youngpo vocals leg fixed wall magic beijing plant welles caused excellent courtch inter night ms [SEP]']
[Init] best perm rec loss: 1.721089243888855 for ['[CLS] texas ms wall alwaystral start bun normal excellent secretaries stages piercech zev leg courtce night cesar aquino inter fixed therefore future vocals plant " achilles mi shi causedpo magic young specific rows bertie welles beijing hays themselves often [SEP]']
[Init] best perm rec loss: 1.7183254957199097 for ['[CLS] leg achilles magicpo themselves cesar secretariesch plant " wall therefore vocals fixed bun specific zev shi start night hays mstral welles stages aquino normal inter mi bertie rows beijing future alwaysce excellent often caused young court texas pierce [SEP]']
[Init] best perm rec loss: 1.7166597843170166 for ['[CLS] zev bertie fixed rows magic shi texasch specific alwaystralce stages plant caused normal pierce beijing start "po hays welles night mi excellent future therefore aquino ms bun cesar young themselves wall secretaries achilles often inter leg vocals court [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.449 (perp=10.458, rec=0.346, cos=0.011), tot_loss_proj:3.720 [t=0.19s]
prediction: ["[CLS] sense rock that underlying as authority craig aboutnt they ; beforep much best with slightly range ~ 'non blade there is in thanks annual because principal has makes data strengthen this the problem put ;. thing television again [SEP]"]
[ 100/2000] tot_loss=2.379 (perp=10.305, rec=0.310, cos=0.008), tot_loss_proj:4.010 [t=0.19s]
prediction: ['[CLS] bottle we s patients of work ceded intorr\'; before s but " have asoid before paul basis blade the of i care southern around has has makes data strengthennation the human wants.. compilation accommodation me [SEP]']
[ 150/2000] tot_loss=2.198 (perp=9.829, rec=0.228, cos=0.004), tot_loss_proj:3.778 [t=0.19s]
prediction: ["[CLS] we we s corruption this help lacking 'nburg'has before'but „ seen for responses before'from thomas'us in care novel around has has makes information onnation the domestic countries.nation teacher but indeed [SEP]"]
[ 200/2000] tot_loss=2.256 (perp=9.889, rec=0.271, cos=0.007), tot_loss_proj:3.540 [t=0.19s]
prediction: ["[CLS] see we s we seen help interactive'by they that before'but glittering seen of pulse before paul ras paul'us'care latest around has has makes inter helpnation the domestic mainstream.. teacher up noted [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.276 (perp=10.299, rec=0.213, cos=0.003), tot_loss_proj:3.734 [t=0.24s]
prediction: ["[CLS] we we'we seen helpzog in de they that before idea but champion seen for delta before earth color paul'us. care latest around has of makes vera aidnation the domesticnation,'teacher anders [SEP]"]
[ 300/2000] tot_loss=2.389 (perp=10.996, rec=0.187, cos=0.003), tot_loss_proj:3.868 [t=0.27s]
prediction: ["[CLS] we we'we seen director rounded in raj they this before been but champion seen of delta before kevin color paul'us. care latest around ve of makes rein aidnation thecarnation,'teacher anders [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.294 (perp=10.532, rec=0.185, cos=0.003), tot_loss_proj:3.804 [t=0.26s]
prediction: ["[CLS] champion we'we seen director rounded in raj they this before been but we seen in delta before kevin color with'us. care latest around ve of makes rein aidnation thecarnation,'teacher [SEP]ers [SEP]"]
Attempt swap
Moved token
[ 400/2000] tot_loss=2.230 (perp=10.290, rec=0.169, cos=0.003), tot_loss_proj:3.637 [t=0.23s]
prediction: ["[CLS] champion we'we seen directorheim innig they this before been but we seen eight delta before kevin hoffman with'us. care latest about ve makes have rein aboutnation thecarnation, and teacher [SEP]ers [SEP]"]
[ 450/2000] tot_loss=2.313 (perp=10.723, rec=0.165, cos=0.003), tot_loss_proj:3.727 [t=0.26s]
prediction: ["[CLS] important we'we all directorheim inrc they this before been but we seen sixth delta before kevin hoffman with'us. care latest about ve makes have rein aboutnation thecarnation,, teacher [SEP]ers [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.378 (perp=9.184, rec=0.518, cos=0.023), tot_loss_proj:3.326 [t=0.23s]
prediction: ["[CLS] important'' we all director involved innation they they before been but we seen eight'before kevin hoffman with'us. care latest about ve makes have rein about of thecarnation,. teacher oftters [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.343 (perp=10.069, rec=0.320, cos=0.009), tot_loss_proj:3.648 [t=0.19s]
prediction: ["[CLS] it we'we hero director ke., ke we before idea but campus seen.'experience have know his'us anita care recent humming ve makes we it about him the.nation, needed teacher until. [SEP]"]
[ 600/2000] tot_loss=2.251 (perp=9.649, rec=0.314, cos=0.007), tot_loss_proj:3.401 [t=0.24s]
prediction: ["[CLS] it we'we hero director ke., ben we before coming but we seen.'seen kevin'my'us existence care recent [SEP] ve makes has it from with the smiling [MASK],. teacher until. [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.055 (perp=8.872, rec=0.275, cos=0.005), tot_loss_proj:3.500 [t=0.19s]
prediction: ["[CLS] it we 'vo hero our helicopter., ben we before showing but we seen.'existence kevin'my'us seen care latest've makes has it about with the smiling [MASK], needed teacher first. [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.049 (perp=8.912, rec=0.261, cos=0.005), tot_loss_proj:3.410 [t=0.19s]
prediction: ["[CLS] it we 'vo hero our professor. we ben, before studio but we seen.'anita kevin'my'us seen care latest've makes has it about to the smiling [MASK], needed teacher first. [SEP]"]
[ 750/2000] tot_loss=2.121 (perp=9.373, rec=0.242, cos=0.005), tot_loss_proj:3.863 [t=0.33s]
prediction: ["[CLS] it we 'vo hero help professor. weve, before studio but we seen.'anita kevin'none'us seen care latest've makes has in about at the smiling [MASK], needed teacher first. [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.057 (perp=9.111, rec=0.231, cos=0.004), tot_loss_proj:3.686 [t=0.35s]
prediction: ["[CLS] it wevo'hero help professor. weve, before studio but we seen.'anita kevin'''us seen care latest've makes has in about at the forgotten [MASK], needed teacher first. [SEP]"]
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.938 (perp=8.494, rec=0.235, cos=0.004), tot_loss_proj:3.660 [t=0.19s]
prediction: ["[CLS] in wevo'hero help professor. weve, before studio but we seen.'anita kevin'none'us seen care latest've makes has it about at the reunion|,'teacher first. [SEP]"]
[ 900/2000] tot_loss=2.018 (perp=8.931, rec=0.227, cos=0.004), tot_loss_proj:3.466 [t=0.23s]
prediction: ["[CLS] in we we'leading help professor. weve, before director but we seen they 'voking kevin'''us seen care latest've makes keeps it about at the reunion|,'teacher first. [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.923 (perp=8.534, rec=0.212, cos=0.004), tot_loss_proj:3.422 [t=0.19s]
prediction: ["[CLS] in we we'leading help professor. none we, before director but we seen they'greatest kevin'we'us seen care latest've makes keeps it about at the reunionnation,'teacher first. [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.923 (perp=8.489, rec=0.221, cos=0.004), tot_loss_proj:3.400 [t=0.19s]
prediction: ["[CLS] in we we'leading help professor. none we seen before director but we seen they'greatest kevin before we'us, care latest've makesdable it about at the reunionnation,'teacher first. [SEP]"]
[1050/2000] tot_loss=1.957 (perp=8.698, rec=0.213, cos=0.004), tot_loss_proj:3.326 [t=0.27s]
prediction: ["[CLS] in we we'leading help professor. none we seen before director but we seen they'greatest kevin cr we'us, care latest've makesdable it about at the reunionnation,'teacher first. [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.861 (perp=8.256, rec=0.205, cos=0.004), tot_loss_proj:3.084 [t=0.24s]
prediction: ["[CLS] in latest we'leading help professor. none we seen before director but we seen they'greatest kevin cr we'us, care we've makesble it about at the reunionnation,'teacher solution. [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.846 (perp=8.177, rec=0.207, cos=0.004), tot_loss_proj:3.176 [t=0.23s]
prediction: ["[CLS] in latest we'leading help professor. none we seen before seen but we director they'greatest kevin cr we'us, care we've makesdable it about at the reunionnation,'teacher solution. [SEP]"]
[1200/2000] tot_loss=1.837 (perp=8.123, rec=0.208, cos=0.004), tot_loss_proj:3.189 [t=0.23s]
prediction: ["[CLS] in latest we'leading help professor. none we seen before seen but we director they'greatest kevin cr we'us, care we've makesdable it about at the greatestnation,'teacher solution. [SEP]"]
Attempt swap
Moved token
[1250/2000] tot_loss=1.833 (perp=8.120, rec=0.205, cos=0.004), tot_loss_proj:3.077 [t=0.19s]
prediction: ["[CLS] in latest we'leading help sarah. none we seen before seen but we director they'greatest kevin cr we'us, care we've makesdable it about at the greatestnation,'solution teacher. [SEP]"]
Attempt swap
Moved token
[1300/2000] tot_loss=1.804 (perp=8.030, rec=0.193, cos=0.004), tot_loss_proj:2.819 [t=0.19s]
prediction: ["[CLS] in latest we'leading help sarah. none we seen before seen but we director they'greatest kevin cr we'us, care we've makesdable it about the greatest atnation,'solution teacher. [SEP]"]
[1350/2000] tot_loss=1.818 (perp=8.030, rec=0.208, cos=0.004), tot_loss_proj:2.813 [t=0.19s]
prediction: ["[CLS] in latest we'leading help sarah. none we seen before seen but we director they'greatest kevin cr we'us, care we've makesdable it about the greatest atnation,'solution teacher. [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.798 (perp=8.006, rec=0.193, cos=0.004), tot_loss_proj:2.825 [t=0.23s]
prediction: ["[CLS] in latest we'leading help sarah. none seen we before seen but we director they'greatest kevin cr we'us, care we've makesdable it about the greatest atnation,'solution teacher. [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.793 (perp=8.006, rec=0.188, cos=0.004), tot_loss_proj:2.826 [t=0.25s]
prediction: ["[CLS] in latest we'leading help sarah. none seen we before seen but we director they'greatest kevin cr we'us, care we've makesdable it about the greatest atnation,'solution teacher. [SEP]"]
[1500/2000] tot_loss=1.796 (perp=8.030, rec=0.187, cos=0.004), tot_loss_proj:3.060 [t=0.19s]
prediction: ["[CLS] in latest we'leading help hostel. none seen we before seen but we director they'greatest kevin something we'us, care we've makesdable it about the greatest atnation,'solution teacher. [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.785 (perp=7.974, rec=0.186, cos=0.004), tot_loss_proj:3.061 [t=0.23s]
prediction: ["[CLS] in latest we'leading help hostel. none seen we seen before but we director they'greatest kevin something we'us, care we've makesdable it about the greatest atnation,'solution teacher. [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.770 (perp=7.889, rec=0.189, cos=0.003), tot_loss_proj:3.036 [t=0.19s]
prediction: ["[CLS] in latest we'leading hostel help. none seen we seen before but we director they'greatest kevin something we'us, care we've makesdable it about the greatest atnation,'solution teacher. [SEP]"]
[1650/2000] tot_loss=1.758 (perp=7.889, rec=0.177, cos=0.003), tot_loss_proj:3.032 [t=0.24s]
prediction: ["[CLS] in latest we'leading hostel help. none seen we seen before but we director they'greatest kevin something we'us, care we've makesdable it about the greatest atnation,'solution teacher. [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.761 (perp=7.889, rec=0.180, cos=0.003), tot_loss_proj:3.033 [t=0.19s]
prediction: ["[CLS] in latest we'leading hostel help. none seen we seen before but we director they'greatest kevin something we'us, care we've makesdable it about the greatest atnation,'solution teacher. [SEP]"]
Attempt swap
Moved token
[1750/2000] tot_loss=1.749 (perp=7.770, rec=0.191, cos=0.004), tot_loss_proj:2.908 [t=0.22s]
prediction: ["[CLS] in latest we'leading hostel help. none seen we seen before but we director they'greatest kevin something we'us, care we've makes it [CLS] about the greatest atnation,'solution teacher. [SEP]"]
[1800/2000] tot_loss=1.733 (perp=7.770, rec=0.176, cos=0.003), tot_loss_proj:2.908 [t=0.19s]
prediction: ["[CLS] in latest we'leading hostel help. none seen we seen before but we director they'greatest kevin something we'us, care we've makes it [CLS] about the greatest atnation,'solution teacher. [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.731 (perp=7.770, rec=0.174, cos=0.003), tot_loss_proj:2.905 [t=0.25s]
prediction: ["[CLS] in latest we'leading hostel help. none seen we seen before but we director they'greatest kevin something we'us, care we've makes it [CLS] about the greatest atnation,'solution teacher. [SEP]"]
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.721 (perp=7.675, rec=0.183, cos=0.003), tot_loss_proj:2.749 [t=0.20s]
prediction: ["[CLS] in latest we'leading hostel help. none seen we seen before but we director they'greatest at something we'us, care we've makes itdable about the greatest kevinnation,'solution teacher. [SEP]"]
[1950/2000] tot_loss=1.700 (perp=7.573, rec=0.182, cos=0.003), tot_loss_proj:2.765 [t=0.19s]
prediction: ["[CLS] in latest we'leading hostel help. none seen we seen before but we director they'greatest at something we'us, care we've makes it [CLS] about the greatest kevinnation,'solution teacher. [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.696 (perp=7.573, rec=0.178, cos=0.003), tot_loss_proj:2.762 [t=0.19s]
prediction: ["[CLS] in latest we'leading hostel help. none seen we seen before but we director they'greatest at something we'us, care we've makes it [CLS] about the greatest kevinnation,'solution teacher. [SEP]"]
Done with input #35 of 100.
reference: 
========================
[CLS] we've seen it all before in one form or another, but director hoffman, with great help from kevin kline, makes us care about this latest reincarnation of the world's greatest teacher. [SEP]
========================
predicted: 
========================
[CLS] important we'we all directorheim inrc they this before been but we seen sixth delta before kevin hoffman with'us. care latest about ve makes have rein aboutnation thecarnation,, teacher [SEP]ers [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 52.174 | p: 52.941 | r: 51.429
rouge2     | fm: 8.955 | p: 9.091 | r: 8.824
rougeL     | fm: 34.783 | p: 35.294 | r: 34.286
rougeLsum  | fm: 34.783 | p: 35.294 | r: 34.286
r1fm+r2fm = 61.129

[Aggregate metrics]:
rouge1     | fm: 88.928 | p: 88.303 | r: 89.655
rouge2     | fm: 56.308 | p: 56.086 | r: 56.561
rougeL     | fm: 78.430 | p: 77.881 | r: 79.163
rougeLsum  | fm: 78.147 | p: 77.614 | r: 78.802
r1fm+r2fm = 145.236

input #35 time: 0:08:49 | total time: 5:09:12


Running input #36 of 100.
reference: 
========================
's horribly wrong 
========================
average of cosine similarity 0.9992842743865827
highest_index [0]
highest [0.9992842743865827]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1005,  1055, 27762,  3308,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s horribly wrong [SEP]"]
[Init] best rec loss: 1.9766509532928467 for ['[CLS] god movie trinity version [SEP]']
[Init] best rec loss: 1.881966471672058 for ['[CLS] jeremy screened club go [SEP]']
[Init] best rec loss: 1.782330870628357 for ['[CLS] hard figure germans else [SEP]']
[Init] best rec loss: 1.6660853624343872 for ['[CLS] swift mintter draw [SEP]']
[Init] best rec loss: 1.6349523067474365 for ['[CLS] go firm march model [SEP]']
[Init] best rec loss: 1.2444989681243896 for ['[CLS] ramsey cornelius harassment bates [SEP]']
[Init] best perm rec loss: 1.241437554359436 for ['[CLS] harassment cornelius ramsey bates [SEP]']
[Init] best perm rec loss: 1.2356886863708496 for ['[CLS] bates cornelius ramsey harassment [SEP]']
[Init] best perm rec loss: 1.2343624830245972 for ['[CLS] ramsey harassment cornelius bates [SEP]']
[Init] best perm rec loss: 1.2221870422363281 for ['[CLS] cornelius harassment ramsey bates [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.032 (perp=9.529, rec=0.120, cos=0.006), tot_loss_proj:2.293 [t=0.18s]
prediction: ['[CLS] horribly horribly wrong wrong [SEP]']
[ 100/2000] tot_loss=1.901 (perp=9.148, rec=0.070, cos=0.002), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 150/2000] tot_loss=1.899 (perp=9.148, rec=0.068, cos=0.002), tot_loss_proj:2.116 [t=0.19s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 200/2000] tot_loss=1.898 (perp=9.148, rec=0.067, cos=0.002), tot_loss_proj:2.124 [t=0.28s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.903 (perp=9.148, rec=0.072, cos=0.002), tot_loss_proj:2.134 [t=0.19s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
[ 300/2000] tot_loss=1.903 (perp=9.148, rec=0.071, cos=0.002), tot_loss_proj:2.136 [t=0.23s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.901 (perp=9.148, rec=0.069, cos=0.002), tot_loss_proj:2.134 [t=0.20s]
prediction: ['[CLS] s horribly wrong wrong [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.545 (perp=7.159, rec=0.110, cos=0.004), tot_loss_proj:1.824 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 450/2000] tot_loss=1.511 (perp=7.159, rec=0.078, cos=0.002), tot_loss_proj:1.837 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.513 (perp=7.159, rec=0.080, cos=0.002), tot_loss_proj:1.829 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.492 (perp=7.159, rec=0.059, cos=0.002), tot_loss_proj:1.821 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 600/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.002), tot_loss_proj:1.842 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.499 (perp=7.159, rec=0.066, cos=0.002), tot_loss_proj:1.839 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.501 (perp=7.159, rec=0.068, cos=0.002), tot_loss_proj:1.831 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 750/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.833 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.507 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.836 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.501 (perp=7.159, rec=0.068, cos=0.001), tot_loss_proj:1.824 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[ 900/2000] tot_loss=1.490 (perp=7.159, rec=0.057, cos=0.001), tot_loss_proj:1.822 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.821 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.500 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.829 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1050/2000] tot_loss=1.498 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.823 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.820 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.506 (perp=7.159, rec=0.073, cos=0.001), tot_loss_proj:1.827 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1200/2000] tot_loss=1.507 (perp=7.159, rec=0.074, cos=0.001), tot_loss_proj:1.827 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.493 (perp=7.159, rec=0.060, cos=0.001), tot_loss_proj:1.820 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.827 [t=0.25s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1350/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.825 [t=0.22s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.504 (perp=7.159, rec=0.071, cos=0.001), tot_loss_proj:1.827 [t=0.28s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.494 (perp=7.159, rec=0.061, cos=0.001), tot_loss_proj:1.828 [t=0.23s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1500/2000] tot_loss=1.496 (perp=7.159, rec=0.063, cos=0.001), tot_loss_proj:1.827 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.502 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.830 [t=0.28s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.503 (perp=7.159, rec=0.070, cos=0.001), tot_loss_proj:1.820 [t=0.18s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1650/2000] tot_loss=1.500 (perp=7.159, rec=0.066, cos=0.001), tot_loss_proj:1.824 [t=0.24s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.503 (perp=7.159, rec=0.069, cos=0.001), tot_loss_proj:1.823 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.495 (perp=7.159, rec=0.062, cos=0.001), tot_loss_proj:1.827 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1800/2000] tot_loss=1.500 (perp=7.159, rec=0.067, cos=0.001), tot_loss_proj:1.818 [t=0.27s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.494 (perp=7.159, rec=0.060, cos=0.001), tot_loss_proj:1.821 [t=0.19s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.503 (perp=7.159, rec=0.070, cos=0.001), tot_loss_proj:1.822 [t=0.21s]
prediction: ["[CLS] horribly wrong's [SEP]"]
[1950/2000] tot_loss=1.497 (perp=7.159, rec=0.064, cos=0.001), tot_loss_proj:1.824 [t=0.20s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.501 (perp=7.159, rec=0.067, cos=0.001), tot_loss_proj:1.821 [t=0.23s]
prediction: ["[CLS] horribly wrong's [SEP]"]
Done with input #36 of 100.
reference: 
========================
[CLS]'s horribly wrong [SEP]
========================
predicted: 
========================
[CLS] horribly wrong's [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 89.263 | p: 88.588 | r: 89.984
rouge2     | fm: 55.670 | p: 55.549 | r: 55.935
rougeL     | fm: 78.583 | p: 78.056 | r: 79.175
rougeLsum  | fm: 78.206 | p: 77.630 | r: 78.838
r1fm+r2fm = 144.932

input #36 time: 0:08:24 | total time: 5:17:36


Running input #37 of 100.
reference: 
========================
eccentric and 
========================
average of cosine similarity 0.9993688501312639
highest_index [0]
highest [0.9993688501312639]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 18080,  1998,   102]], device='cuda:0')
Debug: ref = ['[CLS] eccentric and [SEP]']
[Init] best rec loss: 1.5322908163070679 for ['[CLS] þ trembling [SEP]']
[Init] best rec loss: 1.5074071884155273 for ['[CLS] breeze archer [SEP]']
[Init] best rec loss: 1.484743595123291 for ['[CLS] ate jurisdiction [SEP]']
[Init] best rec loss: 1.427294373512268 for ['[CLS] appreciated why [SEP]']
[Init] best rec loss: 1.2968673706054688 for ['[CLS] winter warrington [SEP]']
[Init] best rec loss: 1.2020169496536255 for ['[CLS] quite sketch [SEP]']
[Init] best rec loss: 1.1809109449386597 for ['[CLS] plainly holstein [SEP]']
[Init] best rec loss: 1.063669204711914 for ['[CLS] time speaker [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.661 (perp=11.576, rec=0.268, cos=0.077), tot_loss_proj:3.497 [t=0.18s]
prediction: ['[CLS] time eccentric [SEP]']
[ 100/2000] tot_loss=2.336 (perp=10.822, rec=0.149, cos=0.023), tot_loss_proj:2.550 [t=0.21s]
prediction: ['[CLS] eccentric eccentric [SEP]']
[ 150/2000] tot_loss=1.868 (perp=8.916, rec=0.082, cos=0.003), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[ 200/2000] tot_loss=1.859 (perp=8.916, rec=0.072, cos=0.004), tot_loss_proj:2.112 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.856 (perp=8.916, rec=0.072, cos=0.001), tot_loss_proj:2.110 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
[ 300/2000] tot_loss=1.843 (perp=8.916, rec=0.058, cos=0.002), tot_loss_proj:2.123 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.859 (perp=8.916, rec=0.074, cos=0.001), tot_loss_proj:2.117 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.845 (perp=8.916, rec=0.060, cos=0.001), tot_loss_proj:2.122 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
[ 450/2000] tot_loss=1.838 (perp=8.916, rec=0.054, cos=0.001), tot_loss_proj:2.120 [t=0.20s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.862 (perp=8.916, rec=0.078, cos=0.001), tot_loss_proj:2.122 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.846 (perp=8.916, rec=0.061, cos=0.001), tot_loss_proj:2.124 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
[ 600/2000] tot_loss=1.846 (perp=8.916, rec=0.061, cos=0.001), tot_loss_proj:2.116 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.857 (perp=8.916, rec=0.072, cos=0.001), tot_loss_proj:2.123 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.844 (perp=8.916, rec=0.059, cos=0.001), tot_loss_proj:2.123 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[ 750/2000] tot_loss=1.843 (perp=8.916, rec=0.058, cos=0.001), tot_loss_proj:2.106 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.839 (perp=8.916, rec=0.054, cos=0.001), tot_loss_proj:2.124 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.850 (perp=8.916, rec=0.066, cos=0.001), tot_loss_proj:2.122 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
[ 900/2000] tot_loss=1.846 (perp=8.916, rec=0.061, cos=0.001), tot_loss_proj:2.132 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.846 (perp=8.916, rec=0.062, cos=0.001), tot_loss_proj:2.127 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1000/2000] tot_loss=1.851 (perp=8.916, rec=0.067, cos=0.001), tot_loss_proj:2.120 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
[1050/2000] tot_loss=1.859 (perp=8.916, rec=0.075, cos=0.001), tot_loss_proj:2.129 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1100/2000] tot_loss=1.844 (perp=8.916, rec=0.060, cos=0.001), tot_loss_proj:2.125 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1150/2000] tot_loss=1.849 (perp=8.916, rec=0.064, cos=0.001), tot_loss_proj:2.110 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
[1200/2000] tot_loss=1.835 (perp=8.916, rec=0.050, cos=0.001), tot_loss_proj:2.124 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1250/2000] tot_loss=1.842 (perp=8.916, rec=0.058, cos=0.001), tot_loss_proj:2.119 [t=0.21s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1300/2000] tot_loss=1.850 (perp=8.916, rec=0.065, cos=0.001), tot_loss_proj:2.120 [t=0.26s]
prediction: ['[CLS] and eccentric [SEP]']
[1350/2000] tot_loss=1.839 (perp=8.916, rec=0.055, cos=0.001), tot_loss_proj:2.116 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1400/2000] tot_loss=1.853 (perp=8.916, rec=0.069, cos=0.001), tot_loss_proj:2.133 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1450/2000] tot_loss=1.857 (perp=8.916, rec=0.073, cos=0.001), tot_loss_proj:2.127 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[1500/2000] tot_loss=1.845 (perp=8.916, rec=0.060, cos=0.001), tot_loss_proj:2.124 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1550/2000] tot_loss=1.842 (perp=8.916, rec=0.057, cos=0.001), tot_loss_proj:2.114 [t=0.19s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1600/2000] tot_loss=1.839 (perp=8.916, rec=0.054, cos=0.001), tot_loss_proj:2.118 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1650/2000] tot_loss=1.851 (perp=8.916, rec=0.066, cos=0.001), tot_loss_proj:2.128 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1700/2000] tot_loss=1.839 (perp=8.916, rec=0.054, cos=0.001), tot_loss_proj:2.126 [t=0.28s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1750/2000] tot_loss=1.858 (perp=8.916, rec=0.073, cos=0.001), tot_loss_proj:2.119 [t=0.23s]
prediction: ['[CLS] and eccentric [SEP]']
[1800/2000] tot_loss=1.855 (perp=8.916, rec=0.071, cos=0.001), tot_loss_proj:2.119 [t=0.24s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1850/2000] tot_loss=1.842 (perp=8.916, rec=0.057, cos=0.001), tot_loss_proj:2.124 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[1900/2000] tot_loss=1.852 (perp=8.916, rec=0.068, cos=0.001), tot_loss_proj:2.127 [t=0.18s]
prediction: ['[CLS] and eccentric [SEP]']
[1950/2000] tot_loss=1.840 (perp=8.916, rec=0.055, cos=0.001), tot_loss_proj:2.123 [t=0.25s]
prediction: ['[CLS] and eccentric [SEP]']
Attempt swap
[2000/2000] tot_loss=1.845 (perp=8.916, rec=0.060, cos=0.001), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] and eccentric [SEP]']
Done with input #37 of 100.
reference: 
========================
[CLS] eccentric and [SEP]
========================
predicted: 
========================
[CLS] and eccentric [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.495 | p: 88.885 | r: 90.293
rouge2     | fm: 54.489 | p: 54.223 | r: 54.741
rougeL     | fm: 78.425 | p: 77.882 | r: 79.139
rougeLsum  | fm: 78.210 | p: 77.636 | r: 78.821
r1fm+r2fm = 143.984

input #37 time: 0:08:28 | total time: 5:26:05


Running input #38 of 100.
reference: 
========================
scare 
========================
average of cosine similarity 0.9992650714710192
highest_index [0]
highest [0.9992650714710192]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 12665,   102]], device='cuda:0')
Debug: ref = ['[CLS] scare [SEP]']
[Init] best rec loss: 1.7612740993499756 for ['[CLS] course [SEP]']
[Init] best rec loss: 1.7215585708618164 for ['[CLS]st [SEP]']
[Init] best rec loss: 1.6414412260055542 for ['[CLS] assuming [SEP]']
[Init] best rec loss: 1.4560658931732178 for ['[CLS] attracted [SEP]']
[Init] best rec loss: 1.382164716720581 for ['[CLS] private [SEP]']
[Init] best rec loss: 1.3276795148849487 for ['[CLS] sergeant [SEP]']
[Init] best rec loss: 1.1771332025527954 for ['[CLS] pound [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.904 (perp=14.069, rec=0.084, cos=0.006), tot_loss_proj:2.873 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 100/2000] tot_loss=2.882 (perp=14.069, rec=0.065, cos=0.003), tot_loss_proj:2.876 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[ 150/2000] tot_loss=2.877 (perp=14.069, rec=0.060, cos=0.003), tot_loss_proj:2.878 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 200/2000] tot_loss=2.875 (perp=14.069, rec=0.058, cos=0.002), tot_loss_proj:2.880 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.885 (perp=14.069, rec=0.068, cos=0.003), tot_loss_proj:2.881 [t=0.31s]
prediction: ['[CLS] scare [SEP]']
[ 300/2000] tot_loss=2.880 (perp=14.069, rec=0.064, cos=0.002), tot_loss_proj:2.879 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.874 (perp=14.069, rec=0.058, cos=0.002), tot_loss_proj:2.866 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.002), tot_loss_proj:2.864 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 450/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.002), tot_loss_proj:2.878 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.876 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.870 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.883 (perp=14.069, rec=0.068, cos=0.001), tot_loss_proj:2.879 [t=0.23s]
prediction: ['[CLS] scare [SEP]']
[ 600/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.867 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.879 (perp=14.069, rec=0.064, cos=0.001), tot_loss_proj:2.877 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.871 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.867 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[ 750/2000] tot_loss=2.885 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.882 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.889 [t=0.26s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.885 (perp=14.069, rec=0.070, cos=0.001), tot_loss_proj:2.870 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[ 900/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.869 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.882 (perp=14.069, rec=0.067, cos=0.001), tot_loss_proj:2.876 [t=0.25s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1000/2000] tot_loss=2.877 (perp=14.069, rec=0.061, cos=0.001), tot_loss_proj:2.869 [t=0.22s]
prediction: ['[CLS] scare [SEP]']
[1050/2000] tot_loss=2.864 (perp=14.069, rec=0.049, cos=0.001), tot_loss_proj:2.877 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1100/2000] tot_loss=2.876 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.882 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1150/2000] tot_loss=2.891 (perp=14.069, rec=0.076, cos=0.001), tot_loss_proj:2.883 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1200/2000] tot_loss=2.867 (perp=14.069, rec=0.051, cos=0.001), tot_loss_proj:2.880 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1250/2000] tot_loss=2.868 (perp=14.069, rec=0.053, cos=0.001), tot_loss_proj:2.879 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1300/2000] tot_loss=2.892 (perp=14.069, rec=0.077, cos=0.001), tot_loss_proj:2.871 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
[1350/2000] tot_loss=2.870 (perp=14.069, rec=0.055, cos=0.001), tot_loss_proj:2.881 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1400/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.858 [t=0.20s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1450/2000] tot_loss=2.878 (perp=14.069, rec=0.062, cos=0.001), tot_loss_proj:2.875 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
[1500/2000] tot_loss=2.880 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.877 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1550/2000] tot_loss=2.875 (perp=14.069, rec=0.060, cos=0.001), tot_loss_proj:2.868 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1600/2000] tot_loss=2.874 (perp=14.069, rec=0.058, cos=0.001), tot_loss_proj:2.875 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[1650/2000] tot_loss=2.871 (perp=14.069, rec=0.056, cos=0.001), tot_loss_proj:2.873 [t=0.24s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1700/2000] tot_loss=2.869 (perp=14.069, rec=0.054, cos=0.001), tot_loss_proj:2.887 [t=0.21s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1750/2000] tot_loss=2.865 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.881 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
[1800/2000] tot_loss=2.881 (perp=14.069, rec=0.066, cos=0.001), tot_loss_proj:2.882 [t=0.18s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1850/2000] tot_loss=2.881 (perp=14.069, rec=0.065, cos=0.001), tot_loss_proj:2.884 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[1900/2000] tot_loss=2.865 (perp=14.069, rec=0.050, cos=0.001), tot_loss_proj:2.893 [t=0.27s]
prediction: ['[CLS] scare [SEP]']
[1950/2000] tot_loss=2.867 (perp=14.069, rec=0.052, cos=0.001), tot_loss_proj:2.869 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Attempt swap
[2000/2000] tot_loss=2.884 (perp=14.069, rec=0.069, cos=0.001), tot_loss_proj:2.870 [t=0.19s]
prediction: ['[CLS] scare [SEP]']
Done with input #38 of 100.
reference: 
========================
[CLS] scare [SEP]
========================
predicted: 
========================
[CLS] scare [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.851 | p: 89.307 | r: 90.575
rouge2     | fm: 55.629 | p: 55.387 | r: 55.868
rougeL     | fm: 78.957 | p: 78.434 | r: 79.541
rougeLsum  | fm: 78.705 | p: 78.219 | r: 79.269
r1fm+r2fm = 145.480

input #38 time: 0:08:24 | total time: 5:34:29


Running input #39 of 100.
reference: 
========================
finds one of our most conservative and hidebound movie-making traditions and gives it new texture , new relevance , new reality . 
========================
average of cosine similarity 0.9992526747729698
highest_index [0]
highest [0.9992526747729698]
Debug: ids_shape = 27, pads = [27]
Debug: input ids = tensor([[  101,  4858,  2028,  1997,  2256,  2087,  4603,  1998,  5342, 15494,
          3185,  1011,  2437,  7443,  1998,  3957,  2009,  2047, 14902,  1010,
          2047, 21923,  1010,  2047,  4507,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]']
[Init] best rec loss: 2.0013740062713623 for ['[CLS]anda eddy wheels assure bound shirt nes cumulativer kuwait best proseraphic go flight gallery bank butler song doctor kind something best variety mrs [SEP]']
[Init] best rec loss: 2.001059055328369 for ['[CLS] foughtcles yearssy city locations helping interception steve rat raising dos n poor words who agents blair reformationio acquired 1945 accent loss warren [SEP]']
[Init] best rec loss: 1.9660497903823853 for ['[CLS] mil ifs news preparatory day yellow sport bmgdes easily david edouard calm wonderingified keytle wentcula infected form tun home carolina [SEP]']
[Init] best rec loss: 1.8613423109054565 for ['[CLS]sp isn brakes single advanced around historic failed eliza ca didn item guide delayed will known collaborate which. kingsley staff gust quan gap important [SEP]']
[Init] best rec loss: 1.8467004299163818 for ['[CLS] snails [UNK] archives though devin shadow branch bell reigns grounds ago los matthew little boyle word createdrid with wing of audience village sounded reached [SEP]']
[Init] best rec loss: 1.7600774765014648 for ['[CLS] leaving knowlestom presents chance themes jody ge sphere intervention suffrage ewing soldert yes sabbath canada traditional became page account her rate system republic [SEP]']
[Init] best rec loss: 1.74936044216156 for ['[CLS] limited symptoms impressiontor jammu runoff formationian facts wyomingful winner ankles when politics turbo our reflex happenedzzo opium look charging relation laugh [SEP]']
[Init] best rec loss: 1.7386794090270996 for ['[CLS] happens silk reads northwest walked peerage commandgu as legal ] erin comprehensive sampled commercial received sun green happens corrections splinter premiere colonel ground inclusive [SEP]']
[Init] best perm rec loss: 1.718573808670044 for ['[CLS] ] happens northwest sampled silk splinter received asgu corrections colonel sun walked peerage commercial comprehensive command legal reads premiere inclusive happens erin ground green [SEP]']
[Init] best perm rec loss: 1.7130188941955566 for ['[CLS] received happens sampled command silk corrections as inclusive happens walked premiere northwest reads sun splinter legal peeragegu ground colonel ] comprehensive erin commercial green [SEP]']
[Init] best perm rec loss: 1.6906909942626953 for ['[CLS] erin silk received colonel legal commercial ground happens premiere commandgu northwest sampled green ] sun walked inclusive peerage splinter happens comprehensive reads as corrections [SEP]']
[Init] best perm rec loss: 1.6896693706512451 for ['[CLS] happens sampled received reads as corrections inclusivegu splinter commercial walked ground silk green legal ] comprehensive colonel peerage sun happens northwest command erin premiere [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.713 (perp=11.920, rec=0.316, cos=0.014), tot_loss_proj:3.077 [t=0.19s]
prediction: ['[CLS] fiber finds together world.,due brought new clark texture ; good decor opposition changes liberal years♯ ec ben fellowship - new chemistry [SEP]']
[ 100/2000] tot_loss=2.222 (perp=10.011, rec=0.212, cos=0.007), tot_loss_proj:2.878 [t=0.30s]
prediction: ['[CLS] diversity finds it our., new gives, traditions texture ; goodbound conservative changes conservative years texture what writers texture - new movie [SEP]']
[ 150/2000] tot_loss=2.069 (perp=9.391, rec=0.187, cos=0.004), tot_loss_proj:2.761 [t=0.25s]
prediction: ['[CLS] tradition finds it our.. new gives,bound texture ; good most conservative campus conservatives texture reality movie texture - new movie [SEP]']
[ 200/2000] tot_loss=2.031 (perp=9.392, rec=0.149, cos=0.003), tot_loss_proj:3.617 [t=0.19s]
prediction: ['[CLS] traditions finds it our and. new gives,bound texture ; good most conservative & hides hide reality movie texture - new. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.171 (perp=10.185, rec=0.130, cos=0.003), tot_loss_proj:3.883 [t=0.27s]
prediction: ['[CLS] traditions finds it our new ducked and gives,bound texture ; good most conservative & hides hide reality movie texturebound new reality [SEP]']
[ 300/2000] tot_loss=2.030 (perp=9.546, rec=0.118, cos=0.003), tot_loss_proj:3.556 [t=0.20s]
prediction: ['[CLS] traditions finds it our new. and gives,bound texture and good most conservative and hides hide reality movie texturebound new reality [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.989 (perp=9.356, rec=0.114, cos=0.004), tot_loss_proj:3.660 [t=0.21s]
prediction: ['[CLS] traditions finds it our new. and gives,bound texture and new most conservative is reality movie texture hide - hidebound new reality [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.763 (perp=8.294, rec=0.102, cos=0.003), tot_loss_proj:3.110 [t=0.19s]
prediction: ['[CLS] traditions finds it our new. and gives hidebound texture and new most conservative is reality movie texture, - hidebound new reality [SEP]']
[ 450/2000] tot_loss=1.763 (perp=8.294, rec=0.102, cos=0.002), tot_loss_proj:3.113 [t=0.19s]
prediction: ['[CLS] traditions finds it our new. and gives hidebound texture and new most conservative is reality movie texture, - hidebound new reality [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.703 (perp=8.030, rec=0.095, cos=0.002), tot_loss_proj:2.828 [t=0.24s]
prediction: ['[CLS] traditions finds it our new movie and gives hidebound texture and new most conservative is reality. texture, - hidebound new reality [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.656 (perp=7.805, rec=0.093, cos=0.002), tot_loss_proj:2.607 [t=0.28s]
prediction: ['[CLS] big finds it our new movie and gives hidebound texture and traditions most conservative movie reality. texture, - hidebound new reality [SEP]']
[ 600/2000] tot_loss=1.648 (perp=7.805, rec=0.084, cos=0.002), tot_loss_proj:2.602 [t=0.25s]
prediction: ['[CLS] big finds it our new movie and gives hidebound texture and traditions most conservative movie reality. texture, - hidebound new reality [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.610 (perp=7.570, rec=0.094, cos=0.002), tot_loss_proj:2.404 [t=0.18s]
prediction: ['[CLS] big finds it our new movie and gives hidebound texture and traditions most conservative movie reality. texture, hidebound - new reality [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.602 (perp=7.570, rec=0.086, cos=0.002), tot_loss_proj:2.402 [t=0.22s]
prediction: ['[CLS] big finds it our new movie and gives hidebound texture and traditions most conservative movie reality. texture, hidebound - new reality [SEP]']
[ 750/2000] tot_loss=1.600 (perp=7.570, rec=0.083, cos=0.002), tot_loss_proj:2.401 [t=0.19s]
prediction: ['[CLS] big finds it our new movie and gives hidebound texture and traditions most conservative movie reality. texture, hidebound - new reality [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.593 (perp=7.535, rec=0.084, cos=0.002), tot_loss_proj:2.303 [t=0.30s]
prediction: ['[CLS] it finds big our new movie and gives hidebound texture and traditions most conservative - reality. texture, hidebound - new reality [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.592 (perp=7.520, rec=0.086, cos=0.002), tot_loss_proj:2.130 [t=0.19s]
prediction: ['[CLS] it finds big our new movie and gives hidebound texture - traditions most conservative - reality. texture, hidebound and new reality [SEP]']
[ 900/2000] tot_loss=1.590 (perp=7.520, rec=0.084, cos=0.002), tot_loss_proj:2.133 [t=0.24s]
prediction: ['[CLS] it finds big our new movie and gives hidebound texture - traditions most conservative - reality. texture, hidebound and new reality [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.597 (perp=7.535, rec=0.088, cos=0.002), tot_loss_proj:2.306 [t=0.19s]
prediction: ['[CLS] it finds big our new movie and gives hidebound texture and traditions most conservative - reality. texture, hidebound - new reality [SEP]']
Attempt swap
Moved sequence
[1000/2000] tot_loss=1.572 (perp=7.390, rec=0.091, cos=0.002), tot_loss_proj:2.293 [t=0.19s]
prediction: ['[CLS] it finds big our new movie and gives hidebound texture and traditions most conservative reality. texture, hidebound - - new reality [SEP]']
[1050/2000] tot_loss=1.567 (perp=7.390, rec=0.086, cos=0.002), tot_loss_proj:2.293 [t=0.19s]
prediction: ['[CLS] it finds big our new movie and gives hidebound texture and traditions most conservative reality. texture, hidebound - - new reality [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.526 (perp=7.176, rec=0.088, cos=0.002), tot_loss_proj:2.286 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative reality. texture, hidebound - - new reality [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.525 (perp=7.176, rec=0.088, cos=0.002), tot_loss_proj:2.281 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative reality. texture, hidebound - - new reality [SEP]']
[1200/2000] tot_loss=1.524 (perp=7.176, rec=0.087, cos=0.002), tot_loss_proj:2.283 [t=0.27s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative reality. texture, hidebound - - new reality [SEP]']
Attempt swap
[1250/2000] tot_loss=1.516 (perp=7.176, rec=0.079, cos=0.002), tot_loss_proj:2.283 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative reality. texture, hidebound - - new reality [SEP]']
Attempt swap
[1300/2000] tot_loss=1.519 (perp=7.176, rec=0.082, cos=0.002), tot_loss_proj:2.281 [t=0.18s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative reality. texture, hidebound - - new reality [SEP]']
[1350/2000] tot_loss=1.492 (perp=7.078, rec=0.074, cos=0.002), tot_loss_proj:2.567 [t=0.18s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative,. texture, hidebound - - new reality [SEP]']
Attempt swap
[1400/2000] tot_loss=1.495 (perp=7.078, rec=0.077, cos=0.002), tot_loss_proj:2.562 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative,. texture, hidebound - - new reality [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.471 (perp=6.890, rec=0.090, cos=0.003), tot_loss_proj:2.669 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. texture, hidebound, - - new reality [SEP]']
[1500/2000] tot_loss=1.458 (perp=6.890, rec=0.078, cos=0.002), tot_loss_proj:2.670 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. texture, hidebound, - - new reality [SEP]']
Attempt swap
[1550/2000] tot_loss=1.455 (perp=6.890, rec=0.075, cos=0.002), tot_loss_proj:2.670 [t=0.29s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. texture, hidebound, - - new reality [SEP]']
Attempt swap
[1600/2000] tot_loss=1.495 (perp=7.062, rec=0.080, cos=0.002), tot_loss_proj:2.637 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. relevance, hidebound, - - new reality [SEP]']
[1650/2000] tot_loss=1.498 (perp=7.062, rec=0.084, cos=0.002), tot_loss_proj:2.634 [t=0.27s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. relevance, hidebound, - - new reality [SEP]']
Attempt swap
[1700/2000] tot_loss=1.499 (perp=7.062, rec=0.084, cos=0.002), tot_loss_proj:2.634 [t=0.26s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. relevance, hidebound, - - new reality [SEP]']
Attempt swap
[1750/2000] tot_loss=1.497 (perp=7.062, rec=0.083, cos=0.002), tot_loss_proj:2.634 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. relevance, hidebound, - - new reality [SEP]']
[1800/2000] tot_loss=1.496 (perp=7.062, rec=0.081, cos=0.002), tot_loss_proj:2.635 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. relevance, hidebound, - - new reality [SEP]']
Attempt swap
[1850/2000] tot_loss=1.502 (perp=7.062, rec=0.088, cos=0.002), tot_loss_proj:2.637 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. relevance, hidebound, - - new reality [SEP]']
Attempt swap
[1900/2000] tot_loss=1.494 (perp=7.062, rec=0.080, cos=0.002), tot_loss_proj:2.639 [t=0.20s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. relevance, hidebound, - - new reality [SEP]']
[1950/2000] tot_loss=1.496 (perp=7.062, rec=0.081, cos=0.002), tot_loss_proj:2.636 [t=0.19s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. relevance, hidebound, - - new reality [SEP]']
Attempt swap
[2000/2000] tot_loss=1.485 (perp=7.062, rec=0.071, cos=0.002), tot_loss_proj:2.634 [t=0.20s]
prediction: ['[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative. relevance, hidebound, - - new reality [SEP]']
Done with input #39 of 100.
reference: 
========================
[CLS] finds one of our most conservative and hidebound movie - making traditions and gives it new texture, new relevance, new reality. [SEP]
========================
predicted: 
========================
[CLS] it finds our new new movie and gives hidebound texture and traditions most conservative,. texture, hidebound - - new reality [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 90.000 | r: 81.818
rouge2     | fm: 20.000 | p: 21.053 | r: 19.048
rougeL     | fm: 47.619 | p: 50.000 | r: 45.455
rougeLsum  | fm: 47.619 | p: 50.000 | r: 45.455
r1fm+r2fm = 105.714

[Aggregate metrics]:
rouge1     | fm: 89.838 | p: 89.314 | r: 90.365
rouge2     | fm: 54.618 | p: 54.449 | r: 54.738
rougeL     | fm: 78.184 | p: 77.710 | r: 78.752
rougeLsum  | fm: 78.002 | p: 77.495 | r: 78.624
r1fm+r2fm = 144.457

input #39 time: 0:08:52 | total time: 5:43:21


Running input #40 of 100.
reference: 
========================
pummel us with phony imagery or music 
========================
average of cosine similarity 0.9993178197074233
highest_index [0]
highest [0.9993178197074233]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101, 16405, 29033,  2149,  2007,  6887, 16585, 13425,  2030,  2189,
           102]], device='cuda:0')
Debug: ref = ['[CLS] pummel us with phony imagery or music [SEP]']
[Init] best rec loss: 1.9793970584869385 for ['[CLS] like negotiate cassieggle archive engineering spirits [SEP] dylan [SEP]']
[Init] best rec loss: 1.7857263088226318 for ['[CLS] beyond gown shooting serb thousands who intercityori nell [SEP]']
[Init] best rec loss: 1.6468653678894043 for ['[CLS] ricky candidates step louis having rival buddhism rare every [SEP]']
[Init] best rec loss: 1.6214605569839478 for ['[CLS] literacy article simon puppet eclipse countyricting returning writing [SEP]']
[Init] best rec loss: 1.5489600896835327 for ['[CLS] breeders counting screen approximately automatic early customs ambrose fixed [SEP]']
[Init] best rec loss: 1.5032769441604614 for ['[CLS] regularly rookie reducedorough cl won technical [MASK] ass [SEP]']
[Init] best rec loss: 1.4233150482177734 for ['[CLS] locus followsle { holds compilation ; partly football [SEP]']
[Init] best rec loss: 1.3850464820861816 for ['[CLS]woman [SEP] koppen ashes innocent ceased then smith big [SEP]']
[Init] best rec loss: 1.1546258926391602 for ['[CLS] many already lady abd but deciding kent georgian° [SEP]']
[Init] best perm rec loss: 1.1405655145645142 for ['[CLS] kent° but already many abd deciding georgian lady [SEP]']
[Init] best perm rec loss: 1.1383553743362427 for ['[CLS] deciding° but lady already kent georgian abd many [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.732 (perp=12.109, rec=0.298, cos=0.012), tot_loss_proj:3.209 [t=0.18s]
prediction: ['[CLS] phone random emotionectmmel printed information or stupid [SEP]']
[ 100/2000] tot_loss=2.286 (perp=10.492, rec=0.180, cos=0.007), tot_loss_proj:3.270 [t=0.21s]
prediction: ['[CLS] puony needles pummel project music orony [SEP]']
[ 150/2000] tot_loss=2.194 (perp=10.286, rec=0.134, cos=0.003), tot_loss_proj:3.338 [t=0.30s]
prediction: ['[CLS] puony with pummel imagery music orony [SEP]']
[ 200/2000] tot_loss=2.239 (perp=10.698, rec=0.097, cos=0.002), tot_loss_proj:3.376 [t=0.18s]
prediction: ['[CLS] puony with usmmel imagery imagery orony [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.036 (perp=9.725, rec=0.089, cos=0.002), tot_loss_proj:3.067 [t=0.20s]
prediction: ['[CLS] puony with usmmelony imagery or imagery [SEP]']
[ 300/2000] tot_loss=2.029 (perp=9.725, rec=0.082, cos=0.002), tot_loss_proj:3.062 [t=0.25s]
prediction: ['[CLS] puony with usmmelony imagery or imagery [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.012 (perp=9.672, rec=0.076, cos=0.002), tot_loss_proj:3.000 [t=0.22s]
prediction: ['[CLS] puony us withmmelony music or imagery [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.224 (perp=10.628, rec=0.097, cos=0.002), tot_loss_proj:3.680 [t=0.19s]
prediction: ['[CLS]ony us with pummel ph music or imagery [SEP]']
[ 450/2000] tot_loss=2.203 (perp=10.628, rec=0.076, cos=0.002), tot_loss_proj:3.680 [t=0.19s]
prediction: ['[CLS]ony us with pummel ph music or imagery [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.829 (perp=8.702, rec=0.087, cos=0.002), tot_loss_proj:2.185 [t=0.18s]
prediction: ['[CLS] us with pummel phony music or imagery [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.652 (perp=7.880, rec=0.074, cos=0.002), tot_loss_proj:1.950 [t=0.19s]
prediction: ['[CLS] us pummel with phony music or imagery [SEP]']
[ 600/2000] tot_loss=1.647 (perp=7.880, rec=0.070, cos=0.001), tot_loss_proj:1.946 [t=0.18s]
prediction: ['[CLS] us pummel with phony music or imagery [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.512 [t=0.21s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.514 [t=0.21s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 750/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.516 [t=0.28s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.506 [t=0.23s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.464 (perp=6.973, rec=0.068, cos=0.001), tot_loss_proj:1.513 [t=0.23s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[ 900/2000] tot_loss=1.459 (perp=6.973, rec=0.063, cos=0.001), tot_loss_proj:1.517 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.447 (perp=6.973, rec=0.051, cos=0.001), tot_loss_proj:1.512 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1000/2000] tot_loss=1.459 (perp=6.973, rec=0.063, cos=0.001), tot_loss_proj:1.516 [t=0.22s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1050/2000] tot_loss=1.451 (perp=6.973, rec=0.055, cos=0.001), tot_loss_proj:1.512 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1100/2000] tot_loss=1.454 (perp=6.973, rec=0.058, cos=0.001), tot_loss_proj:1.519 [t=0.34s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1150/2000] tot_loss=1.446 (perp=6.973, rec=0.050, cos=0.001), tot_loss_proj:1.520 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1200/2000] tot_loss=1.452 (perp=6.973, rec=0.056, cos=0.001), tot_loss_proj:1.521 [t=0.25s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1250/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.522 [t=0.18s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1300/2000] tot_loss=1.456 (perp=6.973, rec=0.060, cos=0.001), tot_loss_proj:1.512 [t=0.24s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1350/2000] tot_loss=1.462 (perp=6.973, rec=0.066, cos=0.001), tot_loss_proj:1.518 [t=0.24s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1400/2000] tot_loss=1.463 (perp=6.973, rec=0.067, cos=0.001), tot_loss_proj:1.513 [t=0.18s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1450/2000] tot_loss=1.460 (perp=6.973, rec=0.064, cos=0.001), tot_loss_proj:1.516 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1500/2000] tot_loss=1.458 (perp=6.973, rec=0.062, cos=0.001), tot_loss_proj:1.512 [t=0.22s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1550/2000] tot_loss=1.466 (perp=6.973, rec=0.070, cos=0.001), tot_loss_proj:1.504 [t=0.18s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1600/2000] tot_loss=1.449 (perp=6.973, rec=0.053, cos=0.001), tot_loss_proj:1.517 [t=0.23s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1650/2000] tot_loss=1.463 (perp=6.973, rec=0.067, cos=0.001), tot_loss_proj:1.511 [t=0.18s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1700/2000] tot_loss=1.459 (perp=6.973, rec=0.063, cos=0.001), tot_loss_proj:1.505 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1750/2000] tot_loss=1.457 (perp=6.973, rec=0.061, cos=0.001), tot_loss_proj:1.517 [t=0.26s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1800/2000] tot_loss=1.450 (perp=6.973, rec=0.054, cos=0.001), tot_loss_proj:1.512 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1850/2000] tot_loss=1.461 (perp=6.973, rec=0.065, cos=0.001), tot_loss_proj:1.504 [t=0.27s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[1900/2000] tot_loss=1.449 (perp=6.973, rec=0.053, cos=0.001), tot_loss_proj:1.512 [t=0.19s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
[1950/2000] tot_loss=1.459 (perp=6.973, rec=0.063, cos=0.001), tot_loss_proj:1.517 [t=0.20s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Attempt swap
[2000/2000] tot_loss=1.453 (perp=6.973, rec=0.057, cos=0.001), tot_loss_proj:1.501 [t=0.21s]
prediction: ['[CLS] pummel us with phony music or imagery [SEP]']
Done with input #40 of 100.
reference: 
========================
[CLS] pummel us with phony imagery or music [SEP]
========================
predicted: 
========================
[CLS] pummel us with phony music or imagery [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 77.778 | p: 77.778 | r: 77.778
rougeLsum  | fm: 77.778 | p: 77.778 | r: 77.778
r1fm+r2fm = 150.000

[Aggregate metrics]:
rouge1     | fm: 89.962 | p: 89.444 | r: 90.573
rouge2     | fm: 54.455 | p: 54.267 | r: 54.617
rougeL     | fm: 78.105 | p: 77.697 | r: 78.708
rougeLsum  | fm: 77.942 | p: 77.471 | r: 78.476
r1fm+r2fm = 144.416

input #40 time: 0:08:36 | total time: 5:51:58


Running input #41 of 100.
reference: 
========================
consistently sensitive 
========================
average of cosine similarity 0.999304507364323
highest_index [0]
highest [0.999304507364323]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 10862,  7591,   102]], device='cuda:0')
Debug: ref = ['[CLS] consistently sensitive [SEP]']
[Init] best rec loss: 1.978039026260376 for ['[CLS] links lewis [SEP]']
[Init] best rec loss: 1.9309391975402832 for ['[CLS] surrounding around [SEP]']
[Init] best rec loss: 1.8171615600585938 for ['[CLS] e ball [SEP]']
[Init] best rec loss: 1.5979645252227783 for ['[CLS] origins pleasure [SEP]']
[Init] best rec loss: 1.5801717042922974 for ['[CLS] lake performance [SEP]']
[Init] best rec loss: 1.5212957859039307 for ['[CLS] hauntedrily [SEP]']
[Init] best rec loss: 1.4396042823791504 for ["[CLS]'classification [SEP]"]
[Init] best rec loss: 1.402101993560791 for ['[CLS] cale fate [SEP]']
[Init] best rec loss: 1.0926122665405273 for ['[CLS] ways whether [SEP]']
[Init] best rec loss: 1.0066304206848145 for ['[CLS] usa some [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.190 (perp=10.212, rec=0.144, cos=0.003), tot_loss_proj:2.112 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 100/2000] tot_loss=2.130 (perp=10.212, rec=0.086, cos=0.002), tot_loss_proj:2.108 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 150/2000] tot_loss=2.102 (perp=10.212, rec=0.058, cos=0.002), tot_loss_proj:2.121 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 200/2000] tot_loss=2.113 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.118 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.120 (perp=10.212, rec=0.076, cos=0.001), tot_loss_proj:2.123 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 300/2000] tot_loss=2.125 (perp=10.212, rec=0.081, cos=0.002), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.128 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.114 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 450/2000] tot_loss=2.100 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.114 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.119 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.098 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.124 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 600/2000] tot_loss=2.112 (perp=10.212, rec=0.069, cos=0.001), tot_loss_proj:2.115 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.113 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.095 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 750/2000] tot_loss=2.099 (perp=10.212, rec=0.055, cos=0.001), tot_loss_proj:2.093 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.104 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.098 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.112 (perp=10.212, rec=0.068, cos=0.001), tot_loss_proj:2.116 [t=0.23s]
prediction: ['[CLS] consistently sensitive [SEP]']
[ 900/2000] tot_loss=2.117 (perp=10.212, rec=0.073, cos=0.001), tot_loss_proj:2.104 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.101 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.116 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1000/2000] tot_loss=2.105 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1050/2000] tot_loss=2.117 (perp=10.212, rec=0.074, cos=0.001), tot_loss_proj:2.120 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1100/2000] tot_loss=2.102 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.113 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1150/2000] tot_loss=2.115 (perp=10.212, rec=0.071, cos=0.001), tot_loss_proj:2.120 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1200/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.101 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1250/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.107 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1300/2000] tot_loss=2.114 (perp=10.212, rec=0.070, cos=0.001), tot_loss_proj:2.113 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1350/2000] tot_loss=2.100 (perp=10.212, rec=0.056, cos=0.001), tot_loss_proj:2.105 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1400/2000] tot_loss=2.102 (perp=10.212, rec=0.058, cos=0.001), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1450/2000] tot_loss=2.100 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.118 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1500/2000] tot_loss=2.103 (perp=10.212, rec=0.059, cos=0.001), tot_loss_proj:2.113 [t=0.27s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1550/2000] tot_loss=2.100 (perp=10.212, rec=0.057, cos=0.001), tot_loss_proj:2.112 [t=0.24s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1600/2000] tot_loss=2.107 (perp=10.212, rec=0.063, cos=0.001), tot_loss_proj:2.115 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1650/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1700/2000] tot_loss=2.106 (perp=10.212, rec=0.062, cos=0.001), tot_loss_proj:2.112 [t=0.25s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1750/2000] tot_loss=2.103 (perp=10.212, rec=0.060, cos=0.001), tot_loss_proj:2.110 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1800/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.097 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1850/2000] tot_loss=2.097 (perp=10.212, rec=0.053, cos=0.001), tot_loss_proj:2.110 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[1900/2000] tot_loss=2.098 (perp=10.212, rec=0.054, cos=0.001), tot_loss_proj:2.097 [t=0.26s]
prediction: ['[CLS] consistently sensitive [SEP]']
[1950/2000] tot_loss=2.094 (perp=10.212, rec=0.050, cos=0.001), tot_loss_proj:2.110 [t=0.19s]
prediction: ['[CLS] consistently sensitive [SEP]']
Attempt swap
[2000/2000] tot_loss=2.105 (perp=10.212, rec=0.061, cos=0.001), tot_loss_proj:2.113 [t=0.21s]
prediction: ['[CLS] consistently sensitive [SEP]']
Done with input #41 of 100.
reference: 
========================
[CLS] consistently sensitive [SEP]
========================
predicted: 
========================
[CLS] consistently sensitive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.172 | p: 89.717 | r: 90.752
rouge2     | fm: 55.745 | p: 55.593 | r: 55.916
rougeL     | fm: 78.731 | p: 78.268 | r: 79.327
rougeLsum  | fm: 78.358 | p: 77.990 | r: 78.862
r1fm+r2fm = 145.917

input #41 time: 0:08:31 | total time: 6:00:29


Running input #42 of 100.
reference: 
========================
the project 's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting . 
========================
average of cosine similarity 0.9993257960966828
highest_index [0]
highest [0.9993257960966828]
Debug: ids_shape = 28, pads = [28]
Debug: input ids = tensor([[  101,  1996,  2622,  1005,  1055, 16587,  9471,  2000,  2421,  2505,
          2130,  8576, 12459,  2004,  2027,  9996,  2128,  4478, 13327, 10611,
          8432,  2046,  1037,  2152,  2082,  4292,  1012,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]"]
[Init] best rec loss: 1.8863037824630737 for ['[CLS] wore eastshima carriers core careerulsive buddy gallon each drop serves suicide ancientkin records onetruct alphabet can slightlyов california musicals by fleeting [SEP]']
[Init] best rec loss: 1.4476348161697388 for ['[CLS] stylistic pun introductions keynes eight still press flood megan packs my zeke without °f rating climate tx off cross lilly mason daemon ja miraclesit conspiracy [SEP]']
[Init] best rec loss: 1.359115481376648 for ['[CLS]ceptive late whole rich enough tee usl fairoid warm )por claim jackng mel study generally lunch speedway bedlice native pole wu prior [SEP]']
[Init] best rec loss: 1.262780785560608 for ['[CLS] pen china garage louis species metre mostly head bragg poverty membership virtual minersdicmute hoc percentᴵ out fire statistical metric once desirable progressive example [SEP]']
[Init] best rec loss: 1.261205792427063 for ['[CLS] anymore read jersey pain / did felt outcomes water shitnagar brazil main subsidiarylde mp materials miami four fr wondering neither kingdom begun throne album [SEP]']
[Init] best rec loss: 1.1889172792434692 for ['[CLS] treaty lifted larger scaleures ever international attracted dare wish offended cutctricrstakingbe stages kitchen maple banda enoughplinggible ran assignment superseded [SEP]']
[Init] best perm rec loss: 1.1876097917556763 for ['[CLS] liftedures ever dare kitchenrs attracted scale enough ran cut mapletaking bandabe treatygible international wishpling superseded stages larger assignmentctric offended [SEP]']
[Init] best perm rec loss: 1.1862833499908447 for ['[CLS] assignmentbe international ran dare ever offendedgibleuresrs enoughtaking wish treaty scale larger attracted cut maplepling superseded kitchenctric banda lifted stages [SEP]']
[Init] best perm rec loss: 1.1856108903884888 for ['[CLS] supersededtakingctric international cut lifted ranrs largerbe kitchenpling assignment enough banda offendedures maple wish treaty attracted scale ever stagesgible dare [SEP]']
[Init] best perm rec loss: 1.1850471496582031 for ['[CLS]taking attracted wish dare ran international offended stagesctric cut superseded largerbe assignment treatypling scalegible enoughures ever lifted maplers banda kitchen [SEP]']
[Init] best perm rec loss: 1.1792911291122437 for ['[CLS] dare ran stages mapleures superseded kitchen banda internationalpling largerrs scale attracted assignmentctric offendedbe wishgible lifted treaty enough ever cuttaking [SEP]']
[Init] best perm rec loss: 1.179050087928772 for ['[CLS] offended dareures banda enough assignment larger ever maplepling attractedctrictaking ran superseded international treaty scale lifted wish kitchenrsgible stages cutbe [SEP]']
[Init] best perm rec loss: 1.173161506652832 for ['[CLS] kitchenures treaty enough ran wish liftedrsbegible superseded scale stages cut dare assignment larger banda ever maple attractedctric offended internationalplingtaking [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.920 (perp=12.862, rec=0.326, cos=0.021), tot_loss_proj:3.450 [t=0.19s]
prediction: ['[CLS].shed cbs butch termctor drug coverage massacre not parallels data strikes os containing boyle experience rescue resulted authorities mixed poorly forgot existing journalism taken [SEP]']
[ 100/2000] tot_loss=2.769 (perp=12.719, rec=0.219, cos=0.006), tot_loss_proj:3.391 [t=0.23s]
prediction: ['[CLS]. as tech scary term forgot held to massacre never parallels international strikes the involving boyle poorly nrhp rookie filmmakers slips poorly forgot concept scary into [SEP]']
[ 150/2000] tot_loss=2.489 (perp=11.342, rec=0.204, cos=0.016), tot_loss_proj:2.926 [t=0.18s]
prediction: ['[CLS]. as project halfway term forgot schools to whichever neverset international strikes the involvinggger we langdon them filmmakersgger poorly forgot anything scary into [SEP]']
[ 200/2000] tot_loss=2.511 (perp=11.803, rec=0.146, cos=0.005), tot_loss_proj:2.967 [t=0.24s]
prediction: ['[CLS]. as project school short forgot school toage neverset international strikes setting scarygger they langdon they filmmakersgger poorly forgot anything scary into [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.442 (perp=11.531, rec=0.133, cos=0.003), tot_loss_proj:2.946 [t=0.19s]
prediction: ['[CLS] re as project high school short forgot to whichever barely including project strikes setting scarygger we langdon they filmmakersgger poorly forgot anything scary into [SEP]']
[ 300/2000] tot_loss=2.374 (perp=11.279, rec=0.116, cos=0.003), tot_loss_proj:2.849 [t=0.19s]
prediction: ['[CLS] re as project high school ginger forgot to three anything including project strikes setting scaryji they s they filmmakersgger poorly forgot anything scary into [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.275 (perp=10.847, rec=0.103, cos=0.003), tot_loss_proj:2.761 [t=0.18s]
prediction: ['[CLS] re as project high school scary forgot to stuck even include character strikes setting scaryjigger s they filmmakers the poorly forgot anything scary into [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.187 (perp=10.451, rec=0.094, cos=0.003), tot_loss_proj:2.656 [t=0.22s]
prediction: ['[CLS] re as project high school scary forgot to include even include character strikes setting scaryjigger s they the filmmakers poorly forgot anything scary into [SEP]']
[ 450/2000] tot_loss=2.272 (perp=10.906, rec=0.089, cos=0.002), tot_loss_proj:2.718 [t=0.19s]
prediction: ['[CLS] re as project high school scary forgot to include even include character murder setting halfwayjigger s they the filmmakers poorly forgot anything scary into [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.081 (perp=9.876, rec=0.103, cos=0.003), tot_loss_proj:2.527 [t=0.26s]
prediction: ['[CLS] re as project high school scary forgot to include even include character strikes setting scaryjigger s scary the filmmakers poorly forgot anything they into [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.018 (perp=9.583, rec=0.099, cos=0.002), tot_loss_proj:2.611 [t=0.21s]
prediction: ['[CLS] re project as high school scary scary to include even include character strikes setting scaryjigger s scary the filmmakers poorly forgot anything they into [SEP]']
[ 600/2000] tot_loss=2.178 (perp=10.422, rec=0.091, cos=0.002), tot_loss_proj:2.722 [t=0.20s]
prediction: ['[CLS] re project as high school attraction fatal to include even include attraction struck setting scaryjigger s scary the filmmakers poorly forgot anything they into [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.119 (perp=10.143, rec=0.087, cos=0.003), tot_loss_proj:2.694 [t=0.19s]
prediction: ['[CLS] re project as high school attraction fatal to even include attraction struck include setting scaryjigger s scary the filmmakers poorly forgot anything they into [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.997 (perp=9.565, rec=0.082, cos=0.002), tot_loss_proj:2.623 [t=0.27s]
prediction: ['[CLS] re project as high school attraction fatal attraction to even include struck include setting scaryjigger s scary the filmmakers poorly forgot anything they into [SEP]']
[ 750/2000] tot_loss=2.008 (perp=9.565, rec=0.092, cos=0.002), tot_loss_proj:2.627 [t=0.27s]
prediction: ['[CLS] re project as high school attraction fatal attraction to even include struck include setting scaryjigger s scary the filmmakers poorly forgot anything they into [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.932 (perp=9.222, rec=0.086, cos=0.002), tot_loss_proj:2.749 [t=0.19s]
prediction: ['[CLS] re project as high school attraction fatal attraction to even include struck include setting scaryjigger into s scary the filmmakers poorly forgot anything they [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.922 (perp=9.154, rec=0.089, cos=0.002), tot_loss_proj:2.700 [t=0.20s]
prediction: ['[CLS] re project as high school attraction fatal attraction to even include struck include setting scaryjigger into s scary the poorly filmmakers forgot anything they [SEP]']
[ 900/2000] tot_loss=1.921 (perp=9.154, rec=0.088, cos=0.002), tot_loss_proj:2.699 [t=0.19s]
prediction: ['[CLS] re project as high school attraction fatal attraction to even include struck include setting scaryjigger into s scary the poorly filmmakers forgot anything they [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.916 (perp=9.154, rec=0.083, cos=0.002), tot_loss_proj:2.701 [t=0.19s]
prediction: ['[CLS] re project as high school attraction fatal attraction to even include struck include setting scaryjigger into s scary the poorly filmmakers forgot anything they [SEP]']
Attempt swap
[1000/2000] tot_loss=1.915 (perp=9.154, rec=0.082, cos=0.002), tot_loss_proj:2.694 [t=0.18s]
prediction: ['[CLS] re project as high school attraction fatal attraction to even include struck include setting scaryjigger into s scary the poorly filmmakers forgot anything they [SEP]']
[1050/2000] tot_loss=1.913 (perp=9.154, rec=0.080, cos=0.002), tot_loss_proj:2.697 [t=0.20s]
prediction: ['[CLS] re project as high school attraction fatal attraction to even include struck include setting scaryjigger into s scary the poorly filmmakers forgot anything they [SEP]']
Attempt swap
[1100/2000] tot_loss=2.134 (perp=10.246, rec=0.083, cos=0.002), tot_loss_proj:2.852 [t=0.21s]
prediction: ['[CLS] re project as high school attraction fatal fatal to even include struck include setting scaryjigger into s scary the poorly filmmakers forgot anything they [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.022 (perp=9.639, rec=0.092, cos=0.003), tot_loss_proj:2.704 [t=0.19s]
prediction: ['[CLS] re project as high school attraction fatal to even include fatal struck include setting scaryjigger into s scary the poorly filmmakers forgot anything they [SEP]']
[1200/2000] tot_loss=2.024 (perp=9.682, rec=0.085, cos=0.002), tot_loss_proj:2.750 [t=0.18s]
prediction: ['[CLS] re project as high school attraction fatal to even include attraction struck include setting scaryjigger into s scary the poorly filmmakers forgot anything they [SEP]']
Attempt swap
[1250/2000] tot_loss=2.128 (perp=10.243, rec=0.077, cos=0.002), tot_loss_proj:2.739 [t=0.26s]
prediction: ['[CLS] re project as high school attraction fatal to even include attraction struck include setting scaryjigger into s attraction the poorly filmmakers forgot anything they [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.056 (perp=9.826, rec=0.089, cos=0.002), tot_loss_proj:2.704 [t=0.19s]
prediction: ['[CLS] re project as high school attraction s to even include attraction struck include setting scaryjigger into fatal attraction the poorly filmmakers forgot anything they [SEP]']
[1350/2000] tot_loss=2.052 (perp=9.826, rec=0.085, cos=0.002), tot_loss_proj:2.707 [t=0.29s]
prediction: ['[CLS] re project as high school attraction s to even include attraction struck include setting scaryjigger into fatal attraction the poorly filmmakers forgot anything they [SEP]']
Attempt swap
Moved sequence
[1400/2000] tot_loss=2.014 (perp=9.689, rec=0.073, cos=0.002), tot_loss_proj:2.815 [t=0.22s]
prediction: ['[CLS] re project as high school attraction to even s include attraction struck include setting scaryjigger into fatal attraction the poorly filmmakers forgot anything they [SEP]']
Attempt swap
[1450/2000] tot_loss=2.019 (perp=9.689, rec=0.079, cos=0.002), tot_loss_proj:2.811 [t=0.19s]
prediction: ['[CLS] re project as high school attraction to even s include attraction struck include setting scaryjigger into fatal attraction the poorly filmmakers forgot anything they [SEP]']
[1500/2000] tot_loss=2.016 (perp=9.689, rec=0.075, cos=0.002), tot_loss_proj:2.807 [t=0.21s]
prediction: ['[CLS] re project as high school attraction to even s include attraction struck include setting scaryjigger into fatal attraction the poorly filmmakers forgot anything they [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.980 (perp=9.491, rec=0.079, cos=0.002), tot_loss_proj:2.757 [t=0.19s]
prediction: ['[CLS] re project as high school attraction to even s include poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=1.960 (perp=9.370, rec=0.084, cos=0.002), tot_loss_proj:2.673 [t=0.18s]
prediction: ['[CLS] re project as high school attraction to s include even poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
[1650/2000] tot_loss=1.954 (perp=9.370, rec=0.077, cos=0.002), tot_loss_proj:2.675 [t=0.18s]
prediction: ['[CLS] re project as high school attraction to s include even poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
Attempt swap
[1700/2000] tot_loss=1.963 (perp=9.370, rec=0.087, cos=0.002), tot_loss_proj:2.676 [t=0.22s]
prediction: ['[CLS] re project as high school attraction to s include even poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
Attempt swap
[1750/2000] tot_loss=1.960 (perp=9.370, rec=0.084, cos=0.002), tot_loss_proj:2.676 [t=0.19s]
prediction: ['[CLS] re project as high school attraction to s include even poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
[1800/2000] tot_loss=1.962 (perp=9.370, rec=0.085, cos=0.002), tot_loss_proj:2.673 [t=0.23s]
prediction: ['[CLS] re project as high school attraction to s include even poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
Attempt swap
[1850/2000] tot_loss=1.961 (perp=9.370, rec=0.085, cos=0.002), tot_loss_proj:2.671 [t=0.20s]
prediction: ['[CLS] re project as high school attraction to s include even poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
Attempt swap
[1900/2000] tot_loss=1.950 (perp=9.370, rec=0.074, cos=0.002), tot_loss_proj:2.671 [t=0.19s]
prediction: ['[CLS] re project as high school attraction to s include even poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
[1950/2000] tot_loss=1.962 (perp=9.370, rec=0.086, cos=0.002), tot_loss_proj:2.672 [t=0.19s]
prediction: ['[CLS] re project as high school attraction to s include even poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
Attempt swap
[2000/2000] tot_loss=1.954 (perp=9.370, rec=0.078, cos=0.002), tot_loss_proj:2.674 [t=0.26s]
prediction: ['[CLS] re project as high school attraction to s include even poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]']
Done with input #42 of 100.
reference: 
========================
[CLS] the project's filmmakers forgot to include anything even halfway scary as they poorly rejigger fatal attraction into a high school setting. [SEP]
========================
predicted: 
========================
[CLS] re project as high school attraction to even s include poorly struck include setting scaryjigger into fatal attraction the attraction filmmakers forgot anything they [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 76.923 | r: 83.333
rouge2     | fm: 12.500 | p: 12.000 | r: 13.043
rougeL     | fm: 32.000 | p: 30.769 | r: 33.333
rougeLsum  | fm: 32.000 | p: 30.769 | r: 33.333
r1fm+r2fm = 92.500

[Aggregate metrics]:
rouge1     | fm: 89.894 | p: 89.443 | r: 90.512
rouge2     | fm: 54.822 | p: 54.642 | r: 55.028
rougeL     | fm: 77.591 | p: 77.184 | r: 78.214
rougeLsum  | fm: 77.401 | p: 76.966 | r: 77.819
r1fm+r2fm = 144.716

input #42 time: 0:08:29 | total time: 6:08:58


Running input #43 of 100.
reference: 
========================
narcissistic 
========================
average of cosine similarity 0.9992732655805339
highest_index [0]
highest [0.9992732655805339]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  6583, 11890, 14643,  6553,   102]], device='cuda:0')
Debug: ref = ['[CLS] narcissistic [SEP]']
[Init] best rec loss: 1.9562627077102661 for ['[CLS] cuisine • dutchable [SEP]']
[Init] best rec loss: 1.9224357604980469 for ['[CLS] arlington over authority jang [SEP]']
[Init] best rec loss: 1.7678141593933105 for ['[CLS] putting highway honey light [SEP]']
[Init] best rec loss: 1.59369695186615 for ['[CLS] emma " companyographer [SEP]']
[Init] best rec loss: 1.452473521232605 for ['[CLS] sho abc faith romania [SEP]']
[Init] best rec loss: 1.360077977180481 for ['[CLS] funny faculty lin look [SEP]']
[Init] best rec loss: 1.2800770998001099 for ['[CLS]wny reins i why [SEP]']
[Init] best rec loss: 1.1548054218292236 for ['[CLS] treatment airplay demo organ [SEP]']
[Init] best rec loss: 1.0956354141235352 for ['[CLS] secondck climbbus [SEP]']
[Init] best perm rec loss: 1.0862125158309937 for ['[CLS]bus second climbck [SEP]']
[Init] best perm rec loss: 1.082431435585022 for ['[CLS] secondckbus climb [SEP]']
[Init] best perm rec loss: 1.0786867141723633 for ['[CLS]ck secondbus climb [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.305 (perp=10.312, rec=0.237, cos=0.005), tot_loss_proj:3.151 [t=0.21s]
prediction: ['[CLS] naististicistic [SEP]']
[ 100/2000] tot_loss=2.433 (perp=11.440, rec=0.140, cos=0.004), tot_loss_proj:2.811 [t=0.21s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 150/2000] tot_loss=2.405 (perp=11.440, rec=0.115, cos=0.003), tot_loss_proj:2.814 [t=0.18s]
prediction: ['[CLS] naissisticiss [SEP]']
[ 200/2000] tot_loss=2.404 (perp=11.440, rec=0.113, cos=0.003), tot_loss_proj:2.822 [t=0.19s]
prediction: ['[CLS] naissisticiss [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.264 (perp=10.690, rec=0.121, cos=0.004), tot_loss_proj:2.408 [t=0.24s]
prediction: ['[CLS] naississistic [SEP]']
[ 300/2000] tot_loss=1.087 (perp=5.048, rec=0.076, cos=0.002), tot_loss_proj:1.082 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.090 (perp=5.048, rec=0.077, cos=0.004), tot_loss_proj:1.076 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.002), tot_loss_proj:1.089 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[ 450/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.002), tot_loss_proj:1.071 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.074 (perp=5.048, rec=0.063, cos=0.002), tot_loss_proj:1.085 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.072 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.065 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
[ 600/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.074 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.078 (perp=5.048, rec=0.067, cos=0.001), tot_loss_proj:1.071 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.086 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
[ 750/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.094 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.068 (perp=5.048, rec=0.057, cos=0.001), tot_loss_proj:1.082 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.076 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
[ 900/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.083 [t=0.26s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.081 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1000/2000] tot_loss=1.079 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.071 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
[1050/2000] tot_loss=1.075 (perp=5.048, rec=0.063, cos=0.001), tot_loss_proj:1.069 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1100/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.076 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1150/2000] tot_loss=1.071 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.073 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
[1200/2000] tot_loss=1.067 (perp=5.048, rec=0.056, cos=0.001), tot_loss_proj:1.077 [t=0.23s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1250/2000] tot_loss=1.077 (perp=5.048, rec=0.066, cos=0.001), tot_loss_proj:1.076 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1300/2000] tot_loss=1.080 (perp=5.048, rec=0.068, cos=0.001), tot_loss_proj:1.084 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
[1350/2000] tot_loss=1.065 (perp=5.048, rec=0.054, cos=0.001), tot_loss_proj:1.084 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1400/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.073 [t=0.21s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1450/2000] tot_loss=1.071 (perp=5.048, rec=0.060, cos=0.001), tot_loss_proj:1.072 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1500/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.069 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1550/2000] tot_loss=1.076 (perp=5.048, rec=0.064, cos=0.001), tot_loss_proj:1.083 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1600/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.078 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
[1650/2000] tot_loss=1.072 (perp=5.048, rec=0.061, cos=0.001), tot_loss_proj:1.062 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1700/2000] tot_loss=1.076 (perp=5.048, rec=0.065, cos=0.001), tot_loss_proj:1.076 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1750/2000] tot_loss=1.073 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.072 [t=0.29s]
prediction: ['[CLS] narcissistic [SEP]']
[1800/2000] tot_loss=1.070 (perp=5.048, rec=0.059, cos=0.001), tot_loss_proj:1.083 [t=0.25s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1850/2000] tot_loss=1.080 (perp=5.048, rec=0.069, cos=0.001), tot_loss_proj:1.071 [t=0.18s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[1900/2000] tot_loss=1.060 (perp=5.048, rec=0.049, cos=0.001), tot_loss_proj:1.077 [t=0.20s]
prediction: ['[CLS] narcissistic [SEP]']
[1950/2000] tot_loss=1.074 (perp=5.048, rec=0.062, cos=0.001), tot_loss_proj:1.077 [t=0.19s]
prediction: ['[CLS] narcissistic [SEP]']
Attempt swap
[2000/2000] tot_loss=1.069 (perp=5.048, rec=0.058, cos=0.001), tot_loss_proj:1.070 [t=0.27s]
prediction: ['[CLS] narcissistic [SEP]']
Done with input #43 of 100.
reference: 
========================
[CLS] narcissistic [SEP]
========================
predicted: 
========================
[CLS] narcissistic [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.134 | p: 89.625 | r: 90.770
rouge2     | fm: 55.710 | p: 55.558 | r: 55.892
rougeL     | fm: 78.105 | p: 77.690 | r: 78.669
rougeLsum  | fm: 77.839 | p: 77.438 | r: 78.474
r1fm+r2fm = 145.844

input #43 time: 0:08:28 | total time: 6:17:27


Running input #44 of 100.
reference: 
========================
has been lost in the translation ... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise . 
========================
average of cosine similarity 0.9992417534706349
highest_index [0]
highest [0.9992417534706349]
Debug: ids_shape = 31, pads = [31]
Debug: input ids = tensor([[  101,  2038,  2042,  2439,  1999,  1996,  5449,  1012,  1012,  1012,
          2178,  9410,  5365, 25966, 14081,  1999,  2029,  1996, 19840,  7781,
          2009, 27072, 10057,  1996, 18691,  3012,  1997,  1996, 18458,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]']
[Init] best rec loss: 1.8814524412155151 for ['[CLS] imprisonment cl truss rex schooling break lawwyl [MASK] herself upper true { trails elbows bizarre ballot lo skepticism business pollutionviere another bachelor planner motion replaced diver erect [SEP]']
[Init] best rec loss: 1.8753631114959717 for ['[CLS] here supporters psycho fighting at portal seconds published break store among color telegramachcing applicable stress tow ways been cervical landing wrists makes grew code dale visual crowley [SEP]']
[Init] best rec loss: 1.6184682846069336 for ['[CLS] interfaceishly barely rather many liberal [CLS] mass plastic dear prohibition composer oblast intra iso research short privateolin male color forced jennie faith heeprint inside floppy " [SEP]']
[Init] best rec loss: 1.566756248474121 for ['[CLS] beside game sum kali provincesif ib tigers corinne hold tensions old oil bob maxim [CLS] major warfare peninsular tied some filed broadcasters voicessa readerlewood stone sr [SEP]']
[Init] best rec loss: 1.5660165548324585 for ['[CLS] landon co formerly data contestants intent contact ltd brow rock blue illustrated haley fatty raceway comedyosi graphic heehair harbor s nation hello settled ; slave capacity contains [SEP]']
[Init] best rec loss: 1.525803565979004 for ['[CLS] reservesdicated friendly sole rurallda counselan signals spec jamie americas foot emigrated tied [MASK] dex comfortdating artillery meditation joinednard readings eve solo ukraine why offspring [SEP]']
[Init] best perm rec loss: 1.5225293636322021 for ['[CLS] artillery [MASK] ukrainedatingnard signals joined sole friendly readings why counsel jamiedicated spec reserves offspring tied dex solo americaslda meditationan foot eve emigrated rural comfort [SEP]']
[Init] best perm rec loss: 1.5178302526474 for ['[CLS] foot friendlynard artillery why [MASK] meditation ukraine americasdicated comfortdating eve signals emigrated sole offspring reservesan joined tied rural jamielda dex counsel solo readings spec [SEP]']
[Init] best perm rec loss: 1.5158740282058716 for ['[CLS] comfort why meditation reserves signals counsel readings ukraine dex emigrated joined jamienarddating tied rural artillery americas friendlylda eve offspring [MASK]dicated solo foot solean spec [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.509 (perp=11.225, rec=0.256, cos=0.008), tot_loss_proj:2.776 [t=0.25s]
prediction: ['[CLS] lost or routine a missing im translation. lost collapsed hiatuscript its mag translation the was routine celaena execution locomotives another routine fictionaldo mud.. exaggerated [SEP]']
[ 100/2000] tot_loss=2.182 (perp=10.132, rec=0.151, cos=0.004), tot_loss_proj:2.834 [t=0.24s]
prediction: ['[CLS] lost. routine the lost was translation in lost losesizesalis the thus translation the midnight frightalic execution slack another routine fictionaldo... hollywood [SEP]']
[ 150/2000] tot_loss=2.250 (perp=10.595, rec=0.128, cos=0.003), tot_loss_proj:3.063 [t=0.19s]
prediction: ['[CLS]fest. routine the lost been translation in lost slackizesalic the frightfest which ones fright executionizes slack another routine fictionaldo... hollywood [SEP]']
[ 200/2000] tot_loss=2.059 (perp=9.727, rec=0.111, cos=0.003), tot_loss_proj:2.909 [t=0.18s]
prediction: ['[CLS]fest. routine the lost has translation in lostalicizesalic the frightfest which the fright executionizes slack another routine fictional events... hollywood [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.962 (perp=9.048, rec=0.149, cos=0.003), tot_loss_proj:2.516 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has translation in lostalicizesalic the frightfest which the fright executionizes slack another routine absurd premise.... [SEP]']
[ 300/2000] tot_loss=1.921 (perp=9.026, rec=0.113, cos=0.002), tot_loss_proj:2.392 [t=0.23s]
prediction: ['[CLS] hollywood hollywood routine the lost has translation in beenalic executionalic the frightfest which the hollywood executionizes slack another routine absurd premise.... [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.913 (perp=9.058, rec=0.099, cos=0.002), tot_loss_proj:2.344 [t=0.19s]
prediction: ['[CLS] hollywood hollywood routine the lost has translation in beenalic executionalic the slack frightfest which the hollywood executionizes another routine absurd premise. [CLS].. [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.776 (perp=8.423, rec=0.090, cos=0.002), tot_loss_proj:2.348 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has translation in beenalic executionalic the slack fright which thefest hollywood executionizes another routine absurd premise.... [SEP]']
[ 450/2000] tot_loss=1.831 (perp=8.683, rec=0.092, cos=0.002), tot_loss_proj:2.398 [t=0.23s]
prediction: ['[CLS]fest hollywood routine the lost has translation in beenalicfestalic the slack fright which thefest hollywood executionizes another routine absurd premise.... [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.780 (perp=8.519, rec=0.074, cos=0.002), tot_loss_proj:2.451 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has translation in beenalicalic the slackfest which thefest hollywoodfest executionizes another routine absurd premise.... [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.087 (perp=9.323, rec=0.213, cos=0.009), tot_loss_proj:2.489 [t=0.18s]
prediction: ['[CLS]fest hollywood routine the lost has translation in beenalicalic the slack fright which the which hollywood routinefest executionizes another absurd premise the it.. [SEP]']
[ 600/2000] tot_loss=1.996 (perp=9.342, rec=0.124, cos=0.003), tot_loss_proj:2.549 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has translation in beenalicalic the slack fright which the which hollywood routinefest executionizes another absurd premise the its.. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.834 (perp=8.422, rec=0.145, cos=0.004), tot_loss_proj:2.427 [t=0.18s]
prediction: ['[CLS]fest hollywood routine the lost has translation in beenalicalic the slack fright which the whichfest hollywood routine executionizes another absurd premise. its.. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.791 (perp=8.310, rec=0.126, cos=0.003), tot_loss_proj:2.382 [t=0.18s]
prediction: ['[CLS]fest hollywood routine the lost has translation been inalicalic the slack fright which the whichfest hollywood routine executionizes another absurd premise. an.. [SEP]']
[ 750/2000] tot_loss=1.784 (perp=8.310, rec=0.119, cos=0.003), tot_loss_proj:2.385 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has translation been inalicalic the slack fright which the whichfest hollywood routine executionizes another absurd premise. an.. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.720 (perp=8.083, rec=0.101, cos=0.002), tot_loss_proj:2.367 [t=0.22s]
prediction: ['[CLS]fest hollywood routine the lost has translation been inalicalic the slack fright. the whichfest hollywood routine executionizes another absurd premise which an.. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.709 (perp=8.002, rec=0.106, cos=0.002), tot_loss_proj:2.348 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has translation been in analic the slack fright. the whichfest hollywood routine executionizes another absurd premise whichalic.. [SEP]']
[ 900/2000] tot_loss=1.696 (perp=8.002, rec=0.094, cos=0.002), tot_loss_proj:2.346 [t=0.23s]
prediction: ['[CLS]fest hollywood routine the lost has translation been in analic the slack fright. the whichfest hollywood routine executionizes another absurd premise whichalic.. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.697 (perp=8.002, rec=0.094, cos=0.002), tot_loss_proj:2.343 [t=0.27s]
prediction: ['[CLS]fest hollywood routine the lost has translation been in analic the slack fright. the whichfest hollywood routine executionizes another absurd premise whichalic.. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.674 (perp=7.859, rec=0.100, cos=0.002), tot_loss_proj:2.229 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has translation been in analic the slack fright. the whichfest hollywood routine execution another absurd premise whichalicizes.. [SEP]']
[1050/2000] tot_loss=1.724 (perp=8.133, rec=0.096, cos=0.002), tot_loss_proj:2.290 [t=0.18s]
prediction: ['[CLS]fest hollywood routine the lost has translation been in analic the slack fright. the.fest hollywood routine execution another absurd premise whichalicizes.. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.698 (perp=8.013, rec=0.093, cos=0.002), tot_loss_proj:2.226 [t=0.21s]
prediction: ['[CLS]fest hollywood routine the lost has translation been in analic the slack fright.. thefest hollywood routine execution another absurd premise whichalicizes.. [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.660 (perp=7.829, rec=0.092, cos=0.002), tot_loss_proj:2.220 [t=0.25s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in analic the slack fright.. thefest hollywood routine execution another absurd premise whichalicizes.. [SEP]']
[1200/2000] tot_loss=1.760 (perp=8.341, rec=0.090, cos=0.002), tot_loss_proj:2.396 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in analic the slack fright.. theity hollywood routine execution another absurd premise whichalicizes.. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.649 (perp=7.788, rec=0.089, cos=0.002), tot_loss_proj:2.350 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in analic the slack fright.. the hollywood routine execution another absurdity premise whichalicizes.. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.632 (perp=7.644, rec=0.101, cos=0.002), tot_loss_proj:2.323 [t=0.22s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in analic the slack fright. the hollywood routine execution another absurdity premise whichalicizes... [SEP]']
[1350/2000] tot_loss=1.622 (perp=7.644, rec=0.091, cos=0.002), tot_loss_proj:2.322 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in analic the slack fright. the hollywood routine execution another absurdity premise whichalicizes... [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.607 (perp=7.548, rec=0.095, cos=0.002), tot_loss_proj:2.356 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in analic the slack fright premise. the hollywood routine execution another absurdity whichalicizes... [SEP]']
Attempt swap
[1450/2000] tot_loss=1.599 (perp=7.548, rec=0.087, cos=0.002), tot_loss_proj:2.351 [t=0.29s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in analic the slack fright premise. the hollywood routine execution another absurdity whichalicizes... [SEP]']
[1500/2000] tot_loss=1.627 (perp=7.734, rec=0.078, cos=0.002), tot_loss_proj:2.435 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in an hollywood the slack fright premise. the hollywood routine execution another absurdity whichalicizes... [SEP]']
Attempt swap
[1550/2000] tot_loss=1.632 (perp=7.734, rec=0.083, cos=0.002), tot_loss_proj:2.438 [t=0.22s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in an hollywood the slack fright premise. the hollywood routine execution another absurdity whichalicizes... [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.613 (perp=7.631, rec=0.085, cos=0.002), tot_loss_proj:2.435 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in an. the slack fright premise. the hollywood routine execution another absurdity whichalicizes. hollywood. [SEP]']
[1650/2000] tot_loss=1.613 (perp=7.631, rec=0.085, cos=0.002), tot_loss_proj:2.432 [t=0.19s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in an. the slack fright premise. the hollywood routine execution another absurdity whichalicizes. hollywood. [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.552 (perp=7.294, rec=0.091, cos=0.002), tot_loss_proj:2.139 [t=0.27s]
prediction: ['[CLS]fest hollywood routine the lost has been translation in an. the slack fright premise. the hollywood routine execution. another absurdity whichalicizes hollywood. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.540 (perp=7.212, rec=0.096, cos=0.002), tot_loss_proj:2.075 [t=0.18s]
prediction: ['[CLS]. hollywood routine the lost has been translation in an. the slack fright premise. the hollywood routine executionfest another absurdity whichalicizes hollywood. [SEP]']
[1800/2000] tot_loss=1.538 (perp=7.212, rec=0.093, cos=0.002), tot_loss_proj:2.079 [t=0.21s]
prediction: ['[CLS]. hollywood routine the lost has been translation in an. the slack fright premise. the hollywood routine executionfest another absurdity whichalicizes hollywood. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.530 (perp=7.212, rec=0.085, cos=0.002), tot_loss_proj:2.086 [t=0.25s]
prediction: ['[CLS]. hollywood routine the lost has been translation in an. the slack fright premise. the hollywood routine executionfest another absurdity whichalicizes hollywood. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.535 (perp=7.212, rec=0.091, cos=0.002), tot_loss_proj:2.088 [t=0.27s]
prediction: ['[CLS]. hollywood routine the lost has been translation in an. the slack fright premise. the hollywood routine executionfest another absurdity whichalicizes hollywood. [SEP]']
[1950/2000] tot_loss=1.505 (perp=7.048, rec=0.093, cos=0.002), tot_loss_proj:2.069 [t=0.19s]
prediction: ['[CLS]. hollywood routine the lost has been translation in.. the slack fright premise. the hollywood routine executionfest another absurdity whichalicizes hollywood. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.497 (perp=7.048, rec=0.085, cos=0.002), tot_loss_proj:2.069 [t=0.19s]
prediction: ['[CLS]. hollywood routine the lost has been translation in.. the slack fright premise. the hollywood routine executionfest another absurdity whichalicizes hollywood. [SEP]']
Done with input #44 of 100.
reference: 
========================
[CLS] has been lost in the translation... another routine hollywood frightfest in which the slack execution italicizes the absurdity of the premise. [SEP]
========================
predicted: 
========================
[CLS]. hollywood routine the lost has been translation in an. the slack fright premise. the hollywood routine executionfest another absurdity whichalicizes hollywood. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 69.565 | p: 69.565 | r: 69.565
rouge2     | fm: 9.091 | p: 9.091 | r: 9.091
rougeL     | fm: 43.478 | p: 43.478 | r: 43.478
rougeLsum  | fm: 43.478 | p: 43.478 | r: 43.478
r1fm+r2fm = 78.656

[Aggregate metrics]:
rouge1     | fm: 89.659 | p: 89.166 | r: 90.241
rouge2     | fm: 54.728 | p: 54.593 | r: 54.873
rougeL     | fm: 77.475 | p: 77.055 | r: 78.012
rougeLsum  | fm: 76.922 | p: 76.576 | r: 77.505
r1fm+r2fm = 144.387

input #44 time: 0:08:28 | total time: 6:25:55


Running input #45 of 100.
reference: 
========================
-- bowel movements than this long-on-the-shelf , point-and-shoot exercise in gimmicky crime drama 
========================
average of cosine similarity 0.9993986811377396
highest_index [0]
highest [0.9993986811377396]
Debug: ids_shape = 30, pads = [30]
Debug: input ids = tensor([[  101,  1011,  1011,  6812,  2884,  5750,  2084,  2023,  2146,  1011,
          2006,  1011,  1996,  1011, 11142,  1010,  2391,  1011,  1998,  1011,
          5607,  6912,  1999, 21025,  7382,  6799,  2100,  4126,  3689,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]']
[Init] best rec loss: 1.9465147256851196 for ['[CLS] master op ceased fantasycal boring grass post dependent mountain cane nationals naming executive most higher ® oakland https poe would halftime ev minaey approach point shaking [SEP]']
[Init] best rec loss: 1.6877418756484985 for ['[CLS]sor moscow folk cropold urge stopnight lottery groundscopic c hi recordingnational festival overturned up grounds columbia conservation knee love surf ups lad every male [SEP]']
[Init] best rec loss: 1.6227409839630127 for ['[CLS] mid states knitting criticizedpatient ram after fusion urban kaitlyn ocean next prevention readily concerning saving individuals aim privategeny deciding sutton steam why instinct through conclusion visitation [SEP]']
[Init] best rec loss: 1.6042251586914062 for ['[CLS] folk rankedgistmetric furthereto herself pac stamp ma jaya descent foremost, case 11 simon installment marie it wizard lucivar sync mcbadscu keepers stable [SEP]']
[Init] best rec loss: 1.388287901878357 for ['[CLS]as makingcity cardinals cent + workingmpt grounds 978 settings succession same together piano reunion neversson b triple mala lexi anymore blues doubts collateral professor ideal [SEP]']
[Init] best rec loss: 1.2057594060897827 for ['[CLS] murmured joan ku taste around few2 fivelanda operated (tiv via military curtis football single tree letter special enclosed gentry whoa bore status entrance v skin [SEP]']
[Init] best perm rec loss: 1.2009996175765991 for ['[CLS] murmured tree whoa special taste five singletiv bore operated2 via football joan ku skin around enclosed ( letter gentry curtis v status military entrancelanda few [SEP]']
[Init] best perm rec loss: 1.1984952688217163 for ['[CLS] tree via gentry football taste operated skin ( status2 single bore curtis militarytiv murmured few ku five whoa special letter around v entrance joan enclosedlanda [SEP]']
[Init] best perm rec loss: 1.1982824802398682 for ['[CLS] entrance2 around v whoa tree status ku football murmured enclosedtiv taste joan military curtis ( bore few via letter single five special operatedlanda gentry skin [SEP]']
[Init] best perm rec loss: 1.1930371522903442 for ['[CLS] bore whoa fivelanda2 skin gentry militarytiv around single tree operated taste curtis few letter special murmured ku football entrance status joan ( v enclosed via [SEP]']
[Init] best perm rec loss: 1.1888641119003296 for ['[CLS] curtis bore status taste gentry enclosed via skin ( letter five tree single whoa2 murmured entrancelanda v ku military joan few around operated footballtiv special [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.530 (perp=10.901, rec=0.331, cos=0.019), tot_loss_proj:3.502 [t=0.18s]
prediction: ['[CLS] curiosity - - beginning and - kill ga, - eastern manipulationel movie shelf both - site than reportedly betweenville lump months dive junior in newman [SEP]']
[ 100/2000] tot_loss=2.525 (perp=10.599, rec=0.337, cos=0.068), tot_loss_proj:3.375 [t=0.34s]
prediction: ['[CLS] movement - - gun than thanting girls than - -alel - shelf bow - bow than exercise shoot milos clowny dive john in middle [SEP]']
[ 150/2000] tot_loss=2.236 (perp=10.230, rec=0.186, cos=0.004), tot_loss_proj:3.156 [t=0.19s]
prediction: ['[CLS] movements - - bow than thanting girls gun - onalel - shelf bow - bow than exercise this than launderingy bench shoot in - [SEP]']
[ 200/2000] tot_loss=2.369 (perp=10.771, rec=0.210, cos=0.006), tot_loss_proj:3.053 [t=0.19s]
prediction: ['[CLS] movements - - bow than thaningboard articles - - accounted an - shelfigraphy - bow shelf exercise this worn exerciseick scene how inth [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.158 (perp=9.943, rec=0.166, cos=0.003), tot_loss_proj:2.946 [t=0.19s]
prediction: ['[CLS] movements - - bow than thany shelf shoot - the shelf an shelf - bow - bow shelf exercise this long exerciseickmm how inth [SEP]']
[ 300/2000] tot_loss=2.265 (perp=10.584, rec=0.143, cos=0.005), tot_loss_proj:3.031 [t=0.20s]
prediction: ['[CLS] movements - -el than thany shelf crime - the shelf an shelf - bow - bow shelf exercise this long exerciseickmm how inth [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.136 (perp=10.032, rec=0.127, cos=0.002), tot_loss_proj:2.928 [t=0.27s]
prediction: ['[CLS] movements - -el than thany shelf crime - the shelf an shelf - bow - bow shelf exercise this long exerciseickmm howth in [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.247 (perp=10.025, rec=0.234, cos=0.008), tot_loss_proj:3.000 [t=0.20s]
prediction: ['[CLS] movements - -el thanවing shelf crime the shelf an shelf - - multi - bow shelf exercise this long exerciseickmm howth in [SEP]']
[ 450/2000] tot_loss=2.176 (perp=10.145, rec=0.143, cos=0.003), tot_loss_proj:3.063 [t=0.26s]
prediction: ['[CLS] movements - -el thanවing shelf crime the on an shelf - - - - bow topic exercise this long gimmmm howth in [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.185 (perp=10.240, rec=0.134, cos=0.002), tot_loss_proj:3.011 [t=0.19s]
prediction: ['[CLS] movements - -el thanවing on crime the shelf an shelf - - long - bow topic exercise this long gimmmm &th in [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.172 (perp=10.226, rec=0.124, cos=0.003), tot_loss_proj:3.106 [t=0.27s]
prediction: ['[CLS] movements - -el thanවing on crime the shelf gi shelf - - long - bow leasemm this long gimm exercise &th in [SEP]']
[ 600/2000] tot_loss=2.167 (perp=10.226, rec=0.119, cos=0.002), tot_loss_proj:3.114 [t=0.19s]
prediction: ['[CLS] movements - -el thanවing on crime the shelf gi shelf - - long - bow leasemm this long gimm exercise &th in [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.216 (perp=10.491, rec=0.115, cos=0.002), tot_loss_proj:3.282 [t=0.27s]
prediction: ['[CLS] movements - -el thanවing long crime the shelf gi shelf - - long - bowmm lease this long dramamm exercise &th in [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=2.150 (perp=10.192, rec=0.109, cos=0.003), tot_loss_proj:3.141 [t=0.19s]
prediction: ['[CLS] movements - -el than theවing long crime shelf gi shelf - - long - bowmm lease this long dramamm exercise &ii in [SEP]']
[ 750/2000] tot_loss=2.126 (perp=10.075, rec=0.109, cos=0.002), tot_loss_proj:3.126 [t=0.19s]
prediction: ['[CLS] movements - -el than theවy long crime shelf gi shelf - - long - bowmm lease this long dramamm exercise &ii in [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.044 (perp=9.711, rec=0.099, cos=0.002), tot_loss_proj:3.158 [t=0.25s]
prediction: ['[CLS] movements - -el than onවy long in shelf gi shelf - - long - bowmm lease this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.042 (perp=9.681, rec=0.104, cos=0.002), tot_loss_proj:3.277 [t=0.19s]
prediction: ['[CLS] movements - -el than onවy long in shoot gi shelf - - longmm bow - lease this long dramamm exercise & shoot crime [SEP]']
[ 900/2000] tot_loss=2.038 (perp=9.681, rec=0.100, cos=0.002), tot_loss_proj:3.276 [t=0.19s]
prediction: ['[CLS] movements - -el than onවy long in shoot gi shelf - - longmm bow - lease this long dramamm exercise & shoot crime [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.939 (perp=9.186, rec=0.099, cos=0.002), tot_loss_proj:3.304 [t=0.18s]
prediction: ['[CLS] movements - -el than onවy long in shoot gi shelf - - longmm bow - shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.918 (perp=9.090, rec=0.098, cos=0.002), tot_loss_proj:3.231 [t=0.19s]
prediction: ['[CLS] movements - -el than onවy long shoot in gi shelf - - longmm bow - shoot this long dramamm exercise & shoot crime [SEP]']
[1050/2000] tot_loss=1.917 (perp=9.090, rec=0.097, cos=0.002), tot_loss_proj:3.235 [t=0.18s]
prediction: ['[CLS] movements - -el than onවy long shoot in gi shelf - - longmm bow - shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
[1100/2000] tot_loss=1.951 (perp=9.298, rec=0.089, cos=0.002), tot_loss_proj:3.312 [t=0.19s]
prediction: ['[CLS] movements - -el than onවick long shoot in gi shelf - - longmm bow - shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.932 (perp=9.196, rec=0.091, cos=0.002), tot_loss_proj:3.051 [t=0.27s]
prediction: ['[CLS] on - -el than movementsවick long shoot in gi shelf - - longmm bow - shoot this long dramamm exercise & shoot crime [SEP]']
[1200/2000] tot_loss=1.958 (perp=9.304, rec=0.095, cos=0.002), tot_loss_proj:3.087 [t=0.19s]
prediction: ['[CLS] on - -el than movementsවick long shoot in gi shelf - - longscopic bow - shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.945 (perp=9.235, rec=0.096, cos=0.002), tot_loss_proj:3.260 [t=0.23s]
prediction: ['[CLS] on - -el thanick movementsව long shoot in gi shelf - - -scopic bow, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
[1300/2000] tot_loss=1.941 (perp=9.235, rec=0.093, cos=0.002), tot_loss_proj:3.265 [t=0.19s]
prediction: ['[CLS] on - -el thanick movementsව long shoot in gi shelf - - -scopic bow, shoot this long dramamm exercise & shoot crime [SEP]']
[1350/2000] tot_loss=1.933 (perp=9.235, rec=0.084, cos=0.002), tot_loss_proj:3.263 [t=0.23s]
prediction: ['[CLS] on - -el thanick movementsව long shoot in gi shelf - - -scopic bow, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
[1400/2000] tot_loss=1.932 (perp=9.235, rec=0.084, cos=0.002), tot_loss_proj:3.260 [t=0.19s]
prediction: ['[CLS] on - -el thanick movementsව long shoot in gi shelf - - -scopic bow, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.904 (perp=9.054, rec=0.091, cos=0.002), tot_loss_proj:3.366 [t=0.25s]
prediction: ['[CLS] on - -el thanick movements shoot longව in gi shelf - - -scopic bow, shoot this long dramamm exercise & shoot crime [SEP]']
[1500/2000] tot_loss=1.927 (perp=9.216, rec=0.082, cos=0.002), tot_loss_proj:3.402 [t=0.27s]
prediction: ['[CLS] on - -el thanick movements shoot longව in gi shelf - - -mmy bow, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.957 (perp=9.313, rec=0.092, cos=0.002), tot_loss_proj:3.477 [t=0.19s]
prediction: ['[CLS] on - -el thanick movements shoot longවscopic gi shelf - - - in bow, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.912 (perp=9.080, rec=0.094, cos=0.002), tot_loss_proj:3.377 [t=0.23s]
prediction: ['[CLS] on - -el thanick movements shoot longව giscopic shelf - - - in bow, shoot this long dramamm exercise & shoot crime [SEP]']
[1650/2000] tot_loss=1.913 (perp=9.080, rec=0.095, cos=0.002), tot_loss_proj:3.374 [t=0.26s]
prediction: ['[CLS] on - -el thanick movements shoot longව giscopic shelf - - - in bow, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.869 (perp=8.918, rec=0.084, cos=0.002), tot_loss_proj:3.321 [t=0.19s]
prediction: ['[CLS] on - -el thanick - shoot longව giscopic shelf - - movements in bow, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.846 (perp=8.752, rec=0.093, cos=0.002), tot_loss_proj:3.331 [t=0.27s]
prediction: ['[CLS] on - -el thanick - shoot longව giscopic shelf - - bow in movements, shoot this long dramamm exercise & shoot crime [SEP]']
[1800/2000] tot_loss=1.844 (perp=8.752, rec=0.091, cos=0.002), tot_loss_proj:3.329 [t=0.29s]
prediction: ['[CLS] on - -el thanick - shoot longව giscopic shelf - - bow in movements, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
[1850/2000] tot_loss=1.839 (perp=8.752, rec=0.087, cos=0.002), tot_loss_proj:3.330 [t=0.26s]
prediction: ['[CLS] on - -el thanick - shoot longව giscopic shelf - - bow in movements, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.828 (perp=8.664, rec=0.093, cos=0.002), tot_loss_proj:3.367 [t=0.27s]
prediction: ['[CLS] - - -el thanick - shoot longව giscopic shelf - on bow in movements, shoot this long dramamm exercise & shoot crime [SEP]']
[1950/2000] tot_loss=1.820 (perp=8.664, rec=0.085, cos=0.002), tot_loss_proj:3.360 [t=0.26s]
prediction: ['[CLS] - - -el thanick - shoot longව giscopic shelf - on bow in movements, shoot this long dramamm exercise & shoot crime [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.779 (perp=8.466, rec=0.084, cos=0.002), tot_loss_proj:3.214 [t=0.18s]
prediction: ['[CLS] - - -el thanick - shoot long on giscopic shelf -ව bow in movements, shoot this long dramamm exercise & shoot crime [SEP]']
Done with input #45 of 100.
reference: 
========================
[CLS] - - bowel movements than this long - on - the - shelf, point - and - shoot exercise in gimmicky crime drama [SEP]
========================
predicted: 
========================
[CLS] on - -el thanick - shoot longව giscopic shelf - - bow in movements, shoot this long dramamm exercise & shoot crime [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 59.459 | p: 57.895 | r: 61.111
rouge2     | fm: 5.714 | p: 5.556 | r: 5.882
rougeL     | fm: 37.838 | p: 36.842 | r: 38.889
rougeLsum  | fm: 37.838 | p: 36.842 | r: 38.889
r1fm+r2fm = 65.174

[Aggregate metrics]:
rouge1     | fm: 89.054 | p: 88.533 | r: 89.662
rouge2     | fm: 53.675 | p: 53.517 | r: 53.805
rougeL     | fm: 76.503 | p: 76.097 | r: 77.032
rougeLsum  | fm: 76.253 | p: 75.800 | r: 76.702
r1fm+r2fm = 142.730

input #45 time: 0:08:39 | total time: 6:34:35


Running input #46 of 100.
reference: 
========================
visually striking and slickly staged 
========================
average of cosine similarity 0.9992703548035418
highest_index [0]
highest [0.9992703548035418]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101, 17453,  8478,  1998, 13554,  2135,  9813,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] visually striking and slickly staged [SEP]']
[Init] best rec loss: 1.990432858467102 for ['[CLS] mouth pass g commission free round [SEP]']
[Init] best rec loss: 1.9770787954330444 for ['[CLS] laboratory squad furtherting cane realized [SEP]']
[Init] best rec loss: 1.9074907302856445 for ['[CLS]ch believed councils panel law battery [SEP]']
[Init] best rec loss: 1.7174855470657349 for ['[CLS] rec only tor twice belle below [SEP]']
[Init] best rec loss: 1.7164666652679443 for ['[CLS] adaptedator shell whether ordinary convincing [SEP]']
[Init] best rec loss: 1.6811225414276123 for ['[CLS] sank including privately heritage surfaced falcon [SEP]']
[Init] best rec loss: 1.6083678007125854 for ['[CLS]sur darius ontario avery never lives [SEP]']
[Init] best perm rec loss: 1.6035552024841309 for ['[CLS] darius neversur avery lives ontario [SEP]']
[Init] best perm rec loss: 1.6031556129455566 for ['[CLS] neversur darius avery ontario lives [SEP]']
[Init] best perm rec loss: 1.5998085737228394 for ['[CLS] never dariussur avery lives ontario [SEP]']
[Init] best perm rec loss: 1.5986922979354858 for ['[CLS]sur lives darius avery never ontario [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.217 (perp=10.117, rec=0.190, cos=0.004), tot_loss_proj:2.754 [t=0.24s]
prediction: ['[CLS] migrants painted striking slick strikingly [SEP]']
[ 100/2000] tot_loss=2.349 (perp=11.095, rec=0.128, cos=0.003), tot_loss_proj:3.173 [t=0.19s]
prediction: ['[CLS] migrants visually striking slick staged visually [SEP]']
[ 150/2000] tot_loss=2.261 (perp=10.784, rec=0.102, cos=0.002), tot_loss_proj:2.705 [t=0.19s]
prediction: ['[CLS] pattern visually striking slick staged visually [SEP]']
[ 200/2000] tot_loss=2.496 (perp=12.061, rec=0.081, cos=0.002), tot_loss_proj:2.752 [t=0.18s]
prediction: ['[CLS] johnson visually striking slick stagedly [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.025 (perp=9.698, rec=0.083, cos=0.002), tot_loss_proj:2.204 [t=0.19s]
prediction: ['[CLS] johnson visually striking slickly staged [SEP]']
[ 300/2000] tot_loss=2.016 (perp=9.698, rec=0.074, cos=0.002), tot_loss_proj:2.191 [t=0.26s]
prediction: ['[CLS] johnson visually striking slickly staged [SEP]']
Attempt swap
Put prefix at the end
[ 350/2000] tot_loss=1.832 (perp=8.807, rec=0.069, cos=0.002), tot_loss_proj:2.046 [t=0.20s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.844 (perp=8.807, rec=0.081, cos=0.002), tot_loss_proj:2.046 [t=0.18s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
[ 450/2000] tot_loss=1.842 (perp=8.807, rec=0.078, cos=0.002), tot_loss_proj:2.035 [t=0.20s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.844 (perp=8.807, rec=0.081, cos=0.002), tot_loss_proj:2.039 [t=0.31s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.845 (perp=8.807, rec=0.082, cos=0.002), tot_loss_proj:2.044 [t=0.18s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
[ 600/2000] tot_loss=1.838 (perp=8.807, rec=0.075, cos=0.002), tot_loss_proj:2.047 [t=0.19s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.832 (perp=8.807, rec=0.069, cos=0.002), tot_loss_proj:2.036 [t=0.19s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.836 (perp=8.807, rec=0.073, cos=0.002), tot_loss_proj:2.041 [t=0.19s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
[ 750/2000] tot_loss=1.836 (perp=8.807, rec=0.073, cos=0.002), tot_loss_proj:2.039 [t=0.20s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.850 (perp=8.807, rec=0.086, cos=0.002), tot_loss_proj:2.038 [t=0.26s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.851 (perp=8.807, rec=0.087, cos=0.002), tot_loss_proj:2.035 [t=0.18s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
[ 900/2000] tot_loss=1.836 (perp=8.807, rec=0.073, cos=0.002), tot_loss_proj:2.040 [t=0.25s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.835 (perp=8.807, rec=0.072, cos=0.002), tot_loss_proj:2.041 [t=0.26s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[1000/2000] tot_loss=1.833 (perp=8.807, rec=0.070, cos=0.002), tot_loss_proj:2.026 [t=0.19s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
[1050/2000] tot_loss=1.834 (perp=8.807, rec=0.071, cos=0.002), tot_loss_proj:2.039 [t=0.27s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
[1100/2000] tot_loss=1.838 (perp=8.807, rec=0.075, cos=0.002), tot_loss_proj:2.036 [t=0.27s]
prediction: ['[CLS] visually striking slickly staged johnson [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.872 (perp=8.994, rec=0.071, cos=0.002), tot_loss_proj:2.150 [t=0.26s]
prediction: ['[CLS] visually striking johnson slickly staged [SEP]']
[1200/2000] tot_loss=1.860 (perp=8.994, rec=0.060, cos=0.002), tot_loss_proj:2.154 [t=0.22s]
prediction: ['[CLS] visually striking johnson slickly staged [SEP]']
Attempt swap
[1250/2000] tot_loss=1.865 (perp=8.994, rec=0.064, cos=0.002), tot_loss_proj:2.158 [t=0.18s]
prediction: ['[CLS] visually striking johnson slickly staged [SEP]']
Attempt swap
[1300/2000] tot_loss=1.261 (perp=5.916, rec=0.076, cos=0.002), tot_loss_proj:1.257 [t=0.24s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1350/2000] tot_loss=1.261 (perp=5.916, rec=0.076, cos=0.002), tot_loss_proj:1.260 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1400/2000] tot_loss=1.257 (perp=5.916, rec=0.072, cos=0.002), tot_loss_proj:1.254 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1450/2000] tot_loss=1.256 (perp=5.916, rec=0.071, cos=0.002), tot_loss_proj:1.248 [t=0.20s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1500/2000] tot_loss=1.271 (perp=5.916, rec=0.086, cos=0.002), tot_loss_proj:1.245 [t=0.26s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1550/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.269 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1600/2000] tot_loss=1.256 (perp=5.916, rec=0.071, cos=0.002), tot_loss_proj:1.249 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1650/2000] tot_loss=1.255 (perp=5.916, rec=0.071, cos=0.002), tot_loss_proj:1.253 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1700/2000] tot_loss=1.258 (perp=5.916, rec=0.074, cos=0.002), tot_loss_proj:1.259 [t=0.22s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1750/2000] tot_loss=1.252 (perp=5.916, rec=0.067, cos=0.002), tot_loss_proj:1.252 [t=0.21s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1800/2000] tot_loss=1.260 (perp=5.916, rec=0.075, cos=0.002), tot_loss_proj:1.261 [t=0.27s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1850/2000] tot_loss=1.255 (perp=5.916, rec=0.070, cos=0.002), tot_loss_proj:1.252 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[1900/2000] tot_loss=1.259 (perp=5.916, rec=0.074, cos=0.002), tot_loss_proj:1.250 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
[1950/2000] tot_loss=1.266 (perp=5.916, rec=0.081, cos=0.002), tot_loss_proj:1.255 [t=0.19s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Attempt swap
[2000/2000] tot_loss=1.263 (perp=5.916, rec=0.078, cos=0.002), tot_loss_proj:1.249 [t=0.18s]
prediction: ['[CLS] visually striking and slickly staged [SEP]']
Done with input #46 of 100.
reference: 
========================
[CLS] visually striking and slickly staged [SEP]
========================
predicted: 
========================
[CLS] visually striking johnson slickly staged [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 152.381

[Aggregate metrics]:
rouge1     | fm: 88.961 | p: 88.479 | r: 89.551
rouge2     | fm: 54.134 | p: 53.996 | r: 54.274
rougeL     | fm: 76.603 | p: 76.198 | r: 77.077
rougeLsum  | fm: 76.289 | p: 75.844 | r: 76.865
r1fm+r2fm = 143.095

input #46 time: 0:08:27 | total time: 6:43:03


Running input #47 of 100.
reference: 
========================
downright transparent 
========================
average of cosine similarity 0.9992059059142622
highest_index [0]
highest [0.9992059059142622]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  2091, 15950, 13338,   102]], device='cuda:0')
Debug: ref = ['[CLS] downright transparent [SEP]']
[Init] best rec loss: 1.1954387426376343 for ['[CLS] all cup royce [SEP]']
[Init] best perm rec loss: 1.1952502727508545 for ['[CLS] cup all royce [SEP]']
[Init] best perm rec loss: 1.1847620010375977 for ['[CLS] all royce cup [SEP]']
[Init] best perm rec loss: 1.1834989786148071 for ['[CLS] royce all cup [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.600 (perp=11.366, rec=0.233, cos=0.094), tot_loss_proj:3.464 [t=0.18s]
prediction: ['[CLS]right transparent skin [SEP]']
[ 100/2000] tot_loss=2.684 (perp=12.488, rec=0.160, cos=0.027), tot_loss_proj:3.495 [t=0.18s]
prediction: ['[CLS]right transparent transparent [SEP]']
[ 150/2000] tot_loss=2.796 (perp=13.345, rec=0.116, cos=0.011), tot_loss_proj:3.628 [t=0.19s]
prediction: ['[CLS]right transparentright [SEP]']
[ 200/2000] tot_loss=2.772 (perp=13.122, rec=0.125, cos=0.023), tot_loss_proj:3.669 [t=0.18s]
prediction: ['[CLS]right transparent down [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.953 (perp=8.803, rec=0.155, cos=0.038), tot_loss_proj:1.959 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 300/2000] tot_loss=1.845 (perp=8.803, rec=0.078, cos=0.006), tot_loss_proj:1.961 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.850 (perp=8.803, rec=0.066, cos=0.023), tot_loss_proj:1.952 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.823 (perp=8.803, rec=0.060, cos=0.003), tot_loss_proj:1.961 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[ 450/2000] tot_loss=1.853 (perp=8.803, rec=0.071, cos=0.021), tot_loss_proj:1.956 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.817 (perp=8.803, rec=0.053, cos=0.004), tot_loss_proj:1.957 [t=0.28s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.835 (perp=8.803, rec=0.068, cos=0.006), tot_loss_proj:1.942 [t=0.29s]
prediction: ['[CLS] downright transparent [SEP]']
[ 600/2000] tot_loss=1.827 (perp=8.803, rec=0.063, cos=0.003), tot_loss_proj:1.948 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.832 (perp=8.803, rec=0.065, cos=0.007), tot_loss_proj:1.954 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.812 (perp=8.803, rec=0.048, cos=0.003), tot_loss_proj:1.951 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[ 750/2000] tot_loss=1.820 (perp=8.803, rec=0.057, cos=0.002), tot_loss_proj:1.943 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.820 (perp=8.803, rec=0.055, cos=0.005), tot_loss_proj:1.949 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.831 (perp=8.803, rec=0.069, cos=0.002), tot_loss_proj:1.952 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[ 900/2000] tot_loss=1.829 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.939 [t=0.20s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.812 (perp=8.803, rec=0.047, cos=0.004), tot_loss_proj:1.944 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1000/2000] tot_loss=1.820 (perp=8.803, rec=0.057, cos=0.002), tot_loss_proj:1.943 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
[1050/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.950 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1100/2000] tot_loss=1.819 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.933 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1150/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.938 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
[1200/2000] tot_loss=1.826 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.925 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1250/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.940 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1300/2000] tot_loss=1.828 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.934 [t=0.22s]
prediction: ['[CLS] downright transparent [SEP]']
[1350/2000] tot_loss=1.836 (perp=8.803, rec=0.074, cos=0.002), tot_loss_proj:1.931 [t=0.25s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1400/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.933 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1450/2000] tot_loss=1.828 (perp=8.803, rec=0.066, cos=0.002), tot_loss_proj:1.935 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1500/2000] tot_loss=1.815 (perp=8.803, rec=0.053, cos=0.002), tot_loss_proj:1.932 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1550/2000] tot_loss=1.835 (perp=8.803, rec=0.073, cos=0.002), tot_loss_proj:1.942 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1600/2000] tot_loss=1.823 (perp=8.803, rec=0.061, cos=0.002), tot_loss_proj:1.942 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1650/2000] tot_loss=1.822 (perp=8.803, rec=0.060, cos=0.002), tot_loss_proj:1.930 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1700/2000] tot_loss=1.824 (perp=8.803, rec=0.062, cos=0.002), tot_loss_proj:1.935 [t=0.19s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1750/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.930 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
[1800/2000] tot_loss=1.825 (perp=8.803, rec=0.063, cos=0.002), tot_loss_proj:1.934 [t=0.21s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1850/2000] tot_loss=1.829 (perp=8.803, rec=0.067, cos=0.002), tot_loss_proj:1.926 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[1900/2000] tot_loss=1.818 (perp=8.803, rec=0.056, cos=0.002), tot_loss_proj:1.924 [t=0.18s]
prediction: ['[CLS] downright transparent [SEP]']
[1950/2000] tot_loss=1.826 (perp=8.803, rec=0.064, cos=0.002), tot_loss_proj:1.926 [t=0.24s]
prediction: ['[CLS] downright transparent [SEP]']
Attempt swap
[2000/2000] tot_loss=1.828 (perp=8.803, rec=0.065, cos=0.002), tot_loss_proj:1.939 [t=0.23s]
prediction: ['[CLS] downright transparent [SEP]']
Done with input #47 of 100.
reference: 
========================
[CLS] downright transparent [SEP]
========================
predicted: 
========================
[CLS] downright transparent [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.216 | p: 88.709 | r: 89.828
rouge2     | fm: 54.859 | p: 54.737 | r: 55.083
rougeL     | fm: 77.230 | p: 76.773 | r: 77.791
rougeLsum  | fm: 76.899 | p: 76.515 | r: 77.382
r1fm+r2fm = 144.075

input #47 time: 0:08:21 | total time: 6:51:25


Running input #48 of 100.
reference: 
========================
rotting underbelly 
========================
average of cosine similarity 0.9993046234064709
highest_index [0]
highest [0.9993046234064709]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101, 22005,  2104, 17327,  2100,   102]], device='cuda:0')
Debug: ref = ['[CLS] rotting underbelly [SEP]']
[Init] best rec loss: 1.6311019659042358 for ['[CLS] bulls regard nsw membership [SEP]']
[Init] best rec loss: 1.61383056640625 for ['[CLS] with before ashore guy [SEP]']
[Init] best rec loss: 1.5250935554504395 for ['[CLS] cereal sk damned nanny [SEP]']
[Init] best rec loss: 1.266484260559082 for ['[CLS] future -movable working [SEP]']
[Init] best rec loss: 1.1338359117507935 for ['[CLS] graveyardtute runsdine [SEP]']
[Init] best perm rec loss: 1.1290621757507324 for ['[CLS] graveyardtutedine runs [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.584 (perp=12.047, rec=0.169, cos=0.006), tot_loss_proj:2.850 [t=0.24s]
prediction: ['[CLS] rotting rotting under rotting [SEP]']
[ 100/2000] tot_loss=2.552 (perp=12.071, rec=0.134, cos=0.005), tot_loss_proj:2.701 [t=0.20s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 150/2000] tot_loss=2.515 (perp=12.071, rec=0.098, cos=0.002), tot_loss_proj:2.696 [t=0.24s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
[ 200/2000] tot_loss=2.507 (perp=12.071, rec=0.090, cos=0.002), tot_loss_proj:2.689 [t=0.20s]
prediction: ['[CLS] rotting rotting underbell [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=2.214 (perp=10.480, rec=0.114, cos=0.003), tot_loss_proj:2.486 [t=0.24s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
[ 300/2000] tot_loss=2.178 (perp=10.480, rec=0.080, cos=0.002), tot_loss_proj:2.491 [t=0.19s]
prediction: ['[CLS] underbell rotting rotting [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.233 (perp=10.781, rec=0.075, cos=0.001), tot_loss_proj:2.653 [t=0.25s]
prediction: ['[CLS] underbell rottingy [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.482 (perp=7.028, rec=0.075, cos=0.001), tot_loss_proj:1.720 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 450/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.730 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.730 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.466 (perp=7.028, rec=0.059, cos=0.001), tot_loss_proj:1.734 [t=0.20s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 600/2000] tot_loss=1.468 (perp=7.028, rec=0.061, cos=0.001), tot_loss_proj:1.747 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.480 (perp=7.028, rec=0.073, cos=0.001), tot_loss_proj:1.734 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.481 (perp=7.028, rec=0.074, cos=0.001), tot_loss_proj:1.731 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 750/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.738 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.479 (perp=7.028, rec=0.072, cos=0.001), tot_loss_proj:1.727 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.461 (perp=7.028, rec=0.054, cos=0.001), tot_loss_proj:1.732 [t=0.23s]
prediction: ['[CLS] underbelly rotting [SEP]']
[ 900/2000] tot_loss=1.476 (perp=7.028, rec=0.069, cos=0.001), tot_loss_proj:1.736 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.476 (perp=7.028, rec=0.069, cos=0.001), tot_loss_proj:1.740 [t=0.29s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1000/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.730 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1050/2000] tot_loss=1.465 (perp=7.028, rec=0.058, cos=0.001), tot_loss_proj:1.733 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1100/2000] tot_loss=1.466 (perp=7.028, rec=0.059, cos=0.001), tot_loss_proj:1.737 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1150/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.725 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1200/2000] tot_loss=1.477 (perp=7.028, rec=0.070, cos=0.001), tot_loss_proj:1.738 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1250/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.735 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1300/2000] tot_loss=1.467 (perp=7.028, rec=0.060, cos=0.001), tot_loss_proj:1.739 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1350/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1400/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.734 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1450/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.733 [t=0.24s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1500/2000] tot_loss=1.479 (perp=7.028, rec=0.072, cos=0.001), tot_loss_proj:1.728 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1550/2000] tot_loss=1.474 (perp=7.028, rec=0.067, cos=0.001), tot_loss_proj:1.741 [t=0.19s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1600/2000] tot_loss=1.472 (perp=7.028, rec=0.065, cos=0.001), tot_loss_proj:1.732 [t=0.20s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1650/2000] tot_loss=1.457 (perp=7.028, rec=0.050, cos=0.001), tot_loss_proj:1.729 [t=0.25s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1700/2000] tot_loss=1.473 (perp=7.028, rec=0.066, cos=0.001), tot_loss_proj:1.730 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1750/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1800/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.723 [t=0.26s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1850/2000] tot_loss=1.470 (perp=7.028, rec=0.063, cos=0.001), tot_loss_proj:1.740 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[1900/2000] tot_loss=1.471 (perp=7.028, rec=0.064, cos=0.001), tot_loss_proj:1.738 [t=0.22s]
prediction: ['[CLS] underbelly rotting [SEP]']
[1950/2000] tot_loss=1.469 (perp=7.028, rec=0.062, cos=0.001), tot_loss_proj:1.727 [t=0.18s]
prediction: ['[CLS] underbelly rotting [SEP]']
Attempt swap
[2000/2000] tot_loss=1.475 (perp=7.028, rec=0.068, cos=0.001), tot_loss_proj:1.737 [t=0.27s]
prediction: ['[CLS] underbelly rotting [SEP]']
Done with input #48 of 100.
reference: 
========================
[CLS] rotting underbelly [SEP]
========================
predicted: 
========================
[CLS] underbelly rotting [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.390 | p: 88.918 | r: 89.978
rouge2     | fm: 53.969 | p: 53.784 | r: 54.154
rougeL     | fm: 77.107 | p: 76.665 | r: 77.629
rougeLsum  | fm: 76.885 | p: 76.492 | r: 77.349
r1fm+r2fm = 143.359

input #48 time: 0:08:19 | total time: 6:59:44


Running input #49 of 100.
reference: 
========================
could possibly be more contemptuous of the single female population . 
========================
average of cosine similarity 0.9992285770800434
highest_index [0]
highest [0.9992285770800434]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  2071,  4298,  2022,  2062, 17152,  8918,  1997,  1996,  2309,
          2931,  2313,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] could possibly be more contemptuous of the single female population. [SEP]']
[Init] best rec loss: 1.508844017982483 for ['[CLS] torture correctly situation tracks license romano records jones full dylanos study [SEP]']
[Init] best rec loss: 1.4430917501449585 for ['[CLS] man players te wan time ever personnel killer extra raja race roll [SEP]']
[Init] best rec loss: 1.4197598695755005 for ['[CLS] chargesbered harsh today dion craftsuvenssen tool break backup guest [SEP]']
[Init] best rec loss: 1.3730542659759521 for ['[CLS] evolved [SEP] armed desert silence rugby peering officers down did society quarter [SEP]']
[Init] best rec loss: 1.3694813251495361 for ['[CLS] in before car lend only surprise securities radiation following montagu turkishpers [SEP]']
[Init] best rec loss: 1.316090703010559 for ['[CLS] chair assured dick fine chance household every expect boat couple freestyleerly [SEP]']
[Init] best rec loss: 1.3142051696777344 for ['[CLS] pyrenees answered bowling riding chloe minus bo language attentionocating nataya [SEP]']
[Init] best rec loss: 1.313950538635254 for ['[CLS] votesify dawn longingo destructive stop fortxious branchperationħ [SEP]']
[Init] best rec loss: 1.296747088432312 for ['[CLS] awareness sort domestic roles challenge @rifiedound optical family pass numbers [SEP]']
[Init] best rec loss: 1.296575665473938 for ['[CLS] londonrst victoria traded host dear free rided letting technicallytagram [SEP]']
[Init] best perm rec loss: 1.2936689853668213 for ['[CLS] ride technically dear free londonrsttagram victoria lettingd traded host [SEP]']
[Init] best perm rec loss: 1.292286992073059 for ['[CLS] letting victoria hosttagramrst dear ride free london tradedd technically [SEP]']
[Init] best perm rec loss: 1.2903485298156738 for ['[CLS] ride free technically hosttagramrst london victoria dear lettingd traded [SEP]']
[Init] best perm rec loss: 1.2879154682159424 for ['[CLS] technicallyrst dear host victoria traded london lettingtagram free rided [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.501 (perp=10.829, rec=0.282, cos=0.053), tot_loss_proj:3.409 [t=0.18s]
prediction: ['[CLS] contempt june female. more related female primary suggested greater contempt contempt [SEP]']
[ 100/2000] tot_loss=2.403 (perp=10.974, rec=0.190, cos=0.018), tot_loss_proj:3.266 [t=0.24s]
prediction: ['[CLS]uous population female could more dozen single population could more contempt contempt [SEP]']
[ 150/2000] tot_loss=2.509 (perp=11.820, rec=0.134, cos=0.011), tot_loss_proj:3.339 [t=0.24s]
prediction: ['[CLS]uous population female be moresitor single population could moreuous contempt [SEP]']
[ 200/2000] tot_loss=2.393 (perp=11.353, rec=0.116, cos=0.007), tot_loss_proj:3.106 [t=0.20s]
prediction: ['[CLS]uous population female be moresitor single. could possiblyuous contempt [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.151 (perp=10.137, rec=0.114, cos=0.009), tot_loss_proj:2.915 [t=0.25s]
prediction: ['[CLS]uous population female be more the single population could possibly contempt population [SEP]']
[ 300/2000] tot_loss=1.963 (perp=9.351, rec=0.087, cos=0.006), tot_loss_proj:2.709 [t=0.18s]
prediction: ['[CLS]uous population female be more the single population could possibly contempt of [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.896 (perp=9.013, rec=0.088, cos=0.006), tot_loss_proj:2.639 [t=0.26s]
prediction: ['[CLS]uous female population be more the single population could possibly contempt of [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.826 (perp=8.700, rec=0.080, cos=0.006), tot_loss_proj:2.542 [t=0.20s]
prediction: ['[CLS]uous female population more be the single population could possibly contempt of [SEP]']
[ 450/2000] tot_loss=1.832 (perp=8.700, rec=0.087, cos=0.005), tot_loss_proj:2.538 [t=0.19s]
prediction: ['[CLS]uous female population more be the single population could possibly contempt of [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.781 (perp=8.448, rec=0.085, cos=0.006), tot_loss_proj:2.598 [t=0.20s]
prediction: ['[CLS] female market more be the single population could possibly contemptuous of [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.779 (perp=8.448, rec=0.084, cos=0.006), tot_loss_proj:2.596 [t=0.18s]
prediction: ['[CLS] female market more be the single population could possibly contemptuous of [SEP]']
[ 600/2000] tot_loss=1.778 (perp=8.448, rec=0.082, cos=0.006), tot_loss_proj:2.597 [t=0.18s]
prediction: ['[CLS] female market more be the single population could possibly contemptuous of [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.772 (perp=8.448, rec=0.077, cos=0.005), tot_loss_proj:2.597 [t=0.19s]
prediction: ['[CLS] female market more be the single population could possibly contemptuous of [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.775 (perp=8.448, rec=0.080, cos=0.006), tot_loss_proj:2.592 [t=0.18s]
prediction: ['[CLS] female market more be the single population could possibly contemptuous of [SEP]']
[ 750/2000] tot_loss=1.781 (perp=8.448, rec=0.086, cos=0.005), tot_loss_proj:2.597 [t=0.25s]
prediction: ['[CLS] female market more be the single population could possibly contemptuous of [SEP]']
Attempt swap
Moved sequence
[ 800/2000] tot_loss=1.613 (perp=7.467, rec=0.110, cos=0.009), tot_loss_proj:2.637 [t=0.27s]
prediction: ['[CLS] female market more the single population could possibly be contemptuous of [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.612 (perp=7.467, rec=0.110, cos=0.008), tot_loss_proj:2.641 [t=0.19s]
prediction: ['[CLS] female market more the single population could possibly be contemptuous of [SEP]']
[ 900/2000] tot_loss=1.603 (perp=7.467, rec=0.102, cos=0.008), tot_loss_proj:2.638 [t=0.19s]
prediction: ['[CLS] female market more the single population could possibly be contemptuous of [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.598 (perp=7.457, rec=0.099, cos=0.008), tot_loss_proj:2.766 [t=0.18s]
prediction: ['[CLS] female population more the single market could possibly be contemptuous of [SEP]']
Attempt swap
Put prefix at the end
[1000/2000] tot_loss=1.455 (perp=6.711, rec=0.104, cos=0.009), tot_loss_proj:2.097 [t=0.19s]
prediction: ['[CLS] more the single market could possibly be contemptuous of female population [SEP]']
[1050/2000] tot_loss=1.456 (perp=6.711, rec=0.106, cos=0.008), tot_loss_proj:2.092 [t=0.18s]
prediction: ['[CLS] more the single market could possibly be contemptuous of female population [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.366 (perp=6.333, rec=0.092, cos=0.008), tot_loss_proj:2.029 [t=0.18s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1150/2000] tot_loss=1.364 (perp=6.333, rec=0.090, cos=0.008), tot_loss_proj:2.036 [t=0.18s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
[1200/2000] tot_loss=1.378 (perp=6.333, rec=0.104, cos=0.007), tot_loss_proj:2.033 [t=0.19s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1250/2000] tot_loss=1.360 (perp=6.333, rec=0.086, cos=0.007), tot_loss_proj:2.037 [t=0.25s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1300/2000] tot_loss=1.373 (perp=6.333, rec=0.100, cos=0.007), tot_loss_proj:2.031 [t=0.25s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
[1350/2000] tot_loss=1.369 (perp=6.333, rec=0.096, cos=0.007), tot_loss_proj:2.032 [t=0.20s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1400/2000] tot_loss=1.359 (perp=6.333, rec=0.085, cos=0.007), tot_loss_proj:2.034 [t=0.18s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1450/2000] tot_loss=1.365 (perp=6.333, rec=0.092, cos=0.007), tot_loss_proj:2.030 [t=0.25s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
[1500/2000] tot_loss=1.363 (perp=6.333, rec=0.090, cos=0.007), tot_loss_proj:2.034 [t=0.26s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1550/2000] tot_loss=1.369 (perp=6.333, rec=0.095, cos=0.007), tot_loss_proj:2.033 [t=0.18s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1600/2000] tot_loss=1.370 (perp=6.333, rec=0.097, cos=0.007), tot_loss_proj:2.029 [t=0.26s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
[1650/2000] tot_loss=1.365 (perp=6.333, rec=0.092, cos=0.007), tot_loss_proj:2.036 [t=0.19s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1700/2000] tot_loss=1.364 (perp=6.333, rec=0.090, cos=0.007), tot_loss_proj:2.035 [t=0.23s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1750/2000] tot_loss=1.368 (perp=6.333, rec=0.095, cos=0.007), tot_loss_proj:2.032 [t=0.18s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
[1800/2000] tot_loss=1.358 (perp=6.333, rec=0.084, cos=0.007), tot_loss_proj:2.034 [t=0.19s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1850/2000] tot_loss=1.363 (perp=6.333, rec=0.090, cos=0.006), tot_loss_proj:2.037 [t=0.20s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[1900/2000] tot_loss=1.358 (perp=6.333, rec=0.085, cos=0.006), tot_loss_proj:2.034 [t=0.18s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
[1950/2000] tot_loss=1.360 (perp=6.333, rec=0.087, cos=0.006), tot_loss_proj:2.034 [t=0.19s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Attempt swap
[2000/2000] tot_loss=1.362 (perp=6.333, rec=0.089, cos=0.006), tot_loss_proj:2.031 [t=0.18s]
prediction: ['[CLS] the single market more could possibly be contemptuous of female population [SEP]']
Done with input #49 of 100.
reference: 
========================
[CLS] could possibly be more contemptuous of the single female population. [SEP]
========================
predicted: 
========================
[CLS]uous female population more be the single population could possibly contempt of [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.615 | p: 78.571 | r: 91.667
rouge2     | fm: 25.000 | p: 23.077 | r: 27.273
rougeL     | fm: 46.154 | p: 42.857 | r: 50.000
rougeLsum  | fm: 46.154 | p: 42.857 | r: 50.000
r1fm+r2fm = 109.615

[Aggregate metrics]:
rouge1     | fm: 89.266 | p: 88.733 | r: 89.968
rouge2     | fm: 53.348 | p: 53.150 | r: 53.550
rougeL     | fm: 76.480 | p: 75.989 | r: 77.069
rougeLsum  | fm: 76.287 | p: 75.840 | r: 76.870
r1fm+r2fm = 142.613

input #49 time: 0:08:22 | total time: 7:08:07


Running input #50 of 100.
reference: 
========================
what the english call ` too clever by half 
========================
average of cosine similarity 0.9992840964591766
highest_index [0]
highest [0.9992840964591766]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  2054,  1996,  2394,  2655,  1036,  2205, 12266,  2011,  2431,
           102]], device='cuda:0')
Debug: ref = ['[CLS] what the english call ` too clever by half [SEP]']
[Init] best rec loss: 1.7681097984313965 for ['[CLS] de malaya warlord different hay li quick anymore governing [SEP]']
[Init] best rec loss: 1.5493779182434082 for ['[CLS] young division operator earliest kabul maud trail kay bra [SEP]']
[Init] best rec loss: 1.5217300653457642 for ['[CLS] garbage well delegationaround slow songs j spoke into [SEP]']
[Init] best rec loss: 1.4632673263549805 for ['[CLS] redieving by crisislent nightham bridget accordance [SEP]']
[Init] best rec loss: 1.4029443264007568 for ['[CLS] rama fueled sq napkinok unit trust associated gall [SEP]']
[Init] best perm rec loss: 1.401523470878601 for ['[CLS] associated fueled trustok rama sq napkin gall unit [SEP]']
[Init] best perm rec loss: 1.40097177028656 for ['[CLS]ok gall napkin associated fueled sq trust unit rama [SEP]']
[Init] best perm rec loss: 1.3933467864990234 for ['[CLS] gall sq napkin trust fueled unit ramaok associated [SEP]']
[Init] best perm rec loss: 1.3920629024505615 for ['[CLS] napkinok trust unit gall fueled rama sq associated [SEP]']
[Init] best perm rec loss: 1.3910012245178223 for ['[CLS] unit gall associated sq fueled napkinok rama trust [SEP]']
[Init] best perm rec loss: 1.3904179334640503 for ['[CLS] trust sq unit gallok associated napkin rama fueled [SEP]']
[Init] best perm rec loss: 1.390091061592102 for ['[CLS] gall napkin unit fueled associated sqok trust rama [SEP]']
[Init] best perm rec loss: 1.3895784616470337 for ['[CLS] unit gall napkin associated sq trustok fueled rama [SEP]']
[Init] best perm rec loss: 1.3889405727386475 for ['[CLS] unit gall trust fueledok sq associated napkin rama [SEP]']
[Init] best perm rec loss: 1.3880995512008667 for ['[CLS] fueled gall napkin unit sq trustok associated rama [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.038 (perp=12.702, rec=0.409, cos=0.089), tot_loss_proj:4.288 [t=0.18s]
prediction: ['[CLS] huntington mk prime scott chance rating thorpe simply clever [SEP]']
[ 100/2000] tot_loss=2.605 (perp=11.151, rec=0.325, cos=0.051), tot_loss_proj:3.196 [t=0.18s]
prediction: ["[CLS] what'animals on chance half excessive english clever [SEP]"]
[ 150/2000] tot_loss=2.439 (perp=10.496, rec=0.295, cos=0.045), tot_loss_proj:2.967 [t=0.21s]
prediction: ['[CLS] what call animals by chance half overly english clever [SEP]']
[ 200/2000] tot_loss=2.303 (perp=10.302, rec=0.218, cos=0.024), tot_loss_proj:2.810 [t=0.22s]
prediction: ['[CLS] what call son by chance half too english clever [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.277 (perp=10.454, rec=0.170, cos=0.016), tot_loss_proj:2.889 [t=0.25s]
prediction: ['[CLS] what english callnessy by ` half too clever [SEP]']
[ 300/2000] tot_loss=2.244 (perp=10.454, rec=0.143, cos=0.010), tot_loss_proj:2.915 [t=0.19s]
prediction: ['[CLS] what english callnessy by ` half too clever [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.170 (perp=10.228, rec=0.116, cos=0.009), tot_loss_proj:2.563 [t=0.19s]
prediction: ['[CLS] what english call ` the by half too clever [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.795 (perp=8.499, rec=0.092, cos=0.003), tot_loss_proj:2.375 [t=0.21s]
prediction: ['[CLS] what english call the ` by half too clever [SEP]']
[ 450/2000] tot_loss=1.776 (perp=8.499, rec=0.075, cos=0.002), tot_loss_proj:2.389 [t=0.19s]
prediction: ['[CLS] what english call the ` by half too clever [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.775 (perp=8.499, rec=0.073, cos=0.002), tot_loss_proj:2.389 [t=0.19s]
prediction: ['[CLS] what english call the ` by half too clever [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.675 (perp=8.037, rec=0.065, cos=0.003), tot_loss_proj:2.136 [t=0.20s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[ 600/2000] tot_loss=1.673 (perp=8.037, rec=0.064, cos=0.002), tot_loss_proj:2.133 [t=0.24s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.676 (perp=8.037, rec=0.067, cos=0.002), tot_loss_proj:2.129 [t=0.25s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.679 (perp=8.037, rec=0.070, cos=0.002), tot_loss_proj:2.130 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[ 750/2000] tot_loss=1.669 (perp=8.037, rec=0.060, cos=0.002), tot_loss_proj:2.131 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.678 (perp=8.037, rec=0.069, cos=0.002), tot_loss_proj:2.128 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.669 (perp=8.037, rec=0.060, cos=0.002), tot_loss_proj:2.126 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[ 900/2000] tot_loss=1.673 (perp=8.037, rec=0.064, cos=0.002), tot_loss_proj:2.123 [t=0.29s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.679 (perp=8.037, rec=0.070, cos=0.002), tot_loss_proj:2.119 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1000/2000] tot_loss=1.679 (perp=8.037, rec=0.070, cos=0.001), tot_loss_proj:2.113 [t=0.22s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1050/2000] tot_loss=1.680 (perp=8.037, rec=0.071, cos=0.001), tot_loss_proj:2.119 [t=0.27s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1100/2000] tot_loss=1.669 (perp=8.037, rec=0.060, cos=0.002), tot_loss_proj:2.118 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1150/2000] tot_loss=1.671 (perp=8.037, rec=0.062, cos=0.001), tot_loss_proj:2.115 [t=0.21s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1200/2000] tot_loss=1.673 (perp=8.037, rec=0.065, cos=0.001), tot_loss_proj:2.115 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1250/2000] tot_loss=1.677 (perp=8.037, rec=0.068, cos=0.001), tot_loss_proj:2.115 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1300/2000] tot_loss=1.680 (perp=8.037, rec=0.071, cos=0.001), tot_loss_proj:2.111 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1350/2000] tot_loss=1.677 (perp=8.037, rec=0.069, cos=0.001), tot_loss_proj:2.112 [t=0.20s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1400/2000] tot_loss=1.671 (perp=8.037, rec=0.063, cos=0.001), tot_loss_proj:2.109 [t=0.24s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1450/2000] tot_loss=1.668 (perp=8.037, rec=0.059, cos=0.001), tot_loss_proj:2.105 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1500/2000] tot_loss=1.672 (perp=8.037, rec=0.064, cos=0.001), tot_loss_proj:2.114 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1550/2000] tot_loss=1.669 (perp=8.037, rec=0.060, cos=0.001), tot_loss_proj:2.110 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1600/2000] tot_loss=1.669 (perp=8.037, rec=0.060, cos=0.001), tot_loss_proj:2.103 [t=0.23s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1650/2000] tot_loss=1.671 (perp=8.037, rec=0.062, cos=0.001), tot_loss_proj:2.104 [t=0.21s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1700/2000] tot_loss=1.677 (perp=8.037, rec=0.068, cos=0.001), tot_loss_proj:2.108 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1750/2000] tot_loss=1.675 (perp=8.037, rec=0.066, cos=0.001), tot_loss_proj:2.107 [t=0.20s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1800/2000] tot_loss=1.672 (perp=8.037, rec=0.063, cos=0.001), tot_loss_proj:2.104 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1850/2000] tot_loss=1.673 (perp=8.037, rec=0.064, cos=0.001), tot_loss_proj:2.102 [t=0.18s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[1900/2000] tot_loss=1.666 (perp=8.037, rec=0.057, cos=0.001), tot_loss_proj:2.103 [t=0.25s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
[1950/2000] tot_loss=1.670 (perp=8.037, rec=0.061, cos=0.001), tot_loss_proj:2.104 [t=0.22s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Attempt swap
[2000/2000] tot_loss=1.677 (perp=8.037, rec=0.068, cos=0.001), tot_loss_proj:2.107 [t=0.19s]
prediction: ['[CLS] what the english call ` by half too clever [SEP]']
Done with input #50 of 100.
reference: 
========================
[CLS] what the english call ` too clever by half [SEP]
========================
predicted: 
========================
[CLS] what the english call ` by half too clever [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 66.667 | p: 66.667 | r: 66.667
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 166.667

[Aggregate metrics]:
rouge1     | fm: 89.423 | p: 88.858 | r: 90.156
rouge2     | fm: 53.468 | p: 53.285 | r: 53.692
rougeL     | fm: 76.520 | p: 76.091 | r: 77.098
rougeLsum  | fm: 76.459 | p: 75.982 | r: 77.038
r1fm+r2fm = 142.890

input #50 time: 0:08:13 | total time: 7:16:20


Running input #51 of 100.
reference: 
========================
sucks , but has a funny moment or two . 
========================
average of cosine similarity 0.9992548315433463
highest_index [0]
highest [0.9992548315433463]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101, 19237,  1010,  2021,  2038,  1037,  6057,  2617,  2030,  2048,
          1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] sucks, but has a funny moment or two. [SEP]']
[Init] best rec loss: 1.5581773519515991 for ['[CLS] professor teenager a rooney often ass travel [MASK] tideid [SEP]']
[Init] best rec loss: 1.3123705387115479 for ['[CLS] wickets welcomed unto arnold centuries sirens conductor english face eve [SEP]']
[Init] best rec loss: 1.2994669675827026 for ['[CLS] link bullshitw couldn reid bbc took e frustration in [SEP]']
[Init] best rec loss: 1.2463165521621704 for ['[CLS] nationals offense - vaguely world justine domesticished majorage [SEP]']
[Init] best rec loss: 1.2434269189834595 for ["[CLS] rested judo 'wig admitted matt knowledgeni heard gee [SEP]"]
[Init] best rec loss: 1.1884088516235352 for ['[CLS] flight sync breathework - faintlyase wild ownershipki [SEP]']
[Init] best rec loss: 1.1509753465652466 for ['[CLS] include plants hole abuse especially multiple fingers & since accepting [SEP]']
[Init] best perm rec loss: 1.1506011486053467 for ['[CLS] accepting hole multiple since abuse especially plants & include fingers [SEP]']
[Init] best perm rec loss: 1.1483800411224365 for ['[CLS] multiple accepting hole especially include since & fingers abuse plants [SEP]']
[Init] best perm rec loss: 1.1480402946472168 for ['[CLS] accepting plants include especially since multiple & fingers hole abuse [SEP]']
[Init] best perm rec loss: 1.146215558052063 for ['[CLS] multiple especially accepting since abuse & hole fingers plants include [SEP]']
[Init] best perm rec loss: 1.1452608108520508 for ['[CLS] multiple especially accepting since & plants hole fingers include abuse [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.781 (perp=11.026, rec=0.390, cos=0.186), tot_loss_proj:3.296 [t=0.24s]
prediction: ['[CLS] stronger strange, because funny frederick sucks sucks sucks space [SEP]']
[ 100/2000] tot_loss=2.114 (perp=9.069, rec=0.257, cos=0.044), tot_loss_proj:2.881 [t=0.18s]
prediction: ['[CLS] closed funny, but funny phrase sucks funny sucks but [SEP]']
[ 150/2000] tot_loss=2.361 (perp=8.944, rec=0.398, cos=0.173), tot_loss_proj:2.969 [t=0.18s]
prediction: ['[CLS] has funny, and moment perhaps sucks funny sucks but [SEP]']
[ 200/2000] tot_loss=2.309 (perp=10.438, rec=0.190, cos=0.031), tot_loss_proj:3.295 [t=0.22s]
prediction: ['[CLS] kept funny funny or moment or sucks has sucks but [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.807 (perp=8.216, rec=0.142, cos=0.022), tot_loss_proj:2.495 [t=0.23s]
prediction: ['[CLS] has funny or funny moment or sucks has sucks but [SEP]']
[ 300/2000] tot_loss=1.743 (perp=7.966, rec=0.129, cos=0.021), tot_loss_proj:2.493 [t=0.18s]
prediction: ['[CLS] a funny or funny moment or sucks has sucks but [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.610 (perp=7.437, rec=0.109, cos=0.014), tot_loss_proj:2.418 [t=0.18s]
prediction: ['[CLS] a funny or funny moment has sucks two sucks but [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.788 (perp=8.383, rec=0.100, cos=0.011), tot_loss_proj:2.430 [t=0.24s]
prediction: ['[CLS] a funny sucks. moment has or two sucks but [SEP]']
[ 450/2000] tot_loss=1.702 (perp=7.976, rec=0.099, cos=0.008), tot_loss_proj:2.349 [t=0.18s]
prediction: ['[CLS] a funny sucks a moment has or two sucks but [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.607 (perp=7.548, rec=0.090, cos=0.007), tot_loss_proj:2.228 [t=0.18s]
prediction: ['[CLS] a funny sucks has a moment or two sucks but [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.614 (perp=7.492, rec=0.099, cos=0.016), tot_loss_proj:2.411 [t=0.22s]
prediction: ['[CLS]. funny sucks has a moment or two but sucks [SEP]']
[ 600/2000] tot_loss=1.596 (perp=7.492, rec=0.093, cos=0.006), tot_loss_proj:2.417 [t=0.18s]
prediction: ['[CLS]. funny sucks has a moment or two but sucks [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.546 (perp=7.213, rec=0.093, cos=0.010), tot_loss_proj:2.336 [t=0.18s]
prediction: ['[CLS]. funny has sucks a moment or two but sucks [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.461 (perp=6.891, rec=0.077, cos=0.005), tot_loss_proj:2.427 [t=0.24s]
prediction: ['[CLS]. has funny sucks a moment or two but sucks [SEP]']
[ 750/2000] tot_loss=1.460 (perp=6.891, rec=0.077, cos=0.005), tot_loss_proj:2.427 [t=0.18s]
prediction: ['[CLS]. has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.469 (perp=6.891, rec=0.086, cos=0.005), tot_loss_proj:2.427 [t=0.18s]
prediction: ['[CLS]. has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.467 (perp=6.891, rec=0.084, cos=0.004), tot_loss_proj:2.420 [t=0.24s]
prediction: ['[CLS]. has funny sucks a moment or two but sucks [SEP]']
[ 900/2000] tot_loss=1.469 (perp=6.891, rec=0.086, cos=0.004), tot_loss_proj:2.426 [t=0.19s]
prediction: ['[CLS]. has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.457 (perp=6.891, rec=0.075, cos=0.004), tot_loss_proj:2.422 [t=0.18s]
prediction: ['[CLS]. has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1000/2000] tot_loss=1.457 (perp=6.891, rec=0.074, cos=0.004), tot_loss_proj:2.422 [t=0.18s]
prediction: ['[CLS]. has funny sucks a moment or two but sucks [SEP]']
[1050/2000] tot_loss=1.459 (perp=6.867, rec=0.081, cos=0.004), tot_loss_proj:2.318 [t=0.18s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1100/2000] tot_loss=1.453 (perp=6.867, rec=0.076, cos=0.004), tot_loss_proj:2.317 [t=0.23s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1150/2000] tot_loss=1.456 (perp=6.867, rec=0.078, cos=0.004), tot_loss_proj:2.317 [t=0.24s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
[1200/2000] tot_loss=1.457 (perp=6.867, rec=0.079, cos=0.004), tot_loss_proj:2.319 [t=0.24s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1250/2000] tot_loss=1.454 (perp=6.867, rec=0.076, cos=0.004), tot_loss_proj:2.316 [t=0.24s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1300/2000] tot_loss=1.455 (perp=6.867, rec=0.077, cos=0.004), tot_loss_proj:2.312 [t=0.19s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
[1350/2000] tot_loss=1.457 (perp=6.867, rec=0.080, cos=0.004), tot_loss_proj:2.320 [t=0.18s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1400/2000] tot_loss=1.450 (perp=6.867, rec=0.072, cos=0.004), tot_loss_proj:2.319 [t=0.19s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1450/2000] tot_loss=1.456 (perp=6.867, rec=0.078, cos=0.004), tot_loss_proj:2.316 [t=0.27s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
[1500/2000] tot_loss=1.449 (perp=6.867, rec=0.071, cos=0.004), tot_loss_proj:2.318 [t=0.19s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1550/2000] tot_loss=1.459 (perp=6.867, rec=0.082, cos=0.004), tot_loss_proj:2.316 [t=0.19s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1600/2000] tot_loss=1.450 (perp=6.867, rec=0.072, cos=0.004), tot_loss_proj:2.317 [t=0.20s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
[1650/2000] tot_loss=1.451 (perp=6.867, rec=0.073, cos=0.004), tot_loss_proj:2.320 [t=0.22s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1700/2000] tot_loss=1.453 (perp=6.867, rec=0.075, cos=0.004), tot_loss_proj:2.316 [t=0.27s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1750/2000] tot_loss=1.450 (perp=6.867, rec=0.073, cos=0.004), tot_loss_proj:2.317 [t=0.23s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
[1800/2000] tot_loss=1.447 (perp=6.867, rec=0.070, cos=0.004), tot_loss_proj:2.313 [t=0.21s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1850/2000] tot_loss=1.457 (perp=6.867, rec=0.079, cos=0.004), tot_loss_proj:2.319 [t=0.28s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[1900/2000] tot_loss=1.450 (perp=6.867, rec=0.072, cos=0.004), tot_loss_proj:2.319 [t=0.20s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
[1950/2000] tot_loss=1.457 (perp=6.867, rec=0.079, cos=0.004), tot_loss_proj:2.317 [t=0.22s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Attempt swap
[2000/2000] tot_loss=1.446 (perp=6.867, rec=0.069, cos=0.004), tot_loss_proj:2.318 [t=0.19s]
prediction: ['[CLS], has funny sucks a moment or two but sucks [SEP]']
Done with input #51 of 100.
reference: 
========================
[CLS] sucks, but has a funny moment or two. [SEP]
========================
predicted: 
========================
[CLS], has funny sucks a moment or two but sucks [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 95.238 | p: 90.909 | r: 100.000
rouge2     | fm: 21.053 | p: 20.000 | r: 22.222
rougeL     | fm: 66.667 | p: 63.636 | r: 70.000
rougeLsum  | fm: 66.667 | p: 63.636 | r: 70.000
r1fm+r2fm = 116.291

[Aggregate metrics]:
rouge1     | fm: 89.622 | p: 89.037 | r: 90.458
rouge2     | fm: 52.963 | p: 52.762 | r: 53.215
rougeL     | fm: 76.215 | p: 75.736 | r: 76.844
rougeLsum  | fm: 76.219 | p: 75.727 | r: 76.840
r1fm+r2fm = 142.585

input #51 time: 0:08:33 | total time: 7:24:53


Running input #52 of 100.
reference: 
========================
trailer-trash 
========================
average of cosine similarity 0.9992769471396806
highest_index [0]
highest [0.9992769471396806]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101,  9117,  1011, 11669,   102]], device='cuda:0')
Debug: ref = ['[CLS] trailer - trash [SEP]']
[Init] best rec loss: 1.9447109699249268 for ['[CLS] onto cells country [SEP]']
[Init] best rec loss: 1.8204642534255981 for ['[CLS]nae part turk [SEP]']
[Init] best rec loss: 1.6631529331207275 for ['[CLS] federally by these [SEP]']
[Init] best rec loss: 1.606566071510315 for ['[CLS] field darkedge [SEP]']
[Init] best rec loss: 1.5411300659179688 for ['[CLS] treated death straw [SEP]']
[Init] best rec loss: 1.0370672941207886 for ['[CLS] token ghetto tree [SEP]']
[Init] best rec loss: 0.9874905347824097 for ['[CLS] vocabulary football expected [SEP]']
[Init] best perm rec loss: 0.9856306314468384 for ['[CLS] expected football vocabulary [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.326 (perp=10.789, rec=0.163, cos=0.005), tot_loss_proj:2.557 [t=0.21s]
prediction: ['[CLS] trash trailer trash [SEP]']
[ 100/2000] tot_loss=2.242 (perp=10.655, rec=0.107, cos=0.004), tot_loss_proj:2.461 [t=0.28s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 150/2000] tot_loss=2.227 (perp=10.655, rec=0.092, cos=0.004), tot_loss_proj:2.452 [t=0.19s]
prediction: ['[CLS] trailer trailer trash [SEP]']
[ 200/2000] tot_loss=2.212 (perp=10.655, rec=0.078, cos=0.003), tot_loss_proj:2.467 [t=0.19s]
prediction: ['[CLS] trailer trailer trash [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.821 (perp=8.541, rec=0.110, cos=0.003), tot_loss_proj:2.166 [t=0.20s]
prediction: ['[CLS] trash trailer trailer [SEP]']
[ 300/2000] tot_loss=1.792 (perp=8.541, rec=0.082, cos=0.002), tot_loss_proj:2.161 [t=0.19s]
prediction: ['[CLS] trash trailer trailer [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.777 (perp=8.482, rec=0.079, cos=0.002), tot_loss_proj:2.131 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.002), tot_loss_proj:2.128 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 450/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.126 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.134 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.122 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 600/2000] tot_loss=1.765 (perp=8.482, rec=0.067, cos=0.001), tot_loss_proj:2.117 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.761 (perp=8.482, rec=0.063, cos=0.001), tot_loss_proj:2.124 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.768 (perp=8.482, rec=0.070, cos=0.001), tot_loss_proj:2.115 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 750/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.122 [t=0.18s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.122 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.128 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[ 900/2000] tot_loss=1.767 (perp=8.482, rec=0.070, cos=0.001), tot_loss_proj:2.119 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.123 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.121 [t=0.26s]
prediction: ['[CLS] trash trailer - [SEP]']
[1050/2000] tot_loss=1.771 (perp=8.482, rec=0.073, cos=0.001), tot_loss_proj:2.127 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.757 (perp=8.482, rec=0.059, cos=0.001), tot_loss_proj:2.127 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.764 (perp=8.482, rec=0.066, cos=0.001), tot_loss_proj:2.123 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
[1200/2000] tot_loss=1.762 (perp=8.482, rec=0.064, cos=0.001), tot_loss_proj:2.114 [t=0.31s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.119 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.753 (perp=8.482, rec=0.055, cos=0.001), tot_loss_proj:2.126 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
[1350/2000] tot_loss=1.753 (perp=8.482, rec=0.055, cos=0.001), tot_loss_proj:2.119 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.759 (perp=8.482, rec=0.061, cos=0.001), tot_loss_proj:2.116 [t=0.23s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.773 (perp=8.482, rec=0.075, cos=0.001), tot_loss_proj:2.129 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
[1500/2000] tot_loss=1.758 (perp=8.482, rec=0.060, cos=0.001), tot_loss_proj:2.119 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.121 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.121 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
[1650/2000] tot_loss=1.776 (perp=8.482, rec=0.078, cos=0.001), tot_loss_proj:2.117 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.751 (perp=8.482, rec=0.053, cos=0.001), tot_loss_proj:2.122 [t=0.25s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.756 (perp=8.482, rec=0.058, cos=0.001), tot_loss_proj:2.130 [t=0.24s]
prediction: ['[CLS] trash trailer - [SEP]']
[1800/2000] tot_loss=1.760 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.128 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.763 (perp=8.482, rec=0.065, cos=0.001), tot_loss_proj:2.124 [t=0.19s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.754 (perp=8.482, rec=0.056, cos=0.001), tot_loss_proj:2.124 [t=0.21s]
prediction: ['[CLS] trash trailer - [SEP]']
[1950/2000] tot_loss=1.769 (perp=8.482, rec=0.071, cos=0.001), tot_loss_proj:2.129 [t=0.20s]
prediction: ['[CLS] trash trailer - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.759 (perp=8.482, rec=0.062, cos=0.001), tot_loss_proj:2.126 [t=0.22s]
prediction: ['[CLS] trash trailer - [SEP]']
Done with input #52 of 100.
reference: 
========================
[CLS] trailer - trash [SEP]
========================
predicted: 
========================
[CLS] trash trailer - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.726 | p: 89.087 | r: 90.516
rouge2     | fm: 51.830 | p: 51.650 | r: 52.037
rougeL     | fm: 76.470 | p: 75.942 | r: 77.036
rougeLsum  | fm: 76.187 | p: 75.685 | r: 76.714
r1fm+r2fm = 141.556

input #52 time: 0:08:48 | total time: 7:33:42


Running input #53 of 100.
reference: 
========================
flinching 
========================
average of cosine similarity 0.9993462296030828
highest_index [0]
highest [0.9993462296030828]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 23224,  2075,   102]], device='cuda:0')
Debug: ref = ['[CLS] flinching [SEP]']
[Init] best rec loss: 1.7769790887832642 for ['[CLS] fixture trust [SEP]']
[Init] best rec loss: 1.7505303621292114 for ['[CLS] pledge se [SEP]']
[Init] best rec loss: 1.7399649620056152 for ['[CLS] government cf [SEP]']
[Init] best rec loss: 1.6215876340866089 for ['[CLS]gens maybe [SEP]']
[Init] best rec loss: 1.6025766134262085 for ['[CLS] manga rise [SEP]']
[Init] best rec loss: 1.2801052331924438 for ['[CLS] zone top [SEP]']
[Init] best rec loss: 1.2687050104141235 for ['[CLS]real hot [SEP]']
[Init] best rec loss: 1.1997308731079102 for ['[CLS] ralph not [SEP]']
[Init] best rec loss: 1.1960270404815674 for ['[CLS] university rock [SEP]']
[Init] best perm rec loss: 1.192598581314087 for ['[CLS] rock university [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.636 (perp=11.471, rec=0.276, cos=0.065), tot_loss_proj:3.027 [t=0.25s]
prediction: ['[CLS] fighting flinch [SEP]']
[ 100/2000] tot_loss=2.687 (perp=12.492, rec=0.165, cos=0.024), tot_loss_proj:3.337 [t=0.19s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 150/2000] tot_loss=2.653 (perp=12.492, rec=0.134, cos=0.020), tot_loss_proj:3.348 [t=0.21s]
prediction: ['[CLS] flinch flinch [SEP]']
[ 200/2000] tot_loss=2.696 (perp=12.492, rec=0.176, cos=0.021), tot_loss_proj:3.324 [t=0.25s]
prediction: ['[CLS] flinch flinch [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.570 (perp=12.413, rec=0.083, cos=0.005), tot_loss_proj:3.329 [t=0.18s]
prediction: ['[CLS]ing flinch [SEP]']
[ 300/2000] tot_loss=2.556 (perp=12.413, rec=0.071, cos=0.002), tot_loss_proj:3.330 [t=0.19s]
prediction: ['[CLS]ing flinch [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.682 (perp=8.090, rec=0.062, cos=0.002), tot_loss_proj:1.695 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.681 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[ 450/2000] tot_loss=1.676 (perp=8.090, rec=0.057, cos=0.001), tot_loss_proj:1.691 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.680 (perp=8.090, rec=0.061, cos=0.001), tot_loss_proj:1.703 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.681 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.698 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
[ 600/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.697 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.679 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.701 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.694 (perp=8.090, rec=0.075, cos=0.001), tot_loss_proj:1.693 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[ 750/2000] tot_loss=1.692 (perp=8.090, rec=0.073, cos=0.001), tot_loss_proj:1.695 [t=0.20s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.674 (perp=8.090, rec=0.055, cos=0.001), tot_loss_proj:1.690 [t=0.21s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.692 (perp=8.090, rec=0.073, cos=0.001), tot_loss_proj:1.692 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[ 900/2000] tot_loss=1.683 (perp=8.090, rec=0.064, cos=0.001), tot_loss_proj:1.694 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.687 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.701 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1000/2000] tot_loss=1.679 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.698 [t=0.29s]
prediction: ['[CLS] flinching [SEP]']
[1050/2000] tot_loss=1.686 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.697 [t=0.30s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1100/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.704 [t=0.28s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1150/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.694 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
[1200/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.687 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1250/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.689 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1300/2000] tot_loss=1.682 (perp=8.090, rec=0.063, cos=0.001), tot_loss_proj:1.682 [t=0.20s]
prediction: ['[CLS] flinching [SEP]']
[1350/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.700 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1400/2000] tot_loss=1.670 (perp=8.090, rec=0.051, cos=0.001), tot_loss_proj:1.690 [t=0.26s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1450/2000] tot_loss=1.682 (perp=8.090, rec=0.062, cos=0.001), tot_loss_proj:1.696 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[1500/2000] tot_loss=1.691 (perp=8.090, rec=0.072, cos=0.001), tot_loss_proj:1.690 [t=0.22s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1550/2000] tot_loss=1.672 (perp=8.090, rec=0.053, cos=0.001), tot_loss_proj:1.691 [t=0.23s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1600/2000] tot_loss=1.674 (perp=8.090, rec=0.054, cos=0.001), tot_loss_proj:1.691 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[1650/2000] tot_loss=1.696 (perp=8.090, rec=0.077, cos=0.001), tot_loss_proj:1.698 [t=0.20s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1700/2000] tot_loss=1.686 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.698 [t=0.20s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1750/2000] tot_loss=1.684 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.705 [t=0.24s]
prediction: ['[CLS] flinching [SEP]']
[1800/2000] tot_loss=1.686 (perp=8.090, rec=0.067, cos=0.001), tot_loss_proj:1.688 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1850/2000] tot_loss=1.685 (perp=8.090, rec=0.065, cos=0.001), tot_loss_proj:1.695 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[1900/2000] tot_loss=1.693 (perp=8.090, rec=0.074, cos=0.001), tot_loss_proj:1.689 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
[1950/2000] tot_loss=1.679 (perp=8.090, rec=0.060, cos=0.001), tot_loss_proj:1.693 [t=0.19s]
prediction: ['[CLS] flinching [SEP]']
Attempt swap
[2000/2000] tot_loss=1.678 (perp=8.090, rec=0.059, cos=0.001), tot_loss_proj:1.694 [t=0.27s]
prediction: ['[CLS] flinching [SEP]']
Done with input #53 of 100.
reference: 
========================
[CLS] flinching [SEP]
========================
predicted: 
========================
[CLS] flinching [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.009 | p: 89.396 | r: 90.762
rouge2     | fm: 52.720 | p: 52.526 | r: 52.951
rougeL     | fm: 76.886 | p: 76.367 | r: 77.380
rougeLsum  | fm: 76.516 | p: 76.006 | r: 77.064
r1fm+r2fm = 142.729

input #53 time: 0:08:50 | total time: 7:42:33


Running input #54 of 100.
reference: 
========================
hot topics 
========================
average of cosine similarity 0.9991885466091153
highest_index [0]
highest [0.9991885466091153]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[ 101, 2980, 7832,  102]], device='cuda:0')
Debug: ref = ['[CLS] hot topics [SEP]']
[Init] best rec loss: 1.7071905136108398 for ['[CLS] bill background [SEP]']
[Init] best rec loss: 1.552504062652588 for ['[CLS] living devices [SEP]']
[Init] best rec loss: 1.5421050786972046 for ['[CLS] trinity passed [SEP]']
[Init] best rec loss: 1.5026865005493164 for ['[CLS] solutions on [SEP]']
[Init] best rec loss: 1.2422250509262085 for ['[CLS] soon anxious [SEP]']
[Init] best rec loss: 1.139829158782959 for ['[CLS] delivery content [SEP]']
[Init] best rec loss: 1.0659000873565674 for ['[CLS] deployment bro [SEP]']
[Init] best rec loss: 0.9896990060806274 for ['[CLS] wild exercised [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.931 (perp=8.198, rec=0.271, cos=0.021), tot_loss_proj:1.741 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[ 100/2000] tot_loss=1.787 (perp=8.198, rec=0.141, cos=0.006), tot_loss_proj:1.742 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[ 150/2000] tot_loss=1.732 (perp=8.198, rec=0.088, cos=0.004), tot_loss_proj:1.742 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
[ 200/2000] tot_loss=1.721 (perp=8.198, rec=0.078, cos=0.003), tot_loss_proj:1.730 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.728 (perp=8.198, rec=0.084, cos=0.004), tot_loss_proj:1.740 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 300/2000] tot_loss=1.713 (perp=8.198, rec=0.071, cos=0.003), tot_loss_proj:1.734 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.710 (perp=8.198, rec=0.068, cos=0.003), tot_loss_proj:1.741 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.711 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.723 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[ 450/2000] tot_loss=1.705 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.735 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.712 (perp=8.198, rec=0.071, cos=0.002), tot_loss_proj:1.744 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.706 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.734 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
[ 600/2000] tot_loss=1.703 (perp=8.198, rec=0.062, cos=0.002), tot_loss_proj:1.725 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.709 (perp=8.198, rec=0.068, cos=0.002), tot_loss_proj:1.730 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.721 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
[ 750/2000] tot_loss=1.710 (perp=8.198, rec=0.068, cos=0.002), tot_loss_proj:1.729 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.690 (perp=8.198, rec=0.048, cos=0.002), tot_loss_proj:1.736 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.701 (perp=8.198, rec=0.059, cos=0.002), tot_loss_proj:1.738 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[ 900/2000] tot_loss=1.706 (perp=8.198, rec=0.065, cos=0.002), tot_loss_proj:1.734 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.707 (perp=8.198, rec=0.065, cos=0.002), tot_loss_proj:1.741 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1000/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.736 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[1050/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.741 [t=0.21s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1100/2000] tot_loss=1.688 (perp=8.198, rec=0.047, cos=0.002), tot_loss_proj:1.730 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1150/2000] tot_loss=1.702 (perp=8.198, rec=0.061, cos=0.002), tot_loss_proj:1.729 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
[1200/2000] tot_loss=1.706 (perp=8.198, rec=0.064, cos=0.002), tot_loss_proj:1.743 [t=0.29s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1250/2000] tot_loss=1.698 (perp=8.198, rec=0.057, cos=0.002), tot_loss_proj:1.726 [t=0.25s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1300/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.728 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
[1350/2000] tot_loss=1.710 (perp=8.198, rec=0.069, cos=0.002), tot_loss_proj:1.735 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1400/2000] tot_loss=1.695 (perp=8.198, rec=0.054, cos=0.002), tot_loss_proj:1.748 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1450/2000] tot_loss=1.711 (perp=8.198, rec=0.070, cos=0.002), tot_loss_proj:1.742 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
[1500/2000] tot_loss=1.709 (perp=8.198, rec=0.068, cos=0.002), tot_loss_proj:1.744 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1550/2000] tot_loss=1.701 (perp=8.198, rec=0.060, cos=0.002), tot_loss_proj:1.741 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1600/2000] tot_loss=1.708 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.735 [t=0.26s]
prediction: ['[CLS] hot topics [SEP]']
[1650/2000] tot_loss=1.695 (perp=8.198, rec=0.054, cos=0.002), tot_loss_proj:1.738 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1700/2000] tot_loss=1.707 (perp=8.198, rec=0.066, cos=0.002), tot_loss_proj:1.732 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1750/2000] tot_loss=1.693 (perp=8.198, rec=0.052, cos=0.002), tot_loss_proj:1.729 [t=0.27s]
prediction: ['[CLS] hot topics [SEP]']
[1800/2000] tot_loss=1.688 (perp=8.198, rec=0.047, cos=0.002), tot_loss_proj:1.743 [t=0.18s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1850/2000] tot_loss=1.705 (perp=8.198, rec=0.063, cos=0.002), tot_loss_proj:1.737 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[1900/2000] tot_loss=1.687 (perp=8.198, rec=0.046, cos=0.002), tot_loss_proj:1.734 [t=0.20s]
prediction: ['[CLS] hot topics [SEP]']
[1950/2000] tot_loss=1.699 (perp=8.198, rec=0.058, cos=0.002), tot_loss_proj:1.731 [t=0.24s]
prediction: ['[CLS] hot topics [SEP]']
Attempt swap
[2000/2000] tot_loss=1.708 (perp=8.198, rec=0.067, cos=0.002), tot_loss_proj:1.746 [t=0.19s]
prediction: ['[CLS] hot topics [SEP]']
Done with input #54 of 100.
reference: 
========================
[CLS] hot topics [SEP]
========================
predicted: 
========================
[CLS] hot topics [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.163 | p: 89.554 | r: 90.925
rouge2     | fm: 53.672 | p: 53.550 | r: 53.910
rougeL     | fm: 77.131 | p: 76.697 | r: 77.699
rougeLsum  | fm: 76.995 | p: 76.582 | r: 77.580
r1fm+r2fm = 143.835

input #54 time: 0:08:39 | total time: 7:51:12


Running input #55 of 100.
reference: 
========================
settles too easily 
========================
average of cosine similarity 0.9991205863745829
highest_index [0]
highest [0.9991205863745829]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 27221,  2205,  4089,   102]], device='cuda:0')
Debug: ref = ['[CLS] settles too easily [SEP]']
[Init] best rec loss: 1.8857332468032837 for ['[CLS] records althoughhony [SEP]']
[Init] best rec loss: 1.5969682931900024 for ['[CLS] due tired letters [SEP]']
[Init] best rec loss: 1.32254958152771 for ['[CLS] are martha erin [SEP]']
[Init] best rec loss: 1.3047670125961304 for ['[CLS]ies finished haired [SEP]']
[Init] best rec loss: 1.264054298400879 for ['[CLS] stride holly post [SEP]']
[Init] best rec loss: 1.2127386331558228 for ['[CLS] precipitation written mounted [SEP]']
[Init] best perm rec loss: 1.2090678215026855 for ['[CLS] written precipitation mounted [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.602 (perp=8.740, rec=0.525, cos=0.329), tot_loss_proj:3.483 [t=0.19s]
prediction: ['[CLS] no resignation factors [SEP]']
[ 100/2000] tot_loss=2.568 (perp=10.346, rec=0.376, cos=0.123), tot_loss_proj:3.423 [t=0.18s]
prediction: ['[CLS] no deeper settles [SEP]']
[ 150/2000] tot_loss=2.768 (perp=12.183, rec=0.278, cos=0.053), tot_loss_proj:3.924 [t=0.19s]
prediction: ['[CLS] easily worse settles [SEP]']
[ 200/2000] tot_loss=2.608 (perp=12.144, rec=0.164, cos=0.015), tot_loss_proj:3.033 [t=0.21s]
prediction: ['[CLS] easily too settles [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.839 (perp=8.687, rec=0.096, cos=0.005), tot_loss_proj:2.242 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
[ 300/2000] tot_loss=1.822 (perp=8.687, rec=0.082, cos=0.003), tot_loss_proj:2.242 [t=0.27s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.807 (perp=8.687, rec=0.067, cos=0.002), tot_loss_proj:2.254 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.797 (perp=8.687, rec=0.057, cos=0.002), tot_loss_proj:2.259 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
[ 450/2000] tot_loss=1.813 (perp=8.687, rec=0.073, cos=0.002), tot_loss_proj:2.262 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.806 (perp=8.687, rec=0.067, cos=0.002), tot_loss_proj:2.267 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.807 (perp=8.687, rec=0.068, cos=0.002), tot_loss_proj:2.261 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
[ 600/2000] tot_loss=1.817 (perp=8.687, rec=0.078, cos=0.002), tot_loss_proj:2.245 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.806 (perp=8.687, rec=0.067, cos=0.002), tot_loss_proj:2.253 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.798 (perp=8.687, rec=0.059, cos=0.002), tot_loss_proj:2.248 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
[ 750/2000] tot_loss=1.809 (perp=8.687, rec=0.070, cos=0.002), tot_loss_proj:2.248 [t=0.26s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.814 (perp=8.687, rec=0.075, cos=0.002), tot_loss_proj:2.260 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.806 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.254 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
[ 900/2000] tot_loss=1.817 (perp=8.687, rec=0.078, cos=0.002), tot_loss_proj:2.253 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.803 (perp=8.687, rec=0.063, cos=0.002), tot_loss_proj:2.253 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1000/2000] tot_loss=1.811 (perp=8.687, rec=0.072, cos=0.002), tot_loss_proj:2.260 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
[1050/2000] tot_loss=1.799 (perp=8.687, rec=0.060, cos=0.002), tot_loss_proj:2.254 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1100/2000] tot_loss=1.793 (perp=8.687, rec=0.054, cos=0.002), tot_loss_proj:2.258 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1150/2000] tot_loss=1.797 (perp=8.687, rec=0.058, cos=0.002), tot_loss_proj:2.255 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
[1200/2000] tot_loss=1.801 (perp=8.687, rec=0.062, cos=0.002), tot_loss_proj:2.265 [t=0.23s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1250/2000] tot_loss=1.808 (perp=8.687, rec=0.069, cos=0.002), tot_loss_proj:2.259 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1300/2000] tot_loss=1.813 (perp=8.687, rec=0.074, cos=0.002), tot_loss_proj:2.254 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
[1350/2000] tot_loss=1.791 (perp=8.687, rec=0.051, cos=0.002), tot_loss_proj:2.255 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1400/2000] tot_loss=1.801 (perp=8.687, rec=0.062, cos=0.002), tot_loss_proj:2.257 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1450/2000] tot_loss=1.802 (perp=8.687, rec=0.063, cos=0.002), tot_loss_proj:2.254 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
[1500/2000] tot_loss=1.797 (perp=8.687, rec=0.058, cos=0.002), tot_loss_proj:2.256 [t=0.18s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1550/2000] tot_loss=1.814 (perp=8.687, rec=0.075, cos=0.002), tot_loss_proj:2.254 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1600/2000] tot_loss=1.811 (perp=8.687, rec=0.072, cos=0.002), tot_loss_proj:2.252 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
[1650/2000] tot_loss=1.800 (perp=8.687, rec=0.061, cos=0.002), tot_loss_proj:2.250 [t=0.21s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1700/2000] tot_loss=1.804 (perp=8.687, rec=0.065, cos=0.002), tot_loss_proj:2.261 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1750/2000] tot_loss=1.805 (perp=8.687, rec=0.066, cos=0.002), tot_loss_proj:2.252 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1800/2000] tot_loss=1.807 (perp=8.687, rec=0.068, cos=0.002), tot_loss_proj:2.259 [t=0.20s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1850/2000] tot_loss=1.800 (perp=8.687, rec=0.061, cos=0.002), tot_loss_proj:2.266 [t=0.24s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[1900/2000] tot_loss=1.810 (perp=8.687, rec=0.071, cos=0.002), tot_loss_proj:2.251 [t=0.25s]
prediction: ['[CLS] too easily settles [SEP]']
[1950/2000] tot_loss=1.797 (perp=8.687, rec=0.058, cos=0.002), tot_loss_proj:2.263 [t=0.22s]
prediction: ['[CLS] too easily settles [SEP]']
Attempt swap
[2000/2000] tot_loss=1.804 (perp=8.687, rec=0.065, cos=0.002), tot_loss_proj:2.250 [t=0.19s]
prediction: ['[CLS] too easily settles [SEP]']
Done with input #55 of 100.
reference: 
========================
[CLS] settles too easily [SEP]
========================
predicted: 
========================
[CLS] too easily settles [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 90.428 | p: 89.808 | r: 91.154
rouge2     | fm: 53.214 | p: 52.996 | r: 53.404
rougeL     | fm: 77.244 | p: 76.776 | r: 77.838
rougeLsum  | fm: 77.045 | p: 76.518 | r: 77.667
r1fm+r2fm = 143.642

input #55 time: 0:08:38 | total time: 7:59:51


Running input #56 of 100.
reference: 
========================
films which will cause loads of irreparable damage that years and years of costly analysis could never fix 
========================
average of cosine similarity 0.9992743912224646
highest_index [0]
highest [0.9992743912224646]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[  101,  3152,  2029,  2097,  3426, 15665,  1997, 20868,  2890, 28689,
          3468,  4053,  2008,  2086,  1998,  2086,  1997, 17047,  4106,  2071,
          2196,  8081,   102]], device='cuda:0')
Debug: ref = ['[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]']
[Init] best rec loss: 1.7055118083953857 for ['[CLS] rotting pleading victim hug signed lose tongue rebuilt biocky may listen voltage stein burnt districtde despite course shown [SEP]']
[Init] best rec loss: 1.6200506687164307 for ['[CLS] component sequence authority at language bit bottom now cross dominant offer. % setrated familyride ex into told hedge [SEP]']
[Init] best rec loss: 1.5344394445419312 for ['[CLS] press passhunorescence ellenot eveviritan conditioning sale past fabric lines plenty parentsstick? family need us [SEP]']
[Init] best rec loss: 1.4744815826416016 for ['[CLS] code laid sense strike determined iron depression charter bear technique avidured blame ; en unfortunately backed sympathy tis reflection k [SEP]']
[Init] best perm rec loss: 1.4654475450515747 for ['[CLS] sense en depression avid laid ironured bear k strike blame reflection technique determined backed unfortunately ; sympathy charter code tis [SEP]']
[Init] best perm rec loss: 1.456282377243042 for ['[CLS] strike charter unfortunately en backed reflection code laid tis blame k determined depression technique sense bear sympathy ironured ; avid [SEP]']
[Init] best perm rec loss: 1.4561269283294678 for ['[CLS] technique charter backed ; iron avid code sympathy sense bear determined laid en reflection depression tis blame k unfortunately strikeured [SEP]']
[Init] best perm rec loss: 1.4547836780548096 for ['[CLS] technique charter en tis kured code ; determined blame sympathy reflection sense unfortunately depression bear iron laid backed avid strike [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.568 (perp=11.494, rec=0.258, cos=0.011), tot_loss_proj:3.903 [t=0.24s]
prediction: ['[CLS] criminal event mortal films of damage bring years as expensive probably films during damage of things 1983 analysis reviewfighting films [SEP]']
[ 100/2000] tot_loss=2.695 (perp=12.472, rec=0.193, cos=0.008), tot_loss_proj:4.032 [t=0.26s]
prediction: ['[CLS] cause primarily decades films which damage fix years which expensive tons films that costly of could analysis never costly easier films [SEP]']
[ 150/2000] tot_loss=2.363 (perp=11.101, rec=0.140, cos=0.003), tot_loss_proj:3.729 [t=0.32s]
prediction: ['[CLS] cause possibility decades loads which damage fix that a damage loads analysis of costly never could analysis never costly fix films [SEP]']
[ 200/2000] tot_loss=2.435 (perp=11.596, rec=0.114, cos=0.002), tot_loss_proj:3.703 [t=0.19s]
prediction: ['[CLS] cause will years loads which damage fix that of damage loads analysis of costly never couldpara never costly never films [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.469 (perp=11.798, rec=0.107, cos=0.003), tot_loss_proj:3.495 [t=0.28s]
prediction: ['[CLS] cause will years never which damage fix that ofpara loads analysis years costly never couldpara loads costly never films [SEP]']
[ 300/2000] tot_loss=2.630 (perp=12.702, rec=0.088, cos=0.002), tot_loss_proj:3.543 [t=0.20s]
prediction: ['[CLS] cause willpara never which damage fix that ofble loads analysis years costly never couldpara loads years never films [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.443 (perp=11.759, rec=0.090, cos=0.002), tot_loss_proj:3.316 [t=0.26s]
prediction: ['[CLS] cause willpara never which damage fix that ofble costly loads analysis years never couldpara loads years never films [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=2.241 (perp=10.740, rec=0.091, cos=0.002), tot_loss_proj:3.091 [t=0.29s]
prediction: ['[CLS] cause will never which damage fix that ofparable costly loads analysis years never couldpara loads years never films [SEP]']
[ 450/2000] tot_loss=2.239 (perp=10.740, rec=0.089, cos=0.002), tot_loss_proj:3.096 [t=0.20s]
prediction: ['[CLS] cause will never which damage fix that ofparable costly loads analysis years never couldpara loads years never films [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.123 (perp=10.171, rec=0.088, cos=0.002), tot_loss_proj:3.041 [t=0.19s]
prediction: ['[CLS] cause will neverpara which damage fix that ofparable costly loads analysis years never could loads years never films [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=2.056 (perp=9.871, rec=0.080, cos=0.002), tot_loss_proj:2.964 [t=0.23s]
prediction: ['[CLS] cause will neverpara which damage fix that ofparable costly loads analysis years never could films loads years never [SEP]']
[ 600/2000] tot_loss=2.099 (perp=10.105, rec=0.076, cos=0.002), tot_loss_proj:3.021 [t=0.21s]
prediction: ['[CLS] cause will neverpara which damage fix that ofparable costly loads analysis years never could films ir years never [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.058 (perp=9.896, rec=0.077, cos=0.002), tot_loss_proj:3.093 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fix that ofparable costly loads analysis years never could films ir years never [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.954 (perp=9.361, rec=0.080, cos=0.002), tot_loss_proj:2.892 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre ofparable costly loads analysis years never could films that years never [SEP]']
[ 750/2000] tot_loss=1.913 (perp=9.136, rec=0.084, cos=0.002), tot_loss_proj:2.843 [t=0.20s]
prediction: ['[CLS] cause which will neverpara damage fixre ofparable costly loads analysis of never could films that years never [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.862 (perp=8.957, rec=0.070, cos=0.002), tot_loss_proj:2.872 [t=0.24s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly loads analysis of films could never that years never [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.816 (perp=8.694, rec=0.076, cos=0.002), tot_loss_proj:2.904 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly loads analysis of films that could never years never [SEP]']
[ 900/2000] tot_loss=1.818 (perp=8.694, rec=0.077, cos=0.002), tot_loss_proj:2.904 [t=0.24s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly loads analysis of films that could never years never [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.771 (perp=8.445, rec=0.081, cos=0.002), tot_loss_proj:2.617 [t=0.25s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads of films that could never years never [SEP]']
Attempt swap
[1000/2000] tot_loss=1.761 (perp=8.445, rec=0.071, cos=0.002), tot_loss_proj:2.619 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads of films that could never years never [SEP]']
[1050/2000] tot_loss=1.773 (perp=8.445, rec=0.082, cos=0.002), tot_loss_proj:2.623 [t=0.27s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads of films that could never years never [SEP]']
Attempt swap
[1100/2000] tot_loss=1.760 (perp=8.445, rec=0.069, cos=0.002), tot_loss_proj:2.619 [t=0.25s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads of films that could never years never [SEP]']
Attempt swap
[1150/2000] tot_loss=1.798 (perp=8.581, rec=0.081, cos=0.002), tot_loss_proj:2.661 [t=0.20s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
[1200/2000] tot_loss=1.796 (perp=8.581, rec=0.079, cos=0.002), tot_loss_proj:2.671 [t=0.22s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
Attempt swap
[1250/2000] tot_loss=1.794 (perp=8.581, rec=0.077, cos=0.002), tot_loss_proj:2.670 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
Attempt swap
[1300/2000] tot_loss=1.790 (perp=8.581, rec=0.072, cos=0.002), tot_loss_proj:2.676 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
[1350/2000] tot_loss=1.795 (perp=8.581, rec=0.077, cos=0.002), tot_loss_proj:2.671 [t=0.23s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
Attempt swap
[1400/2000] tot_loss=1.786 (perp=8.581, rec=0.069, cos=0.002), tot_loss_proj:2.675 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
Attempt swap
[1450/2000] tot_loss=1.787 (perp=8.581, rec=0.069, cos=0.002), tot_loss_proj:2.667 [t=0.21s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
[1500/2000] tot_loss=1.789 (perp=8.581, rec=0.071, cos=0.002), tot_loss_proj:2.669 [t=0.20s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
Attempt swap
[1550/2000] tot_loss=1.790 (perp=8.581, rec=0.072, cos=0.002), tot_loss_proj:2.671 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
Attempt swap
[1600/2000] tot_loss=1.787 (perp=8.581, rec=0.069, cos=0.002), tot_loss_proj:2.667 [t=0.20s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
[1650/2000] tot_loss=1.792 (perp=8.581, rec=0.074, cos=0.002), tot_loss_proj:2.676 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
Attempt swap
[1700/2000] tot_loss=1.792 (perp=8.581, rec=0.074, cos=0.002), tot_loss_proj:2.673 [t=0.20s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.788 (perp=8.574, rec=0.072, cos=0.002), tot_loss_proj:2.829 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and that films could never years never [SEP]']
[1800/2000] tot_loss=1.782 (perp=8.574, rec=0.066, cos=0.002), tot_loss_proj:2.832 [t=0.19s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and that films could never years never [SEP]']
Attempt swap
[1850/2000] tot_loss=1.787 (perp=8.574, rec=0.071, cos=0.002), tot_loss_proj:2.828 [t=0.22s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and that films could never years never [SEP]']
Attempt swap
[1900/2000] tot_loss=1.789 (perp=8.574, rec=0.073, cos=0.002), tot_loss_proj:2.825 [t=0.20s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and that films could never years never [SEP]']
[1950/2000] tot_loss=1.786 (perp=8.574, rec=0.070, cos=0.002), tot_loss_proj:2.828 [t=0.20s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and that films could never years never [SEP]']
Attempt swap
[2000/2000] tot_loss=1.791 (perp=8.574, rec=0.075, cos=0.002), tot_loss_proj:2.831 [t=0.27s]
prediction: ['[CLS] cause which will neverpara damage fixre of irble costly analysis loads and that films could never years never [SEP]']
Done with input #56 of 100.
reference: 
========================
[CLS] films which will cause loads of irreparable damage that years and years of costly analysis could never fix [SEP]
========================
predicted: 
========================
[CLS] cause which will neverpara damage fixre of irble costly analysis loads and films that could never years never [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 80.000 | p: 80.000 | r: 80.000
rouge2     | fm: 15.789 | p: 15.789 | r: 15.789
rougeL     | fm: 50.000 | p: 50.000 | r: 50.000
rougeLsum  | fm: 50.000 | p: 50.000 | r: 50.000
r1fm+r2fm = 95.789

[Aggregate metrics]:
rouge1     | fm: 90.209 | p: 89.611 | r: 90.926
rouge2     | fm: 52.407 | p: 52.235 | r: 52.585
rougeL     | fm: 76.791 | p: 76.306 | r: 77.400
rougeLsum  | fm: 76.628 | p: 76.126 | r: 77.123
r1fm+r2fm = 142.616

input #56 time: 0:08:52 | total time: 8:08:44


Running input #57 of 100.
reference: 
========================
wears 
========================
average of cosine similarity 0.9993815950585874
highest_index [0]
highest [0.9993815950585874]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[  101, 11651,   102]], device='cuda:0')
Debug: ref = ['[CLS] wears [SEP]']
[Init] best rec loss: 1.7954795360565186 for ['[CLS]ne [SEP]']
[Init] best rec loss: 1.633437156677246 for ['[CLS] software [SEP]']
[Init] best rec loss: 1.5058315992355347 for ['[CLS] passed [SEP]']
[Init] best rec loss: 1.4965696334838867 for ['[CLS]cta [SEP]']
[Init] best rec loss: 1.4871668815612793 for ['[CLS] modern [SEP]']
[Init] best rec loss: 1.4436358213424683 for ['[CLS] bundesliga [SEP]']
[Init] best rec loss: 1.4208097457885742 for ['[CLS] thanks [SEP]']
[Init] best rec loss: 1.4164838790893555 for ['[CLS] decision [SEP]']
[Init] best rec loss: 1.390770435333252 for ['[CLS]ering [SEP]']
[Init] best rec loss: 1.3783762454986572 for ['[CLS] dorm [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.844 (perp=8.573, rec=0.538, cos=0.592), tot_loss_proj:3.487 [t=0.19s]
prediction: ['[CLS] graduate [SEP]']
[ 100/2000] tot_loss=2.695 (perp=12.282, rec=0.185, cos=0.054), tot_loss_proj:2.510 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[ 150/2000] tot_loss=2.550 (perp=12.282, rec=0.084, cos=0.010), tot_loss_proj:2.514 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[ 200/2000] tot_loss=2.519 (perp=12.282, rec=0.060, cos=0.002), tot_loss_proj:2.515 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.002), tot_loss_proj:2.523 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[ 300/2000] tot_loss=2.513 (perp=12.282, rec=0.055, cos=0.002), tot_loss_proj:2.518 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.521 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.514 (perp=12.282, rec=0.056, cos=0.001), tot_loss_proj:2.508 [t=0.22s]
prediction: ['[CLS] wears [SEP]']
[ 450/2000] tot_loss=2.525 (perp=12.282, rec=0.067, cos=0.001), tot_loss_proj:2.508 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.518 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.531 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.524 (perp=12.282, rec=0.067, cos=0.001), tot_loss_proj:2.528 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[ 600/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.518 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.504 (perp=12.282, rec=0.047, cos=0.001), tot_loss_proj:2.525 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.509 (perp=12.282, rec=0.051, cos=0.001), tot_loss_proj:2.525 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[ 750/2000] tot_loss=2.505 (perp=12.282, rec=0.047, cos=0.001), tot_loss_proj:2.520 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.520 (perp=12.282, rec=0.062, cos=0.001), tot_loss_proj:2.512 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.512 (perp=12.282, rec=0.054, cos=0.001), tot_loss_proj:2.520 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[ 900/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.515 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.521 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.513 [t=0.26s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1000/2000] tot_loss=2.508 (perp=12.282, rec=0.051, cos=0.001), tot_loss_proj:2.521 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1050/2000] tot_loss=2.506 (perp=12.282, rec=0.048, cos=0.001), tot_loss_proj:2.508 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1100/2000] tot_loss=2.513 (perp=12.282, rec=0.056, cos=0.001), tot_loss_proj:2.516 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1150/2000] tot_loss=2.527 (perp=12.282, rec=0.069, cos=0.001), tot_loss_proj:2.522 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
[1200/2000] tot_loss=2.503 (perp=12.282, rec=0.045, cos=0.001), tot_loss_proj:2.521 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1250/2000] tot_loss=2.509 (perp=12.282, rec=0.051, cos=0.001), tot_loss_proj:2.523 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1300/2000] tot_loss=2.514 (perp=12.282, rec=0.057, cos=0.001), tot_loss_proj:2.516 [t=0.25s]
prediction: ['[CLS] wears [SEP]']
[1350/2000] tot_loss=2.509 (perp=12.282, rec=0.052, cos=0.001), tot_loss_proj:2.521 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1400/2000] tot_loss=2.516 (perp=12.282, rec=0.058, cos=0.001), tot_loss_proj:2.521 [t=0.23s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1450/2000] tot_loss=2.522 (perp=12.282, rec=0.064, cos=0.001), tot_loss_proj:2.521 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[1500/2000] tot_loss=2.528 (perp=12.282, rec=0.070, cos=0.001), tot_loss_proj:2.505 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1550/2000] tot_loss=2.522 (perp=12.282, rec=0.065, cos=0.001), tot_loss_proj:2.527 [t=0.21s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1600/2000] tot_loss=2.505 (perp=12.282, rec=0.048, cos=0.001), tot_loss_proj:2.523 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[1650/2000] tot_loss=2.506 (perp=12.282, rec=0.048, cos=0.001), tot_loss_proj:2.510 [t=0.28s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1700/2000] tot_loss=2.525 (perp=12.282, rec=0.067, cos=0.001), tot_loss_proj:2.511 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1750/2000] tot_loss=2.518 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.507 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[1800/2000] tot_loss=2.518 (perp=12.282, rec=0.060, cos=0.001), tot_loss_proj:2.513 [t=0.20s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1850/2000] tot_loss=2.524 (perp=12.282, rec=0.067, cos=0.001), tot_loss_proj:2.542 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[1900/2000] tot_loss=2.528 (perp=12.282, rec=0.071, cos=0.001), tot_loss_proj:2.509 [t=0.19s]
prediction: ['[CLS] wears [SEP]']
[1950/2000] tot_loss=2.521 (perp=12.282, rec=0.063, cos=0.001), tot_loss_proj:2.515 [t=0.27s]
prediction: ['[CLS] wears [SEP]']
Attempt swap
[2000/2000] tot_loss=2.519 (perp=12.282, rec=0.061, cos=0.001), tot_loss_proj:2.519 [t=0.18s]
prediction: ['[CLS] wears [SEP]']
Done with input #57 of 100.
reference: 
========================
[CLS] wears [SEP]
========================
predicted: 
========================
[CLS] wears [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.344 | p: 89.794 | r: 91.068
rouge2     | fm: 53.327 | p: 53.171 | r: 53.508
rougeL     | fm: 77.059 | p: 76.661 | r: 77.651
rougeLsum  | fm: 76.853 | p: 76.400 | r: 77.382
r1fm+r2fm = 143.671

input #57 time: 0:08:32 | total time: 8:17:16


Running input #58 of 100.
reference: 
========================
is an inspirational love story , capturing the innocence and idealism of that first encounter 
========================
average of cosine similarity 0.9992685151622416
highest_index [0]
highest [0.9992685151622416]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2003,  2019, 28676,  2293,  2466,  1010, 11847,  1996, 12660,
          1998,  7812,  2964,  1997,  2008,  2034,  8087,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]']
[Init] best rec loss: 1.8984190225601196 for ['[CLS] necessary cheated congregation nippleanian hold meetback seeking than claws bones position ever jobs time [SEP]']
[Init] best rec loss: 1.8598558902740479 for ['[CLS] thinking humming human speakers generalyal ended lowlands per willuity music hearts timing jazz toys [SEP]']
[Init] best rec loss: 1.6641579866409302 for ['[CLS] ) after rca adventures / yong beat bad http stoodagendingple ]erson trailing [SEP]']
[Init] best rec loss: 1.6362143754959106 for ['[CLS] insidethed subject layton devoted approachhead physicians keys vice tarzan mile norman warlord choosebaldi [SEP]']
[Init] best rec loss: 1.633800745010376 for ['[CLS] hissedoop whispered h delayed!lwyn [SEP] could prove atrocities backsie square shu tam [SEP]']
[Init] best rec loss: 1.5590686798095703 for ['[CLS]lusion wake case species applicationnding fluent passing bakeralo couple win used texas installed tucker [SEP]']
[Init] best perm rec loss: 1.5537745952606201 for ['[CLS] passingalo species used baker installednding tucker texas win wakelusion couple application case fluent [SEP]']
[Init] best perm rec loss: 1.5531631708145142 for ['[CLS] tucker installed used texas case bakerlusionnding wake application fluentalo couple passing species win [SEP]']
[Init] best perm rec loss: 1.5502347946166992 for ['[CLS] texas fluent used tucker bakeralolusion application case installednding passing win couple wake species [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.965 (perp=11.368, rec=0.568, cos=0.123), tot_loss_proj:4.210 [t=0.19s]
prediction: ['[CLS] sydney ⁿ how chance tom to football application parallel stuck season london win couple chemistry feeling [SEP]']
[ 100/2000] tot_loss=2.771 (perp=11.704, rec=0.400, cos=0.031), tot_loss_proj:3.800 [t=0.19s]
prediction: ['[CLS] yourself gripping how medicine river or football application parallel choose season love brand couple music psychology [SEP]']
[ 150/2000] tot_loss=2.593 (perp=11.535, rec=0.277, cos=0.009), tot_loss_proj:3.662 [t=0.20s]
prediction: ['[CLS] yourself, an medicine river or football application tale amongst season love inspirational recreation chemistry psychology [SEP]']
[ 200/2000] tot_loss=2.343 (perp=10.480, rec=0.242, cos=0.006), tot_loss_proj:3.245 [t=0.26s]
prediction: ['[CLS] thoughtful, ansters ocean and legal application pieces chose season love inspirational recreation chemistry story [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.385 (perp=10.810, rec=0.218, cos=0.006), tot_loss_proj:4.095 [t=0.32s]
prediction: ['[CLS] mitchell or an airs ocean, football application puzzle chose season. inspirational couple rap story [SEP]']
[ 300/2000] tot_loss=2.493 (perp=11.449, rec=0.199, cos=0.004), tot_loss_proj:4.030 [t=0.20s]
prediction: ['[CLS] mitchell and an innocence ocean,oping application initial chose season love inspirational love rap story [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.342 (perp=10.768, rec=0.184, cos=0.004), tot_loss_proj:3.833 [t=0.19s]
prediction: ['[CLS]oping and is innocence synthesis, texas application initial chose season love inspirational love rap story [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.186 (perp=10.050, rec=0.172, cos=0.004), tot_loss_proj:3.472 [t=0.20s]
prediction: ['[CLS]oping love is innocence synthesis, texas application initial chose season and inspirational love chemistry story [SEP]']
[ 450/2000] tot_loss=2.179 (perp=10.050, rec=0.165, cos=0.003), tot_loss_proj:3.462 [t=0.19s]
prediction: ['[CLS]oping love is innocence synthesis, texas application initial chose season and inspirational love chemistry story [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.287 (perp=10.601, rec=0.163, cos=0.003), tot_loss_proj:3.947 [t=0.19s]
prediction: ['[CLS] his those is innocenceesa, texas application initial chose rap and inspirational love season story [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.178 (perp=10.082, rec=0.158, cos=0.003), tot_loss_proj:3.954 [t=0.19s]
prediction: ['[CLS] his those is innocenceesa, think application initial and chose rap inspirational love season story [SEP]']
[ 600/2000] tot_loss=2.201 (perp=10.238, rec=0.150, cos=0.003), tot_loss_proj:3.774 [t=0.22s]
prediction: ['[CLS] the those is innocenceesa, think application initial and representing rap inspirational love season story [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=2.106 (perp=9.782, rec=0.147, cos=0.003), tot_loss_proj:3.702 [t=0.20s]
prediction: ['[CLS] those is the innocence descendants, think application initial and representing rap inspirational love season story [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.088 (perp=9.695, rec=0.146, cos=0.003), tot_loss_proj:3.365 [t=0.19s]
prediction: ['[CLS] those is the innocence chemistry, think application initial and representingism inspirational love season story [SEP]']
[ 750/2000] tot_loss=2.059 (perp=9.611, rec=0.134, cos=0.003), tot_loss_proj:2.588 [t=0.19s]
prediction: ['[CLS] those is the capturing chemistry, think application initial and goldenism inspirational love season story [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.968 (perp=9.129, rec=0.139, cos=0.003), tot_loss_proj:2.414 [t=0.20s]
prediction: ['[CLS] those is the capturing chemistry, think applicationism and golden encounter inspirational love season story [SEP]']
Attempt swap
Moved sequence
[ 850/2000] tot_loss=1.737 (perp=7.966, rec=0.141, cos=0.003), tot_loss_proj:2.080 [t=0.29s]
prediction: ['[CLS] love is the season capturing chemistry, think individualism and golden initial inspirational love story [SEP]']
[ 900/2000] tot_loss=1.718 (perp=7.962, rec=0.123, cos=0.003), tot_loss_proj:2.103 [t=0.18s]
prediction: ['[CLS] those is the season capturing chemistry, think individualism and golden encounter inspirational love story [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.763 (perp=8.147, rec=0.131, cos=0.003), tot_loss_proj:2.268 [t=0.24s]
prediction: ['[CLS] those is the season capturing chemistry, think individualism inspirational golden initial and love story [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.692 (perp=7.795, rec=0.130, cos=0.003), tot_loss_proj:2.099 [t=0.21s]
prediction: ['[CLS] love is the season capturing encounter, inspirational individualism think golden first and love story [SEP]']
[1050/2000] tot_loss=1.690 (perp=7.795, rec=0.129, cos=0.003), tot_loss_proj:2.099 [t=0.24s]
prediction: ['[CLS] love is the season capturing encounter, inspirational individualism think golden first and love story [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.829 (perp=8.507, rec=0.125, cos=0.003), tot_loss_proj:2.361 [t=0.20s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think golden the first love story [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.757 (perp=8.149, rec=0.124, cos=0.003), tot_loss_proj:2.263 [t=0.21s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first golden love story [SEP]']
[1200/2000] tot_loss=1.757 (perp=8.149, rec=0.125, cos=0.003), tot_loss_proj:2.261 [t=0.23s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first golden love story [SEP]']
Attempt swap
[1250/2000] tot_loss=1.758 (perp=8.149, rec=0.126, cos=0.003), tot_loss_proj:2.264 [t=0.20s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first golden love story [SEP]']
Attempt swap
[1300/2000] tot_loss=1.756 (perp=8.149, rec=0.123, cos=0.003), tot_loss_proj:2.261 [t=0.24s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first golden love story [SEP]']
[1350/2000] tot_loss=1.754 (perp=8.149, rec=0.122, cos=0.003), tot_loss_proj:2.262 [t=0.19s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first golden love story [SEP]']
Attempt swap
[1400/2000] tot_loss=1.761 (perp=8.149, rec=0.129, cos=0.003), tot_loss_proj:2.261 [t=0.23s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first golden love story [SEP]']
Attempt swap
[1450/2000] tot_loss=1.736 (perp=8.100, rec=0.114, cos=0.003), tot_loss_proj:2.329 [t=0.23s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
[1500/2000] tot_loss=1.741 (perp=8.100, rec=0.118, cos=0.003), tot_loss_proj:2.328 [t=0.20s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
Attempt swap
[1550/2000] tot_loss=1.739 (perp=8.100, rec=0.116, cos=0.003), tot_loss_proj:2.331 [t=0.19s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
Attempt swap
[1600/2000] tot_loss=1.745 (perp=8.100, rec=0.123, cos=0.003), tot_loss_proj:2.324 [t=0.25s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
[1650/2000] tot_loss=1.744 (perp=8.100, rec=0.122, cos=0.003), tot_loss_proj:2.333 [t=0.25s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
Attempt swap
[1700/2000] tot_loss=1.740 (perp=8.100, rec=0.117, cos=0.003), tot_loss_proj:2.325 [t=0.23s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
Attempt swap
[1750/2000] tot_loss=1.740 (perp=8.100, rec=0.118, cos=0.003), tot_loss_proj:2.329 [t=0.20s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
[1800/2000] tot_loss=1.734 (perp=8.100, rec=0.111, cos=0.003), tot_loss_proj:2.329 [t=0.25s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
Attempt swap
[1850/2000] tot_loss=1.743 (perp=8.100, rec=0.120, cos=0.003), tot_loss_proj:2.323 [t=0.24s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
Attempt swap
[1900/2000] tot_loss=1.745 (perp=8.100, rec=0.123, cos=0.003), tot_loss_proj:2.321 [t=0.28s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
[1950/2000] tot_loss=1.732 (perp=8.100, rec=0.110, cos=0.003), tot_loss_proj:2.321 [t=0.19s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
Attempt swap
[2000/2000] tot_loss=1.730 (perp=8.100, rec=0.107, cos=0.003), tot_loss_proj:2.321 [t=0.25s]
prediction: ['[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]']
Done with input #58 of 100.
reference: 
========================
[CLS] is an inspirational love story, capturing the innocence and idealism of that first encounter [SEP]
========================
predicted: 
========================
[CLS] love is the season capturing encounter, inspirational applicationism think the first innocence love story [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 68.750 | p: 68.750 | r: 68.750
rouge2     | fm: 6.667 | p: 6.667 | r: 6.667
rougeL     | fm: 37.500 | p: 37.500 | r: 37.500
rougeLsum  | fm: 37.500 | p: 37.500 | r: 37.500
r1fm+r2fm = 75.417

[Aggregate metrics]:
rouge1     | fm: 89.999 | p: 89.484 | r: 90.677
rouge2     | fm: 52.682 | p: 52.516 | r: 52.896
rougeL     | fm: 76.439 | p: 76.023 | r: 77.050
rougeLsum  | fm: 76.253 | p: 75.784 | r: 76.813
r1fm+r2fm = 142.681

input #58 time: 0:08:51 | total time: 8:26:08


Running input #59 of 100.
reference: 
========================
has the charisma of a young woman who knows how to hold the screen 
========================
average of cosine similarity 0.9992224669689527
highest_index [0]
highest [0.9992224669689527]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  2038,  1996, 25869,  2964,  2050,  1997,  1037,  2402,  2450,
          2040,  4282,  2129,  2000,  2907,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]']
[Init] best rec loss: 1.9130570888519287 for ['[CLS] zero treasurer kennedy vet when le bronze plans curiosity frigate greenbis wa ant chamber disks [SEP]']
[Init] best rec loss: 1.893306851387024 for ['[CLS]ization ul csi delegate its sex million glasses ek investigated through steep valkyrie prime wondering jordan [SEP]']
[Init] best rec loss: 1.8817111253738403 for ['[CLS] shares josephine settled commerce refrain bulletsgi moved plot awaitanies roger console fergusotidew [SEP]']
[Init] best rec loss: 1.7740832567214966 for ['[CLS] meetings primarily afar vietnamille sound explaining bun ii powerped able speaking [SEP] brow illumination [SEP]']
[Init] best rec loss: 1.75552499294281 for ['[CLS] trollsity underoh othersrion vault sorry days premiereend wivesjit reachedhold motorway [SEP]']
[Init] best rec loss: 1.6795601844787598 for ['[CLS] approaches dumb accept households frame relation sport replymis logan surrounding dutch dragon different com discipline [SEP]']
[Init] best rec loss: 1.6730873584747314 for ['[CLS] thus races noah pump awhile 1993 information bolognaby stuff temperament fleetak bobo was tunnel [SEP]']
[Init] best rec loss: 1.4757320880889893 for ['[CLS] organic passengers heroic wall duty change surgery drag kay statesflower hadn retirement cross will money [SEP]']
[Init] best perm rec loss: 1.473044991493225 for ['[CLS]flower states passengers cross drag organic money change wall hadn retirement kay heroic surgery will duty [SEP]']
[Init] best perm rec loss: 1.4710206985473633 for ['[CLS] wall passengers will states duty kay drag cross change money surgery heroicflower hadn organic retirement [SEP]']
[Init] best perm rec loss: 1.4710203409194946 for ['[CLS] hadn passengers retirement wall states organic drag change duty surgery kayflower money heroic cross will [SEP]']
[Init] best perm rec loss: 1.4642279148101807 for ['[CLS] wall organic passengers drag change surgeryflower will states retirement duty money kay cross heroic hadn [SEP]']
[Init] best perm rec loss: 1.4622763395309448 for ['[CLS] states passengers cross change organic surgeryflower kay money drag retirement wall will heroic duty hadn [SEP]']
[Init] best perm rec loss: 1.4614100456237793 for ['[CLS] hadn organic passengersflower surgery heroic cross kay will wall retirement change money states drag duty [SEP]']
[Init] best perm rec loss: 1.4608839750289917 for ['[CLS] organicflower retirement will money heroic duty hadn wall drag surgery cross passengers states change kay [SEP]']
[Init] best perm rec loss: 1.4605615139007568 for ['[CLS] organic drag passengers heroicflower cross kay surgery retirement wall will duty states money change hadn [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.640 (perp=11.540, rec=0.323, cos=0.009), tot_loss_proj:3.431 [t=0.20s]
prediction: ["[CLS] dedicated sheer look tales could woman'of felix soldiers grant singer from film screen writer [SEP]"]
[ 100/2000] tot_loss=2.434 (perp=10.900, rec=0.249, cos=0.005), tot_loss_proj:4.080 [t=0.18s]
prediction: ['[CLS] has char of char should womans of screen soldiers young screen where young screen screen [SEP]']
[ 150/2000] tot_loss=2.491 (perp=11.402, rec=0.206, cos=0.004), tot_loss_proj:3.390 [t=0.23s]
prediction: ['[CLS] has char ofism knows woman who of screen eric what screen who woman how screen [SEP]']
[ 200/2000] tot_loss=2.451 (perp=11.439, rec=0.160, cos=0.003), tot_loss_proj:3.373 [t=0.21s]
prediction: ['[CLS] has char ofism knows woman who of screen eric young screen who woman how screen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.474 (perp=11.640, rec=0.143, cos=0.003), tot_loss_proj:3.626 [t=0.24s]
prediction: ['[CLS] has char ofism what woman who a screen trinity knows screen who char how screen [SEP]']
[ 300/2000] tot_loss=2.309 (perp=10.901, rec=0.127, cos=0.002), tot_loss_proj:3.589 [t=0.26s]
prediction: ['[CLS] has char ofism what woman who a screen the hold screen who knows how screen [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.155 (perp=10.203, rec=0.112, cos=0.002), tot_loss_proj:2.888 [t=0.20s]
prediction: ['[CLS] has hold ofism positive young who a screen a char screen who knows how screen [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.077 (perp=9.816, rec=0.111, cos=0.003), tot_loss_proj:2.844 [t=0.19s]
prediction: ['[CLS] has hold ofism positive young woman a how a char screen who knows the screen [SEP]']
[ 450/2000] tot_loss=1.996 (perp=9.459, rec=0.102, cos=0.002), tot_loss_proj:3.081 [t=0.20s]
prediction: ['[CLS] has hold ofism of young woman a how a char screen who knows the screen [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.726 (perp=8.120, rec=0.099, cos=0.002), tot_loss_proj:2.670 [t=0.19s]
prediction: ['[CLS] has hold ofism of young a woman how a char woman who knows the screen [SEP]']
Attempt swap
Moved sequence
[ 550/2000] tot_loss=1.695 (perp=7.981, rec=0.096, cos=0.002), tot_loss_proj:2.793 [t=0.19s]
prediction: ['[CLS] young has hold ofism of a woman how the char woman who knows the screen [SEP]']
[ 600/2000] tot_loss=1.702 (perp=7.981, rec=0.104, cos=0.002), tot_loss_proj:2.796 [t=0.19s]
prediction: ['[CLS] young has hold ofism of a woman how the char woman who knows the screen [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.625 (perp=7.658, rec=0.091, cos=0.002), tot_loss_proj:2.709 [t=0.22s]
prediction: ['[CLS] young has the hold ofism of a woman how char woman who knows the screen [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.594 (perp=7.448, rec=0.102, cos=0.002), tot_loss_proj:2.699 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman how char woman who knows the screen [SEP]']
[ 750/2000] tot_loss=1.584 (perp=7.448, rec=0.092, cos=0.002), tot_loss_proj:2.701 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman how char woman who knows the screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.580 (perp=7.448, rec=0.089, cos=0.002), tot_loss_proj:2.697 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman how char woman who knows the screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.570 (perp=7.448, rec=0.079, cos=0.002), tot_loss_proj:2.701 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman how char woman who knows the screen [SEP]']
[ 900/2000] tot_loss=1.572 (perp=7.448, rec=0.081, cos=0.002), tot_loss_proj:2.696 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman how char woman who knows the screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.571 (perp=7.448, rec=0.080, cos=0.002), tot_loss_proj:2.696 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman how char woman who knows the screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.574 (perp=7.448, rec=0.082, cos=0.002), tot_loss_proj:2.694 [t=0.20s]
prediction: ['[CLS] has the hold ofism of a young woman how char woman who knows the screen [SEP]']
[1050/2000] tot_loss=1.568 (perp=7.448, rec=0.076, cos=0.002), tot_loss_proj:2.694 [t=0.21s]
prediction: ['[CLS] has the hold ofism of a young woman how char woman who knows the screen [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.547 (perp=7.264, rec=0.092, cos=0.002), tot_loss_proj:1.914 [t=0.28s]
prediction: ['[CLS] has the hold ofism of a young woman char woman who knows how the screen [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.530 (perp=7.213, rec=0.085, cos=0.002), tot_loss_proj:1.824 [t=0.28s]
prediction: ['[CLS] has the hold ofism of a young char woman woman who knows how the screen [SEP]']
[1200/2000] tot_loss=1.533 (perp=7.213, rec=0.089, cos=0.002), tot_loss_proj:1.833 [t=0.24s]
prediction: ['[CLS] has the hold ofism of a young char woman woman who knows how the screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.530 (perp=7.213, rec=0.085, cos=0.002), tot_loss_proj:1.832 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young char woman woman who knows how the screen [SEP]']
Attempt swap
Moved sequence
[1300/2000] tot_loss=1.508 (perp=7.099, rec=0.087, cos=0.002), tot_loss_proj:2.331 [t=0.22s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
[1350/2000] tot_loss=1.505 (perp=7.099, rec=0.083, cos=0.002), tot_loss_proj:2.320 [t=0.26s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.512 (perp=7.099, rec=0.091, cos=0.002), tot_loss_proj:2.324 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.507 (perp=7.099, rec=0.086, cos=0.002), tot_loss_proj:2.332 [t=0.24s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
[1500/2000] tot_loss=1.506 (perp=7.099, rec=0.084, cos=0.002), tot_loss_proj:2.326 [t=0.20s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.515 (perp=7.099, rec=0.093, cos=0.002), tot_loss_proj:2.321 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.516 (perp=7.099, rec=0.094, cos=0.002), tot_loss_proj:2.333 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
[1650/2000] tot_loss=1.511 (perp=7.099, rec=0.089, cos=0.002), tot_loss_proj:2.341 [t=0.20s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.513 (perp=7.099, rec=0.092, cos=0.002), tot_loss_proj:2.331 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.505 (perp=7.099, rec=0.084, cos=0.002), tot_loss_proj:2.335 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
[1800/2000] tot_loss=1.510 (perp=7.099, rec=0.089, cos=0.002), tot_loss_proj:2.330 [t=0.29s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows how char the screen [SEP]']
Attempt swap
Moved token
[1850/2000] tot_loss=1.508 (perp=7.121, rec=0.082, cos=0.002), tot_loss_proj:2.064 [t=0.25s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows char how the screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.513 (perp=7.121, rec=0.087, cos=0.002), tot_loss_proj:2.065 [t=0.27s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows char how the screen [SEP]']
[1950/2000] tot_loss=1.505 (perp=7.121, rec=0.079, cos=0.002), tot_loss_proj:2.057 [t=0.17s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows char how the screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.509 (perp=7.121, rec=0.083, cos=0.002), tot_loss_proj:2.060 [t=0.19s]
prediction: ['[CLS] has the hold ofism of a young woman woman who knows char how the screen [SEP]']
Done with input #59 of 100.
reference: 
========================
[CLS] has the charisma of a young woman who knows how to hold the screen [SEP]
========================
predicted: 
========================
[CLS] has the hold ofism of a young woman woman who knows char how the screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.848 | p: 82.353 | r: 87.500
rouge2     | fm: 58.065 | p: 56.250 | r: 60.000
rougeL     | fm: 78.788 | p: 76.471 | r: 81.250
rougeLsum  | fm: 78.788 | p: 76.471 | r: 81.250
r1fm+r2fm = 142.913

[Aggregate metrics]:
rouge1     | fm: 89.944 | p: 89.338 | r: 90.666
rouge2     | fm: 52.831 | p: 52.624 | r: 53.093
rougeL     | fm: 76.561 | p: 76.089 | r: 77.140
rougeLsum  | fm: 76.367 | p: 75.820 | r: 76.957
r1fm+r2fm = 142.776

input #59 time: 0:08:49 | total time: 8:34:58


Running input #60 of 100.
reference: 
========================
circuit is the awkwardly paced soap opera-ish story . 
========================
average of cosine similarity 0.999371813039142
highest_index [0]
highest [0.999371813039142]
Debug: ids_shape = 14, pads = [14]
Debug: input ids = tensor([[  101,  4984,  2003,  1996, 18822, 13823,  7815,  3850,  1011,  2003,
          2232,  2466,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]']
[Init] best rec loss: 1.8264330625534058 for ['[CLS] records instruments few stain lea conference searching " minor jp program abroad [SEP]']
[Init] best rec loss: 1.785794734954834 for ['[CLS] sub size practice duty sank topology pilgrims pyramid defense sc di dun [SEP]']
[Init] best rec loss: 1.5257476568222046 for ['[CLS] breath merely reception context find fake sale black duet side fitzgerald benny [SEP]']
[Init] best rec loss: 1.4993537664413452 for ['[CLS] analytics spring era jameson mortimer maddie ground! regiment how de deep [SEP]']
[Init] best rec loss: 1.494861125946045 for ['[CLS] internal begins by anything overrs mauriceorraation classroom yes josie [SEP]']
[Init] best rec loss: 1.4207831621170044 for ['[CLS] strungitude plenty majority cover through constitution /ouring upsetlbyshaw [SEP]']
[Init] best perm rec loss: 1.4200644493103027 for ['[CLS] constitutionitude upsetshaw coverlby strungouring majority plenty / through [SEP]']
[Init] best perm rec loss: 1.413394570350647 for ['[CLS] cover majority /lby constitution upset strung throughshawouringitude plenty [SEP]']
[Init] best perm rec loss: 1.4109059572219849 for ['[CLS] majority upset strungitude /ouringshawlby cover through plenty constitution [SEP]']
[Init] best perm rec loss: 1.4078900814056396 for ['[CLS] / majority strungouringshawlby through constitutionitude plenty cover upset [SEP]']
[Init] best perm rec loss: 1.4074980020523071 for ['[CLS] majority strung throughouringlbyitudeshaw / constitution upset plenty cover [SEP]']
[Init] best perm rec loss: 1.4071258306503296 for ['[CLS] plentyitude /lby strung cover upsetshaw constitution through majorityouring [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.622 (perp=11.780, rec=0.256, cos=0.010), tot_loss_proj:3.009 [t=0.27s]
prediction: ['[CLS] awkwardly awkwardly awkwardly transit protocol the message tax awkwardly soap. circuit [SEP]']
[ 100/2000] tot_loss=2.652 (perp=12.199, rec=0.204, cos=0.008), tot_loss_proj:3.034 [t=0.24s]
prediction: ['[CLS] awkwardly awkwardly awkwardly transit paced the is opera soap soap circuit circuit [SEP]']
[ 150/2000] tot_loss=2.489 (perp=11.625, rec=0.157, cos=0.007), tot_loss_proj:2.749 [t=0.20s]
prediction: ['[CLS] is awkwardly awkwardly opera paced is ish soap soap circuit story [SEP]']
[ 200/2000] tot_loss=1.973 (perp=9.296, rec=0.111, cos=0.003), tot_loss_proj:2.301 [t=0.19s]
prediction: ['[CLS] is awkwardly awkwardly opera paced the ish soap opera circuit story [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.971 (perp=9.296, rec=0.108, cos=0.003), tot_loss_proj:2.305 [t=0.18s]
prediction: ['[CLS] is awkwardly awkwardly opera paced the ish soap opera circuit story [SEP]']
[ 300/2000] tot_loss=2.190 (perp=10.496, rec=0.089, cos=0.002), tot_loss_proj:2.562 [t=0.19s]
prediction: ['[CLS] is awkwardly awkwardly opera paced the -h soap opera circuit story [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.023 (perp=9.632, rec=0.095, cos=0.002), tot_loss_proj:2.394 [t=0.28s]
prediction: ['[CLS] is awkwardly awkwardly opera pacedh - the soap opera circuit story [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.929 (perp=9.186, rec=0.090, cos=0.002), tot_loss_proj:2.264 [t=0.19s]
prediction: ['[CLS] opera is awkwardly awkwardly pacedh - the soap opera circuit story [SEP]']
[ 450/2000] tot_loss=1.914 (perp=9.186, rec=0.074, cos=0.002), tot_loss_proj:2.258 [t=0.19s]
prediction: ['[CLS] opera is awkwardly awkwardly pacedh - the soap opera circuit story [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.872 (perp=8.904, rec=0.089, cos=0.002), tot_loss_proj:2.192 [t=0.27s]
prediction: ['[CLS]h is awkwardly awkwardly paced opera - the soap opera circuit story [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.777 (perp=8.488, rec=0.077, cos=0.002), tot_loss_proj:2.083 [t=0.19s]
prediction: ['[CLS]h is awkwardly awkwardly paced soap opera - the opera circuit story [SEP]']
[ 600/2000] tot_loss=2.024 (perp=9.710, rec=0.080, cos=0.002), tot_loss_proj:2.355 [t=0.19s]
prediction: ['[CLS]h is awkwardly awkwardly paced soap is - the opera circuit story [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.837 (perp=8.743, rec=0.086, cos=0.002), tot_loss_proj:2.244 [t=0.18s]
prediction: ['[CLS]h is awkwardly awkwardly paced soap - the opera circuit story is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.835 (perp=8.743, rec=0.084, cos=0.002), tot_loss_proj:2.243 [t=0.27s]
prediction: ['[CLS]h is awkwardly awkwardly paced soap - the opera circuit story is [SEP]']
[ 750/2000] tot_loss=1.828 (perp=8.743, rec=0.077, cos=0.002), tot_loss_proj:2.241 [t=0.18s]
prediction: ['[CLS]h is awkwardly awkwardly paced soap - the opera circuit story is [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.886 (perp=9.054, rec=0.073, cos=0.002), tot_loss_proj:2.342 [t=0.19s]
prediction: ['[CLS]h is awkwardly، paced soap opera - the circuit story is [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.815 (perp=8.686, rec=0.075, cos=0.002), tot_loss_proj:2.323 [t=0.19s]
prediction: ['[CLS]h is awkwardly، paced soap opera - the story circuit is [SEP]']
[ 900/2000] tot_loss=1.805 (perp=8.634, rec=0.076, cos=0.002), tot_loss_proj:2.339 [t=0.19s]
prediction: ['[CLS]h is awkwardly [PAD] paced soap opera - the story circuit is [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.827 (perp=8.822, rec=0.060, cos=0.002), tot_loss_proj:2.235 [t=0.25s]
prediction: ['[CLS] titularh is awkwardly paced soap opera - the story circuit is [SEP]']
Attempt swap
Put prefix at the end
[1000/2000] tot_loss=1.770 (perp=8.401, rec=0.088, cos=0.002), tot_loss_proj:2.124 [t=0.23s]
prediction: ['[CLS]h is awkwardly paced soap opera - the story circuit is antagonist [SEP]']
[1050/2000] tot_loss=1.753 (perp=8.401, rec=0.070, cos=0.002), tot_loss_proj:2.116 [t=0.19s]
prediction: ['[CLS]h is awkwardly paced soap opera - the story circuit is antagonist [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.700 (perp=8.125, rec=0.073, cos=0.002), tot_loss_proj:2.417 [t=0.19s]
prediction: ['[CLS]h is awkwardly paced soap opera antagonist - the story circuit is [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.679 (perp=8.003, rec=0.076, cos=0.002), tot_loss_proj:2.265 [t=0.22s]
prediction: ['[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]']
[1200/2000] tot_loss=1.675 (perp=8.003, rec=0.072, cos=0.002), tot_loss_proj:2.260 [t=0.20s]
prediction: ['[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.681 (perp=8.003, rec=0.079, cos=0.002), tot_loss_proj:2.266 [t=0.19s]
prediction: ['[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.668 (perp=8.003, rec=0.066, cos=0.002), tot_loss_proj:2.266 [t=0.19s]
prediction: ['[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]']
[1350/2000] tot_loss=1.673 (perp=8.003, rec=0.070, cos=0.002), tot_loss_proj:2.266 [t=0.26s]
prediction: ['[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.669 (perp=8.003, rec=0.067, cos=0.002), tot_loss_proj:2.269 [t=0.22s]
prediction: ['[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.670 (perp=8.003, rec=0.067, cos=0.002), tot_loss_proj:2.265 [t=0.19s]
prediction: ['[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]']
[1500/2000] tot_loss=1.679 (perp=8.003, rec=0.077, cos=0.002), tot_loss_proj:2.267 [t=0.19s]
prediction: ['[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.668 (perp=8.003, rec=0.065, cos=0.002), tot_loss_proj:2.268 [t=0.20s]
prediction: ['[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.762 (perp=8.415, rec=0.076, cos=0.002), tot_loss_proj:2.155 [t=0.19s]
prediction: ['[CLS]h is awkwardly paced soap opera - the antagonist story circuit is [SEP]']
[1650/2000] tot_loss=1.765 (perp=8.415, rec=0.079, cos=0.002), tot_loss_proj:2.154 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the antagonist story circuit is [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.672 (perp=7.981, rec=0.073, cos=0.002), tot_loss_proj:2.033 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the antagonist circuit story is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.670 (perp=7.981, rec=0.072, cos=0.002), tot_loss_proj:2.041 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the antagonist circuit story is [SEP]']
[1800/2000] tot_loss=1.664 (perp=7.981, rec=0.066, cos=0.002), tot_loss_proj:2.026 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the antagonist circuit story is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.672 (perp=7.981, rec=0.073, cos=0.002), tot_loss_proj:2.037 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the antagonist circuit story is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.674 (perp=7.981, rec=0.075, cos=0.002), tot_loss_proj:2.036 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the antagonist circuit story is [SEP]']
[1950/2000] tot_loss=1.670 (perp=7.981, rec=0.072, cos=0.002), tot_loss_proj:2.029 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the antagonist circuit story is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.674 (perp=7.981, rec=0.076, cos=0.002), tot_loss_proj:2.038 [t=0.17s]
prediction: ['[CLS]h is awkwardly paced soap opera - the antagonist circuit story is [SEP]']
Done with input #60 of 100.
reference: 
========================
[CLS] circuit is the awkwardly paced soap opera - ish story. [SEP]
========================
predicted: 
========================
[CLS]h antagonist is awkwardly paced soap opera - the story circuit is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 83.333 | p: 76.923 | r: 90.909
rouge2     | fm: 36.364 | p: 33.333 | r: 40.000
rougeL     | fm: 66.667 | p: 61.538 | r: 72.727
rougeLsum  | fm: 66.667 | p: 61.538 | r: 72.727
r1fm+r2fm = 119.697

[Aggregate metrics]:
rouge1     | fm: 89.802 | p: 89.119 | r: 90.682
rouge2     | fm: 52.428 | p: 52.204 | r: 52.789
rougeL     | fm: 76.308 | p: 75.787 | r: 76.988
rougeLsum  | fm: 76.238 | p: 75.646 | r: 76.972
r1fm+r2fm = 142.230

input #60 time: 0:08:19 | total time: 8:43:18


Running input #61 of 100.
reference: 
========================
, beautiful scene 
========================
average of cosine similarity 0.999284746941759
highest_index [0]
highest [0.999284746941759]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1010, 3376, 3496,  102]], device='cuda:0')
Debug: ref = ['[CLS], beautiful scene [SEP]']
[Init] best rec loss: 1.8300962448120117 for ['[CLS] deploytore glanced [SEP]']
[Init] best rec loss: 1.8116177320480347 for ['[CLS]zeeali donated [SEP]']
[Init] best rec loss: 1.6035362482070923 for ['[CLS] age bad link [SEP]']
[Init] best rec loss: 1.6008113622665405 for ['[CLS] maximus broken initiative [SEP]']
[Init] best rec loss: 1.175456166267395 for ['[CLS] request lets mini [SEP]']
[Init] best perm rec loss: 1.1720333099365234 for ['[CLS] lets mini request [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.989 (perp=8.940, rec=0.190, cos=0.011), tot_loss_proj:2.144 [t=0.17s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 100/2000] tot_loss=1.945 (perp=8.940, rec=0.149, cos=0.008), tot_loss_proj:2.133 [t=0.18s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 150/2000] tot_loss=1.934 (perp=8.940, rec=0.139, cos=0.007), tot_loss_proj:2.135 [t=0.18s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
[ 200/2000] tot_loss=1.920 (perp=8.940, rec=0.126, cos=0.005), tot_loss_proj:2.135 [t=0.18s]
prediction: ['[CLS] beautiful scene beautiful [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.504 (perp=7.101, rec=0.082, cos=0.002), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 300/2000] tot_loss=1.486 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.624 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.628 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.491 (perp=7.101, rec=0.069, cos=0.001), tot_loss_proj:1.624 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 450/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.617 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.481 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.614 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.477 (perp=7.101, rec=0.055, cos=0.001), tot_loss_proj:1.623 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 600/2000] tot_loss=1.486 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.491 (perp=7.101, rec=0.070, cos=0.001), tot_loss_proj:1.626 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.498 (perp=7.101, rec=0.077, cos=0.001), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 750/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.619 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.490 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.485 (perp=7.101, rec=0.063, cos=0.001), tot_loss_proj:1.621 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
[ 900/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.617 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.626 [t=0.20s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1000/2000] tot_loss=1.486 (perp=7.101, rec=0.064, cos=0.001), tot_loss_proj:1.625 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1050/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.610 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1100/2000] tot_loss=1.495 (perp=7.101, rec=0.073, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1150/2000] tot_loss=1.493 (perp=7.101, rec=0.071, cos=0.001), tot_loss_proj:1.614 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1200/2000] tot_loss=1.496 (perp=7.101, rec=0.074, cos=0.001), tot_loss_proj:1.616 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.475 (perp=7.101, rec=0.053, cos=0.001), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1300/2000] tot_loss=1.473 (perp=7.101, rec=0.052, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1350/2000] tot_loss=1.489 (perp=7.101, rec=0.068, cos=0.001), tot_loss_proj:1.623 [t=0.19s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1400/2000] tot_loss=1.497 (perp=7.101, rec=0.075, cos=0.001), tot_loss_proj:1.624 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.620 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1500/2000] tot_loss=1.482 (perp=7.101, rec=0.060, cos=0.001), tot_loss_proj:1.619 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1550/2000] tot_loss=1.470 (perp=7.101, rec=0.049, cos=0.001), tot_loss_proj:1.629 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1600/2000] tot_loss=1.495 (perp=7.101, rec=0.073, cos=0.001), tot_loss_proj:1.626 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1650/2000] tot_loss=1.479 (perp=7.101, rec=0.057, cos=0.001), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1700/2000] tot_loss=1.488 (perp=7.101, rec=0.067, cos=0.001), tot_loss_proj:1.632 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1750/2000] tot_loss=1.487 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.617 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1800/2000] tot_loss=1.483 (perp=7.101, rec=0.061, cos=0.001), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.477 (perp=7.101, rec=0.055, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.487 (perp=7.101, rec=0.065, cos=0.001), tot_loss_proj:1.619 [t=0.18s]
prediction: ['[CLS] beautiful scene, [SEP]']
[1950/2000] tot_loss=1.497 (perp=7.101, rec=0.075, cos=0.001), tot_loss_proj:1.623 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Attempt swap
[2000/2000] tot_loss=1.488 (perp=7.101, rec=0.066, cos=0.001), tot_loss_proj:1.621 [t=0.17s]
prediction: ['[CLS] beautiful scene, [SEP]']
Done with input #61 of 100.
reference: 
========================
[CLS], beautiful scene [SEP]
========================
predicted: 
========================
[CLS] beautiful scene, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.919 | p: 89.244 | r: 90.795
rouge2     | fm: 53.203 | p: 52.919 | r: 53.496
rougeL     | fm: 76.641 | p: 76.120 | r: 77.317
rougeLsum  | fm: 76.584 | p: 76.068 | r: 77.270
r1fm+r2fm = 143.122

input #61 time: 0:07:14 | total time: 8:50:32


Running input #62 of 100.
reference: 
========================
grace to call for prevention rather than to place blame , making it one of the best war movies ever made 
========================
average of cosine similarity 0.999255650346929
highest_index [0]
highest [0.999255650346929]
Debug: ids_shape = 23, pads = [23]
Debug: input ids = tensor([[ 101, 4519, 2000, 2655, 2005, 9740, 2738, 2084, 2000, 2173, 7499, 1010,
         2437, 2009, 2028, 1997, 1996, 2190, 2162, 5691, 2412, 2081,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]']
[Init] best rec loss: 1.9530375003814697 for ['[CLS] marries ship sonny research bug jersey society bench share states cope change plants talesisation henry settledgly curb ryan bare [SEP]']
[Init] best rec loss: 1.880612850189209 for ['[CLS] sometimes break last convention ian species thousandsthe draft outside over season train telecom ray gayivating migration masovian sure stuff [SEP]']
[Init] best rec loss: 1.7968920469284058 for ['[CLS] help rarely extensionbreaker local sea team mom beacon tear wax chairmanphstatic mum new osman intervention [CLS] attentionius [SEP]']
[Init] best rec loss: 1.767058253288269 for ['[CLS]tled traffic conduct atoms sets commercial : robertsrgeonkney hard sherman [SEP] bus forbc charlie dragons medal same gravity [SEP]']
[Init] best rec loss: 1.749898910522461 for ['[CLS] wasn homosexual carey sometimes wave october, vampire bbc bloody pie hudson contemporary crowd turning error helped pepper thus reaches recently [SEP]']
[Init] best rec loss: 1.741378664970398 for ['[CLS] such duo demand appeared being pv status stereotypes superlary eight song signage thing conform take pup i planetary feed free [SEP]']
[Init] best rec loss: 1.7179762125015259 for ['[CLS] ammunition nowheregut opinion deemed romansdong was mattered al body mono turkish abet main alone stations bag lead facebook [SEP]']
[Init] best rec loss: 1.6971365213394165 for ['[CLS] adam skin lissa love dannberg western wrote food serious apart departureml gameposedmat few resides because track believed [SEP]']
[Init] best perm rec loss: 1.6958225965499878 for ['[CLS]mat departure game wrote skin lissa resides adam western fewml foodnberg track apart because believed seriousposed dan love [SEP]']
[Init] best perm rec loss: 1.6951234340667725 for ['[CLS] adam few departure danmatmlposednberg food because game serious believed resides wrote lissa western apart track love skin [SEP]']
[Init] best perm rec loss: 1.6936944723129272 for ['[CLS] lissa apartml western believed love gamenberg fewposed trackmat because resides dan skin adam serious wrote food departure [SEP]']
[Init] best perm rec loss: 1.6933423280715942 for ['[CLS] track serious adamnberg gameposed apart because few wrote resides dan food skin believed westernml lissa lovemat departure [SEP]']
[Init] best perm rec loss: 1.6924365758895874 for ['[CLS] track resides departure apart few love becausenberg believed wrote lissa game adam dan skinml western seriousposedmat food [SEP]']
[Init] best perm rec loss: 1.6920912265777588 for ['[CLS]mat apart love few western skin because game believednbergml serious adam wrote track departure lissaposed food resides dan [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.445 (perp=10.485, rec=0.337, cos=0.011), tot_loss_proj:3.880 [t=0.18s]
prediction: ['[CLS] for ho revolutionary of an aunt. war longer ff dangerous gracelaze down victory the may & arts presents ; [SEP]']
[ 100/2000] tot_loss=2.215 (perp=9.938, rec=0.222, cos=0.005), tot_loss_proj:3.392 [t=0.18s]
prediction: ['[CLS] of the revolutionary best to prevention aisle prevention ever to war grace greatest best movies making war war movies grace to [SEP]']
[ 150/2000] tot_loss=1.940 (perp=8.865, rec=0.164, cos=0.003), tot_loss_proj:3.337 [t=0.18s]
prediction: ['[CLS] one of war best to prevention prevention prevention ever to war grace as three movie making war war movies grace, [SEP]']
[ 200/2000] tot_loss=2.184 (perp=10.245, rec=0.133, cos=0.002), tot_loss_proj:3.556 [t=0.18s]
prediction: ['[CLS] one the war best to preventiondable prevention ever to ones grace to ones creation making war war movies grace, [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=2.115 (perp=9.947, rec=0.124, cos=0.002), tot_loss_proj:3.572 [t=0.18s]
prediction: ['[CLS] one the war best to prevention into prevention ever call ones creation grace to ones making war war movies grace, [SEP]']
[ 300/2000] tot_loss=1.966 (perp=9.233, rec=0.117, cos=0.002), tot_loss_proj:3.482 [t=0.24s]
prediction: ['[CLS] one the war best to prevention for rather ever call made it grace to ones making it war movies grace, [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.875 (perp=8.842, rec=0.105, cos=0.002), tot_loss_proj:3.702 [t=0.18s]
prediction: ['[CLS] one the war best to grace for rather ever call for it grace of ones making blame war movies prevention, [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.800 (perp=8.507, rec=0.097, cos=0.002), tot_loss_proj:3.630 [t=0.18s]
prediction: ['[CLS] one the war best for grace to rather ever call for it grace to made making blame war movies prevention, [SEP]']
[ 450/2000] tot_loss=1.866 (perp=8.860, rec=0.092, cos=0.002), tot_loss_proj:3.766 [t=0.19s]
prediction: ['[CLS] one the war best for grace to rather ever call for it grace of made making blame war movies prevention, [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.701 (perp=8.052, rec=0.089, cos=0.002), tot_loss_proj:3.576 [t=0.22s]
prediction: ['[CLS] one the war best for grace to rather ever call for it of grace made making blame war movies prevention, [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.646 (perp=7.860, rec=0.073, cos=0.002), tot_loss_proj:3.405 [t=0.18s]
prediction: ['[CLS] one the war best for grace to ever rather call to it of grace made making blame war movies prevention, [SEP]']
[ 600/2000] tot_loss=1.646 (perp=7.860, rec=0.072, cos=0.002), tot_loss_proj:3.408 [t=0.18s]
prediction: ['[CLS] one the war best for grace to ever rather call to it of grace made making blame war movies prevention, [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.626 (perp=7.770, rec=0.070, cos=0.002), tot_loss_proj:2.989 [t=0.19s]
prediction: ['[CLS] one the best war for grace to ever rather call to it of grace made making blame war movies prevention, [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.599 (perp=7.568, rec=0.084, cos=0.002), tot_loss_proj:3.200 [t=0.19s]
prediction: ['[CLS] one the best war for grace to ever rather call to it of grace made making war movies prevention blame, [SEP]']
[ 750/2000] tot_loss=1.597 (perp=7.568, rec=0.082, cos=0.002), tot_loss_proj:3.200 [t=0.18s]
prediction: ['[CLS] one the best war for grace to ever rather call to it of grace made making war movies prevention blame, [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.567 (perp=7.484, rec=0.069, cos=0.001), tot_loss_proj:3.112 [t=0.18s]
prediction: ['[CLS] one the best war for grace to ever rather call to it made grace of making war movies prevention blame, [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.681 (perp=7.989, rec=0.082, cos=0.002), tot_loss_proj:3.163 [t=0.18s]
prediction: ['[CLS] one the best war for grace to ever rather call place grace made it of making war movies prevention blame, [SEP]']
[ 900/2000] tot_loss=1.678 (perp=7.989, rec=0.079, cos=0.002), tot_loss_proj:3.167 [t=0.18s]
prediction: ['[CLS] one the best war for grace to ever rather call place grace made it of making war movies prevention blame, [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.648 (perp=7.863, rec=0.074, cos=0.002), tot_loss_proj:3.404 [t=0.18s]
prediction: ['[CLS] one the best war for grace to ever rather call grace made it place of making war movies prevention blame, [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.638 (perp=7.762, rec=0.084, cos=0.002), tot_loss_proj:3.247 [t=0.18s]
prediction: ['[CLS] one the best war for grace to ever rather call grace made it prevention of making war movies place blame, [SEP]']
[1050/2000] tot_loss=1.626 (perp=7.762, rec=0.072, cos=0.001), tot_loss_proj:3.246 [t=0.20s]
prediction: ['[CLS] one the best war for grace to ever rather call grace made it prevention of making war movies place blame, [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.570 (perp=7.455, rec=0.078, cos=0.002), tot_loss_proj:3.496 [t=0.20s]
prediction: ['[CLS] one the best war for grace to ever call grace rather made it prevention of making war movies place blame, [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.567 (perp=7.434, rec=0.078, cos=0.001), tot_loss_proj:3.457 [t=0.21s]
prediction: ['[CLS] one the best war for grace to ever call grace rather it made prevention of making war movies place blame, [SEP]']
[1200/2000] tot_loss=1.561 (perp=7.434, rec=0.073, cos=0.001), tot_loss_proj:3.452 [t=0.21s]
prediction: ['[CLS] one the best war for grace to ever call grace rather it made prevention of making war movies place blame, [SEP]']
Attempt swap
[1250/2000] tot_loss=1.560 (perp=7.434, rec=0.072, cos=0.001), tot_loss_proj:3.451 [t=0.20s]
prediction: ['[CLS] one the best war for grace to ever call grace rather it made prevention of making war movies place blame, [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.543 (perp=7.310, rec=0.079, cos=0.002), tot_loss_proj:3.379 [t=0.19s]
prediction: ['[CLS] one the best place for grace to ever call grace rather it made prevention of making war movies war blame, [SEP]']
[1350/2000] tot_loss=1.542 (perp=7.310, rec=0.079, cos=0.001), tot_loss_proj:3.378 [t=0.18s]
prediction: ['[CLS] one the best place for grace to ever call grace rather it made prevention of making war movies war blame, [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.514 (perp=7.234, rec=0.066, cos=0.001), tot_loss_proj:3.165 [t=0.19s]
prediction: ['[CLS] the one best place for grace to ever call grace rather it made prevention of making war movies war blame, [SEP]']
Attempt swap
[1450/2000] tot_loss=1.522 (perp=7.234, rec=0.073, cos=0.001), tot_loss_proj:3.163 [t=0.19s]
prediction: ['[CLS] the one best place for grace to ever call grace rather it made prevention of making war movies war blame, [SEP]']
[1500/2000] tot_loss=1.520 (perp=7.234, rec=0.072, cos=0.001), tot_loss_proj:3.165 [t=0.20s]
prediction: ['[CLS] the one best place for grace to ever call grace rather it made prevention of making war movies war blame, [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=1.514 (perp=7.234, rec=0.066, cos=0.002), tot_loss_proj:3.177 [t=0.19s]
prediction: ['[CLS] the one best place for grace to ever call grace rather it made prevention of making war movies war blame, [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.471 (perp=7.019, rec=0.066, cos=0.002), tot_loss_proj:3.356 [t=0.19s]
prediction: ['[CLS] the best place for grace to ever call grace rather one it made prevention of making war movies war blame, [SEP]']
[1650/2000] tot_loss=1.478 (perp=7.019, rec=0.073, cos=0.001), tot_loss_proj:3.360 [t=0.19s]
prediction: ['[CLS] the best place for grace to ever call grace rather one it made prevention of making war movies war blame, [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.486 (perp=7.055, rec=0.073, cos=0.001), tot_loss_proj:3.384 [t=0.20s]
prediction: ['[CLS] the best place for grace to ever call grace rather made it one prevention of making war movies war blame, [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.490 (perp=7.055, rec=0.077, cos=0.001), tot_loss_proj:3.386 [t=0.19s]
prediction: ['[CLS] the best place for grace to ever call grace rather made it one prevention of making war movies war blame, [SEP]']
[1800/2000] tot_loss=1.490 (perp=7.055, rec=0.078, cos=0.001), tot_loss_proj:3.380 [t=0.18s]
prediction: ['[CLS] the best place for grace to ever call grace rather made it one prevention of making war movies war blame, [SEP]']
Attempt swap
[1850/2000] tot_loss=1.487 (perp=7.055, rec=0.075, cos=0.001), tot_loss_proj:3.385 [t=0.19s]
prediction: ['[CLS] the best place for grace to ever call grace rather made it one prevention of making war movies war blame, [SEP]']
Attempt swap
[1900/2000] tot_loss=1.491 (perp=7.055, rec=0.078, cos=0.001), tot_loss_proj:3.383 [t=0.22s]
prediction: ['[CLS] the best place for grace to ever call grace rather made it one prevention of making war movies war blame, [SEP]']
[1950/2000] tot_loss=1.482 (perp=7.055, rec=0.070, cos=0.001), tot_loss_proj:3.381 [t=0.25s]
prediction: ['[CLS] the best place for grace to ever call grace rather made it one prevention of making war movies war blame, [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.465 (perp=6.940, rec=0.075, cos=0.001), tot_loss_proj:3.317 [t=0.18s]
prediction: ['[CLS] the best place for grace to ever call grace rather one made it prevention of making war movies war blame, [SEP]']
Done with input #62 of 100.
reference: 
========================
[CLS] grace to call for prevention rather than to place blame, making it one of the best war movies ever made [SEP]
========================
predicted: 
========================
[CLS] one the best war for grace to ever call grace rather it made prevention of making war movies place blame, [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 90.909 | p: 90.909 | r: 90.909
rouge2     | fm: 23.810 | p: 23.810 | r: 23.810
rougeL     | fm: 45.455 | p: 45.455 | r: 45.455
rougeLsum  | fm: 45.455 | p: 45.455 | r: 45.455
r1fm+r2fm = 114.719

[Aggregate metrics]:
rouge1     | fm: 90.026 | p: 89.377 | r: 90.816
rouge2     | fm: 52.582 | p: 52.323 | r: 52.863
rougeL     | fm: 76.271 | p: 75.644 | r: 76.839
rougeLsum  | fm: 76.100 | p: 75.593 | r: 76.763
r1fm+r2fm = 142.608

input #62 time: 0:07:32 | total time: 8:58:04


Running input #63 of 100.
reference: 
========================
looking for a return ticket 
========================
average of cosine similarity 0.9992646432214791
highest_index [0]
highest [0.9992646432214791]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[ 101, 2559, 2005, 1037, 2709, 7281,  102]], device='cuda:0')
Debug: ref = ['[CLS] looking for a return ticket [SEP]']
[Init] best rec loss: 1.875612497329712 for ['[CLS] mind newcastle avtees prussia [SEP]']
[Init] best rec loss: 1.2830250263214111 for ['[CLS] where box leftedope [SEP]']
[Init] best rec loss: 1.216496467590332 for ['[CLS] written spend brighter workingism [SEP]']
[Init] best rec loss: 1.2096959352493286 for ['[CLS] prison glided relations musician category [SEP]']
[Init] best rec loss: 1.208850383758545 for ['[CLS] established named tiffany club violent [SEP]']
[Init] best rec loss: 1.1488268375396729 for ['[CLS] ice coe poor t approaching [SEP]']
[Init] best perm rec loss: 1.1447150707244873 for ['[CLS] ice t approaching poor coe [SEP]']
[Init] best perm rec loss: 1.1429733037948608 for ['[CLS] coe approaching t poor ice [SEP]']
[Init] best perm rec loss: 1.142871618270874 for ['[CLS] approaching coe poor t ice [SEP]']
[Init] best perm rec loss: 1.1421325206756592 for ['[CLS] t ice approaching poor coe [SEP]']
[Init] best perm rec loss: 1.1394460201263428 for ['[CLS] coe poor approaching t ice [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.329 (perp=10.203, rec=0.262, cos=0.027), tot_loss_proj:3.185 [t=0.19s]
prediction: ['[CLS] ticket electro looking ticket ticket [SEP]']
[ 100/2000] tot_loss=1.941 (perp=8.975, rec=0.139, cos=0.007), tot_loss_proj:2.713 [t=0.20s]
prediction: ['[CLS] ticket for looking return ticket [SEP]']
[ 150/2000] tot_loss=1.890 (perp=8.975, rec=0.091, cos=0.004), tot_loss_proj:2.723 [t=0.18s]
prediction: ['[CLS] ticket for looking return ticket [SEP]']
[ 200/2000] tot_loss=1.869 (perp=8.975, rec=0.070, cos=0.004), tot_loss_proj:2.712 [t=0.17s]
prediction: ['[CLS] ticket for looking return ticket [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.637 (perp=7.803, rec=0.072, cos=0.004), tot_loss_proj:1.931 [t=0.19s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 300/2000] tot_loss=1.635 (perp=7.803, rec=0.070, cos=0.004), tot_loss_proj:1.934 [t=0.18s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.634 (perp=7.803, rec=0.070, cos=0.003), tot_loss_proj:1.934 [t=0.17s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.642 (perp=7.803, rec=0.078, cos=0.003), tot_loss_proj:1.938 [t=0.17s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 450/2000] tot_loss=1.640 (perp=7.803, rec=0.076, cos=0.003), tot_loss_proj:1.933 [t=0.17s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.633 (perp=7.803, rec=0.069, cos=0.003), tot_loss_proj:1.926 [t=0.20s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.630 (perp=7.803, rec=0.066, cos=0.003), tot_loss_proj:1.931 [t=0.20s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 600/2000] tot_loss=1.628 (perp=7.803, rec=0.064, cos=0.003), tot_loss_proj:1.938 [t=0.19s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.631 (perp=7.803, rec=0.067, cos=0.003), tot_loss_proj:1.928 [t=0.17s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.636 (perp=7.803, rec=0.072, cos=0.003), tot_loss_proj:1.930 [t=0.19s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 750/2000] tot_loss=1.627 (perp=7.803, rec=0.063, cos=0.003), tot_loss_proj:1.933 [t=0.19s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.632 (perp=7.803, rec=0.068, cos=0.003), tot_loss_proj:1.936 [t=0.21s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.631 (perp=7.803, rec=0.068, cos=0.003), tot_loss_proj:1.931 [t=0.17s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[ 900/2000] tot_loss=1.641 (perp=7.803, rec=0.077, cos=0.003), tot_loss_proj:1.935 [t=0.21s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.629 (perp=7.803, rec=0.066, cos=0.003), tot_loss_proj:1.932 [t=0.21s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
Attempt swap
[1000/2000] tot_loss=1.633 (perp=7.803, rec=0.070, cos=0.003), tot_loss_proj:1.926 [t=0.18s]
prediction: ['[CLS] looking for ticket return ticket [SEP]']
[1050/2000] tot_loss=1.288 (perp=6.111, rec=0.063, cos=0.002), tot_loss_proj:1.311 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1100/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.002), tot_loss_proj:1.311 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1150/2000] tot_loss=1.290 (perp=6.111, rec=0.066, cos=0.002), tot_loss_proj:1.320 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1200/2000] tot_loss=1.280 (perp=6.111, rec=0.056, cos=0.002), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1250/2000] tot_loss=1.293 (perp=6.111, rec=0.070, cos=0.002), tot_loss_proj:1.316 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1300/2000] tot_loss=1.277 (perp=6.111, rec=0.053, cos=0.002), tot_loss_proj:1.312 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1350/2000] tot_loss=1.284 (perp=6.111, rec=0.061, cos=0.001), tot_loss_proj:1.319 [t=0.18s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1400/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.299 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1450/2000] tot_loss=1.284 (perp=6.111, rec=0.060, cos=0.001), tot_loss_proj:1.308 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1500/2000] tot_loss=1.286 (perp=6.111, rec=0.062, cos=0.001), tot_loss_proj:1.309 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1550/2000] tot_loss=1.278 (perp=6.111, rec=0.054, cos=0.001), tot_loss_proj:1.312 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1600/2000] tot_loss=1.288 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.301 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1650/2000] tot_loss=1.289 (perp=6.111, rec=0.066, cos=0.001), tot_loss_proj:1.309 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1700/2000] tot_loss=1.279 (perp=6.111, rec=0.056, cos=0.001), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1750/2000] tot_loss=1.289 (perp=6.111, rec=0.065, cos=0.001), tot_loss_proj:1.310 [t=0.17s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1800/2000] tot_loss=1.290 (perp=6.111, rec=0.067, cos=0.001), tot_loss_proj:1.306 [t=0.19s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1850/2000] tot_loss=1.294 (perp=6.111, rec=0.070, cos=0.001), tot_loss_proj:1.300 [t=0.18s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[1900/2000] tot_loss=1.288 (perp=6.111, rec=0.064, cos=0.001), tot_loss_proj:1.311 [t=0.19s]
prediction: ['[CLS] looking for a return ticket [SEP]']
[1950/2000] tot_loss=1.282 (perp=6.111, rec=0.058, cos=0.001), tot_loss_proj:1.307 [t=0.18s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Attempt swap
[2000/2000] tot_loss=1.276 (perp=6.111, rec=0.053, cos=0.001), tot_loss_proj:1.310 [t=0.21s]
prediction: ['[CLS] looking for a return ticket [SEP]']
Done with input #63 of 100.
reference: 
========================
[CLS] looking for a return ticket [SEP]
========================
predicted: 
========================
[CLS] looking for a return ticket [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.093 | p: 89.394 | r: 90.900
rouge2     | fm: 53.340 | p: 53.067 | r: 53.557
rougeL     | fm: 76.569 | p: 76.010 | r: 77.233
rougeLsum  | fm: 76.524 | p: 75.938 | r: 77.185
r1fm+r2fm = 143.433

input #63 time: 0:07:24 | total time: 9:05:29


Running input #64 of 100.
reference: 
========================
the strange horror 
========================
average of cosine similarity 0.999160846219472
highest_index [0]
highest [0.999160846219472]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 1996, 4326, 5469,  102]], device='cuda:0')
Debug: ref = ['[CLS] the strange horror [SEP]']
[Init] best rec loss: 1.8793610334396362 for ['[CLS] step maddie sorry [SEP]']
[Init] best rec loss: 1.8335012197494507 for ['[CLS]bled independence clearing [SEP]']
[Init] best rec loss: 1.8333404064178467 for ['[CLS]ounded keydale [SEP]']
[Init] best rec loss: 1.414121150970459 for ['[CLS] understood shelter cl [SEP]']
[Init] best rec loss: 1.4084160327911377 for ['[CLS] spends adrian mating [SEP]']
[Init] best rec loss: 1.1607979536056519 for ['[CLS]onale water visions [SEP]']
[Init] best perm rec loss: 1.154465675354004 for ['[CLS] water visionsonale [SEP]']
[Init] best perm rec loss: 1.1528769731521606 for ['[CLS] visions wateronale [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.966 (perp=8.653, rec=0.200, cos=0.036), tot_loss_proj:2.062 [t=0.17s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 100/2000] tot_loss=1.900 (perp=8.653, rec=0.150, cos=0.019), tot_loss_proj:2.050 [t=0.17s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 150/2000] tot_loss=1.904 (perp=8.653, rec=0.145, cos=0.029), tot_loss_proj:2.051 [t=0.17s]
prediction: ['[CLS] strange horror horror [SEP]']
[ 200/2000] tot_loss=2.077 (perp=9.634, rec=0.135, cos=0.016), tot_loss_proj:2.558 [t=0.17s]
prediction: ['[CLS] strange horror strange [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.976 (perp=9.190, rec=0.127, cos=0.012), tot_loss_proj:2.202 [t=0.17s]
prediction: ['[CLS] strange strange horror [SEP]']
[ 300/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.714 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.684 (perp=8.065, rec=0.069, cos=0.002), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.672 (perp=8.065, rec=0.058, cos=0.002), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[ 450/2000] tot_loss=1.671 (perp=8.065, rec=0.056, cos=0.002), tot_loss_proj:1.713 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.675 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[ 600/2000] tot_loss=1.674 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.667 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.714 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[ 750/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.667 (perp=8.065, rec=0.052, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.696 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[ 900/2000] tot_loss=1.670 (perp=8.065, rec=0.055, cos=0.002), tot_loss_proj:1.717 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.677 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1000/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.716 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1050/2000] tot_loss=1.681 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1100/2000] tot_loss=1.668 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1150/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.715 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1200/2000] tot_loss=1.680 (perp=8.065, rec=0.065, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1250/2000] tot_loss=1.683 (perp=8.065, rec=0.068, cos=0.002), tot_loss_proj:1.713 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1300/2000] tot_loss=1.674 (perp=8.065, rec=0.060, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1350/2000] tot_loss=1.673 (perp=8.065, rec=0.059, cos=0.002), tot_loss_proj:1.710 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1400/2000] tot_loss=1.687 (perp=8.065, rec=0.072, cos=0.002), tot_loss_proj:1.706 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1450/2000] tot_loss=1.676 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.708 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
[1500/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.716 [t=0.19s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1550/2000] tot_loss=1.671 (perp=8.065, rec=0.057, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1600/2000] tot_loss=1.682 (perp=8.065, rec=0.067, cos=0.002), tot_loss_proj:1.716 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
[1650/2000] tot_loss=1.678 (perp=8.065, rec=0.063, cos=0.002), tot_loss_proj:1.709 [t=0.18s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1700/2000] tot_loss=1.676 (perp=8.065, rec=0.062, cos=0.002), tot_loss_proj:1.712 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1750/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.694 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1800/2000] tot_loss=1.679 (perp=8.065, rec=0.064, cos=0.002), tot_loss_proj:1.718 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1850/2000] tot_loss=1.667 (perp=8.065, rec=0.053, cos=0.002), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[1900/2000] tot_loss=1.675 (perp=8.065, rec=0.061, cos=0.002), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
[1950/2000] tot_loss=1.688 (perp=8.065, rec=0.073, cos=0.002), tot_loss_proj:1.710 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Attempt swap
[2000/2000] tot_loss=1.680 (perp=8.065, rec=0.066, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] the strange horror [SEP]']
Done with input #64 of 100.
reference: 
========================
[CLS] the strange horror [SEP]
========================
predicted: 
========================
[CLS] the strange horror [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.274 | p: 89.629 | r: 91.109
rouge2     | fm: 54.095 | p: 53.873 | r: 54.326
rougeL     | fm: 76.986 | p: 76.450 | r: 77.659
rougeLsum  | fm: 76.917 | p: 76.385 | r: 77.567
r1fm+r2fm = 144.369

input #64 time: 0:06:55 | total time: 9:12:24


Running input #65 of 100.
reference: 
========================
, joyous romp of a film . 
========================
average of cosine similarity 0.9992260466615117
highest_index [0]
highest [0.9992260466615117]
Debug: ids_shape = 11, pads = [11]
Debug: input ids = tensor([[  101,  1010,  6569,  3560, 17083,  2361,  1997,  1037,  2143,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS], joyous romp of a film. [SEP]']
[Init] best rec loss: 1.9480024576187134 for ['[CLS] propertylus total welcomed reichlet every based? [SEP]']
[Init] best rec loss: 1.935711145401001 for ['[CLS] question away greek ordained speaker archbishop afterward flip caine [SEP]']
[Init] best rec loss: 1.9066228866577148 for ['[CLS] stable bourne writers sp here plays spell keeping another [SEP]']
[Init] best rec loss: 1.7932060956954956 for ['[CLS] boss sucks goodbye poorlyions palestinianquest languagecliff [SEP]']
[Init] best rec loss: 1.7819745540618896 for ['[CLS] butter memorandumece happy cry laurence cum york accept [SEP]']
[Init] best rec loss: 1.7478106021881104 for ['[CLS] forth drag roger choice rival familiar howellacingbies [SEP]']
[Init] best rec loss: 1.7460284233093262 for ['[CLS] tobago resist clinched industryementga team rim cancer [SEP]']
[Init] best rec loss: 1.6370292901992798 for ['[CLS] puhoff overs fun someday general evenmament news [SEP]']
[Init] best rec loss: 1.5800213813781738 for ['[CLS] dreamed common evbell infantry soon duel paradise birds [SEP]']
[Init] best perm rec loss: 1.579031229019165 for ['[CLS] birds duel paradise dreamed ev infantry soonbell common [SEP]']
[Init] best perm rec loss: 1.5777679681777954 for ['[CLS] duel birds dreamed infantrybell soon ev paradise common [SEP]']
[Init] best perm rec loss: 1.57088303565979 for ['[CLS] birds commonbell infantry duel dreamed ev paradise soon [SEP]']
[Init] best perm rec loss: 1.5680181980133057 for ['[CLS] dreamed paradise duel common evbell infantry soon birds [SEP]']
[Init] best perm rec loss: 1.5678985118865967 for ['[CLS]bell common paradise dreamed birds duel infantry ev soon [SEP]']
[Init] best perm rec loss: 1.5646346807479858 for ['[CLS] birds duel dreamed infantry evbell common soon paradise [SEP]']
[Init] best perm rec loss: 1.563547968864441 for ['[CLS] dreamed duel paradise common birds evbell infantry soon [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.230 (perp=9.915, rec=0.240, cos=0.007), tot_loss_proj:2.716 [t=0.17s]
prediction: ['[CLS] joy joyousd [SEP], rom joys [SEP]']
[ 100/2000] tot_loss=1.749 (perp=7.963, rec=0.151, cos=0.005), tot_loss_proj:2.093 [t=0.17s]
prediction: ['[CLS] joy joyous film film, rom joy. [SEP]']
[ 150/2000] tot_loss=1.804 (perp=8.464, rec=0.108, cos=0.003), tot_loss_proj:2.527 [t=0.17s]
prediction: ['[CLS] rom joyous film of, rom joy. [SEP]']
[ 200/2000] tot_loss=1.792 (perp=8.464, rec=0.096, cos=0.004), tot_loss_proj:2.523 [t=0.17s]
prediction: ['[CLS] rom joyous film of, rom joy. [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.485 (perp=6.829, rec=0.116, cos=0.003), tot_loss_proj:2.180 [t=0.17s]
prediction: ['[CLS] rom joyous of film, rom joy. [SEP]']
[ 300/2000] tot_loss=1.464 (perp=6.829, rec=0.096, cos=0.002), tot_loss_proj:2.174 [t=0.17s]
prediction: ['[CLS] rom joyous of film, rom joy. [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.638 (perp=7.800, rec=0.076, cos=0.002), tot_loss_proj:2.054 [t=0.17s]
prediction: ['[CLS] a joyous of film, rom joy. [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.436 (perp=6.772, rec=0.079, cos=0.002), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] a joyous rom of film, joy. [SEP]']
[ 450/2000] tot_loss=1.328 (perp=6.199, rec=0.087, cos=0.002), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] a joyous romp film, joy. [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.272 (perp=6.008, rec=0.069, cos=0.002), tot_loss_proj:1.572 [t=0.17s]
prediction: ['[CLS] a joyous romp joy, film. [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.228 (perp=5.748, rec=0.076, cos=0.002), tot_loss_proj:1.502 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[ 600/2000] tot_loss=1.228 (perp=5.748, rec=0.077, cos=0.002), tot_loss_proj:1.490 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.219 (perp=5.748, rec=0.067, cos=0.002), tot_loss_proj:1.496 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.215 (perp=5.748, rec=0.064, cos=0.002), tot_loss_proj:1.487 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[ 750/2000] tot_loss=1.226 (perp=5.748, rec=0.075, cos=0.002), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.231 (perp=5.748, rec=0.079, cos=0.002), tot_loss_proj:1.482 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.228 (perp=5.748, rec=0.077, cos=0.002), tot_loss_proj:1.486 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[ 900/2000] tot_loss=1.231 (perp=5.748, rec=0.080, cos=0.002), tot_loss_proj:1.483 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.229 (perp=5.748, rec=0.078, cos=0.002), tot_loss_proj:1.487 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1000/2000] tot_loss=1.223 (perp=5.748, rec=0.072, cos=0.002), tot_loss_proj:1.487 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[1050/2000] tot_loss=1.217 (perp=5.748, rec=0.066, cos=0.002), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1100/2000] tot_loss=1.221 (perp=5.748, rec=0.069, cos=0.002), tot_loss_proj:1.482 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1150/2000] tot_loss=1.204 (perp=5.748, rec=0.053, cos=0.002), tot_loss_proj:1.481 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[1200/2000] tot_loss=1.231 (perp=5.748, rec=0.079, cos=0.002), tot_loss_proj:1.482 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1250/2000] tot_loss=1.227 (perp=5.748, rec=0.076, cos=0.002), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1300/2000] tot_loss=1.217 (perp=5.748, rec=0.065, cos=0.002), tot_loss_proj:1.491 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[1350/2000] tot_loss=1.228 (perp=5.748, rec=0.077, cos=0.002), tot_loss_proj:1.488 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.230 (perp=5.748, rec=0.079, cos=0.002), tot_loss_proj:1.489 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1450/2000] tot_loss=1.217 (perp=5.748, rec=0.065, cos=0.002), tot_loss_proj:1.481 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[1500/2000] tot_loss=1.225 (perp=5.748, rec=0.074, cos=0.002), tot_loss_proj:1.482 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.216 (perp=5.748, rec=0.065, cos=0.002), tot_loss_proj:1.485 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1600/2000] tot_loss=1.223 (perp=5.748, rec=0.072, cos=0.002), tot_loss_proj:1.494 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[1650/2000] tot_loss=1.215 (perp=5.748, rec=0.063, cos=0.002), tot_loss_proj:1.476 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1700/2000] tot_loss=1.226 (perp=5.748, rec=0.075, cos=0.002), tot_loss_proj:1.488 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1750/2000] tot_loss=1.228 (perp=5.748, rec=0.077, cos=0.002), tot_loss_proj:1.481 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[1800/2000] tot_loss=1.225 (perp=5.748, rec=0.074, cos=0.002), tot_loss_proj:1.486 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1850/2000] tot_loss=1.224 (perp=5.748, rec=0.073, cos=0.002), tot_loss_proj:1.487 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.219 (perp=5.748, rec=0.068, cos=0.002), tot_loss_proj:1.476 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
[1950/2000] tot_loss=1.222 (perp=5.748, rec=0.071, cos=0.002), tot_loss_proj:1.484 [t=0.17s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.219 (perp=5.748, rec=0.068, cos=0.002), tot_loss_proj:1.486 [t=0.21s]
prediction: ['[CLS] a joyous joy romp, film. [SEP]']
Done with input #65 of 100.
reference: 
========================
[CLS], joyous romp of a film. [SEP]
========================
predicted: 
========================
[CLS] a joyous joy romp, film. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 16.667 | p: 16.667 | r: 16.667
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 102.381

[Aggregate metrics]:
rouge1     | fm: 90.233 | p: 89.618 | r: 91.010
rouge2     | fm: 53.345 | p: 53.128 | r: 53.640
rougeL     | fm: 76.869 | p: 76.364 | r: 77.554
rougeLsum  | fm: 76.856 | p: 76.319 | r: 77.496
r1fm+r2fm = 143.578

input #65 time: 0:06:56 | total time: 9:19:20


Running input #66 of 100.
reference: 
========================
a longtime tolkien fan 
========================
average of cosine similarity 0.9992330092949469
highest_index [0]
highest [0.9992330092949469]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  1037, 11155, 23602,  5470,   102]], device='cuda:0')
Debug: ref = ['[CLS] a longtime tolkien fan [SEP]']
[Init] best rec loss: 1.9587653875350952 for ['[CLS] compiler devlin world spell [SEP]']
[Init] best rec loss: 1.838042974472046 for ['[CLS] same heads deep independents [SEP]']
[Init] best rec loss: 1.8294860124588013 for ['[CLS] adding guilty electricion [SEP]']
[Init] best rec loss: 1.8049302101135254 for ['[CLS] school divisional labor liberals [SEP]']
[Init] best rec loss: 1.6972644329071045 for ['[CLS] edo examplewell allmusic [SEP]']
[Init] best rec loss: 1.5281866788864136 for ['[CLS] background leader screen [CLS] [SEP]']
[Init] best rec loss: 1.4521524906158447 for ['[CLS] game scout juliet shoulders [SEP]']
[Init] best rec loss: 1.2160919904708862 for ['[CLS] finish eachensis clark [SEP]']
[Init] best perm rec loss: 1.2056833505630493 for ['[CLS] each clarkensis finish [SEP]']
[Init] best perm rec loss: 1.2052438259124756 for ['[CLS]ensis each clark finish [SEP]']
[Init] best perm rec loss: 1.202699899673462 for ['[CLS]ensis clark each finish [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.262 (perp=10.314, rec=0.191, cos=0.008), tot_loss_proj:2.452 [t=0.23s]
prediction: ['[CLS] longtime tolkien fan longtime [SEP]']
[ 100/2000] tot_loss=1.861 (perp=8.912, rec=0.077, cos=0.002), tot_loss_proj:2.162 [t=0.19s]
prediction: ['[CLS] longtime tolkien fan a [SEP]']
[ 150/2000] tot_loss=1.856 (perp=8.912, rec=0.071, cos=0.002), tot_loss_proj:2.166 [t=0.19s]
prediction: ['[CLS] longtime tolkien fan a [SEP]']
[ 200/2000] tot_loss=1.861 (perp=8.912, rec=0.077, cos=0.002), tot_loss_proj:2.185 [t=0.19s]
prediction: ['[CLS] longtime tolkien fan a [SEP]']
Attempt swap
Put prefix at the end
[ 250/2000] tot_loss=1.609 (perp=7.673, rec=0.072, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 300/2000] tot_loss=1.594 (perp=7.673, rec=0.058, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.604 (perp=7.673, rec=0.068, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.590 (perp=7.673, rec=0.054, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 450/2000] tot_loss=1.589 (perp=7.673, rec=0.053, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.598 (perp=7.673, rec=0.062, cos=0.002), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 600/2000] tot_loss=1.603 (perp=7.673, rec=0.067, cos=0.002), tot_loss_proj:1.594 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.592 (perp=7.673, rec=0.055, cos=0.002), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 750/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[ 900/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.601 (perp=7.673, rec=0.065, cos=0.002), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1000/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1050/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1100/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.590 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1150/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1200/2000] tot_loss=1.584 (perp=7.673, rec=0.048, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1250/2000] tot_loss=1.608 (perp=7.673, rec=0.072, cos=0.002), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1300/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.604 [t=0.19s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1350/2000] tot_loss=1.602 (perp=7.673, rec=0.066, cos=0.002), tot_loss_proj:1.593 [t=0.19s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1400/2000] tot_loss=1.591 (perp=7.673, rec=0.055, cos=0.002), tot_loss_proj:1.611 [t=0.20s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1450/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1500/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1550/2000] tot_loss=1.588 (perp=7.673, rec=0.052, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1600/2000] tot_loss=1.592 (perp=7.673, rec=0.056, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1650/2000] tot_loss=1.584 (perp=7.673, rec=0.048, cos=0.002), tot_loss_proj:1.592 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1700/2000] tot_loss=1.595 (perp=7.673, rec=0.059, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1750/2000] tot_loss=1.596 (perp=7.673, rec=0.060, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1800/2000] tot_loss=1.599 (perp=7.673, rec=0.063, cos=0.002), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1850/2000] tot_loss=1.589 (perp=7.673, rec=0.053, cos=0.002), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[1900/2000] tot_loss=1.600 (perp=7.673, rec=0.064, cos=0.002), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
[1950/2000] tot_loss=1.607 (perp=7.673, rec=0.071, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Attempt swap
[2000/2000] tot_loss=1.591 (perp=7.673, rec=0.055, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] a longtime tolkien fan [SEP]']
Done with input #66 of 100.
reference: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
predicted: 
========================
[CLS] a longtime tolkien fan [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 90.424 | p: 89.784 | r: 91.224
rouge2     | fm: 54.328 | p: 54.115 | r: 54.573
rougeL     | fm: 77.331 | p: 76.825 | r: 77.948
rougeLsum  | fm: 77.226 | p: 76.692 | r: 77.813
r1fm+r2fm = 144.752

input #66 time: 0:07:12 | total time: 9:26:33


Running input #67 of 100.
reference: 
========================
heartwarming , nonjudgmental kind 
========================
average of cosine similarity 0.999292690019056
highest_index [0]
highest [0.999292690019056]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[  101,  2540,  9028,  6562,  1010,  2512,  9103,  2094, 21693, 21050,
          2785,   102]], device='cuda:0')
Debug: ref = ['[CLS] heartwarming, nonjudgmental kind [SEP]']
[Init] best rec loss: 1.834237813949585 for ['[CLS] art |erved reinided annual later strangeruce beyond [SEP]']
[Init] best rec loss: 1.7785722017288208 for ['[CLS] ^ banksgger biology mont neck administration action pool neo [SEP]']
[Init] best rec loss: 1.7256571054458618 for ['[CLS] mortonructured hendricks partial banned time jae published leave psalm [SEP]']
[Init] best rec loss: 1.69612717628479 for ['[CLS] practically squadron pacific cheated rick under countryorð⁄₄ [SEP]']
[Init] best rec loss: 1.6957756280899048 for ['[CLS]lusionunt sign utah america zeppelin light katy outbreak betray [SEP]']
[Init] best rec loss: 1.6956020593643188 for ['[CLS] [ script part song log principal custom enlisted cabinet charged [SEP]']
[Init] best rec loss: 1.676373839378357 for ['[CLS] marcus cause rudder straight mustered ordinary competitive population getting believe [SEP]']
[Init] best rec loss: 1.6748206615447998 for ['[CLS] vessel definitearound attendant visionrained league nearest sets nut [SEP]']
[Init] best perm rec loss: 1.6736490726470947 for ['[CLS]around nut definiterained vessel league vision attendant nearest sets [SEP]']
[Init] best perm rec loss: 1.6704751253128052 for ['[CLS]around nearestrained definite attendant sets league vision nut vessel [SEP]']
[Init] best perm rec loss: 1.6678307056427002 for ['[CLS] leaguearound vesselrained attendant sets nearest vision definite nut [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.900 (perp=12.948, rec=0.303, cos=0.007), tot_loss_proj:4.202 [t=0.17s]
prediction: ['[CLS] heart downtown kind kind defense kind kind. quickwar [SEP]']
[ 100/2000] tot_loss=3.183 (perp=14.532, rec=0.270, cos=0.007), tot_loss_proj:4.429 [t=0.17s]
prediction: ['[CLS] heart scientific kindfeld non kind kindming kindwar [SEP]']
[ 150/2000] tot_loss=3.213 (perp=14.787, rec=0.251, cos=0.005), tot_loss_proj:4.292 [t=0.17s]
prediction: ['[CLS] heart scientific kindental nonental kindming kindwar [SEP]']
[ 200/2000] tot_loss=3.068 (perp=14.488, rec=0.168, cos=0.002), tot_loss_proj:4.493 [t=0.17s]
prediction: ['[CLS] heart scientific kindental nonental kindmingentalwar [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.426 (perp=11.444, rec=0.135, cos=0.002), tot_loss_proj:3.592 [t=0.17s]
prediction: ['[CLS] heartwar,ental nonentalwarmingental kind [SEP]']
[ 300/2000] tot_loss=2.414 (perp=11.444, rec=0.124, cos=0.002), tot_loss_proj:3.622 [t=0.17s]
prediction: ['[CLS] heartwar,ental nonentalwarmingental kind [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.817 (perp=13.436, rec=0.127, cos=0.002), tot_loss_proj:3.840 [t=0.17s]
prediction: ['[CLS] heartgmming,gm nonentalwarental kind [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.944 (perp=9.183, rec=0.106, cos=0.002), tot_loss_proj:2.196 [t=0.17s]
prediction: ['[CLS] heartwarming,gm nonentalgmental kind [SEP]']
[ 450/2000] tot_loss=1.931 (perp=9.183, rec=0.092, cos=0.002), tot_loss_proj:2.185 [t=0.17s]
prediction: ['[CLS] heartwarming,gm nonentalgmental kind [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.498 (perp=7.030, rec=0.090, cos=0.002), tot_loss_proj:1.727 [t=0.17s]
prediction: ['[CLS] heartwarming,gmental nongmental kind [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.635 (perp=7.719, rec=0.089, cos=0.002), tot_loss_proj:1.776 [t=0.17s]
prediction: ['[CLS] heartwarming, heart nongmgmental kind [SEP]']
[ 600/2000] tot_loss=1.639 (perp=7.719, rec=0.094, cos=0.002), tot_loss_proj:1.764 [t=0.17s]
prediction: ['[CLS] heartwarming, heart nongmgmental kind [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.625 (perp=7.719, rec=0.079, cos=0.002), tot_loss_proj:1.765 [t=0.17s]
prediction: ['[CLS] heartwarming, heart nongmgmental kind [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.631 (perp=7.719, rec=0.085, cos=0.002), tot_loss_proj:1.776 [t=0.17s]
prediction: ['[CLS] heartwarming, heart nongmgmental kind [SEP]']
[ 750/2000] tot_loss=1.628 (perp=7.719, rec=0.082, cos=0.002), tot_loss_proj:1.762 [t=0.17s]
prediction: ['[CLS] heartwarming, heart nongmgmental kind [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.623 (perp=7.719, rec=0.077, cos=0.002), tot_loss_proj:1.769 [t=0.17s]
prediction: ['[CLS] heartwarming, heart nongmgmental kind [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.635 (perp=7.719, rec=0.089, cos=0.002), tot_loss_proj:1.770 [t=0.17s]
prediction: ['[CLS] heartwarming, heart nongmgmental kind [SEP]']
[ 900/2000] tot_loss=1.631 (perp=7.719, rec=0.085, cos=0.002), tot_loss_proj:1.768 [t=0.17s]
prediction: ['[CLS] heartwarming, heart nongmgmental kind [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.766 (perp=8.319, rec=0.100, cos=0.002), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] heartwarming, nongmgmentalental kind [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.454 (perp=6.881, rec=0.076, cos=0.002), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS] heartwarming, nongmentalgmental kind [SEP]']
[1050/2000] tot_loss=1.453 (perp=6.881, rec=0.075, cos=0.002), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] heartwarming, nongmentalgmental kind [SEP]']
Attempt swap
[1100/2000] tot_loss=1.726 (perp=8.215, rec=0.081, cos=0.002), tot_loss_proj:1.865 [t=0.17s]
prediction: ['[CLS] heartwarming, nongmentaljuental kind [SEP]']
Attempt swap
[1150/2000] tot_loss=1.725 (perp=8.215, rec=0.080, cos=0.002), tot_loss_proj:1.863 [t=0.17s]
prediction: ['[CLS] heartwarming, nongmentaljuental kind [SEP]']
[1200/2000] tot_loss=1.722 (perp=8.215, rec=0.077, cos=0.002), tot_loss_proj:1.859 [t=0.17s]
prediction: ['[CLS] heartwarming, nongmentaljuental kind [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.594 (perp=7.547, rec=0.083, cos=0.002), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjuentalgmental kind [SEP]']
Attempt swap
[1300/2000] tot_loss=1.597 (perp=7.547, rec=0.086, cos=0.002), tot_loss_proj:1.674 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjuentalgmental kind [SEP]']
[1350/2000] tot_loss=1.583 (perp=7.547, rec=0.072, cos=0.002), tot_loss_proj:1.676 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjuentalgmental kind [SEP]']
Attempt swap
[1400/2000] tot_loss=1.583 (perp=7.547, rec=0.072, cos=0.002), tot_loss_proj:1.687 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjuentalgmental kind [SEP]']
Attempt swap
[1450/2000] tot_loss=1.589 (perp=7.547, rec=0.078, cos=0.002), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjuentalgmental kind [SEP]']
[1500/2000] tot_loss=1.590 (perp=7.547, rec=0.079, cos=0.002), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjuentalgmental kind [SEP]']
Attempt swap
[1550/2000] tot_loss=1.593 (perp=7.547, rec=0.082, cos=0.002), tot_loss_proj:1.690 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjuentalgmental kind [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.563 (perp=7.432, rec=0.075, cos=0.002), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] heartwarming,ental nonjugmental kind [SEP]']
[1650/2000] tot_loss=1.568 (perp=7.432, rec=0.080, cos=0.002), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] heartwarming,ental nonjugmental kind [SEP]']
Attempt swap
[1700/2000] tot_loss=1.557 (perp=7.432, rec=0.069, cos=0.002), tot_loss_proj:1.695 [t=0.17s]
prediction: ['[CLS] heartwarming,ental nonjugmental kind [SEP]']
Attempt swap
[1750/2000] tot_loss=1.558 (perp=7.432, rec=0.070, cos=0.002), tot_loss_proj:1.683 [t=0.17s]
prediction: ['[CLS] heartwarming,ental nonjugmental kind [SEP]']
[1800/2000] tot_loss=1.566 (perp=7.432, rec=0.078, cos=0.002), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] heartwarming,ental nonjugmental kind [SEP]']
Attempt swap
[1850/2000] tot_loss=1.724 (perp=8.266, rec=0.069, cos=0.002), tot_loss_proj:1.923 [t=0.17s]
prediction: ['[CLS] heartwarming,e nonjugmental kind [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.519 (perp=7.142, rec=0.089, cos=0.002), tot_loss_proj:1.796 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjugmental kinde [SEP]']
[1950/2000] tot_loss=1.660 (perp=7.937, rec=0.071, cos=0.002), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjugmental kindental [SEP]']
Attempt swap
Moved sequence
[2000/2000] tot_loss=1.610 (perp=7.703, rec=0.068, cos=0.002), tot_loss_proj:1.646 [t=0.17s]
prediction: ['[CLS] heartwarming, nonjuegmental kind [SEP]']
Done with input #67 of 100.
reference: 
========================
[CLS] heartwarming, nonjudgmental kind [SEP]
========================
predicted: 
========================
[CLS] heartwarming,ental nonjugmental kind [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 72.727 | p: 66.667 | r: 80.000
rouge2     | fm: 44.444 | p: 40.000 | r: 50.000
rougeL     | fm: 72.727 | p: 66.667 | r: 80.000
rougeLsum  | fm: 72.727 | p: 66.667 | r: 80.000
r1fm+r2fm = 117.172

[Aggregate metrics]:
rouge1     | fm: 90.106 | p: 89.347 | r: 91.026
rouge2     | fm: 54.228 | p: 54.006 | r: 54.548
rougeL     | fm: 77.173 | p: 76.596 | r: 77.932
rougeLsum  | fm: 77.230 | p: 76.634 | r: 77.937
r1fm+r2fm = 144.334

input #67 time: 0:06:57 | total time: 9:33:30


Running input #68 of 100.
reference: 
========================
uncouth , incomprehensible , vicious and absurd 
========================
average of cosine similarity 0.9992789242841313
highest_index [0]
highest [0.9992789242841313]
Debug: ids_shape = 15, pads = [15]
Debug: input ids = tensor([[  101,  4895,  3597, 14317,  1010,  4297, 25377,  2890, 10222, 19307,
          1010, 13925,  1998, 18691,   102]], device='cuda:0')
Debug: ref = ['[CLS] uncouth, incomprehensible, vicious and absurd [SEP]']
[Init] best rec loss: 1.9883288145065308 for ['[CLS] view top well bam senate upon campus grade podium elected essentialget combat [SEP]']
[Init] best rec loss: 1.9612467288970947 for ['[CLS] brothers tensionquitable tyler twist yes year brought % almost barely pain emirates [SEP]']
[Init] best rec loss: 1.6541982889175415 for ['[CLS] gun ʐ station affairs substance enough sleepsrableoper manual background michael deadline [SEP]']
[Init] best rec loss: 1.6288515329360962 for ['[CLS] °f force recreationalyde fighting extras who livestock guaranteed singles short gloves kitchen [SEP]']
[Init] best rec loss: 1.6066203117370605 for ['[CLS] collecting congresses hundred slightest summit survive [CLS] although fred diego fantastic relief? [SEP]']
[Init] best rec loss: 1.5576926469802856 for ['[CLS] $ offs dreams national been wallszzsar council frederick but lankan comprehensive [SEP]']
[Init] best rec loss: 1.459212064743042 for ['[CLS] feelings stole besides spoil bit prone decay spider insteadane about ars payments [SEP]']
[Init] best rec loss: 1.1719552278518677 for ['[CLS]. form beth floor view medal comfortiferous riding councils diedyn possibly [SEP]']
[Init] best perm rec loss: 1.1586320400238037 for ['[CLS] floor medal comfort viewiferous beth riding possiblyyn form. councils died [SEP]']
[Init] best perm rec loss: 1.1505303382873535 for ['[CLS] form possiblyyn diediferous. floor view councils riding comfort medal beth [SEP]']
[Init] best perm rec loss: 1.1384704113006592 for ['[CLS] possiblyiferous.yn riding medal form councils view floor comfort beth died [SEP]']
[Init] best perm rec loss: 1.1313153505325317 for ['[CLS]iferous beth died form. floor councils riding medalyn view possibly comfort [SEP]']
[Init] best perm rec loss: 1.1300716400146484 for ['[CLS]yniferous comfort beth floor form possibly medal riding view. councils died [SEP]']
[Init] best perm rec loss: 1.1216068267822266 for ['[CLS]yn comfort riding possiblyiferous beth councils form floor medal. view died [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.314 (perp=10.509, rec=0.206, cos=0.006), tot_loss_proj:2.606 [t=0.17s]
prediction: ['[CLS] cbs ethnic, and un absurd vicious formsgent and absurd absurdup [SEP]']
[ 100/2000] tot_loss=2.231 (perp=10.463, rec=0.136, cos=0.003), tot_loss_proj:2.596 [t=0.17s]
prediction: ['[CLS]coomp, unsible absurd vicioussiblesible and absurd absurd] [SEP]']
[ 150/2000] tot_loss=2.408 (perp=11.545, rec=0.097, cos=0.002), tot_loss_proj:2.847 [t=0.17s]
prediction: ['[CLS]coomp, unuthuth vicioushensible andsible absurdwhile [SEP]']
[ 200/2000] tot_loss=2.325 (perp=11.218, rec=0.080, cos=0.002), tot_loss_proj:2.689 [t=0.17s]
prediction: ['[CLS]coomp, unuthuth vicioushensible andsible absurd] [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.140 (perp=10.291, rec=0.080, cos=0.002), tot_loss_proj:2.448 [t=0.17s]
prediction: ['[CLS]couth, unomputh vicioushensible andomp absurd 囗 [SEP]']
[ 300/2000] tot_loss=2.144 (perp=10.291, rec=0.084, cos=0.002), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS]couth, unomputh vicioushensible andomp absurd 囗 [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.137 (perp=9.607, rec=0.206, cos=0.010), tot_loss_proj:2.371 [t=0.17s]
prediction: ['[CLS]couth, unomputh vicioushensible and absurdnaud the [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.680 (perp=7.608, rec=0.155, cos=0.004), tot_loss_proj:1.910 [t=0.17s]
prediction: ['[CLS]couth, uncouthhensible and vicious absurdomp the [SEP]']
[ 450/2000] tot_loss=1.700 (perp=7.854, rec=0.126, cos=0.003), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS]couth, uncouthhensible and vicious absurdomp ( [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.557 (perp=7.187, rec=0.117, cos=0.003), tot_loss_proj:1.800 [t=0.17s]
prediction: ['[CLS]couth., uncouthhensible and vicious absurd di [SEP]']
Attempt swap
Put prefix at the end
[ 550/2000] tot_loss=1.580 (perp=7.189, rec=0.139, cos=0.003), tot_loss_proj:1.860 [t=0.17s]
prediction: ['[CLS], uncouthhensible and vicious absurd (couth. [SEP]']
[ 600/2000] tot_loss=1.359 (perp=6.210, rec=0.114, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS], uncouthhensible and vicious absurd adcouth. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.492 (perp=6.925, rec=0.105, cos=0.002), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] absurd, uncouthhensible and vicious adcouth un [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.501 (perp=6.993, rec=0.100, cos=0.002), tot_loss_proj:1.773 [t=0.17s]
prediction: ['[CLS] absurd, uncouthhensibleomp and vicious adcouth [SEP]']
[ 750/2000] tot_loss=1.518 (perp=7.107, rec=0.095, cos=0.002), tot_loss_proj:1.799 [t=0.17s]
prediction: ['[CLS] absurd, uncouthhensibleomp and vicious inscouth [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.404 (perp=6.573, rec=0.088, cos=0.002), tot_loss_proj:1.608 [t=0.17s]
prediction: ['[CLS] absurd, uncouthomphensible and vicious inscouth [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.487 (perp=6.962, rec=0.093, cos=0.002), tot_loss_proj:1.711 [t=0.17s]
prediction: ['[CLS] vicious, uncouthomphensible and absurdompcouth [SEP]']
[ 900/2000] tot_loss=1.488 (perp=6.962, rec=0.094, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] vicious, uncouthomphensible and absurdompcouth [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.481 (perp=6.962, rec=0.087, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] vicious, uncouthomphensible and absurdompcouth [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.592 (perp=7.515, rec=0.087, cos=0.002), tot_loss_proj:1.814 [t=0.17s]
prediction: ['[CLS] vicious, uncouthomphensible and absurd andomputh [SEP]']
[1050/2000] tot_loss=1.586 (perp=7.515, rec=0.081, cos=0.002), tot_loss_proj:1.815 [t=0.17s]
prediction: ['[CLS] vicious, uncouthomphensible and absurd andomputh [SEP]']
Attempt swap
Put prefix at the end
[1100/2000] tot_loss=1.483 (perp=6.936, rec=0.093, cos=0.002), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] andomputh vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=1.476 (perp=6.913, rec=0.091, cos=0.002), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS] andomputh, vicious uncouthomphensible and absurd [SEP]']
[1200/2000] tot_loss=1.470 (perp=6.913, rec=0.085, cos=0.002), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] andomputh, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
[1250/2000] tot_loss=1.492 (perp=7.025, rec=0.085, cos=0.002), tot_loss_proj:1.939 [t=0.17s]
prediction: ['[CLS] andomp,, vicious uncouthomphensible and absurd [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.326 (perp=6.205, rec=0.083, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
[1350/2000] tot_loss=1.319 (perp=6.205, rec=0.076, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
[1400/2000] tot_loss=1.332 (perp=6.205, rec=0.089, cos=0.002), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
[1450/2000] tot_loss=1.323 (perp=6.205, rec=0.080, cos=0.002), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
[1500/2000] tot_loss=1.323 (perp=6.205, rec=0.080, cos=0.002), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
[1550/2000] tot_loss=1.325 (perp=6.205, rec=0.082, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
[1600/2000] tot_loss=1.317 (perp=6.205, rec=0.074, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
[1650/2000] tot_loss=1.323 (perp=6.205, rec=0.080, cos=0.002), tot_loss_proj:1.710 [t=0.18s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
[1700/2000] tot_loss=1.324 (perp=6.205, rec=0.081, cos=0.002), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
[1750/2000] tot_loss=1.320 (perp=6.205, rec=0.077, cos=0.002), tot_loss_proj:1.712 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
[1800/2000] tot_loss=1.325 (perp=6.205, rec=0.082, cos=0.002), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
[1850/2000] tot_loss=1.326 (perp=6.205, rec=0.083, cos=0.002), tot_loss_proj:1.703 [t=0.18s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
[1900/2000] tot_loss=1.318 (perp=6.205, rec=0.075, cos=0.002), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
[1950/2000] tot_loss=1.315 (perp=6.205, rec=0.072, cos=0.002), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Attempt swap
[2000/2000] tot_loss=1.315 (perp=6.205, rec=0.072, cos=0.002), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]']
Done with input #68 of 100.
reference: 
========================
[CLS] uncouth, incomprehensible, vicious and absurd [SEP]
========================
predicted: 
========================
[CLS] andomp, vicious, uncouthomphensible and absurd [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 71.429 | p: 71.429 | r: 71.429
rouge2     | fm: 33.333 | p: 33.333 | r: 33.333
rougeL     | fm: 71.429 | p: 71.429 | r: 71.429
rougeLsum  | fm: 71.429 | p: 71.429 | r: 71.429
r1fm+r2fm = 104.762

[Aggregate metrics]:
rouge1     | fm: 89.841 | p: 89.117 | r: 90.731
rouge2     | fm: 54.000 | p: 53.724 | r: 54.328
rougeL     | fm: 76.918 | p: 76.374 | r: 77.668
rougeLsum  | fm: 77.084 | p: 76.458 | r: 77.715
r1fm+r2fm = 143.840

input #68 time: 0:06:56 | total time: 9:40:27


Running input #69 of 100.
reference: 
========================
a real winner -- smart , funny , subtle , and resonant . 
========================
average of cosine similarity 0.9992908222867736
highest_index [0]
highest [0.9992908222867736]
Debug: ids_shape = 18, pads = [18]
Debug: input ids = tensor([[  101,  1037,  2613,  3453,  1011,  1011,  6047,  1010,  6057,  1010,
         11259,  1010,  1998, 24501,  7856,  3372,  1012,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]']
[Init] best rec loss: 1.8529300689697266 for ['[CLS] california worth additional aston choices successfully apprenticeship rothschild mob kick or model sole living promoting cooper [SEP]']
[Init] best rec loss: 1.7803916931152344 for ['[CLS] pretty campus department slow behind alias laborphobia really abilityrama sl offices markers schedule maximum [SEP]']
[Init] best rec loss: 1.777809977531433 for ['[CLS] link mark andgi gutierrez exile planwriter bot amateur innings dreaming chestots those watershed [SEP]']
[Init] best rec loss: 1.6611499786376953 for ['[CLS] squadong it code recording why what qualifyingjonpsy bad bound paintings nuclear only panchayat [SEP]']
[Init] best rec loss: 1.5930790901184082 for ["[CLS] wait pale s force'an tyne km honey teaching contemporaryable finn over thanked favourite [SEP]"]
[Init] best perm rec loss: 1.5880229473114014 for ["[CLS] finn teaching honey s contemporary thanked favourite over wait km an force tyneable'pale [SEP]"]
[Init] best perm rec loss: 1.587775468826294 for ["[CLS]'thanked finn favourite contemporary pale teaching wait km an s over tyne honeyable force [SEP]"]
[Init] best perm rec loss: 1.585741400718689 for ["[CLS] over honey contemporary s favourite thanked tyne km finn pale'force teaching waitable an [SEP]"]
[Init] best perm rec loss: 1.5847747325897217 for ["[CLS] honey forceable s pale an teaching contemporary km finn thanked favourite over wait'tyne [SEP]"]
[Init] best perm rec loss: 1.5815293788909912 for ["[CLS] thanked s tyne favourite'pale teaching km finn contemporary force anable honey over wait [SEP]"]
[Init] best perm rec loss: 1.58074951171875 for ["[CLS] pale s over teaching km thanked favourite'finn tyne forceable honey wait contemporary an [SEP]"]
[Init] best perm rec loss: 1.5794026851654053 for ["[CLS] tyneable s wait favourite pale finn force contemporary thanked over km'teaching honey an [SEP]"]
[Init] best perm rec loss: 1.5793405771255493 for ["[CLS] over honey contemporary tyne teaching favourite finn sable force'an wait km pale thanked [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=3.695 (perp=11.907, rec=0.729, cos=0.584), tot_loss_proj:4.378 [t=0.17s]
prediction: ['[CLS] water crossing across ( industry occurs are wound losing is bianca burst bloom acc paleentation [SEP]']
[ 100/2000] tot_loss=2.964 (perp=10.756, rec=0.689, cos=0.124), tot_loss_proj:4.139 [t=0.17s]
prediction: ['[CLS] atomic [MASK] when to, © be. mounted fully lesbian combat bloom emblem. east [SEP]']
[ 150/2000] tot_loss=3.048 (perp=11.703, rec=0.619, cos=0.088), tot_loss_proj:4.321 [t=0.17s]
prediction: ['[CLS] electric [MASK] when for, occurs be active located dual lesbian combat window emblem. east [SEP]']
[ 200/2000] tot_loss=3.144 (perp=12.609, rec=0.549, cos=0.073), tot_loss_proj:4.508 [t=0.17s]
prediction: ['[CLS] prima [MASK] when for, occurs range active located dual lesbian combat window emblem. territorial [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.778 (perp=10.961, rec=0.519, cos=0.067), tot_loss_proj:4.127 [t=0.17s]
prediction: ['[CLS] stella [MASK] behind, occurs range for strong. dual lesbian combat window emblem. territorial [SEP]']
[ 300/2000] tot_loss=2.679 (perp=10.675, rec=0.489, cos=0.055), tot_loss_proj:4.168 [t=0.17s]
prediction: ['[CLS] [SEP] [MASK] behind, occurs be for definitely.. lesbian combat window emblem. territorial [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.621 (perp=10.586, rec=0.454, cos=0.050), tot_loss_proj:4.135 [t=0.17s]
prediction: ['[CLS] [SEP] [MASK], behind occurs ref for definitely.. lesbian combat window emblem. territorial [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=2.433 (perp=9.593, rec=0.461, cos=0.053), tot_loss_proj:3.935 [t=0.17s]
prediction: ['[CLS] [SEP] [MASK], behind occurs for smart. ref. lesbian combat window emblem. territorial [SEP]']
[ 450/2000] tot_loss=2.722 (perp=11.014, rec=0.490, cos=0.029), tot_loss_proj:4.194 [t=0.17s]
prediction: ['[CLS] [SEP] [MASK], behind occurs independent funny. made and lesbian firepot adolph. dialed [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.446 (perp=10.072, rec=0.415, cos=0.017), tot_loss_proj:4.070 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, behind occurs independent funny. range. lesbian firepot adolph. [MASK] [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=2.470 (perp=10.267, rec=0.403, cos=0.013), tot_loss_proj:4.084 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, when occurs independent funny. range, lesbian firepot armed [CLS]. [SEP]']
[ 600/2000] tot_loss=2.371 (perp=9.991, rec=0.365, cos=0.008), tot_loss_proj:4.059 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, when occurs independent funny. extended ( lesbian firepot armed the. [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.144 (perp=8.962, rec=0.345, cos=0.007), tot_loss_proj:3.832 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, when occurs independent funny. extended ( the firepot armed lesbian. [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.045 (perp=8.548, rec=0.330, cos=0.006), tot_loss_proj:3.729 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, independent occurs when funny. point ( the firepot armed lesbian. [SEP]']
[ 750/2000] tot_loss=2.137 (perp=9.049, rec=0.322, cos=0.006), tot_loss_proj:3.798 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, independent occurs across funny, point ( the firepot armed lesbian. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.082 (perp=8.780, rec=0.320, cos=0.005), tot_loss_proj:3.767 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, independent occurs across funny armed point ( the firepot, lesbian. [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.171 (perp=9.244, rec=0.316, cos=0.006), tot_loss_proj:3.854 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, independent, across funny armedlla - the firepot © lesbian. [SEP]']
[ 900/2000] tot_loss=2.144 (perp=9.169, rec=0.306, cos=0.005), tot_loss_proj:3.821 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, independent, across funny armed deco - the firepot © lesbian. [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=2.113 (perp=9.027, rec=0.303, cos=0.005), tot_loss_proj:3.828 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, independent - across smart armed deco, the firepot © lesbian. [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=2.065 (perp=8.850, rec=0.291, cos=0.005), tot_loss_proj:3.803 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, independent - the smart armed deco, across firepot © lesbian. [SEP]']
[1050/2000] tot_loss=2.245 (perp=9.737, rec=0.293, cos=0.005), tot_loss_proj:4.016 [t=0.17s]
prediction: ['[CLS] [SEP] dialed,frey - the smart armed deco, across firepot © lesbian. [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=2.123 (perp=9.146, rec=0.290, cos=0.004), tot_loss_proj:3.812 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, armed - the smartfrey deco, across firepot © lesbian. [SEP]']
Attempt swap
Moved token
[1150/2000] tot_loss=2.079 (perp=8.951, rec=0.285, cos=0.004), tot_loss_proj:3.794 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, armed - the smartfrey deco, firepot across © lesbian. [SEP]']
[1200/2000] tot_loss=2.074 (perp=8.951, rec=0.280, cos=0.004), tot_loss_proj:3.802 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, armed - the smartfrey deco, firepot across © lesbian. [SEP]']
Attempt swap
[1250/2000] tot_loss=2.113 (perp=9.134, rec=0.282, cos=0.004), tot_loss_proj:3.790 [t=0.19s]
prediction: ['[CLS] [SEP] dialed, armed - the smartfrey deco, firepot behind © lesbian. [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=2.097 (perp=9.047, rec=0.284, cos=0.004), tot_loss_proj:3.824 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, armed behind the smart compatibleonate, firepot - © lesbian. [SEP]']
[1350/2000] tot_loss=2.050 (perp=8.851, rec=0.275, cos=0.004), tot_loss_proj:3.807 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, armed behind the smart compatible deco, firepot - © lesbian. [SEP]']
Attempt swap
[1400/2000] tot_loss=2.096 (perp=9.111, rec=0.270, cos=0.004), tot_loss_proj:3.857 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, red behind the smart compatibleonate, firepot - © lesbian. [SEP]']
Attempt swap
[1450/2000] tot_loss=2.101 (perp=9.111, rec=0.276, cos=0.004), tot_loss_proj:3.854 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, red behind the smart compatibleonate, firepot - © lesbian. [SEP]']
[1500/2000] tot_loss=2.103 (perp=9.111, rec=0.277, cos=0.004), tot_loss_proj:3.858 [t=0.17s]
prediction: ['[CLS] [SEP] dialed, red behind the smart compatibleonate, firepot - © lesbian. [SEP]']
Attempt swap
Swapped tokens
[1550/2000] tot_loss=2.000 (perp=8.586, rec=0.279, cos=0.004), tot_loss_proj:3.717 [t=0.17s]
prediction: ['[CLS] [SEP] dialed,onate behind the smart compatible red, firepot - © lesbian. [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=2.006 (perp=8.637, rec=0.274, cos=0.004), tot_loss_proj:3.673 [t=0.17s]
prediction: ['[CLS] [SEP] dialedonate, behind the smart compatible form, firepot - © lesbian. [SEP]']
[1650/2000] tot_loss=2.021 (perp=8.691, rec=0.279, cos=0.004), tot_loss_proj:3.780 [t=0.17s]
prediction: ['[CLS] [SEP] dialedption, behind the smart compatible form, firepot - © lesbian. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=2.048 (perp=8.852, rec=0.274, cos=0.004), tot_loss_proj:3.798 [t=0.17s]
prediction: ['[CLS] [SEP] dialed compatible, behind the smart deco form, firepot - © lesbian. [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.982 (perp=8.460, rec=0.286, cos=0.004), tot_loss_proj:3.685 [t=0.17s]
prediction: ['[CLS] [SEP] dialed compatible, behind the smart - form, firepot deco © lesbian. [SEP]']
[1800/2000] tot_loss=1.973 (perp=8.460, rec=0.277, cos=0.004), tot_loss_proj:3.689 [t=0.20s]
prediction: ['[CLS] [SEP] dialed compatible, behind the smart - form, firepot deco © lesbian. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.921 (perp=8.197, rec=0.278, cos=0.004), tot_loss_proj:3.627 [t=0.17s]
prediction: ['[CLS] [SEP] dialed compatible, behind the form - smart, firepot deco © lesbian. [SEP]']
Attempt swap
[1900/2000] tot_loss=1.916 (perp=8.197, rec=0.272, cos=0.004), tot_loss_proj:3.627 [t=0.17s]
prediction: ['[CLS] [SEP] dialed compatible, behind the form - smart, firepot deco © lesbian. [SEP]']
[1950/2000] tot_loss=1.916 (perp=8.197, rec=0.273, cos=0.004), tot_loss_proj:3.624 [t=0.17s]
prediction: ['[CLS] [SEP] dialed compatible, behind the form - smart, firepot deco © lesbian. [SEP]']
Attempt swap
[2000/2000] tot_loss=1.906 (perp=8.197, rec=0.263, cos=0.004), tot_loss_proj:3.623 [t=0.17s]
prediction: ['[CLS] [SEP] dialed compatible, behind the form - smart, firepot deco © lesbian. [SEP]']
Done with input #69 of 100.
reference: 
========================
[CLS] a real winner - - smart, funny, subtle, and resonant. [SEP]
========================
predicted: 
========================
[CLS] [SEP] dialed compatible, behind the form - smart, firepot deco © lesbian. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 27.273 | p: 25.000 | r: 30.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 27.273 | p: 25.000 | r: 30.000
rougeLsum  | fm: 27.273 | p: 25.000 | r: 30.000
r1fm+r2fm = 27.273

[Aggregate metrics]:
rouge1     | fm: 89.056 | p: 88.298 | r: 89.913
rouge2     | fm: 53.290 | p: 52.999 | r: 53.625
rougeL     | fm: 76.434 | p: 75.836 | r: 77.124
rougeLsum  | fm: 76.212 | p: 75.597 | r: 76.909
r1fm+r2fm = 142.346

input #69 time: 0:06:57 | total time: 9:47:25


Running input #70 of 100.
reference: 
========================
gets clunky on the screen 
========================
average of cosine similarity 0.9993748902467187
highest_index [0]
highest [0.9993748902467187]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[  101,  4152, 18856, 16814,  2100,  2006,  1996,  3898,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] gets clunky on the screen [SEP]']
[Init] best rec loss: 1.7679567337036133 for ['[CLS] [CLS]el yourself lined dos written redwood [SEP]']
[Init] best rec loss: 1.536930799484253 for ['[CLS] monk laundry lights contractsbell gala viet [SEP]']
[Init] best rec loss: 1.408258080482483 for ['[CLS] buenos sol aspects powerful otherpass wallace [SEP]']
[Init] best rec loss: 1.3998394012451172 for ['[CLS] piano myth casualty immediately vocal right bottle [SEP]']
[Init] best rec loss: 1.2374904155731201 for ['[CLS] detention technological effects blood sharma herself mark [SEP]']
[Init] best rec loss: 1.2105610370635986 for ['[CLS] meg admitthermal success prize debut falcon [SEP]']
[Init] best rec loss: 1.1166847944259644 for ['[CLS] modern bob party িbution guy muscle [SEP]']
[Init] best perm rec loss: 1.1123631000518799 for ['[CLS] modern bobbution guy ি muscle party [SEP]']
[Init] best perm rec loss: 1.110944390296936 for ['[CLS] িbution guy party muscle modern bob [SEP]']
[Init] best perm rec loss: 1.1077313423156738 for ['[CLS] muscle িbution party guy modern bob [SEP]']
[Init] best perm rec loss: 1.1058592796325684 for ['[CLS] bob guy modern muscle িbution party [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.135 (perp=14.105, rec=0.291, cos=0.023), tot_loss_proj:4.418 [t=0.17s]
prediction: ['[CLS]unk screen get getsunk station screen [SEP]']
[ 100/2000] tot_loss=2.619 (perp=12.181, rec=0.172, cos=0.011), tot_loss_proj:4.209 [t=0.17s]
prediction: ['[CLS]unky gets getsunk screen screen [SEP]']
[ 150/2000] tot_loss=2.144 (perp=10.066, rec=0.125, cos=0.006), tot_loss_proj:2.660 [t=0.17s]
prediction: ['[CLS]unky gets cly the screen [SEP]']
[ 200/2000] tot_loss=1.938 (perp=9.164, rec=0.101, cos=0.005), tot_loss_proj:2.733 [t=0.17s]
prediction: ['[CLS]unky gets cly on screen [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.572 (perp=7.184, rec=0.122, cos=0.013), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 300/2000] tot_loss=1.519 (perp=7.184, rec=0.079, cos=0.003), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.521 (perp=7.184, rec=0.081, cos=0.003), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.507 (perp=7.184, rec=0.068, cos=0.003), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 450/2000] tot_loss=1.505 (perp=7.184, rec=0.065, cos=0.003), tot_loss_proj:1.747 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.510 (perp=7.184, rec=0.071, cos=0.003), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.517 (perp=7.184, rec=0.078, cos=0.002), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 600/2000] tot_loss=1.511 (perp=7.184, rec=0.072, cos=0.003), tot_loss_proj:1.766 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.519 (perp=7.184, rec=0.080, cos=0.002), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.512 (perp=7.184, rec=0.073, cos=0.002), tot_loss_proj:1.748 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 750/2000] tot_loss=1.513 (perp=7.184, rec=0.074, cos=0.002), tot_loss_proj:1.764 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.517 (perp=7.184, rec=0.078, cos=0.002), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.517 (perp=7.184, rec=0.078, cos=0.002), tot_loss_proj:1.739 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[ 900/2000] tot_loss=1.511 (perp=7.184, rec=0.072, cos=0.002), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.504 (perp=7.184, rec=0.065, cos=0.002), tot_loss_proj:1.753 [t=0.19s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1000/2000] tot_loss=1.517 (perp=7.184, rec=0.078, cos=0.002), tot_loss_proj:1.763 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1050/2000] tot_loss=1.504 (perp=7.184, rec=0.065, cos=0.002), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1100/2000] tot_loss=1.515 (perp=7.184, rec=0.076, cos=0.002), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1150/2000] tot_loss=1.513 (perp=7.184, rec=0.074, cos=0.002), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1200/2000] tot_loss=1.515 (perp=7.184, rec=0.076, cos=0.002), tot_loss_proj:1.750 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1250/2000] tot_loss=1.515 (perp=7.184, rec=0.076, cos=0.002), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1300/2000] tot_loss=1.511 (perp=7.184, rec=0.072, cos=0.002), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1350/2000] tot_loss=1.509 (perp=7.184, rec=0.070, cos=0.002), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1400/2000] tot_loss=1.507 (perp=7.184, rec=0.068, cos=0.002), tot_loss_proj:1.761 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1450/2000] tot_loss=1.502 (perp=7.184, rec=0.063, cos=0.002), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1500/2000] tot_loss=1.501 (perp=7.184, rec=0.062, cos=0.002), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1550/2000] tot_loss=1.510 (perp=7.184, rec=0.071, cos=0.002), tot_loss_proj:1.756 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1600/2000] tot_loss=1.500 (perp=7.184, rec=0.061, cos=0.002), tot_loss_proj:1.751 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1650/2000] tot_loss=1.512 (perp=7.184, rec=0.073, cos=0.002), tot_loss_proj:1.759 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1700/2000] tot_loss=1.520 (perp=7.184, rec=0.081, cos=0.002), tot_loss_proj:1.761 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1750/2000] tot_loss=1.505 (perp=7.184, rec=0.066, cos=0.002), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1800/2000] tot_loss=1.495 (perp=7.184, rec=0.056, cos=0.002), tot_loss_proj:1.753 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1850/2000] tot_loss=1.504 (perp=7.184, rec=0.065, cos=0.002), tot_loss_proj:1.749 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[1900/2000] tot_loss=1.517 (perp=7.184, rec=0.078, cos=0.002), tot_loss_proj:1.760 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
[1950/2000] tot_loss=1.509 (perp=7.184, rec=0.070, cos=0.002), tot_loss_proj:1.764 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Attempt swap
[2000/2000] tot_loss=1.516 (perp=7.184, rec=0.077, cos=0.002), tot_loss_proj:1.758 [t=0.17s]
prediction: ['[CLS]y gets clunky on screen [SEP]']
Done with input #70 of 100.
reference: 
========================
[CLS] gets clunky on the screen [SEP]
========================
predicted: 
========================
[CLS]y gets clunky on screen [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 85.714 | p: 85.714 | r: 85.714
rouge2     | fm: 50.000 | p: 50.000 | r: 50.000
rougeL     | fm: 85.714 | p: 85.714 | r: 85.714
rougeLsum  | fm: 85.714 | p: 85.714 | r: 85.714
r1fm+r2fm = 135.714

[Aggregate metrics]:
rouge1     | fm: 88.907 | p: 88.190 | r: 89.817
rouge2     | fm: 52.902 | p: 52.609 | r: 53.204
rougeL     | fm: 76.405 | p: 75.790 | r: 77.133
rougeLsum  | fm: 76.483 | p: 75.884 | r: 77.155
r1fm+r2fm = 141.809

input #70 time: 0:06:54 | total time: 9:54:19


Running input #71 of 100.
reference: 
========================
there 's not a single jump-in-your-seat moment and 
========================
average of cosine similarity 0.9993403548184047
highest_index [0]
highest [0.9993403548184047]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2045, 1005, 1055, 2025, 1037, 2309, 5376, 1011, 1999, 1011, 2115,
         1011, 2835, 2617, 1998,  102]], device='cuda:0')
Debug: ref = ["[CLS] there's not a single jump - in - your - seat moment and [SEP]"]
[Init] best rec loss: 1.8314898014068604 for ['[CLS] numerous boot maintenance archive welded societies nam recover news placement 1400 hunter bridegative between [SEP]']
[Init] best rec loss: 1.6892049312591553 for ['[CLS] exceed proof streak romeo cardinalsifice shy quality settlershaft unit copyright shawn rapid expensive [SEP]']
[Init] best rec loss: 1.4518476724624634 for ['[CLS] promising della ticket bbc cut claireda spielberg amsterdam tomb counts july adding annoyance elias [SEP]']
[Init] best rec loss: 1.4424015283584595 for ['[CLS] bad drainage monster seatystvision recorded abbotrcus distinguish luke safety smaller petition contracts [SEP]']
[Init] best rec loss: 1.4241973161697388 for ['[CLS] bonus sam deck resolve carson defense lots cancer sparhawk reasonable innocence pills no colony secret [SEP]']
[Init] best rec loss: 1.4165459871292114 for ['[CLS] emptied advertising dominant orange gap mini clothes subsequent history series dakotaminatehab goesu [SEP]']
[Init] best rec loss: 1.3269407749176025 for ['[CLS]gies amir plus locomotive contacthane flat all highest helmet postal operations political blindness colors [SEP]']
[Init] best rec loss: 1.3191274404525757 for ['[CLS] jean bed queens fewer of professor fall ram surhear marshall over liam molly creatures [SEP]']
[Init] best perm rec loss: 1.3124475479125977 for ['[CLS] ramhear liam bed fall jean fewer professor over creatures queens molly sur marshall of [SEP]']
[Init] best perm rec loss: 1.312007188796997 for ['[CLS] molly liam fewer professor of queens jean creatures sur marshall bed over ram fallhear [SEP]']
[Init] best perm rec loss: 1.3116501569747925 for ['[CLS]hear marshall sur ram of fewer professor liam creatures molly bed over queens fall jean [SEP]']
[Init] best perm rec loss: 1.309478759765625 for ['[CLS] sur jeanhear fall fewer marshall molly liam professor ram queens bed of creatures over [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.845 (perp=12.182, rec=0.341, cos=0.067), tot_loss_proj:3.659 [t=0.17s]
prediction: ["[CLS] eight alongside jump moment beer competing replaced jumping 'ana flight sound no seating [SEP]"]
[ 100/2000] tot_loss=1.832 (perp=8.034, rec=0.203, cos=0.022), tot_loss_proj:2.804 [t=0.17s]
prediction: ['[CLS] but single single moment - jump single jump - - your - not single and [SEP]']
[ 150/2000] tot_loss=1.775 (perp=8.026, rec=0.155, cos=0.015), tot_loss_proj:2.782 [t=0.17s]
prediction: ['[CLS] there single single moment - jump transportation jump - - your seat not single and [SEP]']
[ 200/2000] tot_loss=1.741 (perp=8.109, rec=0.113, cos=0.006), tot_loss_proj:2.814 [t=0.17s]
prediction: ['[CLS] there single a moment - jump transportation jump - - your seat not seat and [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.648 (perp=7.669, rec=0.107, cos=0.007), tot_loss_proj:2.952 [t=0.17s]
prediction: ['[CLS] there single a moment - farms jump in - your seat not your seat and [SEP]']
[ 300/2000] tot_loss=1.471 (perp=6.835, rec=0.101, cos=0.003), tot_loss_proj:2.880 [t=0.17s]
prediction: ['[CLS] there single a moment - a jump in - your seat not your seat and [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.674 (perp=7.959, rec=0.079, cos=0.003), tot_loss_proj:3.222 [t=0.17s]
prediction: ['[CLS] there single a moment - a in jump - your seat not stay seat and [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.757 (perp=8.345, rec=0.085, cos=0.003), tot_loss_proj:3.019 [t=0.17s]
prediction: ['[CLS] there a single moment - fried in jump - your seat not stay seat and [SEP]']
[ 450/2000] tot_loss=1.725 (perp=8.201, rec=0.082, cos=0.002), tot_loss_proj:3.218 [t=0.17s]
prediction: ['[CLS] there a single moment - lore in jump - your seat not stay seat and [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.495 (perp=7.104, rec=0.072, cos=0.002), tot_loss_proj:2.654 [t=0.17s]
prediction: ["[CLS] there s single moment -'in jump - your seat not a seat and [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.380 (perp=6.149, rec=0.142, cos=0.008), tot_loss_proj:2.517 [t=0.17s]
prediction: ["[CLS] there's single moment - in jump - your seat not a seat and [SEP]"]
[ 600/2000] tot_loss=1.347 (perp=6.149, rec=0.114, cos=0.003), tot_loss_proj:2.512 [t=0.17s]
prediction: ["[CLS] there's single moment - in jump - your seat not a seat and [SEP]"]
Attempt swap
Moved token
[ 650/2000] tot_loss=1.295 (perp=5.989, rec=0.095, cos=0.002), tot_loss_proj:2.482 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.279 (perp=5.989, rec=0.079, cos=0.002), tot_loss_proj:2.488 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
[ 750/2000] tot_loss=1.277 (perp=5.989, rec=0.078, cos=0.002), tot_loss_proj:2.483 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.268 (perp=5.989, rec=0.069, cos=0.002), tot_loss_proj:2.493 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.276 (perp=5.989, rec=0.076, cos=0.002), tot_loss_proj:2.493 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
[ 900/2000] tot_loss=1.272 (perp=5.989, rec=0.073, cos=0.002), tot_loss_proj:2.488 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.272 (perp=5.989, rec=0.073, cos=0.002), tot_loss_proj:2.487 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.271 (perp=5.989, rec=0.072, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
[1050/2000] tot_loss=1.272 (perp=5.989, rec=0.072, cos=0.002), tot_loss_proj:2.496 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.275 (perp=5.989, rec=0.076, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.273 (perp=5.989, rec=0.074, cos=0.002), tot_loss_proj:2.500 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
[1200/2000] tot_loss=1.262 (perp=5.989, rec=0.063, cos=0.002), tot_loss_proj:2.495 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.273 (perp=5.989, rec=0.074, cos=0.002), tot_loss_proj:2.498 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.270 (perp=5.989, rec=0.071, cos=0.002), tot_loss_proj:2.496 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
[1350/2000] tot_loss=1.274 (perp=5.989, rec=0.074, cos=0.002), tot_loss_proj:2.496 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.275 (perp=5.989, rec=0.075, cos=0.002), tot_loss_proj:2.493 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.265 (perp=5.989, rec=0.066, cos=0.002), tot_loss_proj:2.492 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
[1500/2000] tot_loss=1.261 (perp=5.989, rec=0.062, cos=0.002), tot_loss_proj:2.493 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.260 (perp=5.989, rec=0.061, cos=0.001), tot_loss_proj:2.496 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.266 (perp=5.989, rec=0.066, cos=0.002), tot_loss_proj:2.493 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
[1650/2000] tot_loss=1.268 (perp=5.989, rec=0.069, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.270 (perp=5.989, rec=0.071, cos=0.002), tot_loss_proj:2.496 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.266 (perp=5.989, rec=0.066, cos=0.002), tot_loss_proj:2.496 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
[1800/2000] tot_loss=1.268 (perp=5.989, rec=0.069, cos=0.002), tot_loss_proj:2.495 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.272 (perp=5.989, rec=0.073, cos=0.002), tot_loss_proj:2.497 [t=0.18s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.277 (perp=5.989, rec=0.078, cos=0.002), tot_loss_proj:2.496 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
[1950/2000] tot_loss=1.277 (perp=5.989, rec=0.078, cos=0.002), tot_loss_proj:2.495 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.271 (perp=5.989, rec=0.072, cos=0.002), tot_loss_proj:2.502 [t=0.17s]
prediction: ["[CLS] there's single moment in jump - - your seat not a seat and [SEP]"]
Done with input #71 of 100.
reference: 
========================
[CLS] there's not a single jump - in - your - seat moment and [SEP]
========================
predicted: 
========================
[CLS] there's single moment in jump - - your seat not a seat and [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.296 | p: 92.857 | r: 100.000
rouge2     | fm: 40.000 | p: 38.462 | r: 41.667
rougeL     | fm: 66.667 | p: 64.286 | r: 69.231
rougeLsum  | fm: 66.667 | p: 64.286 | r: 69.231
r1fm+r2fm = 136.296

[Aggregate metrics]:
rouge1     | fm: 88.989 | p: 88.227 | r: 89.949
rouge2     | fm: 53.030 | p: 52.685 | r: 53.364
rougeL     | fm: 76.390 | p: 75.766 | r: 77.121
rougeLsum  | fm: 76.349 | p: 75.684 | r: 77.050
r1fm+r2fm = 142.018

input #71 time: 0:07:01 | total time: 10:01:21


Running input #72 of 100.
reference: 
========================
has a tougher time balancing its violence with kafka-inspired philosophy 
========================
average of cosine similarity 0.9992329827199963
highest_index [0]
highest [0.9992329827199963]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2038,  1037,  7823,  2121,  2051, 20120,  2049,  4808,  2007,
         10556, 24316,  2050,  1011,  4427,  4695,   102]], device='cuda:0')
Debug: ref = ['[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]']
[Init] best rec loss: 1.660793662071228 for ['[CLS] fall cdpock eclipsefle anatomicalesis son quick sunshine percentage liquor katraz grandpa [SEP]']
[Init] best rec loss: 1.5929793119430542 for ['[CLS]ei credit cross chestduction mobile cis donekar rights grab bach route dot please [SEP]']
[Init] best rec loss: 1.4265902042388916 for ['[CLS] sutton matthew asher happily other virus variety killed an ear tar fixurn deepara [SEP]']
[Init] best rec loss: 1.4027378559112549 for ['[CLS]nted seriously public caesar failure major eli city edo memberf runway koppen join useless [SEP]']
[Init] best rec loss: 1.3698697090148926 for ['[CLS] stand parameters sunday fence turn strange breast ground and videos attic sets fell anotherraphic [SEP]']
[Init] best rec loss: 1.3598313331604004 for ['[CLS] shot stoppedwk wide maintenance upheld excused formation trojan al clit buckingham sand aching dams [SEP]']
[Init] best rec loss: 1.2334275245666504 for ['[CLS] office sat prime beneath applicationsism test ward humor spoke meal canada day school transportation [SEP]']
[Init] best rec loss: 1.2262848615646362 for ['[CLS] easier unified familiar sy ringo demand self injury outern board end craft dawn gods [SEP]']
[Init] best rec loss: 1.216339349746704 for ['[CLS] them relations quickly sip abexed without connected counties glacier digitalhic professor teller page [SEP]']
[Init] best rec loss: 1.190377116203308 for ['[CLS] things substitute air favors bishop defined werewolf anywaylusion ghana tonnesboard favorfin cy [SEP]']
[Init] best perm rec loss: 1.1880836486816406 for ['[CLS] ghana favorslusion air cy anywayboard werewolf tonnes things favor substitutefin bishop defined [SEP]']
[Init] best perm rec loss: 1.1873072385787964 for ['[CLS] favor ghana air bishop tonnes substitutelusion werewolf cy things anywayboard defined favorsfin [SEP]']
[Init] best perm rec loss: 1.1828306913375854 for ['[CLS] ghana bishop defined substitute tonnes favors anywaylusion things werewolffin favor air cyboard [SEP]']
[Init] best perm rec loss: 1.1827526092529297 for ['[CLS]fin favorslusion substitute anyway werewolf bishop air definedboard things favor ghana cy tonnes [SEP]']
[Init] best perm rec loss: 1.1818435192108154 for ['[CLS] ghana cy favorlusion defined substituteboard tonnes air things bishop favors anywayfin werewolf [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.882 (perp=12.498, rec=0.345, cos=0.038), tot_loss_proj:3.522 [t=0.19s]
prediction: ['[CLS] has to ignoring la harder time it some infringement tries food under costsor decline [SEP]']
[ 100/2000] tot_loss=2.351 (perp=10.389, rec=0.257, cos=0.017), tot_loss_proj:3.596 [t=0.19s]
prediction: ['[CLS] has time despite has tough time it technical violence changes food under tough shape compromise [SEP]']
[ 150/2000] tot_loss=2.305 (perp=10.520, rec=0.190, cos=0.011), tot_loss_proj:3.398 [t=0.19s]
prediction: ['[CLS] has time tough has tough time it its violence its philosophy a toughachal philosophy [SEP]']
[ 200/2000] tot_loss=2.133 (perp=9.930, rec=0.141, cos=0.006), tot_loss_proj:3.217 [t=0.19s]
prediction: ['[CLS] has time tough has tough time its its violence its philosophy with tough liz philosophy [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.802 (perp=8.391, rec=0.119, cos=0.005), tot_loss_proj:3.383 [t=0.21s]
prediction: ['[CLS] had balancing tough has tough time inspired its violence philosophy with its tough philosophy philosophy [SEP]']
[ 300/2000] tot_loss=1.895 (perp=8.963, rec=0.098, cos=0.004), tot_loss_proj:3.486 [t=0.17s]
prediction: ['[CLS] a balancing tough haser time inspired its violence philosophy with its toughathic philosophy [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.673 (perp=7.880, rec=0.095, cos=0.003), tot_loss_proj:3.194 [t=0.17s]
prediction: ['[CLS] a tough haser time inspired balancing its violence philosophy with its tough inspired philosophy [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.580 (perp=7.531, rec=0.072, cos=0.002), tot_loss_proj:2.448 [t=0.17s]
prediction: ['[CLS] a has tougher time inspired balancing its violence philosophy with its tough inspired philosophy [SEP]']
[ 450/2000] tot_loss=1.581 (perp=7.531, rec=0.073, cos=0.002), tot_loss_proj:2.438 [t=0.17s]
prediction: ['[CLS] a has tougher time inspired balancing its violence philosophy with its tough inspired philosophy [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.636 (perp=7.791, rec=0.076, cos=0.002), tot_loss_proj:2.563 [t=0.17s]
prediction: ['[CLS] has a tougher time inspired balancing its violencefk with its tough inspired philosophy [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.561 (perp=7.461, rec=0.066, cos=0.002), tot_loss_proj:1.853 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence inspiredfk with its tough inspired philosophy [SEP]']
[ 600/2000] tot_loss=1.567 (perp=7.461, rec=0.073, cos=0.002), tot_loss_proj:1.857 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence inspiredfk with its tough inspired philosophy [SEP]']
Attempt swap
Moved sequence
[ 650/2000] tot_loss=1.530 (perp=7.327, rec=0.062, cos=0.002), tot_loss_proj:1.781 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with its tough inspiredfk inspired philosophy [SEP]']
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.494 (perp=7.134, rec=0.066, cos=0.002), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with its toughfk inspired inspired philosophy [SEP]']
[ 750/2000] tot_loss=1.534 (perp=7.344, rec=0.064, cos=0.002), tot_loss_proj:1.714 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with its -fk inspired inspired philosophy [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.454 (perp=6.902, rec=0.072, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired inspired philosophy - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.454 (perp=6.902, rec=0.072, cos=0.002), tot_loss_proj:1.613 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired inspired philosophy - [SEP]']
[ 900/2000] tot_loss=1.440 (perp=6.902, rec=0.058, cos=0.002), tot_loss_proj:1.609 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired inspired philosophy - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.444 (perp=6.902, rec=0.062, cos=0.002), tot_loss_proj:1.611 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired inspired philosophy - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.454 (perp=6.902, rec=0.072, cos=0.002), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired inspired philosophy - [SEP]']
[1050/2000] tot_loss=1.444 (perp=6.902, rec=0.062, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired inspired philosophy - [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.448 (perp=6.875, rec=0.072, cos=0.002), tot_loss_proj:1.602 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired philosophy - inspired [SEP]']
Attempt swap
[1150/2000] tot_loss=1.445 (perp=6.875, rec=0.068, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired philosophy - inspired [SEP]']
[1200/2000] tot_loss=1.440 (perp=6.875, rec=0.064, cos=0.002), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired philosophy - inspired [SEP]']
Attempt swap
[1250/2000] tot_loss=1.449 (perp=6.875, rec=0.072, cos=0.001), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired philosophy - inspired [SEP]']
Attempt swap
[1300/2000] tot_loss=1.441 (perp=6.875, rec=0.065, cos=0.002), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired philosophy - inspired [SEP]']
[1350/2000] tot_loss=1.445 (perp=6.875, rec=0.068, cos=0.002), tot_loss_proj:1.606 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired philosophy - inspired [SEP]']
Attempt swap
[1400/2000] tot_loss=1.452 (perp=6.875, rec=0.075, cos=0.002), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired philosophy - inspired [SEP]']
Attempt swap
[1450/2000] tot_loss=1.440 (perp=6.875, rec=0.064, cos=0.002), tot_loss_proj:1.601 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired philosophy - inspired [SEP]']
[1500/2000] tot_loss=1.437 (perp=6.875, rec=0.060, cos=0.002), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with itsfk inspired philosophy - inspired [SEP]']
Attempt swap
[1550/2000] tot_loss=1.549 (perp=7.423, rec=0.063, cos=0.002), tot_loss_proj:1.671 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafk inspired philosophy - inspired [SEP]']
Attempt swap
[1600/2000] tot_loss=1.552 (perp=7.423, rec=0.066, cos=0.002), tot_loss_proj:1.672 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafk inspired philosophy - inspired [SEP]']
[1650/2000] tot_loss=1.553 (perp=7.423, rec=0.067, cos=0.002), tot_loss_proj:1.664 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafk inspired philosophy - inspired [SEP]']
Attempt swap
[1700/2000] tot_loss=1.543 (perp=7.423, rec=0.057, cos=0.002), tot_loss_proj:1.670 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafk inspired philosophy - inspired [SEP]']
Attempt swap
[1750/2000] tot_loss=1.556 (perp=7.423, rec=0.070, cos=0.002), tot_loss_proj:1.665 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafk inspired philosophy - inspired [SEP]']
[1800/2000] tot_loss=1.555 (perp=7.423, rec=0.069, cos=0.002), tot_loss_proj:1.661 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafk inspired philosophy - inspired [SEP]']
Attempt swap
[1850/2000] tot_loss=1.331 (perp=6.308, rec=0.068, cos=0.002), tot_loss_proj:1.402 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafka philosophy - inspired [SEP]']
Attempt swap
[1900/2000] tot_loss=1.333 (perp=6.308, rec=0.070, cos=0.002), tot_loss_proj:1.393 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafka philosophy - inspired [SEP]']
[1950/2000] tot_loss=1.329 (perp=6.308, rec=0.066, cos=0.002), tot_loss_proj:1.415 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafka philosophy - inspired [SEP]']
Attempt swap
[2000/2000] tot_loss=1.326 (perp=6.308, rec=0.063, cos=0.002), tot_loss_proj:1.403 [t=0.17s]
prediction: ['[CLS] has a tougher time balancing its violence with kafka philosophy - inspired [SEP]']
Done with input #72 of 100.
reference: 
========================
[CLS] has a tougher time balancing its violence with kafka - inspired philosophy [SEP]
========================
predicted: 
========================
[CLS] has a tougher time balancing its violence with kafk inspired philosophy - inspired [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 85.714 | r: 92.308
rouge2     | fm: 72.000 | p: 69.231 | r: 75.000
rougeL     | fm: 88.889 | p: 85.714 | r: 92.308
rougeLsum  | fm: 88.889 | p: 85.714 | r: 92.308
r1fm+r2fm = 160.889

[Aggregate metrics]:
rouge1     | fm: 89.010 | p: 88.189 | r: 90.001
rouge2     | fm: 53.096 | p: 52.795 | r: 53.495
rougeL     | fm: 76.604 | p: 75.951 | r: 77.357
rougeLsum  | fm: 76.516 | p: 75.864 | r: 77.239
r1fm+r2fm = 142.106

input #72 time: 0:07:10 | total time: 10:08:31


Running input #73 of 100.
reference: 
========================
bad filmmaking 
========================
average of cosine similarity 0.9991746597716884
highest_index [0]
highest [0.9991746597716884]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2919, 24466,   102]], device='cuda:0')
Debug: ref = ['[CLS] bad filmmaking [SEP]']
[Init] best rec loss: 1.8824208974838257 for ['[CLS] lands anglo [SEP]']
[Init] best rec loss: 1.7401381731033325 for ['[CLS] capitol living [SEP]']
[Init] best rec loss: 1.6489461660385132 for ['[CLS] symphony apparatus [SEP]']
[Init] best rec loss: 1.5039418935775757 for ['[CLS] denied airline [SEP]']
[Init] best rec loss: 1.4107468128204346 for ['[CLS] tierney sector [SEP]']
[Init] best perm rec loss: 1.407352328300476 for ['[CLS] sector tierney [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.134 (perp=9.723, rec=0.181, cos=0.009), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 100/2000] tot_loss=2.016 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 150/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.000 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 200/2000] tot_loss=2.003 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 250/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 300/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 350/2000] tot_loss=2.011 (perp=9.723, rec=0.064, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 400/2000] tot_loss=2.004 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:2.001 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 450/2000] tot_loss=1.998 (perp=9.723, rec=0.051, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.008 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.001 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 600/2000] tot_loss=2.003 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 650/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.012 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 700/2000] tot_loss=2.006 (perp=9.723, rec=0.060, cos=0.002), tot_loss_proj:2.018 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 750/2000] tot_loss=2.011 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 800/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 850/2000] tot_loss=2.008 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.017 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[ 900/2000] tot_loss=2.002 (perp=9.723, rec=0.056, cos=0.002), tot_loss_proj:2.009 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[ 950/2000] tot_loss=2.004 (perp=9.723, rec=0.057, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1000/2000] tot_loss=2.009 (perp=9.723, rec=0.062, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1050/2000] tot_loss=1.998 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1100/2000] tot_loss=2.023 (perp=9.723, rec=0.076, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1150/2000] tot_loss=1.994 (perp=9.723, rec=0.047, cos=0.002), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1200/2000] tot_loss=1.998 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1250/2000] tot_loss=2.006 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.022 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1300/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.007 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1350/2000] tot_loss=2.008 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.010 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1400/2000] tot_loss=2.016 (perp=9.723, rec=0.070, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1450/2000] tot_loss=2.007 (perp=9.723, rec=0.061, cos=0.002), tot_loss_proj:2.014 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1500/2000] tot_loss=2.010 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:2.013 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1550/2000] tot_loss=2.012 (perp=9.723, rec=0.065, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1600/2000] tot_loss=2.009 (perp=9.723, rec=0.063, cos=0.002), tot_loss_proj:1.997 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1650/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.020 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1700/2000] tot_loss=1.998 (perp=9.723, rec=0.052, cos=0.002), tot_loss_proj:2.002 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1750/2000] tot_loss=2.005 (perp=9.723, rec=0.059, cos=0.002), tot_loss_proj:2.011 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1800/2000] tot_loss=2.002 (perp=9.723, rec=0.055, cos=0.002), tot_loss_proj:2.006 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1850/2000] tot_loss=2.014 (perp=9.723, rec=0.068, cos=0.002), tot_loss_proj:2.019 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[1900/2000] tot_loss=2.005 (perp=9.723, rec=0.058, cos=0.002), tot_loss_proj:1.998 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
[1950/2000] tot_loss=2.012 (perp=9.723, rec=0.066, cos=0.002), tot_loss_proj:2.016 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Attempt swap
[2000/2000] tot_loss=2.001 (perp=9.723, rec=0.054, cos=0.002), tot_loss_proj:2.005 [t=0.17s]
prediction: ['[CLS] bad filmmaking [SEP]']
Done with input #73 of 100.
reference: 
========================
[CLS] bad filmmaking [SEP]
========================
predicted: 
========================
[CLS] bad filmmaking [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.221 | p: 88.381 | r: 90.151
rouge2     | fm: 53.744 | p: 53.395 | r: 54.124
rougeL     | fm: 76.853 | p: 76.211 | r: 77.623
rougeLsum  | fm: 76.776 | p: 76.152 | r: 77.530
r1fm+r2fm = 142.965

input #73 time: 0:06:56 | total time: 10:15:28


Running input #74 of 100.
reference: 
========================
share 
========================
average of cosine similarity 0.9992591939462341
highest_index [0]
highest [0.9992591939462341]
Debug: ids_shape = 3, pads = [3]
Debug: input ids = tensor([[ 101, 3745,  102]], device='cuda:0')
Debug: ref = ['[CLS] share [SEP]']
[Init] best rec loss: 1.6898705959320068 for ['[CLS]wed [SEP]']
[Init] best rec loss: 1.191595196723938 for ['[CLS] storage [SEP]']
[Init] best rec loss: 0.9334901571273804 for ['[CLS] answering [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.994 (perp=8.178, rec=0.323, cos=0.036), tot_loss_proj:2.151 [t=0.16s]
prediction: ['[CLS] share [SEP]']
[ 100/2000] tot_loss=1.758 (perp=8.178, rec=0.118, cos=0.004), tot_loss_proj:1.987 [t=0.19s]
prediction: ['[CLS] share [SEP]']
[ 150/2000] tot_loss=1.710 (perp=8.178, rec=0.073, cos=0.002), tot_loss_proj:1.748 [t=0.19s]
prediction: ['[CLS] share [SEP]']
[ 200/2000] tot_loss=1.689 (perp=8.178, rec=0.052, cos=0.002), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.695 (perp=8.178, rec=0.058, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 300/2000] tot_loss=1.706 (perp=8.178, rec=0.068, cos=0.002), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.717 (perp=8.178, rec=0.080, cos=0.002), tot_loss_proj:1.721 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.702 (perp=8.178, rec=0.065, cos=0.001), tot_loss_proj:1.742 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 450/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.683 (perp=8.178, rec=0.046, cos=0.002), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.002), tot_loss_proj:1.728 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 600/2000] tot_loss=1.686 (perp=8.178, rec=0.049, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.685 (perp=8.178, rec=0.048, cos=0.001), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 750/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.732 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.701 (perp=8.178, rec=0.064, cos=0.002), tot_loss_proj:1.754 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.703 (perp=8.178, rec=0.066, cos=0.001), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[ 900/2000] tot_loss=1.686 (perp=8.178, rec=0.049, cos=0.001), tot_loss_proj:1.728 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.001), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1000/2000] tot_loss=1.700 (perp=8.178, rec=0.063, cos=0.001), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1050/2000] tot_loss=1.708 (perp=8.178, rec=0.071, cos=0.001), tot_loss_proj:1.727 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1100/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.734 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1150/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.717 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1200/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.725 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1250/2000] tot_loss=1.697 (perp=8.178, rec=0.060, cos=0.001), tot_loss_proj:1.738 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1300/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.734 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1350/2000] tot_loss=1.681 (perp=8.178, rec=0.044, cos=0.001), tot_loss_proj:1.731 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1400/2000] tot_loss=1.707 (perp=8.178, rec=0.070, cos=0.001), tot_loss_proj:1.752 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1450/2000] tot_loss=1.699 (perp=8.178, rec=0.062, cos=0.001), tot_loss_proj:1.740 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1500/2000] tot_loss=1.687 (perp=8.178, rec=0.050, cos=0.001), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1550/2000] tot_loss=1.693 (perp=8.178, rec=0.056, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1600/2000] tot_loss=1.687 (perp=8.178, rec=0.050, cos=0.001), tot_loss_proj:1.746 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1650/2000] tot_loss=1.716 (perp=8.178, rec=0.079, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1700/2000] tot_loss=1.704 (perp=8.178, rec=0.067, cos=0.001), tot_loss_proj:1.736 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1750/2000] tot_loss=1.701 (perp=8.178, rec=0.064, cos=0.001), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1800/2000] tot_loss=1.682 (perp=8.178, rec=0.045, cos=0.001), tot_loss_proj:1.737 [t=0.20s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1850/2000] tot_loss=1.698 (perp=8.178, rec=0.061, cos=0.001), tot_loss_proj:1.730 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[1900/2000] tot_loss=1.705 (perp=8.178, rec=0.068, cos=0.001), tot_loss_proj:1.733 [t=0.17s]
prediction: ['[CLS] share [SEP]']
[1950/2000] tot_loss=1.696 (perp=8.178, rec=0.059, cos=0.001), tot_loss_proj:1.737 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Attempt swap
[2000/2000] tot_loss=1.688 (perp=8.178, rec=0.051, cos=0.001), tot_loss_proj:1.741 [t=0.17s]
prediction: ['[CLS] share [SEP]']
Done with input #74 of 100.
reference: 
========================
[CLS] share [SEP]
========================
predicted: 
========================
[CLS] share [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.333 | p: 88.515 | r: 90.260
rouge2     | fm: 54.249 | p: 53.986 | r: 54.597
rougeL     | fm: 77.197 | p: 76.558 | r: 77.918
rougeLsum  | fm: 77.055 | p: 76.436 | r: 77.756
r1fm+r2fm = 143.582

input #74 time: 0:06:46 | total time: 10:22:15


Running input #75 of 100.
reference: 
========================
this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten . 
========================
average of cosine similarity 0.9993458403755586
highest_index [0]
highest [0.9993458403755586]
Debug: ids_shape = 21, pads = [21]
Debug: input ids = tensor([[  101,  2023, 26144,  2046,  1996,  8680, 29110,  1997,  2566, 26289,
          3436,  5177, 18549,  2003,  2025,  4089,  7219,  2030,  6404,  1012,
           102]], device='cuda:0')
Debug: ref = ['[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]']
[Init] best rec loss: 1.9394946098327637 for ['[CLS] ran earlier gunner apps nitrogen at outnumbered now turbo torch symbolection late students unit immediately underside driving author [SEP]']
[Init] best rec loss: 1.9215192794799805 for ['[CLS]isch expansion earl early badly bea camp manuscripts nas counted butcher spike braun planned lark chad constant blue himself [SEP]']
[Init] best rec loss: 1.861011028289795 for ['[CLS]jal asked final tv. hooked arsine transit tonightper avon burlington us prize ri cables asity [SEP]']
[Init] best rec loss: 1.7244476079940796 for ['[CLS] ah rotten noctuidae find lynn mcc spectators bowl 1 walk nash hang laurel god town prairie wanted raiate [SEP]']
[Init] best rec loss: 1.7233116626739502 for ['[CLS] clan rush connacht zach section churches duties help es reason marlene alfred malone meaningose regiment lakes double moth [SEP]']
[Init] best rec loss: 1.661628007888794 for ['[CLS] surrounding imlence health flow mecklenburg dining twins execution plannercott by yes guy rattle senior batch 社 earth [SEP]']
[Init] best perm rec loss: 1.660509467124939 for ['[CLS] 社 execution senior bycott twins planner earth mecklenburg yes dininglence surrounding health flow guy im rattle batch [SEP]']
[Init] best perm rec loss: 1.6556261777877808 for ['[CLS] rattle mecklenburg dining surrounding flow batchcott guy planner by earthlence im twins health 社 execution senior yes [SEP]']
[Init] best perm rec loss: 1.6549123525619507 for ['[CLS] execution 社 senior surroundingcott mecklenburg guylence dining planner twins by health batch yes flow im rattle earth [SEP]']
[Init] best perm rec loss: 1.653684377670288 for ['[CLS] flow surrounding im mecklenburg planner batch 社 guycott twins by earthlence rattle senior execution dining health yes [SEP]']
[Init] best perm rec loss: 1.6525647640228271 for ['[CLS] surrounding mecklenburg health bycott guy batch flow plannerlence dining earth 社 yes twins rattle execution senior im [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.854 (perp=12.091, rec=0.393, cos=0.042), tot_loss_proj:3.875 [t=0.17s]
prediction: ['[CLS] expanded be eventspath mode. efficiency emotional duo " easily started stretching inspiration linked also never storm program [SEP]']
[ 100/2000] tot_loss=2.704 (perp=12.203, rec=0.247, cos=0.017), tot_loss_proj:3.791 [t=0.17s]
prediction: ['[CLS] fi be eventspath not not dismissed forgotten recreational during easily meet instability inspiration helped easily not forgotten forgotten [SEP]']
[ 150/2000] tot_loss=2.218 (perp=10.104, rec=0.188, cos=0.009), tot_loss_proj:3.006 [t=0.17s]
prediction: ['[CLS] this be experiences is not not dismissed forgotten economic in excursion our instability / implications easily not forgotten forgotten [SEP]']
[ 200/2000] tot_loss=2.076 (perp=9.687, rec=0.134, cos=0.005), tot_loss_proj:3.279 [t=0.17s]
prediction: ['[CLS] this or excursion is not not dismissed forgotten inward in excursion our instability or smackdown easily not dismissed forgotten [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=2.028 (perp=9.327, rec=0.156, cos=0.006), tot_loss_proj:2.903 [t=0.17s]
prediction: ['[CLS] this. excursion is not not dismissed forgotten ᅡ into excursion to instability or emotional not dismissed easily forgotten [SEP]']
[ 300/2000] tot_loss=2.207 (perp=10.392, rec=0.125, cos=0.004), tot_loss_proj:3.810 [t=0.17s]
prediction: ['[CLS] this. excursion is not not dismissed forgotten artistic into excursionenter instability or emotional dismissed dismissed easily forgotten [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=2.112 (perp=10.027, rec=0.103, cos=0.004), tot_loss_proj:3.416 [t=0.17s]
prediction: ['[CLS] this. excursion is not not dismissed forgotten artistic colony into excursionenter instability or emotional dismissed easily forgotten [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.989 (perp=9.345, rec=0.117, cos=0.003), tot_loss_proj:2.959 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissed forgotten artistic colony into excursionenter instability or emotional dismissed easily forgotten. [SEP]']
[ 450/2000] tot_loss=1.967 (perp=9.345, rec=0.096, cos=0.002), tot_loss_proj:2.956 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissed forgotten artistic colony into excursionenter instability or emotional dismissed easily forgotten. [SEP]']
Attempt swap
Moved sequence
[ 500/2000] tot_loss=1.917 (perp=9.113, rec=0.093, cos=0.002), tot_loss_proj:2.807 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissed into excursionenter instability or forgotten mental colony emotional dismissed easily forgotten. [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.854 (perp=8.790, rec=0.095, cos=0.002), tot_loss_proj:2.833 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissed into excursion mental instability or forgotten mentalenter mental dismissed easily forgotten. [SEP]']
[ 600/2000] tot_loss=1.822 (perp=8.655, rec=0.090, cos=0.002), tot_loss_proj:2.687 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissed intoenter mental instability or forgotten mentalenter mental dismissed easily forgotten. [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.802 (perp=8.581, rec=0.084, cos=0.002), tot_loss_proj:2.599 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissed intoenter mental mental instability or forgotten mentalenter dismissed easily forgotten. [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.795 (perp=8.505, rec=0.092, cos=0.002), tot_loss_proj:3.232 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissedenter into mental mental instability or forgotten mentalenter dismissed easily forgotten. [SEP]']
[ 750/2000] tot_loss=1.908 (perp=9.041, rec=0.098, cos=0.002), tot_loss_proj:3.177 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissedenter into mental mental instability or forgotten mentalenter dismissed easilyenter. [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.857 (perp=8.822, rec=0.091, cos=0.002), tot_loss_proj:3.376 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissedenter into mental mental instability or mental forgottenenter dismissed easilyenter. [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.798 (perp=8.536, rec=0.089, cos=0.002), tot_loss_proj:2.533 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissed into into mental mental instability or mental forgottenenter easily dismissedenter. [SEP]']
[ 900/2000] tot_loss=1.792 (perp=8.536, rec=0.083, cos=0.002), tot_loss_proj:2.534 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissed into into mental mental instability or mental forgottenenter easily dismissedenter. [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.682 (perp=8.008, rec=0.079, cos=0.002), tot_loss_proj:2.928 [t=0.17s]
prediction: ['[CLS] this excursion is not not dismissedenter into into mental mental instability or mental forgotten easily dismissedenter. [SEP]']
Attempt swap
Moved token
[1000/2000] tot_loss=1.624 (perp=7.648, rec=0.092, cos=0.002), tot_loss_proj:2.200 [t=0.17s]
prediction: ['[CLS] this excursion is not forgotten not dismissedenter into into mental mental instability or mental easily dismissedenter. [SEP]']
[1050/2000] tot_loss=1.616 (perp=7.648, rec=0.085, cos=0.002), tot_loss_proj:2.211 [t=0.17s]
prediction: ['[CLS] this excursion is not forgotten not dismissedenter into into mental mental instability or mental easily dismissedenter. [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.788 (perp=8.509, rec=0.085, cos=0.002), tot_loss_proj:2.494 [t=0.17s]
prediction: ['[CLS] this excursion is not not forgotten rhinoenter into into mental mental instability or mental easily dismissedenter. [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.709 (perp=8.070, rec=0.094, cos=0.001), tot_loss_proj:2.287 [t=0.17s]
prediction: ['[CLS] this excursion is not not forgottenenter into rhino into mental mental instability or mental easily dismissedenter. [SEP]']
[1200/2000] tot_loss=1.706 (perp=8.070, rec=0.090, cos=0.001), tot_loss_proj:2.294 [t=0.17s]
prediction: ['[CLS] this excursion is not not forgottenenter into rhino into mental mental instability or mental easily dismissedenter. [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.647 (perp=7.814, rec=0.083, cos=0.001), tot_loss_proj:2.246 [t=0.17s]
prediction: ['[CLS] this excursion is not not forgottenenter into rhino mental into mental instability or mental easily dismissedenter. [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.612 (perp=7.643, rec=0.081, cos=0.002), tot_loss_proj:2.457 [t=0.17s]
prediction: ['[CLS] this excursion is not forgottenenter into rhino mental into mental instability or mental not easily dismissedenter. [SEP]']
[1350/2000] tot_loss=1.615 (perp=7.643, rec=0.085, cos=0.001), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] this excursion is not forgottenenter into rhino mental into mental instability or mental not easily dismissedenter. [SEP]']
Attempt swap
[1400/2000] tot_loss=1.603 (perp=7.643, rec=0.073, cos=0.001), tot_loss_proj:2.451 [t=0.17s]
prediction: ['[CLS] this excursion is not forgottenenter into rhino mental into mental instability or mental not easily dismissedenter. [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.599 (perp=7.643, rec=0.069, cos=0.001), tot_loss_proj:2.436 [t=0.17s]
prediction: ['[CLS] this excursion is not forgottenenter into rhino mental into mental instability or mental not easily dismissedenter. [SEP]']
[1500/2000] tot_loss=1.605 (perp=7.643, rec=0.075, cos=0.001), tot_loss_proj:2.444 [t=0.17s]
prediction: ['[CLS] this excursion is not forgottenenter into rhino mental into mental instability or mental not easily dismissedenter. [SEP]']
Attempt swap
[1550/2000] tot_loss=1.609 (perp=7.643, rec=0.079, cos=0.001), tot_loss_proj:2.443 [t=0.17s]
prediction: ['[CLS] this excursion is not forgottenenter into rhino mental into mental instability or mental not easily dismissedenter. [SEP]']
Attempt swap
Moved token
[1600/2000] tot_loss=1.876 (perp=8.939, rec=0.087, cos=0.001), tot_loss_proj:2.726 [t=0.17s]
prediction: ['[CLS] this excursion is not forgottenenterenter mentalcola into mental instability or mental not easily dismissedenter. [SEP]']
[1650/2000] tot_loss=1.860 (perp=8.939, rec=0.071, cos=0.001), tot_loss_proj:2.723 [t=0.17s]
prediction: ['[CLS] this excursion is not forgottenenterenter mentalcola into mental instability or mental not easily dismissedenter. [SEP]']
Attempt swap
Swapped tokens
[1700/2000] tot_loss=1.772 (perp=8.460, rec=0.078, cos=0.002), tot_loss_proj:2.710 [t=0.17s]
prediction: ['[CLS] this excursion is not forgotten mentalenterentercola into mental instability or mental not easily dismissedenter. [SEP]']
Attempt swap
Moved token
[1750/2000] tot_loss=1.723 (perp=8.204, rec=0.081, cos=0.002), tot_loss_proj:2.343 [t=0.17s]
prediction: ['[CLS] this excursion is not forgotten mentalenterentercola into mental instability or mentalenter not easily dismissed. [SEP]']
[1800/2000] tot_loss=1.723 (perp=8.204, rec=0.081, cos=0.002), tot_loss_proj:2.347 [t=0.17s]
prediction: ['[CLS] this excursion is not forgotten mentalenterentercola into mental instability or mentalenter not easily dismissed. [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.686 (perp=8.030, rec=0.079, cos=0.002), tot_loss_proj:2.293 [t=0.17s]
prediction: ['[CLS] this excursion is not forgotten mentalcolaenterenter into mental instability or mentalenter not easily dismissed. [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.667 (perp=7.922, rec=0.081, cos=0.002), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] this excursion is not forgotten mentalcolaenterenter into into mental instability or mental not easily dismissed. [SEP]']
[1950/2000] tot_loss=1.665 (perp=7.922, rec=0.080, cos=0.002), tot_loss_proj:2.528 [t=0.17s]
prediction: ['[CLS] this excursion is not forgotten mentalcolaenterenter into into mental instability or mental not easily dismissed. [SEP]']
Attempt swap
Moved token
[2000/2000] tot_loss=1.735 (perp=8.299, rec=0.074, cos=0.002), tot_loss_proj:2.407 [t=0.17s]
prediction: ['[CLS] this excursion is not forgotten mentalcolaenterenterenter mental into mental instability or not easily dismissed. [SEP]']
Done with input #75 of 100.
reference: 
========================
[CLS] this excursion into the epicenter of percolating mental instability is not easily dismissed or forgotten. [SEP]
========================
predicted: 
========================
[CLS] this excursion is not forgottenenter intocola mental into mental instability or mental not easily dismissedenter. [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 64.706 | p: 64.706 | r: 64.706
rouge2     | fm: 31.250 | p: 31.250 | r: 31.250
rougeL     | fm: 52.941 | p: 52.941 | r: 52.941
rougeLsum  | fm: 52.941 | p: 52.941 | r: 52.941
r1fm+r2fm = 95.956

[Aggregate metrics]:
rouge1     | fm: 88.989 | p: 88.218 | r: 89.939
rouge2     | fm: 53.984 | p: 53.670 | r: 54.346
rougeL     | fm: 76.728 | p: 76.099 | r: 77.539
rougeLsum  | fm: 76.776 | p: 76.139 | r: 77.534
r1fm+r2fm = 142.972

input #75 time: 0:06:53 | total time: 10:29:08


Running input #76 of 100.
reference: 
========================
's as if allen , at 66 , has stopped challenging himself . 
========================
average of cosine similarity 0.9991386602126575
highest_index [0]
highest [0.9991386602126575]
Debug: ids_shape = 16, pads = [16]
Debug: input ids = tensor([[  101,  1005,  1055,  2004,  2065,  5297,  1010,  2012,  5764,  1010,
          2038,  3030, 10368,  2370,  1012,   102]], device='cuda:0')
Debug: ref = ["[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]"]
[Init] best rec loss: 1.782433271408081 for ['[CLS] touch 20 has forth rapper fighter formsolis relay whatoration r bug riverside [SEP]']
[Init] best rec loss: 1.7596430778503418 for ['[CLS] aretadt hopper abe hours og begin ratios ( harmonic nonedget straight requiem [SEP]']
[Init] best rec loss: 1.7049720287322998 for ['[CLS] vimes spread stanford telescope formed neighbourhood wire chang miniseries farmers kyle having bend attempt [SEP]']
[Init] best rec loss: 1.6918405294418335 for ['[CLS] tonight crushed approximately includinganal uncovered issue eye couples overvanberger crime meditation [SEP]']
[Init] best rec loss: 1.674768328666687 for ['[CLS] midnight even task j mesh constellation village typhoonorough, advancing hammerist carol [SEP]']
[Init] best rec loss: 1.591769814491272 for ['[CLS] pan absence attachedzzinessgrass rus julius allen highrian passion budget strong area [SEP]']
[Init] best rec loss: 1.4612284898757935 for ['[CLS] tuesdayrd en described resthedron vantage regards drag fall press inception twelvemill [SEP]']
[Init] best rec loss: 1.3690840005874634 for ['[CLS] mango onwards purse backward tauthaw ab left surreal pushedˣ hard (oning [SEP]']
[Init] best perm rec loss: 1.3682646751403809 for ['[CLS] ( backward ab taut mangoˣ left onwards pushed hard surrealhawoning purse [SEP]']
[Init] best perm rec loss: 1.3626619577407837 for ['[CLS]ˣ (haw onwards aboning taut left hard backward surreal pushed mango purse [SEP]']
[Init] best perm rec loss: 1.3604645729064941 for ['[CLS] (ˣ leftoning onwards pushed taut ab hard backward surreal mango pursehaw [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.810 (perp=12.341, rec=0.321, cos=0.021), tot_loss_proj:3.887 [t=0.17s]
prediction: ['[CLS] is held left. infantry s fangs stopped stopped effects challenging seemed charlotte stopped [SEP]']
[ 100/2000] tot_loss=2.263 (perp=10.222, rec=0.207, cos=0.011), tot_loss_proj:3.126 [t=0.17s]
prediction: ["[CLS] like'stopped. himself, challenging stopped stopped challenging challenging began with stopped [SEP]"]
[ 150/2000] tot_loss=2.338 (perp=10.894, rec=0.152, cos=0.006), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] as 17 has. allen has challenging stopped stopped challenging himself has with stopped [SEP]']
[ 200/2000] tot_loss=1.970 (perp=9.187, rec=0.127, cos=0.005), tot_loss_proj:2.740 [t=0.17s]
prediction: ['[CLS] as 66 has. allen, has stopped stopped challenging himself has, stopped [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.807 (perp=7.845, rec=0.226, cos=0.012), tot_loss_proj:2.418 [t=0.17s]
prediction: ["[CLS] as at'', allen, has stopped stopped challenging himself has at [SEP]"]
[ 300/2000] tot_loss=1.813 (perp=8.235, rec=0.159, cos=0.006), tot_loss_proj:2.720 [t=0.17s]
prediction: ["[CLS] as at'', allen, has stopped stopped challenging himself has without [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.614 (perp=7.330, rec=0.143, cos=0.005), tot_loss_proj:2.270 [t=0.17s]
prediction: ["[CLS] as at'', allen, has stopped at challenging himself has stopped [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.553 (perp=7.090, rec=0.130, cos=0.005), tot_loss_proj:2.221 [t=0.17s]
prediction: ["[CLS] as'at ', allen, has stopped at challenging himself has stopped [SEP]"]
[ 450/2000] tot_loss=1.621 (perp=7.429, rec=0.130, cos=0.005), tot_loss_proj:2.518 [t=0.17s]
prediction: ["[CLS] as'66 ', allen, subsequently stopped at challenging himself has stopped [SEP]"]
Attempt swap
[ 500/2000] tot_loss=1.615 (perp=7.429, rec=0.125, cos=0.004), tot_loss_proj:2.510 [t=0.17s]
prediction: ["[CLS] as'66 ', allen, subsequently stopped at challenging himself has stopped [SEP]"]
Attempt swap
[ 550/2000] tot_loss=1.741 (perp=8.122, rec=0.112, cos=0.004), tot_loss_proj:2.625 [t=0.17s]
prediction: ["[CLS] as'66 ', allen, subsequently abbreviated at challenging himself has stopped [SEP]"]
[ 600/2000] tot_loss=1.869 (perp=8.709, rec=0.123, cos=0.004), tot_loss_proj:2.698 [t=0.17s]
prediction: ["[CLS] as'66., allen, subsequently abbreviated at challenging himself has stopped [SEP]"]
Attempt swap
[ 650/2000] tot_loss=1.863 (perp=8.709, rec=0.117, cos=0.004), tot_loss_proj:2.703 [t=0.17s]
prediction: ["[CLS] as'66., allen, subsequently abbreviated at challenging himself has stopped [SEP]"]
Attempt swap
[ 700/2000] tot_loss=1.802 (perp=8.408, rec=0.117, cos=0.004), tot_loss_proj:2.591 [t=0.17s]
prediction: ["[CLS] as'66., allen, subsequentlyoulos at challenging himself has stopped [SEP]"]
[ 750/2000] tot_loss=1.788 (perp=8.408, rec=0.103, cos=0.004), tot_loss_proj:2.586 [t=0.17s]
prediction: ["[CLS] as'66., allen, subsequentlyoulos at challenging himself has stopped [SEP]"]
Attempt swap
[ 800/2000] tot_loss=1.805 (perp=8.408, rec=0.119, cos=0.004), tot_loss_proj:2.592 [t=0.17s]
prediction: ["[CLS] as'66., allen, subsequentlyoulos at challenging himself has stopped [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.802 (perp=8.408, rec=0.117, cos=0.004), tot_loss_proj:2.583 [t=0.17s]
prediction: ["[CLS] as'66., allen, subsequentlyoulos at challenging himself has stopped [SEP]"]
[ 900/2000] tot_loss=1.800 (perp=8.408, rec=0.114, cos=0.004), tot_loss_proj:2.590 [t=0.17s]
prediction: ["[CLS] as'66., allen, subsequentlyoulos at challenging himself has stopped [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.802 (perp=8.408, rec=0.117, cos=0.004), tot_loss_proj:2.590 [t=0.17s]
prediction: ["[CLS] as'66., allen, subsequentlyoulos at challenging himself has stopped [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.811 (perp=8.475, rec=0.113, cos=0.004), tot_loss_proj:2.568 [t=0.17s]
prediction: ["[CLS] as'66., allen, newtoulos at challenging himself has stopped [SEP]"]
[1050/2000] tot_loss=1.867 (perp=8.816, rec=0.100, cos=0.004), tot_loss_proj:2.672 [t=0.17s]
prediction: ["[CLS] as'66., allen, newt dalai at challenging himself has stopped [SEP]"]
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.814 (perp=8.489, rec=0.112, cos=0.004), tot_loss_proj:2.647 [t=0.17s]
prediction: ['[CLS] as at 66. at allen, newtoulos, challenging himself has stopped [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.867 (perp=8.746, rec=0.114, cos=0.004), tot_loss_proj:2.609 [t=0.17s]
prediction: ['[CLS] as at 66., allen, newtnessy at challenging himself has stopped [SEP]']
[1200/2000] tot_loss=1.873 (perp=8.746, rec=0.120, cos=0.004), tot_loss_proj:2.610 [t=0.17s]
prediction: ['[CLS] as at 66., allen, newtnessy at challenging himself has stopped [SEP]']
Attempt swap
[1250/2000] tot_loss=1.846 (perp=8.746, rec=0.094, cos=0.004), tot_loss_proj:2.611 [t=0.17s]
prediction: ['[CLS] as at 66., allen, newtnessy at challenging himself has stopped [SEP]']
Attempt swap
[1300/2000] tot_loss=1.863 (perp=8.746, rec=0.110, cos=0.004), tot_loss_proj:2.609 [t=0.17s]
prediction: ['[CLS] as at 66., allen, newtnessy at challenging himself has stopped [SEP]']
[1350/2000] tot_loss=1.836 (perp=8.654, rec=0.101, cos=0.004), tot_loss_proj:3.113 [t=0.17s]
prediction: ['[CLS] as at 66., allen, newt if at challenging himself has stopped [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.867 (perp=8.783, rec=0.106, cos=0.004), tot_loss_proj:3.641 [t=0.17s]
prediction: ['[CLS] as at 66., allen, newt stopped at challenging himself hasnessy [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.735 (perp=8.133, rec=0.104, cos=0.004), tot_loss_proj:3.162 [t=0.17s]
prediction: ['[CLS] as at. 66, allen, newt stopped at challenging himself has if [SEP]']
[1500/2000] tot_loss=1.724 (perp=8.133, rec=0.093, cos=0.004), tot_loss_proj:3.160 [t=0.17s]
prediction: ['[CLS] as at. 66, allen, newt stopped at challenging himself has if [SEP]']
Attempt swap
[1550/2000] tot_loss=1.748 (perp=8.263, rec=0.092, cos=0.004), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] as at. 66, allen,ignant stopped at challenging himself has if [SEP]']
Attempt swap
[1600/2000] tot_loss=1.763 (perp=8.263, rec=0.107, cos=0.004), tot_loss_proj:3.422 [t=0.17s]
prediction: ['[CLS] as at. 66, allen,ignant stopped at challenging himself has if [SEP]']
[1650/2000] tot_loss=1.750 (perp=8.263, rec=0.094, cos=0.004), tot_loss_proj:3.429 [t=0.17s]
prediction: ['[CLS] as at. 66, allen,ignant stopped at challenging himself has if [SEP]']
Attempt swap
[1700/2000] tot_loss=1.760 (perp=8.263, rec=0.104, cos=0.003), tot_loss_proj:3.429 [t=0.17s]
prediction: ['[CLS] as at. 66, allen,ignant stopped at challenging himself has if [SEP]']
Attempt swap
[1750/2000] tot_loss=1.754 (perp=8.263, rec=0.098, cos=0.003), tot_loss_proj:3.424 [t=0.17s]
prediction: ['[CLS] as at. 66, allen,ignant stopped at challenging himself has if [SEP]']
[1800/2000] tot_loss=1.753 (perp=8.263, rec=0.097, cos=0.003), tot_loss_proj:3.426 [t=0.17s]
prediction: ['[CLS] as at. 66, allen,ignant stopped at challenging himself has if [SEP]']
Attempt swap
[1850/2000] tot_loss=1.756 (perp=8.263, rec=0.100, cos=0.003), tot_loss_proj:3.425 [t=0.17s]
prediction: ['[CLS] as at. 66, allen,ignant stopped at challenging himself has if [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.637 (perp=7.613, rec=0.110, cos=0.004), tot_loss_proj:2.675 [t=0.17s]
prediction: ['[CLS] as at. 66, allen,ignant if at challenging himself has stopped [SEP]']
[1950/2000] tot_loss=1.619 (perp=7.613, rec=0.092, cos=0.004), tot_loss_proj:2.671 [t=0.17s]
prediction: ['[CLS] as at. 66, allen,ignant if at challenging himself has stopped [SEP]']
Attempt swap
[2000/2000] tot_loss=1.727 (perp=8.115, rec=0.100, cos=0.004), tot_loss_proj:3.302 [t=0.17s]
prediction: ['[CLS] as at. 66, allen, if if at challenging himself has stopped [SEP]']
Done with input #76 of 100.
reference: 
========================
[CLS]'s as if allen, at 66, has stopped challenging himself. [SEP]
========================
predicted: 
========================
[CLS] as at. 66, allen,ignant stopped at challenging himself has if [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.000 | p: 84.615 | r: 91.667
rouge2     | fm: 17.391 | p: 16.667 | r: 18.182
rougeL     | fm: 64.000 | p: 61.538 | r: 66.667
rougeLsum  | fm: 64.000 | p: 61.538 | r: 66.667
r1fm+r2fm = 105.391

[Aggregate metrics]:
rouge1     | fm: 89.020 | p: 88.222 | r: 89.994
rouge2     | fm: 53.412 | p: 53.086 | r: 53.755
rougeL     | fm: 76.678 | p: 76.008 | r: 77.462
rougeLsum  | fm: 76.622 | p: 75.937 | r: 77.389
r1fm+r2fm = 142.433

input #76 time: 0:06:49 | total time: 10:35:57


Running input #77 of 100.
reference: 
========================
is its make-believe promise of life that soars above the material realm 
========================
average of cosine similarity 0.9992013460879874
highest_index [0]
highest [0.9992013460879874]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  2003,  2049,  2191,  1011,  2903,  4872,  1997,  2166,  2008,
          2061, 11650,  2682,  1996,  3430,  8391,   102]], device='cuda:0')
Debug: ref = ['[CLS] is its make - believe promise of life that soars above the material realm [SEP]']
[Init] best rec loss: 1.6982685327529907 for ['[CLS] kind still lucian marijuanauariesani selena said parish ems breathing - tar promises cutter [SEP]']
[Init] best rec loss: 1.6925209760665894 for ['[CLS] scoutslip what airfield ref el trunks factionsrk incorporated concentrate lyricsvocation exposition protects [SEP]']
[Init] best rec loss: 1.4739956855773926 for ['[CLS] medium outside purple ways sheep sometimeraphic gray win whereno ole park most lime [SEP]']
[Init] best perm rec loss: 1.4576562643051147 for ['[CLS] where medium limeraphicno ways ole sheep sometime purple outside win most gray park [SEP]']
[Init] best perm rec loss: 1.4574075937271118 for ['[CLS] where medium park oleno ways sheep outside gray purple sometime win mostraphic lime [SEP]']
[Init] best perm rec loss: 1.4540070295333862 for ['[CLS] lime gray medium park whereraphic purple ole most win ways sheep sometime outsideno [SEP]']
[Init] best perm rec loss: 1.4537286758422852 for ['[CLS] parkraphic lime where medium ways ole sometime most purpleno outside gray win sheep [SEP]']
[Init] best perm rec loss: 1.4526270627975464 for ['[CLS] where park gray mediumraphic ways ole most lime sheepno win sometime outside purple [SEP]']
[Init] best perm rec loss: 1.4507323503494263 for ['[CLS] medium sheep park where purpleraphic sometime gray most outsideno ole lime ways win [SEP]']
[Init] best perm rec loss: 1.448798418045044 for ['[CLS] sheep medium gray where sometimeraphic park ole most lime win ways purpleno outside [SEP]']
[Init] best perm rec loss: 1.4465056657791138 for ['[CLS] where medium sometime park ole win purple gray sheep lime ways outsideraphic mostno [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.927 (perp=12.651, rec=0.371, cos=0.025), tot_loss_proj:3.960 [t=0.17s]
prediction: ['[CLS] wonderful sweet date ！ entity predicted promise last variety its tomorrow together less saint potential [SEP]']
[ 100/2000] tot_loss=2.122 (perp=9.215, rec=0.266, cos=0.013), tot_loss_proj:2.547 [t=0.17s]
prediction: ['[CLS] is beautiful above its the materials promise above life its tomorrow together you above potential [SEP]']
[ 150/2000] tot_loss=2.048 (perp=9.211, rec=0.197, cos=0.008), tot_loss_proj:2.568 [t=0.17s]
prediction: ['[CLS] is beautiful above its the believe promise above that the lifears is above life [SEP]']
[ 200/2000] tot_loss=2.195 (perp=10.188, rec=0.152, cos=0.006), tot_loss_proj:3.076 [t=0.17s]
prediction: ['[CLS] isy above its have believe promise make that the lifears that above realm [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.961 (perp=9.006, rec=0.153, cos=0.006), tot_loss_proj:2.943 [t=0.17s]
prediction: ['[CLS] isy above its - of promise made that the lifears believe above realm [SEP]']
[ 300/2000] tot_loss=1.928 (perp=8.956, rec=0.133, cos=0.004), tot_loss_proj:2.681 [t=0.17s]
prediction: ['[CLS] is of above its - of promise made that the lifears believe above realm [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.766 (perp=8.192, rec=0.124, cos=0.003), tot_loss_proj:2.745 [t=0.17s]
prediction: ['[CLS] is - of above its of promise made that the lifears make above realm [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.754 (perp=8.146, rec=0.122, cos=0.004), tot_loss_proj:2.776 [t=0.17s]
prediction: ['[CLS] is - of above its promise of believe that the lifears make above realm [SEP]']
[ 450/2000] tot_loss=1.734 (perp=8.146, rec=0.102, cos=0.003), tot_loss_proj:2.778 [t=0.17s]
prediction: ['[CLS] is - of above its promise of believe that the lifears make above realm [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.656 (perp=7.775, rec=0.099, cos=0.002), tot_loss_proj:2.625 [t=0.18s]
prediction: ['[CLS] is - of above its promise of life that the believears make above realm [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.547 (perp=7.267, rec=0.091, cos=0.002), tot_loss_proj:2.495 [t=0.19s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
[ 600/2000] tot_loss=1.562 (perp=7.267, rec=0.107, cos=0.002), tot_loss_proj:2.496 [t=0.19s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.544 (perp=7.267, rec=0.089, cos=0.002), tot_loss_proj:2.486 [t=0.18s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.541 (perp=7.267, rec=0.085, cos=0.002), tot_loss_proj:2.492 [t=0.19s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
[ 750/2000] tot_loss=1.546 (perp=7.267, rec=0.091, cos=0.002), tot_loss_proj:2.484 [t=0.19s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.544 (perp=7.267, rec=0.089, cos=0.002), tot_loss_proj:2.491 [t=0.18s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.541 (perp=7.267, rec=0.086, cos=0.002), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
[ 900/2000] tot_loss=1.540 (perp=7.267, rec=0.084, cos=0.002), tot_loss_proj:2.487 [t=0.18s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.530 (perp=7.267, rec=0.075, cos=0.002), tot_loss_proj:2.490 [t=0.19s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
Attempt swap
[1000/2000] tot_loss=1.543 (perp=7.267, rec=0.088, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
[1050/2000] tot_loss=1.528 (perp=7.267, rec=0.073, cos=0.002), tot_loss_proj:2.489 [t=0.17s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
Attempt swap
[1100/2000] tot_loss=1.536 (perp=7.267, rec=0.080, cos=0.002), tot_loss_proj:2.488 [t=0.18s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
Attempt swap
[1150/2000] tot_loss=1.536 (perp=7.267, rec=0.081, cos=0.002), tot_loss_proj:2.484 [t=0.17s]
prediction: ['[CLS] is - - above its promise of life that the believears make above realm [SEP]']
[1200/2000] tot_loss=1.468 (perp=6.962, rec=0.074, cos=0.002), tot_loss_proj:2.167 [t=0.17s]
prediction: ['[CLS] is - - so its promise of life that the believears make above realm [SEP]']
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.351 (perp=6.300, rec=0.089, cos=0.002), tot_loss_proj:2.136 [t=0.17s]
prediction: ['[CLS] is - - believe its promise of life that the soars make above material [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.288 (perp=6.017, rec=0.082, cos=0.002), tot_loss_proj:1.870 [t=0.17s]
prediction: ['[CLS] is - - believe its promise of life that soars make above the material [SEP]']
[1350/2000] tot_loss=1.284 (perp=6.017, rec=0.079, cos=0.002), tot_loss_proj:1.866 [t=0.17s]
prediction: ['[CLS] is - - believe its promise of life that soars make above the material [SEP]']
Attempt swap
Moved token
[1400/2000] tot_loss=1.158 (perp=5.338, rec=0.088, cos=0.002), tot_loss_proj:1.656 [t=0.17s]
prediction: ['[CLS] is - - make believe its promise of life that soars above the material [SEP]']
Attempt swap
Moved token
[1450/2000] tot_loss=1.132 (perp=5.248, rec=0.081, cos=0.002), tot_loss_proj:1.542 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
[1500/2000] tot_loss=1.130 (perp=5.248, rec=0.079, cos=0.002), tot_loss_proj:1.543 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
Attempt swap
[1550/2000] tot_loss=1.136 (perp=5.248, rec=0.084, cos=0.002), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
Attempt swap
[1600/2000] tot_loss=1.136 (perp=5.248, rec=0.084, cos=0.002), tot_loss_proj:1.532 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
[1650/2000] tot_loss=1.130 (perp=5.248, rec=0.079, cos=0.002), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
Attempt swap
[1700/2000] tot_loss=1.127 (perp=5.248, rec=0.075, cos=0.002), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
Attempt swap
[1750/2000] tot_loss=1.130 (perp=5.248, rec=0.078, cos=0.002), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
[1800/2000] tot_loss=1.129 (perp=5.248, rec=0.077, cos=0.002), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
Attempt swap
[1850/2000] tot_loss=1.124 (perp=5.248, rec=0.073, cos=0.002), tot_loss_proj:1.531 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
Attempt swap
[1900/2000] tot_loss=1.124 (perp=5.248, rec=0.073, cos=0.002), tot_loss_proj:1.542 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
[1950/2000] tot_loss=1.116 (perp=5.248, rec=0.065, cos=0.002), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
Attempt swap
[2000/2000] tot_loss=1.126 (perp=5.248, rec=0.075, cos=0.002), tot_loss_proj:1.537 [t=0.17s]
prediction: ['[CLS] is - make believe - its promise of life that soars above the material [SEP]']
Done with input #77 of 100.
reference: 
========================
[CLS] is its make - believe promise of life that soars above the material realm [SEP]
========================
predicted: 
========================
[CLS] is - make believe - its promise of life that soars above the material [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 96.552 | p: 100.000 | r: 93.333
rouge2     | fm: 66.667 | p: 69.231 | r: 64.286
rougeL     | fm: 89.655 | p: 92.857 | r: 86.667
rougeLsum  | fm: 89.655 | p: 92.857 | r: 86.667
r1fm+r2fm = 163.218

[Aggregate metrics]:
rouge1     | fm: 89.105 | p: 88.342 | r: 90.002
rouge2     | fm: 53.672 | p: 53.373 | r: 54.043
rougeL     | fm: 76.780 | p: 76.176 | r: 77.562
rougeLsum  | fm: 76.674 | p: 76.102 | r: 77.427
r1fm+r2fm = 142.777

input #77 time: 0:06:59 | total time: 10:42:56


Running input #78 of 100.
reference: 
========================
exit the theater 
========================
average of cosine similarity 0.9992696483604169
highest_index [0]
highest [0.9992696483604169]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[ 101, 6164, 1996, 4258,  102]], device='cuda:0')
Debug: ref = ['[CLS] exit the theater [SEP]']
[Init] best rec loss: 1.9528603553771973 for ['[CLS] final utc quietly [SEP]']
[Init] best rec loss: 1.9048945903778076 for ['[CLS]sten warnertem [SEP]']
[Init] best rec loss: 1.5339909791946411 for ['[CLS] government cleanupser [SEP]']
[Init] best rec loss: 1.3563518524169922 for ['[CLS] le screens grant [SEP]']
[Init] best perm rec loss: 1.354122281074524 for ['[CLS] grant le screens [SEP]']
[Init] best perm rec loss: 1.3496745824813843 for ['[CLS] screens grant le [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=1.981 (perp=8.972, rec=0.177, cos=0.010), tot_loss_proj:2.709 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 100/2000] tot_loss=1.907 (perp=8.972, rec=0.109, cos=0.004), tot_loss_proj:2.712 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 150/2000] tot_loss=1.893 (perp=8.972, rec=0.094, cos=0.005), tot_loss_proj:2.719 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 200/2000] tot_loss=1.887 (perp=8.972, rec=0.088, cos=0.004), tot_loss_proj:2.726 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.886 (perp=8.972, rec=0.087, cos=0.004), tot_loss_proj:2.727 [t=0.17s]
prediction: ['[CLS] exit theater exit [SEP]']
[ 300/2000] tot_loss=2.224 (perp=10.782, rec=0.066, cos=0.002), tot_loss_proj:2.997 [t=0.17s]
prediction: ['[CLS] exit theater the [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.659 (perp=7.958, rec=0.066, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.688 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 450/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.676 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.653 (perp=7.958, rec=0.060, cos=0.001), tot_loss_proj:1.681 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.677 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 600/2000] tot_loss=1.667 (perp=7.958, rec=0.074, cos=0.001), tot_loss_proj:1.671 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.673 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.692 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 750/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.679 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.665 (perp=7.958, rec=0.072, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.647 (perp=7.958, rec=0.054, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[ 900/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.648 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.679 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1000/2000] tot_loss=1.640 (perp=7.958, rec=0.047, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1050/2000] tot_loss=1.661 (perp=7.958, rec=0.068, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1100/2000] tot_loss=1.649 (perp=7.958, rec=0.056, cos=0.001), tot_loss_proj:1.677 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1150/2000] tot_loss=1.658 (perp=7.958, rec=0.065, cos=0.001), tot_loss_proj:1.672 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1200/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1250/2000] tot_loss=1.656 (perp=7.958, rec=0.063, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1300/2000] tot_loss=1.660 (perp=7.958, rec=0.067, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1350/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.678 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1400/2000] tot_loss=1.650 (perp=7.958, rec=0.057, cos=0.001), tot_loss_proj:1.684 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1450/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.682 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1500/2000] tot_loss=1.644 (perp=7.958, rec=0.051, cos=0.001), tot_loss_proj:1.668 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1550/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.675 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1600/2000] tot_loss=1.654 (perp=7.958, rec=0.061, cos=0.001), tot_loss_proj:1.686 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1650/2000] tot_loss=1.649 (perp=7.958, rec=0.055, cos=0.001), tot_loss_proj:1.689 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1700/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1750/2000] tot_loss=1.657 (perp=7.958, rec=0.064, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1800/2000] tot_loss=1.639 (perp=7.958, rec=0.046, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1850/2000] tot_loss=1.662 (perp=7.958, rec=0.069, cos=0.001), tot_loss_proj:1.667 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[1900/2000] tot_loss=1.642 (perp=7.958, rec=0.049, cos=0.001), tot_loss_proj:1.673 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
[1950/2000] tot_loss=1.636 (perp=7.958, rec=0.043, cos=0.001), tot_loss_proj:1.680 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Attempt swap
[2000/2000] tot_loss=1.652 (perp=7.958, rec=0.059, cos=0.001), tot_loss_proj:1.676 [t=0.17s]
prediction: ['[CLS] exit the theater [SEP]']
Done with input #78 of 100.
reference: 
========================
[CLS] exit the theater [SEP]
========================
predicted: 
========================
[CLS] exit the theater [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.271 | p: 88.500 | r: 90.137
rouge2     | fm: 54.326 | p: 54.065 | r: 54.686
rougeL     | fm: 77.044 | p: 76.475 | r: 77.766
rougeLsum  | fm: 77.045 | p: 76.476 | r: 77.785
r1fm+r2fm = 143.597

input #78 time: 0:06:41 | total time: 10:49:38


Running input #79 of 100.
reference: 
========================
is fascinating 
========================
average of cosine similarity 0.9993343381444821
highest_index [0]
highest [0.9993343381444821]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101,  2003, 17160,   102]], device='cuda:0')
Debug: ref = ['[CLS] is fascinating [SEP]']
[Init] best rec loss: 1.9500796794891357 for ['[CLS] snow fake [SEP]']
[Init] best rec loss: 1.7738052606582642 for ['[CLS] registered union [SEP]']
[Init] best rec loss: 1.6991932392120361 for ['[CLS] tapping huge [SEP]']
[Init] best rec loss: 1.544913411140442 for ['[CLS] combined quickly [SEP]']
[Init] best rec loss: 1.2942136526107788 for ['[CLS] texas qualified [SEP]']
[Init] best rec loss: 1.1571640968322754 for ['[CLS] own terrain [SEP]']
[Init] best rec loss: 1.1093544960021973 for ['[CLS] gray should [SEP]']
[Init] best perm rec loss: 1.1035370826721191 for ['[CLS] should gray [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.712 (perp=12.479, rec=0.210, cos=0.006), tot_loss_proj:2.933 [t=0.17s]
prediction: ['[CLS] fascinating gus [SEP]']
[ 100/2000] tot_loss=1.906 (perp=8.695, rec=0.162, cos=0.005), tot_loss_proj:1.956 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 150/2000] tot_loss=2.456 (perp=11.424, rec=0.167, cos=0.004), tot_loss_proj:3.732 [t=0.17s]
prediction: ['[CLS] fascinating noun [SEP]']
[ 200/2000] tot_loss=1.911 (perp=8.695, rec=0.168, cos=0.004), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.880 (perp=8.695, rec=0.137, cos=0.004), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 300/2000] tot_loss=1.877 (perp=8.695, rec=0.134, cos=0.004), tot_loss_proj:1.962 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.891 (perp=8.695, rec=0.148, cos=0.004), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.868 (perp=8.695, rec=0.126, cos=0.003), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 450/2000] tot_loss=1.864 (perp=8.695, rec=0.122, cos=0.003), tot_loss_proj:1.969 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.866 (perp=8.695, rec=0.124, cos=0.003), tot_loss_proj:1.968 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.025 (perp=9.381, rec=0.145, cos=0.004), tot_loss_proj:1.946 [t=0.17s]
prediction: ['[CLS] is fascinating [SEP]']
[ 600/2000] tot_loss=1.995 (perp=9.381, rec=0.116, cos=0.003), tot_loss_proj:1.947 [t=0.17s]
prediction: ['[CLS] is fascinating [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.863 (perp=8.695, rec=0.121, cos=0.003), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.858 (perp=8.695, rec=0.116, cos=0.003), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 750/2000] tot_loss=1.859 (perp=8.695, rec=0.117, cos=0.003), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.853 (perp=8.695, rec=0.111, cos=0.003), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.822 (perp=8.695, rec=0.082, cos=0.002), tot_loss_proj:1.976 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[ 900/2000] tot_loss=1.826 (perp=8.695, rec=0.086, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.807 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1000/2000] tot_loss=1.802 (perp=8.695, rec=0.061, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1050/2000] tot_loss=1.811 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1100/2000] tot_loss=1.814 (perp=8.695, rec=0.074, cos=0.001), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1150/2000] tot_loss=1.798 (perp=8.695, rec=0.058, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1200/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.972 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1250/2000] tot_loss=1.793 (perp=8.695, rec=0.053, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1300/2000] tot_loss=1.806 (perp=8.695, rec=0.066, cos=0.001), tot_loss_proj:1.977 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1350/2000] tot_loss=1.809 (perp=8.695, rec=0.069, cos=0.001), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1400/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.978 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1450/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1500/2000] tot_loss=1.810 (perp=8.695, rec=0.070, cos=0.001), tot_loss_proj:1.970 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1550/2000] tot_loss=1.805 (perp=8.695, rec=0.064, cos=0.001), tot_loss_proj:1.965 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1600/2000] tot_loss=1.805 (perp=8.695, rec=0.065, cos=0.001), tot_loss_proj:1.983 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1650/2000] tot_loss=1.811 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.980 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1700/2000] tot_loss=1.803 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.964 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1750/2000] tot_loss=1.811 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1800/2000] tot_loss=1.813 (perp=8.695, rec=0.073, cos=0.001), tot_loss_proj:1.960 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1850/2000] tot_loss=1.804 (perp=8.695, rec=0.063, cos=0.001), tot_loss_proj:1.967 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[1900/2000] tot_loss=1.803 (perp=8.695, rec=0.062, cos=0.001), tot_loss_proj:1.973 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
[1950/2000] tot_loss=1.798 (perp=8.695, rec=0.057, cos=0.001), tot_loss_proj:1.974 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Attempt swap
[2000/2000] tot_loss=1.811 (perp=8.695, rec=0.071, cos=0.001), tot_loss_proj:1.975 [t=0.17s]
prediction: ['[CLS] fascinating is [SEP]']
Done with input #79 of 100.
reference: 
========================
[CLS] is fascinating [SEP]
========================
predicted: 
========================
[CLS] fascinating is [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 0.000 | p: 0.000 | r: 0.000
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 100.000

[Aggregate metrics]:
rouge1     | fm: 89.354 | p: 88.611 | r: 90.251
rouge2     | fm: 53.342 | p: 53.080 | r: 53.684
rougeL     | fm: 77.131 | p: 76.523 | r: 77.834
rougeLsum  | fm: 76.984 | p: 76.400 | r: 77.695
r1fm+r2fm = 142.696

input #79 time: 0:06:41 | total time: 10:56:19


Running input #80 of 100.
reference: 
========================
wise , wizened 
========================
average of cosine similarity 0.9992812106805644
highest_index [0]
highest [0.9992812106805644]
Debug: ids_shape = 7, pads = [7]
Debug: input ids = tensor([[  101,  7968,  1010, 15536, 10431,  2098,   102]], device='cuda:0')
Debug: ref = ['[CLS] wise, wizened [SEP]']
[Init] best rec loss: 1.8961759805679321 for ['[CLS] born brass promised device stern [SEP]']
[Init] best rec loss: 1.6977639198303223 for ['[CLS]yna snaps california mussolini kicked [SEP]']
[Init] best rec loss: 1.6965769529342651 for ['[CLS] peek yet knees investments trilogy [SEP]']
[Init] best rec loss: 1.6295527219772339 for ['[CLS]ghtlving dried days dressing [SEP]']
[Init] best perm rec loss: 1.626391053199768 for ['[CLS] dressing dayslvingght dried [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.536 (perp=10.968, rec=0.325, cos=0.017), tot_loss_proj:3.589 [t=0.18s]
prediction: ['[CLS] wise abackwynsey! [SEP]']
[ 100/2000] tot_loss=2.400 (perp=11.066, rec=0.183, cos=0.004), tot_loss_proj:3.146 [t=0.20s]
prediction: ['[CLS] wisezen wizenzen [SEP]']
[ 150/2000] tot_loss=1.842 (perp=8.513, rec=0.136, cos=0.003), tot_loss_proj:2.586 [t=0.19s]
prediction: ['[CLS] wisezen wiedzen [SEP]']
[ 200/2000] tot_loss=2.263 (perp=10.745, rec=0.112, cos=0.002), tot_loss_proj:2.977 [t=0.19s]
prediction: ['[CLS] wise wi wiedzen [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.799 (perp=8.574, rec=0.081, cos=0.002), tot_loss_proj:2.083 [t=0.19s]
prediction: ['[CLS] wise wizened wi [SEP]']
[ 300/2000] tot_loss=1.807 (perp=8.574, rec=0.090, cos=0.002), tot_loss_proj:2.080 [t=0.19s]
prediction: ['[CLS] wise wizened wi [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.807 (perp=8.574, rec=0.090, cos=0.002), tot_loss_proj:2.086 [t=0.19s]
prediction: ['[CLS] wise wizened wi [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.796 (perp=8.574, rec=0.080, cos=0.002), tot_loss_proj:2.075 [t=0.19s]
prediction: ['[CLS] wise wizened wi [SEP]']
[ 450/2000] tot_loss=1.800 (perp=8.574, rec=0.084, cos=0.002), tot_loss_proj:2.077 [t=0.20s]
prediction: ['[CLS] wise wizened wi [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.792 (perp=8.574, rec=0.075, cos=0.002), tot_loss_proj:2.077 [t=0.17s]
prediction: ['[CLS] wise wizened wi [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.811 (perp=8.574, rec=0.095, cos=0.002), tot_loss_proj:2.079 [t=0.17s]
prediction: ['[CLS] wise wizened wi [SEP]']
[ 600/2000] tot_loss=1.794 (perp=8.574, rec=0.078, cos=0.002), tot_loss_proj:2.081 [t=0.17s]
prediction: ['[CLS] wise wizened wi [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.859 (perp=8.896, rec=0.078, cos=0.002), tot_loss_proj:2.072 [t=0.17s]
prediction: ['[CLS] wise wizeneded [SEP]']
Attempt swap
Moved token
[ 700/2000] tot_loss=1.671 (perp=7.957, rec=0.078, cos=0.002), tot_loss_proj:2.092 [t=0.17s]
prediction: ['[CLS] wise wiedzened [SEP]']
[ 750/2000] tot_loss=1.668 (perp=7.957, rec=0.075, cos=0.002), tot_loss_proj:2.105 [t=0.17s]
prediction: ['[CLS] wise wiedzened [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.671 (perp=7.957, rec=0.078, cos=0.002), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] wise wiedzened [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.667 (perp=7.957, rec=0.074, cos=0.002), tot_loss_proj:2.095 [t=0.17s]
prediction: ['[CLS] wise wiedzened [SEP]']
[ 900/2000] tot_loss=1.655 (perp=7.957, rec=0.062, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ['[CLS] wise wiedzened [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.667 (perp=7.957, rec=0.074, cos=0.002), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] wise wiedzened [SEP]']
Attempt swap
[1000/2000] tot_loss=1.670 (perp=7.957, rec=0.077, cos=0.002), tot_loss_proj:2.101 [t=0.17s]
prediction: ['[CLS] wise wiedzened [SEP]']
[1050/2000] tot_loss=1.981 (perp=9.561, rec=0.067, cos=0.002), tot_loss_proj:2.478 [t=0.17s]
prediction: ['[CLS] wise wi,zened [SEP]']
Attempt swap
Swapped tokens
[1100/2000] tot_loss=1.396 (perp=6.600, rec=0.074, cos=0.002), tot_loss_proj:1.381 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1150/2000] tot_loss=1.394 (perp=6.600, rec=0.073, cos=0.002), tot_loss_proj:1.391 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
[1200/2000] tot_loss=1.394 (perp=6.600, rec=0.072, cos=0.002), tot_loss_proj:1.392 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1250/2000] tot_loss=1.391 (perp=6.600, rec=0.069, cos=0.002), tot_loss_proj:1.387 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1300/2000] tot_loss=1.399 (perp=6.600, rec=0.077, cos=0.002), tot_loss_proj:1.380 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
[1350/2000] tot_loss=1.380 (perp=6.600, rec=0.058, cos=0.001), tot_loss_proj:1.390 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1400/2000] tot_loss=1.382 (perp=6.600, rec=0.061, cos=0.001), tot_loss_proj:1.381 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1450/2000] tot_loss=1.380 (perp=6.600, rec=0.058, cos=0.001), tot_loss_proj:1.389 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
[1500/2000] tot_loss=1.380 (perp=6.600, rec=0.059, cos=0.001), tot_loss_proj:1.386 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1550/2000] tot_loss=1.384 (perp=6.600, rec=0.062, cos=0.001), tot_loss_proj:1.380 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1600/2000] tot_loss=1.384 (perp=6.600, rec=0.062, cos=0.001), tot_loss_proj:1.380 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
[1650/2000] tot_loss=1.382 (perp=6.600, rec=0.061, cos=0.001), tot_loss_proj:1.390 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1700/2000] tot_loss=1.388 (perp=6.600, rec=0.066, cos=0.001), tot_loss_proj:1.398 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1750/2000] tot_loss=1.381 (perp=6.600, rec=0.060, cos=0.001), tot_loss_proj:1.386 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
[1800/2000] tot_loss=1.385 (perp=6.600, rec=0.063, cos=0.001), tot_loss_proj:1.397 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1850/2000] tot_loss=1.378 (perp=6.600, rec=0.056, cos=0.001), tot_loss_proj:1.389 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[1900/2000] tot_loss=1.374 (perp=6.600, rec=0.053, cos=0.001), tot_loss_proj:1.391 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
[1950/2000] tot_loss=1.374 (perp=6.600, rec=0.052, cos=0.001), tot_loss_proj:1.389 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Attempt swap
[2000/2000] tot_loss=1.384 (perp=6.600, rec=0.062, cos=0.001), tot_loss_proj:1.387 [t=0.17s]
prediction: ['[CLS] wise, wizened [SEP]']
Done with input #80 of 100.
reference: 
========================
[CLS] wise, wizened [SEP]
========================
predicted: 
========================
[CLS] wise, wizened [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.469 | p: 88.782 | r: 90.352
rouge2     | fm: 53.997 | p: 53.725 | r: 54.324
rougeL     | fm: 77.378 | p: 76.819 | r: 78.054
rougeLsum  | fm: 77.318 | p: 76.785 | r: 77.999
r1fm+r2fm = 143.465

input #80 time: 0:06:53 | total time: 11:03:12


Running input #81 of 100.
reference: 
========================
is not the most impressive player 
========================
average of cosine similarity 0.9992879299948307
highest_index [0]
highest [0.9992879299948307]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2003, 2025, 1996, 2087, 8052, 2447,  102]], device='cuda:0')
Debug: ref = ['[CLS] is not the most impressive player [SEP]']
[Init] best rec loss: 1.8443113565444946 for ['[CLS] across side mao township true team [SEP]']
[Init] best rec loss: 1.8287549018859863 for ['[CLS] : heading crush [CLS] possess grand [SEP]']
[Init] best rec loss: 1.5750724077224731 for ['[CLS]oge blocking approaching louie ind eat [SEP]']
[Init] best rec loss: 1.536523699760437 for ['[CLS] anybodyattings general assent framed [SEP]']
[Init] best rec loss: 1.4952508211135864 for ['[CLS] anti quartet dark tavi whom 2000 [SEP]']
[Init] best rec loss: 1.3897989988327026 for ['[CLS] luke roles collectivelid ri treating [SEP]']
[Init] best rec loss: 1.3871291875839233 for ['[CLS] mass seeneer off joe đ [SEP]']
[Init] best rec loss: 1.3777071237564087 for ['[CLS]itating threads modelled approval bands missing [SEP]']
[Init] best rec loss: 1.3360694646835327 for ['[CLS] continued if elementary anywhere boundaries supply [SEP]']
[Init] best rec loss: 1.2880840301513672 for ['[CLS] wrap treaty earlier serial dashboard discover [SEP]']
[Init] best rec loss: 1.2849894762039185 for ['[CLS]down donaldsonvik ivyplate proceeded [SEP]']
[Init] best perm rec loss: 1.2837177515029907 for ['[CLS] donaldson ivydownvikplate proceeded [SEP]']
[Init] best perm rec loss: 1.282072901725769 for ['[CLS]downplate donaldson proceeded ivyvik [SEP]']
[Init] best perm rec loss: 1.28199303150177 for ['[CLS]vik proceeded donaldson ivydownplate [SEP]']
[Init] best perm rec loss: 1.278752326965332 for ['[CLS] donaldson ivydown proceededplatevik [SEP]']
[Init] best perm rec loss: 1.2762550115585327 for ['[CLS] donaldsondownvik proceeded ivyplate [SEP]']
[Init] best perm rec loss: 1.2757786512374878 for ['[CLS] donaldson proceededdownplate ivyvik [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.874 (perp=12.255, rec=0.368, cos=0.055), tot_loss_proj:3.968 [t=0.17s]
prediction: ['[CLS] never biological impressive usually da senior [SEP]']
[ 100/2000] tot_loss=1.946 (perp=8.394, rec=0.244, cos=0.024), tot_loss_proj:2.482 [t=0.17s]
prediction: ['[CLS] not most impressive not several player [SEP]']
[ 150/2000] tot_loss=1.803 (perp=8.002, rec=0.191, cos=0.011), tot_loss_proj:2.373 [t=0.17s]
prediction: ['[CLS] not most impressive not the player [SEP]']
[ 200/2000] tot_loss=1.916 (perp=8.703, rec=0.165, cos=0.010), tot_loss_proj:2.476 [t=0.17s]
prediction: ['[CLS] not most impressive is most player [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.871 (perp=8.703, rec=0.126, cos=0.004), tot_loss_proj:2.481 [t=0.17s]
prediction: ['[CLS] not most impressive is most player [SEP]']
[ 300/2000] tot_loss=1.853 (perp=8.703, rec=0.108, cos=0.004), tot_loss_proj:2.488 [t=0.17s]
prediction: ['[CLS] not most impressive is most player [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.738 (perp=8.136, rec=0.107, cos=0.004), tot_loss_proj:2.719 [t=0.17s]
prediction: ['[CLS] not most impressive player is most [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.641 (perp=7.654, rec=0.105, cos=0.006), tot_loss_proj:3.245 [t=0.17s]
prediction: ['[CLS] not most player is most impressive [SEP]']
[ 450/2000] tot_loss=1.636 (perp=7.654, rec=0.101, cos=0.004), tot_loss_proj:3.257 [t=0.17s]
prediction: ['[CLS] not most player is most impressive [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.572 (perp=7.342, rec=0.100, cos=0.004), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.571 (perp=7.342, rec=0.098, cos=0.004), tot_loss_proj:3.248 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[ 600/2000] tot_loss=1.563 (perp=7.342, rec=0.090, cos=0.004), tot_loss_proj:3.251 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.566 (perp=7.342, rec=0.093, cos=0.005), tot_loss_proj:3.251 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.569 (perp=7.342, rec=0.096, cos=0.005), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[ 750/2000] tot_loss=1.562 (perp=7.342, rec=0.089, cos=0.005), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.575 (perp=7.342, rec=0.102, cos=0.005), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.556 (perp=7.342, rec=0.083, cos=0.005), tot_loss_proj:3.243 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[ 900/2000] tot_loss=1.571 (perp=7.342, rec=0.098, cos=0.005), tot_loss_proj:3.250 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.565 (perp=7.342, rec=0.092, cos=0.005), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.554 (perp=7.342, rec=0.081, cos=0.005), tot_loss_proj:3.254 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[1050/2000] tot_loss=1.557 (perp=7.342, rec=0.084, cos=0.005), tot_loss_proj:3.250 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.570 (perp=7.342, rec=0.097, cos=0.005), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.549 (perp=7.342, rec=0.076, cos=0.005), tot_loss_proj:3.250 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[1200/2000] tot_loss=1.566 (perp=7.342, rec=0.094, cos=0.005), tot_loss_proj:3.256 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.550 (perp=7.342, rec=0.077, cos=0.005), tot_loss_proj:3.253 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.563 (perp=7.342, rec=0.090, cos=0.005), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[1350/2000] tot_loss=1.548 (perp=7.342, rec=0.076, cos=0.005), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.556 (perp=7.342, rec=0.083, cos=0.005), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.556 (perp=7.342, rec=0.083, cos=0.005), tot_loss_proj:3.246 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[1500/2000] tot_loss=1.570 (perp=7.342, rec=0.097, cos=0.005), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.563 (perp=7.342, rec=0.090, cos=0.005), tot_loss_proj:3.248 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.563 (perp=7.342, rec=0.090, cos=0.005), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[1650/2000] tot_loss=1.550 (perp=7.342, rec=0.078, cos=0.005), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.565 (perp=7.342, rec=0.092, cos=0.005), tot_loss_proj:3.250 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.557 (perp=7.342, rec=0.084, cos=0.005), tot_loss_proj:3.250 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[1800/2000] tot_loss=1.570 (perp=7.342, rec=0.097, cos=0.005), tot_loss_proj:3.253 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.563 (perp=7.342, rec=0.090, cos=0.005), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.558 (perp=7.342, rec=0.085, cos=0.005), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
[1950/2000] tot_loss=1.557 (perp=7.342, rec=0.084, cos=0.005), tot_loss_proj:3.247 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.566 (perp=7.342, rec=0.093, cos=0.005), tot_loss_proj:3.252 [t=0.17s]
prediction: ['[CLS] most not player is most impressive [SEP]']
Done with input #81 of 100.
reference: 
========================
[CLS] is not the most impressive player [SEP]
========================
predicted: 
========================
[CLS] most not player is most impressive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 87.500 | p: 87.500 | r: 87.500
rouge2     | fm: 14.286 | p: 14.286 | r: 14.286
rougeL     | fm: 62.500 | p: 62.500 | r: 62.500
rougeLsum  | fm: 62.500 | p: 62.500 | r: 62.500
r1fm+r2fm = 101.786

[Aggregate metrics]:
rouge1     | fm: 89.492 | p: 88.762 | r: 90.343
rouge2     | fm: 53.692 | p: 53.436 | r: 54.004
rougeL     | fm: 77.210 | p: 76.685 | r: 77.860
rougeLsum  | fm: 77.195 | p: 76.642 | r: 77.849
r1fm+r2fm = 143.184

input #81 time: 0:06:42 | total time: 11:09:55


Running input #82 of 100.
reference: 
========================
it 's undone by a sloppy script 
========================
average of cosine similarity 0.9992801011451229
highest_index [0]
highest [0.9992801011451229]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101,  2009,  1005,  1055, 25757,  2011,  1037, 28810,  5896,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] it's undone by a sloppy script [SEP]"]
[Init] best rec loss: 1.9474414587020874 for ['[CLS]ny lived oro munster iceland or statue couple [SEP]']
[Init] best rec loss: 1.835921287536621 for ['[CLS] erale nese titsisen drive agency [SEP]']
[Init] best rec loss: 1.7372323274612427 for ['[CLS] ecclesiastical novel pre £ moi data push fran [SEP]']
[Init] best rec loss: 1.6888108253479004 for ['[CLS] maltaierif ace players reserve hmm rpm [SEP]']
[Init] best rec loss: 1.6774872541427612 for ['[CLS] cabinet currently manyis domestic practice eventually applications [SEP]']
[Init] best rec loss: 1.4888206720352173 for ['[CLS] crossing pei zurich type tremble pal work day [SEP]']
[Init] best rec loss: 1.3586682081222534 for ['[CLS]ach plumage respective recordbasket whoever rolefur [SEP]']
[Init] best perm rec loss: 1.3419948816299438 for ['[CLS]furbasket respective roleach whoever record plumage [SEP]']
[Init] best perm rec loss: 1.3394792079925537 for ['[CLS]basket respective whoever role plumagefurach record [SEP]']
[Init] best perm rec loss: 1.3392287492752075 for ['[CLS]achbasket record role respectivefur plumage whoever [SEP]']
[Init] best perm rec loss: 1.3361918926239014 for ['[CLS]basket record whoever rolefur respectiveach plumage [SEP]']
[Init] best perm rec loss: 1.3317865133285522 for ['[CLS]basketfur whoever respective role plumage recordach [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.476 (perp=11.108, rec=0.245, cos=0.009), tot_loss_proj:2.982 [t=0.17s]
prediction: ['[CLS] undone undone by are by oil script undone [SEP]']
[ 100/2000] tot_loss=2.253 (perp=10.647, rec=0.120, cos=0.004), tot_loss_proj:2.812 [t=0.17s]
prediction: ['[CLS] undone undone a s by sloppy script undone [SEP]']
[ 150/2000] tot_loss=2.015 (perp=9.641, rec=0.085, cos=0.003), tot_loss_proj:2.514 [t=0.17s]
prediction: ['[CLS] undone it a s by sloppy script undone [SEP]']
[ 200/2000] tot_loss=2.007 (perp=9.641, rec=0.076, cos=0.002), tot_loss_proj:2.515 [t=0.17s]
prediction: ['[CLS] undone it a s by sloppy script undone [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.836 (perp=8.817, rec=0.071, cos=0.002), tot_loss_proj:2.115 [t=0.17s]
prediction: ['[CLS] it a s undone by sloppy script undone [SEP]']
[ 300/2000] tot_loss=1.834 (perp=8.817, rec=0.068, cos=0.002), tot_loss_proj:2.112 [t=0.17s]
prediction: ['[CLS] it a s undone by sloppy script undone [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.643 (perp=7.875, rec=0.066, cos=0.002), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.649 (perp=7.875, rec=0.072, cos=0.002), tot_loss_proj:1.859 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[ 450/2000] tot_loss=1.637 (perp=7.875, rec=0.060, cos=0.002), tot_loss_proj:1.855 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.646 (perp=7.875, rec=0.069, cos=0.002), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.638 (perp=7.875, rec=0.061, cos=0.002), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[ 600/2000] tot_loss=1.640 (perp=7.875, rec=0.064, cos=0.002), tot_loss_proj:1.857 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.642 (perp=7.875, rec=0.066, cos=0.002), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.639 (perp=7.875, rec=0.063, cos=0.002), tot_loss_proj:1.846 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[ 750/2000] tot_loss=1.644 (perp=7.875, rec=0.068, cos=0.002), tot_loss_proj:1.850 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.649 (perp=7.875, rec=0.072, cos=0.002), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.641 (perp=7.875, rec=0.064, cos=0.002), tot_loss_proj:1.844 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[ 900/2000] tot_loss=1.638 (perp=7.875, rec=0.061, cos=0.002), tot_loss_proj:1.848 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.633 (perp=7.875, rec=0.056, cos=0.002), tot_loss_proj:1.839 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1000/2000] tot_loss=1.639 (perp=7.875, rec=0.062, cos=0.002), tot_loss_proj:1.839 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[1050/2000] tot_loss=1.646 (perp=7.875, rec=0.070, cos=0.002), tot_loss_proj:1.844 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1100/2000] tot_loss=1.652 (perp=7.875, rec=0.075, cos=0.002), tot_loss_proj:1.838 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1150/2000] tot_loss=1.650 (perp=7.875, rec=0.073, cos=0.002), tot_loss_proj:1.846 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[1200/2000] tot_loss=1.660 (perp=7.875, rec=0.083, cos=0.002), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1250/2000] tot_loss=1.634 (perp=7.875, rec=0.057, cos=0.002), tot_loss_proj:1.839 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1300/2000] tot_loss=1.640 (perp=7.875, rec=0.064, cos=0.002), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[1350/2000] tot_loss=1.638 (perp=7.875, rec=0.062, cos=0.002), tot_loss_proj:1.842 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1400/2000] tot_loss=1.639 (perp=7.875, rec=0.063, cos=0.002), tot_loss_proj:1.843 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1450/2000] tot_loss=1.649 (perp=7.875, rec=0.072, cos=0.002), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[1500/2000] tot_loss=1.649 (perp=7.875, rec=0.072, cos=0.002), tot_loss_proj:1.839 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1550/2000] tot_loss=1.644 (perp=7.875, rec=0.068, cos=0.002), tot_loss_proj:1.834 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1600/2000] tot_loss=1.644 (perp=7.875, rec=0.067, cos=0.002), tot_loss_proj:1.844 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[1650/2000] tot_loss=1.644 (perp=7.875, rec=0.068, cos=0.002), tot_loss_proj:1.833 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1700/2000] tot_loss=1.635 (perp=7.875, rec=0.059, cos=0.002), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1750/2000] tot_loss=1.647 (perp=7.875, rec=0.070, cos=0.002), tot_loss_proj:1.849 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[1800/2000] tot_loss=1.640 (perp=7.875, rec=0.063, cos=0.002), tot_loss_proj:1.837 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1850/2000] tot_loss=1.648 (perp=7.875, rec=0.072, cos=0.002), tot_loss_proj:1.841 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[1900/2000] tot_loss=1.648 (perp=7.875, rec=0.071, cos=0.002), tot_loss_proj:1.836 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
[1950/2000] tot_loss=1.640 (perp=7.875, rec=0.063, cos=0.002), tot_loss_proj:1.847 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Attempt swap
[2000/2000] tot_loss=1.648 (perp=7.875, rec=0.071, cos=0.002), tot_loss_proj:1.843 [t=0.17s]
prediction: ['[CLS] it s undone by a sloppy script undone [SEP]']
Done with input #82 of 100.
reference: 
========================
[CLS] it's undone by a sloppy script [SEP]
========================
predicted: 
========================
[CLS] it s undone by a sloppy script undone [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.737 | p: 90.000 | r: 100.000
rouge2     | fm: 82.353 | p: 77.778 | r: 87.500
rougeL     | fm: 94.737 | p: 90.000 | r: 100.000
rougeLsum  | fm: 94.737 | p: 90.000 | r: 100.000
r1fm+r2fm = 177.090

[Aggregate metrics]:
rouge1     | fm: 89.580 | p: 88.794 | r: 90.471
rouge2     | fm: 54.066 | p: 53.762 | r: 54.411
rougeL     | fm: 77.421 | p: 76.720 | r: 78.224
rougeLsum  | fm: 77.377 | p: 76.711 | r: 78.092
r1fm+r2fm = 143.646

input #82 time: 0:06:44 | total time: 11:16:40


Running input #83 of 100.
reference: 
========================
know what it wants to be when it grows up 
========================
average of cosine similarity 0.9992427003793516
highest_index [0]
highest [0.9992427003793516]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 2113, 2054, 2009, 4122, 2000, 2022, 2043, 2009, 7502, 2039,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] know what it wants to be when it grows up [SEP]']
[Init] best rec loss: 1.8980540037155151 for ['[CLS] management international cylinder shipping spider saying develin lecture victory [SEP]']
[Init] best rec loss: 1.8680791854858398 for ['[CLS] notwithstanding renamed jane 15 sweeping ram hitting promised witnessinda [SEP]']
[Init] best rec loss: 1.8268553018569946 for ['[CLS] expressing congratulations butch evacuate copyright grenadasome snow paid confidence [SEP]']
[Init] best rec loss: 1.7807674407958984 for ['[CLS] firm from eager ever heavier positions mc depending much those [SEP]']
[Init] best rec loss: 1.6598609685897827 for ['[CLS] ba there considersier capacity kat chances brewer guarddating [SEP]']
[Init] best rec loss: 1.5194369554519653 for ['[CLS] £ mercy already benji someone publishing use hit wild runaway [SEP]']
[Init] best perm rec loss: 1.515126347541809 for ['[CLS] hit already use £ benji runaway mercy wild publishing someone [SEP]']
[Init] best perm rec loss: 1.506394386291504 for ['[CLS] already £ publishing use hit mercy someone wild benji runaway [SEP]']
[Init] best perm rec loss: 1.5047065019607544 for ['[CLS] hit £ already publishing use mercy someone runaway wild benji [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.378 (perp=10.178, rec=0.314, cos=0.028), tot_loss_proj:3.787 [t=0.17s]
prediction: ['[CLS] know what withinович be some someone anymore when someday [SEP]']
[ 100/2000] tot_loss=2.032 (perp=9.039, rec=0.214, cos=0.010), tot_loss_proj:2.807 [t=0.17s]
prediction: ['[CLS] know what it growsy some wants grows when up [SEP]']
[ 150/2000] tot_loss=2.260 (perp=10.428, rec=0.169, cos=0.006), tot_loss_proj:3.269 [t=0.17s]
prediction: ['[CLS] know what it grows wade some wants grows when grows [SEP]']
[ 200/2000] tot_loss=2.008 (perp=9.467, rec=0.111, cos=0.003), tot_loss_proj:2.940 [t=0.17s]
prediction: ['[CLS] know what it grows wade could wants be when up [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.758 (perp=8.325, rec=0.091, cos=0.003), tot_loss_proj:2.993 [t=0.17s]
prediction: ['[CLS] know what it grows up some wants be whenky [SEP]']
[ 300/2000] tot_loss=1.630 (perp=7.745, rec=0.079, cos=0.002), tot_loss_proj:2.503 [t=0.17s]
prediction: ['[CLS] know what it grows up for wants be whenky [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.608 (perp=7.673, rec=0.071, cos=0.002), tot_loss_proj:1.943 [t=0.17s]
prediction: ['[CLS] know what it grows up to wants be when nicholas [SEP]']
Attempt swap
Moved token
[ 400/2000] tot_loss=1.393 (perp=6.588, rec=0.074, cos=0.002), tot_loss_proj:1.735 [t=0.17s]
prediction: ['[CLS] know what it wants grows up to be when nicholas [SEP]']
[ 450/2000] tot_loss=1.282 (perp=6.030, rec=0.074, cos=0.002), tot_loss_proj:1.629 [t=0.17s]
prediction: ['[CLS] know what it wants grows up to be when it [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=1.504 (perp=7.099, rec=0.082, cos=0.002), tot_loss_proj:1.985 [t=0.17s]
prediction: ['[CLS] know what it wants up to be when explained grows [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.146 (perp=5.343, rec=0.075, cos=0.002), tot_loss_proj:1.302 [t=0.17s]
prediction: ['[CLS] know what it wants up to be when it grows [SEP]']
[ 600/2000] tot_loss=1.144 (perp=5.343, rec=0.074, cos=0.002), tot_loss_proj:1.303 [t=0.17s]
prediction: ['[CLS] know what it wants up to be when it grows [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.143 (perp=5.343, rec=0.072, cos=0.002), tot_loss_proj:1.305 [t=0.17s]
prediction: ['[CLS] know what it wants up to be when it grows [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.151 (perp=5.343, rec=0.080, cos=0.002), tot_loss_proj:1.304 [t=0.17s]
prediction: ['[CLS] know what it wants up to be when it grows [SEP]']
[ 750/2000] tot_loss=1.142 (perp=5.343, rec=0.072, cos=0.002), tot_loss_proj:1.314 [t=0.17s]
prediction: ['[CLS] know what it wants up to be when it grows [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.218 (perp=5.665, rec=0.083, cos=0.002), tot_loss_proj:1.424 [t=0.17s]
prediction: ['[CLS] know what it wants to be when to grows up [SEP]']
Attempt swap
Moved token
[ 850/2000] tot_loss=1.114 (perp=5.144, rec=0.083, cos=0.002), tot_loss_proj:1.364 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
[ 900/2000] tot_loss=1.104 (perp=5.144, rec=0.073, cos=0.002), tot_loss_proj:1.364 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.110 (perp=5.144, rec=0.080, cos=0.002), tot_loss_proj:1.365 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1000/2000] tot_loss=1.115 (perp=5.144, rec=0.085, cos=0.002), tot_loss_proj:1.369 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
[1050/2000] tot_loss=1.101 (perp=5.144, rec=0.070, cos=0.002), tot_loss_proj:1.361 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1100/2000] tot_loss=1.106 (perp=5.144, rec=0.075, cos=0.002), tot_loss_proj:1.364 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1150/2000] tot_loss=1.100 (perp=5.144, rec=0.069, cos=0.002), tot_loss_proj:1.365 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
[1200/2000] tot_loss=1.106 (perp=5.144, rec=0.075, cos=0.002), tot_loss_proj:1.365 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1250/2000] tot_loss=1.102 (perp=5.144, rec=0.071, cos=0.002), tot_loss_proj:1.373 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1300/2000] tot_loss=1.108 (perp=5.144, rec=0.077, cos=0.002), tot_loss_proj:1.372 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
[1350/2000] tot_loss=1.101 (perp=5.144, rec=0.070, cos=0.002), tot_loss_proj:1.360 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1400/2000] tot_loss=1.104 (perp=5.144, rec=0.073, cos=0.002), tot_loss_proj:1.363 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1450/2000] tot_loss=1.103 (perp=5.144, rec=0.072, cos=0.002), tot_loss_proj:1.361 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
[1500/2000] tot_loss=1.113 (perp=5.144, rec=0.082, cos=0.002), tot_loss_proj:1.373 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1550/2000] tot_loss=1.096 (perp=5.144, rec=0.065, cos=0.002), tot_loss_proj:1.369 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1600/2000] tot_loss=1.101 (perp=5.144, rec=0.070, cos=0.002), tot_loss_proj:1.368 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
[1650/2000] tot_loss=1.107 (perp=5.144, rec=0.076, cos=0.002), tot_loss_proj:1.364 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1700/2000] tot_loss=1.099 (perp=5.144, rec=0.068, cos=0.002), tot_loss_proj:1.375 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1750/2000] tot_loss=1.104 (perp=5.144, rec=0.073, cos=0.002), tot_loss_proj:1.371 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
[1800/2000] tot_loss=1.101 (perp=5.144, rec=0.071, cos=0.002), tot_loss_proj:1.364 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1850/2000] tot_loss=1.111 (perp=5.144, rec=0.081, cos=0.002), tot_loss_proj:1.370 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[1900/2000] tot_loss=1.093 (perp=5.144, rec=0.063, cos=0.002), tot_loss_proj:1.372 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
[1950/2000] tot_loss=1.102 (perp=5.144, rec=0.072, cos=0.002), tot_loss_proj:1.366 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Attempt swap
[2000/2000] tot_loss=1.100 (perp=5.144, rec=0.069, cos=0.002), tot_loss_proj:1.372 [t=0.17s]
prediction: ['[CLS] to know what it wants to be when grows up [SEP]']
Done with input #83 of 100.
reference: 
========================
[CLS] know what it wants to be when it grows up [SEP]
========================
predicted: 
========================
[CLS] to know what it wants to be when grows up [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 91.667 | p: 91.667 | r: 91.667
rouge2     | fm: 72.727 | p: 72.727 | r: 72.727
rougeL     | fm: 91.667 | p: 91.667 | r: 91.667
rougeLsum  | fm: 91.667 | p: 91.667 | r: 91.667
r1fm+r2fm = 164.394

[Aggregate metrics]:
rouge1     | fm: 89.528 | p: 88.783 | r: 90.444
rouge2     | fm: 54.261 | p: 53.929 | r: 54.653
rougeL     | fm: 77.641 | p: 77.022 | r: 78.385
rougeLsum  | fm: 77.535 | p: 76.897 | r: 78.251
r1fm+r2fm = 143.789

input #83 time: 0:06:41 | total time: 11:23:21


Running input #84 of 100.
reference: 
========================
people have lost the ability to think 
========================
average of cosine similarity 0.9991125724774641
highest_index [0]
highest [0.9991125724774641]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 2111, 2031, 2439, 1996, 3754, 2000, 2228,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] people have lost the ability to think [SEP]']
[Init] best rec loss: 1.8125368356704712 for ['[CLS] contractor trunks are kangaroo uncomfortable shelly manny [SEP]']
[Init] best rec loss: 1.8119263648986816 for ['[CLS]u ideaille flushed mywith lead [SEP]']
[Init] best rec loss: 1.7110885381698608 for ['[CLS] waterfalls answer ramsay proved broad losing amenities [SEP]']
[Init] best rec loss: 1.5840494632720947 for ['[CLS] common where quantum crack fellows good alexander [SEP]']
[Init] best rec loss: 1.5825172662734985 for ['[CLS] over plug indeed middle then [SEP] dead [SEP]']
[Init] best rec loss: 1.5593494176864624 for ['[CLS] gmina standingply italian sessionhelm towards [SEP]']
[Init] best rec loss: 1.5217680931091309 for ['[CLS] gene qualifying call guinea bowling branch announces [SEP]']
[Init] best rec loss: 1.477038025856018 for ['[CLS] outside addressedrip thatarthyna companion [SEP]']
[Init] best rec loss: 1.4265689849853516 for ['[CLS] dark project sar isness block whether [SEP]']
[Init] best rec loss: 1.3894094228744507 for ['[CLS] infinite each ca causediter going its [SEP]']
[Init] best rec loss: 1.3838614225387573 for ['[CLS] tradition captaindock seats [SEP] easier seas [SEP]']
[Init] best perm rec loss: 1.3745696544647217 for ['[CLS]dock tradition seas [SEP] seats captain easier [SEP]']
[Init] best perm rec loss: 1.3726637363433838 for ['[CLS]dock easier tradition captain seats [SEP] seas [SEP]']
[Init] best perm rec loss: 1.3407255411148071 for ['[CLS]dock seas captain tradition [SEP] easier seats [SEP]']
[Init] best perm rec loss: 1.3394502401351929 for ['[CLS]dock [SEP] captain easier seas tradition seats [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.324 (perp=10.321, rec=0.245, cos=0.015), tot_loss_proj:3.127 [t=0.18s]
prediction: ['[CLS] people remember organization lost ability ability lost [SEP]']
[ 100/2000] tot_loss=1.974 (perp=9.126, rec=0.140, cos=0.008), tot_loss_proj:3.116 [t=0.17s]
prediction: ['[CLS] people have think the ability think lost [SEP]']
[ 150/2000] tot_loss=1.809 (perp=8.340, rec=0.130, cos=0.011), tot_loss_proj:2.392 [t=0.17s]
prediction: ['[CLS] people have think the ability have lost [SEP]']
[ 200/2000] tot_loss=1.770 (perp=8.340, rec=0.096, cos=0.006), tot_loss_proj:2.386 [t=0.17s]
prediction: ['[CLS] people have think the ability have lost [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.640 (perp=7.622, rec=0.110, cos=0.005), tot_loss_proj:2.458 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 300/2000] tot_loss=1.614 (perp=7.622, rec=0.087, cos=0.003), tot_loss_proj:2.465 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.602 (perp=7.622, rec=0.076, cos=0.002), tot_loss_proj:2.468 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.596 (perp=7.622, rec=0.070, cos=0.002), tot_loss_proj:2.470 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 450/2000] tot_loss=1.594 (perp=7.622, rec=0.068, cos=0.002), tot_loss_proj:2.469 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.603 (perp=7.622, rec=0.076, cos=0.002), tot_loss_proj:2.457 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.604 (perp=7.622, rec=0.078, cos=0.002), tot_loss_proj:2.460 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 600/2000] tot_loss=1.596 (perp=7.622, rec=0.070, cos=0.002), tot_loss_proj:2.455 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.599 (perp=7.622, rec=0.072, cos=0.002), tot_loss_proj:2.460 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.600 (perp=7.622, rec=0.074, cos=0.002), tot_loss_proj:2.449 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 750/2000] tot_loss=1.590 (perp=7.622, rec=0.064, cos=0.002), tot_loss_proj:2.450 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.604 (perp=7.622, rec=0.078, cos=0.002), tot_loss_proj:2.448 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.596 (perp=7.622, rec=0.070, cos=0.002), tot_loss_proj:2.452 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[ 900/2000] tot_loss=1.594 (perp=7.622, rec=0.068, cos=0.002), tot_loss_proj:2.454 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.592 (perp=7.622, rec=0.066, cos=0.002), tot_loss_proj:2.449 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
Attempt swap
[1000/2000] tot_loss=1.605 (perp=7.622, rec=0.079, cos=0.002), tot_loss_proj:2.444 [t=0.17s]
prediction: ['[CLS] people think have the ability have lost [SEP]']
[1050/2000] tot_loss=1.648 (perp=7.911, rec=0.064, cos=0.002), tot_loss_proj:2.694 [t=0.17s]
prediction: ['[CLS] people think to the ability have lost [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.362 (perp=6.501, rec=0.060, cos=0.002), tot_loss_proj:2.126 [t=0.17s]
prediction: ['[CLS] people think the ability to have lost [SEP]']
Attempt swap
Moved sequence
[1150/2000] tot_loss=1.294 (perp=6.098, rec=0.073, cos=0.002), tot_loss_proj:1.895 [t=0.17s]
prediction: ['[CLS] people think have lost the ability to [SEP]']
[1200/2000] tot_loss=1.288 (perp=6.098, rec=0.067, cos=0.002), tot_loss_proj:1.894 [t=0.17s]
prediction: ['[CLS] people think have lost the ability to [SEP]']
Attempt swap
Moved sequence
[1250/2000] tot_loss=1.006 (perp=4.681, rec=0.068, cos=0.002), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1300/2000] tot_loss=1.003 (perp=4.681, rec=0.065, cos=0.002), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1350/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.053 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1400/2000] tot_loss=0.998 (perp=4.681, rec=0.060, cos=0.002), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1450/2000] tot_loss=1.000 (perp=4.681, rec=0.062, cos=0.002), tot_loss_proj:1.066 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1500/2000] tot_loss=1.001 (perp=4.681, rec=0.063, cos=0.002), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1550/2000] tot_loss=1.006 (perp=4.681, rec=0.068, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1600/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1650/2000] tot_loss=1.005 (perp=4.681, rec=0.067, cos=0.002), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1700/2000] tot_loss=1.002 (perp=4.681, rec=0.064, cos=0.002), tot_loss_proj:1.070 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1750/2000] tot_loss=1.010 (perp=4.681, rec=0.072, cos=0.002), tot_loss_proj:1.062 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1800/2000] tot_loss=0.993 (perp=4.681, rec=0.055, cos=0.002), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1850/2000] tot_loss=1.009 (perp=4.681, rec=0.071, cos=0.002), tot_loss_proj:1.062 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[1900/2000] tot_loss=1.004 (perp=4.681, rec=0.066, cos=0.002), tot_loss_proj:1.068 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
[1950/2000] tot_loss=0.995 (perp=4.681, rec=0.057, cos=0.002), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Attempt swap
[2000/2000] tot_loss=0.997 (perp=4.681, rec=0.059, cos=0.002), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] people have lost the ability to think [SEP]']
Done with input #84 of 100.
reference: 
========================
[CLS] people have lost the ability to think [SEP]
========================
predicted: 
========================
[CLS] people have lost the ability to think [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.700 | p: 88.954 | r: 90.597
rouge2     | fm: 54.786 | p: 54.491 | r: 55.164
rougeL     | fm: 77.925 | p: 77.302 | r: 78.619
rougeLsum  | fm: 77.843 | p: 77.266 | r: 78.573
r1fm+r2fm = 144.485

input #84 time: 0:06:45 | total time: 11:30:07


Running input #85 of 100.
reference: 
========================
unfortunately , it 's also not very good . 
========================
average of cosine similarity 0.9992374406339235
highest_index [0]
highest [0.9992374406339235]
Debug: ids_shape = 12, pads = [12]
Debug: input ids = tensor([[ 101, 6854, 1010, 2009, 1005, 1055, 2036, 2025, 2200, 2204, 1012,  102]],
       device='cuda:0')
Debug: ref = ["[CLS] unfortunately, it's also not very good. [SEP]"]
[Init] best rec loss: 1.9611685276031494 for ['[CLS] residents trade east not into los whatever spencer murphy veracruz [SEP]']
[Init] best rec loss: 1.8875846862792969 for ['[CLS] sent okay too deep partition secrecy consolidated true shouldn our [SEP]']
[Init] best rec loss: 1.7836694717407227 for ['[CLS] avoiding broadcast improved tuned plenty chancellor pet won littleros [SEP]']
[Init] best rec loss: 1.7814399003982544 for ['[CLS] brakeship and acronym senate developing technical leadrine reserve [SEP]']
[Init] best rec loss: 1.7765181064605713 for ['[CLS] mt running waiting worried roverstakesley rating rag age [SEP]']
[Init] best rec loss: 1.6346447467803955 for ['[CLS] marginaltone morning it 9 endowment week [MASK] battalion existing [SEP]']
[Init] best rec loss: 1.5155413150787354 for ['[CLS] thinks macau stand cam form halolic venture cannot vehicle [SEP]']
[Init] best rec loss: 1.44791841506958 for ['[CLS] defender fallenrman roadlein indies indian laps backgroundthing [SEP]']
[Init] best rec loss: 1.3985786437988281 for ['[CLS] young graf challenging haven nord overly graduation blank dad josephine [SEP]']
[Init] best perm rec loss: 1.3900498151779175 for ['[CLS] challenging graf josephine dad haven graduation young overly nord blank [SEP]']
[Init] best perm rec loss: 1.3897099494934082 for ['[CLS] young josephine overly dad graduation challenging blank haven nord graf [SEP]']
[Init] best perm rec loss: 1.3883607387542725 for ['[CLS] young graf josephine nord haven challenging dad overly blank graduation [SEP]']
[Init] best perm rec loss: 1.3878798484802246 for ['[CLS] young graf nord graduation josephine blank dad overly challenging haven [SEP]']
[Init] best perm rec loss: 1.387863039970398 for ['[CLS] blank haven josephine young dad graf nord overly graduation challenging [SEP]']
[Init] best perm rec loss: 1.3863424062728882 for ['[CLS] graduation haven nord josephine dad young challenging overly graf blank [SEP]']
[Init] best perm rec loss: 1.3851666450500488 for ['[CLS] young graf challenging nord graduation overly haven josephine dad blank [SEP]']
[Init] best perm rec loss: 1.384523630142212 for ['[CLS] young blank josephine nord graduation dad challenging overly graf haven [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.367 (perp=10.239, rec=0.300, cos=0.020), tot_loss_proj:3.487 [t=0.17s]
prediction: ['[CLS] unfortunately not unfortunately unfortunately unfortunately s good not unfortunately unfortunately [SEP]']
[ 100/2000] tot_loss=1.922 (perp=8.733, rec=0.168, cos=0.007), tot_loss_proj:2.449 [t=0.17s]
prediction: ['[CLS] unfortunately not also unfortunately not s good not good good [SEP]']
[ 150/2000] tot_loss=1.592 (perp=7.329, rec=0.121, cos=0.005), tot_loss_proj:2.866 [t=0.17s]
prediction: ['[CLS] unfortunately not also, not very good also good good [SEP]']
[ 200/2000] tot_loss=1.684 (perp=7.967, rec=0.086, cos=0.004), tot_loss_proj:3.091 [t=0.17s]
prediction: ['[CLS] unfortunately not s, not very good also good good [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.887 (perp=8.153, rec=0.239, cos=0.018), tot_loss_proj:2.081 [t=0.17s]
prediction: ['[CLS] unfortunately. it, s very ® also not good [SEP]']
[ 300/2000] tot_loss=1.774 (perp=8.153, rec=0.138, cos=0.005), tot_loss_proj:2.034 [t=0.17s]
prediction: ['[CLS] unfortunately. it, s very ® also not good [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.674 (perp=7.740, rec=0.122, cos=0.004), tot_loss_proj:2.142 [t=0.17s]
prediction: ['[CLS] unfortunately. s also s very ®, not good [SEP]']
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.274 (perp=5.819, rec=0.106, cos=0.004), tot_loss_proj:1.566 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s ®. not very good [SEP]']
[ 450/2000] tot_loss=1.253 (perp=5.819, rec=0.085, cos=0.004), tot_loss_proj:1.565 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s ®. not very good [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.256 (perp=5.819, rec=0.088, cos=0.004), tot_loss_proj:1.563 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s ®. not very good [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.266 (perp=5.819, rec=0.098, cos=0.004), tot_loss_proj:1.550 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s ®. not very good [SEP]']
[ 600/2000] tot_loss=1.263 (perp=5.819, rec=0.095, cos=0.004), tot_loss_proj:1.553 [t=0.17s]
prediction: ['[CLS] unfortunately, it also s ®. not very good [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.355 (perp=6.306, rec=0.089, cos=0.004), tot_loss_proj:1.665 [t=0.17s]
prediction: ['[CLS] unfortunately, s also s ® not very good. [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.355 (perp=6.306, rec=0.089, cos=0.004), tot_loss_proj:1.655 [t=0.17s]
prediction: ['[CLS] unfortunately, s also s ® not very good. [SEP]']
[ 750/2000] tot_loss=1.356 (perp=6.306, rec=0.091, cos=0.004), tot_loss_proj:1.656 [t=0.17s]
prediction: ['[CLS] unfortunately, s also s ® not very good. [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.340 (perp=6.242, rec=0.088, cos=0.004), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] unfortunately, s also ® not very good. s [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.341 (perp=6.242, rec=0.089, cos=0.004), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] unfortunately, s also ® not very good. s [SEP]']
[ 900/2000] tot_loss=1.342 (perp=6.242, rec=0.089, cos=0.004), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] unfortunately, s also ® not very good. s [SEP]']
Attempt swap
Moved token
[ 950/2000] tot_loss=1.243 (perp=5.807, rec=0.077, cos=0.004), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1000/2000] tot_loss=1.247 (perp=5.807, rec=0.082, cos=0.004), tot_loss_proj:1.585 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
[1050/2000] tot_loss=1.244 (perp=5.807, rec=0.078, cos=0.004), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1100/2000] tot_loss=1.247 (perp=5.807, rec=0.082, cos=0.004), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1150/2000] tot_loss=1.253 (perp=5.807, rec=0.088, cos=0.004), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
[1200/2000] tot_loss=1.243 (perp=5.807, rec=0.078, cos=0.004), tot_loss_proj:1.592 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1250/2000] tot_loss=1.245 (perp=5.807, rec=0.080, cos=0.004), tot_loss_proj:1.590 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1300/2000] tot_loss=1.243 (perp=5.807, rec=0.077, cos=0.004), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
[1350/2000] tot_loss=1.242 (perp=5.807, rec=0.076, cos=0.004), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1400/2000] tot_loss=1.235 (perp=5.807, rec=0.070, cos=0.004), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1450/2000] tot_loss=1.238 (perp=5.807, rec=0.073, cos=0.004), tot_loss_proj:1.586 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
[1500/2000] tot_loss=1.250 (perp=5.807, rec=0.084, cos=0.004), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1550/2000] tot_loss=1.247 (perp=5.807, rec=0.082, cos=0.004), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1600/2000] tot_loss=1.247 (perp=5.807, rec=0.081, cos=0.004), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
[1650/2000] tot_loss=1.245 (perp=5.807, rec=0.079, cos=0.004), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1700/2000] tot_loss=1.248 (perp=5.807, rec=0.083, cos=0.004), tot_loss_proj:1.599 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1750/2000] tot_loss=1.246 (perp=5.807, rec=0.081, cos=0.004), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
[1800/2000] tot_loss=1.247 (perp=5.807, rec=0.082, cos=0.004), tot_loss_proj:1.592 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1850/2000] tot_loss=1.242 (perp=5.807, rec=0.077, cos=0.004), tot_loss_proj:1.585 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[1900/2000] tot_loss=1.253 (perp=5.807, rec=0.088, cos=0.004), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
[1950/2000] tot_loss=1.243 (perp=5.807, rec=0.078, cos=0.004), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Attempt swap
[2000/2000] tot_loss=1.243 (perp=5.807, rec=0.077, cos=0.004), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] unfortunately, s ® also not very good. s [SEP]']
Done with input #85 of 100.
reference: 
========================
[CLS] unfortunately, it's also not very good. [SEP]
========================
predicted: 
========================
[CLS] unfortunately, s ® also not very good. s [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 88.889 | p: 88.889 | r: 88.889
rouge2     | fm: 62.500 | p: 62.500 | r: 62.500
rougeL     | fm: 88.889 | p: 88.889 | r: 88.889
rougeLsum  | fm: 88.889 | p: 88.889 | r: 88.889
r1fm+r2fm = 151.389

[Aggregate metrics]:
rouge1     | fm: 89.692 | p: 88.931 | r: 90.572
rouge2     | fm: 54.758 | p: 54.445 | r: 55.157
rougeL     | fm: 77.983 | p: 77.373 | r: 78.686
rougeLsum  | fm: 77.961 | p: 77.340 | r: 78.706
r1fm+r2fm = 144.450

input #85 time: 0:06:47 | total time: 11:36:54


Running input #86 of 100.
reference: 
========================
clarity and emotional 
========================
average of cosine similarity 0.9993327117168653
highest_index [0]
highest [0.9993327117168653]
Debug: ids_shape = 5, pads = [5]
Debug: input ids = tensor([[  101, 15563,  1998,  6832,   102]], device='cuda:0')
Debug: ref = ['[CLS] clarity and emotional [SEP]']
[Init] best rec loss: 1.9023118019104004 for ['[CLS] henry north choral [SEP]']
[Init] best rec loss: 1.8336035013198853 for ['[CLS] exchanged devi virginity [SEP]']
[Init] best rec loss: 1.7943329811096191 for ['[CLS] feeling bank give [SEP]']
[Init] best rec loss: 1.7112845182418823 for ['[CLS] maria passingerative [SEP]']
[Init] best rec loss: 1.6274235248565674 for ['[CLS] bipolar sea set [SEP]']
[Init] best rec loss: 1.5547959804534912 for ['[CLS] lp happy winston [SEP]']
[Init] best rec loss: 1.4702644348144531 for ['[CLS] studied ride roar [SEP]']
[Init] best rec loss: 1.2827883958816528 for ['[CLS] tons things wi [SEP]']
[Init] best rec loss: 0.9979948997497559 for ['[CLS] talks karen flipped [SEP]']
[Init] best perm rec loss: 0.9904369711875916 for ['[CLS] flipped karen talks [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.541 (perp=11.543, rec=0.224, cos=0.008), tot_loss_proj:3.604 [t=0.17s]
prediction: ['[CLS] emotional formula clarity [SEP]']
[ 100/2000] tot_loss=1.973 (perp=9.124, rec=0.144, cos=0.003), tot_loss_proj:2.244 [t=0.17s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
[ 150/2000] tot_loss=1.952 (perp=9.124, rec=0.125, cos=0.002), tot_loss_proj:2.233 [t=0.17s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
[ 200/2000] tot_loss=1.939 (perp=9.124, rec=0.112, cos=0.002), tot_loss_proj:2.231 [t=0.17s]
prediction: ['[CLS] emotional emotional clarity [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.875 (perp=8.855, rec=0.101, cos=0.002), tot_loss_proj:2.059 [t=0.17s]
prediction: ['[CLS] & emotional clarity [SEP]']
[ 300/2000] tot_loss=1.745 (perp=8.211, rec=0.101, cos=0.002), tot_loss_proj:1.874 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.751 (perp=8.211, rec=0.106, cos=0.003), tot_loss_proj:1.885 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.726 (perp=8.211, rec=0.081, cos=0.002), tot_loss_proj:1.868 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 450/2000] tot_loss=2.202 (perp=10.458, rec=0.108, cos=0.002), tot_loss_proj:2.548 [t=0.17s]
prediction: ['[CLS] expanded emotional clarity [SEP]']
Attempt swap
[ 500/2000] tot_loss=2.071 (perp=9.824, rec=0.103, cos=0.002), tot_loss_proj:3.359 [t=0.17s]
prediction: ['[CLS] or emotional clarity [SEP]']
Attempt swap
[ 550/2000] tot_loss=2.071 (perp=9.824, rec=0.104, cos=0.002), tot_loss_proj:3.365 [t=0.17s]
prediction: ['[CLS] or emotional clarity [SEP]']
[ 600/2000] tot_loss=1.726 (perp=8.211, rec=0.082, cos=0.002), tot_loss_proj:1.880 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.747 (perp=8.211, rec=0.102, cos=0.002), tot_loss_proj:1.884 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.745 (perp=8.211, rec=0.101, cos=0.002), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 750/2000] tot_loss=1.750 (perp=8.211, rec=0.105, cos=0.002), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.736 (perp=8.211, rec=0.092, cos=0.002), tot_loss_proj:1.879 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.746 (perp=8.211, rec=0.102, cos=0.002), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[ 900/2000] tot_loss=1.732 (perp=8.211, rec=0.087, cos=0.002), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.728 (perp=8.211, rec=0.084, cos=0.002), tot_loss_proj:1.882 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1000/2000] tot_loss=1.728 (perp=8.211, rec=0.085, cos=0.002), tot_loss_proj:1.881 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1050/2000] tot_loss=1.714 (perp=8.211, rec=0.070, cos=0.001), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1100/2000] tot_loss=1.711 (perp=8.211, rec=0.067, cos=0.001), tot_loss_proj:1.883 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1150/2000] tot_loss=1.706 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1200/2000] tot_loss=1.714 (perp=8.211, rec=0.070, cos=0.001), tot_loss_proj:1.882 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1250/2000] tot_loss=1.724 (perp=8.211, rec=0.080, cos=0.001), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1300/2000] tot_loss=1.709 (perp=8.211, rec=0.066, cos=0.001), tot_loss_proj:1.880 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1350/2000] tot_loss=1.715 (perp=8.211, rec=0.071, cos=0.001), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1400/2000] tot_loss=1.716 (perp=8.211, rec=0.072, cos=0.001), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1450/2000] tot_loss=1.712 (perp=8.211, rec=0.069, cos=0.001), tot_loss_proj:1.883 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1500/2000] tot_loss=1.705 (perp=8.211, rec=0.061, cos=0.001), tot_loss_proj:1.884 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1550/2000] tot_loss=1.701 (perp=8.211, rec=0.057, cos=0.001), tot_loss_proj:1.888 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1600/2000] tot_loss=1.713 (perp=8.211, rec=0.069, cos=0.001), tot_loss_proj:1.889 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1650/2000] tot_loss=1.703 (perp=8.211, rec=0.059, cos=0.001), tot_loss_proj:1.882 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1700/2000] tot_loss=1.706 (perp=8.211, rec=0.062, cos=0.001), tot_loss_proj:1.883 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1750/2000] tot_loss=1.707 (perp=8.211, rec=0.063, cos=0.001), tot_loss_proj:1.886 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1800/2000] tot_loss=1.708 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.887 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1850/2000] tot_loss=1.709 (perp=8.211, rec=0.065, cos=0.001), tot_loss_proj:1.877 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[1900/2000] tot_loss=1.712 (perp=8.211, rec=0.068, cos=0.001), tot_loss_proj:1.881 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
[1950/2000] tot_loss=1.705 (perp=8.211, rec=0.062, cos=0.001), tot_loss_proj:1.877 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Attempt swap
[2000/2000] tot_loss=1.710 (perp=8.211, rec=0.067, cos=0.001), tot_loss_proj:1.891 [t=0.17s]
prediction: ['[CLS] and emotional clarity [SEP]']
Done with input #86 of 100.
reference: 
========================
[CLS] clarity and emotional [SEP]
========================
predicted: 
========================
[CLS] and emotional clarity [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 80.000 | p: 80.000 | r: 80.000
rougeLsum  | fm: 80.000 | p: 80.000 | r: 80.000
r1fm+r2fm = 125.000

[Aggregate metrics]:
rouge1     | fm: 89.802 | p: 89.068 | r: 90.664
rouge2     | fm: 54.529 | p: 54.266 | r: 54.891
rougeL     | fm: 77.936 | p: 77.327 | r: 78.665
rougeLsum  | fm: 77.890 | p: 77.299 | r: 78.583
r1fm+r2fm = 144.331

input #86 time: 0:06:46 | total time: 11:43:41


Running input #87 of 100.
reference: 
========================
propulsive 
========================
average of cosine similarity 0.9992553760665845
highest_index [0]
highest [0.9992553760665845]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 17678, 23004,   102]], device='cuda:0')
Debug: ref = ['[CLS] propulsive [SEP]']
[Init] best rec loss: 1.4715983867645264 for ['[CLS] illusion hum [SEP]']
[Init] best rec loss: 1.1083849668502808 for ['[CLS] soleety [SEP]']
[Init] best rec loss: 1.1040385961532593 for ['[CLS] distinct post [SEP]']
[Init] best rec loss: 1.0068668127059937 for ['[CLS] d close [SEP]']
[Init] best rec loss: 0.9670395851135254 for ['[CLS] study format [SEP]']
[Init] best perm rec loss: 0.9667397141456604 for ['[CLS] format study [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.888 (perp=12.535, rec=0.343, cos=0.038), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS]ulsiveulsive [SEP]']
[ 100/2000] tot_loss=1.628 (perp=7.258, rec=0.170, cos=0.007), tot_loss_proj:1.517 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 150/2000] tot_loss=1.568 (perp=7.258, rec=0.113, cos=0.003), tot_loss_proj:1.513 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 200/2000] tot_loss=1.526 (perp=7.258, rec=0.072, cos=0.002), tot_loss_proj:1.537 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.618 (perp=7.258, rec=0.154, cos=0.013), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 300/2000] tot_loss=1.530 (perp=7.258, rec=0.077, cos=0.002), tot_loss_proj:1.532 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.002), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.002), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 450/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.505 (perp=7.258, rec=0.052, cos=0.001), tot_loss_proj:1.516 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.535 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 600/2000] tot_loss=1.495 (perp=7.258, rec=0.042, cos=0.002), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.509 (perp=7.258, rec=0.056, cos=0.001), tot_loss_proj:1.533 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.523 (perp=7.258, rec=0.070, cos=0.002), tot_loss_proj:1.544 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 750/2000] tot_loss=1.513 (perp=7.258, rec=0.060, cos=0.001), tot_loss_proj:1.522 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.520 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[ 900/2000] tot_loss=1.503 (perp=7.258, rec=0.050, cos=0.001), tot_loss_proj:1.549 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.529 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1000/2000] tot_loss=1.507 (perp=7.258, rec=0.054, cos=0.001), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1050/2000] tot_loss=1.493 (perp=7.258, rec=0.040, cos=0.001), tot_loss_proj:1.521 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1100/2000] tot_loss=1.502 (perp=7.258, rec=0.049, cos=0.001), tot_loss_proj:1.538 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1150/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.527 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1200/2000] tot_loss=1.521 (perp=7.258, rec=0.068, cos=0.001), tot_loss_proj:1.532 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1250/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.530 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1300/2000] tot_loss=1.515 (perp=7.258, rec=0.062, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1350/2000] tot_loss=1.508 (perp=7.258, rec=0.055, cos=0.001), tot_loss_proj:1.537 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1400/2000] tot_loss=1.517 (perp=7.258, rec=0.064, cos=0.001), tot_loss_proj:1.545 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1450/2000] tot_loss=1.499 (perp=7.258, rec=0.046, cos=0.001), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1500/2000] tot_loss=1.505 (perp=7.258, rec=0.052, cos=0.001), tot_loss_proj:1.539 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1550/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.550 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1600/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.524 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1650/2000] tot_loss=1.500 (perp=7.258, rec=0.047, cos=0.001), tot_loss_proj:1.543 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1700/2000] tot_loss=1.511 (perp=7.258, rec=0.058, cos=0.001), tot_loss_proj:1.531 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1750/2000] tot_loss=1.504 (perp=7.258, rec=0.051, cos=0.001), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1800/2000] tot_loss=1.518 (perp=7.258, rec=0.065, cos=0.001), tot_loss_proj:1.548 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1850/2000] tot_loss=1.524 (perp=7.258, rec=0.071, cos=0.001), tot_loss_proj:1.536 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[1900/2000] tot_loss=1.531 (perp=7.258, rec=0.078, cos=0.001), tot_loss_proj:1.526 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
[1950/2000] tot_loss=1.519 (perp=7.258, rec=0.066, cos=0.001), tot_loss_proj:1.528 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Attempt swap
[2000/2000] tot_loss=1.516 (perp=7.258, rec=0.063, cos=0.001), tot_loss_proj:1.522 [t=0.17s]
prediction: ['[CLS] propulsive [SEP]']
Done with input #87 of 100.
reference: 
========================
[CLS] propulsive [SEP]
========================
predicted: 
========================
[CLS] propulsive [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.857 | p: 89.165 | r: 90.759
rouge2     | fm: 55.045 | p: 54.686 | r: 55.399
rougeL     | fm: 78.263 | p: 77.677 | r: 78.956
rougeLsum  | fm: 78.211 | p: 77.623 | r: 78.852
r1fm+r2fm = 144.901

input #87 time: 0:06:48 | total time: 11:50:29


Running input #88 of 100.
reference: 
========================
p.t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible . 
========================
average of cosine similarity 0.9992358071326222
highest_index [0]
highest [0.9992358071326222]
Debug: ids_shape = 45, pads = [45]
Debug: input ids = tensor([[  101,  1052,  1012,  1056,  1012,  5143, 19821,  1996,  2882,  2791,
          1997,  7472,  1998,  2129,  2293,  2003,  1996,  2307,  5020, 17629,
          2008,  2064,  5475,  2149,  1997,  2256,  3679,  5665,  2015,  1998,
          3288,  2041,  6569,  2015,  1999,  2256,  3268,  2008,  2057,  2196,
          2354,  2020,  2825,  1012,   102]], device='cuda:0')
Debug: ref = ['[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]']
[Init] best rec loss: 1.9200705289840698 for ['[CLS] filter mir sign unnamed jet mike male elizaste nentiis transfer films theory parishes world nathan agents def daemon minus breath dial bravery heyyria via fast theatre fleet scanninglan fewer rank disc motion until actorulating bent fairy throat [SEP]']
[Init] best rec loss: 1.8874351978302002 for ['[CLS] history o ratio pines date zombie pig multiple one [CLS] pushed lore needs carson solo worcester playcentric runway tuning firstly drawssedhee dog excess commission thought public had k professional abstracts north splitmax intelligence & mississippi long relatingchment care [SEP]']
[Init] best rec loss: 1.8369611501693726 for ['[CLS]ho dukevs counter licence fruitoninguded customerbasket manufacturingeon movement psyche life researchers dart foreign nadia occasion mare good maximumerty unemployment pattern though alpha flames day :rop at mechanics scratch 200 forewings boss emergency loanex decades overview [SEP]']
[Init] best rec loss: 1.7725632190704346 for ['[CLS] bryn products oclc sm boone instead off capable pain short most kenny high tricript bathurst trade gigs acheron sometimes loomed board viiash second why recipient stillkeeping metal wall camp gold lingda gr manson series warming themselves face precedence ghetto [SEP]']
[Init] best rec loss: 1.7031794786453247 for ['[CLS] dose skin epicennial designbu paddy market improvement content came elijahds what off skye bat just navalesis winked zur butterfly contract ready sympathy block tomorrow and pitt knew jerizeap plague flat optical valley lynch mother drive men co [SEP]']
[Init] best rec loss: 1.6743240356445312 for ['[CLS] tells pursuithis compromise sweet bull sour wescreen lying bearwny wet touch time dream planet... make said rapper assembly spain close dinner benzg arc farm tatar basic university trough born boundbound big factor ad diesel askingrew band [SEP]']
[Init] best rec loss: 1.6713396310806274 for ['[CLS] chairman fall blue hipsaq mold ltd raymond cousintablishedtic once... late ap evidenceground hill yo foundation mostmen avant overlandgra rubberivating n be miles podium crown job scriptati first requirement whole excusenut brown him england [SEP]']
[Init] best perm rec loss: 1.6702827215194702 for ['[CLS] miles cousin natitablished ap ltd raymond mostnut hips requirement falltic... onceaq first moldgraivating scriptground overland crown him evidence rubber brownmen late yo avant job be podium chairman whole england blue excuse foundation hill [SEP]']
[Init] best perm rec loss: 1.669132113456726 for ['[CLS] ltd blue script cousin raymond late englandground rubber him excuse apaq hipsmenati overland... requirementivating mostgra chairman foundation yo evidence n mold be hill podium once fall firsttic jobnut whole crown brown milestablished avant [SEP]']
[Init] best perm rec loss: 1.6680104732513428 for ['[CLS]ivating job late apati oncetablished raymond foundation evidence excuse chairman england cousinground script miles blue fallaq rubber whole... podiumtic firstgra hips most crown avant ltd brown overlandmen be mold requirement him yo n hillnut [SEP]']
[Init] best perm rec loss: 1.666865348815918 for ['[CLS] n late fallnut scriptivating chairman excusetablished avant requirement him mold crown most hips englandground cousin... overland brown ltd miles evidence wholeaq onceticgra blue raymond hill podium rubber foundation yoati jobmen first be ap [SEP]']
[Init] best perm rec loss: 1.6660468578338623 for ['[CLS] miles ltd mold first... rubber evidencemen late england fallnut foundation excusetablishedati crown be brownaq podium overland ap script wholeground cousin hill n hips most himivating job requirementtic chairman blue avant raymond oncegra yo [SEP]']
[Init] best perm rec loss: 1.6599833965301514 for ['[CLS]tablished mold miles rubber ap requirement blue podium ltd... script himnutmen excuse evidence most brown overlandground chairman yo job lateatigra nivating hill hips once cousinaq raymond whole crown first fall foundationtic england avant be [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.559 (perp=11.194, rec=0.313, cos=0.007), tot_loss_proj:3.560 [t=0.17s]
prediction: ['[CLS] brother horror group normal andiful the beautiful romantic rancho craft peter creative fiction jazz seeds literature ultimatesh real burrows.. emotional ; understood those comfort goodness understand. historical 5000less mysteries evil pleasure. science and history of of [SEP]']
[ 100/2000] tot_loss=2.357 (perp=10.271, rec=0.298, cos=0.005), tot_loss_proj:3.511 [t=0.17s]
prediction: ['[CLS] he romantic besides normal and and the grand love calm symptoms t mainstream love jazz degrees hurt buildingsic our campbell.. emotions ; great how happiness goodness understands, annual www bearing beauty evil pleasure. science understandsstone. of [SEP]']
[ 150/2000] tot_loss=2.484 (perp=10.919, rec=0.294, cos=0.007), tot_loss_proj:3.457 [t=0.17s]
prediction: ['[CLS]™ romance eventually joy and beings the grand love calmization p ள. bible seven women ʷic we campbell of. love butter deeply that happiness joy understands mining our theination family． strangers is science directlybook oneself. [SEP]']
[ 200/2000] tot_loss=2.475 (perp=10.719, rec=0.325, cos=0.006), tot_loss_proj:3.767 [t=0.17s]
prediction: ['[CLS]? romantic. pleasant and that the grand love smileization} ள,! heavens lost shortlyoese with gilbert of. good when gay that 疒 © understands, several of " inequality ェ love these lexi with poem ள ¨ [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.247 (perp=9.791, rec=0.284, cos=0.004), tot_loss_proj:3.211 [t=0.17s]
prediction: ['[CLS]? hung and warmth and in the great our calm lives}.,! nouns day shortly anything our gilbert to. that when truly power། laughter understands ⇄ three of and bethlehem ェ love is her understand poetry! ¨ [SEP]']
[ 300/2000] tot_loss=2.356 (perp=10.553, rec=0.243, cos=0.003), tot_loss_proj:3.413 [t=0.17s]
prediction: ['[CLS]? hung. calm and in the great our calm lives} is,! nouns festival shortly nothing us anderson to. that when truly trust། joy understands ⇄ three of and wnba ェ love is she thank romance global ¨ [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.293 (perp=10.354, rec=0.220, cos=0.002), tot_loss_proj:3.960 [t=0.17s]
prediction: ['[CLS] calm hung.? and in the grand our calm lives} is,! nouns festival shortly losing our anderson to. that when truly trust། joy understands earthly three of and fashion ェ romance is she thank romance global ¨ [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.089 (perp=9.310, rec=0.224, cos=0.003), tot_loss_proj:3.430 [t=0.19s]
prediction: ['[CLS] calm hung.. and in the grand our calm lives, is}!tance, creates win our anderson to. that when truly good། pleasure understands earthly three of and settlement ェ romance that. never romance global ¨ [SEP]']
[ 450/2000] tot_loss=2.066 (perp=9.290, rec=0.205, cos=0.002), tot_loss_proj:3.752 [t=0.17s]
prediction: ['[CLS] ill hung.. and in the grand our calm lives, is}! every likely creates yang our anderson of. that when truly good། joy understands [CLS] three of andness ェ romance in. never romance global ¨ [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=2.089 (perp=9.434, rec=0.199, cos=0.002), tot_loss_proj:3.755 [t=0.17s]
prediction: ['[CLS] ill hung.. and in the grand our calm lives, is}! every likely creates that our anderson of. that t truly good། joy understands [CLS] three of andness ェ romance yang. could romance global ¨ [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=1.999 (perp=9.039, rec=0.189, cos=0.002), tot_loss_proj:3.629 [t=0.17s]
prediction: ['[CLS] ill hung.. and in the grand our calm lives, of}! every ever creates that our anderson of. that t how good། joy understands and [CLS] three ofness} romance yang. could romance global ¨ [SEP]']
[ 600/2000] tot_loss=2.087 (perp=9.512, rec=0.183, cos=0.002), tot_loss_proj:3.811 [t=0.17s]
prediction: ['[CLS] ill hung.. and in the grand our calm lives, is}!nity ever creates we our anderson of. that t daily good། joy understands was [CLS] three ofness} romance yang. could romance how ¨ [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.994 (perp=9.035, rec=0.185, cos=0.002), tot_loss_proj:3.695 [t=0.17s]
prediction: ['[CLS] ill hung.. and in the grand our calm lives, is}! ill ever creates that our anderson of། that t toll good. joy understands and [CLS] three ofness ェ romance yang. could romance how genome [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.900 (perp=8.586, rec=0.181, cos=0.002), tot_loss_proj:3.173 [t=0.17s]
prediction: ['[CLS] ill hung.. and in the grand our calm lives, is good! ill relative creates we our anderson of། that t daily}. joy understands and [CLS] three ofness} romance us. could romance how genome [SEP]']
[ 750/2000] tot_loss=2.020 (perp=9.181, rec=0.181, cos=0.002), tot_loss_proj:3.518 [t=0.17s]
prediction: ['[CLS] ill hung.. and in the grand our calm lives, is good! ill ever creates we our anderson of། that t daily} ill joy understands and earthly three ofness ェ romance our. could romance how genome [SEP]']
Attempt swap
Moved token
[ 800/2000] tot_loss=1.986 (perp=9.020, rec=0.180, cos=0.002), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS] ill hung.. and in the grand our calm lives, is good! ill ever creates we our anderson of། that t daily} ill joy understands and daily three ofness ェ our romance. how romance how genome [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=1.955 (perp=8.882, rec=0.177, cos=0.002), tot_loss_proj:3.536 [t=0.17s]
prediction: ['[CLS] ill hung.. and in the grand} calm lives, of good! ill ever creates we our anderson of། that t daily our ill joy understands and daily three ofness ェ our romance. how romance how genome [SEP]']
[ 900/2000] tot_loss=1.985 (perp=9.096, rec=0.164, cos=0.002), tot_loss_proj:3.694 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calmwrite, of good! ill ever creates we our anderson of། that t daily our ill joy understands and daily three ofness ェ our romance. how romance how genome [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.980 (perp=9.022, rec=0.173, cos=0.002), tot_loss_proj:3.563 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance, that good! ill ever creates we our anderson of got that t daily our ill joy understands and daily three ofness ェ our romance. how lives how genome [SEP]']
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.975 (perp=9.017, rec=0.170, cos=0.002), tot_loss_proj:3.487 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance, that good! ill personally creates we our anderson of joy that t daily our ill got understands was daily three ofness ェ our romance. how livess genome [SEP]']
[1050/2000] tot_loss=1.953 (perp=8.883, rec=0.174, cos=0.002), tot_loss_proj:3.480 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance, of good! ill could creates we our anderson of joy that t daily our ill got understands was daily three ofness ェ our romance. how livess genome [SEP]']
Attempt swap
Moved token
[1100/2000] tot_loss=1.964 (perp=8.985, rec=0.165, cos=0.002), tot_loss_proj:3.404 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance, that great! homer could creates we our anderson of joy that t daily our ill got understands was three ofness ェ daily our romance. how livess genome [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.918 (perp=8.740, rec=0.168, cos=0.002), tot_loss_proj:3.565 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance, that great! ill ever creates we our anderson of joy that t daily our ill got understands were three ェness of daily our romance. how livess genome [SEP]']
[1200/2000] tot_loss=1.912 (perp=8.740, rec=0.162, cos=0.002), tot_loss_proj:3.566 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance, that great! ill ever creates we our anderson of joy that t daily our ill got understands were three ェness of daily our romance. how livess genome [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=1.878 (perp=8.574, rec=0.162, cos=0.002), tot_loss_proj:3.510 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance, that great! ill ever creates we our anderson of joy that t daily our ill got understands were three ェness of daily our romance. how lives genomes [SEP]']
Attempt swap
Moved token
[1300/2000] tot_loss=1.864 (perp=8.476, rec=0.167, cos=0.002), tot_loss_proj:3.398 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! that great ill ever creates we our anderson of joy that t daily our ill got understands was three ェness of daily our romance. how lives genomes [SEP]']
[1350/2000] tot_loss=1.899 (perp=8.680, rec=0.162, cos=0.002), tot_loss_proj:3.474 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! that great ill ever creates we our anderson of joy that t daily our ill got understands were three ェness of daily we romance. how lives genomes [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.865 (perp=8.504, rec=0.162, cos=0.002), tot_loss_proj:3.314 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! that great ill got creates we our anderson of joy that t daily our ill personally understands and three ェness of daily our romance. how lives genomes [SEP]']
Attempt swap
[1450/2000] tot_loss=1.864 (perp=8.504, rec=0.161, cos=0.002), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! that great ill got creates we our anderson of joy that t daily our ill personally understands and three ェness of daily our romance. how lives genomes [SEP]']
[1500/2000] tot_loss=1.891 (perp=8.671, rec=0.155, cos=0.002), tot_loss_proj:3.265 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! that great homer pl creates we our anderson of joy that t daily our ill personally understands and three ェness of daily our romance. how lives genomes [SEP]']
Attempt swap
[1550/2000] tot_loss=1.894 (perp=8.671, rec=0.158, cos=0.002), tot_loss_proj:3.267 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! that great homer pl creates we our anderson of joy that t daily our ill personally understands and three ェness of daily our romance. how lives genomes [SEP]']
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.906 (perp=8.740, rec=0.156, cos=0.002), tot_loss_proj:3.229 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! personally great homer pl creates we our anderson of joy that t daily our ill that understands was three ェness of daily our romance. how lives genomes [SEP]']
[1650/2000] tot_loss=1.861 (perp=8.528, rec=0.154, cos=0.002), tot_loss_proj:3.305 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! personally great ill pl creates we our anderson of joy that t daily our ill that understands was three ェness of daily our romance. how lives genomes [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.835 (perp=8.409, rec=0.151, cos=0.002), tot_loss_proj:3.295 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! personally great ill pl creates our anderson of joy we that t daily our ill that understands were three ェness of daily our romance. how understand genomes [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.810 (perp=8.266, rec=0.155, cos=0.002), tot_loss_proj:3.306 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! personally great ill pl ェ our anderson of joy we that t daily our ill that understands were three createsness of daily our romance. how understand genomes [SEP]']
[1800/2000] tot_loss=1.814 (perp=8.266, rec=0.159, cos=0.002), tot_loss_proj:3.312 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! personally great ill pl ェ our anderson of joy we that t daily our ill that understands were three createsness of daily our romance. how understand genomes [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.819 (perp=8.293, rec=0.158, cos=0.002), tot_loss_proj:3.370 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! personally great ill pl ェ our anderson of joy we that t daily our ill understands that were three createsness of daily our romance. how understand genomes [SEP]']
Attempt swap
Moved token
[1900/2000] tot_loss=1.832 (perp=8.354, rec=0.160, cos=0.002), tot_loss_proj:3.280 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! personally great ill pl ェ our anderson of joy we that p our daily ill understands that were three createsness of daily our romance. how understand genomes [SEP]']
[1950/2000] tot_loss=1.823 (perp=8.339, rec=0.154, cos=0.002), tot_loss_proj:3.386 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! personally great ill pl ェ our anderson of joy we that t our daily ill understands that were three createsness of daily our romance. how understand genomes [SEP]']
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.830 (perp=8.374, rec=0.153, cos=0.002), tot_loss_proj:3.367 [t=0.17s]
prediction: ['[CLS] ill hung.. and that the grand} calm romance,! daily great ill pl ェ our anderson of joy we that t our daily ill understands that creates three wereness of daily our romance. how understand genomes [SEP]']
Done with input #88 of 100.
reference: 
========================
[CLS] p. t. anderson understands the grandness of romance and how love is the great equalizer that can calm us of our daily ills and bring out joys in our lives that we never knew were possible. [SEP]
========================
predicted: 
========================
[CLS] ill hung.. and that the grand} calm romance,! daily great ill pl ェ our anderson of joy we that t our daily ill understands that creates three wereness of daily our romance. how understand genomes [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 51.351 | p: 52.778 | r: 50.000
rouge2     | fm: 2.778 | p: 2.857 | r: 2.703
rougeL     | fm: 24.324 | p: 25.000 | r: 23.684
rougeLsum  | fm: 24.324 | p: 25.000 | r: 23.684
r1fm+r2fm = 54.129

[Aggregate metrics]:
rouge1     | fm: 89.495 | p: 88.808 | r: 90.320
rouge2     | fm: 54.525 | p: 54.272 | r: 54.854
rougeL     | fm: 77.625 | p: 77.057 | r: 78.334
rougeLsum  | fm: 77.586 | p: 77.050 | r: 78.293
r1fm+r2fm = 144.020

input #88 time: 0:06:51 | total time: 11:57:21


Running input #89 of 100.
reference: 
========================
tactic to cover up the fact that the picture is constructed around a core of flimsy -- or , worse yet , nonexistent -- ideas 
========================
average of cosine similarity 0.9993426143386362
highest_index [0]
highest [0.9993426143386362]
Debug: ids_shape = 34, pads = [34]
Debug: input ids = tensor([[  101, 19717,  2000,  3104,  2039,  1996,  2755,  2008,  1996,  3861,
          2003,  3833,  2105,  1037,  4563,  1997, 13109,  5714,  6508,  1011,
          1011,  2030,  1010,  4788,  2664,  1010,  3904,  9048, 16173,  2102,
          1011,  1011,  4784,   102]], device='cuda:0')
Debug: ref = ['[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]']
[Init] best rec loss: 1.9183775186538696 for ['[CLS] kun allmusic women bothz reveal this / grandmotherbled accident squinting chase roads located fame amosopus lava father boot commissioner similar king mentally united initiative mani miracle item dial down [SEP]']
[Init] best rec loss: 1.9162806272506714 for ['[CLS] tin turkey templegillparts category upper... as an dedicated sixties toast longer hotel regarding congratulations blind when department settlement trainee transgender longest captive skating headquarters sr shaping near ea patron [SEP]']
[Init] best rec loss: 1.8926299810409546 for ['[CLS] diameter county website oro scale among design episodebino inhibition cross changes browning isolation customerscribe laureate brigade spoonately centerobe ash tend carnival roles action overboard unanimous discontinued when triangle [SEP]']
[Init] best rec loss: 1.8359391689300537 for ['[CLS] an other⁄ given fire miniseries fit followed inhabitants opposite kilometres earliest varyact simplest areness shy law armand reissue ritchie does promoted deal al mathematics amazon brethren that indeed inter [SEP]']
[Init] best rec loss: 1.529639720916748 for ['[CLS] lux valueao hail enlisted holidayrable livertightws launch headsbiotic reigned intelligence associated commonwealth huge way horses luciusncy adept y negativebbing ramp turtles texasrogen chinese clearance [SEP]']
[Init] best rec loss: 1.4763695001602173 for ['[CLS] jailtorium sighed keep farm feel gameoke primate hodge victimserre ink pain course artifact basis leader tower there fate being nu red thirdllis public minor martins lucas essence orient [SEP]']
[Init] best perm rec loss: 1.4759719371795654 for ['[CLS] there artifact farm courseerretorium primate thirdoke sighed lucas fate tower martins minor essence feel leaderllis keep ink being nu red victims orient public game pain hodge jail basis [SEP]']
[Init] best perm rec loss: 1.4655603170394897 for ['[CLS] red there hodge feel nu third farm ink fatelliserre basis being course primate tower artifact essence keep jail sighedoke game minor lucas victimstorium leader pain public orient martins [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.051 (perp=12.501, rec=0.469, cos=0.082), tot_loss_proj:4.513 [t=0.17s]
prediction: ['[CLS] adept when cadve following ) musician edge artist theirbread his into capturedran itsunced separate / then river ( derookan ء acoustic duo sydney 10 winter pronunciation [SEP]']
[ 100/2000] tot_loss=2.705 (perp=11.974, rec=0.297, cos=0.013), tot_loss_proj:3.926 [t=0.17s]
prediction: ['[CLS] tactic when /ve marginal ari theska theory a, our an vu beauty puzzle tacticras -, ideas ( worse historic ;¤ / air institute 30 winterge [SEP]']
[ 150/2000] tot_loss=2.273 (perp=10.150, rec=0.236, cos=0.007), tot_loss_proj:3.452 [t=0.17s]
prediction: ['[CLS] tactic cover owned - - fact the lack genre a, the a picture conception tactic tactic operation -, ideas or worse historic yet - - air volunteer pu philip textbooks [SEP]']
[ 200/2000] tot_loss=2.491 (perp=9.821, rec=0.452, cos=0.075), tot_loss_proj:3.456 [t=0.17s]
prediction: ['[CLS] tactic cover owned - - fact fact lack genre a, the a picture picture tactic tactic breath -, ideas or worse historic yet wickets -,worth exam. experiment [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.350 (perp=9.801, rec=0.362, cos=0.027), tot_loss_proj:3.193 [t=0.17s]
prediction: ['[CLS] tactic covert character book that was none ideas a, documentary a, ideas response tactic body 978, text or worse academic yet contacts <,sible blog. examination [SEP]']
[ 300/2000] tot_loss=2.413 (perp=10.450, rec=0.308, cos=0.015), tot_loss_proj:3.400 [t=0.17s]
prediction: ['[CLS] tactic coverly as book that was none ideas a, picture a, ideas version tactic breath 978, ideas or worse academic yet sentai <,sible tortricidae. examination [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.363 (perp=10.375, rec=0.277, cos=0.011), tot_loss_proj:3.600 [t=0.17s]
prediction: ['[CLS] tactic coverly as book that was none thesis a, picture a, ideas cover tactic breath 978, ideas or worse academic yet briannasible - < tortricidae,etti [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=2.281 (perp=10.038, rec=0.264, cos=0.010), tot_loss_proj:3.491 [t=0.17s]
prediction: ['[CLS] tactic coverted as book that was but thesis a, picture a, ideas cover tactic breath became, ideas or worse academic yet symptomssible - none worse↦etti [SEP]']
[ 450/2000] tot_loss=2.342 (perp=10.422, rec=0.249, cos=0.009), tot_loss_proj:3.512 [t=0.17s]
prediction: ['[CLS] tactic coverted as book that faced but thesis a, picture a, ideas cover tactic breathedge, ideas or worse academic yetidsible - none worseiumetti [SEP]']
Attempt swap
Moved token
[ 500/2000] tot_loss=2.248 (perp=10.060, rec=0.228, cos=0.008), tot_loss_proj:3.430 [t=0.17s]
prediction: ['[CLS] tactic coverted as book that to but ideas a picture, a, ideas cover tactic breathedge, ideas or worse academic yetidsible - none worseiumnik [SEP]']
Attempt swap
Moved token
[ 550/2000] tot_loss=2.255 (perp=10.115, rec=0.224, cos=0.007), tot_loss_proj:3.630 [t=0.17s]
prediction: ['[CLS] tactic coverxi as book that to but ideas a picture, picture a, cover tactic breathedge, ideas or worse academic yetidsible - none worseiouslynik [SEP]']
[ 600/2000] tot_loss=2.288 (perp=10.380, rec=0.206, cos=0.006), tot_loss_proj:3.567 [t=0.17s]
prediction: ['[CLS] tactic coverxi asgroup that to but ideas a picture, picture a, cover tactic movingedge, ideas or worse academic yetidsible - none worseiouslynik [SEP]']
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=2.194 (perp=9.915, rec=0.204, cos=0.006), tot_loss_proj:3.361 [t=0.17s]
prediction: ['[CLS] tactic coverxi academicgroup fact to but ideas a picture, picture a, cover tactic moving -, ideas or worse as yetidsible - none worse ェnik [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=2.169 (perp=9.789, rec=0.206, cos=0.006), tot_loss_proj:3.238 [t=0.17s]
prediction: ['[CLS] tactic coverid academicgroup fact to but ideas a picture, picture a, cover coded moving -, ideas or worse become yetxisible - none worse√nik [SEP]']
[ 750/2000] tot_loss=2.158 (perp=9.799, rec=0.193, cos=0.005), tot_loss_proj:3.262 [t=0.17s]
prediction: ['[CLS] tactic coverid academicgroup fact to but ideas a picture, picture a, cover coded moving -, ideas or worse become yetxisible - none worse hartanik [SEP]']
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=2.132 (perp=9.673, rec=0.192, cos=0.005), tot_loss_proj:3.262 [t=0.17s]
prediction: ['[CLS] tactic coverpartisan academicgroup to fact but ideas a picture, picture a, cover coded moving -, ideas or worse become yetxisible - none worse hartanik [SEP]']
Attempt swap
Swapped tokens
[ 850/2000] tot_loss=2.012 (perp=9.082, rec=0.191, cos=0.005), tot_loss_proj:3.185 [t=0.17s]
prediction: ['[CLS] tactic coverthing academicgroup to fact but - a picture, picture a, cover coded moving ideas, ideas or worse become yetxisible - none worse hartanik [SEP]']
[ 900/2000] tot_loss=2.010 (perp=9.101, rec=0.185, cos=0.005), tot_loss_proj:3.301 [t=0.17s]
prediction: ['[CLS] tactic covercoming academicgroup to fact but - a picture, picture a, cover diverse moving ideas, ideas or worse become yetxisible - none worse hartanik [SEP]']
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.986 (perp=8.989, rec=0.184, cos=0.005), tot_loss_proj:3.239 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic knots to fact but - a picture, picture a, cover diverse moving ideas, ideas worse or become yetxisible - none worseciationnik [SEP]']
Attempt swap
[1000/2000] tot_loss=1.984 (perp=8.989, rec=0.182, cos=0.005), tot_loss_proj:3.238 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic knots to fact but - a picture, picture a, cover diverse moving ideas, ideas worse or become yetxisible - none worseciationnik [SEP]']
[1050/2000] tot_loss=2.037 (perp=9.283, rec=0.176, cos=0.004), tot_loss_proj:3.234 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic knots to fact but - a picture, picture a, avengers diverse moving ideas, ideas worse or become yetxisible - none worseciationnik [SEP]']
Attempt swap
[1100/2000] tot_loss=2.150 (perp=9.834, rec=0.178, cos=0.004), tot_loss_proj:3.608 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic knots to fact but - a constructed, picture a, avengers diverse moving ideas, ideas worse or become yetxisible - none worseciationnik [SEP]']
Attempt swap
Swapped tokens
[1150/2000] tot_loss=2.071 (perp=9.454, rec=0.176, cos=0.005), tot_loss_proj:3.148 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic knots to fact ideas - a constructed, picture a, avengers diverse moving fact, but worse or become yetxisible - none worseciationnik [SEP]']
[1200/2000] tot_loss=2.073 (perp=9.477, rec=0.173, cos=0.004), tot_loss_proj:3.130 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic knots to fact ideas - a constructed, picture a, avengers much moving fact, but worse or become yetxisible - none worseciationnik [SEP]']
Attempt swap
Moved token
[1250/2000] tot_loss=2.029 (perp=9.257, rec=0.174, cos=0.004), tot_loss_proj:3.241 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic knots to fact ideas - a constructed, picture a avengers, much moving fact, but worse or become yetxisible - none worseciationnik [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.991 (perp=9.037, rec=0.179, cos=0.005), tot_loss_proj:3.043 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic knots to fact ideas - a constructed a picture, avengers, much moving fact, but worse or become yetxisible - none worseciationnik [SEP]']
[1350/2000] tot_loss=1.986 (perp=9.037, rec=0.174, cos=0.004), tot_loss_proj:3.041 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic knots to fact ideas - a constructed a picture, avengers, much moving fact, but worse or become yetxisible - none worseciationnik [SEP]']
Attempt swap
Swapped tokens
[1400/2000] tot_loss=1.972 (perp=8.961, rec=0.175, cos=0.004), tot_loss_proj:3.022 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv to fact ideas, a constructed a picture, avengers - much moving fact, but worse or become yetxisible - none worseciationdle [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.974 (perp=8.996, rec=0.171, cos=0.004), tot_loss_proj:3.214 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv to fact ideas, a constructed a picture, avengers - much moving fact, but worse or yet -xisible yet none worseciationdle [SEP]']
[1500/2000] tot_loss=1.973 (perp=8.996, rec=0.169, cos=0.004), tot_loss_proj:3.210 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv to fact ideas, a constructed a picture, avengers - much moving fact, but worse or yet -xisible yet none worseciationdle [SEP]']
Attempt swap
Moved token
[1550/2000] tot_loss=2.015 (perp=9.188, rec=0.174, cos=0.004), tot_loss_proj:2.794 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv to fact ideas, a constructed a picture, avengers - much walls fact, - worse or yet - nonexisible yet worseciationdle [SEP]']
Attempt swap
Moved sequence
[1600/2000] tot_loss=2.003 (perp=9.106, rec=0.178, cos=0.004), tot_loss_proj:2.850 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv, to fact ideas a constructed a picture, avengers - much walls fact, - worse or yet - nonexisible yet worseciationdle [SEP]']
[1650/2000] tot_loss=1.980 (perp=8.994, rec=0.177, cos=0.004), tot_loss_proj:2.791 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv, to fact ideas a constructed a picture, avengers - much walls fact, - worse or yet - nonexisible yet worseciation speech [SEP]']
Attempt swap
Moved token
[1700/2000] tot_loss=1.899 (perp=8.661, rec=0.163, cos=0.004), tot_loss_proj:2.725 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv, to fact ideas a constructed a picture, avengers - much walls fact, - worse yet - nonexisible or yet worseciation speech [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.882 (perp=8.524, rec=0.172, cos=0.005), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv, to fact ideas a constructed a picture, avengers - - walls fact, much worse yet - nonexisible or yet worseciation speech [SEP]']
[1800/2000] tot_loss=1.882 (perp=8.524, rec=0.173, cos=0.004), tot_loss_proj:2.587 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv, to fact ideas a constructed a picture, avengers - - walls fact, much worse yet - nonexisible or yet worseciation speech [SEP]']
Attempt swap
[1850/2000] tot_loss=1.878 (perp=8.524, rec=0.169, cos=0.004), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv, to fact ideas a constructed a picture, avengers - - walls fact, much worse yet - nonexisible or yet worseciation speech [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.870 (perp=8.494, rec=0.167, cos=0.004), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv, fact to ideas a constructed a picture, avengers - - walls fact, much worse yet - nonexisible or yet worse touchdown speech [SEP]']
[1950/2000] tot_loss=1.873 (perp=8.494, rec=0.170, cos=0.004), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv, fact to ideas a constructed a picture, avengers - - walls fact, much worse yet - nonexisible or yet worse touchdown speech [SEP]']
Attempt swap
[2000/2000] tot_loss=1.872 (perp=8.494, rec=0.169, cos=0.004), tot_loss_proj:2.584 [t=0.17s]
prediction: ['[CLS] tactic covercoming academic aviv, fact to ideas a constructed a picture, avengers - - walls fact, much worse yet - nonexisible or yet worse touchdown speech [SEP]']
Done with input #89 of 100.
reference: 
========================
[CLS] tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]
========================
predicted: 
========================
[CLS] tactic covercoming academic aviv, fact to ideas a constructed a picture, avengers - - walls fact, much worse yet - nonexisible or yet worse touchdown speech [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 50.000 | p: 48.000 | r: 52.174
rouge2     | fm: 8.696 | p: 8.333 | r: 9.091
rougeL     | fm: 33.333 | p: 32.000 | r: 34.783
rougeLsum  | fm: 33.333 | p: 32.000 | r: 34.783
r1fm+r2fm = 58.696

[Aggregate metrics]:
rouge1     | fm: 89.015 | p: 88.340 | r: 89.870
rouge2     | fm: 54.244 | p: 53.946 | r: 54.580
rougeL     | fm: 77.257 | p: 76.656 | r: 77.956
rougeLsum  | fm: 77.127 | p: 76.563 | r: 77.799
r1fm+r2fm = 143.258

input #89 time: 0:06:52 | total time: 12:04:13


Running input #90 of 100.
reference: 
========================
how ridiculous and money-oriented 
========================
average of cosine similarity 0.9993650968600143
highest_index [0]
highest [0.9993650968600143]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[ 101, 2129, 9951, 1998, 2769, 1011, 8048,  102]], device='cuda:0')
Debug: ref = ['[CLS] how ridiculous and money - oriented [SEP]']
[Init] best rec loss: 1.889743447303772 for ['[CLS]uising camps native guard cooled mathematical [SEP]']
[Init] best rec loss: 1.827311396598816 for ['[CLS] event cheap sector value music volumes [SEP]']
[Init] best rec loss: 1.7925564050674438 for ['[CLS] education ace each catholicsor anti [SEP]']
[Init] best rec loss: 1.566908359527588 for ['[CLS] 1 aft include job hu spectacle [SEP]']
[Init] best rec loss: 1.5568602085113525 for ['[CLS] track direct unconscious unable eyes release [SEP]']
[Init] best rec loss: 1.453827977180481 for ['[CLS] whether alfa artwork lamp ground wang [SEP]']
[Init] best rec loss: 1.4401582479476929 for ['[CLS] hectares sessions tiny skin litter positions [SEP]']
[Init] best rec loss: 1.3662965297698975 for ['[CLS] cannot released when male spirited entourage [SEP]']
[Init] best perm rec loss: 1.3659476041793823 for ['[CLS] released male cannot spirited entourage when [SEP]']
[Init] best perm rec loss: 1.3621010780334473 for ['[CLS] cannot released spirited male when entourage [SEP]']
[Init] best perm rec loss: 1.3619078397750854 for ['[CLS] cannot male released spirited entourage when [SEP]']
[Init] best perm rec loss: 1.3608994483947754 for ['[CLS] cannot released male spirited entourage when [SEP]']
[Init] best perm rec loss: 1.3607511520385742 for ['[CLS] cannot released entourage male spirited when [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.083 (perp=8.783, rec=0.299, cos=0.027), tot_loss_proj:2.317 [t=0.17s]
prediction: ['[CLS] how ridiculous how bush attacks money [SEP]']
[ 100/2000] tot_loss=1.893 (perp=8.622, rec=0.161, cos=0.007), tot_loss_proj:2.157 [t=0.17s]
prediction: ['[CLS] how ridiculous how money oriented money [SEP]']
[ 150/2000] tot_loss=1.847 (perp=8.622, rec=0.118, cos=0.005), tot_loss_proj:2.162 [t=0.17s]
prediction: ['[CLS] how ridiculous how money oriented money [SEP]']
[ 200/2000] tot_loss=1.947 (perp=9.286, rec=0.087, cos=0.003), tot_loss_proj:2.388 [t=0.17s]
prediction: ['[CLS] and ridiculous how money oriented money [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.548 (perp=7.251, rec=0.094, cos=0.004), tot_loss_proj:1.808 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented money [SEP]']
[ 300/2000] tot_loss=1.530 (perp=7.251, rec=0.078, cos=0.002), tot_loss_proj:1.813 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented money [SEP]']
Attempt swap
Moved sequence
[ 350/2000] tot_loss=1.513 (perp=7.069, rec=0.096, cos=0.003), tot_loss_proj:1.953 [t=0.17s]
prediction: ['[CLS] money how ridiculous and money oriented [SEP]']
Attempt swap
Put prefix at the end
[ 400/2000] tot_loss=1.527 (perp=7.251, rec=0.075, cos=0.002), tot_loss_proj:1.826 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented money [SEP]']
[ 450/2000] tot_loss=1.441 (perp=6.870, rec=0.065, cos=0.002), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.440 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.443 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 600/2000] tot_loss=1.441 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.430 (perp=6.870, rec=0.054, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.443 (perp=6.870, rec=0.068, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 750/2000] tot_loss=1.450 (perp=6.870, rec=0.074, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.428 (perp=6.870, rec=0.052, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[ 900/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.693 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1000/2000] tot_loss=1.439 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.687 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1050/2000] tot_loss=1.437 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1100/2000] tot_loss=1.435 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1150/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1200/2000] tot_loss=1.437 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.713 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1250/2000] tot_loss=1.438 (perp=6.870, rec=0.062, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1300/2000] tot_loss=1.436 (perp=6.870, rec=0.060, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1350/2000] tot_loss=1.445 (perp=6.870, rec=0.069, cos=0.001), tot_loss_proj:1.713 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1400/2000] tot_loss=1.442 (perp=6.870, rec=0.067, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1450/2000] tot_loss=1.438 (perp=6.870, rec=0.063, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1500/2000] tot_loss=1.441 (perp=6.870, rec=0.066, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1550/2000] tot_loss=1.432 (perp=6.870, rec=0.057, cos=0.001), tot_loss_proj:1.709 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1600/2000] tot_loss=1.448 (perp=6.870, rec=0.073, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1650/2000] tot_loss=1.431 (perp=6.870, rec=0.056, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1700/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1750/2000] tot_loss=1.444 (perp=6.870, rec=0.069, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1800/2000] tot_loss=1.428 (perp=6.870, rec=0.052, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1850/2000] tot_loss=1.436 (perp=6.870, rec=0.061, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[1900/2000] tot_loss=1.445 (perp=6.870, rec=0.070, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
[1950/2000] tot_loss=1.440 (perp=6.870, rec=0.065, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Attempt swap
[2000/2000] tot_loss=1.439 (perp=6.870, rec=0.064, cos=0.001), tot_loss_proj:1.713 [t=0.17s]
prediction: ['[CLS] how ridiculous and money oriented - [SEP]']
Done with input #90 of 100.
reference: 
========================
[CLS] how ridiculous and money - oriented [SEP]
========================
predicted: 
========================
[CLS] how ridiculous and money oriented - [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.201 | p: 88.518 | r: 90.049
rouge2     | fm: 54.449 | p: 54.158 | r: 54.767
rougeL     | fm: 77.393 | p: 76.815 | r: 78.082
rougeLsum  | fm: 77.325 | p: 76.766 | r: 78.031
r1fm+r2fm = 143.651

input #90 time: 0:06:42 | total time: 12:10:56


Running input #91 of 100.
reference: 
========================
muy loco , but no more ridiculous 
========================
average of cosine similarity 0.9993538374859834
highest_index [0]
highest [0.9993538374859834]
Debug: ids_shape = 10, pads = [10]
Debug: input ids = tensor([[  101, 14163,  2100, 28046,  1010,  2021,  2053,  2062,  9951,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] muy loco, but no more ridiculous [SEP]']
[Init] best rec loss: 1.8815274238586426 for ['[CLS] gravel effective snarled lighterogammed fans sometime [SEP]']
[Init] best rec loss: 1.5670865774154663 for ['[CLS] landssulłdotenick own get distant [SEP]']
[Init] best rec loss: 1.5520261526107788 for ['[CLS] blind prop notice taxis tang exchanged charge underlying [SEP]']
[Init] best rec loss: 1.24383544921875 for ['[CLS] mollusk jesuit fake software automaticaar verbal machine [SEP]']
[Init] best rec loss: 1.160547137260437 for ['[CLS] doubled regimental baby cement י game ultimate ideal [SEP]']
[Init] best rec loss: 1.1217325925827026 for ['[CLS] apollo lucia umpire skip gentleman grandmothergna line [SEP]']
[Init] best rec loss: 1.0907552242279053 for ['[CLS] choice seedbol transport anti if stairs guys [SEP]']
[Init] best rec loss: 1.0540754795074463 for ['[CLS]lippment revolution ponydern shelter hard unknown [SEP]']
[Init] best perm rec loss: 1.0526354312896729 for ['[CLS] unknown shelterpmentlipdern hard revolution pony [SEP]']
[Init] best perm rec loss: 1.0524038076400757 for ['[CLS]pmentlip pony revolution unknown harddern shelter [SEP]']
[Init] best perm rec loss: 1.05027437210083 for ['[CLS]lip revolution hard ponydern unknownpment shelter [SEP]']
[Init] best perm rec loss: 1.0482343435287476 for ['[CLS]lip unknownpment revolution shelterdern hard pony [SEP]']
[Init] best perm rec loss: 1.0455262660980225 for ['[CLS]lip revolutionpment unknown harddern shelter pony [SEP]']
[Init] best perm rec loss: 1.0435428619384766 for ['[CLS] shelterdern revolution hardlippment unknown pony [SEP]']
[Init] best perm rec loss: 1.0432696342468262 for ['[CLS] harddernlippment shelter revolution unknown pony [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.605 (perp=11.363, rec=0.305, cos=0.027), tot_loss_proj:3.131 [t=0.17s]
prediction: ['[CLS] bi nasty rid. mo ridiculous ridiculous loco [SEP]']
[ 100/2000] tot_loss=2.344 (perp=10.041, rec=0.259, cos=0.077), tot_loss_proj:2.697 [t=0.17s]
prediction: ['[CLS] but loco loco but mo ridiculous loco loco [SEP]']
[ 150/2000] tot_loss=2.032 (perp=9.236, rec=0.170, cos=0.014), tot_loss_proj:2.548 [t=0.17s]
prediction: ['[CLS] no locoy but mu ridiculous loco more [SEP]']
[ 200/2000] tot_loss=1.971 (perp=9.236, rec=0.118, cos=0.006), tot_loss_proj:2.550 [t=0.17s]
prediction: ['[CLS] no locoy but mu ridiculous loco more [SEP]']
Attempt swap
Moved sequence
[ 250/2000] tot_loss=1.946 (perp=9.220, rec=0.097, cos=0.005), tot_loss_proj:2.575 [t=0.17s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[ 300/2000] tot_loss=1.929 (perp=9.220, rec=0.082, cos=0.003), tot_loss_proj:2.571 [t=0.17s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.915 (perp=9.220, rec=0.069, cos=0.003), tot_loss_proj:2.577 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.929 (perp=9.220, rec=0.082, cos=0.003), tot_loss_proj:2.573 [t=0.18s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[ 450/2000] tot_loss=1.925 (perp=9.220, rec=0.079, cos=0.003), tot_loss_proj:2.584 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.922 (perp=9.220, rec=0.075, cos=0.003), tot_loss_proj:2.579 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.927 (perp=9.220, rec=0.080, cos=0.002), tot_loss_proj:2.581 [t=0.18s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[ 600/2000] tot_loss=1.921 (perp=9.220, rec=0.074, cos=0.002), tot_loss_proj:2.581 [t=0.18s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.930 (perp=9.220, rec=0.083, cos=0.002), tot_loss_proj:2.578 [t=0.18s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.929 (perp=9.220, rec=0.082, cos=0.002), tot_loss_proj:2.576 [t=0.17s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[ 750/2000] tot_loss=1.914 (perp=9.220, rec=0.067, cos=0.002), tot_loss_proj:2.585 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.919 (perp=9.220, rec=0.072, cos=0.002), tot_loss_proj:2.582 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.918 (perp=9.220, rec=0.071, cos=0.002), tot_loss_proj:2.582 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[ 900/2000] tot_loss=1.925 (perp=9.220, rec=0.079, cos=0.002), tot_loss_proj:2.577 [t=0.18s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.925 (perp=9.220, rec=0.078, cos=0.002), tot_loss_proj:2.591 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1000/2000] tot_loss=1.930 (perp=9.220, rec=0.084, cos=0.002), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[1050/2000] tot_loss=1.924 (perp=9.220, rec=0.078, cos=0.002), tot_loss_proj:2.582 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1100/2000] tot_loss=1.920 (perp=9.220, rec=0.074, cos=0.002), tot_loss_proj:2.582 [t=0.17s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1150/2000] tot_loss=1.916 (perp=9.220, rec=0.070, cos=0.002), tot_loss_proj:2.584 [t=0.18s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[1200/2000] tot_loss=1.914 (perp=9.220, rec=0.067, cos=0.002), tot_loss_proj:2.582 [t=0.18s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1250/2000] tot_loss=1.922 (perp=9.220, rec=0.076, cos=0.002), tot_loss_proj:2.586 [t=0.18s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1300/2000] tot_loss=1.917 (perp=9.220, rec=0.070, cos=0.002), tot_loss_proj:2.589 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[1350/2000] tot_loss=1.921 (perp=9.220, rec=0.075, cos=0.002), tot_loss_proj:2.583 [t=0.20s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1400/2000] tot_loss=1.909 (perp=9.220, rec=0.063, cos=0.002), tot_loss_proj:2.583 [t=0.17s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1450/2000] tot_loss=1.918 (perp=9.220, rec=0.072, cos=0.002), tot_loss_proj:2.586 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[1500/2000] tot_loss=1.925 (perp=9.220, rec=0.078, cos=0.002), tot_loss_proj:2.585 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1550/2000] tot_loss=1.921 (perp=9.220, rec=0.075, cos=0.002), tot_loss_proj:2.582 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1600/2000] tot_loss=1.918 (perp=9.220, rec=0.072, cos=0.002), tot_loss_proj:2.585 [t=0.18s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
[1650/2000] tot_loss=1.929 (perp=9.220, rec=0.083, cos=0.002), tot_loss_proj:2.582 [t=0.19s]
prediction: ['[CLS] no muy loco but mu ridiculous more [SEP]']
Attempt swap
[1700/2000] tot_loss=1.921 (perp=9.207, rec=0.078, cos=0.002), tot_loss_proj:2.440 [t=0.18s]
prediction: ['[CLS] no muy loco but, ridiculous more [SEP]']
Attempt swap
Swapped tokens
[1750/2000] tot_loss=1.733 (perp=8.279, rec=0.075, cos=0.002), tot_loss_proj:2.280 [t=0.18s]
prediction: ['[CLS] no muy loco but, more ridiculous [SEP]']
[1800/2000] tot_loss=1.730 (perp=8.279, rec=0.072, cos=0.002), tot_loss_proj:2.276 [t=0.18s]
prediction: ['[CLS] no muy loco but, more ridiculous [SEP]']
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.657 (perp=7.929, rec=0.069, cos=0.002), tot_loss_proj:2.431 [t=0.19s]
prediction: ['[CLS] no muy, but loco more ridiculous [SEP]']
Attempt swap
[1900/2000] tot_loss=1.655 (perp=7.929, rec=0.067, cos=0.002), tot_loss_proj:2.429 [t=0.19s]
prediction: ['[CLS] no muy, but loco more ridiculous [SEP]']
[1950/2000] tot_loss=1.653 (perp=7.929, rec=0.066, cos=0.002), tot_loss_proj:2.430 [t=0.20s]
prediction: ['[CLS] no muy, but loco more ridiculous [SEP]']
Attempt swap
[2000/2000] tot_loss=1.648 (perp=7.929, rec=0.060, cos=0.002), tot_loss_proj:2.432 [t=0.19s]
prediction: ['[CLS] no muy, but loco more ridiculous [SEP]']
Done with input #91 of 100.
reference: 
========================
[CLS] muy loco, but no more ridiculous [SEP]
========================
predicted: 
========================
[CLS] no muy, but loco more ridiculous [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 28.571 | p: 28.571 | r: 28.571
rougeL     | fm: 75.000 | p: 75.000 | r: 75.000
rougeLsum  | fm: 75.000 | p: 75.000 | r: 75.000
r1fm+r2fm = 128.571

[Aggregate metrics]:
rouge1     | fm: 89.229 | p: 88.573 | r: 90.054
rouge2     | fm: 54.216 | p: 53.924 | r: 54.521
rougeL     | fm: 77.421 | p: 76.859 | r: 78.093
rougeLsum  | fm: 77.314 | p: 76.748 | r: 77.996
r1fm+r2fm = 143.445

input #91 time: 0:07:08 | total time: 12:18:05


Running input #92 of 100.
reference: 
========================
deceit 
========================
average of cosine similarity 0.9993137310302476
highest_index [0]
highest [0.9993137310302476]
Debug: ids_shape = 4, pads = [4]
Debug: input ids = tensor([[  101, 11703, 20175,   102]], device='cuda:0')
Debug: ref = ['[CLS] deceit [SEP]']
[Init] best rec loss: 1.81099534034729 for ['[CLS] damncoat [SEP]']
[Init] best rec loss: 1.76921546459198 for ['[CLS] franz counter [SEP]']
[Init] best rec loss: 1.7248120307922363 for ['[CLS] false issue [SEP]']
[Init] best rec loss: 1.6912018060684204 for ['[CLS] mandatory maneuver [SEP]']
[Init] best rec loss: 1.4354274272918701 for ['[CLS] mine may [SEP]']
[Init] best rec loss: 1.4101020097732544 for ['[CLS] wish rich [SEP]']
[Init] best rec loss: 1.2274341583251953 for ['[CLS] tank lonely [SEP]']
[Init] best perm rec loss: 1.2247881889343262 for ['[CLS] lonely tank [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.630 (perp=12.265, rec=0.171, cos=0.006), tot_loss_proj:3.210 [t=0.17s]
prediction: ['[CLS] erroreit [SEP]']
[ 100/2000] tot_loss=1.592 (perp=7.646, rec=0.061, cos=0.002), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 150/2000] tot_loss=1.592 (perp=7.646, rec=0.061, cos=0.002), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 200/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 250/2000] tot_loss=1.580 (perp=7.646, rec=0.049, cos=0.002), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 300/2000] tot_loss=1.586 (perp=7.646, rec=0.055, cos=0.002), tot_loss_proj:1.595 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.599 (perp=7.646, rec=0.068, cos=0.001), tot_loss_proj:1.612 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.605 (perp=7.646, rec=0.074, cos=0.001), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 450/2000] tot_loss=1.605 (perp=7.646, rec=0.075, cos=0.001), tot_loss_proj:1.604 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.596 (perp=7.646, rec=0.066, cos=0.001), tot_loss_proj:1.590 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 600/2000] tot_loss=1.594 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.596 (perp=7.646, rec=0.065, cos=0.001), tot_loss_proj:1.605 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 750/2000] tot_loss=1.601 (perp=7.646, rec=0.071, cos=0.001), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.584 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.603 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.594 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.598 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[ 900/2000] tot_loss=1.595 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.596 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.576 (perp=7.646, rec=0.046, cos=0.001), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1000/2000] tot_loss=1.588 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1050/2000] tot_loss=1.582 (perp=7.646, rec=0.051, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1100/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1150/2000] tot_loss=1.591 (perp=7.646, rec=0.061, cos=0.001), tot_loss_proj:1.578 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1200/2000] tot_loss=1.606 (perp=7.646, rec=0.076, cos=0.001), tot_loss_proj:1.610 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1250/2000] tot_loss=1.604 (perp=7.646, rec=0.073, cos=0.001), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1300/2000] tot_loss=1.586 (perp=7.646, rec=0.055, cos=0.001), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1350/2000] tot_loss=1.570 (perp=7.646, rec=0.040, cos=0.001), tot_loss_proj:1.584 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1400/2000] tot_loss=1.594 (perp=7.646, rec=0.064, cos=0.001), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1450/2000] tot_loss=1.583 (perp=7.646, rec=0.053, cos=0.001), tot_loss_proj:1.600 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1500/2000] tot_loss=1.585 (perp=7.646, rec=0.054, cos=0.001), tot_loss_proj:1.581 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1550/2000] tot_loss=1.600 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.583 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1600/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.589 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1650/2000] tot_loss=1.586 (perp=7.646, rec=0.056, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1700/2000] tot_loss=1.580 (perp=7.646, rec=0.049, cos=0.001), tot_loss_proj:1.593 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1750/2000] tot_loss=1.601 (perp=7.646, rec=0.070, cos=0.001), tot_loss_proj:1.592 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1800/2000] tot_loss=1.593 (perp=7.646, rec=0.063, cos=0.001), tot_loss_proj:1.591 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1850/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.588 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[1900/2000] tot_loss=1.590 (perp=7.646, rec=0.060, cos=0.001), tot_loss_proj:1.594 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
[1950/2000] tot_loss=1.587 (perp=7.646, rec=0.057, cos=0.001), tot_loss_proj:1.587 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Attempt swap
[2000/2000] tot_loss=1.593 (perp=7.646, rec=0.062, cos=0.001), tot_loss_proj:1.597 [t=0.17s]
prediction: ['[CLS] deceit [SEP]']
Done with input #92 of 100.
reference: 
========================
[CLS] deceit [SEP]
========================
predicted: 
========================
[CLS] deceit [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.396 | p: 88.681 | r: 90.256
rouge2     | fm: 54.623 | p: 54.334 | r: 54.931
rougeL     | fm: 77.658 | p: 77.129 | r: 78.306
rougeLsum  | fm: 77.620 | p: 77.009 | r: 78.272
r1fm+r2fm = 144.019

input #92 time: 0:06:46 | total time: 12:24:52


Running input #93 of 100.
reference: 
========================
in its understanding , often funny way 
========================
average of cosine similarity 0.9993323263895038
highest_index [0]
highest [0.9993323263895038]
Debug: ids_shape = 9, pads = [9]
Debug: input ids = tensor([[ 101, 1999, 2049, 4824, 1010, 2411, 6057, 2126,  102]],
       device='cuda:0')
Debug: ref = ['[CLS] in its understanding, often funny way [SEP]']
[Init] best rec loss: 1.9964412450790405 for ['[CLS] pennsylvaniaplay after polish best foe sparhawk [SEP]']
[Init] best rec loss: 1.804612159729004 for ['[CLS]tz being fluent nevernished clinging met [SEP]']
[Init] best rec loss: 1.764283537864685 for ['[CLS] will individual unitsbular absent lights distribution [SEP]']
[Init] best rec loss: 1.7488878965377808 for ['[CLS] overall teachers you helping parkmedia neutral [SEP]']
[Init] best rec loss: 1.7436745166778564 for ['[CLS] lucas war breaks baby my pauline divided [SEP]']
[Init] best rec loss: 1.738550066947937 for ['[CLS] village tallest almost giro opened wine section [SEP]']
[Init] best rec loss: 1.5410614013671875 for ['[CLS] [CLS]rac madonna premiership further jeremy colby [SEP]']
[Init] best perm rec loss: 1.5395601987838745 for ['[CLS]rac jeremy madonna further premiership [CLS] colby [SEP]']
[Init] best perm rec loss: 1.536518931388855 for ['[CLS] madonna premiership jeremy further colby [CLS]rac [SEP]']
[Init] best perm rec loss: 1.5341161489486694 for ['[CLS] madonna premiership colbyrac [CLS] further jeremy [SEP]']
[Init] best perm rec loss: 1.5311251878738403 for ['[CLS] further madonna jeremy [CLS] colby premiershiprac [SEP]']
[Init] best perm rec loss: 1.5273934602737427 for ['[CLS] colby madonna premiership further jeremyrac [CLS] [SEP]']
[Init] best perm rec loss: 1.525164246559143 for ['[CLS] further madonnarac colby jeremy premiership [CLS] [SEP]']
[Init] best perm rec loss: 1.5250414609909058 for ['[CLS] premiership jeremy madonnarac colby further [CLS] [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.449 (perp=10.738, rec=0.289, cos=0.012), tot_loss_proj:3.118 [t=0.17s]
prediction: ['[CLS] sometimes brian jay funny sometimes understanding funny [SEP]']
[ 100/2000] tot_loss=2.117 (perp=9.535, rec=0.205, cos=0.005), tot_loss_proj:2.677 [t=0.17s]
prediction: ['[CLS] sometimes in in funny sometimes understanding way [SEP]']
[ 150/2000] tot_loss=2.151 (perp=10.102, rec=0.126, cos=0.004), tot_loss_proj:2.351 [t=0.17s]
prediction: ['[CLS] its, in funny often understanding way [SEP]']
[ 200/2000] tot_loss=2.142 (perp=10.102, rec=0.117, cos=0.004), tot_loss_proj:2.352 [t=0.17s]
prediction: ['[CLS] its, in funny often understanding way [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.781 (perp=8.377, rec=0.103, cos=0.002), tot_loss_proj:2.065 [t=0.17s]
prediction: ['[CLS] understanding, in funny often its way [SEP]']
[ 300/2000] tot_loss=1.747 (perp=8.377, rec=0.070, cos=0.001), tot_loss_proj:2.065 [t=0.17s]
prediction: ['[CLS] understanding, in funny often its way [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.458 (perp=6.937, rec=0.069, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.452 (perp=6.937, rec=0.063, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 450/2000] tot_loss=1.451 (perp=6.937, rec=0.063, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.451 (perp=6.937, rec=0.062, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.444 (perp=6.937, rec=0.055, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 600/2000] tot_loss=1.449 (perp=6.937, rec=0.060, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.460 (perp=6.937, rec=0.072, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.451 (perp=6.937, rec=0.062, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 750/2000] tot_loss=1.447 (perp=6.937, rec=0.058, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.463 (perp=6.937, rec=0.074, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.444 (perp=6.937, rec=0.056, cos=0.001), tot_loss_proj:1.698 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[ 900/2000] tot_loss=1.449 (perp=6.937, rec=0.060, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.458 (perp=6.937, rec=0.069, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1000/2000] tot_loss=1.439 (perp=6.937, rec=0.050, cos=0.001), tot_loss_proj:1.705 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1050/2000] tot_loss=1.455 (perp=6.937, rec=0.066, cos=0.001), tot_loss_proj:1.696 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1100/2000] tot_loss=1.446 (perp=6.937, rec=0.057, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1150/2000] tot_loss=1.462 (perp=6.937, rec=0.073, cos=0.001), tot_loss_proj:1.700 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1200/2000] tot_loss=1.457 (perp=6.937, rec=0.068, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1250/2000] tot_loss=1.450 (perp=6.937, rec=0.062, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1300/2000] tot_loss=1.448 (perp=6.937, rec=0.059, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1350/2000] tot_loss=1.451 (perp=6.937, rec=0.062, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1400/2000] tot_loss=1.453 (perp=6.937, rec=0.064, cos=0.001), tot_loss_proj:1.697 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1450/2000] tot_loss=1.452 (perp=6.937, rec=0.063, cos=0.001), tot_loss_proj:1.704 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1500/2000] tot_loss=1.458 (perp=6.937, rec=0.070, cos=0.001), tot_loss_proj:1.708 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1550/2000] tot_loss=1.453 (perp=6.937, rec=0.064, cos=0.001), tot_loss_proj:1.706 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1600/2000] tot_loss=1.450 (perp=6.937, rec=0.061, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1650/2000] tot_loss=1.453 (perp=6.937, rec=0.065, cos=0.001), tot_loss_proj:1.699 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1700/2000] tot_loss=1.449 (perp=6.937, rec=0.060, cos=0.001), tot_loss_proj:1.703 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1750/2000] tot_loss=1.448 (perp=6.937, rec=0.059, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1800/2000] tot_loss=1.454 (perp=6.937, rec=0.065, cos=0.001), tot_loss_proj:1.702 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1850/2000] tot_loss=1.452 (perp=6.937, rec=0.063, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[1900/2000] tot_loss=1.456 (perp=6.937, rec=0.068, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
[1950/2000] tot_loss=1.454 (perp=6.937, rec=0.065, cos=0.001), tot_loss_proj:1.701 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Attempt swap
[2000/2000] tot_loss=1.451 (perp=6.937, rec=0.062, cos=0.001), tot_loss_proj:1.707 [t=0.17s]
prediction: ['[CLS] understanding, in its often funny way [SEP]']
Done with input #93 of 100.
reference: 
========================
[CLS] in its understanding, often funny way [SEP]
========================
predicted: 
========================
[CLS] understanding, in its often funny way [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 57.143 | p: 57.143 | r: 57.143
rougeL     | fm: 87.500 | p: 87.500 | r: 87.500
rougeLsum  | fm: 87.500 | p: 87.500 | r: 87.500
r1fm+r2fm = 157.143

[Aggregate metrics]:
rouge1     | fm: 89.476 | p: 88.850 | r: 90.283
rouge2     | fm: 54.769 | p: 54.486 | r: 55.124
rougeL     | fm: 77.757 | p: 77.199 | r: 78.434
rougeLsum  | fm: 77.696 | p: 77.173 | r: 78.350
r1fm+r2fm = 144.245

input #93 time: 0:06:47 | total time: 12:31:39


Running input #94 of 100.
reference: 
========================
a caper that 's neither original nor terribly funny 
========================
average of cosine similarity 0.9993168061064917
highest_index [0]
highest [0.9993168061064917]
Debug: ids_shape = 13, pads = [13]
Debug: input ids = tensor([[  101,  1037,  4880,  2099,  2008,  1005,  1055,  4445,  2434,  4496,
         16668,  6057,   102]], device='cuda:0')
Debug: ref = ["[CLS] a caper that's neither original nor terribly funny [SEP]"]
[Init] best rec loss: 1.9509918689727783 for ['[CLS] address am forms census depending nolan rumor constantly paste indoorsizan [SEP]']
[Init] best rec loss: 1.9232128858566284 for ['[CLS] milling library casual constructed board equationphs similaron cookies intended [SEP]']
[Init] best rec loss: 1.8279337882995605 for ['[CLS] scent crosses am history single connections set likeuatingface other [SEP]']
[Init] best rec loss: 1.823370099067688 for ['[CLS]ser straight alligator inches subject never splashed pony des withancy [SEP]']
[Init] best rec loss: 1.5088582038879395 for ['[CLS]rite branches experiences guitarist chart wife [CLS] toe grandpa floor no [SEP]']
[Init] best rec loss: 1.4581665992736816 for ['[CLS]pour matters bad slowedble bow spirititercedeer mir [SEP]']
[Init] best rec loss: 1.445499062538147 for ['[CLS]venting rockwell internal expedition plum chronic shocks flowering territorial crushed centre [SEP]']
[Init] best perm rec loss: 1.4265179634094238 for ['[CLS] shocks territorial rockwell internal crushedventing expedition centre flowering chronic plum [SEP]']
[Init] best perm rec loss: 1.4207502603530884 for ['[CLS] internal plum flowering expedition territorial shocks chronic centre crushed rockwellventing [SEP]']
[Init] best perm rec loss: 1.4164097309112549 for ['[CLS] centreventing flowering expedition shocks chronic crushed internal rockwell territorial plum [SEP]']
[Init] best perm rec loss: 1.4148106575012207 for ['[CLS] chronicventing territorial expedition shocks crushed centre internal rockwell flowering plum [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.627 (perp=11.481, rec=0.317, cos=0.014), tot_loss_proj:3.249 [t=0.17s]
prediction: ['[CLS] nor fur neither nor clean none costume have neither funny neither [SEP]']
[ 100/2000] tot_loss=2.566 (perp=11.899, rec=0.180, cos=0.007), tot_loss_proj:3.072 [t=0.17s]
prediction: ['[CLS] terribly cape neither nor original another neither have nor funny neither [SEP]']
[ 150/2000] tot_loss=2.215 (perp=10.602, rec=0.093, cos=0.002), tot_loss_proj:2.672 [t=0.17s]
prediction: ['[CLS] terribly cape neither s original a cape that nor funny neither [SEP]']
[ 200/2000] tot_loss=2.207 (perp=10.602, rec=0.085, cos=0.002), tot_loss_proj:2.684 [t=0.17s]
prediction: ['[CLS] terribly cape neither s original a cape that nor funny neither [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.985 (perp=9.462, rec=0.091, cos=0.002), tot_loss_proj:2.468 [t=0.21s]
prediction: ['[CLS] terribly neitherr s original a cape that nor funny cape [SEP]']
[ 300/2000] tot_loss=1.965 (perp=9.462, rec=0.072, cos=0.001), tot_loss_proj:2.475 [t=0.17s]
prediction: ['[CLS] terribly neitherr s original a cape that nor funny cape [SEP]']
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.733 (perp=8.303, rec=0.071, cos=0.001), tot_loss_proj:2.228 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor funny cape [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.728 (perp=8.303, rec=0.065, cos=0.001), tot_loss_proj:2.228 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor funny cape [SEP]']
[ 450/2000] tot_loss=1.730 (perp=8.303, rec=0.068, cos=0.001), tot_loss_proj:2.231 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor funny cape [SEP]']
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.706 (perp=8.227, rec=0.059, cos=0.001), tot_loss_proj:2.199 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.707 (perp=8.227, rec=0.060, cos=0.001), tot_loss_proj:2.192 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[ 600/2000] tot_loss=1.708 (perp=8.227, rec=0.061, cos=0.001), tot_loss_proj:2.192 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.712 (perp=8.227, rec=0.065, cos=0.001), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.689 (perp=8.227, rec=0.042, cos=0.001), tot_loss_proj:2.195 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[ 750/2000] tot_loss=1.713 (perp=8.227, rec=0.066, cos=0.001), tot_loss_proj:2.193 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.713 (perp=8.227, rec=0.067, cos=0.001), tot_loss_proj:2.192 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.708 (perp=8.227, rec=0.062, cos=0.001), tot_loss_proj:2.190 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[ 900/2000] tot_loss=1.705 (perp=8.227, rec=0.059, cos=0.001), tot_loss_proj:2.192 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.714 (perp=8.227, rec=0.067, cos=0.001), tot_loss_proj:2.193 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1000/2000] tot_loss=1.714 (perp=8.227, rec=0.067, cos=0.001), tot_loss_proj:2.192 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[1050/2000] tot_loss=1.711 (perp=8.227, rec=0.064, cos=0.001), tot_loss_proj:2.190 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1100/2000] tot_loss=1.704 (perp=8.227, rec=0.057, cos=0.001), tot_loss_proj:2.195 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1150/2000] tot_loss=1.702 (perp=8.227, rec=0.055, cos=0.001), tot_loss_proj:2.190 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[1200/2000] tot_loss=1.714 (perp=8.227, rec=0.067, cos=0.001), tot_loss_proj:2.195 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1250/2000] tot_loss=1.718 (perp=8.227, rec=0.071, cos=0.001), tot_loss_proj:2.196 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1300/2000] tot_loss=1.715 (perp=8.227, rec=0.068, cos=0.001), tot_loss_proj:2.192 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[1350/2000] tot_loss=1.707 (perp=8.227, rec=0.060, cos=0.001), tot_loss_proj:2.185 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1400/2000] tot_loss=1.713 (perp=8.227, rec=0.066, cos=0.001), tot_loss_proj:2.187 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1450/2000] tot_loss=1.712 (perp=8.227, rec=0.066, cos=0.001), tot_loss_proj:2.193 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[1500/2000] tot_loss=1.704 (perp=8.227, rec=0.057, cos=0.001), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1550/2000] tot_loss=1.709 (perp=8.227, rec=0.062, cos=0.001), tot_loss_proj:2.193 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1600/2000] tot_loss=1.714 (perp=8.227, rec=0.067, cos=0.001), tot_loss_proj:2.190 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[1650/2000] tot_loss=1.720 (perp=8.227, rec=0.073, cos=0.001), tot_loss_proj:2.196 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1700/2000] tot_loss=1.714 (perp=8.227, rec=0.067, cos=0.001), tot_loss_proj:2.192 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1750/2000] tot_loss=1.706 (perp=8.227, rec=0.059, cos=0.001), tot_loss_proj:2.188 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[1800/2000] tot_loss=1.718 (perp=8.227, rec=0.071, cos=0.001), tot_loss_proj:2.186 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1850/2000] tot_loss=1.716 (perp=8.227, rec=0.069, cos=0.001), tot_loss_proj:2.193 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[1900/2000] tot_loss=1.717 (perp=8.227, rec=0.070, cos=0.001), tot_loss_proj:2.183 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
[1950/2000] tot_loss=1.703 (perp=8.227, rec=0.056, cos=0.001), tot_loss_proj:2.189 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Attempt swap
[2000/2000] tot_loss=1.719 (perp=8.227, rec=0.073, cos=0.001), tot_loss_proj:2.186 [t=0.17s]
prediction: ['[CLS] that neitherr s original a cape terribly nor cape funny [SEP]']
Done with input #94 of 100.
reference: 
========================
[CLS] a caper that's neither original nor terribly funny [SEP]
========================
predicted: 
========================
[CLS] that neitherr s original a cape terribly nor cape funny [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 78.261 | p: 75.000 | r: 81.818
rouge2     | fm: 9.524 | p: 9.091 | r: 10.000
rougeL     | fm: 60.870 | p: 58.333 | r: 63.636
rougeLsum  | fm: 60.870 | p: 58.333 | r: 63.636
r1fm+r2fm = 87.785

[Aggregate metrics]:
rouge1     | fm: 89.390 | p: 88.703 | r: 90.220
rouge2     | fm: 54.325 | p: 53.998 | r: 54.656
rougeL     | fm: 77.631 | p: 77.042 | r: 78.369
rougeLsum  | fm: 77.528 | p: 76.978 | r: 78.252
r1fm+r2fm = 143.715

input #94 time: 0:06:47 | total time: 12:38:27


Running input #95 of 100.
reference: 
========================
( denis ' ) story becomes a hopeless , unsatisfying muddle 
========================
average of cosine similarity 0.9991574288984811
highest_index [0]
highest [0.9991574288984811]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[  101,  1006, 11064,  1005,  1007,  2466,  4150,  1037, 20625,  1010,
          4895, 16846,  2483, 14116,  8494, 10362,   102]], device='cuda:0')
Debug: ref = ["[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]"]
[Init] best rec loss: 1.9503685235977173 for ['[CLS] condition leon cup began habitc boy floor imperial major i sud inside missed over [SEP]']
[Init] best rec loss: 1.9354028701782227 for ['[CLS] bree theological teaching maybe backed past starvinglusion pigs twitcharable badic flower able [SEP]']
[Init] best rec loss: 1.8349953889846802 for ['[CLS] channel congestion approach nude scottful performing blackout suffered introduced ground sr planted evans declared [SEP]']
[Init] best rec loss: 1.8156688213348389 for ['[CLS]ian media ye deposit cook point tied ranking original mean believe cellular neon scrolls next [SEP]']
[Init] best rec loss: 1.7410764694213867 for ['[CLS] rage campulsion exitscribe thought countrer pain rubin shop second bowler vinyl fitch [SEP]']
[Init] best rec loss: 1.6973210573196411 for ['[CLS] paul jai employer smell han roosevelt extinct scar duty volga charley sprint back fashioned paige [SEP]']
[Init] best rec loss: 1.6551605463027954 for ['[CLS] fire some phillip margin khz number grace discipline formula plains when secretarygrave duke hell [SEP]']
[Init] best rec loss: 1.560425043106079 for ['[CLS] end output rather overall of byron inventor earth interests novel adult heir night bryan remaining [SEP]']
[Init] best rec loss: 1.3368700742721558 for ['[CLS] pressure ] completenne damp trailer block wireے tech sister private cut monty hanging [SEP]']
[Init] best perm rec loss: 1.3238457441329956 for ['[CLS] trailer private cut dampnne hanging block ] complete wire sisterے pressure monty tech [SEP]']
[Init] best perm rec loss: 1.3197247982025146 for ['[CLS] ] damp tech trailer cut privateے hanging block complete monty pressure sister wirenne [SEP]']
[Init] best perm rec loss: 1.319675087928772 for ['[CLS] damp pressure techے monty sister private cut complete trailer hanging ] wire blocknne [SEP]']
[Init] best perm rec loss: 1.3172006607055664 for ['[CLS] ] cut private technne monty trailer block sister wire dampے hanging complete pressure [SEP]']
[Init] best perm rec loss: 1.3129985332489014 for ['[CLS] monty sister private cut tech trailer wire block hangingnne damp ]ے complete pressure [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.466 (perp=10.976, rec=0.262, cos=0.008), tot_loss_proj:2.838 [t=0.17s]
prediction: ['[CLS] hopeless bed private housing, ( ship storage against hopeless pathetic hopeless career became hopeless [SEP]']
[ 100/2000] tot_loss=2.516 (perp=11.703, rec=0.171, cos=0.004), tot_loss_proj:2.829 [t=0.17s]
prediction: ['[CLS] the mud a tub, hopeless shipdle againstsatfying hopeless story becomes hopeless [SEP]']
[ 150/2000] tot_loss=2.319 (perp=10.889, rec=0.137, cos=0.004), tot_loss_proj:2.756 [t=0.17s]
prediction: ["[CLS]'mud adle, a shipdle naivesatfying hopeless story becomesdle [SEP]"]
[ 200/2000] tot_loss=2.565 (perp=11.948, rec=0.170, cos=0.005), tot_loss_proj:2.966 [t=0.17s]
prediction: ["[CLS]'mud adle, a irishdle clementsatfying hopeless story becomesdle [SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.052 (perp=9.656, rec=0.118, cos=0.003), tot_loss_proj:2.488 [t=0.17s]
prediction: ["[CLS]'a muddle, a dnadle clementsatfying hopeless story becomesdle [SEP]"]
[ 300/2000] tot_loss=2.124 (perp=10.099, rec=0.101, cos=0.003), tot_loss_proj:2.540 [t=0.17s]
prediction: ["[CLS]'a muddle, a denisdle clementsatfying hopeless story becomesdle [SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=2.275 (perp=10.815, rec=0.110, cos=0.003), tot_loss_proj:2.633 [t=0.17s]
prediction: ["[CLS]'a mud ) becomes un denisdle (satfying hopeless story,dle [SEP]"]
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.912 (perp=9.012, rec=0.107, cos=0.002), tot_loss_proj:2.237 [t=0.17s]
prediction: ["[CLS]'a muddle becomes un denisdle (satfying hopeless story, ) [SEP]"]
[ 450/2000] tot_loss=2.076 (perp=9.867, rec=0.101, cos=0.002), tot_loss_proj:2.437 [t=0.17s]
prediction: ["[CLS]'a muddle becomes ( denisdle (satfying hopeless story, ) [SEP]"]
Attempt swap
Moved token
[ 500/2000] tot_loss=1.848 (perp=8.773, rec=0.091, cos=0.003), tot_loss_proj:2.242 [t=0.17s]
prediction: ["[CLS] ('a muddle becomes denisdle (satfying hopeless story, ) [SEP]"]
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.950 (perp=9.274, rec=0.092, cos=0.002), tot_loss_proj:2.405 [t=0.17s]
prediction: ["[CLS] ('a mud story becomes denisdle (satfying hopeless un, ) [SEP]"]
[ 600/2000] tot_loss=1.946 (perp=9.274, rec=0.089, cos=0.002), tot_loss_proj:2.398 [t=0.17s]
prediction: ["[CLS] ('a mud story becomes denisdle (satfying hopeless un, ) [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.737 (perp=8.232, rec=0.088, cos=0.002), tot_loss_proj:2.262 [t=0.17s]
prediction: ["[CLS] ('a mud story becomes denisdle (sat un hopelessfying, ) [SEP]"]
Attempt swap
Moved sequence
[ 700/2000] tot_loss=1.569 (perp=7.357, rec=0.095, cos=0.002), tot_loss_proj:2.265 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat un hopelessfying, ) [SEP]"]
[ 750/2000] tot_loss=1.572 (perp=7.357, rec=0.098, cos=0.002), tot_loss_proj:2.274 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat un hopelessfying, ) [SEP]"]
Attempt swap
Moved token
[ 800/2000] tot_loss=1.509 (perp=7.070, rec=0.092, cos=0.002), tot_loss_proj:2.214 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[ 850/2000] tot_loss=1.499 (perp=7.070, rec=0.083, cos=0.002), tot_loss_proj:2.217 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
[ 900/2000] tot_loss=1.504 (perp=7.070, rec=0.088, cos=0.002), tot_loss_proj:2.197 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[ 950/2000] tot_loss=1.501 (perp=7.070, rec=0.085, cos=0.002), tot_loss_proj:2.207 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1000/2000] tot_loss=1.502 (perp=7.070, rec=0.086, cos=0.002), tot_loss_proj:2.192 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
[1050/2000] tot_loss=1.499 (perp=7.070, rec=0.083, cos=0.002), tot_loss_proj:2.193 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1100/2000] tot_loss=1.493 (perp=7.070, rec=0.077, cos=0.002), tot_loss_proj:2.132 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1150/2000] tot_loss=1.506 (perp=7.070, rec=0.089, cos=0.002), tot_loss_proj:2.102 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
[1200/2000] tot_loss=1.504 (perp=7.070, rec=0.088, cos=0.002), tot_loss_proj:2.087 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1250/2000] tot_loss=1.489 (perp=7.070, rec=0.073, cos=0.002), tot_loss_proj:2.064 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.501 (perp=7.070, rec=0.085, cos=0.002), tot_loss_proj:1.976 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
[1350/2000] tot_loss=1.481 (perp=7.070, rec=0.065, cos=0.002), tot_loss_proj:1.980 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1400/2000] tot_loss=1.496 (perp=7.070, rec=0.080, cos=0.002), tot_loss_proj:1.981 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1450/2000] tot_loss=1.501 (perp=7.070, rec=0.085, cos=0.002), tot_loss_proj:1.988 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
[1500/2000] tot_loss=1.483 (perp=7.070, rec=0.067, cos=0.002), tot_loss_proj:1.996 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1550/2000] tot_loss=1.480 (perp=7.070, rec=0.064, cos=0.002), tot_loss_proj:1.996 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1600/2000] tot_loss=1.489 (perp=7.070, rec=0.073, cos=0.002), tot_loss_proj:1.994 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
[1650/2000] tot_loss=1.492 (perp=7.070, rec=0.076, cos=0.002), tot_loss_proj:1.996 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.492 (perp=7.070, rec=0.076, cos=0.002), tot_loss_proj:1.991 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.485 (perp=7.070, rec=0.069, cos=0.002), tot_loss_proj:2.000 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
[1800/2000] tot_loss=1.489 (perp=7.070, rec=0.073, cos=0.002), tot_loss_proj:2.001 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1850/2000] tot_loss=1.487 (perp=7.070, rec=0.071, cos=0.002), tot_loss_proj:1.999 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.494 (perp=7.070, rec=0.078, cos=0.002), tot_loss_proj:2.001 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
[1950/2000] tot_loss=1.492 (perp=7.070, rec=0.076, cos=0.002), tot_loss_proj:1.996 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Attempt swap
[2000/2000] tot_loss=1.484 (perp=7.070, rec=0.069, cos=0.002), tot_loss_proj:1.996 [t=0.17s]
prediction: ["[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]"]
Done with input #95 of 100.
reference: 
========================
[CLS] ( denis') story becomes a hopeless, unsatisfying muddle [SEP]
========================
predicted: 
========================
[CLS] ('a muddle story becomes denis (sat unfying, hopeless ) [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 84.211 | p: 80.000 | r: 88.889
rouge2     | fm: 11.765 | p: 11.111 | r: 12.500
rougeL     | fm: 52.632 | p: 50.000 | r: 55.556
rougeLsum  | fm: 52.632 | p: 50.000 | r: 55.556
r1fm+r2fm = 95.975

[Aggregate metrics]:
rouge1     | fm: 89.421 | p: 88.642 | r: 90.315
rouge2     | fm: 53.946 | p: 53.638 | r: 54.292
rougeL     | fm: 77.319 | p: 76.757 | r: 77.998
rougeLsum  | fm: 77.275 | p: 76.680 | r: 77.997
r1fm+r2fm = 143.367

input #95 time: 0:06:50 | total time: 12:45:18


Running input #96 of 100.
reference: 
========================
force himself on people and into situations that would make lesser men run for cover 
========================
average of cosine similarity 0.9992866562400882
highest_index [0]
highest [0.9992866562400882]
Debug: ids_shape = 17, pads = [17]
Debug: input ids = tensor([[ 101, 2486, 2370, 2006, 2111, 1998, 2046, 8146, 2008, 2052, 2191, 8276,
         2273, 2448, 2005, 3104,  102]], device='cuda:0')
Debug: ref = ['[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]']
[Init] best rec loss: 1.794450283050537 for ['[CLS] all extended factor darethesis receiver depths fr disclosure billfold cool gall afford theoretical [SEP]']
[Init] best rec loss: 1.7930576801300049 for ['[CLS] earning poly dishes every mistaken as ok loose sage families morse platt we charm acts [SEP]']
[Init] best rec loss: 1.6783851385116577 for ['[CLS] robinson fits fr home professor shanghai virgin firing inside machlmancize arm decade [SEP]']
[Init] best rec loss: 1.6411691904067993 for ['[CLS] smashwords memoir spent soundinggn save statue time projectile typical living pondered august wig era [SEP]']
[Init] best rec loss: 1.634422779083252 for ['[CLS]rg woken became jenny marx further league performance union holding winning instrumental re distance conscious [SEP]']
[Init] best rec loss: 1.4709296226501465 for ['[CLS] hand hopefullysas super profit laundry readings context places liaison mollusk talents rest feature date [SEP]']
[Init] best perm rec loss: 1.466230869293213 for ['[CLS] profitsas hand rest hopefully places laundry mollusk date liaison feature talents readings context super [SEP]']
[Init] best perm rec loss: 1.4635539054870605 for ['[CLS] readings liaison profit places contextsas rest hopefully laundry feature hand talents date super mollusk [SEP]']
[Init] best perm rec loss: 1.4631778001785278 for ['[CLS] date hopefully laundry talents super profit restsas feature mollusk hand places context liaison readings [SEP]']
[Init] best perm rec loss: 1.4482918977737427 for ['[CLS] super profit context readings laundry places datesas feature hand liaison hopefully rest talents mollusk [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.868 (perp=12.530, rec=0.317, cos=0.045), tot_loss_proj:3.667 [t=0.17s]
prediction: ['[CLS] purpose owns something marathon worldwide courses segment forceers woman team situations feel people development [SEP]']
[ 100/2000] tot_loss=2.531 (perp=11.412, rec=0.234, cos=0.014), tot_loss_proj:3.445 [t=0.17s]
prediction: ['[CLS] force himself forcetime town places situations force in days men lesser run men forces [SEP]']
[ 150/2000] tot_loss=2.392 (perp=10.888, rec=0.202, cos=0.012), tot_loss_proj:3.383 [t=0.17s]
prediction: ['[CLS] force himself force into on back situations lust into cover cover lesser run people himself [SEP]']
[ 200/2000] tot_loss=2.360 (perp=10.951, rec=0.160, cos=0.009), tot_loss_proj:3.007 [t=0.17s]
prediction: ['[CLS] force himself force into on well situations lust would cover cover lesser into people himself [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.089 (perp=9.752, rec=0.133, cos=0.005), tot_loss_proj:2.998 [t=0.17s]
prediction: ['[CLS] force himself into force on well situations else would run cover lesser into people himself [SEP]']
[ 300/2000] tot_loss=2.146 (perp=10.074, rec=0.127, cos=0.004), tot_loss_proj:3.368 [t=0.17s]
prediction: ['[CLS] force himself into force on well situations proposal would run cover lesser into people it [SEP]']
Attempt swap
Moved token
[ 350/2000] tot_loss=1.968 (perp=9.238, rec=0.116, cos=0.004), tot_loss_proj:3.468 [t=0.17s]
prediction: ['[CLS] force himself and force on town else situations would run cover lesser into people it [SEP]']
Attempt swap
Swapped tokens
[ 400/2000] tot_loss=1.843 (perp=8.680, rec=0.102, cos=0.005), tot_loss_proj:3.089 [t=0.17s]
prediction: ['[CLS] force himself and force on well proposal situations would run cover lesser people into it [SEP]']
[ 450/2000] tot_loss=1.850 (perp=8.737, rec=0.099, cos=0.004), tot_loss_proj:3.172 [t=0.17s]
prediction: ['[CLS] force himself and force on town proposal situations would run cover lesser people into that [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.878 (perp=8.924, rec=0.089, cos=0.004), tot_loss_proj:3.228 [t=0.17s]
prediction: ['[CLS] force himself and force on word proposal situations would run cover lesser people into that [SEP]']
Attempt swap
Swapped tokens
[ 550/2000] tot_loss=1.785 (perp=8.435, rec=0.094, cos=0.004), tot_loss_proj:3.314 [t=0.17s]
prediction: ['[CLS] force himself and force on in more situations would run cover lesser people into proposal [SEP]']
[ 600/2000] tot_loss=1.763 (perp=8.335, rec=0.092, cos=0.003), tot_loss_proj:2.773 [t=0.17s]
prediction: ['[CLS] force himself and force on in that situations would run cover lesser people into proposal [SEP]']
Attempt swap
Moved token
[ 650/2000] tot_loss=1.845 (perp=8.758, rec=0.090, cos=0.003), tot_loss_proj:2.663 [t=0.17s]
prediction: ['[CLS] force himself and force on word situations that would run cover lesser people into proposal [SEP]']
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.704 (perp=8.061, rec=0.088, cos=0.004), tot_loss_proj:2.973 [t=0.17s]
prediction: ['[CLS] for himself and force on word situations that would run into lesser people cover proposal [SEP]']
[ 750/2000] tot_loss=1.499 (perp=7.062, rec=0.084, cos=0.003), tot_loss_proj:2.325 [t=0.17s]
prediction: ['[CLS] for himself and force on in situations that would run into lesser people cover women [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.662 (perp=7.838, rec=0.091, cos=0.003), tot_loss_proj:2.643 [t=0.17s]
prediction: ['[CLS] for himself and force on word situations that would run into lesser people cover men [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.662 (perp=7.838, rec=0.092, cos=0.003), tot_loss_proj:2.644 [t=0.17s]
prediction: ['[CLS] for himself and force on word situations that would run into lesser people cover men [SEP]']
[ 900/2000] tot_loss=1.665 (perp=7.838, rec=0.094, cos=0.003), tot_loss_proj:2.650 [t=0.17s]
prediction: ['[CLS] for himself and force on word situations that would run into lesser people cover men [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.692 (perp=7.993, rec=0.090, cos=0.003), tot_loss_proj:2.492 [t=0.17s]
prediction: ['[CLS] for himself and force on city situations that would run into lesser people cover men [SEP]']
Attempt swap
[1000/2000] tot_loss=1.683 (perp=7.993, rec=0.082, cos=0.003), tot_loss_proj:2.499 [t=0.17s]
prediction: ['[CLS] for himself and force on city situations that would run into lesser people cover men [SEP]']
[1050/2000] tot_loss=1.681 (perp=7.993, rec=0.080, cos=0.003), tot_loss_proj:2.490 [t=0.17s]
prediction: ['[CLS] for himself and force on city situations that would run into lesser people cover men [SEP]']
Attempt swap
[1100/2000] tot_loss=1.596 (perp=7.531, rec=0.087, cos=0.003), tot_loss_proj:2.615 [t=0.17s]
prediction: ['[CLS] for himself and force on for situations that would run into lesser people cover men [SEP]']
Attempt swap
[1150/2000] tot_loss=1.591 (perp=7.531, rec=0.083, cos=0.002), tot_loss_proj:2.611 [t=0.17s]
prediction: ['[CLS] for himself and force on for situations that would run into lesser people cover men [SEP]']
[1200/2000] tot_loss=1.595 (perp=7.531, rec=0.086, cos=0.002), tot_loss_proj:2.614 [t=0.17s]
prediction: ['[CLS] for himself and force on for situations that would run into lesser people cover men [SEP]']
Attempt swap
[1250/2000] tot_loss=1.595 (perp=7.531, rec=0.087, cos=0.002), tot_loss_proj:2.607 [t=0.17s]
prediction: ['[CLS] for himself and force on for situations that would run into lesser people cover men [SEP]']
Attempt swap
Swapped tokens
[1300/2000] tot_loss=1.565 (perp=7.403, rec=0.081, cos=0.003), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser people cover men [SEP]']
[1350/2000] tot_loss=1.563 (perp=7.403, rec=0.080, cos=0.002), tot_loss_proj:2.507 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser people cover men [SEP]']
Attempt swap
[1400/2000] tot_loss=1.559 (perp=7.403, rec=0.076, cos=0.002), tot_loss_proj:2.513 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser people cover men [SEP]']
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.529 (perp=7.217, rec=0.083, cos=0.002), tot_loss_proj:2.424 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]']
[1500/2000] tot_loss=1.528 (perp=7.217, rec=0.082, cos=0.002), tot_loss_proj:2.429 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]']
Attempt swap
[1550/2000] tot_loss=1.521 (perp=7.217, rec=0.075, cos=0.002), tot_loss_proj:2.418 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]']
Attempt swap
[1600/2000] tot_loss=1.523 (perp=7.217, rec=0.077, cos=0.002), tot_loss_proj:2.427 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]']
[1650/2000] tot_loss=1.523 (perp=7.217, rec=0.077, cos=0.002), tot_loss_proj:2.430 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]']
Attempt swap
[1700/2000] tot_loss=1.531 (perp=7.217, rec=0.085, cos=0.002), tot_loss_proj:2.425 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]']
Attempt swap
[1750/2000] tot_loss=1.524 (perp=7.217, rec=0.078, cos=0.002), tot_loss_proj:2.423 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]']
[1800/2000] tot_loss=1.516 (perp=7.217, rec=0.070, cos=0.002), tot_loss_proj:2.421 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]']
Attempt swap
[1850/2000] tot_loss=1.520 (perp=7.217, rec=0.074, cos=0.002), tot_loss_proj:2.423 [t=0.17s]
prediction: ['[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]']
Attempt swap
Swapped tokens
[1900/2000] tot_loss=1.489 (perp=7.027, rec=0.081, cos=0.003), tot_loss_proj:2.305 [t=0.17s]
prediction: ['[CLS] for himself on people and for situations that would run into lesser men cover force [SEP]']
[1950/2000] tot_loss=1.487 (perp=7.027, rec=0.079, cos=0.002), tot_loss_proj:2.303 [t=0.17s]
prediction: ['[CLS] for himself on people and for situations that would run into lesser men cover force [SEP]']
Attempt swap
[2000/2000] tot_loss=1.486 (perp=7.027, rec=0.078, cos=0.002), tot_loss_proj:2.299 [t=0.17s]
prediction: ['[CLS] for himself on people and for situations that would run into lesser men cover force [SEP]']
Done with input #96 of 100.
reference: 
========================
[CLS] force himself on people and into situations that would make lesser men run for cover [SEP]
========================
predicted: 
========================
[CLS] for himself on force and for situations that would run into lesser men cover people [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 94.118 | p: 94.118 | r: 94.118
rouge2     | fm: 25.000 | p: 25.000 | r: 25.000
rougeL     | fm: 64.706 | p: 64.706 | r: 64.706
rougeLsum  | fm: 64.706 | p: 64.706 | r: 64.706
r1fm+r2fm = 119.118

[Aggregate metrics]:
rouge1     | fm: 89.401 | p: 88.693 | r: 90.236
rouge2     | fm: 53.345 | p: 53.075 | r: 53.658
rougeL     | fm: 77.204 | p: 76.566 | r: 77.953
rougeLsum  | fm: 77.188 | p: 76.555 | r: 77.833
r1fm+r2fm = 142.745

input #96 time: 0:06:50 | total time: 12:52:08


Running input #97 of 100.
reference: 
========================
and unforgettable characters 
========================
average of cosine similarity 0.9991660915875735
highest_index [0]
highest [0.9991660915875735]
Debug: ids_shape = 8, pads = [8]
Debug: input ids = tensor([[  101,  1998,  4895, 29278, 18150, 10880,  3494,   102]],
       device='cuda:0')
Debug: ref = ['[CLS] and unforgettable characters [SEP]']
[Init] best rec loss: 1.292439579963684 for ['[CLS] ring halt populated rich striking miranda [SEP]']
[Init] best rec loss: 1.0615618228912354 for ['[CLS]ten which 2016 victoria pass test [SEP]']
[Init] best perm rec loss: 1.0516561269760132 for ['[CLS] victoriaten test pass 2016 which [SEP]']
[Init] best perm rec loss: 1.0462650060653687 for ['[CLS] pass testten which 2016 victoria [SEP]']
[Init] best perm rec loss: 1.0451700687408447 for ['[CLS] pass test victoriaten 2016 which [SEP]']
[Init] best perm rec loss: 1.0422724485397339 for ['[CLS] victoria test 2016 pass whichten [SEP]']
[Init] best perm rec loss: 1.0385247468948364 for ['[CLS] pass test which victoria 2016ten [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=2.530 (perp=11.207, rec=0.272, cos=0.017), tot_loss_proj:4.118 [t=0.17s]
prediction: ['[CLS]fortableforforfor characters [SEP]']
[ 100/2000] tot_loss=2.270 (perp=10.361, rec=0.186, cos=0.012), tot_loss_proj:3.477 [t=0.17s]
prediction: ['[CLS]gettablefortabletable characters [SEP]']
[ 150/2000] tot_loss=2.269 (perp=10.686, rec=0.121, cos=0.010), tot_loss_proj:3.204 [t=0.17s]
prediction: ['[CLS]get unfortabletable characters [SEP]']
[ 200/2000] tot_loss=2.271 (perp=10.686, rec=0.126, cos=0.007), tot_loss_proj:3.220 [t=0.17s]
prediction: ['[CLS]get unfortabletable characters [SEP]']
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=1.480 (perp=6.679, rec=0.133, cos=0.011), tot_loss_proj:1.651 [t=0.17s]
prediction: ['[CLS]table unforgettable characters [SEP]']
[ 300/2000] tot_loss=1.440 (perp=6.679, rec=0.098, cos=0.007), tot_loss_proj:1.662 [t=0.17s]
prediction: ['[CLS]table unforgettable characters [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.440 (perp=6.679, rec=0.099, cos=0.005), tot_loss_proj:1.674 [t=0.17s]
prediction: ['[CLS]table unforgettable characters [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.676 (perp=7.875, rec=0.096, cos=0.005), tot_loss_proj:2.319 [t=0.17s]
prediction: ['[CLS]tier unforgettable characters [SEP]']
[ 450/2000] tot_loss=1.156 (perp=5.309, rec=0.090, cos=0.004), tot_loss_proj:1.142 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.131 (perp=5.309, rec=0.068, cos=0.002), tot_loss_proj:1.132 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.123 (perp=5.309, rec=0.060, cos=0.002), tot_loss_proj:1.124 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 600/2000] tot_loss=1.119 (perp=5.309, rec=0.056, cos=0.002), tot_loss_proj:1.126 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.131 (perp=5.309, rec=0.067, cos=0.002), tot_loss_proj:1.130 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.122 (perp=5.309, rec=0.059, cos=0.002), tot_loss_proj:1.117 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 750/2000] tot_loss=1.128 (perp=5.309, rec=0.064, cos=0.002), tot_loss_proj:1.130 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.112 (perp=5.309, rec=0.049, cos=0.002), tot_loss_proj:1.128 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.137 (perp=5.309, rec=0.073, cos=0.002), tot_loss_proj:1.127 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[ 900/2000] tot_loss=1.119 (perp=5.309, rec=0.056, cos=0.002), tot_loss_proj:1.122 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.118 (perp=5.309, rec=0.054, cos=0.002), tot_loss_proj:1.124 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1000/2000] tot_loss=1.122 (perp=5.309, rec=0.059, cos=0.002), tot_loss_proj:1.130 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1050/2000] tot_loss=1.123 (perp=5.309, rec=0.059, cos=0.002), tot_loss_proj:1.133 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1100/2000] tot_loss=1.120 (perp=5.309, rec=0.057, cos=0.002), tot_loss_proj:1.128 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1150/2000] tot_loss=1.119 (perp=5.309, rec=0.055, cos=0.002), tot_loss_proj:1.131 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1200/2000] tot_loss=1.123 (perp=5.309, rec=0.060, cos=0.002), tot_loss_proj:1.121 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1250/2000] tot_loss=1.133 (perp=5.309, rec=0.069, cos=0.002), tot_loss_proj:1.123 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1300/2000] tot_loss=1.121 (perp=5.309, rec=0.057, cos=0.002), tot_loss_proj:1.130 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1350/2000] tot_loss=1.122 (perp=5.309, rec=0.058, cos=0.002), tot_loss_proj:1.126 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1400/2000] tot_loss=1.122 (perp=5.309, rec=0.058, cos=0.002), tot_loss_proj:1.114 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1450/2000] tot_loss=1.132 (perp=5.309, rec=0.068, cos=0.002), tot_loss_proj:1.122 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1500/2000] tot_loss=1.133 (perp=5.309, rec=0.070, cos=0.002), tot_loss_proj:1.119 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1550/2000] tot_loss=1.127 (perp=5.309, rec=0.064, cos=0.002), tot_loss_proj:1.131 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1600/2000] tot_loss=1.131 (perp=5.309, rec=0.067, cos=0.002), tot_loss_proj:1.131 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1650/2000] tot_loss=1.118 (perp=5.309, rec=0.055, cos=0.002), tot_loss_proj:1.135 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1700/2000] tot_loss=1.133 (perp=5.309, rec=0.069, cos=0.002), tot_loss_proj:1.132 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1750/2000] tot_loss=1.122 (perp=5.309, rec=0.058, cos=0.002), tot_loss_proj:1.122 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1800/2000] tot_loss=1.119 (perp=5.309, rec=0.056, cos=0.002), tot_loss_proj:1.128 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1850/2000] tot_loss=1.132 (perp=5.309, rec=0.068, cos=0.002), tot_loss_proj:1.129 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[1900/2000] tot_loss=1.112 (perp=5.309, rec=0.048, cos=0.002), tot_loss_proj:1.132 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
[1950/2000] tot_loss=1.129 (perp=5.309, rec=0.066, cos=0.002), tot_loss_proj:1.134 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Attempt swap
[2000/2000] tot_loss=1.129 (perp=5.309, rec=0.065, cos=0.002), tot_loss_proj:1.123 [t=0.17s]
prediction: ['[CLS] and unforgettable characters [SEP]']
Done with input #97 of 100.
reference: 
========================
[CLS] and unforgettable characters [SEP]
========================
predicted: 
========================
[CLS] and unforgettable characters [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.578 | p: 88.819 | r: 90.403
rouge2     | fm: 54.022 | p: 53.693 | r: 54.380
rougeL     | fm: 77.437 | p: 76.870 | r: 78.107
rougeLsum  | fm: 77.388 | p: 76.816 | r: 78.122
r1fm+r2fm = 143.599

input #97 time: 0:06:56 | total time: 12:59:05


Running input #98 of 100.
reference: 
========================
unfulfilling 
========================
average of cosine similarity 0.9991916976323436
highest_index [0]
highest [0.9991916976323436]
Debug: ids_shape = 6, pads = [6]
Debug: input ids = tensor([[  101,  4895,  3993,  8873, 13112,   102]], device='cuda:0')
Debug: ref = ['[CLS] unfulfilling [SEP]']
[Init] best rec loss: 1.1314566135406494 for ['[CLS] prohibited jed ada nos [SEP]']
[Init] best rec loss: 1.1208252906799316 for ['[CLS] nature " open victims [SEP]']
[Init] best perm rec loss: 1.1160643100738525 for ['[CLS] " victims nature open [SEP]']
Nsteps: 2000
[  50/2000] tot_loss=3.253 (perp=14.382, rec=0.345, cos=0.032), tot_loss_proj:4.742 [t=0.24s]
prediction: ['[CLS]ditional 2002 pouredful [SEP]']
[ 100/2000] tot_loss=2.555 (perp=11.484, rec=0.244, cos=0.015), tot_loss_proj:3.289 [t=0.17s]
prediction: ['[CLS]fulsteadfulful [SEP]']
[ 150/2000] tot_loss=2.417 (perp=11.177, rec=0.174, cos=0.008), tot_loss_proj:3.018 [t=0.17s]
prediction: ['[CLS] unfifulful [SEP]']
[ 200/2000] tot_loss=2.206 (perp=10.508, rec=0.101, cos=0.003), tot_loss_proj:2.525 [t=0.17s]
prediction: ['[CLS] unfifullling [SEP]']
Attempt swap
Moved token
[ 250/2000] tot_loss=1.080 (perp=4.948, rec=0.087, cos=0.003), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 300/2000] tot_loss=1.060 (perp=4.948, rec=0.069, cos=0.002), tot_loss_proj:1.062 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 350/2000] tot_loss=1.056 (perp=4.948, rec=0.064, cos=0.003), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 400/2000] tot_loss=1.056 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 450/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 500/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.072 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 550/2000] tot_loss=1.057 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 600/2000] tot_loss=1.060 (perp=4.948, rec=0.069, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 650/2000] tot_loss=1.055 (perp=4.948, rec=0.064, cos=0.002), tot_loss_proj:1.066 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 700/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 750/2000] tot_loss=1.041 (perp=4.948, rec=0.050, cos=0.002), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 800/2000] tot_loss=1.042 (perp=4.948, rec=0.050, cos=0.002), tot_loss_proj:1.060 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 850/2000] tot_loss=1.036 (perp=4.948, rec=0.045, cos=0.002), tot_loss_proj:1.074 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[ 900/2000] tot_loss=1.064 (perp=4.948, rec=0.072, cos=0.002), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[ 950/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1000/2000] tot_loss=1.043 (perp=4.948, rec=0.051, cos=0.002), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1050/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.065 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1100/2000] tot_loss=1.054 (perp=4.948, rec=0.062, cos=0.002), tot_loss_proj:1.061 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1150/2000] tot_loss=1.045 (perp=4.948, rec=0.054, cos=0.002), tot_loss_proj:1.054 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1200/2000] tot_loss=1.060 (perp=4.948, rec=0.069, cos=0.002), tot_loss_proj:1.057 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1250/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1300/2000] tot_loss=1.056 (perp=4.948, rec=0.065, cos=0.002), tot_loss_proj:1.049 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1350/2000] tot_loss=1.052 (perp=4.948, rec=0.061, cos=0.002), tot_loss_proj:1.067 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1400/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.052 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1450/2000] tot_loss=1.044 (perp=4.948, rec=0.052, cos=0.002), tot_loss_proj:1.051 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1500/2000] tot_loss=1.054 (perp=4.948, rec=0.063, cos=0.002), tot_loss_proj:1.058 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1550/2000] tot_loss=1.044 (perp=4.948, rec=0.053, cos=0.002), tot_loss_proj:1.046 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1600/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1650/2000] tot_loss=1.051 (perp=4.948, rec=0.060, cos=0.002), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1700/2000] tot_loss=1.039 (perp=4.948, rec=0.047, cos=0.002), tot_loss_proj:1.063 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1750/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1800/2000] tot_loss=1.049 (perp=4.948, rec=0.058, cos=0.002), tot_loss_proj:1.056 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1850/2000] tot_loss=1.050 (perp=4.948, rec=0.059, cos=0.002), tot_loss_proj:1.055 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[1900/2000] tot_loss=1.058 (perp=4.948, rec=0.067, cos=0.002), tot_loss_proj:1.064 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
[1950/2000] tot_loss=1.047 (perp=4.948, rec=0.056, cos=0.002), tot_loss_proj:1.059 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Attempt swap
[2000/2000] tot_loss=1.058 (perp=4.948, rec=0.066, cos=0.002), tot_loss_proj:1.056 [t=0.17s]
prediction: ['[CLS] unfulfilling [SEP]']
Done with input #98 of 100.
reference: 
========================
[CLS] unfulfilling [SEP]
========================
predicted: 
========================
[CLS] unfulfilling [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 100.000 | p: 100.000 | r: 100.000
rouge2     | fm: 100.000 | p: 100.000 | r: 100.000
rougeL     | fm: 100.000 | p: 100.000 | r: 100.000
rougeLsum  | fm: 100.000 | p: 100.000 | r: 100.000
r1fm+r2fm = 200.000

[Aggregate metrics]:
rouge1     | fm: 89.677 | p: 88.939 | r: 90.519
rouge2     | fm: 54.583 | p: 54.263 | r: 54.925
rougeL     | fm: 77.624 | p: 77.010 | r: 78.262
rougeLsum  | fm: 77.583 | p: 76.982 | r: 78.267
r1fm+r2fm = 144.259

input #98 time: 0:06:46 | total time: 13:05:52


Running input #99 of 100.
reference: 
========================
walked out muttering words like `` horrible '' and `` terrible , '' but had so much fun dissing the film that they did n't mind the ticket cost 
========================
average of cosine similarity 0.9993095816453154
highest_index [0]
highest [0.9993095816453154]
Debug: ids_shape = 38, pads = [38]
Debug: input ids = tensor([[  101,  2939,  2041, 22581,  2616,  2066,  1036,  1036,  9202,  1005,
          1005,  1998,  1036,  1036,  6659,  1010,  1005,  1005,  2021,  2018,
          2061,  2172,  4569,  4487, 18965,  1996,  2143,  2008,  2027,  2106,
          1050,  1005,  1056,  2568,  1996,  7281,  3465,   102]],
       device='cuda:0')
Debug: ref = ["[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]"]
[Init] best rec loss: 1.5378683805465698 for ['[CLS]tering aleباد were edition transmission now church around era equal enough specific mad ed alba contributors does printed sustainabilitynal gig squad bunch demonstration position should chu rankingdie outer matingurgent fenton stuff immediate [SEP]']
[Init] best rec loss: 1.4138236045837402 for ['[CLS] true rules study britain key division [SEP] o canteen flu meadows another throw beating no alignment master than fair este department profit cam endurance here media tragedy mother bird vest super lineage intersection drum { nan [SEP]']
[Init] best rec loss: 1.3704537153244019 for ['[CLS] nature pena chuck turns wig department never lay clancy synth maxi past verse my pueblo part ancient angel flash work colin sufficient vowel * scale cast energy strawberry intra lookical million bates assent laughter forth [SEP]']
[Init] best rec loss: 1.3552578687667847 for ['[CLS] football trust o guide every into integral? maybe200nington just layne what alaska priory incidentffled gymnastics manufactured lines kim survived told particularlygui discipline lonely # level pointsuna loves leaving it providence [SEP]']
[Init] best rec loss: 1.3264182806015015 for ['[CLS] jail england serves maggie point acid travis dual hell [MASK] judgment urban caledonia story lost fallsnum steps titleisinge classified mine live byron guitarists s mineral considered pow pride signage [SEP] avalon street heavily [SEP]']
[Init] best rec loss: 1.2738163471221924 for ['[CLS] claireˈ ratings cushionts bearing orient slight actually harper taste screens when thunder synonym ferns [MASK] garcia still services bet earliest re himself right barbie knowledge forced opposed currentlyaging distance te temps dentalte [SEP]']
[Init] best rec loss: 1.2734564542770386 for ["[CLS]jevic authority could victory gregory u yearquin choshing though horton else final obama authored speeding'recreation as disgust grace heroin his door pronunciationlu heel japanese nehru lower distinguished mere buenos base whether [SEP]"]
[Init] best perm rec loss: 1.2730098962783813 for ["[CLS] grace whether mere u nehrushing could recreation heroin base year distinguished victory pronunciation gregory authority disgust final as lower speeding hortonquin his'japanese though heel obamalu else buenosjevic authored cho door [SEP]"]
[Init] best perm rec loss: 1.27029550075531 for ["[CLS] final base as victory though disgust door gregory obama distinguished mere u yearquin'authored heel japanese could horton lower else nehru authority cho heroin pronunciation buenos grace whetherlujevicshing his speeding recreation [SEP]"]
[Init] best perm rec loss: 1.2686342000961304 for ["[CLS] victory speeding'year obama u whether mere heel japanesequin heroin his door buenos could else distinguished final authority authored grace nehru recreation horton lower disgust gregory pronunciation thoughlushing as chojevic base [SEP]"]
[Init] best perm rec loss: 1.2669504880905151 for ["[CLS] lower disgust his buenos as speeding year authored obama base mere distinguished grace victory whether though final heelshing heroin doorjevic nehru gregory u japanese'authority couldquin elselu pronunciation recreation cho horton [SEP]"]
[Init] best perm rec loss: 1.261819839477539 for ["[CLS] year buenos japanese though'u couldquin distinguished obama else door heel nehru authority final speeding cho whether victory as base pronunciation disgust heroinshing gregory grace hortonjevic lower recreation authoredlu his mere [SEP]"]
[Init] best perm rec loss: 1.257513165473938 for ["[CLS] grace distinguished could horton base his heroin though final victory else lower heelquin gregory obama door authority u authored'mere as speeding buenosjevic year cho whetherlu japanese recreation nehru disgust pronunciationshing [SEP]"]
[Init] best perm rec loss: 1.2564736604690552 for ["[CLS] base lower buenos gregory authority year pronunciation recreationquin nehru though disgust u speeding japanese cho victory authored grace door as could distinguished heroinshinglujevic final heel horton obama whether'his mere else [SEP]"]
[Init] best perm rec loss: 1.2494480609893799 for ["[CLS] victory u distinguished disgust gregory heroin authoredshing buenos grace else year lower heel mere finallu pronunciation'cho recreation though whetherquin door could base japanese obama his as nehrujevic speeding authority horton [SEP]"]
Nsteps: 2000
[  50/2000] tot_loss=2.610 (perp=11.452, rec=0.303, cos=0.016), tot_loss_proj:3.335 [t=0.17s]
prediction: ['[CLS] atoms complete stalking everything dinner fraud none cursed movie didn done when jaenelle ulster but uefa badssing the film crew expected something okay givinging ran planning the package bullshit coin the another cents enhanced [SEP]']
[ 100/2000] tot_loss=2.311 (perp=10.430, rec=0.213, cos=0.011), tot_loss_proj:3.391 [t=0.17s]
prediction: ['[CLS] weeks ` stalking everything ticket poetry were terrible film reason minded when ` their but fun dissing the film!ssing something okay givinging walked into the passengers funff the the cents enhanced [SEP]']
[ 150/2000] tot_loss=2.052 (perp=9.399, rec=0.166, cos=0.006), tot_loss_proj:2.969 [t=0.17s]
prediction: ["[CLS] walked ` out everything ticket out were terrible film'minded that ` because but fun dissing the film somethingssing'terrible givinging walked into that ticket fun enjoy the the ticket, [SEP]"]
[ 200/2000] tot_loss=2.093 (perp=9.655, rec=0.154, cos=0.008), tot_loss_proj:2.587 [t=0.17s]
prediction: ["[CLS] walked ` muttering everything ticket out were terrible film'minded that ` bros but fun dissing the film theyssing so horrible di had walked into they ticket fun mind the the cost'[SEP]"]
Attempt swap
Swapped tokens
[ 250/2000] tot_loss=2.102 (perp=9.882, rec=0.120, cos=0.005), tot_loss_proj:2.694 [t=0.17s]
prediction: ["[CLS] walked ` muttering everything ticket out didn terrible films ticket minded that `'but fun dissing the film thatssing so horrible di had walked do they'fun mind their the cost'[SEP]"]
[ 300/2000] tot_loss=2.214 (perp=10.506, rec=0.109, cos=0.004), tot_loss_proj:2.980 [t=0.17s]
prediction: ["[CLS] walked ` muttering everything ticket out didn terrible ` n minded that `'but fun dissing the film thatssing so horrible inclusion had walked does they ` fun mind they the cost'[SEP]"]
Attempt swap
Swapped tokens
[ 350/2000] tot_loss=1.943 (perp=9.182, rec=0.103, cos=0.004), tot_loss_proj:2.574 [t=0.17s]
prediction: ["[CLS] walked ` muttering everything ticket out t terrible'' minded that `ssing but fun dissing the film that'so horrible'had walked does they ` fun mind they the cost'[SEP]"]
Attempt swap
Moved sequence
[ 400/2000] tot_loss=1.961 (perp=9.302, rec=0.097, cos=0.003), tot_loss_proj:2.566 [t=0.17s]
prediction: ["[CLS] walked ` muttering'ticket out t terrible'' minded that `ssing but fun dissing the film product'so horrible ( had walkedn'they ` fun mind they the cost [SEP]"]
[ 450/2000] tot_loss=1.949 (perp=9.260, rec=0.093, cos=0.003), tot_loss_proj:2.636 [t=0.17s]
prediction: ["[CLS] walked ` muttering'ticket out t terrible'' i that `ssing but fun dissing the film product'so horrible'had walkedn'they ` fun mind they the cost [SEP]"]
Attempt swap
Swapped tokens
[ 500/2000] tot_loss=1.886 (perp=9.002, rec=0.083, cos=0.003), tot_loss_proj:2.582 [t=0.17s]
prediction: ["[CLS] walked ` muttering'ticket out t terrible film'myself that `ssing but fun dissing the'product'so horrible'had walkedn'they ` fun mind they the cost [SEP]"]
Attempt swap
Moved token
[ 550/2000] tot_loss=1.895 (perp=8.995, rec=0.093, cos=0.003), tot_loss_proj:2.553 [t=0.17s]
prediction: ["[CLS] walked ` muttering'ticket out t terrible film'outer that `ssing but much dissing the'them'so horrible'had walked then'they ` fun mind they cost [SEP]"]
[ 600/2000] tot_loss=1.839 (perp=8.761, rec=0.084, cos=0.003), tot_loss_proj:2.522 [t=0.17s]
prediction: ["[CLS] walked ` muttering'ticket out t terrible film'' that `ssing but much dissing the'them'so horrible'had walked then'they ` fun mind they cost [SEP]"]
Attempt swap
Swapped tokens
[ 650/2000] tot_loss=1.805 (perp=8.598, rec=0.083, cos=0.003), tot_loss_proj:2.483 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t terrible film'' that `ssing but much dissing the'product'so horrible'had walked then'they walked fun mind they cost [SEP]"]
Attempt swap
Swapped tokens
[ 700/2000] tot_loss=1.774 (perp=8.439, rec=0.083, cos=0.003), tot_loss_proj:2.403 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible lips that `ssing but much dissing the'product'so horrible'had walked then'they walked fun mind they cost [SEP]"]
[ 750/2000] tot_loss=1.742 (perp=8.240, rec=0.092, cos=0.002), tot_loss_proj:2.336 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible'that `ssing but much dissing the'product'so horrible, had walked then'they walked fun mind they cost [SEP]"]
Attempt swap
Swapped tokens
[ 800/2000] tot_loss=1.736 (perp=8.260, rec=0.082, cos=0.002), tot_loss_proj:2.341 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible'that ` lips but much dissing the'product'so horrible, had walked didn'they walked fun mind they cost [SEP]"]
Attempt swap
Moved token
[ 850/2000] tot_loss=1.694 (perp=8.067, rec=0.079, cos=0.002), tot_loss_proj:2.400 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible'that ` lips much dissing but the'product'so horrible, had walked didn'they walked fun mind they cost [SEP]"]
[ 900/2000] tot_loss=1.701 (perp=8.067, rec=0.086, cos=0.002), tot_loss_proj:2.400 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible'that ` lips much dissing but the'product'so horrible, had walked didn'they walked fun mind they cost [SEP]"]
Attempt swap
Swapped tokens
[ 950/2000] tot_loss=1.677 (perp=7.987, rec=0.078, cos=0.002), tot_loss_proj:2.377 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible much that ` lips'dissing but the'product'so horrible, had walked didn'they walked fun mind they cost [SEP]"]
Attempt swap
Swapped tokens
[1000/2000] tot_loss=1.638 (perp=7.782, rec=0.079, cos=0.002), tot_loss_proj:2.375 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible much that ` lips'dissing but the'product'so horrible they had walked didn'they walked fun mind, cost [SEP]"]
[1050/2000] tot_loss=1.639 (perp=7.782, rec=0.081, cos=0.002), tot_loss_proj:2.379 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible much that ` lips'dissing but the'product'so horrible they had walked didn'they walked fun mind, cost [SEP]"]
Attempt swap
Moved sequence
[1100/2000] tot_loss=1.572 (perp=7.455, rec=0.079, cos=0.002), tot_loss_proj:2.276 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible much'that `'dissing but the'product'so horrible they had walked didn'they walked fun mind, cost [SEP]"]
Attempt swap
Swapped tokens
[1150/2000] tot_loss=1.560 (perp=7.411, rec=0.076, cos=0.002), tot_loss_proj:2.328 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible much'that `'dissing but the'product'so horrible they had walked didn'they walked fun, mind cost [SEP]"]
[1200/2000] tot_loss=1.611 (perp=7.647, rec=0.080, cos=0.002), tot_loss_proj:2.319 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible much'that `'dissing but the'product'so horrible they had walked did n'' walked fun, mind cost [SEP]"]
Attempt swap
Swapped tokens
[1250/2000] tot_loss=1.566 (perp=7.424, rec=0.080, cos=0.002), tot_loss_proj:2.238 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible much'that `'dissing but the'product'so horrible they had walked did n'walked'fun, mind cost [SEP]"]
Attempt swap
[1300/2000] tot_loss=1.544 (perp=7.302, rec=0.081, cos=0.002), tot_loss_proj:2.324 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible much'that `'dissing but the'that'so horrible they had walked did n'walked'fun, mind cost [SEP]"]
[1350/2000] tot_loss=1.538 (perp=7.302, rec=0.076, cos=0.002), tot_loss_proj:2.327 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film terrible much'that `'dissing but the'that'so horrible they had walked did n'walked'fun, mind cost [SEP]"]
Attempt swap
Moved token
[1400/2000] tot_loss=1.531 (perp=7.266, rec=0.076, cos=0.002), tot_loss_proj:2.330 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film much terrible'that `'dissing but the'that'so horrible they had walked did n'walked'fun, mind cost [SEP]"]
Attempt swap
Swapped tokens
[1450/2000] tot_loss=1.571 (perp=7.447, rec=0.079, cos=0.002), tot_loss_proj:3.166 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film much terrible'that `'dissing but the'that'so horrible they had walked they n'walked did fun, mind cost [SEP]"]
[1500/2000] tot_loss=1.577 (perp=7.511, rec=0.074, cos=0.002), tot_loss_proj:3.156 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film much terrible'that `'dissing but the'the'so horrible they had walked they n'walked did fun, mind cost [SEP]"]
Attempt swap
Moved token
[1550/2000] tot_loss=1.555 (perp=7.397, rec=0.074, cos=0.002), tot_loss_proj:3.162 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket out t'film'much terrible that `'dissing but the'the'so horrible they had walked they n'walked did fun, mind cost [SEP]"]
Attempt swap
Swapped tokens
[1600/2000] tot_loss=1.480 (perp=7.003, rec=0.078, cos=0.002), tot_loss_proj:3.055 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket't'film'much terrible that `'dissing but the'the out so horrible they had walked'n'walked did fun, mind cost [SEP]"]
[1650/2000] tot_loss=1.475 (perp=7.003, rec=0.072, cos=0.002), tot_loss_proj:3.055 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket't'film'much terrible that `'dissing but the'the out so horrible they had walked'n'walked did fun, mind cost [SEP]"]
Attempt swap
[1700/2000] tot_loss=1.488 (perp=7.003, rec=0.086, cos=0.002), tot_loss_proj:3.057 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket't'film'much terrible that `'dissing but the'the out so horrible they had walked'n'walked did fun, mind cost [SEP]"]
Attempt swap
[1750/2000] tot_loss=1.479 (perp=7.003, rec=0.077, cos=0.002), tot_loss_proj:3.053 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket't'film'much terrible that `'dissing but the'the out so horrible they had walked'n'walked did fun, mind cost [SEP]"]
[1800/2000] tot_loss=1.477 (perp=7.003, rec=0.074, cos=0.002), tot_loss_proj:3.054 [t=0.17s]
prediction: ["[CLS] ` ` muttering'ticket't'film'much terrible that `'dissing but the'the out so horrible they had walked'n'walked did fun, mind cost [SEP]"]
Attempt swap
Swapped tokens
[1850/2000] tot_loss=1.456 (perp=6.869, rec=0.081, cos=0.002), tot_loss_proj:3.109 [t=0.17s]
prediction: ["[CLS] ` ` muttering'n't'film'much terrible that `'dissing but the'the out so horrible they had walked'ticket'walked did fun, mind cost [SEP]"]
Attempt swap
[1900/2000] tot_loss=1.453 (perp=6.869, rec=0.077, cos=0.002), tot_loss_proj:3.111 [t=0.17s]
prediction: ["[CLS] ` ` muttering'n't'film'much terrible that `'dissing but the'the out so horrible they had walked'ticket'walked did fun, mind cost [SEP]"]
[1950/2000] tot_loss=1.442 (perp=6.869, rec=0.066, cos=0.002), tot_loss_proj:3.112 [t=0.17s]
prediction: ["[CLS] ` ` muttering'n't'film'much terrible that `'dissing but the'the out so horrible they had walked'ticket'walked did fun, mind cost [SEP]"]
Attempt swap
Swapped tokens
[2000/2000] tot_loss=1.427 (perp=6.754, rec=0.074, cos=0.002), tot_loss_proj:3.146 [t=0.17s]
prediction: ["[CLS] ` ` muttering'n't'film that much terrible'`'dissing but the'the out so horrible they had walked'ticket'walked did fun, mind cost [SEP]"]
Done with input #99 of 100.
reference: 
========================
[CLS] walked out muttering words like ` ` horrible'' and ` ` terrible,'' but had so much fun dissing the film that they didn't mind the ticket cost [SEP]
========================
predicted: 
========================
[CLS] ` ` muttering'ticket't'film'much terrible that `'dissing but the'the out so horrible they had walked'n'walked did fun, mind cost [SEP]
========================
[Curr input metrics]:
rouge1     | fm: 86.275 | p: 88.000 | r: 84.615
rouge2     | fm: 4.082 | p: 4.167 | r: 4.000
rougeL     | fm: 35.294 | p: 36.000 | r: 34.615
rougeLsum  | fm: 35.294 | p: 36.000 | r: 34.615
r1fm+r2fm = 90.356

[Aggregate metrics]:
rouge1     | fm: 89.626 | p: 88.956 | r: 90.519
rouge2     | fm: 53.913 | p: 53.624 | r: 54.231
rougeL     | fm: 77.138 | p: 76.591 | r: 77.819
rougeLsum  | fm: 77.240 | p: 76.649 | r: 77.915
r1fm+r2fm = 143.539

input #99 time: 0:06:47 | total time: 13:12:40


Average Cosine Similarity: 0.9992812683158312
Done with all.
